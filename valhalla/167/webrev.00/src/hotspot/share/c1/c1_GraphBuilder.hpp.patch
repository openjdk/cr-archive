diff a/src/hotspot/share/c1/c1_GraphBuilder.hpp b/src/hotspot/share/c1/c1_GraphBuilder.hpp
--- a/src/hotspot/share/c1/c1_GraphBuilder.hpp
+++ b/src/hotspot/share/c1/c1_GraphBuilder.hpp
@@ -33,10 +33,30 @@
 #include "ci/ciStreams.hpp"
 #include "compiler/compileLog.hpp"
 
 class MemoryBuffer;
 
+class DelayedFlattenedFieldAccess : public CompilationResourceObj {
+private:
+  Value _obj;
+  ciField* _field;
+  int _offset;
+public:
+  DelayedFlattenedFieldAccess(Value obj, ciField* field, int offset)
+  : _obj(obj)
+  , _field(field)
+  , _offset(offset) { }
+
+  void update(ciField* field, int offset) {
+    _field = field;
+    _offset += offset;
+  }
+  Value obj() { return _obj; }
+  ciField* field() { return _field; }
+  int offset() { return _offset; }
+};
+
 class GraphBuilder {
  private:
   // Per-scope data. These are pushed and popped as we descend into
   // inlined methods. Currently in order to generate good code in the
   // inliner we have to attempt to inline methods directly into the
@@ -189,10 +209,14 @@
   BlockBegin*       _block;                      // the current block
   ValueStack*       _state;                      // the current execution state
   Instruction*      _last;                       // the last instruction added
   bool              _skip_block;                 // skip processing of the rest of this block
 
+  DelayedFlattenedFieldAccess* _delayed_flattened_field_access;
+  bool              has_delayed_flattened_field_access() { return _delayed_flattened_field_access != NULL; }
+
+
   // accessors
   ScopeData*        scope_data() const           { return _scope_data; }
   Compilation*      compilation() const          { return _compilation; }
   BlockList*        bci2block() const            { return scope_data()->bci2block(); }
   ValueMap*         vmap() const                 { assert(UseLocalValueNumbering, "should not access otherwise"); return _vmap; }
