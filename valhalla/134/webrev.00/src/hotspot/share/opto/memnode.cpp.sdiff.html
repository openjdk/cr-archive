<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/memnode.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="macroArrayCopy.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../../../../test/hotspot/jtreg/compiler/valhalla/inlinetypes/TestNullableArrays.java.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/memnode.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 205 
 206 Node *MemNode::optimize_memory_chain(Node *mchain, const TypePtr *t_adr, Node *load, PhaseGVN *phase) {
 207   const TypeOopPtr* t_oop = t_adr-&gt;isa_oopptr();
 208   if (t_oop == NULL)
 209     return mchain;  // don&#39;t try to optimize non-oop types
 210   Node* result = optimize_simple_memory_chain(mchain, t_oop, load, phase);
 211   bool is_instance = t_oop-&gt;is_known_instance_field();
 212   PhaseIterGVN *igvn = phase-&gt;is_IterGVN();
 213   if (is_instance &amp;&amp; igvn != NULL &amp;&amp; result-&gt;is_Phi()) {
 214     PhiNode *mphi = result-&gt;as_Phi();
 215     assert(mphi-&gt;bottom_type() == Type::MEMORY, &quot;memory phi required&quot;);
 216     const TypePtr *t = mphi-&gt;adr_type();
 217     if (t == TypePtr::BOTTOM || t == TypeRawPtr::BOTTOM ||
 218         (t-&gt;isa_oopptr() &amp;&amp; !t-&gt;is_oopptr()-&gt;is_known_instance() &amp;&amp;
 219          t-&gt;is_oopptr()-&gt;cast_to_exactness(true)
 220            -&gt;is_oopptr()-&gt;cast_to_ptr_type(t_oop-&gt;ptr())
 221             -&gt;is_oopptr()-&gt;cast_to_instance_id(t_oop-&gt;instance_id()) == t_oop)) {
 222       // clone the Phi with our address type
 223       result = mphi-&gt;split_out_instance(t_adr, igvn);
 224     } else {





 225       assert(phase-&gt;C-&gt;get_alias_index(t) == phase-&gt;C-&gt;get_alias_index(t_adr), &quot;correct memory chain&quot;);
 226     }
 227   }
 228   return result;
 229 }
 230 
 231 static Node *step_through_mergemem(PhaseGVN *phase, MergeMemNode *mmem,  const TypePtr *tp, const TypePtr *adr_check, outputStream *st) {
 232   uint alias_idx = phase-&gt;C-&gt;get_alias_index(tp);
 233   Node *mem = mmem;
 234 #ifdef ASSERT
 235   {
 236     // Check that current type is consistent with the alias index used during graph construction
 237     assert(alias_idx &gt;= Compile::AliasIdxRaw, &quot;must not be a bad alias_idx&quot;);
 238     bool consistent =  adr_check == NULL || adr_check-&gt;empty() ||
 239                        phase-&gt;C-&gt;must_alias(adr_check, alias_idx );
 240     // Sometimes dead array references collapse to a[-1], a[-2], or a[-3]
 241     if( !consistent &amp;&amp; adr_check != NULL &amp;&amp; !adr_check-&gt;empty() &amp;&amp;
 242         tp-&gt;isa_aryptr() &amp;&amp;        tp-&gt;offset() == Type::OffsetBot &amp;&amp;
 243         adr_check-&gt;isa_aryptr() &amp;&amp; adr_check-&gt;offset() != Type::OffsetBot &amp;&amp;
 244         ( adr_check-&gt;offset() == arrayOopDesc::length_offset_in_bytes() ||
</pre>
<hr />
<pre>
 945 
 946     LoadNode* ld = clone()-&gt;as_Load();
 947     Node* addp = in(MemNode::Address)-&gt;clone();
 948     if (ac-&gt;as_ArrayCopy()-&gt;is_clonebasic()) {
 949       assert(ld_alloc != NULL, &quot;need an alloc&quot;);
 950       assert(addp-&gt;is_AddP(), &quot;address must be addp&quot;);
 951       BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
 952       assert(bs-&gt;step_over_gc_barrier(addp-&gt;in(AddPNode::Base)) == bs-&gt;step_over_gc_barrier(ac-&gt;in(ArrayCopyNode::Dest)), &quot;strange pattern&quot;);
 953       assert(bs-&gt;step_over_gc_barrier(addp-&gt;in(AddPNode::Address)) == bs-&gt;step_over_gc_barrier(ac-&gt;in(ArrayCopyNode::Dest)), &quot;strange pattern&quot;);
 954       addp-&gt;set_req(AddPNode::Base, src);
 955       addp-&gt;set_req(AddPNode::Address, src);
 956     } else {
 957       assert(ac-&gt;as_ArrayCopy()-&gt;is_arraycopy_validated() ||
 958              ac-&gt;as_ArrayCopy()-&gt;is_copyof_validated() ||
 959              ac-&gt;as_ArrayCopy()-&gt;is_copyofrange_validated(), &quot;only supported cases&quot;);
 960       assert(addp-&gt;in(AddPNode::Base) == addp-&gt;in(AddPNode::Address), &quot;should be&quot;);
 961       addp-&gt;set_req(AddPNode::Base, src);
 962       addp-&gt;set_req(AddPNode::Address, src);
 963 
 964       const TypeAryPtr* ary_t = phase-&gt;type(in(MemNode::Address))-&gt;isa_aryptr();
<span class="line-modified"> 965       BasicType ary_elem  = ary_t-&gt;klass()-&gt;as_array_klass()-&gt;element_type()-&gt;basic_type();</span>
 966       uint header = arrayOopDesc::base_offset_in_bytes(ary_elem);
 967       uint shift  = exact_log2(type2aelembytes(ary_elem));
 968       if (ary_t-&gt;klass()-&gt;is_flat_array_klass()) {
 969         ciFlatArrayKlass* vak = ary_t-&gt;klass()-&gt;as_flat_array_klass();
 970         shift = vak-&gt;log2_element_size();
 971       }
 972 
 973       Node* diff = phase-&gt;transform(new SubINode(ac-&gt;in(ArrayCopyNode::SrcPos), ac-&gt;in(ArrayCopyNode::DestPos)));
 974 #ifdef _LP64
 975       diff = phase-&gt;transform(new ConvI2LNode(diff));
 976 #endif
 977       diff = phase-&gt;transform(new LShiftXNode(diff, phase-&gt;intcon(shift)));
 978 
 979       Node* offset = phase-&gt;transform(new AddXNode(addp-&gt;in(AddPNode::Offset), diff));
 980       addp-&gt;set_req(AddPNode::Offset, offset);
 981     }
 982     addp = phase-&gt;transform(addp);
 983 #ifdef ASSERT
 984     const TypePtr* adr_type = phase-&gt;type(addp)-&gt;is_ptr();
 985     ld-&gt;_adr_type = adr_type;
</pre>
</td>
<td>
<hr />
<pre>
 205 
 206 Node *MemNode::optimize_memory_chain(Node *mchain, const TypePtr *t_adr, Node *load, PhaseGVN *phase) {
 207   const TypeOopPtr* t_oop = t_adr-&gt;isa_oopptr();
 208   if (t_oop == NULL)
 209     return mchain;  // don&#39;t try to optimize non-oop types
 210   Node* result = optimize_simple_memory_chain(mchain, t_oop, load, phase);
 211   bool is_instance = t_oop-&gt;is_known_instance_field();
 212   PhaseIterGVN *igvn = phase-&gt;is_IterGVN();
 213   if (is_instance &amp;&amp; igvn != NULL &amp;&amp; result-&gt;is_Phi()) {
 214     PhiNode *mphi = result-&gt;as_Phi();
 215     assert(mphi-&gt;bottom_type() == Type::MEMORY, &quot;memory phi required&quot;);
 216     const TypePtr *t = mphi-&gt;adr_type();
 217     if (t == TypePtr::BOTTOM || t == TypeRawPtr::BOTTOM ||
 218         (t-&gt;isa_oopptr() &amp;&amp; !t-&gt;is_oopptr()-&gt;is_known_instance() &amp;&amp;
 219          t-&gt;is_oopptr()-&gt;cast_to_exactness(true)
 220            -&gt;is_oopptr()-&gt;cast_to_ptr_type(t_oop-&gt;ptr())
 221             -&gt;is_oopptr()-&gt;cast_to_instance_id(t_oop-&gt;instance_id()) == t_oop)) {
 222       // clone the Phi with our address type
 223       result = mphi-&gt;split_out_instance(t_adr, igvn);
 224     } else {
<span class="line-added"> 225       if (t-&gt;isa_aryptr()) {</span>
<span class="line-added"> 226         // In the case of a flattened inline type array, each field has its own slice.</span>
<span class="line-added"> 227         // TODO This should be re-evaluated with JDK-8251039</span>
<span class="line-added"> 228         t = t-&gt;is_aryptr()-&gt;with_field_offset(t_adr-&gt;is_aryptr()-&gt;field_offset().get());</span>
<span class="line-added"> 229       }</span>
 230       assert(phase-&gt;C-&gt;get_alias_index(t) == phase-&gt;C-&gt;get_alias_index(t_adr), &quot;correct memory chain&quot;);
 231     }
 232   }
 233   return result;
 234 }
 235 
 236 static Node *step_through_mergemem(PhaseGVN *phase, MergeMemNode *mmem,  const TypePtr *tp, const TypePtr *adr_check, outputStream *st) {
 237   uint alias_idx = phase-&gt;C-&gt;get_alias_index(tp);
 238   Node *mem = mmem;
 239 #ifdef ASSERT
 240   {
 241     // Check that current type is consistent with the alias index used during graph construction
 242     assert(alias_idx &gt;= Compile::AliasIdxRaw, &quot;must not be a bad alias_idx&quot;);
 243     bool consistent =  adr_check == NULL || adr_check-&gt;empty() ||
 244                        phase-&gt;C-&gt;must_alias(adr_check, alias_idx );
 245     // Sometimes dead array references collapse to a[-1], a[-2], or a[-3]
 246     if( !consistent &amp;&amp; adr_check != NULL &amp;&amp; !adr_check-&gt;empty() &amp;&amp;
 247         tp-&gt;isa_aryptr() &amp;&amp;        tp-&gt;offset() == Type::OffsetBot &amp;&amp;
 248         adr_check-&gt;isa_aryptr() &amp;&amp; adr_check-&gt;offset() != Type::OffsetBot &amp;&amp;
 249         ( adr_check-&gt;offset() == arrayOopDesc::length_offset_in_bytes() ||
</pre>
<hr />
<pre>
 950 
 951     LoadNode* ld = clone()-&gt;as_Load();
 952     Node* addp = in(MemNode::Address)-&gt;clone();
 953     if (ac-&gt;as_ArrayCopy()-&gt;is_clonebasic()) {
 954       assert(ld_alloc != NULL, &quot;need an alloc&quot;);
 955       assert(addp-&gt;is_AddP(), &quot;address must be addp&quot;);
 956       BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
 957       assert(bs-&gt;step_over_gc_barrier(addp-&gt;in(AddPNode::Base)) == bs-&gt;step_over_gc_barrier(ac-&gt;in(ArrayCopyNode::Dest)), &quot;strange pattern&quot;);
 958       assert(bs-&gt;step_over_gc_barrier(addp-&gt;in(AddPNode::Address)) == bs-&gt;step_over_gc_barrier(ac-&gt;in(ArrayCopyNode::Dest)), &quot;strange pattern&quot;);
 959       addp-&gt;set_req(AddPNode::Base, src);
 960       addp-&gt;set_req(AddPNode::Address, src);
 961     } else {
 962       assert(ac-&gt;as_ArrayCopy()-&gt;is_arraycopy_validated() ||
 963              ac-&gt;as_ArrayCopy()-&gt;is_copyof_validated() ||
 964              ac-&gt;as_ArrayCopy()-&gt;is_copyofrange_validated(), &quot;only supported cases&quot;);
 965       assert(addp-&gt;in(AddPNode::Base) == addp-&gt;in(AddPNode::Address), &quot;should be&quot;);
 966       addp-&gt;set_req(AddPNode::Base, src);
 967       addp-&gt;set_req(AddPNode::Address, src);
 968 
 969       const TypeAryPtr* ary_t = phase-&gt;type(in(MemNode::Address))-&gt;isa_aryptr();
<span class="line-modified"> 970       BasicType ary_elem = ary_t-&gt;klass()-&gt;as_array_klass()-&gt;element_type()-&gt;basic_type();</span>
 971       uint header = arrayOopDesc::base_offset_in_bytes(ary_elem);
 972       uint shift  = exact_log2(type2aelembytes(ary_elem));
 973       if (ary_t-&gt;klass()-&gt;is_flat_array_klass()) {
 974         ciFlatArrayKlass* vak = ary_t-&gt;klass()-&gt;as_flat_array_klass();
 975         shift = vak-&gt;log2_element_size();
 976       }
 977 
 978       Node* diff = phase-&gt;transform(new SubINode(ac-&gt;in(ArrayCopyNode::SrcPos), ac-&gt;in(ArrayCopyNode::DestPos)));
 979 #ifdef _LP64
 980       diff = phase-&gt;transform(new ConvI2LNode(diff));
 981 #endif
 982       diff = phase-&gt;transform(new LShiftXNode(diff, phase-&gt;intcon(shift)));
 983 
 984       Node* offset = phase-&gt;transform(new AddXNode(addp-&gt;in(AddPNode::Offset), diff));
 985       addp-&gt;set_req(AddPNode::Offset, offset);
 986     }
 987     addp = phase-&gt;transform(addp);
 988 #ifdef ASSERT
 989     const TypePtr* adr_type = phase-&gt;type(addp)-&gt;is_ptr();
 990     ld-&gt;_adr_type = adr_type;
</pre>
</td>
</tr>
</table>
<center><a href="macroArrayCopy.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../../../../test/hotspot/jtreg/compiler/valhalla/inlinetypes/TestNullableArrays.java.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>