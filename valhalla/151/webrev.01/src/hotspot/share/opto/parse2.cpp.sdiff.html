<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/parse2.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="memnode.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="subnode.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/parse2.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  64     if (element_type != NULL || element_ptr != ProfileMaybeNull) {
  65       ld = record_profile_for_speculation(ld, element_type, element_ptr);
  66     }
  67   }
  68   return ld;
  69 }
  70 
  71 
  72 //---------------------------------array_load----------------------------------
  73 void Parse::array_load(BasicType bt) {
  74   const Type* elemtype = Type::TOP;
  75   Node* adr = array_addressing(bt, 0, elemtype);
  76   if (stopped())  return;     // guaranteed null or range check
  77 
  78   Node* idx = pop();
  79   Node* ary = pop();
  80 
  81   // Handle inline type arrays
  82   const TypeOopPtr* elemptr = elemtype-&gt;make_oopptr();
  83   const TypeAryPtr* ary_t = _gvn.type(ary)-&gt;is_aryptr();
<span class="line-modified">  84   if (elemtype-&gt;isa_inlinetype() != NULL) {</span>
  85     C-&gt;set_flattened_accesses();
  86     // Load from flattened inline type array
  87     Node* vt = InlineTypeNode::make_from_flattened(this, elemtype-&gt;inline_klass(), ary, adr);
  88     push(vt);
  89     return;
<span class="line-modified">  90   } else if (elemptr != NULL &amp;&amp; elemptr-&gt;is_inlinetypeptr() &amp;&amp; !elemptr-&gt;maybe_null()) {</span>
  91     // Load from non-flattened inline type array (elements can never be null)
  92     bt = T_INLINE_TYPE;
  93   } else if (!ary_t-&gt;is_not_flat()) {
  94     // Cannot statically determine if array is flattened, emit runtime check
  95     assert(UseFlatArray &amp;&amp; is_reference_type(bt) &amp;&amp; elemptr-&gt;can_be_inline_type() &amp;&amp; !ary_t-&gt;klass_is_exact() &amp;&amp; !ary_t-&gt;is_not_null_free() &amp;&amp;
  96            (!elemptr-&gt;is_inlinetypeptr() || elemptr-&gt;inline_klass()-&gt;flatten_array()), &quot;array can&#39;t be flattened&quot;);
  97     IdealKit ideal(this);
  98     IdealVariable res(ideal);
  99     ideal.declarations_done();
 100     ideal.if_then(is_non_flattened_array(ary)); {
 101       // non-flattened
 102       assert(ideal.ctrl()-&gt;in(0)-&gt;as_If()-&gt;is_non_flattened_array_check(&amp;_gvn), &quot;Should be found&quot;);
 103       sync_kit(ideal);
 104       const TypeAryPtr* adr_type = TypeAryPtr::get_array_body_type(bt);
 105       Node* ld = access_load_at(ary, adr, adr_type, elemptr, bt,
 106                                 IN_HEAP | IS_ARRAY | C2_CONTROL_DEPENDENT_LOAD);
 107       ideal.sync_kit(this);
 108       ideal.set(res, ld);
 109     } ideal.else_(); {
 110       // flattened
</pre>
<hr />
<pre>
 172           ideal.make_leaf_call(OptoRuntime::load_unknown_inline_type(),
 173                                CAST_FROM_FN_PTR(address, OptoRuntime::load_unknown_inline),
 174                                &quot;load_unknown_inline&quot;,
 175                                ary, idx, alloc_obj);
 176           sync_kit(ideal);
 177         }
 178 
 179         // This makes sure no other thread sees a partially initialized buffered inline type
 180         insert_mem_bar_volatile(Op_MemBarStoreStore, Compile::AliasIdxRaw, alloc-&gt;proj_out_or_null(AllocateNode::RawAddress));
 181 
 182         // Same as MemBarCPUOrder above: keep this unknown flattened
 183         // array access correctly ordered with other flattened array
 184         // access
 185         insert_mem_bar_volatile(Op_MemBarCPUOrder, C-&gt;get_alias_index(TypeAryPtr::INLINES));
 186 
 187         // Prevent any use of the newly allocated inline type before it is fully initialized
 188         alloc_obj = new CastPPNode(alloc_obj, _gvn.type(alloc_obj), true);
 189         alloc_obj-&gt;set_req(0, control());
 190         alloc_obj = _gvn.transform(alloc_obj);
 191 
<span class="line-modified"> 192         const Type* unknown_value = elemptr-&gt;is_instptr()-&gt;cast_to_flat_array();</span>
 193         alloc_obj = _gvn.transform(new CheckCastPPNode(control(), alloc_obj, unknown_value));
 194 
 195         ideal.sync_kit(this);
 196         ideal.set(res, alloc_obj);
 197       }
 198     } ideal.end_if();
 199     sync_kit(ideal);
 200     Node* ld = _gvn.transform(ideal.value(res));
 201     ld = record_profile_for_speculation_at_array_load(ld);
 202     push_node(bt, ld);
 203     return;
 204   }
 205 
 206   if (elemtype == TypeInt::BOOL) {
 207     bt = T_BOOLEAN;
 208   }
 209   const TypeAryPtr* adr_type = TypeAryPtr::get_array_body_type(bt);
 210   Node* ld = access_load_at(ary, adr, adr_type, elemtype, bt,
 211                             IN_HEAP | IS_ARRAY | C2_CONTROL_DEPENDENT_LOAD);
 212   if (bt == T_INLINE_TYPE) {
</pre>
<hr />
<pre>
 254     // This is only legal for non-null stores because the array_store_check always passes for null, even
 255     // if the array is null-free. Null stores are handled in GraphKit::gen_inline_array_null_guard().
 256     bool not_inline = !tval-&gt;isa_inlinetype() &amp;&amp;
 257                       ((!tval_init-&gt;maybe_null() &amp;&amp; !tval_init-&gt;is_oopptr()-&gt;can_be_inline_type()) ||
 258                        (!tval-&gt;maybe_null() &amp;&amp; !tval-&gt;is_oopptr()-&gt;can_be_inline_type()));
 259     bool not_flattened = not_inline || ((tval_init-&gt;is_inlinetypeptr() || tval_init-&gt;isa_inlinetype()) &amp;&amp; !tval_init-&gt;inline_klass()-&gt;flatten_array());
 260     if (!ary_t-&gt;is_not_null_free() &amp;&amp; not_inline) {
 261       // Storing a non-inline type, mark array as not null-free (-&gt; not flat).
 262       ary_t = ary_t-&gt;cast_to_not_null_free();
 263       Node* cast = _gvn.transform(new CheckCastPPNode(control(), ary, ary_t));
 264       replace_in_map(ary, cast);
 265       ary = cast;
 266     } else if (!ary_t-&gt;is_not_flat() &amp;&amp; not_flattened) {
 267       // Storing a non-flattened value, mark array as not flat.
 268       ary_t = ary_t-&gt;cast_to_not_flat();
 269       Node* cast = _gvn.transform(new CheckCastPPNode(control(), ary, ary_t));
 270       replace_in_map(ary, cast);
 271       ary = cast;
 272     }
 273 
<span class="line-modified"> 274     if (ary_t-&gt;elem()-&gt;isa_inlinetype() != NULL) {</span>
 275       // Store to flattened inline type array
 276       C-&gt;set_flattened_accesses();
 277       if (!cast_val-&gt;is_InlineType()) {
 278         inc_sp(3);
 279         cast_val = null_check(cast_val);
 280         if (stopped()) return;
 281         dec_sp(3);
 282         cast_val = InlineTypeNode::make_from_oop(this, cast_val, ary_t-&gt;elem()-&gt;inline_klass());
 283       }
 284       // Re-execute flattened array store if buffering triggers deoptimization
 285       PreserveReexecuteState preexecs(this);
 286       inc_sp(3);
 287       jvms()-&gt;set_should_reexecute(true);
 288       cast_val-&gt;as_InlineType()-&gt;store_flattened(this, ary, adr, NULL, 0, MO_UNORDERED | IN_HEAP | IS_ARRAY);
 289       return;
<span class="line-modified"> 290     } else if (elemtype-&gt;is_inlinetypeptr() &amp;&amp; !elemtype-&gt;maybe_null()) {</span>
 291       // Store to non-flattened inline type array (elements can never be null)
 292       if (!cast_val-&gt;is_InlineType() &amp;&amp; tval-&gt;maybe_null()) {
 293         inc_sp(3);
 294         cast_val = null_check(cast_val);
 295         if (stopped()) return;
 296         dec_sp(3);
 297       }
 298     } else if (!ary_t-&gt;is_not_flat() &amp;&amp; tval != TypePtr::NULL_PTR) {
 299       // Array might be flattened, emit runtime checks (for NULL, a simple inline_array_null_guard is sufficient).
 300       assert(UseFlatArray &amp;&amp; !not_flattened &amp;&amp; elemtype-&gt;is_oopptr()-&gt;can_be_inline_type() &amp;&amp;
 301              !ary_t-&gt;klass_is_exact() &amp;&amp; !ary_t-&gt;is_not_null_free(), &quot;array can&#39;t be flattened&quot;);
 302       IdealKit ideal(this);
 303       ideal.if_then(is_non_flattened_array(ary)); {
 304         // non-flattened
 305         assert(ideal.ctrl()-&gt;in(0)-&gt;as_If()-&gt;is_non_flattened_array_check(&amp;_gvn), &quot;Should be found&quot;);
 306         sync_kit(ideal);
 307         gen_inline_array_null_guard(ary, cast_val, 3);
 308         inc_sp(3);
 309         access_store_at(ary, adr, adr_type, cast_val, elemtype, bt, MO_UNORDERED | IN_HEAP | IS_ARRAY, false);
 310         dec_sp(3);
</pre>
</td>
<td>
<hr />
<pre>
  64     if (element_type != NULL || element_ptr != ProfileMaybeNull) {
  65       ld = record_profile_for_speculation(ld, element_type, element_ptr);
  66     }
  67   }
  68   return ld;
  69 }
  70 
  71 
  72 //---------------------------------array_load----------------------------------
  73 void Parse::array_load(BasicType bt) {
  74   const Type* elemtype = Type::TOP;
  75   Node* adr = array_addressing(bt, 0, elemtype);
  76   if (stopped())  return;     // guaranteed null or range check
  77 
  78   Node* idx = pop();
  79   Node* ary = pop();
  80 
  81   // Handle inline type arrays
  82   const TypeOopPtr* elemptr = elemtype-&gt;make_oopptr();
  83   const TypeAryPtr* ary_t = _gvn.type(ary)-&gt;is_aryptr();
<span class="line-modified">  84   if (ary_t-&gt;is_flat()) {</span>
  85     C-&gt;set_flattened_accesses();
  86     // Load from flattened inline type array
  87     Node* vt = InlineTypeNode::make_from_flattened(this, elemtype-&gt;inline_klass(), ary, adr);
  88     push(vt);
  89     return;
<span class="line-modified">  90   } else if (ary_t-&gt;is_null_free()) {</span>
  91     // Load from non-flattened inline type array (elements can never be null)
  92     bt = T_INLINE_TYPE;
  93   } else if (!ary_t-&gt;is_not_flat()) {
  94     // Cannot statically determine if array is flattened, emit runtime check
  95     assert(UseFlatArray &amp;&amp; is_reference_type(bt) &amp;&amp; elemptr-&gt;can_be_inline_type() &amp;&amp; !ary_t-&gt;klass_is_exact() &amp;&amp; !ary_t-&gt;is_not_null_free() &amp;&amp;
  96            (!elemptr-&gt;is_inlinetypeptr() || elemptr-&gt;inline_klass()-&gt;flatten_array()), &quot;array can&#39;t be flattened&quot;);
  97     IdealKit ideal(this);
  98     IdealVariable res(ideal);
  99     ideal.declarations_done();
 100     ideal.if_then(is_non_flattened_array(ary)); {
 101       // non-flattened
 102       assert(ideal.ctrl()-&gt;in(0)-&gt;as_If()-&gt;is_non_flattened_array_check(&amp;_gvn), &quot;Should be found&quot;);
 103       sync_kit(ideal);
 104       const TypeAryPtr* adr_type = TypeAryPtr::get_array_body_type(bt);
 105       Node* ld = access_load_at(ary, adr, adr_type, elemptr, bt,
 106                                 IN_HEAP | IS_ARRAY | C2_CONTROL_DEPENDENT_LOAD);
 107       ideal.sync_kit(this);
 108       ideal.set(res, ld);
 109     } ideal.else_(); {
 110       // flattened
</pre>
<hr />
<pre>
 172           ideal.make_leaf_call(OptoRuntime::load_unknown_inline_type(),
 173                                CAST_FROM_FN_PTR(address, OptoRuntime::load_unknown_inline),
 174                                &quot;load_unknown_inline&quot;,
 175                                ary, idx, alloc_obj);
 176           sync_kit(ideal);
 177         }
 178 
 179         // This makes sure no other thread sees a partially initialized buffered inline type
 180         insert_mem_bar_volatile(Op_MemBarStoreStore, Compile::AliasIdxRaw, alloc-&gt;proj_out_or_null(AllocateNode::RawAddress));
 181 
 182         // Same as MemBarCPUOrder above: keep this unknown flattened
 183         // array access correctly ordered with other flattened array
 184         // access
 185         insert_mem_bar_volatile(Op_MemBarCPUOrder, C-&gt;get_alias_index(TypeAryPtr::INLINES));
 186 
 187         // Prevent any use of the newly allocated inline type before it is fully initialized
 188         alloc_obj = new CastPPNode(alloc_obj, _gvn.type(alloc_obj), true);
 189         alloc_obj-&gt;set_req(0, control());
 190         alloc_obj = _gvn.transform(alloc_obj);
 191 
<span class="line-modified"> 192         const Type* unknown_value = elemptr-&gt;is_instptr()-&gt;cast_to_flatten_array();</span>
 193         alloc_obj = _gvn.transform(new CheckCastPPNode(control(), alloc_obj, unknown_value));
 194 
 195         ideal.sync_kit(this);
 196         ideal.set(res, alloc_obj);
 197       }
 198     } ideal.end_if();
 199     sync_kit(ideal);
 200     Node* ld = _gvn.transform(ideal.value(res));
 201     ld = record_profile_for_speculation_at_array_load(ld);
 202     push_node(bt, ld);
 203     return;
 204   }
 205 
 206   if (elemtype == TypeInt::BOOL) {
 207     bt = T_BOOLEAN;
 208   }
 209   const TypeAryPtr* adr_type = TypeAryPtr::get_array_body_type(bt);
 210   Node* ld = access_load_at(ary, adr, adr_type, elemtype, bt,
 211                             IN_HEAP | IS_ARRAY | C2_CONTROL_DEPENDENT_LOAD);
 212   if (bt == T_INLINE_TYPE) {
</pre>
<hr />
<pre>
 254     // This is only legal for non-null stores because the array_store_check always passes for null, even
 255     // if the array is null-free. Null stores are handled in GraphKit::gen_inline_array_null_guard().
 256     bool not_inline = !tval-&gt;isa_inlinetype() &amp;&amp;
 257                       ((!tval_init-&gt;maybe_null() &amp;&amp; !tval_init-&gt;is_oopptr()-&gt;can_be_inline_type()) ||
 258                        (!tval-&gt;maybe_null() &amp;&amp; !tval-&gt;is_oopptr()-&gt;can_be_inline_type()));
 259     bool not_flattened = not_inline || ((tval_init-&gt;is_inlinetypeptr() || tval_init-&gt;isa_inlinetype()) &amp;&amp; !tval_init-&gt;inline_klass()-&gt;flatten_array());
 260     if (!ary_t-&gt;is_not_null_free() &amp;&amp; not_inline) {
 261       // Storing a non-inline type, mark array as not null-free (-&gt; not flat).
 262       ary_t = ary_t-&gt;cast_to_not_null_free();
 263       Node* cast = _gvn.transform(new CheckCastPPNode(control(), ary, ary_t));
 264       replace_in_map(ary, cast);
 265       ary = cast;
 266     } else if (!ary_t-&gt;is_not_flat() &amp;&amp; not_flattened) {
 267       // Storing a non-flattened value, mark array as not flat.
 268       ary_t = ary_t-&gt;cast_to_not_flat();
 269       Node* cast = _gvn.transform(new CheckCastPPNode(control(), ary, ary_t));
 270       replace_in_map(ary, cast);
 271       ary = cast;
 272     }
 273 
<span class="line-modified"> 274     if (ary_t-&gt;is_flat()) {</span>
 275       // Store to flattened inline type array
 276       C-&gt;set_flattened_accesses();
 277       if (!cast_val-&gt;is_InlineType()) {
 278         inc_sp(3);
 279         cast_val = null_check(cast_val);
 280         if (stopped()) return;
 281         dec_sp(3);
 282         cast_val = InlineTypeNode::make_from_oop(this, cast_val, ary_t-&gt;elem()-&gt;inline_klass());
 283       }
 284       // Re-execute flattened array store if buffering triggers deoptimization
 285       PreserveReexecuteState preexecs(this);
 286       inc_sp(3);
 287       jvms()-&gt;set_should_reexecute(true);
 288       cast_val-&gt;as_InlineType()-&gt;store_flattened(this, ary, adr, NULL, 0, MO_UNORDERED | IN_HEAP | IS_ARRAY);
 289       return;
<span class="line-modified"> 290     } else if (ary_t-&gt;is_null_free()) {</span>
 291       // Store to non-flattened inline type array (elements can never be null)
 292       if (!cast_val-&gt;is_InlineType() &amp;&amp; tval-&gt;maybe_null()) {
 293         inc_sp(3);
 294         cast_val = null_check(cast_val);
 295         if (stopped()) return;
 296         dec_sp(3);
 297       }
 298     } else if (!ary_t-&gt;is_not_flat() &amp;&amp; tval != TypePtr::NULL_PTR) {
 299       // Array might be flattened, emit runtime checks (for NULL, a simple inline_array_null_guard is sufficient).
 300       assert(UseFlatArray &amp;&amp; !not_flattened &amp;&amp; elemtype-&gt;is_oopptr()-&gt;can_be_inline_type() &amp;&amp;
 301              !ary_t-&gt;klass_is_exact() &amp;&amp; !ary_t-&gt;is_not_null_free(), &quot;array can&#39;t be flattened&quot;);
 302       IdealKit ideal(this);
 303       ideal.if_then(is_non_flattened_array(ary)); {
 304         // non-flattened
 305         assert(ideal.ctrl()-&gt;in(0)-&gt;as_If()-&gt;is_non_flattened_array_check(&amp;_gvn), &quot;Should be found&quot;);
 306         sync_kit(ideal);
 307         gen_inline_array_null_guard(ary, cast_val, 3);
 308         inc_sp(3);
 309         access_store_at(ary, adr, adr_type, cast_val, elemtype, bt, MO_UNORDERED | IN_HEAP | IS_ARRAY, false);
 310         dec_sp(3);
</pre>
</td>
</tr>
</table>
<center><a href="memnode.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="subnode.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>