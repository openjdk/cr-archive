<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/cpu/aarch64/aarch64.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
    1 //
    2 // Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.
    3 // Copyright (c) 2014, 2020, Red Hat, Inc. All rights reserved.
    4 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    5 //
    6 // This code is free software; you can redistribute it and/or modify it
    7 // under the terms of the GNU General Public License version 2 only, as
    8 // published by the Free Software Foundation.
    9 //
   10 // This code is distributed in the hope that it will be useful, but WITHOUT
   11 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   12 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   13 // version 2 for more details (a copy is included in the LICENSE file that
   14 // accompanied this code).
   15 //
   16 // You should have received a copy of the GNU General Public License version
   17 // 2 along with this work; if not, write to the Free Software Foundation,
   18 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   19 //
   20 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   21 // or visit www.oracle.com if you need additional information or have any
   22 // questions.
   23 //
   24 //
   25 
   26 // AArch64 Architecture Description File
   27 
   28 //----------REGISTER DEFINITION BLOCK------------------------------------------
   29 // This information is used by the matcher and the register allocator to
   30 // describe individual registers and classes of registers within the target
   31 // archtecture.
   32 
   33 register %{
   34 //----------Architecture Description Register Definitions----------------------
   35 // General Registers
   36 // &quot;reg_def&quot;  name ( register save type, C convention save type,
   37 //                   ideal register type, encoding );
   38 // Register Save Types:
   39 //
   40 // NS  = No-Save:       The register allocator assumes that these registers
   41 //                      can be used without saving upon entry to the method, &amp;
   42 //                      that they do not need to be saved at call sites.
   43 //
   44 // SOC = Save-On-Call:  The register allocator assumes that these registers
   45 //                      can be used without saving upon entry to the method,
   46 //                      but that they must be saved at call sites.
   47 //
   48 // SOE = Save-On-Entry: The register allocator assumes that these registers
   49 //                      must be saved before using them upon entry to the
   50 //                      method, but they do not need to be saved at call
   51 //                      sites.
   52 //
   53 // AS  = Always-Save:   The register allocator assumes that these registers
   54 //                      must be saved before using them upon entry to the
   55 //                      method, &amp; that they must be saved at call sites.
   56 //
   57 // Ideal Register Type is used to determine how to save &amp; restore a
   58 // register.  Op_RegI will get spilled with LoadI/StoreI, Op_RegP will get
   59 // spilled with LoadP/StoreP.  If the register supports both, use Op_RegI.
   60 //
   61 // The encoding number is the actual bit-pattern placed into the opcodes.
   62 
   63 // We must define the 64 bit int registers in two 32 bit halves, the
   64 // real lower register and a virtual upper half register. upper halves
   65 // are used by the register allocator but are not actually supplied as
   66 // operands to memory ops.
   67 //
   68 // follow the C1 compiler in making registers
   69 //
   70 //   r0-r7,r10-r26 volatile (caller save)
   71 //   r27-r32 system (no save, no allocate)
   72 //   r8-r9 invisible to the allocator (so we can use them as scratch regs)
   73 //
   74 // as regards Java usage. we don&#39;t use any callee save registers
   75 // because this makes it difficult to de-optimise a frame (see comment
   76 // in x86 implementation of Deoptimization::unwind_callee_save_values)
   77 //
   78 
   79 // General Registers
   80 
   81 reg_def R0      ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()         );
   82 reg_def R0_H    ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()-&gt;next() );
   83 reg_def R1      ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()         );
   84 reg_def R1_H    ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()-&gt;next() );
   85 reg_def R2      ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()         );
   86 reg_def R2_H    ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()-&gt;next() );
   87 reg_def R3      ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()         );
   88 reg_def R3_H    ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()-&gt;next() );
   89 reg_def R4      ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()         );
   90 reg_def R4_H    ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()-&gt;next() );
   91 reg_def R5      ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()         );
   92 reg_def R5_H    ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()-&gt;next() );
   93 reg_def R6      ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()         );
   94 reg_def R6_H    ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()-&gt;next() );
   95 reg_def R7      ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()         );
   96 reg_def R7_H    ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()-&gt;next() );
   97 reg_def R10     ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()        );
   98 reg_def R10_H   ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()-&gt;next());
   99 reg_def R11     ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()        );
  100 reg_def R11_H   ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()-&gt;next());
  101 reg_def R12     ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()        );
  102 reg_def R12_H   ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()-&gt;next());
  103 reg_def R13     ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()        );
  104 reg_def R13_H   ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()-&gt;next());
  105 reg_def R14     ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()        );
  106 reg_def R14_H   ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()-&gt;next());
  107 reg_def R15     ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()        );
  108 reg_def R15_H   ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()-&gt;next());
  109 reg_def R16     ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()        );
  110 reg_def R16_H   ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()-&gt;next());
  111 reg_def R17     ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()        );
  112 reg_def R17_H   ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()-&gt;next());
  113 reg_def R18     ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()        );
  114 reg_def R18_H   ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()-&gt;next());
  115 reg_def R19     ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()        );
  116 reg_def R19_H   ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()-&gt;next());
  117 reg_def R20     ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()        ); // caller esp
  118 reg_def R20_H   ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()-&gt;next());
  119 reg_def R21     ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()        );
  120 reg_def R21_H   ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()-&gt;next());
  121 reg_def R22     ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()        );
  122 reg_def R22_H   ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()-&gt;next());
  123 reg_def R23     ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()        );
  124 reg_def R23_H   ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()-&gt;next());
  125 reg_def R24     ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()        );
  126 reg_def R24_H   ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()-&gt;next());
  127 reg_def R25     ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()        );
  128 reg_def R25_H   ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()-&gt;next());
  129 reg_def R26     ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()        );
  130 reg_def R26_H   ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()-&gt;next());
  131 reg_def R27     ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()        ); // heapbase
  132 reg_def R27_H   ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()-&gt;next());
  133 reg_def R28     (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()        ); // thread
  134 reg_def R28_H   (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()-&gt;next());
  135 reg_def R29     (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()        ); // fp
  136 reg_def R29_H   (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()-&gt;next());
  137 reg_def R30     (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()        ); // lr
  138 reg_def R30_H   (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()-&gt;next());
  139 reg_def R31     (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()     ); // sp
  140 reg_def R31_H   (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()-&gt;next());
  141 
  142 // ----------------------------
  143 // Float/Double Registers
  144 // ----------------------------
  145 
  146 // Double Registers
  147 
  148 // The rules of ADL require that double registers be defined in pairs.
  149 // Each pair must be two 32-bit values, but not necessarily a pair of
  150 // single float registers. In each pair, ADLC-assigned register numbers
  151 // must be adjacent, with the lower number even. Finally, when the
  152 // CPU stores such a register pair to memory, the word associated with
  153 // the lower ADLC-assigned number must be stored to the lower address.
  154 
  155 // AArch64 has 32 floating-point registers. Each can store a vector of
  156 // single or double precision floating-point values up to 8 * 32
  157 // floats, 4 * 64 bit floats or 2 * 128 bit floats.  We currently only
  158 // use the first float or double element of the vector.
  159 
  160 // for Java use float registers v0-v15 are always save on call whereas
  161 // the platform ABI treats v8-v15 as callee save). float registers
  162 // v16-v31 are SOC as per the platform spec
  163 
  164   reg_def V0   ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()          );
  165   reg_def V0_H ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next()  );
  166   reg_def V0_J ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(2) );
  167   reg_def V0_K ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(3) );
  168 
  169   reg_def V1   ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()          );
  170   reg_def V1_H ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next()  );
  171   reg_def V1_J ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(2) );
  172   reg_def V1_K ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(3) );
  173 
  174   reg_def V2   ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()          );
  175   reg_def V2_H ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next()  );
  176   reg_def V2_J ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(2) );
  177   reg_def V2_K ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(3) );
  178 
  179   reg_def V3   ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()          );
  180   reg_def V3_H ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next()  );
  181   reg_def V3_J ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(2) );
  182   reg_def V3_K ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(3) );
  183 
  184   reg_def V4   ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()          );
  185   reg_def V4_H ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next()  );
  186   reg_def V4_J ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(2) );
  187   reg_def V4_K ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(3) );
  188 
  189   reg_def V5   ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()          );
  190   reg_def V5_H ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next()  );
  191   reg_def V5_J ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(2) );
  192   reg_def V5_K ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(3) );
  193 
  194   reg_def V6   ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()          );
  195   reg_def V6_H ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next()  );
  196   reg_def V6_J ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(2) );
  197   reg_def V6_K ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(3) );
  198 
  199   reg_def V7   ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()          );
  200   reg_def V7_H ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next()  );
  201   reg_def V7_J ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(2) );
  202   reg_def V7_K ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(3) );
  203 
  204   reg_def V8   ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()          );
  205   reg_def V8_H ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next()  );
  206   reg_def V8_J ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(2) );
  207   reg_def V8_K ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(3) );
  208 
  209   reg_def V9   ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()          );
  210   reg_def V9_H ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next()  );
  211   reg_def V9_J ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(2) );
  212   reg_def V9_K ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(3) );
  213 
  214   reg_def V10  ( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()         );
  215   reg_def V10_H( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next() );
  216   reg_def V10_J( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(2));
  217   reg_def V10_K( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(3));
  218 
  219   reg_def V11  ( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()         );
  220   reg_def V11_H( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next() );
  221   reg_def V11_J( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(2));
  222   reg_def V11_K( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(3));
  223 
  224   reg_def V12  ( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()         );
  225   reg_def V12_H( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next() );
  226   reg_def V12_J( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(2));
  227   reg_def V12_K( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(3));
  228 
  229   reg_def V13  ( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()         );
  230   reg_def V13_H( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next() );
  231   reg_def V13_J( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(2));
  232   reg_def V13_K( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(3));
  233 
  234   reg_def V14  ( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()         );
  235   reg_def V14_H( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next() );
  236   reg_def V14_J( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(2));
  237   reg_def V14_K( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(3));
  238 
  239   reg_def V15  ( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()         );
  240   reg_def V15_H( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next() );
  241   reg_def V15_J( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(2));
  242   reg_def V15_K( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(3));
  243 
  244   reg_def V16  ( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()         );
  245   reg_def V16_H( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next() );
  246   reg_def V16_J( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(2));
  247   reg_def V16_K( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(3));
  248 
  249   reg_def V17  ( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()         );
  250   reg_def V17_H( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next() );
  251   reg_def V17_J( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(2));
  252   reg_def V17_K( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(3));
  253 
  254   reg_def V18  ( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()         );
  255   reg_def V18_H( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next() );
  256   reg_def V18_J( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(2));
  257   reg_def V18_K( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(3));
  258 
  259   reg_def V19  ( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()         );
  260   reg_def V19_H( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next() );
  261   reg_def V19_J( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(2));
  262   reg_def V19_K( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(3));
  263 
  264   reg_def V20  ( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()         );
  265   reg_def V20_H( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next() );
  266   reg_def V20_J( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(2));
  267   reg_def V20_K( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(3));
  268 
  269   reg_def V21  ( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()         );
  270   reg_def V21_H( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next() );
  271   reg_def V21_J( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(2));
  272   reg_def V21_K( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(3));
  273 
  274   reg_def V22  ( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()         );
  275   reg_def V22_H( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next() );
  276   reg_def V22_J( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(2));
  277   reg_def V22_K( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(3));
  278 
  279   reg_def V23  ( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()         );
  280   reg_def V23_H( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next() );
  281   reg_def V23_J( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(2));
  282   reg_def V23_K( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(3));
  283 
  284   reg_def V24  ( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()         );
  285   reg_def V24_H( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next() );
  286   reg_def V24_J( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(2));
  287   reg_def V24_K( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(3));
  288 
  289   reg_def V25  ( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()         );
  290   reg_def V25_H( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next() );
  291   reg_def V25_J( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(2));
  292   reg_def V25_K( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(3));
  293 
  294   reg_def V26  ( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()         );
  295   reg_def V26_H( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next() );
  296   reg_def V26_J( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(2));
  297   reg_def V26_K( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(3));
  298 
  299   reg_def V27  ( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()         );
  300   reg_def V27_H( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next() );
  301   reg_def V27_J( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(2));
  302   reg_def V27_K( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(3));
  303 
  304   reg_def V28  ( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()         );
  305   reg_def V28_H( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next() );
  306   reg_def V28_J( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(2));
  307   reg_def V28_K( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(3));
  308 
  309   reg_def V29  ( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()         );
  310   reg_def V29_H( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next() );
  311   reg_def V29_J( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(2));
  312   reg_def V29_K( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(3));
  313 
  314   reg_def V30  ( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()         );
  315   reg_def V30_H( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next() );
  316   reg_def V30_J( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(2));
  317   reg_def V30_K( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(3));
  318 
  319   reg_def V31  ( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()         );
  320   reg_def V31_H( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next() );
  321   reg_def V31_J( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(2));
  322   reg_def V31_K( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(3));
  323 
  324 // ----------------------------
  325 // Special Registers
  326 // ----------------------------
  327 
  328 // the AArch64 CSPR status flag register is not directly acessible as
  329 // instruction operand. the FPSR status flag register is a system
  330 // register which can be written/read using MSR/MRS but again does not
  331 // appear as an operand (a code identifying the FSPR occurs as an
  332 // immediate value in the instruction).
  333 
  334 reg_def RFLAGS(SOC, SOC, 0, 32, VMRegImpl::Bad());
  335 
  336 
  337 // Specify priority of register selection within phases of register
  338 // allocation.  Highest priority is first.  A useful heuristic is to
  339 // give registers a low priority when they are required by machine
  340 // instructions, like EAX and EDX on I486, and choose no-save registers
  341 // before save-on-call, &amp; save-on-call before save-on-entry.  Registers
  342 // which participate in fixed calling sequences should come last.
  343 // Registers which are used as pairs must fall on an even boundary.
  344 
  345 alloc_class chunk0(
  346     // volatiles
  347     R10, R10_H,
  348     R11, R11_H,
  349     R12, R12_H,
  350     R13, R13_H,
  351     R14, R14_H,
  352     R15, R15_H,
  353     R16, R16_H,
  354     R17, R17_H,
  355     R18, R18_H,
  356 
  357     // arg registers
  358     R0, R0_H,
  359     R1, R1_H,
  360     R2, R2_H,
  361     R3, R3_H,
  362     R4, R4_H,
  363     R5, R5_H,
  364     R6, R6_H,
  365     R7, R7_H,
  366 
  367     // non-volatiles
  368     R19, R19_H,
  369     R20, R20_H,
  370     R21, R21_H,
  371     R22, R22_H,
  372     R23, R23_H,
  373     R24, R24_H,
  374     R25, R25_H,
  375     R26, R26_H,
  376 
  377     // non-allocatable registers
  378 
  379     R27, R27_H, // heapbase
  380     R28, R28_H, // thread
  381     R29, R29_H, // fp
  382     R30, R30_H, // lr
  383     R31, R31_H, // sp
  384 );
  385 
  386 alloc_class chunk1(
  387 
  388     // no save
  389     V16, V16_H, V16_J, V16_K,
  390     V17, V17_H, V17_J, V17_K,
  391     V18, V18_H, V18_J, V18_K,
  392     V19, V19_H, V19_J, V19_K,
  393     V20, V20_H, V20_J, V20_K,
  394     V21, V21_H, V21_J, V21_K,
  395     V22, V22_H, V22_J, V22_K,
  396     V23, V23_H, V23_J, V23_K,
  397     V24, V24_H, V24_J, V24_K,
  398     V25, V25_H, V25_J, V25_K,
  399     V26, V26_H, V26_J, V26_K,
  400     V27, V27_H, V27_J, V27_K,
  401     V28, V28_H, V28_J, V28_K,
  402     V29, V29_H, V29_J, V29_K,
  403     V30, V30_H, V30_J, V30_K,
  404     V31, V31_H, V31_J, V31_K,
  405 
  406     // arg registers
  407     V0, V0_H, V0_J, V0_K,
  408     V1, V1_H, V1_J, V1_K,
  409     V2, V2_H, V2_J, V2_K,
  410     V3, V3_H, V3_J, V3_K,
  411     V4, V4_H, V4_J, V4_K,
  412     V5, V5_H, V5_J, V5_K,
  413     V6, V6_H, V6_J, V6_K,
  414     V7, V7_H, V7_J, V7_K,
  415 
  416     // non-volatiles
  417     V8, V8_H, V8_J, V8_K,
  418     V9, V9_H, V9_J, V9_K,
  419     V10, V10_H, V10_J, V10_K,
  420     V11, V11_H, V11_J, V11_K,
  421     V12, V12_H, V12_J, V12_K,
  422     V13, V13_H, V13_J, V13_K,
  423     V14, V14_H, V14_J, V14_K,
  424     V15, V15_H, V15_J, V15_K,
  425 );
  426 
  427 alloc_class chunk2(RFLAGS);
  428 
  429 //----------Architecture Description Register Classes--------------------------
  430 // Several register classes are automatically defined based upon information in
  431 // this architecture description.
  432 // 1) reg_class inline_cache_reg           ( /* as def&#39;d in frame section */ )
  433 // 2) reg_class compiler_method_oop_reg    ( /* as def&#39;d in frame section */ )
  434 // 2) reg_class interpreter_method_oop_reg ( /* as def&#39;d in frame section */ )
  435 // 3) reg_class stack_slots( /* one chunk of stack-based &quot;registers&quot; */ )
  436 //
  437 
  438 // Class for all 32 bit general purpose registers
  439 reg_class all_reg32(
  440     R0,
  441     R1,
  442     R2,
  443     R3,
  444     R4,
  445     R5,
  446     R6,
  447     R7,
  448     R10,
  449     R11,
  450     R12,
  451     R13,
  452     R14,
  453     R15,
  454     R16,
  455     R17,
  456     R18,
  457     R19,
  458     R20,
  459     R21,
  460     R22,
  461     R23,
  462     R24,
  463     R25,
  464     R26,
  465     R27,
  466     R28,
  467     R29,
  468     R30,
  469     R31
  470 );
  471 
  472 
  473 // Class for all 32 bit integer registers (excluding SP which
  474 // will never be used as an integer register)
  475 reg_class any_reg32 %{
  476   return _ANY_REG32_mask;
  477 %}
  478 
  479 // Singleton class for R0 int register
  480 reg_class int_r0_reg(R0);
  481 
  482 // Singleton class for R2 int register
  483 reg_class int_r2_reg(R2);
  484 
  485 // Singleton class for R3 int register
  486 reg_class int_r3_reg(R3);
  487 
  488 // Singleton class for R4 int register
  489 reg_class int_r4_reg(R4);
  490 
  491 // Singleton class for R31 int register
  492 reg_class int_r31_reg(R31);
  493 
  494 // Class for all 64 bit general purpose registers
  495 reg_class all_reg(
  496     R0, R0_H,
  497     R1, R1_H,
  498     R2, R2_H,
  499     R3, R3_H,
  500     R4, R4_H,
  501     R5, R5_H,
  502     R6, R6_H,
  503     R7, R7_H,
  504     R10, R10_H,
  505     R11, R11_H,
  506     R12, R12_H,
  507     R13, R13_H,
  508     R14, R14_H,
  509     R15, R15_H,
  510     R16, R16_H,
  511     R17, R17_H,
  512     R18, R18_H,
  513     R19, R19_H,
  514     R20, R20_H,
  515     R21, R21_H,
  516     R22, R22_H,
  517     R23, R23_H,
  518     R24, R24_H,
  519     R25, R25_H,
  520     R26, R26_H,
  521     R27, R27_H,
  522     R28, R28_H,
  523     R29, R29_H,
  524     R30, R30_H,
  525     R31, R31_H
  526 );
  527 
  528 // Class for all long integer registers (including SP)
  529 reg_class any_reg %{
  530   return _ANY_REG_mask;
  531 %}
  532 
  533 // Class for non-allocatable 32 bit registers
  534 reg_class non_allocatable_reg32(
  535     R28,                        // thread
  536     R30,                        // lr
  537     R31                         // sp
  538 );
  539 
  540 // Class for non-allocatable 64 bit registers
  541 reg_class non_allocatable_reg(
  542     R28, R28_H,                 // thread
  543     R30, R30_H,                 // lr
  544     R31, R31_H                  // sp
  545 );
  546 
  547 // Class for all non-special integer registers
  548 reg_class no_special_reg32 %{
  549   return _NO_SPECIAL_REG32_mask;
  550 %}
  551 
  552 // Class for all non-special long integer registers
  553 reg_class no_special_reg %{
  554   return _NO_SPECIAL_REG_mask;
  555 %}
  556 
  557 // Class for 64 bit register r0
  558 reg_class r0_reg(
  559     R0, R0_H
  560 );
  561 
  562 // Class for 64 bit register r1
  563 reg_class r1_reg(
  564     R1, R1_H
  565 );
  566 
  567 // Class for 64 bit register r2
  568 reg_class r2_reg(
  569     R2, R2_H
  570 );
  571 
  572 // Class for 64 bit register r3
  573 reg_class r3_reg(
  574     R3, R3_H
  575 );
  576 
  577 // Class for 64 bit register r4
  578 reg_class r4_reg(
  579     R4, R4_H
  580 );
  581 
  582 // Class for 64 bit register r5
  583 reg_class r5_reg(
  584     R5, R5_H
  585 );
  586 
  587 // Class for 64 bit register r10
  588 reg_class r10_reg(
  589     R10, R10_H
  590 );
  591 
  592 // Class for 64 bit register r11
  593 reg_class r11_reg(
  594     R11, R11_H
  595 );
  596 
  597 // Class for method register
  598 reg_class method_reg(
  599     R12, R12_H
  600 );
  601 
  602 // Class for heapbase register
  603 reg_class heapbase_reg(
  604     R27, R27_H
  605 );
  606 
  607 // Class for thread register
  608 reg_class thread_reg(
  609     R28, R28_H
  610 );
  611 
  612 // Class for frame pointer register
  613 reg_class fp_reg(
  614     R29, R29_H
  615 );
  616 
  617 // Class for link register
  618 reg_class lr_reg(
  619     R30, R30_H
  620 );
  621 
  622 // Class for long sp register
  623 reg_class sp_reg(
  624   R31, R31_H
  625 );
  626 
  627 // Class for all pointer registers
  628 reg_class ptr_reg %{
  629   return _PTR_REG_mask;
  630 %}
  631 
  632 // Class for all non_special pointer registers
  633 reg_class no_special_ptr_reg %{
  634   return _NO_SPECIAL_PTR_REG_mask;
  635 %}
  636 
  637 // Class for all float registers
  638 reg_class float_reg(
  639     V0,
  640     V1,
  641     V2,
  642     V3,
  643     V4,
  644     V5,
  645     V6,
  646     V7,
  647     V8,
  648     V9,
  649     V10,
  650     V11,
  651     V12,
  652     V13,
  653     V14,
  654     V15,
  655     V16,
  656     V17,
  657     V18,
  658     V19,
  659     V20,
  660     V21,
  661     V22,
  662     V23,
  663     V24,
  664     V25,
  665     V26,
  666     V27,
  667     V28,
  668     V29,
  669     V30,
  670     V31
  671 );
  672 
  673 // Double precision float registers have virtual `high halves&#39; that
  674 // are needed by the allocator.
  675 // Class for all double registers
  676 reg_class double_reg(
  677     V0, V0_H,
  678     V1, V1_H,
  679     V2, V2_H,
  680     V3, V3_H,
  681     V4, V4_H,
  682     V5, V5_H,
  683     V6, V6_H,
  684     V7, V7_H,
  685     V8, V8_H,
  686     V9, V9_H,
  687     V10, V10_H,
  688     V11, V11_H,
  689     V12, V12_H,
  690     V13, V13_H,
  691     V14, V14_H,
  692     V15, V15_H,
  693     V16, V16_H,
  694     V17, V17_H,
  695     V18, V18_H,
  696     V19, V19_H,
  697     V20, V20_H,
  698     V21, V21_H,
  699     V22, V22_H,
  700     V23, V23_H,
  701     V24, V24_H,
  702     V25, V25_H,
  703     V26, V26_H,
  704     V27, V27_H,
  705     V28, V28_H,
  706     V29, V29_H,
  707     V30, V30_H,
  708     V31, V31_H
  709 );
  710 
  711 // Class for all 64bit vector registers
  712 reg_class vectord_reg(
  713     V0, V0_H,
  714     V1, V1_H,
  715     V2, V2_H,
  716     V3, V3_H,
  717     V4, V4_H,
  718     V5, V5_H,
  719     V6, V6_H,
  720     V7, V7_H,
  721     V8, V8_H,
  722     V9, V9_H,
  723     V10, V10_H,
  724     V11, V11_H,
  725     V12, V12_H,
  726     V13, V13_H,
  727     V14, V14_H,
  728     V15, V15_H,
  729     V16, V16_H,
  730     V17, V17_H,
  731     V18, V18_H,
  732     V19, V19_H,
  733     V20, V20_H,
  734     V21, V21_H,
  735     V22, V22_H,
  736     V23, V23_H,
  737     V24, V24_H,
  738     V25, V25_H,
  739     V26, V26_H,
  740     V27, V27_H,
  741     V28, V28_H,
  742     V29, V29_H,
  743     V30, V30_H,
  744     V31, V31_H
  745 );
  746 
  747 // Class for all 128bit vector registers
  748 reg_class vectorx_reg(
  749     V0, V0_H, V0_J, V0_K,
  750     V1, V1_H, V1_J, V1_K,
  751     V2, V2_H, V2_J, V2_K,
  752     V3, V3_H, V3_J, V3_K,
  753     V4, V4_H, V4_J, V4_K,
  754     V5, V5_H, V5_J, V5_K,
  755     V6, V6_H, V6_J, V6_K,
  756     V7, V7_H, V7_J, V7_K,
  757     V8, V8_H, V8_J, V8_K,
  758     V9, V9_H, V9_J, V9_K,
  759     V10, V10_H, V10_J, V10_K,
  760     V11, V11_H, V11_J, V11_K,
  761     V12, V12_H, V12_J, V12_K,
  762     V13, V13_H, V13_J, V13_K,
  763     V14, V14_H, V14_J, V14_K,
  764     V15, V15_H, V15_J, V15_K,
  765     V16, V16_H, V16_J, V16_K,
  766     V17, V17_H, V17_J, V17_K,
  767     V18, V18_H, V18_J, V18_K,
  768     V19, V19_H, V19_J, V19_K,
  769     V20, V20_H, V20_J, V20_K,
  770     V21, V21_H, V21_J, V21_K,
  771     V22, V22_H, V22_J, V22_K,
  772     V23, V23_H, V23_J, V23_K,
  773     V24, V24_H, V24_J, V24_K,
  774     V25, V25_H, V25_J, V25_K,
  775     V26, V26_H, V26_J, V26_K,
  776     V27, V27_H, V27_J, V27_K,
  777     V28, V28_H, V28_J, V28_K,
  778     V29, V29_H, V29_J, V29_K,
  779     V30, V30_H, V30_J, V30_K,
  780     V31, V31_H, V31_J, V31_K
  781 );
  782 
  783 // Class for 128 bit register v0
  784 reg_class v0_reg(
  785     V0, V0_H
  786 );
  787 
  788 // Class for 128 bit register v1
  789 reg_class v1_reg(
  790     V1, V1_H
  791 );
  792 
  793 // Class for 128 bit register v2
  794 reg_class v2_reg(
  795     V2, V2_H
  796 );
  797 
  798 // Class for 128 bit register v3
  799 reg_class v3_reg(
  800     V3, V3_H
  801 );
  802 
  803 // Class for 128 bit register v4
  804 reg_class v4_reg(
  805     V4, V4_H
  806 );
  807 
  808 // Class for 128 bit register v5
  809 reg_class v5_reg(
  810     V5, V5_H
  811 );
  812 
  813 // Class for 128 bit register v6
  814 reg_class v6_reg(
  815     V6, V6_H
  816 );
  817 
  818 // Class for 128 bit register v7
  819 reg_class v7_reg(
  820     V7, V7_H
  821 );
  822 
  823 // Class for 128 bit register v8
  824 reg_class v8_reg(
  825     V8, V8_H
  826 );
  827 
  828 // Class for 128 bit register v9
  829 reg_class v9_reg(
  830     V9, V9_H
  831 );
  832 
  833 // Class for 128 bit register v10
  834 reg_class v10_reg(
  835     V10, V10_H
  836 );
  837 
  838 // Class for 128 bit register v11
  839 reg_class v11_reg(
  840     V11, V11_H
  841 );
  842 
  843 // Class for 128 bit register v12
  844 reg_class v12_reg(
  845     V12, V12_H
  846 );
  847 
  848 // Class for 128 bit register v13
  849 reg_class v13_reg(
  850     V13, V13_H
  851 );
  852 
  853 // Class for 128 bit register v14
  854 reg_class v14_reg(
  855     V14, V14_H
  856 );
  857 
  858 // Class for 128 bit register v15
  859 reg_class v15_reg(
  860     V15, V15_H
  861 );
  862 
  863 // Class for 128 bit register v16
  864 reg_class v16_reg(
  865     V16, V16_H
  866 );
  867 
  868 // Class for 128 bit register v17
  869 reg_class v17_reg(
  870     V17, V17_H
  871 );
  872 
  873 // Class for 128 bit register v18
  874 reg_class v18_reg(
  875     V18, V18_H
  876 );
  877 
  878 // Class for 128 bit register v19
  879 reg_class v19_reg(
  880     V19, V19_H
  881 );
  882 
  883 // Class for 128 bit register v20
  884 reg_class v20_reg(
  885     V20, V20_H
  886 );
  887 
  888 // Class for 128 bit register v21
  889 reg_class v21_reg(
  890     V21, V21_H
  891 );
  892 
  893 // Class for 128 bit register v22
  894 reg_class v22_reg(
  895     V22, V22_H
  896 );
  897 
  898 // Class for 128 bit register v23
  899 reg_class v23_reg(
  900     V23, V23_H
  901 );
  902 
  903 // Class for 128 bit register v24
  904 reg_class v24_reg(
  905     V24, V24_H
  906 );
  907 
  908 // Class for 128 bit register v25
  909 reg_class v25_reg(
  910     V25, V25_H
  911 );
  912 
  913 // Class for 128 bit register v26
  914 reg_class v26_reg(
  915     V26, V26_H
  916 );
  917 
  918 // Class for 128 bit register v27
  919 reg_class v27_reg(
  920     V27, V27_H
  921 );
  922 
  923 // Class for 128 bit register v28
  924 reg_class v28_reg(
  925     V28, V28_H
  926 );
  927 
  928 // Class for 128 bit register v29
  929 reg_class v29_reg(
  930     V29, V29_H
  931 );
  932 
  933 // Class for 128 bit register v30
  934 reg_class v30_reg(
  935     V30, V30_H
  936 );
  937 
  938 // Class for 128 bit register v31
  939 reg_class v31_reg(
  940     V31, V31_H
  941 );
  942 
  943 // Singleton class for condition codes
  944 reg_class int_flags(RFLAGS);
  945 
  946 %}
  947 
  948 //----------DEFINITION BLOCK---------------------------------------------------
  949 // Define name --&gt; value mappings to inform the ADLC of an integer valued name
  950 // Current support includes integer values in the range [0, 0x7FFFFFFF]
  951 // Format:
  952 //        int_def  &lt;name&gt;         ( &lt;int_value&gt;, &lt;expression&gt;);
  953 // Generated Code in ad_&lt;arch&gt;.hpp
  954 //        #define  &lt;name&gt;   (&lt;expression&gt;)
  955 //        // value == &lt;int_value&gt;
  956 // Generated code in ad_&lt;arch&gt;.cpp adlc_verification()
  957 //        assert( &lt;name&gt; == &lt;int_value&gt;, &quot;Expect (&lt;expression&gt;) to equal &lt;int_value&gt;&quot;);
  958 //
  959 
  960 // we follow the ppc-aix port in using a simple cost model which ranks
  961 // register operations as cheap, memory ops as more expensive and
  962 // branches as most expensive. the first two have a low as well as a
  963 // normal cost. huge cost appears to be a way of saying don&#39;t do
  964 // something
  965 
  966 definitions %{
  967   // The default cost (of a register move instruction).
  968   int_def INSN_COST            (    100,     100);
  969   int_def BRANCH_COST          (    200,     2 * INSN_COST);
  970   int_def CALL_COST            (    200,     2 * INSN_COST);
  971   int_def VOLATILE_REF_COST    (   1000,     10 * INSN_COST);
  972 %}
  973 
  974 
  975 //----------SOURCE BLOCK-------------------------------------------------------
  976 // This is a block of C++ code which provides values, functions, and
  977 // definitions necessary in the rest of the architecture description
  978 
  979 source_hpp %{
  980 
  981 #include &quot;asm/macroAssembler.hpp&quot;
  982 #include &quot;gc/shared/cardTable.hpp&quot;
  983 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;
  984 #include &quot;gc/shared/collectedHeap.hpp&quot;
  985 #include &quot;opto/addnode.hpp&quot;
  986 #include &quot;opto/convertnode.hpp&quot;
  987 
  988 extern RegMask _ANY_REG32_mask;
  989 extern RegMask _ANY_REG_mask;
  990 extern RegMask _PTR_REG_mask;
  991 extern RegMask _NO_SPECIAL_REG32_mask;
  992 extern RegMask _NO_SPECIAL_REG_mask;
  993 extern RegMask _NO_SPECIAL_PTR_REG_mask;
  994 
  995 class CallStubImpl {
  996 
  997   //--------------------------------------------------------------
  998   //---&lt;  Used for optimization in Compile::shorten_branches  &gt;---
  999   //--------------------------------------------------------------
 1000 
 1001  public:
 1002   // Size of call trampoline stub.
 1003   static uint size_call_trampoline() {
 1004     return 0; // no call trampolines on this platform
 1005   }
 1006 
 1007   // number of relocations needed by a call trampoline stub
 1008   static uint reloc_call_trampoline() {
 1009     return 0; // no call trampolines on this platform
 1010   }
 1011 };
 1012 
 1013 class HandlerImpl {
 1014 
 1015  public:
 1016 
 1017   static int emit_exception_handler(CodeBuffer &amp;cbuf);
 1018   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
 1019 
 1020   static uint size_exception_handler() {
 1021     return MacroAssembler::far_branch_size();
 1022   }
 1023 
 1024   static uint size_deopt_handler() {
 1025     // count one adr and one far branch instruction
 1026     return 4 * NativeInstruction::instruction_size;
 1027   }
 1028 };
 1029 
 1030 class Node::PD {
 1031 public:
 1032   enum NodeFlags {
 1033     _last_flag = Node::_last_flag
 1034   };
 1035 };
 1036 
 1037  bool is_CAS(int opcode, bool maybe_volatile);
 1038 
 1039   // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1040 
 1041   bool unnecessary_acquire(const Node *barrier);
 1042   bool needs_acquiring_load(const Node *load);
 1043 
 1044   // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1045 
 1046   bool unnecessary_release(const Node *barrier);
 1047   bool unnecessary_volatile(const Node *barrier);
 1048   bool needs_releasing_store(const Node *store);
 1049 
 1050   // predicate controlling translation of CompareAndSwapX
 1051   bool needs_acquiring_load_exclusive(const Node *load);
 1052 
 1053   // predicate controlling addressing modes
 1054   bool size_fits_all_mem_uses(AddPNode* addp, int shift);
 1055 %}
 1056 
 1057 source %{
 1058 
 1059   // Derived RegMask with conditionally allocatable registers
 1060 
 1061   void PhaseOutput::pd_perform_mach_node_analysis() {
 1062   }
 1063 
 1064   int MachNode::pd_alignment_required() const {
 1065     return 1;
 1066   }
 1067 
 1068   int MachNode::compute_padding(int current_offset) const {
 1069     return 0;
 1070   }
 1071 
 1072   RegMask _ANY_REG32_mask;
 1073   RegMask _ANY_REG_mask;
 1074   RegMask _PTR_REG_mask;
 1075   RegMask _NO_SPECIAL_REG32_mask;
 1076   RegMask _NO_SPECIAL_REG_mask;
 1077   RegMask _NO_SPECIAL_PTR_REG_mask;
 1078 
 1079   void reg_mask_init() {
 1080     // We derive below RegMask(s) from the ones which are auto-generated from
 1081     // adlc register classes to make AArch64 rheapbase (r27) and rfp (r29)
 1082     // registers conditionally reserved.
 1083 
 1084     _ANY_REG32_mask = _ALL_REG32_mask;
 1085     _ANY_REG32_mask.Remove(OptoReg::as_OptoReg(r31_sp-&gt;as_VMReg()));
 1086 
 1087     _ANY_REG_mask = _ALL_REG_mask;
 1088 
 1089     _PTR_REG_mask = _ALL_REG_mask;
 1090 
 1091     _NO_SPECIAL_REG32_mask = _ALL_REG32_mask;
 1092     _NO_SPECIAL_REG32_mask.SUBTRACT(_NON_ALLOCATABLE_REG32_mask);
 1093 
 1094     _NO_SPECIAL_REG_mask = _ALL_REG_mask;
 1095     _NO_SPECIAL_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1096 
 1097     _NO_SPECIAL_PTR_REG_mask = _ALL_REG_mask;
 1098     _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1099 
 1100     // r27 is not allocatable when compressed oops is on and heapbase is not
 1101     // zero, compressed klass pointers doesn&#39;t use r27 after JDK-8234794
 1102     if (UseCompressedOops &amp;&amp; CompressedOops::ptrs_base() != NULL) {
 1103       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r27-&gt;as_VMReg()));
 1104       _NO_SPECIAL_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1105       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1106     }
 1107 
 1108     // r29 is not allocatable when PreserveFramePointer is on
 1109     if (PreserveFramePointer) {
 1110       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r29-&gt;as_VMReg()));
 1111       _NO_SPECIAL_REG_mask.SUBTRACT(_FP_REG_mask);
 1112       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_FP_REG_mask);
 1113     }
 1114   }
 1115 
 1116   // Optimizaton of volatile gets and puts
 1117   // -------------------------------------
 1118   //
 1119   // AArch64 has ldar&lt;x&gt; and stlr&lt;x&gt; instructions which we can safely
 1120   // use to implement volatile reads and writes. For a volatile read
 1121   // we simply need
 1122   //
 1123   //   ldar&lt;x&gt;
 1124   //
 1125   // and for a volatile write we need
 1126   //
 1127   //   stlr&lt;x&gt;
 1128   //
 1129   // Alternatively, we can implement them by pairing a normal
 1130   // load/store with a memory barrier. For a volatile read we need
 1131   //
 1132   //   ldr&lt;x&gt;
 1133   //   dmb ishld
 1134   //
 1135   // for a volatile write
 1136   //
 1137   //   dmb ish
 1138   //   str&lt;x&gt;
 1139   //   dmb ish
 1140   //
 1141   // We can also use ldaxr and stlxr to implement compare and swap CAS
 1142   // sequences. These are normally translated to an instruction
 1143   // sequence like the following
 1144   //
 1145   //   dmb      ish
 1146   // retry:
 1147   //   ldxr&lt;x&gt;   rval raddr
 1148   //   cmp       rval rold
 1149   //   b.ne done
 1150   //   stlxr&lt;x&gt;  rval, rnew, rold
 1151   //   cbnz      rval retry
 1152   // done:
 1153   //   cset      r0, eq
 1154   //   dmb ishld
 1155   //
 1156   // Note that the exclusive store is already using an stlxr
 1157   // instruction. That is required to ensure visibility to other
 1158   // threads of the exclusive write (assuming it succeeds) before that
 1159   // of any subsequent writes.
 1160   //
 1161   // The following instruction sequence is an improvement on the above
 1162   //
 1163   // retry:
 1164   //   ldaxr&lt;x&gt;  rval raddr
 1165   //   cmp       rval rold
 1166   //   b.ne done
 1167   //   stlxr&lt;x&gt;  rval, rnew, rold
 1168   //   cbnz      rval retry
 1169   // done:
 1170   //   cset      r0, eq
 1171   //
 1172   // We don&#39;t need the leading dmb ish since the stlxr guarantees
 1173   // visibility of prior writes in the case that the swap is
 1174   // successful. Crucially we don&#39;t have to worry about the case where
 1175   // the swap is not successful since no valid program should be
 1176   // relying on visibility of prior changes by the attempting thread
 1177   // in the case where the CAS fails.
 1178   //
 1179   // Similarly, we don&#39;t need the trailing dmb ishld if we substitute
 1180   // an ldaxr instruction since that will provide all the guarantees we
 1181   // require regarding observation of changes made by other threads
 1182   // before any change to the CAS address observed by the load.
 1183   //
 1184   // In order to generate the desired instruction sequence we need to
 1185   // be able to identify specific &#39;signature&#39; ideal graph node
 1186   // sequences which i) occur as a translation of a volatile reads or
 1187   // writes or CAS operations and ii) do not occur through any other
 1188   // translation or graph transformation. We can then provide
 1189   // alternative aldc matching rules which translate these node
 1190   // sequences to the desired machine code sequences. Selection of the
 1191   // alternative rules can be implemented by predicates which identify
 1192   // the relevant node sequences.
 1193   //
 1194   // The ideal graph generator translates a volatile read to the node
 1195   // sequence
 1196   //
 1197   //   LoadX[mo_acquire]
 1198   //   MemBarAcquire
 1199   //
 1200   // As a special case when using the compressed oops optimization we
 1201   // may also see this variant
 1202   //
 1203   //   LoadN[mo_acquire]
 1204   //   DecodeN
 1205   //   MemBarAcquire
 1206   //
 1207   // A volatile write is translated to the node sequence
 1208   //
 1209   //   MemBarRelease
 1210   //   StoreX[mo_release] {CardMark}-optional
 1211   //   MemBarVolatile
 1212   //
 1213   // n.b. the above node patterns are generated with a strict
 1214   // &#39;signature&#39; configuration of input and output dependencies (see
 1215   // the predicates below for exact details). The card mark may be as
 1216   // simple as a few extra nodes or, in a few GC configurations, may
 1217   // include more complex control flow between the leading and
 1218   // trailing memory barriers. However, whatever the card mark
 1219   // configuration these signatures are unique to translated volatile
 1220   // reads/stores -- they will not appear as a result of any other
 1221   // bytecode translation or inlining nor as a consequence of
 1222   // optimizing transforms.
 1223   //
 1224   // We also want to catch inlined unsafe volatile gets and puts and
 1225   // be able to implement them using either ldar&lt;x&gt;/stlr&lt;x&gt; or some
 1226   // combination of ldr&lt;x&gt;/stlr&lt;x&gt; and dmb instructions.
 1227   //
 1228   // Inlined unsafe volatiles puts manifest as a minor variant of the
 1229   // normal volatile put node sequence containing an extra cpuorder
 1230   // membar
 1231   //
 1232   //   MemBarRelease
 1233   //   MemBarCPUOrder
 1234   //   StoreX[mo_release] {CardMark}-optional
 1235   //   MemBarCPUOrder
 1236   //   MemBarVolatile
 1237   //
 1238   // n.b. as an aside, a cpuorder membar is not itself subject to
 1239   // matching and translation by adlc rules.  However, the rule
 1240   // predicates need to detect its presence in order to correctly
 1241   // select the desired adlc rules.
 1242   //
 1243   // Inlined unsafe volatile gets manifest as a slightly different
 1244   // node sequence to a normal volatile get because of the
 1245   // introduction of some CPUOrder memory barriers to bracket the
 1246   // Load. However, but the same basic skeleton of a LoadX feeding a
 1247   // MemBarAcquire, possibly thorugh an optional DecodeN, is still
 1248   // present
 1249   //
 1250   //   MemBarCPUOrder
 1251   //        ||       \\
 1252   //   MemBarCPUOrder LoadX[mo_acquire]
 1253   //        ||            |
 1254   //        ||       {DecodeN} optional
 1255   //        ||       /
 1256   //     MemBarAcquire
 1257   //
 1258   // In this case the acquire membar does not directly depend on the
 1259   // load. However, we can be sure that the load is generated from an
 1260   // inlined unsafe volatile get if we see it dependent on this unique
 1261   // sequence of membar nodes. Similarly, given an acquire membar we
 1262   // can know that it was added because of an inlined unsafe volatile
 1263   // get if it is fed and feeds a cpuorder membar and if its feed
 1264   // membar also feeds an acquiring load.
 1265   //
 1266   // Finally an inlined (Unsafe) CAS operation is translated to the
 1267   // following ideal graph
 1268   //
 1269   //   MemBarRelease
 1270   //   MemBarCPUOrder
 1271   //   CompareAndSwapX {CardMark}-optional
 1272   //   MemBarCPUOrder
 1273   //   MemBarAcquire
 1274   //
 1275   // So, where we can identify these volatile read and write
 1276   // signatures we can choose to plant either of the above two code
 1277   // sequences. For a volatile read we can simply plant a normal
 1278   // ldr&lt;x&gt; and translate the MemBarAcquire to a dmb. However, we can
 1279   // also choose to inhibit translation of the MemBarAcquire and
 1280   // inhibit planting of the ldr&lt;x&gt;, instead planting an ldar&lt;x&gt;.
 1281   //
 1282   // When we recognise a volatile store signature we can choose to
 1283   // plant at a dmb ish as a translation for the MemBarRelease, a
 1284   // normal str&lt;x&gt; and then a dmb ish for the MemBarVolatile.
 1285   // Alternatively, we can inhibit translation of the MemBarRelease
 1286   // and MemBarVolatile and instead plant a simple stlr&lt;x&gt;
 1287   // instruction.
 1288   //
 1289   // when we recognise a CAS signature we can choose to plant a dmb
 1290   // ish as a translation for the MemBarRelease, the conventional
 1291   // macro-instruction sequence for the CompareAndSwap node (which
 1292   // uses ldxr&lt;x&gt;) and then a dmb ishld for the MemBarAcquire.
 1293   // Alternatively, we can elide generation of the dmb instructions
 1294   // and plant the alternative CompareAndSwap macro-instruction
 1295   // sequence (which uses ldaxr&lt;x&gt;).
 1296   //
 1297   // Of course, the above only applies when we see these signature
 1298   // configurations. We still want to plant dmb instructions in any
 1299   // other cases where we may see a MemBarAcquire, MemBarRelease or
 1300   // MemBarVolatile. For example, at the end of a constructor which
 1301   // writes final/volatile fields we will see a MemBarRelease
 1302   // instruction and this needs a &#39;dmb ish&#39; lest we risk the
 1303   // constructed object being visible without making the
 1304   // final/volatile field writes visible.
 1305   //
 1306   // n.b. the translation rules below which rely on detection of the
 1307   // volatile signatures and insert ldar&lt;x&gt; or stlr&lt;x&gt; are failsafe.
 1308   // If we see anything other than the signature configurations we
 1309   // always just translate the loads and stores to ldr&lt;x&gt; and str&lt;x&gt;
 1310   // and translate acquire, release and volatile membars to the
 1311   // relevant dmb instructions.
 1312   //
 1313 
 1314   // is_CAS(int opcode, bool maybe_volatile)
 1315   //
 1316   // return true if opcode is one of the possible CompareAndSwapX
 1317   // values otherwise false.
 1318 
 1319   bool is_CAS(int opcode, bool maybe_volatile)
 1320   {
 1321     switch(opcode) {
 1322       // We handle these
 1323     case Op_CompareAndSwapI:
 1324     case Op_CompareAndSwapL:
 1325     case Op_CompareAndSwapP:
 1326     case Op_CompareAndSwapN:
 1327     case Op_ShenandoahCompareAndSwapP:
 1328     case Op_ShenandoahCompareAndSwapN:
 1329     case Op_CompareAndSwapB:
 1330     case Op_CompareAndSwapS:
 1331     case Op_GetAndSetI:
 1332     case Op_GetAndSetL:
 1333     case Op_GetAndSetP:
 1334     case Op_GetAndSetN:
 1335     case Op_GetAndAddI:
 1336     case Op_GetAndAddL:
 1337       return true;
 1338     case Op_CompareAndExchangeI:
 1339     case Op_CompareAndExchangeN:
 1340     case Op_CompareAndExchangeB:
 1341     case Op_CompareAndExchangeS:
 1342     case Op_CompareAndExchangeL:
 1343     case Op_CompareAndExchangeP:
 1344     case Op_WeakCompareAndSwapB:
 1345     case Op_WeakCompareAndSwapS:
 1346     case Op_WeakCompareAndSwapI:
 1347     case Op_WeakCompareAndSwapL:
 1348     case Op_WeakCompareAndSwapP:
 1349     case Op_WeakCompareAndSwapN:
 1350     case Op_ShenandoahWeakCompareAndSwapP:
 1351     case Op_ShenandoahWeakCompareAndSwapN:
 1352     case Op_ShenandoahCompareAndExchangeP:
 1353     case Op_ShenandoahCompareAndExchangeN:
 1354       return maybe_volatile;
 1355     default:
 1356       return false;
 1357     }
 1358   }
 1359 
 1360   // helper to determine the maximum number of Phi nodes we may need to
 1361   // traverse when searching from a card mark membar for the merge mem
 1362   // feeding a trailing membar or vice versa
 1363 
 1364 // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt;
 1365 
 1366 bool unnecessary_acquire(const Node *barrier)
 1367 {
 1368   assert(barrier-&gt;is_MemBar(), &quot;expecting a membar&quot;);
 1369 
 1370   MemBarNode* mb = barrier-&gt;as_MemBar();
 1371 
 1372   if (mb-&gt;trailing_load()) {
 1373     return true;
 1374   }
 1375 
 1376   if (mb-&gt;trailing_load_store()) {
 1377     Node* load_store = mb-&gt;in(MemBarNode::Precedent);
 1378     assert(load_store-&gt;is_LoadStore(), &quot;unexpected graph shape&quot;);
 1379     return is_CAS(load_store-&gt;Opcode(), true);
 1380   }
 1381 
 1382   return false;
 1383 }
 1384 
 1385 bool needs_acquiring_load(const Node *n)
 1386 {
 1387   assert(n-&gt;is_Load(), &quot;expecting a load&quot;);
 1388   LoadNode *ld = n-&gt;as_Load();
 1389   return ld-&gt;is_acquire();
 1390 }
 1391 
 1392 bool unnecessary_release(const Node *n)
 1393 {
 1394   assert((n-&gt;is_MemBar() &amp;&amp;
 1395           n-&gt;Opcode() == Op_MemBarRelease),
 1396          &quot;expecting a release membar&quot;);
 1397 
 1398   MemBarNode *barrier = n-&gt;as_MemBar();
 1399   if (!barrier-&gt;leading()) {
 1400     return false;
 1401   } else {
 1402     Node* trailing = barrier-&gt;trailing_membar();
 1403     MemBarNode* trailing_mb = trailing-&gt;as_MemBar();
 1404     assert(trailing_mb-&gt;trailing(), &quot;Not a trailing membar?&quot;);
 1405     assert(trailing_mb-&gt;leading_membar() == n, &quot;inconsistent leading/trailing membars&quot;);
 1406 
 1407     Node* mem = trailing_mb-&gt;in(MemBarNode::Precedent);
 1408     if (mem-&gt;is_Store()) {
 1409       assert(mem-&gt;as_Store()-&gt;is_release(), &quot;&quot;);
 1410       assert(trailing_mb-&gt;Opcode() == Op_MemBarVolatile, &quot;&quot;);
 1411       return true;
 1412     } else {
 1413       assert(mem-&gt;is_LoadStore(), &quot;&quot;);
 1414       assert(trailing_mb-&gt;Opcode() == Op_MemBarAcquire, &quot;&quot;);
 1415       return is_CAS(mem-&gt;Opcode(), true);
 1416     }
 1417   }
 1418   return false;
 1419 }
 1420 
 1421 bool unnecessary_volatile(const Node *n)
 1422 {
 1423   // assert n-&gt;is_MemBar();
 1424   MemBarNode *mbvol = n-&gt;as_MemBar();
 1425 
 1426   bool release = mbvol-&gt;trailing_store();
 1427   assert(!release || (mbvol-&gt;in(MemBarNode::Precedent)-&gt;is_Store() &amp;&amp; mbvol-&gt;in(MemBarNode::Precedent)-&gt;as_Store()-&gt;is_release()), &quot;&quot;);
 1428 #ifdef ASSERT
 1429   if (release) {
 1430     Node* leading = mbvol-&gt;leading_membar();
 1431     assert(leading-&gt;Opcode() == Op_MemBarRelease, &quot;&quot;);
 1432     assert(leading-&gt;as_MemBar()-&gt;leading_store(), &quot;&quot;);
 1433     assert(leading-&gt;as_MemBar()-&gt;trailing_membar() == mbvol, &quot;&quot;);
 1434   }
 1435 #endif
 1436 
 1437   return release;
 1438 }
 1439 
 1440 // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt;
 1441 
 1442 bool needs_releasing_store(const Node *n)
 1443 {
 1444   // assert n-&gt;is_Store();
 1445   StoreNode *st = n-&gt;as_Store();
 1446   return st-&gt;trailing_membar() != NULL;
 1447 }
 1448 
 1449 // predicate controlling translation of CAS
 1450 //
 1451 // returns true if CAS needs to use an acquiring load otherwise false
 1452 
 1453 bool needs_acquiring_load_exclusive(const Node *n)
 1454 {
 1455   assert(is_CAS(n-&gt;Opcode(), true), &quot;expecting a compare and swap&quot;);
 1456   LoadStoreNode* ldst = n-&gt;as_LoadStore();
 1457   if (is_CAS(n-&gt;Opcode(), false)) {
 1458     assert(ldst-&gt;trailing_membar() != NULL, &quot;expected trailing membar&quot;);
 1459   } else {
 1460     return ldst-&gt;trailing_membar() != NULL;
 1461   }
 1462 
 1463   // so we can just return true here
 1464   return true;
 1465 }
 1466 
 1467 #define __ _masm.
 1468 
 1469 // advance declarations for helper functions to convert register
 1470 // indices to register objects
 1471 
 1472 // the ad file has to provide implementations of certain methods
 1473 // expected by the generic code
 1474 //
 1475 // REQUIRED FUNCTIONALITY
 1476 
 1477 //=============================================================================
 1478 
 1479 // !!!!! Special hack to get all types of calls to specify the byte offset
 1480 //       from the start of the call to the point where the return address
 1481 //       will point.
 1482 
 1483 int MachCallStaticJavaNode::ret_addr_offset()
 1484 {
 1485   // call should be a simple bl
 1486   int off = 4;
 1487   return off;
 1488 }
 1489 
 1490 int MachCallDynamicJavaNode::ret_addr_offset()
 1491 {
 1492   return 16; // movz, movk, movk, bl
 1493 }
 1494 
 1495 int MachCallRuntimeNode::ret_addr_offset() {
 1496   // for generated stubs the call will be
 1497   //   far_call(addr)
 1498   // for real runtime callouts it will be six instructions
 1499   // see aarch64_enc_java_to_runtime
 1500   //   adr(rscratch2, retaddr)
 1501   //   lea(rscratch1, RuntimeAddress(addr)
 1502   //   stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)))
 1503   //   blr(rscratch1)
 1504   CodeBlob *cb = CodeCache::find_blob(_entry_point);
 1505   if (cb) {
 1506     return MacroAssembler::far_branch_size();
 1507   } else {
 1508     return 6 * NativeInstruction::instruction_size;
 1509   }
 1510 }
 1511 
 1512 // Indicate if the safepoint node needs the polling page as an input
 1513 
 1514 // the shared code plants the oop data at the start of the generated
 1515 // code for the safepoint node and that needs ot be at the load
 1516 // instruction itself. so we cannot plant a mov of the safepoint poll
 1517 // address followed by a load. setting this to true means the mov is
 1518 // scheduled as a prior instruction. that&#39;s better for scheduling
 1519 // anyway.
 1520 
 1521 bool SafePointNode::needs_polling_address_input()
 1522 {
 1523   return true;
 1524 }
 1525 
 1526 //=============================================================================
 1527 
 1528 #ifndef PRODUCT
 1529 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1530   st-&gt;print(&quot;BREAKPOINT&quot;);
 1531 }
 1532 #endif
 1533 
 1534 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1535   C2_MacroAssembler _masm(&amp;cbuf);
 1536   __ brk(0);
 1537 }
 1538 
 1539 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
 1540   return MachNode::size(ra_);
 1541 }
 1542 
 1543 //=============================================================================
 1544 
 1545 #ifndef PRODUCT
 1546   void MachNopNode::format(PhaseRegAlloc*, outputStream* st) const {
 1547     st-&gt;print(&quot;nop \t# %d bytes pad for loops and calls&quot;, _count);
 1548   }
 1549 #endif
 1550 
 1551   void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc*) const {
 1552     C2_MacroAssembler _masm(&amp;cbuf);
 1553     for (int i = 0; i &lt; _count; i++) {
 1554       __ nop();
 1555     }
 1556   }
 1557 
 1558   uint MachNopNode::size(PhaseRegAlloc*) const {
 1559     return _count * NativeInstruction::instruction_size;
 1560   }
 1561 
 1562 //=============================================================================
 1563 const RegMask&amp; MachConstantBaseNode::_out_RegMask = RegMask::Empty;
 1564 
 1565 int ConstantTable::calculate_table_base_offset() const {
 1566   return 0;  // absolute addressing, no offset
 1567 }
 1568 
 1569 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
 1570 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1571   ShouldNotReachHere();
 1572 }
 1573 
 1574 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1575   // Empty encoding
 1576 }
 1577 
 1578 uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
 1579   return 0;
 1580 }
 1581 
 1582 #ifndef PRODUCT
 1583 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1584   st-&gt;print(&quot;-- \t// MachConstantBaseNode (empty encoding)&quot;);
 1585 }
 1586 #endif
 1587 
 1588 #ifndef PRODUCT
 1589 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1590   Compile* C = ra_-&gt;C;
 1591 
 1592   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1593 
 1594   if (C-&gt;output()-&gt;need_stack_bang(framesize))
 1595     st-&gt;print(&quot;# stack bang size=%d\n\t&quot;, framesize);
 1596 
 1597   if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1598     st-&gt;print(&quot;sub  sp, sp, #%d\n\t&quot;, framesize);
 1599     st-&gt;print(&quot;stp  rfp, lr, [sp, #%d]&quot;, framesize - 2 * wordSize);
 1600     if (PreserveFramePointer) st-&gt;print(&quot;\n\tadd  rfp, sp, #%d&quot;, framesize - 2 * wordSize);
 1601   } else {
 1602     st-&gt;print(&quot;stp  lr, rfp, [sp, #%d]!\n\t&quot;, -(2 * wordSize));
 1603     if (PreserveFramePointer) st-&gt;print(&quot;mov  rfp, sp\n\t&quot;);
 1604     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1605     st-&gt;print(&quot;sub  sp, sp, rscratch1&quot;);
 1606   }
 1607   if (C-&gt;stub_function() == NULL &amp;&amp; BarrierSet::barrier_set()-&gt;barrier_set_nmethod() != NULL) {
 1608     st-&gt;print(&quot;\n\t&quot;);
 1609     st-&gt;print(&quot;ldr  rscratch1, [guard]\n\t&quot;);
 1610     st-&gt;print(&quot;dmb ishld\n\t&quot;);
 1611     st-&gt;print(&quot;ldr  rscratch2, [rthread, #thread_disarmed_offset]\n\t&quot;);
 1612     st-&gt;print(&quot;cmp  rscratch1, rscratch2\n\t&quot;);
 1613     st-&gt;print(&quot;b.eq skip&quot;);
 1614     st-&gt;print(&quot;\n\t&quot;);
 1615     st-&gt;print(&quot;blr #nmethod_entry_barrier_stub\n\t&quot;);
 1616     st-&gt;print(&quot;b skip\n\t&quot;);
 1617     st-&gt;print(&quot;guard: int\n\t&quot;);
 1618     st-&gt;print(&quot;\n\t&quot;);
 1619     st-&gt;print(&quot;skip:\n\t&quot;);
 1620   }
 1621 }
 1622 #endif
 1623 
 1624 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1625   Compile* C = ra_-&gt;C;
 1626   C2_MacroAssembler _masm(&amp;cbuf);
 1627 
 1628   // n.b. frame size includes space for return pc and rfp
 1629   const long framesize = C-&gt;output()-&gt;frame_size_in_bytes();
 1630   assert(framesize%(2*wordSize) == 0, &quot;must preserve 2*wordSize alignment&quot;);
 1631 
 1632   // insert a nop at the start of the prolog so we can patch in a
 1633   // branch if we need to invalidate the method later
 1634   __ nop();
 1635 
 1636   if (C-&gt;clinit_barrier_on_entry()) {
 1637     assert(!C-&gt;method()-&gt;holder()-&gt;is_not_initialized(), &quot;initialization should have been started&quot;);
 1638 
 1639     Label L_skip_barrier;
 1640 
 1641     __ mov_metadata(rscratch2, C-&gt;method()-&gt;holder()-&gt;constant_encoding());
 1642     __ clinit_barrier(rscratch2, rscratch1, &amp;L_skip_barrier);
 1643     __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));
 1644     __ bind(L_skip_barrier);
 1645   }
 1646 
 1647   int bangsize = C-&gt;output()-&gt;bang_size_in_bytes();
 1648   if (C-&gt;output()-&gt;need_stack_bang(bangsize) &amp;&amp; UseStackBanging)
 1649     __ generate_stack_overflow_check(bangsize);
 1650 
 1651   __ build_frame(framesize);
 1652 
 1653   if (C-&gt;stub_function() == NULL) {
 1654     BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
 1655     bs-&gt;nmethod_entry_barrier(&amp;_masm);
 1656   }
 1657 
 1658   if (VerifyStackAtCalls) {
 1659     Unimplemented();
 1660   }
 1661 
 1662   C-&gt;output()-&gt;set_frame_complete(cbuf.insts_size());
 1663 
 1664   if (C-&gt;has_mach_constant_base_node()) {
 1665     // NOTE: We set the table base offset here because users might be
 1666     // emitted before MachConstantBaseNode.
 1667     ConstantTable&amp; constant_table = C-&gt;output()-&gt;constant_table();
 1668     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
 1669   }
 1670 }
 1671 
 1672 uint MachPrologNode::size(PhaseRegAlloc* ra_) const
 1673 {
 1674   return MachNode::size(ra_); // too many variables; just compute it
 1675                               // the hard way
 1676 }
 1677 
 1678 int MachPrologNode::reloc() const
 1679 {
 1680   return 0;
 1681 }
 1682 
 1683 //=============================================================================
 1684 
 1685 #ifndef PRODUCT
 1686 void MachEpilogNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1687   Compile* C = ra_-&gt;C;
 1688   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1689 
 1690   st-&gt;print(&quot;# pop frame %d\n\t&quot;,framesize);
 1691 
 1692   if (framesize == 0) {
 1693     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1694   } else if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1695     st-&gt;print(&quot;ldp  lr, rfp, [sp,#%d]\n\t&quot;, framesize - 2 * wordSize);
 1696     st-&gt;print(&quot;add  sp, sp, #%d\n\t&quot;, framesize);
 1697   } else {
 1698     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1699     st-&gt;print(&quot;add  sp, sp, rscratch1\n\t&quot;);
 1700     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1701   }
 1702 
 1703   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1704     st-&gt;print(&quot;# touch polling page\n\t&quot;);
 1705     st-&gt;print(&quot;ldr rscratch1, [rthread],#polling_page_offset\n\t&quot;);
 1706     st-&gt;print(&quot;ldr zr, [rscratch1]&quot;);
 1707   }
 1708 }
 1709 #endif
 1710 
 1711 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1712   Compile* C = ra_-&gt;C;
 1713   C2_MacroAssembler _masm(&amp;cbuf);
 1714   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1715 
 1716   __ remove_frame(framesize);
 1717 
 1718   if (StackReservedPages &gt; 0 &amp;&amp; C-&gt;has_reserved_stack_access()) {
 1719     __ reserved_stack_check();
 1720   }
 1721 
 1722   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1723     __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);
 1724   }
 1725 }
 1726 
 1727 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
 1728   // Variable size. Determine dynamically.
 1729   return MachNode::size(ra_);
 1730 }
 1731 
 1732 int MachEpilogNode::reloc() const {
 1733   // Return number of relocatable values contained in this instruction.
 1734   return 1; // 1 for polling page.
 1735 }
 1736 
 1737 const Pipeline * MachEpilogNode::pipeline() const {
 1738   return MachNode::pipeline_class();
 1739 }
 1740 
 1741 //=============================================================================
 1742 
 1743 // Figure out which register class each belongs in: rc_int, rc_float or
 1744 // rc_stack.
 1745 enum RC { rc_bad, rc_int, rc_float, rc_stack };
 1746 
 1747 static enum RC rc_class(OptoReg::Name reg) {
 1748 
 1749   if (reg == OptoReg::Bad) {
 1750     return rc_bad;
 1751   }
 1752 
 1753   // we have 30 int registers * 2 halves
 1754   // (rscratch1 and rscratch2 are omitted)
 1755   int slots_of_int_registers = RegisterImpl::max_slots_per_register * (RegisterImpl::number_of_registers - 2);
 1756 
 1757   if (reg &lt; slots_of_int_registers) {
 1758     return rc_int;
 1759   }
 1760 
 1761   // we have 32 float register * 4 halves
 1762   if (reg &lt; slots_of_int_registers + FloatRegisterImpl::max_slots_per_register * FloatRegisterImpl::number_of_registers) {
 1763     return rc_float;
 1764   }
 1765 
 1766   // Between float regs &amp; stack is the flags regs.
 1767   assert(OptoReg::is_stack(reg), &quot;blow up if spilling flags&quot;);
 1768 
 1769   return rc_stack;
 1770 }
 1771 
 1772 uint MachSpillCopyNode::implementation(CodeBuffer *cbuf, PhaseRegAlloc *ra_, bool do_size, outputStream *st) const {
 1773   Compile* C = ra_-&gt;C;
 1774 
 1775   // Get registers to move.
 1776   OptoReg::Name src_hi = ra_-&gt;get_reg_second(in(1));
 1777   OptoReg::Name src_lo = ra_-&gt;get_reg_first(in(1));
 1778   OptoReg::Name dst_hi = ra_-&gt;get_reg_second(this);
 1779   OptoReg::Name dst_lo = ra_-&gt;get_reg_first(this);
 1780 
 1781   enum RC src_hi_rc = rc_class(src_hi);
 1782   enum RC src_lo_rc = rc_class(src_lo);
 1783   enum RC dst_hi_rc = rc_class(dst_hi);
 1784   enum RC dst_lo_rc = rc_class(dst_lo);
 1785 
 1786   assert(src_lo != OptoReg::Bad &amp;&amp; dst_lo != OptoReg::Bad, &quot;must move at least 1 register&quot;);
 1787 
 1788   if (src_hi != OptoReg::Bad) {
 1789     assert((src_lo&amp;1)==0 &amp;&amp; src_lo+1==src_hi &amp;&amp;
 1790            (dst_lo&amp;1)==0 &amp;&amp; dst_lo+1==dst_hi,
 1791            &quot;expected aligned-adjacent pairs&quot;);
 1792   }
 1793 
 1794   if (src_lo == dst_lo &amp;&amp; src_hi == dst_hi) {
 1795     return 0;            // Self copy, no move.
 1796   }
 1797 
 1798   bool is64 = (src_lo &amp; 1) == 0 &amp;&amp; src_lo + 1 == src_hi &amp;&amp;
 1799               (dst_lo &amp; 1) == 0 &amp;&amp; dst_lo + 1 == dst_hi;
 1800   int src_offset = ra_-&gt;reg2offset(src_lo);
 1801   int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1802 
 1803   if (bottom_type()-&gt;isa_vect() != NULL) {
 1804     uint ireg = ideal_reg();
 1805     assert(ireg == Op_VecD || ireg == Op_VecX, &quot;must be 64 bit or 128 bit vector&quot;);
 1806     if (cbuf) {
 1807       C2_MacroAssembler _masm(cbuf);
 1808       assert((src_lo_rc != rc_int &amp;&amp; dst_lo_rc != rc_int), &quot;sanity&quot;);
 1809       if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1810         // stack-&gt;stack
 1811         assert((src_offset &amp; 7) == 0 &amp;&amp; (dst_offset &amp; 7) == 0, &quot;unaligned stack offset&quot;);
 1812         if (ireg == Op_VecD) {
 1813           __ unspill(rscratch1, true, src_offset);
 1814           __ spill(rscratch1, true, dst_offset);
 1815         } else {
 1816           __ spill_copy128(src_offset, dst_offset);
 1817         }
 1818       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_float) {
 1819         __ mov(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1820                ireg == Op_VecD ? __ T8B : __ T16B,
 1821                as_FloatRegister(Matcher::_regEncode[src_lo]));
 1822       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_stack) {
 1823         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1824                        ireg == Op_VecD ? __ D : __ Q,
 1825                        ra_-&gt;reg2offset(dst_lo));
 1826       } else if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_float) {
 1827         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1828                        ireg == Op_VecD ? __ D : __ Q,
 1829                        ra_-&gt;reg2offset(src_lo));
 1830       } else {
 1831         ShouldNotReachHere();
 1832       }
 1833     }
 1834   } else if (cbuf) {
 1835     C2_MacroAssembler _masm(cbuf);
 1836     switch (src_lo_rc) {
 1837     case rc_int:
 1838       if (dst_lo_rc == rc_int) {  // gpr --&gt; gpr copy
 1839         if (is64) {
 1840             __ mov(as_Register(Matcher::_regEncode[dst_lo]),
 1841                    as_Register(Matcher::_regEncode[src_lo]));
 1842         } else {
 1843             C2_MacroAssembler _masm(cbuf);
 1844             __ movw(as_Register(Matcher::_regEncode[dst_lo]),
 1845                     as_Register(Matcher::_regEncode[src_lo]));
 1846         }
 1847       } else if (dst_lo_rc == rc_float) { // gpr --&gt; fpr copy
 1848         if (is64) {
 1849             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1850                      as_Register(Matcher::_regEncode[src_lo]));
 1851         } else {
 1852             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1853                      as_Register(Matcher::_regEncode[src_lo]));
 1854         }
 1855       } else {                    // gpr --&gt; stack spill
 1856         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1857         __ spill(as_Register(Matcher::_regEncode[src_lo]), is64, dst_offset);
 1858       }
 1859       break;
 1860     case rc_float:
 1861       if (dst_lo_rc == rc_int) {  // fpr --&gt; gpr copy
 1862         if (is64) {
 1863             __ fmovd(as_Register(Matcher::_regEncode[dst_lo]),
 1864                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1865         } else {
 1866             __ fmovs(as_Register(Matcher::_regEncode[dst_lo]),
 1867                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1868         }
 1869       } else if (dst_lo_rc == rc_float) { // fpr --&gt; fpr copy
 1870           if (cbuf) {
 1871             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1872                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1873         } else {
 1874             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1875                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1876         }
 1877       } else {                    // fpr --&gt; stack spill
 1878         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1879         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1880                  is64 ? __ D : __ S, dst_offset);
 1881       }
 1882       break;
 1883     case rc_stack:
 1884       if (dst_lo_rc == rc_int) {  // stack --&gt; gpr load
 1885         __ unspill(as_Register(Matcher::_regEncode[dst_lo]), is64, src_offset);
 1886       } else if (dst_lo_rc == rc_float) { // stack --&gt; fpr load
 1887         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1888                    is64 ? __ D : __ S, src_offset);
 1889       } else {                    // stack --&gt; stack copy
 1890         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1891         __ unspill(rscratch1, is64, src_offset);
 1892         __ spill(rscratch1, is64, dst_offset);
 1893       }
 1894       break;
 1895     default:
 1896       assert(false, &quot;bad rc_class for spill&quot;);
 1897       ShouldNotReachHere();
 1898     }
 1899   }
 1900 
 1901   if (st) {
 1902     st-&gt;print(&quot;spill &quot;);
 1903     if (src_lo_rc == rc_stack) {
 1904       st-&gt;print(&quot;[sp, #%d] -&gt; &quot;, ra_-&gt;reg2offset(src_lo));
 1905     } else {
 1906       st-&gt;print(&quot;%s -&gt; &quot;, Matcher::regName[src_lo]);
 1907     }
 1908     if (dst_lo_rc == rc_stack) {
 1909       st-&gt;print(&quot;[sp, #%d]&quot;, ra_-&gt;reg2offset(dst_lo));
 1910     } else {
 1911       st-&gt;print(&quot;%s&quot;, Matcher::regName[dst_lo]);
 1912     }
 1913     if (bottom_type()-&gt;isa_vect() != NULL) {
 1914       st-&gt;print(&quot;\t# vector spill size = %d&quot;, ideal_reg()==Op_VecD ? 64:128);
 1915     } else {
 1916       st-&gt;print(&quot;\t# spill size = %d&quot;, is64 ? 64:32);
 1917     }
 1918   }
 1919 
 1920   return 0;
 1921 
 1922 }
 1923 
 1924 #ifndef PRODUCT
 1925 void MachSpillCopyNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1926   if (!ra_)
 1927     st-&gt;print(&quot;N%d = SpillCopy(N%d)&quot;, _idx, in(1)-&gt;_idx);
 1928   else
 1929     implementation(NULL, ra_, false, st);
 1930 }
 1931 #endif
 1932 
 1933 void MachSpillCopyNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1934   implementation(&amp;cbuf, ra_, false, NULL);
 1935 }
 1936 
 1937 uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
 1938   return MachNode::size(ra_);
 1939 }
 1940 
 1941 //=============================================================================
 1942 
 1943 #ifndef PRODUCT
 1944 void BoxLockNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1945   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1946   int reg = ra_-&gt;get_reg_first(this);
 1947   st-&gt;print(&quot;add %s, rsp, #%d]\t# box lock&quot;,
 1948             Matcher::regName[reg], offset);
 1949 }
 1950 #endif
 1951 
 1952 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1953   C2_MacroAssembler _masm(&amp;cbuf);
 1954 
 1955   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1956   int reg    = ra_-&gt;get_encode(this);
 1957 
 1958   // This add will handle any 24-bit signed offset. 24 bits allows an
 1959   // 8 megabyte stack frame.
 1960   __ add(as_Register(reg), sp, offset);
 1961 }
 1962 
 1963 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 1964   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_).
 1965   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1966 
 1967   if (Assembler::operand_valid_for_add_sub_immediate(offset)) {
 1968     return NativeInstruction::instruction_size;
 1969   } else {
 1970     return 2 * NativeInstruction::instruction_size;
 1971   }
 1972 }
 1973 
 1974 //=============================================================================
 1975 
 1976 #ifndef PRODUCT
 1977 void MachUEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 1978 {
 1979   st-&gt;print_cr(&quot;# MachUEPNode&quot;);
 1980   if (UseCompressedClassPointers) {
 1981     st-&gt;print_cr(&quot;\tldrw rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1982     if (CompressedKlassPointers::shift() != 0) {
 1983       st-&gt;print_cr(&quot;\tdecode_klass_not_null rscratch1, rscratch1&quot;);
 1984     }
 1985   } else {
 1986    st-&gt;print_cr(&quot;\tldr rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1987   }
 1988   st-&gt;print_cr(&quot;\tcmp r0, rscratch1\t # Inline cache check&quot;);
 1989   st-&gt;print_cr(&quot;\tbne, SharedRuntime::_ic_miss_stub&quot;);
 1990 }
 1991 #endif
 1992 
 1993 void MachUEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 1994 {
 1995   // This is the unverified entry point.
 1996   C2_MacroAssembler _masm(&amp;cbuf);
 1997 
 1998   __ cmp_klass(j_rarg0, rscratch2, rscratch1);
 1999   Label skip;
 2000   // TODO
 2001   // can we avoid this skip and still use a reloc?
 2002   __ br(Assembler::EQ, skip);
 2003   __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 2004   __ bind(skip);
 2005 }
 2006 
 2007 uint MachUEPNode::size(PhaseRegAlloc* ra_) const
 2008 {
 2009   return MachNode::size(ra_);
 2010 }
 2011 
 2012 // REQUIRED EMIT CODE
 2013 
 2014 //=============================================================================
 2015 
 2016 // Emit exception handler code.
 2017 int HandlerImpl::emit_exception_handler(CodeBuffer&amp; cbuf)
 2018 {
 2019   // mov rscratch1 #exception_blob_entry_point
 2020   // br rscratch1
 2021   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2022   // That&#39;s why we must use the macroassembler to generate a handler.
 2023   C2_MacroAssembler _masm(&amp;cbuf);
 2024   address base = __ start_a_stub(size_exception_handler());
 2025   if (base == NULL) {
 2026     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2027     return 0;  // CodeBuffer::expand failed
 2028   }
 2029   int offset = __ offset();
 2030   __ far_jump(RuntimeAddress(OptoRuntime::exception_blob()-&gt;entry_point()));
 2031   assert(__ offset() - offset &lt;= (int) size_exception_handler(), &quot;overflow&quot;);
 2032   __ end_a_stub();
 2033   return offset;
 2034 }
 2035 
 2036 // Emit deopt handler code.
 2037 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf)
 2038 {
 2039   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2040   // That&#39;s why we must use the macroassembler to generate a handler.
 2041   C2_MacroAssembler _masm(&amp;cbuf);
 2042   address base = __ start_a_stub(size_deopt_handler());
 2043   if (base == NULL) {
 2044     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2045     return 0;  // CodeBuffer::expand failed
 2046   }
 2047   int offset = __ offset();
 2048 
 2049   __ adr(lr, __ pc());
 2050   __ far_jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 2051 
 2052   assert(__ offset() - offset &lt;= (int) size_deopt_handler(), &quot;overflow&quot;);
 2053   __ end_a_stub();
 2054   return offset;
 2055 }
 2056 
 2057 // REQUIRED MATCHER CODE
 2058 
 2059 //=============================================================================
 2060 
 2061 const bool Matcher::match_rule_supported(int opcode) {
 2062   if (!has_match_rule(opcode))
 2063     return false;
 2064 
 2065   bool ret_value = true;
 2066   switch (opcode) {
 2067     case Op_CacheWB:
 2068     case Op_CacheWBPreSync:
 2069     case Op_CacheWBPostSync:
 2070       if (!VM_Version::supports_data_cache_line_flush()) {
 2071         ret_value = false;
 2072       }
 2073       break;
 2074   }
 2075 
 2076   return ret_value; // Per default match rules are supported.
 2077 }
 2078 
 2079 // Identify extra cases that we might want to provide match rules for vector nodes and
 2080 // other intrinsics guarded with vector length (vlen) and element type (bt).
 2081 const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {
 2082   if (!match_rule_supported(opcode)) {
 2083     return false;
 2084   }
 2085 
 2086   // Special cases which require vector length
 2087   switch (opcode) {
 2088     case Op_MulAddVS2VI: {
 2089       if (vlen != 4) {
 2090         return false;
 2091       }
 2092       break;
 2093     }
 2094   }
 2095 
 2096   return true; // Per default match rules are supported.
 2097 }
 2098 
 2099 const bool Matcher::has_predicated_vectors(void) {
 2100   return false;
 2101 }
 2102 
 2103 const int Matcher::float_pressure(int default_pressure_threshold) {
 2104   return default_pressure_threshold;
 2105 }
 2106 
 2107 int Matcher::regnum_to_fpu_offset(int regnum)
 2108 {
 2109   Unimplemented();
 2110   return 0;
 2111 }
 2112 
 2113 // Is this branch offset short enough that a short branch can be used?
 2114 //
 2115 // NOTE: If the platform does not provide any short branch variants, then
 2116 //       this method should return false for offset 0.
 2117 bool Matcher::is_short_branch_offset(int rule, int br_size, int offset) {
 2118   // The passed offset is relative to address of the branch.
 2119 
 2120   return (-32768 &lt;= offset &amp;&amp; offset &lt; 32768);
 2121 }
 2122 
 2123 const bool Matcher::isSimpleConstant64(jlong value) {
 2124   // Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.
 2125   // Probably always true, even if a temp register is required.
 2126   return true;
 2127 }
 2128 
 2129 // true just means we have fast l2f conversion
 2130 const bool Matcher::convL2FSupported(void) {
 2131   return true;
 2132 }
 2133 
 2134 // Vector width in bytes.
 2135 const int Matcher::vector_width_in_bytes(BasicType bt) {
 2136   int size = MIN2(16,(int)MaxVectorSize);
 2137   // Minimum 2 values in vector
 2138   if (size &lt; 2*type2aelembytes(bt)) size = 0;
 2139   // But never &lt; 4
 2140   if (size &lt; 4) size = 0;
 2141   return size;
 2142 }
 2143 
 2144 // Limits on vector size (number of elements) loaded into vector.
 2145 const int Matcher::max_vector_size(const BasicType bt) {
 2146   return vector_width_in_bytes(bt)/type2aelembytes(bt);
 2147 }
 2148 const int Matcher::min_vector_size(const BasicType bt) {
 2149 //  For the moment limit the vector size to 8 bytes
 2150     int size = 8 / type2aelembytes(bt);
 2151     if (size &lt; 2) size = 2;
 2152     return size;
 2153 }
 2154 
 2155 // Vector ideal reg.
 2156 const uint Matcher::vector_ideal_reg(int len) {
 2157   switch(len) {
 2158     case  8: return Op_VecD;
 2159     case 16: return Op_VecX;
 2160   }
 2161   ShouldNotReachHere();
 2162   return 0;
 2163 }
 2164 
 2165 // AES support not yet implemented
 2166 const bool Matcher::pass_original_key_for_aes() {
 2167   return false;
 2168 }
 2169 
 2170 // aarch64 supports misaligned vectors store/load.
 2171 const bool Matcher::misaligned_vectors_ok() {
 2172   return true;
 2173 }
 2174 
 2175 // false =&gt; size gets scaled to BytesPerLong, ok.
 2176 const bool Matcher::init_array_count_is_in_bytes = false;
 2177 
 2178 // Use conditional move (CMOVL)
 2179 const int Matcher::long_cmove_cost() {
 2180   // long cmoves are no more expensive than int cmoves
 2181   return 0;
 2182 }
 2183 
 2184 const int Matcher::float_cmove_cost() {
 2185   // float cmoves are no more expensive than int cmoves
 2186   return 0;
 2187 }
 2188 
 2189 // Does the CPU require late expand (see block.cpp for description of late expand)?
 2190 const bool Matcher::require_postalloc_expand = false;
 2191 
 2192 // Do we need to mask the count passed to shift instructions or does
 2193 // the cpu only look at the lower 5/6 bits anyway?
 2194 const bool Matcher::need_masked_shift_count = false;
 2195 
 2196 // No support for generic vector operands.
 2197 const bool Matcher::supports_generic_vector_operands  = false;
 2198 
 2199 MachOper* Matcher::pd_specialize_generic_vector_operand(MachOper* original_opnd, uint ideal_reg, bool is_temp) {
 2200   ShouldNotReachHere(); // generic vector operands not supported
 2201   return NULL;
 2202 }
 2203 
 2204 bool Matcher::is_generic_reg2reg_move(MachNode* m) {
 2205   ShouldNotReachHere();  // generic vector operands not supported
 2206   return false;
 2207 }
 2208 
 2209 bool Matcher::is_generic_vector(MachOper* opnd)  {
 2210   ShouldNotReachHere();  // generic vector operands not supported
 2211   return false;
 2212 }
 2213 
 2214 // This affects two different things:
 2215 //  - how Decode nodes are matched
 2216 //  - how ImplicitNullCheck opportunities are recognized
 2217 // If true, the matcher will try to remove all Decodes and match them
 2218 // (as operands) into nodes. NullChecks are not prepared to deal with
 2219 // Decodes by final_graph_reshaping().
 2220 // If false, final_graph_reshaping() forces the decode behind the Cmp
 2221 // for a NullCheck. The matcher matches the Decode node into a register.
 2222 // Implicit_null_check optimization moves the Decode along with the
 2223 // memory operation back up before the NullCheck.
 2224 bool Matcher::narrow_oop_use_complex_address() {
 2225   return CompressedOops::shift() == 0;
 2226 }
 2227 
 2228 bool Matcher::narrow_klass_use_complex_address() {
 2229 // TODO
 2230 // decide whether we need to set this to true
 2231   return false;
 2232 }
 2233 
 2234 bool Matcher::const_oop_prefer_decode() {
 2235   // Prefer ConN+DecodeN over ConP in simple compressed oops mode.
 2236   return CompressedOops::base() == NULL;
 2237 }
 2238 
 2239 bool Matcher::const_klass_prefer_decode() {
 2240   // Prefer ConNKlass+DecodeNKlass over ConP in simple compressed klass mode.
 2241   return CompressedKlassPointers::base() == NULL;
 2242 }
 2243 
 2244 // Is it better to copy float constants, or load them directly from
 2245 // memory?  Intel can load a float constant from a direct address,
 2246 // requiring no extra registers.  Most RISCs will have to materialize
 2247 // an address into a register first, so they would do better to copy
 2248 // the constant from stack.
 2249 const bool Matcher::rematerialize_float_constants = false;
 2250 
 2251 // If CPU can load and store mis-aligned doubles directly then no
 2252 // fixup is needed.  Else we split the double into 2 integer pieces
 2253 // and move it piece-by-piece.  Only happens when passing doubles into
 2254 // C code as the Java calling convention forces doubles to be aligned.
 2255 const bool Matcher::misaligned_doubles_ok = true;
 2256 
 2257 // No-op on amd64
 2258 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 2259   Unimplemented();
 2260 }
 2261 
 2262 // Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.
 2263 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 2264 
 2265 // Are floats converted to double when stored to stack during
 2266 // deoptimization?
 2267 bool Matcher::float_in_double() { return false; }
 2268 
 2269 // Do ints take an entire long register or just half?
 2270 // The relevant question is how the int is callee-saved:
 2271 // the whole long is written but de-opt&#39;ing will have to extract
 2272 // the relevant 32 bits.
 2273 const bool Matcher::int_in_long = true;
 2274 
 2275 // Return whether or not this register is ever used as an argument.
 2276 // This function is used on startup to build the trampoline stubs in
 2277 // generateOptoStub.  Registers not mentioned will be killed by the VM
 2278 // call in the trampoline, and arguments in those registers not be
 2279 // available to the callee.
 2280 bool Matcher::can_be_java_arg(int reg)
 2281 {
 2282   return
 2283     reg ==  R0_num || reg == R0_H_num ||
 2284     reg ==  R1_num || reg == R1_H_num ||
 2285     reg ==  R2_num || reg == R2_H_num ||
 2286     reg ==  R3_num || reg == R3_H_num ||
 2287     reg ==  R4_num || reg == R4_H_num ||
 2288     reg ==  R5_num || reg == R5_H_num ||
 2289     reg ==  R6_num || reg == R6_H_num ||
 2290     reg ==  R7_num || reg == R7_H_num ||
 2291     reg ==  V0_num || reg == V0_H_num ||
 2292     reg ==  V1_num || reg == V1_H_num ||
 2293     reg ==  V2_num || reg == V2_H_num ||
 2294     reg ==  V3_num || reg == V3_H_num ||
 2295     reg ==  V4_num || reg == V4_H_num ||
 2296     reg ==  V5_num || reg == V5_H_num ||
 2297     reg ==  V6_num || reg == V6_H_num ||
 2298     reg ==  V7_num || reg == V7_H_num;
 2299 }
 2300 
 2301 bool Matcher::is_spillable_arg(int reg)
 2302 {
 2303   return can_be_java_arg(reg);
 2304 }
 2305 
 2306 bool Matcher::use_asm_for_ldiv_by_con(jlong divisor) {
 2307   return false;
 2308 }
 2309 
 2310 RegMask Matcher::divI_proj_mask() {
 2311   ShouldNotReachHere();
 2312   return RegMask();
 2313 }
 2314 
 2315 // Register for MODI projection of divmodI.
 2316 RegMask Matcher::modI_proj_mask() {
 2317   ShouldNotReachHere();
 2318   return RegMask();
 2319 }
 2320 
 2321 // Register for DIVL projection of divmodL.
 2322 RegMask Matcher::divL_proj_mask() {
 2323   ShouldNotReachHere();
 2324   return RegMask();
 2325 }
 2326 
 2327 // Register for MODL projection of divmodL.
 2328 RegMask Matcher::modL_proj_mask() {
 2329   ShouldNotReachHere();
 2330   return RegMask();
 2331 }
 2332 
 2333 const RegMask Matcher::method_handle_invoke_SP_save_mask() {
 2334   return FP_REG_mask();
 2335 }
 2336 
 2337 bool size_fits_all_mem_uses(AddPNode* addp, int shift) {
 2338   for (DUIterator_Fast imax, i = addp-&gt;fast_outs(imax); i &lt; imax; i++) {
 2339     Node* u = addp-&gt;fast_out(i);
 2340     if (u-&gt;is_Mem()) {
 2341       int opsize = u-&gt;as_Mem()-&gt;memory_size();
 2342       assert(opsize &gt; 0, &quot;unexpected memory operand size&quot;);
 2343       if (u-&gt;as_Mem()-&gt;memory_size() != (1&lt;&lt;shift)) {
 2344         return false;
 2345       }
 2346     }
 2347   }
 2348   return true;
 2349 }
 2350 
 2351 const bool Matcher::convi2l_type_required = false;
 2352 
 2353 // Should the matcher clone input &#39;m&#39; of node &#39;n&#39;?
 2354 bool Matcher::pd_clone_node(Node* n, Node* m, Matcher::MStack&amp; mstack) {
 2355   if (is_vshift_con_pattern(n, m)) { // ShiftV src (ShiftCntV con)
 2356     mstack.push(m, Visit);           // m = ShiftCntV
 2357     return true;
 2358   }
 2359   return false;
 2360 }
 2361 
 2362 // Should the Matcher clone shifts on addressing modes, expecting them
 2363 // to be subsumed into complex addressing expressions or compute them
 2364 // into registers?
 2365 bool Matcher::pd_clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
 2366   if (clone_base_plus_offset_address(m, mstack, address_visited)) {
 2367     return true;
 2368   }
 2369 
 2370   Node *off = m-&gt;in(AddPNode::Offset);
 2371   if (off-&gt;Opcode() == Op_LShiftL &amp;&amp; off-&gt;in(2)-&gt;is_Con() &amp;&amp;
 2372       size_fits_all_mem_uses(m, off-&gt;in(2)-&gt;get_int()) &amp;&amp;
 2373       // Are there other uses besides address expressions?
 2374       !is_visited(off)) {
 2375     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2376     mstack.push(off-&gt;in(2), Visit);
 2377     Node *conv = off-&gt;in(1);
 2378     if (conv-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2379         // Are there other uses besides address expressions?
 2380         !is_visited(conv)) {
 2381       address_visited.set(conv-&gt;_idx); // Flag as address_visited
 2382       mstack.push(conv-&gt;in(1), Pre_Visit);
 2383     } else {
 2384       mstack.push(conv, Pre_Visit);
 2385     }
 2386     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2387     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2388     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2389     return true;
 2390   } else if (off-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2391              // Are there other uses besides address expressions?
 2392              !is_visited(off)) {
 2393     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2394     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2395     mstack.push(off-&gt;in(1), Pre_Visit);
 2396     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2397     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2398     return true;
 2399   }
 2400   return false;
 2401 }
 2402 
 2403 void Compile::reshape_address(AddPNode* addp) {
 2404 }
 2405 
 2406 
 2407 #define MOV_VOLATILE(REG, BASE, INDEX, SCALE, DISP, SCRATCH, INSN)      \
 2408   C2_MacroAssembler _masm(&amp;cbuf);                                       \
 2409   {                                                                     \
 2410     guarantee(INDEX == -1, &quot;mode not permitted for volatile&quot;);          \
 2411     guarantee(DISP == 0, &quot;mode not permitted for volatile&quot;);            \
 2412     guarantee(SCALE == 0, &quot;mode not permitted for volatile&quot;);           \
 2413     __ INSN(REG, as_Register(BASE));                                    \
 2414   }
 2415 
 2416 
 2417 static Address mem2address(int opcode, Register base, int index, int size, int disp)
 2418   {
 2419     Address::extend scale;
 2420 
 2421     // Hooboy, this is fugly.  We need a way to communicate to the
 2422     // encoder that the index needs to be sign extended, so we have to
 2423     // enumerate all the cases.
 2424     switch (opcode) {
 2425     case INDINDEXSCALEDI2L:
 2426     case INDINDEXSCALEDI2LN:
 2427     case INDINDEXI2L:
 2428     case INDINDEXI2LN:
 2429       scale = Address::sxtw(size);
 2430       break;
 2431     default:
 2432       scale = Address::lsl(size);
 2433     }
 2434 
 2435     if (index == -1) {
 2436       return Address(base, disp);
 2437     } else {
 2438       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2439       return Address(base, as_Register(index), scale);
 2440     }
 2441   }
 2442 
 2443 
 2444 typedef void (MacroAssembler::* mem_insn)(Register Rt, const Address &amp;adr);
 2445 typedef void (MacroAssembler::* mem_insn2)(Register Rt, Register adr);
 2446 typedef void (MacroAssembler::* mem_float_insn)(FloatRegister Rt, const Address &amp;adr);
 2447 typedef void (MacroAssembler::* mem_vector_insn)(FloatRegister Rt,
 2448                                   MacroAssembler::SIMD_RegVariant T, const Address &amp;adr);
 2449 
 2450   // Used for all non-volatile memory accesses.  The use of
 2451   // $mem-&gt;opcode() to discover whether this pattern uses sign-extended
 2452   // offsets is something of a kludge.
 2453   static void loadStore(C2_MacroAssembler masm, mem_insn insn,
 2454                         Register reg, int opcode,
 2455                         Register base, int index, int scale, int disp,
 2456                         int size_in_memory)
 2457   {
 2458     Address addr = mem2address(opcode, base, index, scale, disp);
 2459     if (addr.getMode() == Address::base_plus_offset) {
 2460       /* If we get an out-of-range offset it is a bug in the compiler,
 2461          so we assert here. */
 2462       assert(Address::offset_ok_for_immed(addr.offset(), exact_log2(size_in_memory)),
 2463              &quot;c2 compiler bug&quot;);
 2464       /* Fix up any out-of-range offsets. */
 2465       assert_different_registers(rscratch1, base);
 2466       assert_different_registers(rscratch1, reg);
 2467       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2468     }
 2469     (masm.*insn)(reg, addr);
 2470   }
 2471 
 2472   static void loadStore(C2_MacroAssembler masm, mem_float_insn insn,
 2473                         FloatRegister reg, int opcode,
 2474                         Register base, int index, int size, int disp,
 2475                         int size_in_memory)
 2476   {
 2477     Address::extend scale;
 2478 
 2479     switch (opcode) {
 2480     case INDINDEXSCALEDI2L:
 2481     case INDINDEXSCALEDI2LN:
 2482       scale = Address::sxtw(size);
 2483       break;
 2484     default:
 2485       scale = Address::lsl(size);
 2486     }
 2487 
 2488     if (index == -1) {
 2489       /* If we get an out-of-range offset it is a bug in the compiler,
 2490          so we assert here. */
 2491       assert(Address::offset_ok_for_immed(disp, exact_log2(size_in_memory)), &quot;c2 compiler bug&quot;);
 2492       /* Fix up any out-of-range offsets. */
 2493       assert_different_registers(rscratch1, base);
 2494       Address addr = Address(base, disp);
 2495       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2496       (masm.*insn)(reg, addr);
 2497     } else {
 2498       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2499       (masm.*insn)(reg, Address(base, as_Register(index), scale));
 2500     }
 2501   }
 2502 
 2503   static void loadStore(C2_MacroAssembler masm, mem_vector_insn insn,
 2504                         FloatRegister reg, MacroAssembler::SIMD_RegVariant T,
 2505                         int opcode, Register base, int index, int size, int disp)
 2506   {
 2507     if (index == -1) {
 2508       (masm.*insn)(reg, T, Address(base, disp));
 2509     } else {
 2510       assert(disp == 0, &quot;unsupported address mode&quot;);
 2511       (masm.*insn)(reg, T, Address(base, as_Register(index), Address::lsl(size)));
 2512     }
 2513   }
 2514 
 2515 %}
 2516 
 2517 
 2518 
 2519 //----------ENCODING BLOCK-----------------------------------------------------
 2520 // This block specifies the encoding classes used by the compiler to
 2521 // output byte streams.  Encoding classes are parameterized macros
 2522 // used by Machine Instruction Nodes in order to generate the bit
 2523 // encoding of the instruction.  Operands specify their base encoding
 2524 // interface with the interface keyword.  There are currently
 2525 // supported four interfaces, REG_INTER, CONST_INTER, MEMORY_INTER, &amp;
 2526 // COND_INTER.  REG_INTER causes an operand to generate a function
 2527 // which returns its register number when queried.  CONST_INTER causes
 2528 // an operand to generate a function which returns the value of the
 2529 // constant when queried.  MEMORY_INTER causes an operand to generate
 2530 // four functions which return the Base Register, the Index Register,
 2531 // the Scale Value, and the Offset Value of the operand when queried.
 2532 // COND_INTER causes an operand to generate six functions which return
 2533 // the encoding code (ie - encoding bits for the instruction)
 2534 // associated with each basic boolean condition for a conditional
 2535 // instruction.
 2536 //
 2537 // Instructions specify two basic values for encoding.  Again, a
 2538 // function is available to check if the constant displacement is an
 2539 // oop. They use the ins_encode keyword to specify their encoding
 2540 // classes (which must be a sequence of enc_class names, and their
 2541 // parameters, specified in the encoding block), and they use the
 2542 // opcode keyword to specify, in order, their primary, secondary, and
 2543 // tertiary opcode.  Only the opcode sections which a particular
 2544 // instruction needs for encoding need to be specified.
 2545 encode %{
 2546   // Build emit functions for each basic byte or larger field in the
 2547   // intel encoding scheme (opcode, rm, sib, immediate), and call them
 2548   // from C++ code in the enc_class source block.  Emit functions will
 2549   // live in the main source block for now.  In future, we can
 2550   // generalize this by adding a syntax that specifies the sizes of
 2551   // fields in an order, so that the adlc can build the emit functions
 2552   // automagically
 2553 
 2554   // catch all for unimplemented encodings
 2555   enc_class enc_unimplemented %{
 2556     C2_MacroAssembler _masm(&amp;cbuf);
 2557     __ unimplemented(&quot;C2 catch all&quot;);
 2558   %}
 2559 
 2560   // BEGIN Non-volatile memory access
 2561 
 2562   // This encoding class is generated automatically from ad_encode.m4.
 2563   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2564   enc_class aarch64_enc_ldrsbw(iRegI dst, memory1 mem) %{
 2565     Register dst_reg = as_Register($dst$$reg);
 2566     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsbw, dst_reg, $mem-&gt;opcode(),
 2567                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2568   %}
 2569 
 2570   // This encoding class is generated automatically from ad_encode.m4.
 2571   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2572   enc_class aarch64_enc_ldrsb(iRegI dst, memory1 mem) %{
 2573     Register dst_reg = as_Register($dst$$reg);
 2574     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsb, dst_reg, $mem-&gt;opcode(),
 2575                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2576   %}
 2577 
 2578   // This encoding class is generated automatically from ad_encode.m4.
 2579   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2580   enc_class aarch64_enc_ldrb(iRegI dst, memory1 mem) %{
 2581     Register dst_reg = as_Register($dst$$reg);
 2582     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2583                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2584   %}
 2585 
 2586   // This encoding class is generated automatically from ad_encode.m4.
 2587   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2588   enc_class aarch64_enc_ldrb(iRegL dst, memory1 mem) %{
 2589     Register dst_reg = as_Register($dst$$reg);
 2590     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2591                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2592   %}
 2593 
 2594   // This encoding class is generated automatically from ad_encode.m4.
 2595   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2596   enc_class aarch64_enc_ldrshw(iRegI dst, memory2 mem) %{
 2597     Register dst_reg = as_Register($dst$$reg);
 2598     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrshw, dst_reg, $mem-&gt;opcode(),
 2599                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2600   %}
 2601 
 2602   // This encoding class is generated automatically from ad_encode.m4.
 2603   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2604   enc_class aarch64_enc_ldrsh(iRegI dst, memory2 mem) %{
 2605     Register dst_reg = as_Register($dst$$reg);
 2606     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsh, dst_reg, $mem-&gt;opcode(),
 2607                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2608   %}
 2609 
 2610   // This encoding class is generated automatically from ad_encode.m4.
 2611   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2612   enc_class aarch64_enc_ldrh(iRegI dst, memory2 mem) %{
 2613     Register dst_reg = as_Register($dst$$reg);
 2614     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2615                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2616   %}
 2617 
 2618   // This encoding class is generated automatically from ad_encode.m4.
 2619   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2620   enc_class aarch64_enc_ldrh(iRegL dst, memory2 mem) %{
 2621     Register dst_reg = as_Register($dst$$reg);
 2622     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2623                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2624   %}
 2625 
 2626   // This encoding class is generated automatically from ad_encode.m4.
 2627   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2628   enc_class aarch64_enc_ldrw(iRegI dst, memory4 mem) %{
 2629     Register dst_reg = as_Register($dst$$reg);
 2630     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2631                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2632   %}
 2633 
 2634   // This encoding class is generated automatically from ad_encode.m4.
 2635   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2636   enc_class aarch64_enc_ldrw(iRegL dst, memory4 mem) %{
 2637     Register dst_reg = as_Register($dst$$reg);
 2638     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2639                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2640   %}
 2641 
 2642   // This encoding class is generated automatically from ad_encode.m4.
 2643   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2644   enc_class aarch64_enc_ldrsw(iRegL dst, memory4 mem) %{
 2645     Register dst_reg = as_Register($dst$$reg);
 2646     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsw, dst_reg, $mem-&gt;opcode(),
 2647                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2648   %}
 2649 
 2650   // This encoding class is generated automatically from ad_encode.m4.
 2651   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2652   enc_class aarch64_enc_ldr(iRegL dst, memory8 mem) %{
 2653     Register dst_reg = as_Register($dst$$reg);
 2654     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, $mem-&gt;opcode(),
 2655                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2656   %}
 2657 
 2658   // This encoding class is generated automatically from ad_encode.m4.
 2659   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2660   enc_class aarch64_enc_ldrs(vRegF dst, memory4 mem) %{
 2661     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2662     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, dst_reg, $mem-&gt;opcode(),
 2663                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2664   %}
 2665 
 2666   // This encoding class is generated automatically from ad_encode.m4.
 2667   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2668   enc_class aarch64_enc_ldrd(vRegD dst, memory8 mem) %{
 2669     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2670     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, dst_reg, $mem-&gt;opcode(),
 2671                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2672   %}
 2673 
 2674   // This encoding class is generated automatically from ad_encode.m4.
 2675   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2676   enc_class aarch64_enc_strb(iRegI src, memory1 mem) %{
 2677     Register src_reg = as_Register($src$$reg);
 2678     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strb, src_reg, $mem-&gt;opcode(),
 2679                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2680   %}
 2681 
 2682   // This encoding class is generated automatically from ad_encode.m4.
 2683   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2684   enc_class aarch64_enc_strb0(memory1 mem) %{
 2685     C2_MacroAssembler _masm(&amp;cbuf);
 2686     loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2687                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2688   %}
 2689 
 2690   // This encoding class is generated automatically from ad_encode.m4.
 2691   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2692   enc_class aarch64_enc_strh(iRegI src, memory2 mem) %{
 2693     Register src_reg = as_Register($src$$reg);
 2694     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strh, src_reg, $mem-&gt;opcode(),
 2695                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2696   %}
 2697 
 2698   // This encoding class is generated automatically from ad_encode.m4.
 2699   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2700   enc_class aarch64_enc_strh0(memory2 mem) %{
 2701     C2_MacroAssembler _masm(&amp;cbuf);
 2702     loadStore(_masm, &amp;MacroAssembler::strh, zr, $mem-&gt;opcode(),
 2703                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2704   %}
 2705 
 2706   // This encoding class is generated automatically from ad_encode.m4.
 2707   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2708   enc_class aarch64_enc_strw(iRegI src, memory4 mem) %{
 2709     Register src_reg = as_Register($src$$reg);
 2710     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strw, src_reg, $mem-&gt;opcode(),
 2711                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2712   %}
 2713 
 2714   // This encoding class is generated automatically from ad_encode.m4.
 2715   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2716   enc_class aarch64_enc_strw0(memory4 mem) %{
 2717     C2_MacroAssembler _masm(&amp;cbuf);
 2718     loadStore(_masm, &amp;MacroAssembler::strw, zr, $mem-&gt;opcode(),
 2719                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2720   %}
 2721 
 2722   // This encoding class is generated automatically from ad_encode.m4.
 2723   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2724   enc_class aarch64_enc_str(iRegL src, memory8 mem) %{
 2725     Register src_reg = as_Register($src$$reg);
 2726     // we sometimes get asked to store the stack pointer into the
 2727     // current thread -- we cannot do that directly on AArch64
 2728     if (src_reg == r31_sp) {
 2729       C2_MacroAssembler _masm(&amp;cbuf);
 2730       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2731       __ mov(rscratch2, sp);
 2732       src_reg = rscratch2;
 2733     }
 2734     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, $mem-&gt;opcode(),
 2735                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2736   %}
 2737 
 2738   // This encoding class is generated automatically from ad_encode.m4.
 2739   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2740   enc_class aarch64_enc_str0(memory8 mem) %{
 2741     C2_MacroAssembler _masm(&amp;cbuf);
 2742     loadStore(_masm, &amp;MacroAssembler::str, zr, $mem-&gt;opcode(),
 2743                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2744   %}
 2745 
 2746   // This encoding class is generated automatically from ad_encode.m4.
 2747   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2748   enc_class aarch64_enc_strs(vRegF src, memory4 mem) %{
 2749     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2750     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strs, src_reg, $mem-&gt;opcode(),
 2751                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2752   %}
 2753 
 2754   // This encoding class is generated automatically from ad_encode.m4.
 2755   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2756   enc_class aarch64_enc_strd(vRegD src, memory8 mem) %{
 2757     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2758     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strd, src_reg, $mem-&gt;opcode(),
 2759                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2760   %}
 2761 
 2762   // This encoding class is generated automatically from ad_encode.m4.
 2763   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2764   enc_class aarch64_enc_strw_immn(immN src, memory1 mem) %{
 2765     C2_MacroAssembler _masm(&amp;cbuf);
 2766     address con = (address)$src$$constant;
 2767     // need to do this the hard way until we can manage relocs
 2768     // for 32 bit constants
 2769     __ movoop(rscratch2, (jobject)con);
 2770     if (con) __ encode_heap_oop_not_null(rscratch2);
 2771     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2772                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2773   %}
 2774 
 2775   // This encoding class is generated automatically from ad_encode.m4.
 2776   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2777   enc_class aarch64_enc_strw_immnk(immN src, memory4 mem) %{
 2778     C2_MacroAssembler _masm(&amp;cbuf);
 2779     address con = (address)$src$$constant;
 2780     // need to do this the hard way until we can manage relocs
 2781     // for 32 bit constants
 2782     __ movoop(rscratch2, (jobject)con);
 2783     __ encode_klass_not_null(rscratch2);
 2784     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2785                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2786   %}
 2787 
 2788   // This encoding class is generated automatically from ad_encode.m4.
 2789   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2790   enc_class aarch64_enc_strb0_ordered(memory4 mem) %{
 2791       C2_MacroAssembler _masm(&amp;cbuf);
 2792       __ membar(Assembler::StoreStore);
 2793       loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2794                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2795   %}
 2796 
 2797   // END Non-volatile memory access
 2798 
 2799   // Vector loads and stores
 2800   enc_class aarch64_enc_ldrvS(vecD dst, memory mem) %{
 2801     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2802     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::S,
 2803        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2804   %}
 2805 
 2806   enc_class aarch64_enc_ldrvD(vecD dst, memory mem) %{
 2807     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2808     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::D,
 2809        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2810   %}
 2811 
 2812   enc_class aarch64_enc_ldrvQ(vecX dst, memory mem) %{
 2813     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2814     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::Q,
 2815        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2816   %}
 2817 
 2818   enc_class aarch64_enc_strvS(vecD src, memory mem) %{
 2819     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2820     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::S,
 2821        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2822   %}
 2823 
 2824   enc_class aarch64_enc_strvD(vecD src, memory mem) %{
 2825     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2826     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::D,
 2827        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2828   %}
 2829 
 2830   enc_class aarch64_enc_strvQ(vecX src, memory mem) %{
 2831     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2832     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::Q,
 2833        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2834   %}
 2835 
 2836   // volatile loads and stores
 2837 
 2838   enc_class aarch64_enc_stlrb(iRegI src, memory mem) %{
 2839     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2840                  rscratch1, stlrb);
 2841   %}
 2842 
 2843   enc_class aarch64_enc_stlrh(iRegI src, memory mem) %{
 2844     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2845                  rscratch1, stlrh);
 2846   %}
 2847 
 2848   enc_class aarch64_enc_stlrw(iRegI src, memory mem) %{
 2849     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2850                  rscratch1, stlrw);
 2851   %}
 2852 
 2853 
 2854   enc_class aarch64_enc_ldarsbw(iRegI dst, memory mem) %{
 2855     Register dst_reg = as_Register($dst$$reg);
 2856     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2857              rscratch1, ldarb);
 2858     __ sxtbw(dst_reg, dst_reg);
 2859   %}
 2860 
 2861   enc_class aarch64_enc_ldarsb(iRegL dst, memory mem) %{
 2862     Register dst_reg = as_Register($dst$$reg);
 2863     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2864              rscratch1, ldarb);
 2865     __ sxtb(dst_reg, dst_reg);
 2866   %}
 2867 
 2868   enc_class aarch64_enc_ldarbw(iRegI dst, memory mem) %{
 2869     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2870              rscratch1, ldarb);
 2871   %}
 2872 
 2873   enc_class aarch64_enc_ldarb(iRegL dst, memory mem) %{
 2874     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2875              rscratch1, ldarb);
 2876   %}
 2877 
 2878   enc_class aarch64_enc_ldarshw(iRegI dst, memory mem) %{
 2879     Register dst_reg = as_Register($dst$$reg);
 2880     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2881              rscratch1, ldarh);
 2882     __ sxthw(dst_reg, dst_reg);
 2883   %}
 2884 
 2885   enc_class aarch64_enc_ldarsh(iRegL dst, memory mem) %{
 2886     Register dst_reg = as_Register($dst$$reg);
 2887     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2888              rscratch1, ldarh);
 2889     __ sxth(dst_reg, dst_reg);
 2890   %}
 2891 
 2892   enc_class aarch64_enc_ldarhw(iRegI dst, memory mem) %{
 2893     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2894              rscratch1, ldarh);
 2895   %}
 2896 
 2897   enc_class aarch64_enc_ldarh(iRegL dst, memory mem) %{
 2898     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2899              rscratch1, ldarh);
 2900   %}
 2901 
 2902   enc_class aarch64_enc_ldarw(iRegI dst, memory mem) %{
 2903     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2904              rscratch1, ldarw);
 2905   %}
 2906 
 2907   enc_class aarch64_enc_ldarw(iRegL dst, memory mem) %{
 2908     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2909              rscratch1, ldarw);
 2910   %}
 2911 
 2912   enc_class aarch64_enc_ldar(iRegL dst, memory mem) %{
 2913     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2914              rscratch1, ldar);
 2915   %}
 2916 
 2917   enc_class aarch64_enc_fldars(vRegF dst, memory mem) %{
 2918     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2919              rscratch1, ldarw);
 2920     __ fmovs(as_FloatRegister($dst$$reg), rscratch1);
 2921   %}
 2922 
 2923   enc_class aarch64_enc_fldard(vRegD dst, memory mem) %{
 2924     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2925              rscratch1, ldar);
 2926     __ fmovd(as_FloatRegister($dst$$reg), rscratch1);
 2927   %}
 2928 
 2929   enc_class aarch64_enc_stlr(iRegL src, memory mem) %{
 2930     Register src_reg = as_Register($src$$reg);
 2931     // we sometimes get asked to store the stack pointer into the
 2932     // current thread -- we cannot do that directly on AArch64
 2933     if (src_reg == r31_sp) {
 2934       C2_MacroAssembler _masm(&amp;cbuf);
 2935       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2936       __ mov(rscratch2, sp);
 2937       src_reg = rscratch2;
 2938     }
 2939     MOV_VOLATILE(src_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2940                  rscratch1, stlr);
 2941   %}
 2942 
 2943   enc_class aarch64_enc_fstlrs(vRegF src, memory mem) %{
 2944     {
 2945       C2_MacroAssembler _masm(&amp;cbuf);
 2946       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2947       __ fmovs(rscratch2, src_reg);
 2948     }
 2949     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2950                  rscratch1, stlrw);
 2951   %}
 2952 
 2953   enc_class aarch64_enc_fstlrd(vRegD src, memory mem) %{
 2954     {
 2955       C2_MacroAssembler _masm(&amp;cbuf);
 2956       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2957       __ fmovd(rscratch2, src_reg);
 2958     }
 2959     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2960                  rscratch1, stlr);
 2961   %}
 2962 
 2963   // synchronized read/update encodings
 2964 
 2965   enc_class aarch64_enc_ldaxr(iRegL dst, memory8 mem) %{
 2966     C2_MacroAssembler _masm(&amp;cbuf);
 2967     Register dst_reg = as_Register($dst$$reg);
 2968     Register base = as_Register($mem$$base);
 2969     int index = $mem$$index;
 2970     int scale = $mem$$scale;
 2971     int disp = $mem$$disp;
 2972     if (index == -1) {
 2973        if (disp != 0) {
 2974         __ lea(rscratch1, Address(base, disp));
 2975         __ ldaxr(dst_reg, rscratch1);
 2976       } else {
 2977         // TODO
 2978         // should we ever get anything other than this case?
 2979         __ ldaxr(dst_reg, base);
 2980       }
 2981     } else {
 2982       Register index_reg = as_Register(index);
 2983       if (disp == 0) {
 2984         __ lea(rscratch1, Address(base, index_reg, Address::lsl(scale)));
 2985         __ ldaxr(dst_reg, rscratch1);
 2986       } else {
 2987         __ lea(rscratch1, Address(base, disp));
 2988         __ lea(rscratch1, Address(rscratch1, index_reg, Address::lsl(scale)));
 2989         __ ldaxr(dst_reg, rscratch1);
 2990       }
 2991     }
 2992   %}
 2993 
 2994   enc_class aarch64_enc_stlxr(iRegLNoSp src, memory8 mem) %{
 2995     C2_MacroAssembler _masm(&amp;cbuf);
 2996     Register src_reg = as_Register($src$$reg);
 2997     Register base = as_Register($mem$$base);
 2998     int index = $mem$$index;
 2999     int scale = $mem$$scale;
 3000     int disp = $mem$$disp;
 3001     if (index == -1) {
 3002        if (disp != 0) {
 3003         __ lea(rscratch2, Address(base, disp));
 3004         __ stlxr(rscratch1, src_reg, rscratch2);
 3005       } else {
 3006         // TODO
 3007         // should we ever get anything other than this case?
 3008         __ stlxr(rscratch1, src_reg, base);
 3009       }
 3010     } else {
 3011       Register index_reg = as_Register(index);
 3012       if (disp == 0) {
 3013         __ lea(rscratch2, Address(base, index_reg, Address::lsl(scale)));
 3014         __ stlxr(rscratch1, src_reg, rscratch2);
 3015       } else {
 3016         __ lea(rscratch2, Address(base, disp));
 3017         __ lea(rscratch2, Address(rscratch2, index_reg, Address::lsl(scale)));
 3018         __ stlxr(rscratch1, src_reg, rscratch2);
 3019       }
 3020     }
 3021     __ cmpw(rscratch1, zr);
 3022   %}
 3023 
 3024   enc_class aarch64_enc_cmpxchg(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3025     C2_MacroAssembler _masm(&amp;cbuf);
 3026     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3027     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3028                Assembler::xword, /*acquire*/ false, /*release*/ true,
 3029                /*weak*/ false, noreg);
 3030   %}
 3031 
 3032   enc_class aarch64_enc_cmpxchgw(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3033     C2_MacroAssembler _masm(&amp;cbuf);
 3034     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3035     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3036                Assembler::word, /*acquire*/ false, /*release*/ true,
 3037                /*weak*/ false, noreg);
 3038   %}
 3039 
 3040   enc_class aarch64_enc_cmpxchgs(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3041     C2_MacroAssembler _masm(&amp;cbuf);
 3042     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3043     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3044                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 3045                /*weak*/ false, noreg);
 3046   %}
 3047 
 3048   enc_class aarch64_enc_cmpxchgb(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3049     C2_MacroAssembler _masm(&amp;cbuf);
 3050     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3051     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3052                Assembler::byte, /*acquire*/ false, /*release*/ true,
 3053                /*weak*/ false, noreg);
 3054   %}
 3055 
 3056 
 3057   // The only difference between aarch64_enc_cmpxchg and
 3058   // aarch64_enc_cmpxchg_acq is that we use load-acquire in the
 3059   // CompareAndSwap sequence to serve as a barrier on acquiring a
 3060   // lock.
 3061   enc_class aarch64_enc_cmpxchg_acq(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3062     C2_MacroAssembler _masm(&amp;cbuf);
 3063     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3064     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3065                Assembler::xword, /*acquire*/ true, /*release*/ true,
 3066                /*weak*/ false, noreg);
 3067   %}
 3068 
 3069   enc_class aarch64_enc_cmpxchgw_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3070     C2_MacroAssembler _masm(&amp;cbuf);
 3071     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3072     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3073                Assembler::word, /*acquire*/ true, /*release*/ true,
 3074                /*weak*/ false, noreg);
 3075   %}
 3076 
 3077   enc_class aarch64_enc_cmpxchgs_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3078     C2_MacroAssembler _masm(&amp;cbuf);
 3079     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3080     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3081                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 3082                /*weak*/ false, noreg);
 3083   %}
 3084 
 3085   enc_class aarch64_enc_cmpxchgb_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3086     C2_MacroAssembler _masm(&amp;cbuf);
 3087     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3088     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3089                Assembler::byte, /*acquire*/ true, /*release*/ true,
 3090                /*weak*/ false, noreg);
 3091   %}
 3092 
 3093   // auxiliary used for CompareAndSwapX to set result register
 3094   enc_class aarch64_enc_cset_eq(iRegINoSp res) %{
 3095     C2_MacroAssembler _masm(&amp;cbuf);
 3096     Register res_reg = as_Register($res$$reg);
 3097     __ cset(res_reg, Assembler::EQ);
 3098   %}
 3099 
 3100   // prefetch encodings
 3101 
 3102   enc_class aarch64_enc_prefetchw(memory mem) %{
 3103     C2_MacroAssembler _masm(&amp;cbuf);
 3104     Register base = as_Register($mem$$base);
 3105     int index = $mem$$index;
 3106     int scale = $mem$$scale;
 3107     int disp = $mem$$disp;
 3108     if (index == -1) {
 3109       __ prfm(Address(base, disp), PSTL1KEEP);
 3110     } else {
 3111       Register index_reg = as_Register(index);
 3112       if (disp == 0) {
 3113         __ prfm(Address(base, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3114       } else {
 3115         __ lea(rscratch1, Address(base, disp));
 3116 	__ prfm(Address(rscratch1, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3117       }
 3118     }
 3119   %}
 3120 
 3121   /// mov envcodings
 3122 
 3123   enc_class aarch64_enc_movw_imm(iRegI dst, immI src) %{
 3124     C2_MacroAssembler _masm(&amp;cbuf);
 3125     uint32_t con = (uint32_t)$src$$constant;
 3126     Register dst_reg = as_Register($dst$$reg);
 3127     if (con == 0) {
 3128       __ movw(dst_reg, zr);
 3129     } else {
 3130       __ movw(dst_reg, con);
 3131     }
 3132   %}
 3133 
 3134   enc_class aarch64_enc_mov_imm(iRegL dst, immL src) %{
 3135     C2_MacroAssembler _masm(&amp;cbuf);
 3136     Register dst_reg = as_Register($dst$$reg);
 3137     uint64_t con = (uint64_t)$src$$constant;
 3138     if (con == 0) {
 3139       __ mov(dst_reg, zr);
 3140     } else {
 3141       __ mov(dst_reg, con);
 3142     }
 3143   %}
 3144 
 3145   enc_class aarch64_enc_mov_p(iRegP dst, immP src) %{
 3146     C2_MacroAssembler _masm(&amp;cbuf);
 3147     Register dst_reg = as_Register($dst$$reg);
 3148     address con = (address)$src$$constant;
 3149     if (con == NULL || con == (address)1) {
 3150       ShouldNotReachHere();
 3151     } else {
 3152       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3153       if (rtype == relocInfo::oop_type) {
 3154         __ movoop(dst_reg, (jobject)con, /*immediate*/true);
 3155       } else if (rtype == relocInfo::metadata_type) {
 3156         __ mov_metadata(dst_reg, (Metadata*)con);
 3157       } else {
 3158         assert(rtype == relocInfo::none, &quot;unexpected reloc type&quot;);
 3159         if (con &lt; (address)(uintptr_t)os::vm_page_size()) {
 3160           __ mov(dst_reg, con);
 3161         } else {
 3162           unsigned long offset;
 3163           __ adrp(dst_reg, con, offset);
 3164           __ add(dst_reg, dst_reg, offset);
 3165         }
 3166       }
 3167     }
 3168   %}
 3169 
 3170   enc_class aarch64_enc_mov_p0(iRegP dst, immP0 src) %{
 3171     C2_MacroAssembler _masm(&amp;cbuf);
 3172     Register dst_reg = as_Register($dst$$reg);
 3173     __ mov(dst_reg, zr);
 3174   %}
 3175 
 3176   enc_class aarch64_enc_mov_p1(iRegP dst, immP_1 src) %{
 3177     C2_MacroAssembler _masm(&amp;cbuf);
 3178     Register dst_reg = as_Register($dst$$reg);
 3179     __ mov(dst_reg, (uint64_t)1);
 3180   %}
 3181 
 3182   enc_class aarch64_enc_mov_byte_map_base(iRegP dst, immByteMapBase src) %{
 3183     C2_MacroAssembler _masm(&amp;cbuf);
 3184     __ load_byte_map_base($dst$$Register);
 3185   %}
 3186 
 3187   enc_class aarch64_enc_mov_n(iRegN dst, immN src) %{
 3188     C2_MacroAssembler _masm(&amp;cbuf);
 3189     Register dst_reg = as_Register($dst$$reg);
 3190     address con = (address)$src$$constant;
 3191     if (con == NULL) {
 3192       ShouldNotReachHere();
 3193     } else {
 3194       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3195       assert(rtype == relocInfo::oop_type, &quot;unexpected reloc type&quot;);
 3196       __ set_narrow_oop(dst_reg, (jobject)con);
 3197     }
 3198   %}
 3199 
 3200   enc_class aarch64_enc_mov_n0(iRegN dst, immN0 src) %{
 3201     C2_MacroAssembler _masm(&amp;cbuf);
 3202     Register dst_reg = as_Register($dst$$reg);
 3203     __ mov(dst_reg, zr);
 3204   %}
 3205 
 3206   enc_class aarch64_enc_mov_nk(iRegN dst, immNKlass src) %{
 3207     C2_MacroAssembler _masm(&amp;cbuf);
 3208     Register dst_reg = as_Register($dst$$reg);
 3209     address con = (address)$src$$constant;
 3210     if (con == NULL) {
 3211       ShouldNotReachHere();
 3212     } else {
 3213       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3214       assert(rtype == relocInfo::metadata_type, &quot;unexpected reloc type&quot;);
 3215       __ set_narrow_klass(dst_reg, (Klass *)con);
 3216     }
 3217   %}
 3218 
 3219   // arithmetic encodings
 3220 
 3221   enc_class aarch64_enc_addsubw_imm(iRegI dst, iRegI src1, immIAddSub src2) %{
 3222     C2_MacroAssembler _masm(&amp;cbuf);
 3223     Register dst_reg = as_Register($dst$$reg);
 3224     Register src_reg = as_Register($src1$$reg);
 3225     int32_t con = (int32_t)$src2$$constant;
 3226     // add has primary == 0, subtract has primary == 1
 3227     if ($primary) { con = -con; }
 3228     if (con &lt; 0) {
 3229       __ subw(dst_reg, src_reg, -con);
 3230     } else {
 3231       __ addw(dst_reg, src_reg, con);
 3232     }
 3233   %}
 3234 
 3235   enc_class aarch64_enc_addsub_imm(iRegL dst, iRegL src1, immLAddSub src2) %{
 3236     C2_MacroAssembler _masm(&amp;cbuf);
 3237     Register dst_reg = as_Register($dst$$reg);
 3238     Register src_reg = as_Register($src1$$reg);
 3239     int32_t con = (int32_t)$src2$$constant;
 3240     // add has primary == 0, subtract has primary == 1
 3241     if ($primary) { con = -con; }
 3242     if (con &lt; 0) {
 3243       __ sub(dst_reg, src_reg, -con);
 3244     } else {
 3245       __ add(dst_reg, src_reg, con);
 3246     }
 3247   %}
 3248 
 3249   enc_class aarch64_enc_divw(iRegI dst, iRegI src1, iRegI src2) %{
 3250     C2_MacroAssembler _masm(&amp;cbuf);
 3251    Register dst_reg = as_Register($dst$$reg);
 3252    Register src1_reg = as_Register($src1$$reg);
 3253    Register src2_reg = as_Register($src2$$reg);
 3254     __ corrected_idivl(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3255   %}
 3256 
 3257   enc_class aarch64_enc_div(iRegI dst, iRegI src1, iRegI src2) %{
 3258     C2_MacroAssembler _masm(&amp;cbuf);
 3259    Register dst_reg = as_Register($dst$$reg);
 3260    Register src1_reg = as_Register($src1$$reg);
 3261    Register src2_reg = as_Register($src2$$reg);
 3262     __ corrected_idivq(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3263   %}
 3264 
 3265   enc_class aarch64_enc_modw(iRegI dst, iRegI src1, iRegI src2) %{
 3266     C2_MacroAssembler _masm(&amp;cbuf);
 3267    Register dst_reg = as_Register($dst$$reg);
 3268    Register src1_reg = as_Register($src1$$reg);
 3269    Register src2_reg = as_Register($src2$$reg);
 3270     __ corrected_idivl(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3271   %}
 3272 
 3273   enc_class aarch64_enc_mod(iRegI dst, iRegI src1, iRegI src2) %{
 3274     C2_MacroAssembler _masm(&amp;cbuf);
 3275    Register dst_reg = as_Register($dst$$reg);
 3276    Register src1_reg = as_Register($src1$$reg);
 3277    Register src2_reg = as_Register($src2$$reg);
 3278     __ corrected_idivq(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3279   %}
 3280 
 3281   // compare instruction encodings
 3282 
 3283   enc_class aarch64_enc_cmpw(iRegI src1, iRegI src2) %{
 3284     C2_MacroAssembler _masm(&amp;cbuf);
 3285     Register reg1 = as_Register($src1$$reg);
 3286     Register reg2 = as_Register($src2$$reg);
 3287     __ cmpw(reg1, reg2);
 3288   %}
 3289 
 3290   enc_class aarch64_enc_cmpw_imm_addsub(iRegI src1, immIAddSub src2) %{
 3291     C2_MacroAssembler _masm(&amp;cbuf);
 3292     Register reg = as_Register($src1$$reg);
 3293     int32_t val = $src2$$constant;
 3294     if (val &gt;= 0) {
 3295       __ subsw(zr, reg, val);
 3296     } else {
 3297       __ addsw(zr, reg, -val);
 3298     }
 3299   %}
 3300 
 3301   enc_class aarch64_enc_cmpw_imm(iRegI src1, immI src2) %{
 3302     C2_MacroAssembler _masm(&amp;cbuf);
 3303     Register reg1 = as_Register($src1$$reg);
 3304     uint32_t val = (uint32_t)$src2$$constant;
 3305     __ movw(rscratch1, val);
 3306     __ cmpw(reg1, rscratch1);
 3307   %}
 3308 
 3309   enc_class aarch64_enc_cmp(iRegL src1, iRegL src2) %{
 3310     C2_MacroAssembler _masm(&amp;cbuf);
 3311     Register reg1 = as_Register($src1$$reg);
 3312     Register reg2 = as_Register($src2$$reg);
 3313     __ cmp(reg1, reg2);
 3314   %}
 3315 
 3316   enc_class aarch64_enc_cmp_imm_addsub(iRegL src1, immL12 src2) %{
 3317     C2_MacroAssembler _masm(&amp;cbuf);
 3318     Register reg = as_Register($src1$$reg);
 3319     int64_t val = $src2$$constant;
 3320     if (val &gt;= 0) {
 3321       __ subs(zr, reg, val);
 3322     } else if (val != -val) {
 3323       __ adds(zr, reg, -val);
 3324     } else {
 3325     // aargh, Long.MIN_VALUE is a special case
 3326       __ orr(rscratch1, zr, (uint64_t)val);
 3327       __ subs(zr, reg, rscratch1);
 3328     }
 3329   %}
 3330 
 3331   enc_class aarch64_enc_cmp_imm(iRegL src1, immL src2) %{
 3332     C2_MacroAssembler _masm(&amp;cbuf);
 3333     Register reg1 = as_Register($src1$$reg);
 3334     uint64_t val = (uint64_t)$src2$$constant;
 3335     __ mov(rscratch1, val);
 3336     __ cmp(reg1, rscratch1);
 3337   %}
 3338 
 3339   enc_class aarch64_enc_cmpp(iRegP src1, iRegP src2) %{
 3340     C2_MacroAssembler _masm(&amp;cbuf);
 3341     Register reg1 = as_Register($src1$$reg);
 3342     Register reg2 = as_Register($src2$$reg);
 3343     __ cmp(reg1, reg2);
 3344   %}
 3345 
 3346   enc_class aarch64_enc_cmpn(iRegN src1, iRegN src2) %{
 3347     C2_MacroAssembler _masm(&amp;cbuf);
 3348     Register reg1 = as_Register($src1$$reg);
 3349     Register reg2 = as_Register($src2$$reg);
 3350     __ cmpw(reg1, reg2);
 3351   %}
 3352 
 3353   enc_class aarch64_enc_testp(iRegP src) %{
 3354     C2_MacroAssembler _masm(&amp;cbuf);
 3355     Register reg = as_Register($src$$reg);
 3356     __ cmp(reg, zr);
 3357   %}
 3358 
 3359   enc_class aarch64_enc_testn(iRegN src) %{
 3360     C2_MacroAssembler _masm(&amp;cbuf);
 3361     Register reg = as_Register($src$$reg);
 3362     __ cmpw(reg, zr);
 3363   %}
 3364 
 3365   enc_class aarch64_enc_b(label lbl) %{
 3366     C2_MacroAssembler _masm(&amp;cbuf);
 3367     Label *L = $lbl$$label;
 3368     __ b(*L);
 3369   %}
 3370 
 3371   enc_class aarch64_enc_br_con(cmpOp cmp, label lbl) %{
 3372     C2_MacroAssembler _masm(&amp;cbuf);
 3373     Label *L = $lbl$$label;
 3374     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3375   %}
 3376 
 3377   enc_class aarch64_enc_br_conU(cmpOpU cmp, label lbl) %{
 3378     C2_MacroAssembler _masm(&amp;cbuf);
 3379     Label *L = $lbl$$label;
 3380     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3381   %}
 3382 
 3383   enc_class aarch64_enc_partial_subtype_check(iRegP sub, iRegP super, iRegP temp, iRegP result)
 3384   %{
 3385      Register sub_reg = as_Register($sub$$reg);
 3386      Register super_reg = as_Register($super$$reg);
 3387      Register temp_reg = as_Register($temp$$reg);
 3388      Register result_reg = as_Register($result$$reg);
 3389 
 3390      Label miss;
 3391      C2_MacroAssembler _masm(&amp;cbuf);
 3392      __ check_klass_subtype_slow_path(sub_reg, super_reg, temp_reg, result_reg,
 3393                                      NULL, &amp;miss,
 3394                                      /*set_cond_codes:*/ true);
 3395      if ($primary) {
 3396        __ mov(result_reg, zr);
 3397      }
 3398      __ bind(miss);
 3399   %}
 3400 
 3401   enc_class aarch64_enc_java_static_call(method meth) %{
 3402     C2_MacroAssembler _masm(&amp;cbuf);
 3403 
 3404     address addr = (address)$meth$$method;
 3405     address call;
 3406     if (!_method) {
 3407       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
 3408       call = __ trampoline_call(Address(addr, relocInfo::runtime_call_type), &amp;cbuf);
 3409     } else {
 3410       int method_index = resolved_method_index(cbuf);
 3411       RelocationHolder rspec = _optimized_virtual ? opt_virtual_call_Relocation::spec(method_index)
 3412                                                   : static_call_Relocation::spec(method_index);
 3413       call = __ trampoline_call(Address(addr, rspec), &amp;cbuf);
 3414 
 3415       // Emit stub for static call
 3416       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 3417       if (stub == NULL) {
 3418         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3419         return;
 3420       }
 3421     }
 3422     if (call == NULL) {
 3423       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3424       return;
 3425     }
 3426   %}
 3427 
 3428   enc_class aarch64_enc_java_dynamic_call(method meth) %{
 3429     C2_MacroAssembler _masm(&amp;cbuf);
 3430     int method_index = resolved_method_index(cbuf);
 3431     address call = __ ic_call((address)$meth$$method, method_index);
 3432     if (call == NULL) {
 3433       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3434       return;
 3435     }
 3436   %}
 3437 
 3438   enc_class aarch64_enc_call_epilog() %{
 3439     C2_MacroAssembler _masm(&amp;cbuf);
 3440     if (VerifyStackAtCalls) {
 3441       // Check that stack depth is unchanged: find majik cookie on stack
 3442       __ call_Unimplemented();
 3443     }
 3444   %}
 3445 
 3446   enc_class aarch64_enc_java_to_runtime(method meth) %{
 3447     C2_MacroAssembler _masm(&amp;cbuf);
 3448 
 3449     // some calls to generated routines (arraycopy code) are scheduled
 3450     // by C2 as runtime calls. if so we can call them using a br (they
 3451     // will be in a reachable segment) otherwise we have to use a blr
 3452     // which loads the absolute address into a register.
 3453     address entry = (address)$meth$$method;
 3454     CodeBlob *cb = CodeCache::find_blob(entry);
 3455     if (cb) {
 3456       address call = __ trampoline_call(Address(entry, relocInfo::runtime_call_type));
 3457       if (call == NULL) {
 3458         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3459         return;
 3460       }
 3461     } else {
 3462       Label retaddr;
 3463       __ adr(rscratch2, retaddr);
 3464       __ lea(rscratch1, RuntimeAddress(entry));
 3465       // Leave a breadcrumb for JavaFrameAnchor::capture_last_Java_pc()
 3466       __ stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)));
 3467       __ blr(rscratch1);
 3468       __ bind(retaddr);
 3469       __ add(sp, sp, 2 * wordSize);
 3470     }
 3471   %}
 3472 
 3473   enc_class aarch64_enc_rethrow() %{
 3474     C2_MacroAssembler _masm(&amp;cbuf);
 3475     __ far_jump(RuntimeAddress(OptoRuntime::rethrow_stub()));
 3476   %}
 3477 
 3478   enc_class aarch64_enc_ret() %{
 3479     C2_MacroAssembler _masm(&amp;cbuf);
 3480     __ ret(lr);
 3481   %}
 3482 
 3483   enc_class aarch64_enc_tail_call(iRegP jump_target) %{
 3484     C2_MacroAssembler _masm(&amp;cbuf);
 3485     Register target_reg = as_Register($jump_target$$reg);
 3486     __ br(target_reg);
 3487   %}
 3488 
 3489   enc_class aarch64_enc_tail_jmp(iRegP jump_target) %{
 3490     C2_MacroAssembler _masm(&amp;cbuf);
 3491     Register target_reg = as_Register($jump_target$$reg);
 3492     // exception oop should be in r0
 3493     // ret addr has been popped into lr
 3494     // callee expects it in r3
 3495     __ mov(r3, lr);
 3496     __ br(target_reg);
 3497   %}
 3498 
 3499   enc_class aarch64_enc_fast_lock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3500     C2_MacroAssembler _masm(&amp;cbuf);
 3501     Register oop = as_Register($object$$reg);
 3502     Register box = as_Register($box$$reg);
 3503     Register disp_hdr = as_Register($tmp$$reg);
 3504     Register tmp = as_Register($tmp2$$reg);
 3505     Label cont;
 3506     Label object_has_monitor;
 3507     Label cas_failed;
 3508 
 3509     assert_different_registers(oop, box, tmp, disp_hdr);
 3510 
 3511     // Load markWord from object into displaced_header.
 3512     __ ldr(disp_hdr, Address(oop, oopDesc::mark_offset_in_bytes()));
 3513 
 3514     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3515       __ biased_locking_enter(box, oop, disp_hdr, tmp, true, cont);
 3516     }
 3517 
 3518     // Check for existing monitor
 3519     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3520 
 3521     // Set tmp to be (markWord of object | UNLOCK_VALUE).
 3522     __ orr(tmp, disp_hdr, markWord::unlocked_value);
 3523 
 3524     // Initialize the box. (Must happen before we update the object mark!)
 3525     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3526 
 3527     // Compare object markWord with an unlocked value (tmp) and if
 3528     // equal exchange the stack address of our box with object markWord.
 3529     // On failure disp_hdr contains the possibly locked markWord.
 3530     __ cmpxchg(oop, tmp, box, Assembler::xword, /*acquire*/ true,
 3531                /*release*/ true, /*weak*/ false, disp_hdr);
 3532     __ br(Assembler::EQ, cont);
 3533 
 3534     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3535 
 3536     // If the compare-and-exchange succeeded, then we found an unlocked
 3537     // object, will have now locked it will continue at label cont
 3538 
 3539     __ bind(cas_failed);
 3540     // We did not see an unlocked object so try the fast recursive case.
 3541 
 3542     // Check if the owner is self by comparing the value in the
 3543     // markWord of object (disp_hdr) with the stack pointer.
 3544     __ mov(rscratch1, sp);
 3545     __ sub(disp_hdr, disp_hdr, rscratch1);
 3546     __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));
 3547     // If condition is true we are cont and hence we can store 0 as the
 3548     // displaced header in the box, which indicates that it is a recursive lock.
 3549     __ ands(tmp/*==0?*/, disp_hdr, tmp);   // Sets flags for result
 3550     __ str(tmp/*==0, perhaps*/, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3551 
 3552     __ b(cont);
 3553 
 3554     // Handle existing monitor.
 3555     __ bind(object_has_monitor);
 3556 
 3557     // The object&#39;s monitor m is unlocked iff m-&gt;owner == NULL,
 3558     // otherwise m-&gt;owner may contain a thread or a stack address.
 3559     //
 3560     // Try to CAS m-&gt;owner from NULL to current thread.
 3561     __ add(tmp, disp_hdr, (ObjectMonitor::owner_offset_in_bytes()-markWord::monitor_value));
 3562     __ cmpxchg(tmp, zr, rthread, Assembler::xword, /*acquire*/ true,
 3563                /*release*/ true, /*weak*/ false, noreg); // Sets flags for result
 3564 
 3565     // Store a non-null value into the box to avoid looking like a re-entrant
 3566     // lock. The fast-path monitor unlock code checks for
 3567     // markWord::monitor_value so use markWord::unused_mark which has the
 3568     // relevant bit set, and also matches ObjectSynchronizer::enter.
 3569     __ mov(tmp, (address)markWord::unused_mark().value());
 3570     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3571 
 3572     __ bind(cont);
 3573     // flag == EQ indicates success
 3574     // flag == NE indicates failure
 3575   %}
 3576 
 3577   enc_class aarch64_enc_fast_unlock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3578     C2_MacroAssembler _masm(&amp;cbuf);
 3579     Register oop = as_Register($object$$reg);
 3580     Register box = as_Register($box$$reg);
 3581     Register disp_hdr = as_Register($tmp$$reg);
 3582     Register tmp = as_Register($tmp2$$reg);
 3583     Label cont;
 3584     Label object_has_monitor;
 3585 
 3586     assert_different_registers(oop, box, tmp, disp_hdr);
 3587 
 3588     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3589       __ biased_locking_exit(oop, tmp, cont);
 3590     }
 3591 
 3592     // Find the lock address and load the displaced header from the stack.
 3593     __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3594 
 3595     // If the displaced header is 0, we have a recursive unlock.
 3596     __ cmp(disp_hdr, zr);
 3597     __ br(Assembler::EQ, cont);
 3598 
 3599     // Handle existing monitor.
 3600     __ ldr(tmp, Address(oop, oopDesc::mark_offset_in_bytes()));
 3601     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3602 
 3603     // Check if it is still a light weight lock, this is is true if we
 3604     // see the stack address of the basicLock in the markWord of the
 3605     // object.
 3606 
 3607     __ cmpxchg(oop, box, disp_hdr, Assembler::xword, /*acquire*/ false,
 3608                /*release*/ true, /*weak*/ false, tmp);
 3609     __ b(cont);
 3610 
 3611     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3612 
 3613     // Handle existing monitor.
 3614     __ bind(object_has_monitor);
 3615     STATIC_ASSERT(markWord::monitor_value &lt;= INT_MAX);
 3616     __ add(tmp, tmp, -(int)markWord::monitor_value); // monitor
 3617     __ ldr(rscratch1, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3618     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::recursions_offset_in_bytes()));
 3619     __ eor(rscratch1, rscratch1, rthread); // Will be 0 if we are the owner.
 3620     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if there are 0 recursions
 3621     __ cmp(rscratch1, zr); // Sets flags for result
 3622     __ br(Assembler::NE, cont);
 3623 
 3624     __ ldr(rscratch1, Address(tmp, ObjectMonitor::EntryList_offset_in_bytes()));
 3625     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::cxq_offset_in_bytes()));
 3626     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if both are 0.
 3627     __ cmp(rscratch1, zr); // Sets flags for result
 3628     __ cbnz(rscratch1, cont);
 3629     // need a release store here
 3630     __ lea(tmp, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3631     __ stlr(zr, tmp); // set unowned
 3632 
 3633     __ bind(cont);
 3634     // flag == EQ indicates success
 3635     // flag == NE indicates failure
 3636   %}
 3637 
 3638 %}
 3639 
 3640 //----------FRAME--------------------------------------------------------------
 3641 // Definition of frame structure and management information.
 3642 //
 3643 //  S T A C K   L A Y O U T    Allocators stack-slot number
 3644 //                             |   (to get allocators register number
 3645 //  G  Owned by    |        |  v    add OptoReg::stack0())
 3646 //  r   CALLER     |        |
 3647 //  o     |        +--------+      pad to even-align allocators stack-slot
 3648 //  w     V        |  pad0  |        numbers; owned by CALLER
 3649 //  t   -----------+--------+----&gt; Matcher::_in_arg_limit, unaligned
 3650 //  h     ^        |   in   |  5
 3651 //        |        |  args  |  4   Holes in incoming args owned by SELF
 3652 //  |     |        |        |  3
 3653 //  |     |        +--------+
 3654 //  V     |        | old out|      Empty on Intel, window on Sparc
 3655 //        |    old |preserve|      Must be even aligned.
 3656 //        |     SP-+--------+----&gt; Matcher::_old_SP, even aligned
 3657 //        |        |   in   |  3   area for Intel ret address
 3658 //     Owned by    |preserve|      Empty on Sparc.
 3659 //       SELF      +--------+
 3660 //        |        |  pad2  |  2   pad to align old SP
 3661 //        |        +--------+  1
 3662 //        |        | locks  |  0
 3663 //        |        +--------+----&gt; OptoReg::stack0(), even aligned
 3664 //        |        |  pad1  | 11   pad to align new SP
 3665 //        |        +--------+
 3666 //        |        |        | 10
 3667 //        |        | spills |  9   spills
 3668 //        V        |        |  8   (pad0 slot for callee)
 3669 //      -----------+--------+----&gt; Matcher::_out_arg_limit, unaligned
 3670 //        ^        |  out   |  7
 3671 //        |        |  args  |  6   Holes in outgoing args owned by CALLEE
 3672 //     Owned by    +--------+
 3673 //      CALLEE     | new out|  6   Empty on Intel, window on Sparc
 3674 //        |    new |preserve|      Must be even-aligned.
 3675 //        |     SP-+--------+----&gt; Matcher::_new_SP, even aligned
 3676 //        |        |        |
 3677 //
 3678 // Note 1: Only region 8-11 is determined by the allocator.  Region 0-5 is
 3679 //         known from SELF&#39;s arguments and the Java calling convention.
 3680 //         Region 6-7 is determined per call site.
 3681 // Note 2: If the calling convention leaves holes in the incoming argument
 3682 //         area, those holes are owned by SELF.  Holes in the outgoing area
 3683 //         are owned by the CALLEE.  Holes should not be nessecary in the
 3684 //         incoming area, as the Java calling convention is completely under
 3685 //         the control of the AD file.  Doubles can be sorted and packed to
 3686 //         avoid holes.  Holes in the outgoing arguments may be nessecary for
 3687 //         varargs C calling conventions.
 3688 // Note 3: Region 0-3 is even aligned, with pad2 as needed.  Region 3-5 is
 3689 //         even aligned with pad0 as needed.
 3690 //         Region 6 is even aligned.  Region 6-7 is NOT even aligned;
 3691 //           (the latter is true on Intel but is it false on AArch64?)
 3692 //         region 6-11 is even aligned; it may be padded out more so that
 3693 //         the region from SP to FP meets the minimum stack alignment.
 3694 // Note 4: For I2C adapters, the incoming FP may not meet the minimum stack
 3695 //         alignment.  Region 11, pad1, may be dynamically extended so that
 3696 //         SP meets the minimum alignment.
 3697 
 3698 frame %{
 3699   // What direction does stack grow in (assumed to be same for C &amp; Java)
 3700   stack_direction(TOWARDS_LOW);
 3701 
 3702   // These three registers define part of the calling convention
 3703   // between compiled code and the interpreter.
 3704 
 3705   // Inline Cache Register or methodOop for I2C.
 3706   inline_cache_reg(R12);
 3707 
 3708   // Method Oop Register when calling interpreter.
 3709   interpreter_method_oop_reg(R12);
 3710 
 3711   // Number of stack slots consumed by locking an object
 3712   sync_stack_slots(2);
 3713 
 3714   // Compiled code&#39;s Frame Pointer
 3715   frame_pointer(R31);
 3716 
 3717   // Interpreter stores its frame pointer in a register which is
 3718   // stored to the stack by I2CAdaptors.
 3719   // I2CAdaptors convert from interpreted java to compiled java.
 3720   interpreter_frame_pointer(R29);
 3721 
 3722   // Stack alignment requirement
 3723   stack_alignment(StackAlignmentInBytes); // Alignment size in bytes (128-bit -&gt; 16 bytes)
 3724 
 3725   // Number of stack slots between incoming argument block and the start of
 3726   // a new frame.  The PROLOG must add this many slots to the stack.  The
 3727   // EPILOG must remove this many slots. aarch64 needs two slots for
 3728   // return address and fp.
 3729   // TODO think this is correct but check
 3730   in_preserve_stack_slots(4);
 3731 
 3732   // Number of outgoing stack slots killed above the out_preserve_stack_slots
 3733   // for calls to C.  Supports the var-args backing area for register parms.
 3734   varargs_C_out_slots_killed(frame::arg_reg_save_area_bytes/BytesPerInt);
 3735 
 3736   // The after-PROLOG location of the return address.  Location of
 3737   // return address specifies a type (REG or STACK) and a number
 3738   // representing the register number (i.e. - use a register name) or
 3739   // stack slot.
 3740   // Ret Addr is on stack in slot 0 if no locks or verification or alignment.
 3741   // Otherwise, it is above the locks and verification slot and alignment word
 3742   // TODO this may well be correct but need to check why that - 2 is there
 3743   // ppc port uses 0 but we definitely need to allow for fixed_slots
 3744   // which folds in the space used for monitors
 3745   return_addr(STACK - 2 +
 3746               align_up((Compile::current()-&gt;in_preserve_stack_slots() +
 3747                         Compile::current()-&gt;fixed_slots()),
 3748                        stack_alignment_in_slots()));
 3749 
 3750   // Body of function which returns an integer array locating
 3751   // arguments either in registers or in stack slots.  Passed an array
 3752   // of ideal registers called &quot;sig&quot; and a &quot;length&quot; count.  Stack-slot
 3753   // offsets are based on outgoing arguments, i.e. a CALLER setting up
 3754   // arguments for a CALLEE.  Incoming stack arguments are
 3755   // automatically biased by the preserve_stack_slots field above.
 3756 
 3757   calling_convention
 3758   %{
 3759     // No difference between ingoing/outgoing just pass false
 3760     SharedRuntime::java_calling_convention(sig_bt, regs, length, false);
 3761   %}
 3762 
 3763   c_calling_convention
 3764   %{
 3765     // This is obviously always outgoing
 3766     (void) SharedRuntime::c_calling_convention(sig_bt, regs, NULL, length);
 3767   %}
 3768 
 3769   // Location of compiled Java return values.  Same as C for now.
 3770   return_value
 3771   %{
 3772     // TODO do we allow ideal_reg == Op_RegN???
 3773     assert(ideal_reg &gt;= Op_RegI &amp;&amp; ideal_reg &lt;= Op_RegL,
 3774            &quot;only return normal values&quot;);
 3775 
 3776     static const int lo[Op_RegL + 1] = { // enum name
 3777       0,                                 // Op_Node
 3778       0,                                 // Op_Set
 3779       R0_num,                            // Op_RegN
 3780       R0_num,                            // Op_RegI
 3781       R0_num,                            // Op_RegP
 3782       V0_num,                            // Op_RegF
 3783       V0_num,                            // Op_RegD
 3784       R0_num                             // Op_RegL
 3785     };
 3786 
 3787     static const int hi[Op_RegL + 1] = { // enum name
 3788       0,                                 // Op_Node
 3789       0,                                 // Op_Set
 3790       OptoReg::Bad,                      // Op_RegN
 3791       OptoReg::Bad,                      // Op_RegI
 3792       R0_H_num,                          // Op_RegP
 3793       OptoReg::Bad,                      // Op_RegF
 3794       V0_H_num,                          // Op_RegD
 3795       R0_H_num                           // Op_RegL
 3796     };
 3797 
 3798     return OptoRegPair(hi[ideal_reg], lo[ideal_reg]);
 3799   %}
 3800 %}
 3801 
 3802 //----------ATTRIBUTES---------------------------------------------------------
 3803 //----------Operand Attributes-------------------------------------------------
 3804 op_attrib op_cost(1);        // Required cost attribute
 3805 
 3806 //----------Instruction Attributes---------------------------------------------
 3807 ins_attrib ins_cost(INSN_COST); // Required cost attribute
 3808 ins_attrib ins_size(32);        // Required size attribute (in bits)
 3809 ins_attrib ins_short_branch(0); // Required flag: is this instruction
 3810                                 // a non-matching short branch variant
 3811                                 // of some long branch?
 3812 ins_attrib ins_alignment(4);    // Required alignment attribute (must
 3813                                 // be a power of 2) specifies the
 3814                                 // alignment that some part of the
 3815                                 // instruction (not necessarily the
 3816                                 // start) requires.  If &gt; 1, a
 3817                                 // compute_padding() function must be
 3818                                 // provided for the instruction
 3819 
 3820 //----------OPERANDS-----------------------------------------------------------
 3821 // Operand definitions must precede instruction definitions for correct parsing
 3822 // in the ADLC because operands constitute user defined types which are used in
 3823 // instruction definitions.
 3824 
 3825 //----------Simple Operands----------------------------------------------------
 3826 
 3827 // Integer operands 32 bit
 3828 // 32 bit immediate
 3829 operand immI()
 3830 %{
 3831   match(ConI);
 3832 
 3833   op_cost(0);
 3834   format %{ %}
 3835   interface(CONST_INTER);
 3836 %}
 3837 
 3838 // 32 bit zero
 3839 operand immI0()
 3840 %{
 3841   predicate(n-&gt;get_int() == 0);
 3842   match(ConI);
 3843 
 3844   op_cost(0);
 3845   format %{ %}
 3846   interface(CONST_INTER);
 3847 %}
 3848 
 3849 // 32 bit unit increment
 3850 operand immI_1()
 3851 %{
 3852   predicate(n-&gt;get_int() == 1);
 3853   match(ConI);
 3854 
 3855   op_cost(0);
 3856   format %{ %}
 3857   interface(CONST_INTER);
 3858 %}
 3859 
 3860 // 32 bit unit decrement
 3861 operand immI_M1()
 3862 %{
 3863   predicate(n-&gt;get_int() == -1);
 3864   match(ConI);
 3865 
 3866   op_cost(0);
 3867   format %{ %}
 3868   interface(CONST_INTER);
 3869 %}
 3870 
 3871 // Shift values for add/sub extension shift
 3872 operand immIExt()
 3873 %{
 3874   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 4));
 3875   match(ConI);
 3876 
 3877   op_cost(0);
 3878   format %{ %}
 3879   interface(CONST_INTER);
 3880 %}
 3881 
 3882 operand immI_le_4()
 3883 %{
 3884   predicate(n-&gt;get_int() &lt;= 4);
 3885   match(ConI);
 3886 
 3887   op_cost(0);
 3888   format %{ %}
 3889   interface(CONST_INTER);
 3890 %}
 3891 
 3892 operand immI_31()
 3893 %{
 3894   predicate(n-&gt;get_int() == 31);
 3895   match(ConI);
 3896 
 3897   op_cost(0);
 3898   format %{ %}
 3899   interface(CONST_INTER);
 3900 %}
 3901 
 3902 operand immI_8()
 3903 %{
 3904   predicate(n-&gt;get_int() == 8);
 3905   match(ConI);
 3906 
 3907   op_cost(0);
 3908   format %{ %}
 3909   interface(CONST_INTER);
 3910 %}
 3911 
 3912 operand immI_16()
 3913 %{
 3914   predicate(n-&gt;get_int() == 16);
 3915   match(ConI);
 3916 
 3917   op_cost(0);
 3918   format %{ %}
 3919   interface(CONST_INTER);
 3920 %}
 3921 
 3922 operand immI_24()
 3923 %{
 3924   predicate(n-&gt;get_int() == 24);
 3925   match(ConI);
 3926 
 3927   op_cost(0);
 3928   format %{ %}
 3929   interface(CONST_INTER);
 3930 %}
 3931 
 3932 operand immI_32()
 3933 %{
 3934   predicate(n-&gt;get_int() == 32);
 3935   match(ConI);
 3936 
 3937   op_cost(0);
 3938   format %{ %}
 3939   interface(CONST_INTER);
 3940 %}
 3941 
 3942 operand immI_48()
 3943 %{
 3944   predicate(n-&gt;get_int() == 48);
 3945   match(ConI);
 3946 
 3947   op_cost(0);
 3948   format %{ %}
 3949   interface(CONST_INTER);
 3950 %}
 3951 
 3952 operand immI_56()
 3953 %{
 3954   predicate(n-&gt;get_int() == 56);
 3955   match(ConI);
 3956 
 3957   op_cost(0);
 3958   format %{ %}
 3959   interface(CONST_INTER);
 3960 %}
 3961 
 3962 operand immI_63()
 3963 %{
 3964   predicate(n-&gt;get_int() == 63);
 3965   match(ConI);
 3966 
 3967   op_cost(0);
 3968   format %{ %}
 3969   interface(CONST_INTER);
 3970 %}
 3971 
 3972 operand immI_64()
 3973 %{
 3974   predicate(n-&gt;get_int() == 64);
 3975   match(ConI);
 3976 
 3977   op_cost(0);
 3978   format %{ %}
 3979   interface(CONST_INTER);
 3980 %}
 3981 
 3982 operand immI_255()
 3983 %{
 3984   predicate(n-&gt;get_int() == 255);
 3985   match(ConI);
 3986 
 3987   op_cost(0);
 3988   format %{ %}
 3989   interface(CONST_INTER);
 3990 %}
 3991 
 3992 operand immI_65535()
 3993 %{
 3994   predicate(n-&gt;get_int() == 65535);
 3995   match(ConI);
 3996 
 3997   op_cost(0);
 3998   format %{ %}
 3999   interface(CONST_INTER);
 4000 %}
 4001 
 4002 operand immL_255()
 4003 %{
 4004   predicate(n-&gt;get_long() == 255L);
 4005   match(ConL);
 4006 
 4007   op_cost(0);
 4008   format %{ %}
 4009   interface(CONST_INTER);
 4010 %}
 4011 
 4012 operand immL_65535()
 4013 %{
 4014   predicate(n-&gt;get_long() == 65535L);
 4015   match(ConL);
 4016 
 4017   op_cost(0);
 4018   format %{ %}
 4019   interface(CONST_INTER);
 4020 %}
 4021 
 4022 operand immL_4294967295()
 4023 %{
 4024   predicate(n-&gt;get_long() == 4294967295L);
 4025   match(ConL);
 4026 
 4027   op_cost(0);
 4028   format %{ %}
 4029   interface(CONST_INTER);
 4030 %}
 4031 
 4032 operand immL_bitmask()
 4033 %{
 4034   predicate((n-&gt;get_long() != 0)
 4035             &amp;&amp; ((n-&gt;get_long() &amp; 0xc000000000000000l) == 0)
 4036             &amp;&amp; is_power_of_2(n-&gt;get_long() + 1));
 4037   match(ConL);
 4038 
 4039   op_cost(0);
 4040   format %{ %}
 4041   interface(CONST_INTER);
 4042 %}
 4043 
 4044 operand immI_bitmask()
 4045 %{
 4046   predicate((n-&gt;get_int() != 0)
 4047             &amp;&amp; ((n-&gt;get_int() &amp; 0xc0000000) == 0)
 4048             &amp;&amp; is_power_of_2(n-&gt;get_int() + 1));
 4049   match(ConI);
 4050 
 4051   op_cost(0);
 4052   format %{ %}
 4053   interface(CONST_INTER);
 4054 %}
 4055 
 4056 // Scale values for scaled offset addressing modes (up to long but not quad)
 4057 operand immIScale()
 4058 %{
 4059   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 3));
 4060   match(ConI);
 4061 
 4062   op_cost(0);
 4063   format %{ %}
 4064   interface(CONST_INTER);
 4065 %}
 4066 
 4067 // 26 bit signed offset -- for pc-relative branches
 4068 operand immI26()
 4069 %{
 4070   predicate(((-(1 &lt;&lt; 25)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 25)));
 4071   match(ConI);
 4072 
 4073   op_cost(0);
 4074   format %{ %}
 4075   interface(CONST_INTER);
 4076 %}
 4077 
 4078 // 19 bit signed offset -- for pc-relative loads
 4079 operand immI19()
 4080 %{
 4081   predicate(((-(1 &lt;&lt; 18)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 18)));
 4082   match(ConI);
 4083 
 4084   op_cost(0);
 4085   format %{ %}
 4086   interface(CONST_INTER);
 4087 %}
 4088 
 4089 // 12 bit unsigned offset -- for base plus immediate loads
 4090 operand immIU12()
 4091 %{
 4092   predicate((0 &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 12)));
 4093   match(ConI);
 4094 
 4095   op_cost(0);
 4096   format %{ %}
 4097   interface(CONST_INTER);
 4098 %}
 4099 
 4100 operand immLU12()
 4101 %{
 4102   predicate((0 &lt;= n-&gt;get_long()) &amp;&amp; (n-&gt;get_long() &lt; (1 &lt;&lt; 12)));
 4103   match(ConL);
 4104 
 4105   op_cost(0);
 4106   format %{ %}
 4107   interface(CONST_INTER);
 4108 %}
 4109 
 4110 // Offset for scaled or unscaled immediate loads and stores
 4111 operand immIOffset()
 4112 %{
 4113   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4114   match(ConI);
 4115 
 4116   op_cost(0);
 4117   format %{ %}
 4118   interface(CONST_INTER);
 4119 %}
 4120 
 4121 operand immIOffset1()
 4122 %{
 4123   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4124   match(ConI);
 4125 
 4126   op_cost(0);
 4127   format %{ %}
 4128   interface(CONST_INTER);
 4129 %}
 4130 
 4131 operand immIOffset2()
 4132 %{
 4133   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 1));
 4134   match(ConI);
 4135 
 4136   op_cost(0);
 4137   format %{ %}
 4138   interface(CONST_INTER);
 4139 %}
 4140 
 4141 operand immIOffset4()
 4142 %{
 4143   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 2));
 4144   match(ConI);
 4145 
 4146   op_cost(0);
 4147   format %{ %}
 4148   interface(CONST_INTER);
 4149 %}
 4150 
 4151 operand immIOffset8()
 4152 %{
 4153   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 3));
 4154   match(ConI);
 4155 
 4156   op_cost(0);
 4157   format %{ %}
 4158   interface(CONST_INTER);
 4159 %}
 4160 
 4161 operand immIOffset16()
 4162 %{
 4163   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 4));
 4164   match(ConI);
 4165 
 4166   op_cost(0);
 4167   format %{ %}
 4168   interface(CONST_INTER);
 4169 %}
 4170 
 4171 operand immLoffset()
 4172 %{
 4173   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4174   match(ConL);
 4175 
 4176   op_cost(0);
 4177   format %{ %}
 4178   interface(CONST_INTER);
 4179 %}
 4180 
 4181 operand immLoffset1()
 4182 %{
 4183   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4184   match(ConL);
 4185 
 4186   op_cost(0);
 4187   format %{ %}
 4188   interface(CONST_INTER);
 4189 %}
 4190 
 4191 operand immLoffset2()
 4192 %{
 4193   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 1));
 4194   match(ConL);
 4195 
 4196   op_cost(0);
 4197   format %{ %}
 4198   interface(CONST_INTER);
 4199 %}
 4200 
 4201 operand immLoffset4()
 4202 %{
 4203   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 2));
 4204   match(ConL);
 4205 
 4206   op_cost(0);
 4207   format %{ %}
 4208   interface(CONST_INTER);
 4209 %}
 4210 
 4211 operand immLoffset8()
 4212 %{
 4213   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 3));
 4214   match(ConL);
 4215 
 4216   op_cost(0);
 4217   format %{ %}
 4218   interface(CONST_INTER);
 4219 %}
 4220 
 4221 operand immLoffset16()
 4222 %{
 4223   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 4));
 4224   match(ConL);
 4225 
 4226   op_cost(0);
 4227   format %{ %}
 4228   interface(CONST_INTER);
 4229 %}
 4230 
 4231 // 32 bit integer valid for add sub immediate
 4232 operand immIAddSub()
 4233 %{
 4234   predicate(Assembler::operand_valid_for_add_sub_immediate((long)n-&gt;get_int()));
 4235   match(ConI);
 4236   op_cost(0);
 4237   format %{ %}
 4238   interface(CONST_INTER);
 4239 %}
 4240 
 4241 // 32 bit unsigned integer valid for logical immediate
 4242 // TODO -- check this is right when e.g the mask is 0x80000000
 4243 operand immILog()
 4244 %{
 4245   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/true, (unsigned long)n-&gt;get_int()));
 4246   match(ConI);
 4247 
 4248   op_cost(0);
 4249   format %{ %}
 4250   interface(CONST_INTER);
 4251 %}
 4252 
 4253 // Integer operands 64 bit
 4254 // 64 bit immediate
 4255 operand immL()
 4256 %{
 4257   match(ConL);
 4258 
 4259   op_cost(0);
 4260   format %{ %}
 4261   interface(CONST_INTER);
 4262 %}
 4263 
 4264 // 64 bit zero
 4265 operand immL0()
 4266 %{
 4267   predicate(n-&gt;get_long() == 0);
 4268   match(ConL);
 4269 
 4270   op_cost(0);
 4271   format %{ %}
 4272   interface(CONST_INTER);
 4273 %}
 4274 
 4275 // 64 bit unit increment
 4276 operand immL_1()
 4277 %{
 4278   predicate(n-&gt;get_long() == 1);
 4279   match(ConL);
 4280 
 4281   op_cost(0);
 4282   format %{ %}
 4283   interface(CONST_INTER);
 4284 %}
 4285 
 4286 // 64 bit unit decrement
 4287 operand immL_M1()
 4288 %{
 4289   predicate(n-&gt;get_long() == -1);
 4290   match(ConL);
 4291 
 4292   op_cost(0);
 4293   format %{ %}
 4294   interface(CONST_INTER);
 4295 %}
 4296 
 4297 // 32 bit offset of pc in thread anchor
 4298 
 4299 operand immL_pc_off()
 4300 %{
 4301   predicate(n-&gt;get_long() == in_bytes(JavaThread::frame_anchor_offset()) +
 4302                              in_bytes(JavaFrameAnchor::last_Java_pc_offset()));
 4303   match(ConL);
 4304 
 4305   op_cost(0);
 4306   format %{ %}
 4307   interface(CONST_INTER);
 4308 %}
 4309 
 4310 // 64 bit integer valid for add sub immediate
 4311 operand immLAddSub()
 4312 %{
 4313   predicate(Assembler::operand_valid_for_add_sub_immediate(n-&gt;get_long()));
 4314   match(ConL);
 4315   op_cost(0);
 4316   format %{ %}
 4317   interface(CONST_INTER);
 4318 %}
 4319 
 4320 // 64 bit integer valid for logical immediate
 4321 operand immLLog()
 4322 %{
 4323   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/false, (unsigned long)n-&gt;get_long()));
 4324   match(ConL);
 4325   op_cost(0);
 4326   format %{ %}
 4327   interface(CONST_INTER);
 4328 %}
 4329 
 4330 // Long Immediate: low 32-bit mask
 4331 operand immL_32bits()
 4332 %{
 4333   predicate(n-&gt;get_long() == 0xFFFFFFFFL);
 4334   match(ConL);
 4335   op_cost(0);
 4336   format %{ %}
 4337   interface(CONST_INTER);
 4338 %}
 4339 
 4340 // Pointer operands
 4341 // Pointer Immediate
 4342 operand immP()
 4343 %{
 4344   match(ConP);
 4345 
 4346   op_cost(0);
 4347   format %{ %}
 4348   interface(CONST_INTER);
 4349 %}
 4350 
 4351 // NULL Pointer Immediate
 4352 operand immP0()
 4353 %{
 4354   predicate(n-&gt;get_ptr() == 0);
 4355   match(ConP);
 4356 
 4357   op_cost(0);
 4358   format %{ %}
 4359   interface(CONST_INTER);
 4360 %}
 4361 
 4362 // Pointer Immediate One
 4363 // this is used in object initialization (initial object header)
 4364 operand immP_1()
 4365 %{
 4366   predicate(n-&gt;get_ptr() == 1);
 4367   match(ConP);
 4368 
 4369   op_cost(0);
 4370   format %{ %}
 4371   interface(CONST_INTER);
 4372 %}
 4373 
 4374 // Card Table Byte Map Base
 4375 operand immByteMapBase()
 4376 %{
 4377   // Get base of card map
 4378   predicate(BarrierSet::barrier_set()-&gt;is_a(BarrierSet::CardTableBarrierSet) &amp;&amp;
 4379             (CardTable::CardValue*)n-&gt;get_ptr() == ((CardTableBarrierSet*)(BarrierSet::barrier_set()))-&gt;card_table()-&gt;byte_map_base());
 4380   match(ConP);
 4381 
 4382   op_cost(0);
 4383   format %{ %}
 4384   interface(CONST_INTER);
 4385 %}
 4386 
 4387 // Pointer Immediate Minus One
 4388 // this is used when we want to write the current PC to the thread anchor
 4389 operand immP_M1()
 4390 %{
 4391   predicate(n-&gt;get_ptr() == -1);
 4392   match(ConP);
 4393 
 4394   op_cost(0);
 4395   format %{ %}
 4396   interface(CONST_INTER);
 4397 %}
 4398 
 4399 // Pointer Immediate Minus Two
 4400 // this is used when we want to write the current PC to the thread anchor
 4401 operand immP_M2()
 4402 %{
 4403   predicate(n-&gt;get_ptr() == -2);
 4404   match(ConP);
 4405 
 4406   op_cost(0);
 4407   format %{ %}
 4408   interface(CONST_INTER);
 4409 %}
 4410 
 4411 // Float and Double operands
 4412 // Double Immediate
 4413 operand immD()
 4414 %{
 4415   match(ConD);
 4416   op_cost(0);
 4417   format %{ %}
 4418   interface(CONST_INTER);
 4419 %}
 4420 
 4421 // Double Immediate: +0.0d
 4422 operand immD0()
 4423 %{
 4424   predicate(jlong_cast(n-&gt;getd()) == 0);
 4425   match(ConD);
 4426 
 4427   op_cost(0);
 4428   format %{ %}
 4429   interface(CONST_INTER);
 4430 %}
 4431 
 4432 // constant &#39;double +0.0&#39;.
 4433 operand immDPacked()
 4434 %{
 4435   predicate(Assembler::operand_valid_for_float_immediate(n-&gt;getd()));
 4436   match(ConD);
 4437   op_cost(0);
 4438   format %{ %}
 4439   interface(CONST_INTER);
 4440 %}
 4441 
 4442 // Float Immediate
 4443 operand immF()
 4444 %{
 4445   match(ConF);
 4446   op_cost(0);
 4447   format %{ %}
 4448   interface(CONST_INTER);
 4449 %}
 4450 
 4451 // Float Immediate: +0.0f.
 4452 operand immF0()
 4453 %{
 4454   predicate(jint_cast(n-&gt;getf()) == 0);
 4455   match(ConF);
 4456 
 4457   op_cost(0);
 4458   format %{ %}
 4459   interface(CONST_INTER);
 4460 %}
 4461 
 4462 //
 4463 operand immFPacked()
 4464 %{
 4465   predicate(Assembler::operand_valid_for_float_immediate((double)n-&gt;getf()));
 4466   match(ConF);
 4467   op_cost(0);
 4468   format %{ %}
 4469   interface(CONST_INTER);
 4470 %}
 4471 
 4472 // Narrow pointer operands
 4473 // Narrow Pointer Immediate
 4474 operand immN()
 4475 %{
 4476   match(ConN);
 4477 
 4478   op_cost(0);
 4479   format %{ %}
 4480   interface(CONST_INTER);
 4481 %}
 4482 
 4483 // Narrow NULL Pointer Immediate
 4484 operand immN0()
 4485 %{
 4486   predicate(n-&gt;get_narrowcon() == 0);
 4487   match(ConN);
 4488 
 4489   op_cost(0);
 4490   format %{ %}
 4491   interface(CONST_INTER);
 4492 %}
 4493 
 4494 operand immNKlass()
 4495 %{
 4496   match(ConNKlass);
 4497 
 4498   op_cost(0);
 4499   format %{ %}
 4500   interface(CONST_INTER);
 4501 %}
 4502 
 4503 // Integer 32 bit Register Operands
 4504 // Integer 32 bitRegister (excludes SP)
 4505 operand iRegI()
 4506 %{
 4507   constraint(ALLOC_IN_RC(any_reg32));
 4508   match(RegI);
 4509   match(iRegINoSp);
 4510   op_cost(0);
 4511   format %{ %}
 4512   interface(REG_INTER);
 4513 %}
 4514 
 4515 // Integer 32 bit Register not Special
 4516 operand iRegINoSp()
 4517 %{
 4518   constraint(ALLOC_IN_RC(no_special_reg32));
 4519   match(RegI);
 4520   op_cost(0);
 4521   format %{ %}
 4522   interface(REG_INTER);
 4523 %}
 4524 
 4525 // Integer 64 bit Register Operands
 4526 // Integer 64 bit Register (includes SP)
 4527 operand iRegL()
 4528 %{
 4529   constraint(ALLOC_IN_RC(any_reg));
 4530   match(RegL);
 4531   match(iRegLNoSp);
 4532   op_cost(0);
 4533   format %{ %}
 4534   interface(REG_INTER);
 4535 %}
 4536 
 4537 // Integer 64 bit Register not Special
 4538 operand iRegLNoSp()
 4539 %{
 4540   constraint(ALLOC_IN_RC(no_special_reg));
 4541   match(RegL);
 4542   match(iRegL_R0);
 4543   format %{ %}
 4544   interface(REG_INTER);
 4545 %}
 4546 
 4547 // Pointer Register Operands
 4548 // Pointer Register
 4549 operand iRegP()
 4550 %{
 4551   constraint(ALLOC_IN_RC(ptr_reg));
 4552   match(RegP);
 4553   match(iRegPNoSp);
 4554   match(iRegP_R0);
 4555   //match(iRegP_R2);
 4556   //match(iRegP_R4);
 4557   //match(iRegP_R5);
 4558   match(thread_RegP);
 4559   op_cost(0);
 4560   format %{ %}
 4561   interface(REG_INTER);
 4562 %}
 4563 
 4564 // Pointer 64 bit Register not Special
 4565 operand iRegPNoSp()
 4566 %{
 4567   constraint(ALLOC_IN_RC(no_special_ptr_reg));
 4568   match(RegP);
 4569   // match(iRegP);
 4570   // match(iRegP_R0);
 4571   // match(iRegP_R2);
 4572   // match(iRegP_R4);
 4573   // match(iRegP_R5);
 4574   // match(thread_RegP);
 4575   op_cost(0);
 4576   format %{ %}
 4577   interface(REG_INTER);
 4578 %}
 4579 
 4580 // Pointer 64 bit Register R0 only
 4581 operand iRegP_R0()
 4582 %{
 4583   constraint(ALLOC_IN_RC(r0_reg));
 4584   match(RegP);
 4585   // match(iRegP);
 4586   match(iRegPNoSp);
 4587   op_cost(0);
 4588   format %{ %}
 4589   interface(REG_INTER);
 4590 %}
 4591 
 4592 // Pointer 64 bit Register R1 only
 4593 operand iRegP_R1()
 4594 %{
 4595   constraint(ALLOC_IN_RC(r1_reg));
 4596   match(RegP);
 4597   // match(iRegP);
 4598   match(iRegPNoSp);
 4599   op_cost(0);
 4600   format %{ %}
 4601   interface(REG_INTER);
 4602 %}
 4603 
 4604 // Pointer 64 bit Register R2 only
 4605 operand iRegP_R2()
 4606 %{
 4607   constraint(ALLOC_IN_RC(r2_reg));
 4608   match(RegP);
 4609   // match(iRegP);
 4610   match(iRegPNoSp);
 4611   op_cost(0);
 4612   format %{ %}
 4613   interface(REG_INTER);
 4614 %}
 4615 
 4616 // Pointer 64 bit Register R3 only
 4617 operand iRegP_R3()
 4618 %{
 4619   constraint(ALLOC_IN_RC(r3_reg));
 4620   match(RegP);
 4621   // match(iRegP);
 4622   match(iRegPNoSp);
 4623   op_cost(0);
 4624   format %{ %}
 4625   interface(REG_INTER);
 4626 %}
 4627 
 4628 // Pointer 64 bit Register R4 only
 4629 operand iRegP_R4()
 4630 %{
 4631   constraint(ALLOC_IN_RC(r4_reg));
 4632   match(RegP);
 4633   // match(iRegP);
 4634   match(iRegPNoSp);
 4635   op_cost(0);
 4636   format %{ %}
 4637   interface(REG_INTER);
 4638 %}
 4639 
 4640 // Pointer 64 bit Register R5 only
 4641 operand iRegP_R5()
 4642 %{
 4643   constraint(ALLOC_IN_RC(r5_reg));
 4644   match(RegP);
 4645   // match(iRegP);
 4646   match(iRegPNoSp);
 4647   op_cost(0);
 4648   format %{ %}
 4649   interface(REG_INTER);
 4650 %}
 4651 
 4652 // Pointer 64 bit Register R10 only
 4653 operand iRegP_R10()
 4654 %{
 4655   constraint(ALLOC_IN_RC(r10_reg));
 4656   match(RegP);
 4657   // match(iRegP);
 4658   match(iRegPNoSp);
 4659   op_cost(0);
 4660   format %{ %}
 4661   interface(REG_INTER);
 4662 %}
 4663 
 4664 // Long 64 bit Register R0 only
 4665 operand iRegL_R0()
 4666 %{
 4667   constraint(ALLOC_IN_RC(r0_reg));
 4668   match(RegL);
 4669   match(iRegLNoSp);
 4670   op_cost(0);
 4671   format %{ %}
 4672   interface(REG_INTER);
 4673 %}
 4674 
 4675 // Long 64 bit Register R2 only
 4676 operand iRegL_R2()
 4677 %{
 4678   constraint(ALLOC_IN_RC(r2_reg));
 4679   match(RegL);
 4680   match(iRegLNoSp);
 4681   op_cost(0);
 4682   format %{ %}
 4683   interface(REG_INTER);
 4684 %}
 4685 
 4686 // Long 64 bit Register R3 only
 4687 operand iRegL_R3()
 4688 %{
 4689   constraint(ALLOC_IN_RC(r3_reg));
 4690   match(RegL);
 4691   match(iRegLNoSp);
 4692   op_cost(0);
 4693   format %{ %}
 4694   interface(REG_INTER);
 4695 %}
 4696 
 4697 // Long 64 bit Register R11 only
 4698 operand iRegL_R11()
 4699 %{
 4700   constraint(ALLOC_IN_RC(r11_reg));
 4701   match(RegL);
 4702   match(iRegLNoSp);
 4703   op_cost(0);
 4704   format %{ %}
 4705   interface(REG_INTER);
 4706 %}
 4707 
 4708 // Pointer 64 bit Register FP only
 4709 operand iRegP_FP()
 4710 %{
 4711   constraint(ALLOC_IN_RC(fp_reg));
 4712   match(RegP);
 4713   // match(iRegP);
 4714   op_cost(0);
 4715   format %{ %}
 4716   interface(REG_INTER);
 4717 %}
 4718 
 4719 // Register R0 only
 4720 operand iRegI_R0()
 4721 %{
 4722   constraint(ALLOC_IN_RC(int_r0_reg));
 4723   match(RegI);
 4724   match(iRegINoSp);
 4725   op_cost(0);
 4726   format %{ %}
 4727   interface(REG_INTER);
 4728 %}
 4729 
 4730 // Register R2 only
 4731 operand iRegI_R2()
 4732 %{
 4733   constraint(ALLOC_IN_RC(int_r2_reg));
 4734   match(RegI);
 4735   match(iRegINoSp);
 4736   op_cost(0);
 4737   format %{ %}
 4738   interface(REG_INTER);
 4739 %}
 4740 
 4741 // Register R3 only
 4742 operand iRegI_R3()
 4743 %{
 4744   constraint(ALLOC_IN_RC(int_r3_reg));
 4745   match(RegI);
 4746   match(iRegINoSp);
 4747   op_cost(0);
 4748   format %{ %}
 4749   interface(REG_INTER);
 4750 %}
 4751 
 4752 
 4753 // Register R4 only
 4754 operand iRegI_R4()
 4755 %{
 4756   constraint(ALLOC_IN_RC(int_r4_reg));
 4757   match(RegI);
 4758   match(iRegINoSp);
 4759   op_cost(0);
 4760   format %{ %}
 4761   interface(REG_INTER);
 4762 %}
 4763 
 4764 
 4765 // Pointer Register Operands
 4766 // Narrow Pointer Register
 4767 operand iRegN()
 4768 %{
 4769   constraint(ALLOC_IN_RC(any_reg32));
 4770   match(RegN);
 4771   match(iRegNNoSp);
 4772   op_cost(0);
 4773   format %{ %}
 4774   interface(REG_INTER);
 4775 %}
 4776 
 4777 operand iRegN_R0()
 4778 %{
 4779   constraint(ALLOC_IN_RC(r0_reg));
 4780   match(iRegN);
 4781   op_cost(0);
 4782   format %{ %}
 4783   interface(REG_INTER);
 4784 %}
 4785 
 4786 operand iRegN_R2()
 4787 %{
 4788   constraint(ALLOC_IN_RC(r2_reg));
 4789   match(iRegN);
 4790   op_cost(0);
 4791   format %{ %}
 4792   interface(REG_INTER);
 4793 %}
 4794 
 4795 operand iRegN_R3()
 4796 %{
 4797   constraint(ALLOC_IN_RC(r3_reg));
 4798   match(iRegN);
 4799   op_cost(0);
 4800   format %{ %}
 4801   interface(REG_INTER);
 4802 %}
 4803 
 4804 // Integer 64 bit Register not Special
 4805 operand iRegNNoSp()
 4806 %{
 4807   constraint(ALLOC_IN_RC(no_special_reg32));
 4808   match(RegN);
 4809   op_cost(0);
 4810   format %{ %}
 4811   interface(REG_INTER);
 4812 %}
 4813 
 4814 // heap base register -- used for encoding immN0
 4815 
 4816 operand iRegIHeapbase()
 4817 %{
 4818   constraint(ALLOC_IN_RC(heapbase_reg));
 4819   match(RegI);
 4820   op_cost(0);
 4821   format %{ %}
 4822   interface(REG_INTER);
 4823 %}
 4824 
 4825 // Float Register
 4826 // Float register operands
 4827 operand vRegF()
 4828 %{
 4829   constraint(ALLOC_IN_RC(float_reg));
 4830   match(RegF);
 4831 
 4832   op_cost(0);
 4833   format %{ %}
 4834   interface(REG_INTER);
 4835 %}
 4836 
 4837 // Double Register
 4838 // Double register operands
 4839 operand vRegD()
 4840 %{
 4841   constraint(ALLOC_IN_RC(double_reg));
 4842   match(RegD);
 4843 
 4844   op_cost(0);
 4845   format %{ %}
 4846   interface(REG_INTER);
 4847 %}
 4848 
 4849 operand vecD()
 4850 %{
 4851   constraint(ALLOC_IN_RC(vectord_reg));
 4852   match(VecD);
 4853 
 4854   op_cost(0);
 4855   format %{ %}
 4856   interface(REG_INTER);
 4857 %}
 4858 
 4859 operand vecX()
 4860 %{
 4861   constraint(ALLOC_IN_RC(vectorx_reg));
 4862   match(VecX);
 4863 
 4864   op_cost(0);
 4865   format %{ %}
 4866   interface(REG_INTER);
 4867 %}
 4868 
 4869 operand vRegD_V0()
 4870 %{
 4871   constraint(ALLOC_IN_RC(v0_reg));
 4872   match(RegD);
 4873   op_cost(0);
 4874   format %{ %}
 4875   interface(REG_INTER);
 4876 %}
 4877 
 4878 operand vRegD_V1()
 4879 %{
 4880   constraint(ALLOC_IN_RC(v1_reg));
 4881   match(RegD);
 4882   op_cost(0);
 4883   format %{ %}
 4884   interface(REG_INTER);
 4885 %}
 4886 
 4887 operand vRegD_V2()
 4888 %{
 4889   constraint(ALLOC_IN_RC(v2_reg));
 4890   match(RegD);
 4891   op_cost(0);
 4892   format %{ %}
 4893   interface(REG_INTER);
 4894 %}
 4895 
 4896 operand vRegD_V3()
 4897 %{
 4898   constraint(ALLOC_IN_RC(v3_reg));
 4899   match(RegD);
 4900   op_cost(0);
 4901   format %{ %}
 4902   interface(REG_INTER);
 4903 %}
 4904 
 4905 operand vRegD_V4()
 4906 %{
 4907   constraint(ALLOC_IN_RC(v4_reg));
 4908   match(RegD);
 4909   op_cost(0);
 4910   format %{ %}
 4911   interface(REG_INTER);
 4912 %}
 4913 
 4914 operand vRegD_V5()
 4915 %{
 4916   constraint(ALLOC_IN_RC(v5_reg));
 4917   match(RegD);
 4918   op_cost(0);
 4919   format %{ %}
 4920   interface(REG_INTER);
 4921 %}
 4922 
 4923 operand vRegD_V6()
 4924 %{
 4925   constraint(ALLOC_IN_RC(v6_reg));
 4926   match(RegD);
 4927   op_cost(0);
 4928   format %{ %}
 4929   interface(REG_INTER);
 4930 %}
 4931 
 4932 operand vRegD_V7()
 4933 %{
 4934   constraint(ALLOC_IN_RC(v7_reg));
 4935   match(RegD);
 4936   op_cost(0);
 4937   format %{ %}
 4938   interface(REG_INTER);
 4939 %}
 4940 
 4941 operand vRegD_V8()
 4942 %{
 4943   constraint(ALLOC_IN_RC(v8_reg));
 4944   match(RegD);
 4945   op_cost(0);
 4946   format %{ %}
 4947   interface(REG_INTER);
 4948 %}
 4949 
 4950 operand vRegD_V9()
 4951 %{
 4952   constraint(ALLOC_IN_RC(v9_reg));
 4953   match(RegD);
 4954   op_cost(0);
 4955   format %{ %}
 4956   interface(REG_INTER);
 4957 %}
 4958 
 4959 operand vRegD_V10()
 4960 %{
 4961   constraint(ALLOC_IN_RC(v10_reg));
 4962   match(RegD);
 4963   op_cost(0);
 4964   format %{ %}
 4965   interface(REG_INTER);
 4966 %}
 4967 
 4968 operand vRegD_V11()
 4969 %{
 4970   constraint(ALLOC_IN_RC(v11_reg));
 4971   match(RegD);
 4972   op_cost(0);
 4973   format %{ %}
 4974   interface(REG_INTER);
 4975 %}
 4976 
 4977 operand vRegD_V12()
 4978 %{
 4979   constraint(ALLOC_IN_RC(v12_reg));
 4980   match(RegD);
 4981   op_cost(0);
 4982   format %{ %}
 4983   interface(REG_INTER);
 4984 %}
 4985 
 4986 operand vRegD_V13()
 4987 %{
 4988   constraint(ALLOC_IN_RC(v13_reg));
 4989   match(RegD);
 4990   op_cost(0);
 4991   format %{ %}
 4992   interface(REG_INTER);
 4993 %}
 4994 
 4995 operand vRegD_V14()
 4996 %{
 4997   constraint(ALLOC_IN_RC(v14_reg));
 4998   match(RegD);
 4999   op_cost(0);
 5000   format %{ %}
 5001   interface(REG_INTER);
 5002 %}
 5003 
 5004 operand vRegD_V15()
 5005 %{
 5006   constraint(ALLOC_IN_RC(v15_reg));
 5007   match(RegD);
 5008   op_cost(0);
 5009   format %{ %}
 5010   interface(REG_INTER);
 5011 %}
 5012 
 5013 operand vRegD_V16()
 5014 %{
 5015   constraint(ALLOC_IN_RC(v16_reg));
 5016   match(RegD);
 5017   op_cost(0);
 5018   format %{ %}
 5019   interface(REG_INTER);
 5020 %}
 5021 
 5022 operand vRegD_V17()
 5023 %{
 5024   constraint(ALLOC_IN_RC(v17_reg));
 5025   match(RegD);
 5026   op_cost(0);
 5027   format %{ %}
 5028   interface(REG_INTER);
 5029 %}
 5030 
 5031 operand vRegD_V18()
 5032 %{
 5033   constraint(ALLOC_IN_RC(v18_reg));
 5034   match(RegD);
 5035   op_cost(0);
 5036   format %{ %}
 5037   interface(REG_INTER);
 5038 %}
 5039 
 5040 operand vRegD_V19()
 5041 %{
 5042   constraint(ALLOC_IN_RC(v19_reg));
 5043   match(RegD);
 5044   op_cost(0);
 5045   format %{ %}
 5046   interface(REG_INTER);
 5047 %}
 5048 
 5049 operand vRegD_V20()
 5050 %{
 5051   constraint(ALLOC_IN_RC(v20_reg));
 5052   match(RegD);
 5053   op_cost(0);
 5054   format %{ %}
 5055   interface(REG_INTER);
 5056 %}
 5057 
 5058 operand vRegD_V21()
 5059 %{
 5060   constraint(ALLOC_IN_RC(v21_reg));
 5061   match(RegD);
 5062   op_cost(0);
 5063   format %{ %}
 5064   interface(REG_INTER);
 5065 %}
 5066 
 5067 operand vRegD_V22()
 5068 %{
 5069   constraint(ALLOC_IN_RC(v22_reg));
 5070   match(RegD);
 5071   op_cost(0);
 5072   format %{ %}
 5073   interface(REG_INTER);
 5074 %}
 5075 
 5076 operand vRegD_V23()
 5077 %{
 5078   constraint(ALLOC_IN_RC(v23_reg));
 5079   match(RegD);
 5080   op_cost(0);
 5081   format %{ %}
 5082   interface(REG_INTER);
 5083 %}
 5084 
 5085 operand vRegD_V24()
 5086 %{
 5087   constraint(ALLOC_IN_RC(v24_reg));
 5088   match(RegD);
 5089   op_cost(0);
 5090   format %{ %}
 5091   interface(REG_INTER);
 5092 %}
 5093 
 5094 operand vRegD_V25()
 5095 %{
 5096   constraint(ALLOC_IN_RC(v25_reg));
 5097   match(RegD);
 5098   op_cost(0);
 5099   format %{ %}
 5100   interface(REG_INTER);
 5101 %}
 5102 
 5103 operand vRegD_V26()
 5104 %{
 5105   constraint(ALLOC_IN_RC(v26_reg));
 5106   match(RegD);
 5107   op_cost(0);
 5108   format %{ %}
 5109   interface(REG_INTER);
 5110 %}
 5111 
 5112 operand vRegD_V27()
 5113 %{
 5114   constraint(ALLOC_IN_RC(v27_reg));
 5115   match(RegD);
 5116   op_cost(0);
 5117   format %{ %}
 5118   interface(REG_INTER);
 5119 %}
 5120 
 5121 operand vRegD_V28()
 5122 %{
 5123   constraint(ALLOC_IN_RC(v28_reg));
 5124   match(RegD);
 5125   op_cost(0);
 5126   format %{ %}
 5127   interface(REG_INTER);
 5128 %}
 5129 
 5130 operand vRegD_V29()
 5131 %{
 5132   constraint(ALLOC_IN_RC(v29_reg));
 5133   match(RegD);
 5134   op_cost(0);
 5135   format %{ %}
 5136   interface(REG_INTER);
 5137 %}
 5138 
 5139 operand vRegD_V30()
 5140 %{
 5141   constraint(ALLOC_IN_RC(v30_reg));
 5142   match(RegD);
 5143   op_cost(0);
 5144   format %{ %}
 5145   interface(REG_INTER);
 5146 %}
 5147 
 5148 operand vRegD_V31()
 5149 %{
 5150   constraint(ALLOC_IN_RC(v31_reg));
 5151   match(RegD);
 5152   op_cost(0);
 5153   format %{ %}
 5154   interface(REG_INTER);
 5155 %}
 5156 
 5157 // Flags register, used as output of signed compare instructions
 5158 
 5159 // note that on AArch64 we also use this register as the output for
 5160 // for floating point compare instructions (CmpF CmpD). this ensures
 5161 // that ordered inequality tests use GT, GE, LT or LE none of which
 5162 // pass through cases where the result is unordered i.e. one or both
 5163 // inputs to the compare is a NaN. this means that the ideal code can
 5164 // replace e.g. a GT with an LE and not end up capturing the NaN case
 5165 // (where the comparison should always fail). EQ and NE tests are
 5166 // always generated in ideal code so that unordered folds into the NE
 5167 // case, matching the behaviour of AArch64 NE.
 5168 //
 5169 // This differs from x86 where the outputs of FP compares use a
 5170 // special FP flags registers and where compares based on this
 5171 // register are distinguished into ordered inequalities (cmpOpUCF) and
 5172 // EQ/NEQ tests (cmpOpUCF2). x86 has to special case the latter tests
 5173 // to explicitly handle the unordered case in branches. x86 also has
 5174 // to include extra CMoveX rules to accept a cmpOpUCF input.
 5175 
 5176 operand rFlagsReg()
 5177 %{
 5178   constraint(ALLOC_IN_RC(int_flags));
 5179   match(RegFlags);
 5180 
 5181   op_cost(0);
 5182   format %{ &quot;RFLAGS&quot; %}
 5183   interface(REG_INTER);
 5184 %}
 5185 
 5186 // Flags register, used as output of unsigned compare instructions
 5187 operand rFlagsRegU()
 5188 %{
 5189   constraint(ALLOC_IN_RC(int_flags));
 5190   match(RegFlags);
 5191 
 5192   op_cost(0);
 5193   format %{ &quot;RFLAGSU&quot; %}
 5194   interface(REG_INTER);
 5195 %}
 5196 
 5197 // Special Registers
 5198 
 5199 // Method Register
 5200 operand inline_cache_RegP(iRegP reg)
 5201 %{
 5202   constraint(ALLOC_IN_RC(method_reg)); // inline_cache_reg
 5203   match(reg);
 5204   match(iRegPNoSp);
 5205   op_cost(0);
 5206   format %{ %}
 5207   interface(REG_INTER);
 5208 %}
 5209 
 5210 operand interpreter_method_oop_RegP(iRegP reg)
 5211 %{
 5212   constraint(ALLOC_IN_RC(method_reg)); // interpreter_method_oop_reg
 5213   match(reg);
 5214   match(iRegPNoSp);
 5215   op_cost(0);
 5216   format %{ %}
 5217   interface(REG_INTER);
 5218 %}
 5219 
 5220 // Thread Register
 5221 operand thread_RegP(iRegP reg)
 5222 %{
 5223   constraint(ALLOC_IN_RC(thread_reg)); // link_reg
 5224   match(reg);
 5225   op_cost(0);
 5226   format %{ %}
 5227   interface(REG_INTER);
 5228 %}
 5229 
 5230 operand lr_RegP(iRegP reg)
 5231 %{
 5232   constraint(ALLOC_IN_RC(lr_reg)); // link_reg
 5233   match(reg);
 5234   op_cost(0);
 5235   format %{ %}
 5236   interface(REG_INTER);
 5237 %}
 5238 
 5239 //----------Memory Operands----------------------------------------------------
 5240 
 5241 operand indirect(iRegP reg)
 5242 %{
 5243   constraint(ALLOC_IN_RC(ptr_reg));
 5244   match(reg);
 5245   op_cost(0);
 5246   format %{ &quot;[$reg]&quot; %}
 5247   interface(MEMORY_INTER) %{
 5248     base($reg);
 5249     index(0xffffffff);
 5250     scale(0x0);
 5251     disp(0x0);
 5252   %}
 5253 %}
 5254 
 5255 operand indIndexScaledI2L(iRegP reg, iRegI ireg, immIScale scale)
 5256 %{
 5257   constraint(ALLOC_IN_RC(ptr_reg));
 5258   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5259   match(AddP reg (LShiftL (ConvI2L ireg) scale));
 5260   op_cost(0);
 5261   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L&quot; %}
 5262   interface(MEMORY_INTER) %{
 5263     base($reg);
 5264     index($ireg);
 5265     scale($scale);
 5266     disp(0x0);
 5267   %}
 5268 %}
 5269 
 5270 operand indIndexScaled(iRegP reg, iRegL lreg, immIScale scale)
 5271 %{
 5272   constraint(ALLOC_IN_RC(ptr_reg));
 5273   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5274   match(AddP reg (LShiftL lreg scale));
 5275   op_cost(0);
 5276   format %{ &quot;$reg, $lreg lsl($scale)&quot; %}
 5277   interface(MEMORY_INTER) %{
 5278     base($reg);
 5279     index($lreg);
 5280     scale($scale);
 5281     disp(0x0);
 5282   %}
 5283 %}
 5284 
 5285 operand indIndexI2L(iRegP reg, iRegI ireg)
 5286 %{
 5287   constraint(ALLOC_IN_RC(ptr_reg));
 5288   match(AddP reg (ConvI2L ireg));
 5289   op_cost(0);
 5290   format %{ &quot;$reg, $ireg, 0, I2L&quot; %}
 5291   interface(MEMORY_INTER) %{
 5292     base($reg);
 5293     index($ireg);
 5294     scale(0x0);
 5295     disp(0x0);
 5296   %}
 5297 %}
 5298 
 5299 operand indIndex(iRegP reg, iRegL lreg)
 5300 %{
 5301   constraint(ALLOC_IN_RC(ptr_reg));
 5302   match(AddP reg lreg);
 5303   op_cost(0);
 5304   format %{ &quot;$reg, $lreg&quot; %}
 5305   interface(MEMORY_INTER) %{
 5306     base($reg);
 5307     index($lreg);
 5308     scale(0x0);
 5309     disp(0x0);
 5310   %}
 5311 %}
 5312 
 5313 operand indOffI(iRegP reg, immIOffset off)
 5314 %{
 5315   constraint(ALLOC_IN_RC(ptr_reg));
 5316   match(AddP reg off);
 5317   op_cost(0);
 5318   format %{ &quot;[$reg, $off]&quot; %}
 5319   interface(MEMORY_INTER) %{
 5320     base($reg);
 5321     index(0xffffffff);
 5322     scale(0x0);
 5323     disp($off);
 5324   %}
 5325 %}
 5326 
 5327 operand indOffI1(iRegP reg, immIOffset1 off)
 5328 %{
 5329   constraint(ALLOC_IN_RC(ptr_reg));
 5330   match(AddP reg off);
 5331   op_cost(0);
 5332   format %{ &quot;[$reg, $off]&quot; %}
 5333   interface(MEMORY_INTER) %{
 5334     base($reg);
 5335     index(0xffffffff);
 5336     scale(0x0);
 5337     disp($off);
 5338   %}
 5339 %}
 5340 
 5341 operand indOffI2(iRegP reg, immIOffset2 off)
 5342 %{
 5343   constraint(ALLOC_IN_RC(ptr_reg));
 5344   match(AddP reg off);
 5345   op_cost(0);
 5346   format %{ &quot;[$reg, $off]&quot; %}
 5347   interface(MEMORY_INTER) %{
 5348     base($reg);
 5349     index(0xffffffff);
 5350     scale(0x0);
 5351     disp($off);
 5352   %}
 5353 %}
 5354 
 5355 operand indOffI4(iRegP reg, immIOffset4 off)
 5356 %{
 5357   constraint(ALLOC_IN_RC(ptr_reg));
 5358   match(AddP reg off);
 5359   op_cost(0);
 5360   format %{ &quot;[$reg, $off]&quot; %}
 5361   interface(MEMORY_INTER) %{
 5362     base($reg);
 5363     index(0xffffffff);
 5364     scale(0x0);
 5365     disp($off);
 5366   %}
 5367 %}
 5368 
 5369 operand indOffI8(iRegP reg, immIOffset8 off)
 5370 %{
 5371   constraint(ALLOC_IN_RC(ptr_reg));
 5372   match(AddP reg off);
 5373   op_cost(0);
 5374   format %{ &quot;[$reg, $off]&quot; %}
 5375   interface(MEMORY_INTER) %{
 5376     base($reg);
 5377     index(0xffffffff);
 5378     scale(0x0);
 5379     disp($off);
 5380   %}
 5381 %}
 5382 
 5383 operand indOffI16(iRegP reg, immIOffset16 off)
 5384 %{
 5385   constraint(ALLOC_IN_RC(ptr_reg));
 5386   match(AddP reg off);
 5387   op_cost(0);
 5388   format %{ &quot;[$reg, $off]&quot; %}
 5389   interface(MEMORY_INTER) %{
 5390     base($reg);
 5391     index(0xffffffff);
 5392     scale(0x0);
 5393     disp($off);
 5394   %}
 5395 %}
 5396 
 5397 operand indOffL(iRegP reg, immLoffset off)
 5398 %{
 5399   constraint(ALLOC_IN_RC(ptr_reg));
 5400   match(AddP reg off);
 5401   op_cost(0);
 5402   format %{ &quot;[$reg, $off]&quot; %}
 5403   interface(MEMORY_INTER) %{
 5404     base($reg);
 5405     index(0xffffffff);
 5406     scale(0x0);
 5407     disp($off);
 5408   %}
 5409 %}
 5410 
 5411 operand indOffL1(iRegP reg, immLoffset1 off)
 5412 %{
 5413   constraint(ALLOC_IN_RC(ptr_reg));
 5414   match(AddP reg off);
 5415   op_cost(0);
 5416   format %{ &quot;[$reg, $off]&quot; %}
 5417   interface(MEMORY_INTER) %{
 5418     base($reg);
 5419     index(0xffffffff);
 5420     scale(0x0);
 5421     disp($off);
 5422   %}
 5423 %}
 5424 
 5425 operand indOffL2(iRegP reg, immLoffset2 off)
 5426 %{
 5427   constraint(ALLOC_IN_RC(ptr_reg));
 5428   match(AddP reg off);
 5429   op_cost(0);
 5430   format %{ &quot;[$reg, $off]&quot; %}
 5431   interface(MEMORY_INTER) %{
 5432     base($reg);
 5433     index(0xffffffff);
 5434     scale(0x0);
 5435     disp($off);
 5436   %}
 5437 %}
 5438 
 5439 operand indOffL4(iRegP reg, immLoffset4 off)
 5440 %{
 5441   constraint(ALLOC_IN_RC(ptr_reg));
 5442   match(AddP reg off);
 5443   op_cost(0);
 5444   format %{ &quot;[$reg, $off]&quot; %}
 5445   interface(MEMORY_INTER) %{
 5446     base($reg);
 5447     index(0xffffffff);
 5448     scale(0x0);
 5449     disp($off);
 5450   %}
 5451 %}
 5452 
 5453 operand indOffL8(iRegP reg, immLoffset8 off)
 5454 %{
 5455   constraint(ALLOC_IN_RC(ptr_reg));
 5456   match(AddP reg off);
 5457   op_cost(0);
 5458   format %{ &quot;[$reg, $off]&quot; %}
 5459   interface(MEMORY_INTER) %{
 5460     base($reg);
 5461     index(0xffffffff);
 5462     scale(0x0);
 5463     disp($off);
 5464   %}
 5465 %}
 5466 
 5467 operand indOffL16(iRegP reg, immLoffset16 off)
 5468 %{
 5469   constraint(ALLOC_IN_RC(ptr_reg));
 5470   match(AddP reg off);
 5471   op_cost(0);
 5472   format %{ &quot;[$reg, $off]&quot; %}
 5473   interface(MEMORY_INTER) %{
 5474     base($reg);
 5475     index(0xffffffff);
 5476     scale(0x0);
 5477     disp($off);
 5478   %}
 5479 %}
 5480 
 5481 operand indirectN(iRegN reg)
 5482 %{
 5483   predicate(CompressedOops::shift() == 0);
 5484   constraint(ALLOC_IN_RC(ptr_reg));
 5485   match(DecodeN reg);
 5486   op_cost(0);
 5487   format %{ &quot;[$reg]\t# narrow&quot; %}
 5488   interface(MEMORY_INTER) %{
 5489     base($reg);
 5490     index(0xffffffff);
 5491     scale(0x0);
 5492     disp(0x0);
 5493   %}
 5494 %}
 5495 
 5496 operand indIndexScaledI2LN(iRegN reg, iRegI ireg, immIScale scale)
 5497 %{
 5498   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5499   constraint(ALLOC_IN_RC(ptr_reg));
 5500   match(AddP (DecodeN reg) (LShiftL (ConvI2L ireg) scale));
 5501   op_cost(0);
 5502   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L\t# narrow&quot; %}
 5503   interface(MEMORY_INTER) %{
 5504     base($reg);
 5505     index($ireg);
 5506     scale($scale);
 5507     disp(0x0);
 5508   %}
 5509 %}
 5510 
 5511 operand indIndexScaledN(iRegN reg, iRegL lreg, immIScale scale)
 5512 %{
 5513   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5514   constraint(ALLOC_IN_RC(ptr_reg));
 5515   match(AddP (DecodeN reg) (LShiftL lreg scale));
 5516   op_cost(0);
 5517   format %{ &quot;$reg, $lreg lsl($scale)\t# narrow&quot; %}
 5518   interface(MEMORY_INTER) %{
 5519     base($reg);
 5520     index($lreg);
 5521     scale($scale);
 5522     disp(0x0);
 5523   %}
 5524 %}
 5525 
 5526 operand indIndexI2LN(iRegN reg, iRegI ireg)
 5527 %{
 5528   predicate(CompressedOops::shift() == 0);
 5529   constraint(ALLOC_IN_RC(ptr_reg));
 5530   match(AddP (DecodeN reg) (ConvI2L ireg));
 5531   op_cost(0);
 5532   format %{ &quot;$reg, $ireg, 0, I2L\t# narrow&quot; %}
 5533   interface(MEMORY_INTER) %{
 5534     base($reg);
 5535     index($ireg);
 5536     scale(0x0);
 5537     disp(0x0);
 5538   %}
 5539 %}
 5540 
 5541 operand indIndexN(iRegN reg, iRegL lreg)
 5542 %{
 5543   predicate(CompressedOops::shift() == 0);
 5544   constraint(ALLOC_IN_RC(ptr_reg));
 5545   match(AddP (DecodeN reg) lreg);
 5546   op_cost(0);
 5547   format %{ &quot;$reg, $lreg\t# narrow&quot; %}
 5548   interface(MEMORY_INTER) %{
 5549     base($reg);
 5550     index($lreg);
 5551     scale(0x0);
 5552     disp(0x0);
 5553   %}
 5554 %}
 5555 
 5556 operand indOffIN(iRegN reg, immIOffset off)
 5557 %{
 5558   predicate(CompressedOops::shift() == 0);
 5559   constraint(ALLOC_IN_RC(ptr_reg));
 5560   match(AddP (DecodeN reg) off);
 5561   op_cost(0);
 5562   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5563   interface(MEMORY_INTER) %{
 5564     base($reg);
 5565     index(0xffffffff);
 5566     scale(0x0);
 5567     disp($off);
 5568   %}
 5569 %}
 5570 
 5571 operand indOffLN(iRegN reg, immLoffset off)
 5572 %{
 5573   predicate(CompressedOops::shift() == 0);
 5574   constraint(ALLOC_IN_RC(ptr_reg));
 5575   match(AddP (DecodeN reg) off);
 5576   op_cost(0);
 5577   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5578   interface(MEMORY_INTER) %{
 5579     base($reg);
 5580     index(0xffffffff);
 5581     scale(0x0);
 5582     disp($off);
 5583   %}
 5584 %}
 5585 
 5586 
 5587 
 5588 // AArch64 opto stubs need to write to the pc slot in the thread anchor
 5589 operand thread_anchor_pc(thread_RegP reg, immL_pc_off off)
 5590 %{
 5591   constraint(ALLOC_IN_RC(ptr_reg));
 5592   match(AddP reg off);
 5593   op_cost(0);
 5594   format %{ &quot;[$reg, $off]&quot; %}
 5595   interface(MEMORY_INTER) %{
 5596     base($reg);
 5597     index(0xffffffff);
 5598     scale(0x0);
 5599     disp($off);
 5600   %}
 5601 %}
 5602 
 5603 //----------Special Memory Operands--------------------------------------------
 5604 // Stack Slot Operand - This operand is used for loading and storing temporary
 5605 //                      values on the stack where a match requires a value to
 5606 //                      flow through memory.
 5607 operand stackSlotP(sRegP reg)
 5608 %{
 5609   constraint(ALLOC_IN_RC(stack_slots));
 5610   op_cost(100);
 5611   // No match rule because this operand is only generated in matching
 5612   // match(RegP);
 5613   format %{ &quot;[$reg]&quot; %}
 5614   interface(MEMORY_INTER) %{
 5615     base(0x1e);  // RSP
 5616     index(0x0);  // No Index
 5617     scale(0x0);  // No Scale
 5618     disp($reg);  // Stack Offset
 5619   %}
 5620 %}
 5621 
 5622 operand stackSlotI(sRegI reg)
 5623 %{
 5624   constraint(ALLOC_IN_RC(stack_slots));
 5625   // No match rule because this operand is only generated in matching
 5626   // match(RegI);
 5627   format %{ &quot;[$reg]&quot; %}
 5628   interface(MEMORY_INTER) %{
 5629     base(0x1e);  // RSP
 5630     index(0x0);  // No Index
 5631     scale(0x0);  // No Scale
 5632     disp($reg);  // Stack Offset
 5633   %}
 5634 %}
 5635 
 5636 operand stackSlotF(sRegF reg)
 5637 %{
 5638   constraint(ALLOC_IN_RC(stack_slots));
 5639   // No match rule because this operand is only generated in matching
 5640   // match(RegF);
 5641   format %{ &quot;[$reg]&quot; %}
 5642   interface(MEMORY_INTER) %{
 5643     base(0x1e);  // RSP
 5644     index(0x0);  // No Index
 5645     scale(0x0);  // No Scale
 5646     disp($reg);  // Stack Offset
 5647   %}
 5648 %}
 5649 
 5650 operand stackSlotD(sRegD reg)
 5651 %{
 5652   constraint(ALLOC_IN_RC(stack_slots));
 5653   // No match rule because this operand is only generated in matching
 5654   // match(RegD);
 5655   format %{ &quot;[$reg]&quot; %}
 5656   interface(MEMORY_INTER) %{
 5657     base(0x1e);  // RSP
 5658     index(0x0);  // No Index
 5659     scale(0x0);  // No Scale
 5660     disp($reg);  // Stack Offset
 5661   %}
 5662 %}
 5663 
 5664 operand stackSlotL(sRegL reg)
 5665 %{
 5666   constraint(ALLOC_IN_RC(stack_slots));
 5667   // No match rule because this operand is only generated in matching
 5668   // match(RegL);
 5669   format %{ &quot;[$reg]&quot; %}
 5670   interface(MEMORY_INTER) %{
 5671     base(0x1e);  // RSP
 5672     index(0x0);  // No Index
 5673     scale(0x0);  // No Scale
 5674     disp($reg);  // Stack Offset
 5675   %}
 5676 %}
 5677 
 5678 // Operands for expressing Control Flow
 5679 // NOTE: Label is a predefined operand which should not be redefined in
 5680 //       the AD file. It is generically handled within the ADLC.
 5681 
 5682 //----------Conditional Branch Operands----------------------------------------
 5683 // Comparison Op  - This is the operation of the comparison, and is limited to
 5684 //                  the following set of codes:
 5685 //                  L (&lt;), LE (&lt;=), G (&gt;), GE (&gt;=), E (==), NE (!=)
 5686 //
 5687 // Other attributes of the comparison, such as unsignedness, are specified
 5688 // by the comparison instruction that sets a condition code flags register.
 5689 // That result is represented by a flags operand whose subtype is appropriate
 5690 // to the unsignedness (etc.) of the comparison.
 5691 //
 5692 // Later, the instruction which matches both the Comparison Op (a Bool) and
 5693 // the flags (produced by the Cmp) specifies the coding of the comparison op
 5694 // by matching a specific subtype of Bool operand below, such as cmpOpU.
 5695 
 5696 // used for signed integral comparisons and fp comparisons
 5697 
 5698 operand cmpOp()
 5699 %{
 5700   match(Bool);
 5701 
 5702   format %{ &quot;&quot; %}
 5703   interface(COND_INTER) %{
 5704     equal(0x0, &quot;eq&quot;);
 5705     not_equal(0x1, &quot;ne&quot;);
 5706     less(0xb, &quot;lt&quot;);
 5707     greater_equal(0xa, &quot;ge&quot;);
 5708     less_equal(0xd, &quot;le&quot;);
 5709     greater(0xc, &quot;gt&quot;);
 5710     overflow(0x6, &quot;vs&quot;);
 5711     no_overflow(0x7, &quot;vc&quot;);
 5712   %}
 5713 %}
 5714 
 5715 // used for unsigned integral comparisons
 5716 
 5717 operand cmpOpU()
 5718 %{
 5719   match(Bool);
 5720 
 5721   format %{ &quot;&quot; %}
 5722   interface(COND_INTER) %{
 5723     equal(0x0, &quot;eq&quot;);
 5724     not_equal(0x1, &quot;ne&quot;);
 5725     less(0x3, &quot;lo&quot;);
 5726     greater_equal(0x2, &quot;hs&quot;);
 5727     less_equal(0x9, &quot;ls&quot;);
 5728     greater(0x8, &quot;hi&quot;);
 5729     overflow(0x6, &quot;vs&quot;);
 5730     no_overflow(0x7, &quot;vc&quot;);
 5731   %}
 5732 %}
 5733 
 5734 // used for certain integral comparisons which can be
 5735 // converted to cbxx or tbxx instructions
 5736 
 5737 operand cmpOpEqNe()
 5738 %{
 5739   match(Bool);
 5740   op_cost(0);
 5741   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5742             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq);
 5743 
 5744   format %{ &quot;&quot; %}
 5745   interface(COND_INTER) %{
 5746     equal(0x0, &quot;eq&quot;);
 5747     not_equal(0x1, &quot;ne&quot;);
 5748     less(0xb, &quot;lt&quot;);
 5749     greater_equal(0xa, &quot;ge&quot;);
 5750     less_equal(0xd, &quot;le&quot;);
 5751     greater(0xc, &quot;gt&quot;);
 5752     overflow(0x6, &quot;vs&quot;);
 5753     no_overflow(0x7, &quot;vc&quot;);
 5754   %}
 5755 %}
 5756 
 5757 // used for certain integral comparisons which can be
 5758 // converted to cbxx or tbxx instructions
 5759 
 5760 operand cmpOpLtGe()
 5761 %{
 5762   match(Bool);
 5763   op_cost(0);
 5764 
 5765   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5766             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5767 
 5768   format %{ &quot;&quot; %}
 5769   interface(COND_INTER) %{
 5770     equal(0x0, &quot;eq&quot;);
 5771     not_equal(0x1, &quot;ne&quot;);
 5772     less(0xb, &quot;lt&quot;);
 5773     greater_equal(0xa, &quot;ge&quot;);
 5774     less_equal(0xd, &quot;le&quot;);
 5775     greater(0xc, &quot;gt&quot;);
 5776     overflow(0x6, &quot;vs&quot;);
 5777     no_overflow(0x7, &quot;vc&quot;);
 5778   %}
 5779 %}
 5780 
 5781 // used for certain unsigned integral comparisons which can be
 5782 // converted to cbxx or tbxx instructions
 5783 
 5784 operand cmpOpUEqNeLtGe()
 5785 %{
 5786   match(Bool);
 5787   op_cost(0);
 5788 
 5789   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq
 5790             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5791             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5792             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5793 
 5794   format %{ &quot;&quot; %}
 5795   interface(COND_INTER) %{
 5796     equal(0x0, &quot;eq&quot;);
 5797     not_equal(0x1, &quot;ne&quot;);
 5798     less(0xb, &quot;lt&quot;);
 5799     greater_equal(0xa, &quot;ge&quot;);
 5800     less_equal(0xd, &quot;le&quot;);
 5801     greater(0xc, &quot;gt&quot;);
 5802     overflow(0x6, &quot;vs&quot;);
 5803     no_overflow(0x7, &quot;vc&quot;);
 5804   %}
 5805 %}
 5806 
 5807 // Special operand allowing long args to int ops to be truncated for free
 5808 
 5809 operand iRegL2I(iRegL reg) %{
 5810 
 5811   op_cost(0);
 5812 
 5813   match(ConvL2I reg);
 5814 
 5815   format %{ &quot;l2i($reg)&quot; %}
 5816 
 5817   interface(REG_INTER)
 5818 %}
 5819 
 5820 opclass vmem4(indirect, indIndex, indOffI4, indOffL4);
 5821 opclass vmem8(indirect, indIndex, indOffI8, indOffL8);
 5822 opclass vmem16(indirect, indIndex, indOffI16, indOffL16);
 5823 
 5824 //----------OPERAND CLASSES----------------------------------------------------
 5825 // Operand Classes are groups of operands that are used as to simplify
 5826 // instruction definitions by not requiring the AD writer to specify
 5827 // separate instructions for every form of operand when the
 5828 // instruction accepts multiple operand types with the same basic
 5829 // encoding and format. The classic case of this is memory operands.
 5830 
 5831 // memory is used to define read/write location for load/store
 5832 // instruction defs. we can turn a memory op into an Address
 5833 
 5834 opclass memory1(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI1, indOffL1,
 5835                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5836 
 5837 opclass memory2(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI2, indOffL2,
 5838                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5839 
 5840 opclass memory4(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI4, indOffL4,
 5841                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5842 
 5843 opclass memory8(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI8, indOffL8,
 5844                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5845 
 5846 // All of the memory operands. For the pipeline description.
 5847 opclass memory(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex,
 5848                indOffI1, indOffL1, indOffI2, indOffL2, indOffI4, indOffL4, indOffI8, indOffL8,
 5849                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5850 
 5851 
 5852 // iRegIorL2I is used for src inputs in rules for 32 bit int (I)
 5853 // operations. it allows the src to be either an iRegI or a (ConvL2I
 5854 // iRegL). in the latter case the l2i normally planted for a ConvL2I
 5855 // can be elided because the 32-bit instruction will just employ the
 5856 // lower 32 bits anyway.
 5857 //
 5858 // n.b. this does not elide all L2I conversions. if the truncated
 5859 // value is consumed by more than one operation then the ConvL2I
 5860 // cannot be bundled into the consuming nodes so an l2i gets planted
 5861 // (actually a movw $dst $src) and the downstream instructions consume
 5862 // the result of the l2i as an iRegI input. That&#39;s a shame since the
 5863 // movw is actually redundant but its not too costly.
 5864 
 5865 opclass iRegIorL2I(iRegI, iRegL2I);
 5866 
 5867 //----------PIPELINE-----------------------------------------------------------
 5868 // Rules which define the behavior of the target architectures pipeline.
 5869 
 5870 // For specific pipelines, eg A53, define the stages of that pipeline
 5871 //pipe_desc(ISS, EX1, EX2, WR);
 5872 #define ISS S0
 5873 #define EX1 S1
 5874 #define EX2 S2
 5875 #define WR  S3
 5876 
 5877 // Integer ALU reg operation
 5878 pipeline %{
 5879 
 5880 attributes %{
 5881   // ARM instructions are of fixed length
 5882   fixed_size_instructions;        // Fixed size instructions TODO does
 5883   max_instructions_per_bundle = 2;   // A53 = 2, A57 = 4
 5884   // ARM instructions come in 32-bit word units
 5885   instruction_unit_size = 4;         // An instruction is 4 bytes long
 5886   instruction_fetch_unit_size = 64;  // The processor fetches one line
 5887   instruction_fetch_units = 1;       // of 64 bytes
 5888 
 5889   // List of nop instructions
 5890   nops( MachNop );
 5891 %}
 5892 
 5893 // We don&#39;t use an actual pipeline model so don&#39;t care about resources
 5894 // or description. we do use pipeline classes to introduce fixed
 5895 // latencies
 5896 
 5897 //----------RESOURCES----------------------------------------------------------
 5898 // Resources are the functional units available to the machine
 5899 
 5900 resources( INS0, INS1, INS01 = INS0 | INS1,
 5901            ALU0, ALU1, ALU = ALU0 | ALU1,
 5902            MAC,
 5903            DIV,
 5904            BRANCH,
 5905            LDST,
 5906            NEON_FP);
 5907 
 5908 //----------PIPELINE DESCRIPTION-----------------------------------------------
 5909 // Pipeline Description specifies the stages in the machine&#39;s pipeline
 5910 
 5911 // Define the pipeline as a generic 6 stage pipeline
 5912 pipe_desc(S0, S1, S2, S3, S4, S5);
 5913 
 5914 //----------PIPELINE CLASSES---------------------------------------------------
 5915 // Pipeline Classes describe the stages in which input and output are
 5916 // referenced by the hardware pipeline.
 5917 
 5918 pipe_class fp_dop_reg_reg_s(vRegF dst, vRegF src1, vRegF src2)
 5919 %{
 5920   single_instruction;
 5921   src1   : S1(read);
 5922   src2   : S2(read);
 5923   dst    : S5(write);
 5924   INS01  : ISS;
 5925   NEON_FP : S5;
 5926 %}
 5927 
 5928 pipe_class fp_dop_reg_reg_d(vRegD dst, vRegD src1, vRegD src2)
 5929 %{
 5930   single_instruction;
 5931   src1   : S1(read);
 5932   src2   : S2(read);
 5933   dst    : S5(write);
 5934   INS01  : ISS;
 5935   NEON_FP : S5;
 5936 %}
 5937 
 5938 pipe_class fp_uop_s(vRegF dst, vRegF src)
 5939 %{
 5940   single_instruction;
 5941   src    : S1(read);
 5942   dst    : S5(write);
 5943   INS01  : ISS;
 5944   NEON_FP : S5;
 5945 %}
 5946 
 5947 pipe_class fp_uop_d(vRegD dst, vRegD src)
 5948 %{
 5949   single_instruction;
 5950   src    : S1(read);
 5951   dst    : S5(write);
 5952   INS01  : ISS;
 5953   NEON_FP : S5;
 5954 %}
 5955 
 5956 pipe_class fp_d2f(vRegF dst, vRegD src)
 5957 %{
 5958   single_instruction;
 5959   src    : S1(read);
 5960   dst    : S5(write);
 5961   INS01  : ISS;
 5962   NEON_FP : S5;
 5963 %}
 5964 
 5965 pipe_class fp_f2d(vRegD dst, vRegF src)
 5966 %{
 5967   single_instruction;
 5968   src    : S1(read);
 5969   dst    : S5(write);
 5970   INS01  : ISS;
 5971   NEON_FP : S5;
 5972 %}
 5973 
 5974 pipe_class fp_f2i(iRegINoSp dst, vRegF src)
 5975 %{
 5976   single_instruction;
 5977   src    : S1(read);
 5978   dst    : S5(write);
 5979   INS01  : ISS;
 5980   NEON_FP : S5;
 5981 %}
 5982 
 5983 pipe_class fp_f2l(iRegLNoSp dst, vRegF src)
 5984 %{
 5985   single_instruction;
 5986   src    : S1(read);
 5987   dst    : S5(write);
 5988   INS01  : ISS;
 5989   NEON_FP : S5;
 5990 %}
 5991 
 5992 pipe_class fp_i2f(vRegF dst, iRegIorL2I src)
 5993 %{
 5994   single_instruction;
 5995   src    : S1(read);
 5996   dst    : S5(write);
 5997   INS01  : ISS;
 5998   NEON_FP : S5;
 5999 %}
 6000 
 6001 pipe_class fp_l2f(vRegF dst, iRegL src)
 6002 %{
 6003   single_instruction;
 6004   src    : S1(read);
 6005   dst    : S5(write);
 6006   INS01  : ISS;
 6007   NEON_FP : S5;
 6008 %}
 6009 
 6010 pipe_class fp_d2i(iRegINoSp dst, vRegD src)
 6011 %{
 6012   single_instruction;
 6013   src    : S1(read);
 6014   dst    : S5(write);
 6015   INS01  : ISS;
 6016   NEON_FP : S5;
 6017 %}
 6018 
 6019 pipe_class fp_d2l(iRegLNoSp dst, vRegD src)
 6020 %{
 6021   single_instruction;
 6022   src    : S1(read);
 6023   dst    : S5(write);
 6024   INS01  : ISS;
 6025   NEON_FP : S5;
 6026 %}
 6027 
 6028 pipe_class fp_i2d(vRegD dst, iRegIorL2I src)
 6029 %{
 6030   single_instruction;
 6031   src    : S1(read);
 6032   dst    : S5(write);
 6033   INS01  : ISS;
 6034   NEON_FP : S5;
 6035 %}
 6036 
 6037 pipe_class fp_l2d(vRegD dst, iRegIorL2I src)
 6038 %{
 6039   single_instruction;
 6040   src    : S1(read);
 6041   dst    : S5(write);
 6042   INS01  : ISS;
 6043   NEON_FP : S5;
 6044 %}
 6045 
 6046 pipe_class fp_div_s(vRegF dst, vRegF src1, vRegF src2)
 6047 %{
 6048   single_instruction;
 6049   src1   : S1(read);
 6050   src2   : S2(read);
 6051   dst    : S5(write);
 6052   INS0   : ISS;
 6053   NEON_FP : S5;
 6054 %}
 6055 
 6056 pipe_class fp_div_d(vRegD dst, vRegD src1, vRegD src2)
 6057 %{
 6058   single_instruction;
 6059   src1   : S1(read);
 6060   src2   : S2(read);
 6061   dst    : S5(write);
 6062   INS0   : ISS;
 6063   NEON_FP : S5;
 6064 %}
 6065 
 6066 pipe_class fp_cond_reg_reg_s(vRegF dst, vRegF src1, vRegF src2, rFlagsReg cr)
 6067 %{
 6068   single_instruction;
 6069   cr     : S1(read);
 6070   src1   : S1(read);
 6071   src2   : S1(read);
 6072   dst    : S3(write);
 6073   INS01  : ISS;
 6074   NEON_FP : S3;
 6075 %}
 6076 
 6077 pipe_class fp_cond_reg_reg_d(vRegD dst, vRegD src1, vRegD src2, rFlagsReg cr)
 6078 %{
 6079   single_instruction;
 6080   cr     : S1(read);
 6081   src1   : S1(read);
 6082   src2   : S1(read);
 6083   dst    : S3(write);
 6084   INS01  : ISS;
 6085   NEON_FP : S3;
 6086 %}
 6087 
 6088 pipe_class fp_imm_s(vRegF dst)
 6089 %{
 6090   single_instruction;
 6091   dst    : S3(write);
 6092   INS01  : ISS;
 6093   NEON_FP : S3;
 6094 %}
 6095 
 6096 pipe_class fp_imm_d(vRegD dst)
 6097 %{
 6098   single_instruction;
 6099   dst    : S3(write);
 6100   INS01  : ISS;
 6101   NEON_FP : S3;
 6102 %}
 6103 
 6104 pipe_class fp_load_constant_s(vRegF dst)
 6105 %{
 6106   single_instruction;
 6107   dst    : S4(write);
 6108   INS01  : ISS;
 6109   NEON_FP : S4;
 6110 %}
 6111 
 6112 pipe_class fp_load_constant_d(vRegD dst)
 6113 %{
 6114   single_instruction;
 6115   dst    : S4(write);
 6116   INS01  : ISS;
 6117   NEON_FP : S4;
 6118 %}
 6119 
 6120 pipe_class vmul64(vecD dst, vecD src1, vecD src2)
 6121 %{
 6122   single_instruction;
 6123   dst    : S5(write);
 6124   src1   : S1(read);
 6125   src2   : S1(read);
 6126   INS01  : ISS;
 6127   NEON_FP : S5;
 6128 %}
 6129 
 6130 pipe_class vmul128(vecX dst, vecX src1, vecX src2)
 6131 %{
 6132   single_instruction;
 6133   dst    : S5(write);
 6134   src1   : S1(read);
 6135   src2   : S1(read);
 6136   INS0   : ISS;
 6137   NEON_FP : S5;
 6138 %}
 6139 
 6140 pipe_class vmla64(vecD dst, vecD src1, vecD src2)
 6141 %{
 6142   single_instruction;
 6143   dst    : S5(write);
 6144   src1   : S1(read);
 6145   src2   : S1(read);
 6146   dst    : S1(read);
 6147   INS01  : ISS;
 6148   NEON_FP : S5;
 6149 %}
 6150 
 6151 pipe_class vmla128(vecX dst, vecX src1, vecX src2)
 6152 %{
 6153   single_instruction;
 6154   dst    : S5(write);
 6155   src1   : S1(read);
 6156   src2   : S1(read);
 6157   dst    : S1(read);
 6158   INS0   : ISS;
 6159   NEON_FP : S5;
 6160 %}
 6161 
 6162 pipe_class vdop64(vecD dst, vecD src1, vecD src2)
 6163 %{
 6164   single_instruction;
 6165   dst    : S4(write);
 6166   src1   : S2(read);
 6167   src2   : S2(read);
 6168   INS01  : ISS;
 6169   NEON_FP : S4;
 6170 %}
 6171 
 6172 pipe_class vdop128(vecX dst, vecX src1, vecX src2)
 6173 %{
 6174   single_instruction;
 6175   dst    : S4(write);
 6176   src1   : S2(read);
 6177   src2   : S2(read);
 6178   INS0   : ISS;
 6179   NEON_FP : S4;
 6180 %}
 6181 
 6182 pipe_class vlogical64(vecD dst, vecD src1, vecD src2)
 6183 %{
 6184   single_instruction;
 6185   dst    : S3(write);
 6186   src1   : S2(read);
 6187   src2   : S2(read);
 6188   INS01  : ISS;
 6189   NEON_FP : S3;
 6190 %}
 6191 
 6192 pipe_class vlogical128(vecX dst, vecX src1, vecX src2)
 6193 %{
 6194   single_instruction;
 6195   dst    : S3(write);
 6196   src1   : S2(read);
 6197   src2   : S2(read);
 6198   INS0   : ISS;
 6199   NEON_FP : S3;
 6200 %}
 6201 
 6202 pipe_class vshift64(vecD dst, vecD src, vecX shift)
 6203 %{
 6204   single_instruction;
 6205   dst    : S3(write);
 6206   src    : S1(read);
 6207   shift  : S1(read);
 6208   INS01  : ISS;
 6209   NEON_FP : S3;
 6210 %}
 6211 
 6212 pipe_class vshift128(vecX dst, vecX src, vecX shift)
 6213 %{
 6214   single_instruction;
 6215   dst    : S3(write);
 6216   src    : S1(read);
 6217   shift  : S1(read);
 6218   INS0   : ISS;
 6219   NEON_FP : S3;
 6220 %}
 6221 
 6222 pipe_class vshift64_imm(vecD dst, vecD src, immI shift)
 6223 %{
 6224   single_instruction;
 6225   dst    : S3(write);
 6226   src    : S1(read);
 6227   INS01  : ISS;
 6228   NEON_FP : S3;
 6229 %}
 6230 
 6231 pipe_class vshift128_imm(vecX dst, vecX src, immI shift)
 6232 %{
 6233   single_instruction;
 6234   dst    : S3(write);
 6235   src    : S1(read);
 6236   INS0   : ISS;
 6237   NEON_FP : S3;
 6238 %}
 6239 
 6240 pipe_class vdop_fp64(vecD dst, vecD src1, vecD src2)
 6241 %{
 6242   single_instruction;
 6243   dst    : S5(write);
 6244   src1   : S1(read);
 6245   src2   : S1(read);
 6246   INS01  : ISS;
 6247   NEON_FP : S5;
 6248 %}
 6249 
 6250 pipe_class vdop_fp128(vecX dst, vecX src1, vecX src2)
 6251 %{
 6252   single_instruction;
 6253   dst    : S5(write);
 6254   src1   : S1(read);
 6255   src2   : S1(read);
 6256   INS0   : ISS;
 6257   NEON_FP : S5;
 6258 %}
 6259 
 6260 pipe_class vmuldiv_fp64(vecD dst, vecD src1, vecD src2)
 6261 %{
 6262   single_instruction;
 6263   dst    : S5(write);
 6264   src1   : S1(read);
 6265   src2   : S1(read);
 6266   INS0   : ISS;
 6267   NEON_FP : S5;
 6268 %}
 6269 
 6270 pipe_class vmuldiv_fp128(vecX dst, vecX src1, vecX src2)
 6271 %{
 6272   single_instruction;
 6273   dst    : S5(write);
 6274   src1   : S1(read);
 6275   src2   : S1(read);
 6276   INS0   : ISS;
 6277   NEON_FP : S5;
 6278 %}
 6279 
 6280 pipe_class vsqrt_fp128(vecX dst, vecX src)
 6281 %{
 6282   single_instruction;
 6283   dst    : S5(write);
 6284   src    : S1(read);
 6285   INS0   : ISS;
 6286   NEON_FP : S5;
 6287 %}
 6288 
 6289 pipe_class vunop_fp64(vecD dst, vecD src)
 6290 %{
 6291   single_instruction;
 6292   dst    : S5(write);
 6293   src    : S1(read);
 6294   INS01  : ISS;
 6295   NEON_FP : S5;
 6296 %}
 6297 
 6298 pipe_class vunop_fp128(vecX dst, vecX src)
 6299 %{
 6300   single_instruction;
 6301   dst    : S5(write);
 6302   src    : S1(read);
 6303   INS0   : ISS;
 6304   NEON_FP : S5;
 6305 %}
 6306 
 6307 pipe_class vdup_reg_reg64(vecD dst, iRegI src)
 6308 %{
 6309   single_instruction;
 6310   dst    : S3(write);
 6311   src    : S1(read);
 6312   INS01  : ISS;
 6313   NEON_FP : S3;
 6314 %}
 6315 
 6316 pipe_class vdup_reg_reg128(vecX dst, iRegI src)
 6317 %{
 6318   single_instruction;
 6319   dst    : S3(write);
 6320   src    : S1(read);
 6321   INS01  : ISS;
 6322   NEON_FP : S3;
 6323 %}
 6324 
 6325 pipe_class vdup_reg_freg64(vecD dst, vRegF src)
 6326 %{
 6327   single_instruction;
 6328   dst    : S3(write);
 6329   src    : S1(read);
 6330   INS01  : ISS;
 6331   NEON_FP : S3;
 6332 %}
 6333 
 6334 pipe_class vdup_reg_freg128(vecX dst, vRegF src)
 6335 %{
 6336   single_instruction;
 6337   dst    : S3(write);
 6338   src    : S1(read);
 6339   INS01  : ISS;
 6340   NEON_FP : S3;
 6341 %}
 6342 
 6343 pipe_class vdup_reg_dreg128(vecX dst, vRegD src)
 6344 %{
 6345   single_instruction;
 6346   dst    : S3(write);
 6347   src    : S1(read);
 6348   INS01  : ISS;
 6349   NEON_FP : S3;
 6350 %}
 6351 
 6352 pipe_class vmovi_reg_imm64(vecD dst)
 6353 %{
 6354   single_instruction;
 6355   dst    : S3(write);
 6356   INS01  : ISS;
 6357   NEON_FP : S3;
 6358 %}
 6359 
 6360 pipe_class vmovi_reg_imm128(vecX dst)
 6361 %{
 6362   single_instruction;
 6363   dst    : S3(write);
 6364   INS0   : ISS;
 6365   NEON_FP : S3;
 6366 %}
 6367 
 6368 pipe_class vload_reg_mem64(vecD dst, vmem8 mem)
 6369 %{
 6370   single_instruction;
 6371   dst    : S5(write);
 6372   mem    : ISS(read);
 6373   INS01  : ISS;
 6374   NEON_FP : S3;
 6375 %}
 6376 
 6377 pipe_class vload_reg_mem128(vecX dst, vmem16 mem)
 6378 %{
 6379   single_instruction;
 6380   dst    : S5(write);
 6381   mem    : ISS(read);
 6382   INS01  : ISS;
 6383   NEON_FP : S3;
 6384 %}
 6385 
 6386 pipe_class vstore_reg_mem64(vecD src, vmem8 mem)
 6387 %{
 6388   single_instruction;
 6389   mem    : ISS(read);
 6390   src    : S2(read);
 6391   INS01  : ISS;
 6392   NEON_FP : S3;
 6393 %}
 6394 
 6395 pipe_class vstore_reg_mem128(vecD src, vmem16 mem)
 6396 %{
 6397   single_instruction;
 6398   mem    : ISS(read);
 6399   src    : S2(read);
 6400   INS01  : ISS;
 6401   NEON_FP : S3;
 6402 %}
 6403 
 6404 //------- Integer ALU operations --------------------------
 6405 
 6406 // Integer ALU reg-reg operation
 6407 // Operands needed in EX1, result generated in EX2
 6408 // Eg.  ADD     x0, x1, x2
 6409 pipe_class ialu_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6410 %{
 6411   single_instruction;
 6412   dst    : EX2(write);
 6413   src1   : EX1(read);
 6414   src2   : EX1(read);
 6415   INS01  : ISS; // Dual issue as instruction 0 or 1
 6416   ALU    : EX2;
 6417 %}
 6418 
 6419 // Integer ALU reg-reg operation with constant shift
 6420 // Shifted register must be available in LATE_ISS instead of EX1
 6421 // Eg.  ADD     x0, x1, x2, LSL #2
 6422 pipe_class ialu_reg_reg_shift(iRegI dst, iRegI src1, iRegI src2, immI shift)
 6423 %{
 6424   single_instruction;
 6425   dst    : EX2(write);
 6426   src1   : EX1(read);
 6427   src2   : ISS(read);
 6428   INS01  : ISS;
 6429   ALU    : EX2;
 6430 %}
 6431 
 6432 // Integer ALU reg operation with constant shift
 6433 // Eg.  LSL     x0, x1, #shift
 6434 pipe_class ialu_reg_shift(iRegI dst, iRegI src1)
 6435 %{
 6436   single_instruction;
 6437   dst    : EX2(write);
 6438   src1   : ISS(read);
 6439   INS01  : ISS;
 6440   ALU    : EX2;
 6441 %}
 6442 
 6443 // Integer ALU reg-reg operation with variable shift
 6444 // Both operands must be available in LATE_ISS instead of EX1
 6445 // Result is available in EX1 instead of EX2
 6446 // Eg.  LSLV    x0, x1, x2
 6447 pipe_class ialu_reg_reg_vshift(iRegI dst, iRegI src1, iRegI src2)
 6448 %{
 6449   single_instruction;
 6450   dst    : EX1(write);
 6451   src1   : ISS(read);
 6452   src2   : ISS(read);
 6453   INS01  : ISS;
 6454   ALU    : EX1;
 6455 %}
 6456 
 6457 // Integer ALU reg-reg operation with extract
 6458 // As for _vshift above, but result generated in EX2
 6459 // Eg.  EXTR    x0, x1, x2, #N
 6460 pipe_class ialu_reg_reg_extr(iRegI dst, iRegI src1, iRegI src2)
 6461 %{
 6462   single_instruction;
 6463   dst    : EX2(write);
 6464   src1   : ISS(read);
 6465   src2   : ISS(read);
 6466   INS1   : ISS; // Can only dual issue as Instruction 1
 6467   ALU    : EX1;
 6468 %}
 6469 
 6470 // Integer ALU reg operation
 6471 // Eg.  NEG     x0, x1
 6472 pipe_class ialu_reg(iRegI dst, iRegI src)
 6473 %{
 6474   single_instruction;
 6475   dst    : EX2(write);
 6476   src    : EX1(read);
 6477   INS01  : ISS;
 6478   ALU    : EX2;
 6479 %}
 6480 
 6481 // Integer ALU reg mmediate operation
 6482 // Eg.  ADD     x0, x1, #N
 6483 pipe_class ialu_reg_imm(iRegI dst, iRegI src1)
 6484 %{
 6485   single_instruction;
 6486   dst    : EX2(write);
 6487   src1   : EX1(read);
 6488   INS01  : ISS;
 6489   ALU    : EX2;
 6490 %}
 6491 
 6492 // Integer ALU immediate operation (no source operands)
 6493 // Eg.  MOV     x0, #N
 6494 pipe_class ialu_imm(iRegI dst)
 6495 %{
 6496   single_instruction;
 6497   dst    : EX1(write);
 6498   INS01  : ISS;
 6499   ALU    : EX1;
 6500 %}
 6501 
 6502 //------- Compare operation -------------------------------
 6503 
 6504 // Compare reg-reg
 6505 // Eg.  CMP     x0, x1
 6506 pipe_class icmp_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
 6507 %{
 6508   single_instruction;
 6509 //  fixed_latency(16);
 6510   cr     : EX2(write);
 6511   op1    : EX1(read);
 6512   op2    : EX1(read);
 6513   INS01  : ISS;
 6514   ALU    : EX2;
 6515 %}
 6516 
 6517 // Compare reg-reg
 6518 // Eg.  CMP     x0, #N
 6519 pipe_class icmp_reg_imm(rFlagsReg cr, iRegI op1)
 6520 %{
 6521   single_instruction;
 6522 //  fixed_latency(16);
 6523   cr     : EX2(write);
 6524   op1    : EX1(read);
 6525   INS01  : ISS;
 6526   ALU    : EX2;
 6527 %}
 6528 
 6529 //------- Conditional instructions ------------------------
 6530 
 6531 // Conditional no operands
 6532 // Eg.  CSINC   x0, zr, zr, &lt;cond&gt;
 6533 pipe_class icond_none(iRegI dst, rFlagsReg cr)
 6534 %{
 6535   single_instruction;
 6536   cr     : EX1(read);
 6537   dst    : EX2(write);
 6538   INS01  : ISS;
 6539   ALU    : EX2;
 6540 %}
 6541 
 6542 // Conditional 2 operand
 6543 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6544 pipe_class icond_reg_reg(iRegI dst, iRegI src1, iRegI src2, rFlagsReg cr)
 6545 %{
 6546   single_instruction;
 6547   cr     : EX1(read);
 6548   src1   : EX1(read);
 6549   src2   : EX1(read);
 6550   dst    : EX2(write);
 6551   INS01  : ISS;
 6552   ALU    : EX2;
 6553 %}
 6554 
 6555 // Conditional 2 operand
 6556 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6557 pipe_class icond_reg(iRegI dst, iRegI src, rFlagsReg cr)
 6558 %{
 6559   single_instruction;
 6560   cr     : EX1(read);
 6561   src    : EX1(read);
 6562   dst    : EX2(write);
 6563   INS01  : ISS;
 6564   ALU    : EX2;
 6565 %}
 6566 
 6567 //------- Multiply pipeline operations --------------------
 6568 
 6569 // Multiply reg-reg
 6570 // Eg.  MUL     w0, w1, w2
 6571 pipe_class imul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6572 %{
 6573   single_instruction;
 6574   dst    : WR(write);
 6575   src1   : ISS(read);
 6576   src2   : ISS(read);
 6577   INS01  : ISS;
 6578   MAC    : WR;
 6579 %}
 6580 
 6581 // Multiply accumulate
 6582 // Eg.  MADD    w0, w1, w2, w3
 6583 pipe_class imac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6584 %{
 6585   single_instruction;
 6586   dst    : WR(write);
 6587   src1   : ISS(read);
 6588   src2   : ISS(read);
 6589   src3   : ISS(read);
 6590   INS01  : ISS;
 6591   MAC    : WR;
 6592 %}
 6593 
 6594 // Eg.  MUL     w0, w1, w2
 6595 pipe_class lmul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6596 %{
 6597   single_instruction;
 6598   fixed_latency(3); // Maximum latency for 64 bit mul
 6599   dst    : WR(write);
 6600   src1   : ISS(read);
 6601   src2   : ISS(read);
 6602   INS01  : ISS;
 6603   MAC    : WR;
 6604 %}
 6605 
 6606 // Multiply accumulate
 6607 // Eg.  MADD    w0, w1, w2, w3
 6608 pipe_class lmac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6609 %{
 6610   single_instruction;
 6611   fixed_latency(3); // Maximum latency for 64 bit mul
 6612   dst    : WR(write);
 6613   src1   : ISS(read);
 6614   src2   : ISS(read);
 6615   src3   : ISS(read);
 6616   INS01  : ISS;
 6617   MAC    : WR;
 6618 %}
 6619 
 6620 //------- Divide pipeline operations --------------------
 6621 
 6622 // Eg.  SDIV    w0, w1, w2
 6623 pipe_class idiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6624 %{
 6625   single_instruction;
 6626   fixed_latency(8); // Maximum latency for 32 bit divide
 6627   dst    : WR(write);
 6628   src1   : ISS(read);
 6629   src2   : ISS(read);
 6630   INS0   : ISS; // Can only dual issue as instruction 0
 6631   DIV    : WR;
 6632 %}
 6633 
 6634 // Eg.  SDIV    x0, x1, x2
 6635 pipe_class ldiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6636 %{
 6637   single_instruction;
 6638   fixed_latency(16); // Maximum latency for 64 bit divide
 6639   dst    : WR(write);
 6640   src1   : ISS(read);
 6641   src2   : ISS(read);
 6642   INS0   : ISS; // Can only dual issue as instruction 0
 6643   DIV    : WR;
 6644 %}
 6645 
 6646 //------- Load pipeline operations ------------------------
 6647 
 6648 // Load - prefetch
 6649 // Eg.  PFRM    &lt;mem&gt;
 6650 pipe_class iload_prefetch(memory mem)
 6651 %{
 6652   single_instruction;
 6653   mem    : ISS(read);
 6654   INS01  : ISS;
 6655   LDST   : WR;
 6656 %}
 6657 
 6658 // Load - reg, mem
 6659 // Eg.  LDR     x0, &lt;mem&gt;
 6660 pipe_class iload_reg_mem(iRegI dst, memory mem)
 6661 %{
 6662   single_instruction;
 6663   dst    : WR(write);
 6664   mem    : ISS(read);
 6665   INS01  : ISS;
 6666   LDST   : WR;
 6667 %}
 6668 
 6669 // Load - reg, reg
 6670 // Eg.  LDR     x0, [sp, x1]
 6671 pipe_class iload_reg_reg(iRegI dst, iRegI src)
 6672 %{
 6673   single_instruction;
 6674   dst    : WR(write);
 6675   src    : ISS(read);
 6676   INS01  : ISS;
 6677   LDST   : WR;
 6678 %}
 6679 
 6680 //------- Store pipeline operations -----------------------
 6681 
 6682 // Store - zr, mem
 6683 // Eg.  STR     zr, &lt;mem&gt;
 6684 pipe_class istore_mem(memory mem)
 6685 %{
 6686   single_instruction;
 6687   mem    : ISS(read);
 6688   INS01  : ISS;
 6689   LDST   : WR;
 6690 %}
 6691 
 6692 // Store - reg, mem
 6693 // Eg.  STR     x0, &lt;mem&gt;
 6694 pipe_class istore_reg_mem(iRegI src, memory mem)
 6695 %{
 6696   single_instruction;
 6697   mem    : ISS(read);
 6698   src    : EX2(read);
 6699   INS01  : ISS;
 6700   LDST   : WR;
 6701 %}
 6702 
 6703 // Store - reg, reg
 6704 // Eg. STR      x0, [sp, x1]
 6705 pipe_class istore_reg_reg(iRegI dst, iRegI src)
 6706 %{
 6707   single_instruction;
 6708   dst    : ISS(read);
 6709   src    : EX2(read);
 6710   INS01  : ISS;
 6711   LDST   : WR;
 6712 %}
 6713 
 6714 //------- Store pipeline operations -----------------------
 6715 
 6716 // Branch
 6717 pipe_class pipe_branch()
 6718 %{
 6719   single_instruction;
 6720   INS01  : ISS;
 6721   BRANCH : EX1;
 6722 %}
 6723 
 6724 // Conditional branch
 6725 pipe_class pipe_branch_cond(rFlagsReg cr)
 6726 %{
 6727   single_instruction;
 6728   cr     : EX1(read);
 6729   INS01  : ISS;
 6730   BRANCH : EX1;
 6731 %}
 6732 
 6733 // Compare &amp; Branch
 6734 // EG.  CBZ/CBNZ
 6735 pipe_class pipe_cmp_branch(iRegI op1)
 6736 %{
 6737   single_instruction;
 6738   op1    : EX1(read);
 6739   INS01  : ISS;
 6740   BRANCH : EX1;
 6741 %}
 6742 
 6743 //------- Synchronisation operations ----------------------
 6744 
 6745 // Any operation requiring serialization.
 6746 // EG.  DMB/Atomic Ops/Load Acquire/Str Release
 6747 pipe_class pipe_serial()
 6748 %{
 6749   single_instruction;
 6750   force_serialization;
 6751   fixed_latency(16);
 6752   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6753   LDST   : WR;
 6754 %}
 6755 
 6756 // Generic big/slow expanded idiom - also serialized
 6757 pipe_class pipe_slow()
 6758 %{
 6759   instruction_count(10);
 6760   multiple_bundles;
 6761   force_serialization;
 6762   fixed_latency(16);
 6763   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6764   LDST   : WR;
 6765 %}
 6766 
 6767 // Empty pipeline class
 6768 pipe_class pipe_class_empty()
 6769 %{
 6770   single_instruction;
 6771   fixed_latency(0);
 6772 %}
 6773 
 6774 // Default pipeline class.
 6775 pipe_class pipe_class_default()
 6776 %{
 6777   single_instruction;
 6778   fixed_latency(2);
 6779 %}
 6780 
 6781 // Pipeline class for compares.
 6782 pipe_class pipe_class_compare()
 6783 %{
 6784   single_instruction;
 6785   fixed_latency(16);
 6786 %}
 6787 
 6788 // Pipeline class for memory operations.
 6789 pipe_class pipe_class_memory()
 6790 %{
 6791   single_instruction;
 6792   fixed_latency(16);
 6793 %}
 6794 
 6795 // Pipeline class for call.
 6796 pipe_class pipe_class_call()
 6797 %{
 6798   single_instruction;
 6799   fixed_latency(100);
 6800 %}
 6801 
 6802 // Define the class for the Nop node.
 6803 define %{
 6804    MachNop = pipe_class_empty;
 6805 %}
 6806 
 6807 %}
 6808 //----------INSTRUCTIONS-------------------------------------------------------
 6809 //
 6810 // match      -- States which machine-independent subtree may be replaced
 6811 //               by this instruction.
 6812 // ins_cost   -- The estimated cost of this instruction is used by instruction
 6813 //               selection to identify a minimum cost tree of machine
 6814 //               instructions that matches a tree of machine-independent
 6815 //               instructions.
 6816 // format     -- A string providing the disassembly for this instruction.
 6817 //               The value of an instruction&#39;s operand may be inserted
 6818 //               by referring to it with a &#39;$&#39; prefix.
 6819 // opcode     -- Three instruction opcodes may be provided.  These are referred
 6820 //               to within an encode class as $primary, $secondary, and $tertiary
 6821 //               rrspectively.  The primary opcode is commonly used to
 6822 //               indicate the type of machine instruction, while secondary
 6823 //               and tertiary are often used for prefix options or addressing
 6824 //               modes.
 6825 // ins_encode -- A list of encode classes with parameters. The encode class
 6826 //               name must have been defined in an &#39;enc_class&#39; specification
 6827 //               in the encode section of the architecture description.
 6828 
 6829 // ============================================================================
 6830 // Memory (Load/Store) Instructions
 6831 
 6832 // Load Instructions
 6833 
 6834 // Load Byte (8 bit signed)
 6835 instruct loadB(iRegINoSp dst, memory1 mem)
 6836 %{
 6837   match(Set dst (LoadB mem));
 6838   predicate(!needs_acquiring_load(n));
 6839 
 6840   ins_cost(4 * INSN_COST);
 6841   format %{ &quot;ldrsbw  $dst, $mem\t# byte&quot; %}
 6842 
 6843   ins_encode(aarch64_enc_ldrsbw(dst, mem));
 6844 
 6845   ins_pipe(iload_reg_mem);
 6846 %}
 6847 
 6848 // Load Byte (8 bit signed) into long
 6849 instruct loadB2L(iRegLNoSp dst, memory1 mem)
 6850 %{
 6851   match(Set dst (ConvI2L (LoadB mem)));
 6852   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6853 
 6854   ins_cost(4 * INSN_COST);
 6855   format %{ &quot;ldrsb  $dst, $mem\t# byte&quot; %}
 6856 
 6857   ins_encode(aarch64_enc_ldrsb(dst, mem));
 6858 
 6859   ins_pipe(iload_reg_mem);
 6860 %}
 6861 
 6862 // Load Byte (8 bit unsigned)
 6863 instruct loadUB(iRegINoSp dst, memory1 mem)
 6864 %{
 6865   match(Set dst (LoadUB mem));
 6866   predicate(!needs_acquiring_load(n));
 6867 
 6868   ins_cost(4 * INSN_COST);
 6869   format %{ &quot;ldrbw  $dst, $mem\t# byte&quot; %}
 6870 
 6871   ins_encode(aarch64_enc_ldrb(dst, mem));
 6872 
 6873   ins_pipe(iload_reg_mem);
 6874 %}
 6875 
 6876 // Load Byte (8 bit unsigned) into long
 6877 instruct loadUB2L(iRegLNoSp dst, memory1 mem)
 6878 %{
 6879   match(Set dst (ConvI2L (LoadUB mem)));
 6880   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6881 
 6882   ins_cost(4 * INSN_COST);
 6883   format %{ &quot;ldrb  $dst, $mem\t# byte&quot; %}
 6884 
 6885   ins_encode(aarch64_enc_ldrb(dst, mem));
 6886 
 6887   ins_pipe(iload_reg_mem);
 6888 %}
 6889 
 6890 // Load Short (16 bit signed)
 6891 instruct loadS(iRegINoSp dst, memory2 mem)
 6892 %{
 6893   match(Set dst (LoadS mem));
 6894   predicate(!needs_acquiring_load(n));
 6895 
 6896   ins_cost(4 * INSN_COST);
 6897   format %{ &quot;ldrshw  $dst, $mem\t# short&quot; %}
 6898 
 6899   ins_encode(aarch64_enc_ldrshw(dst, mem));
 6900 
 6901   ins_pipe(iload_reg_mem);
 6902 %}
 6903 
 6904 // Load Short (16 bit signed) into long
 6905 instruct loadS2L(iRegLNoSp dst, memory2 mem)
 6906 %{
 6907   match(Set dst (ConvI2L (LoadS mem)));
 6908   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6909 
 6910   ins_cost(4 * INSN_COST);
 6911   format %{ &quot;ldrsh  $dst, $mem\t# short&quot; %}
 6912 
 6913   ins_encode(aarch64_enc_ldrsh(dst, mem));
 6914 
 6915   ins_pipe(iload_reg_mem);
 6916 %}
 6917 
 6918 // Load Char (16 bit unsigned)
 6919 instruct loadUS(iRegINoSp dst, memory2 mem)
 6920 %{
 6921   match(Set dst (LoadUS mem));
 6922   predicate(!needs_acquiring_load(n));
 6923 
 6924   ins_cost(4 * INSN_COST);
 6925   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6926 
 6927   ins_encode(aarch64_enc_ldrh(dst, mem));
 6928 
 6929   ins_pipe(iload_reg_mem);
 6930 %}
 6931 
 6932 // Load Short/Char (16 bit unsigned) into long
 6933 instruct loadUS2L(iRegLNoSp dst, memory2 mem)
 6934 %{
 6935   match(Set dst (ConvI2L (LoadUS mem)));
 6936   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6937 
 6938   ins_cost(4 * INSN_COST);
 6939   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6940 
 6941   ins_encode(aarch64_enc_ldrh(dst, mem));
 6942 
 6943   ins_pipe(iload_reg_mem);
 6944 %}
 6945 
 6946 // Load Integer (32 bit signed)
 6947 instruct loadI(iRegINoSp dst, memory4 mem)
 6948 %{
 6949   match(Set dst (LoadI mem));
 6950   predicate(!needs_acquiring_load(n));
 6951 
 6952   ins_cost(4 * INSN_COST);
 6953   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6954 
 6955   ins_encode(aarch64_enc_ldrw(dst, mem));
 6956 
 6957   ins_pipe(iload_reg_mem);
 6958 %}
 6959 
 6960 // Load Integer (32 bit signed) into long
 6961 instruct loadI2L(iRegLNoSp dst, memory4 mem)
 6962 %{
 6963   match(Set dst (ConvI2L (LoadI mem)));
 6964   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6965 
 6966   ins_cost(4 * INSN_COST);
 6967   format %{ &quot;ldrsw  $dst, $mem\t# int&quot; %}
 6968 
 6969   ins_encode(aarch64_enc_ldrsw(dst, mem));
 6970 
 6971   ins_pipe(iload_reg_mem);
 6972 %}
 6973 
 6974 // Load Integer (32 bit unsigned) into long
 6975 instruct loadUI2L(iRegLNoSp dst, memory4 mem, immL_32bits mask)
 6976 %{
 6977   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 6978   predicate(!needs_acquiring_load(n-&gt;in(1)-&gt;in(1)-&gt;as_Load()));
 6979 
 6980   ins_cost(4 * INSN_COST);
 6981   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6982 
 6983   ins_encode(aarch64_enc_ldrw(dst, mem));
 6984 
 6985   ins_pipe(iload_reg_mem);
 6986 %}
 6987 
 6988 // Load Long (64 bit signed)
 6989 instruct loadL(iRegLNoSp dst, memory8 mem)
 6990 %{
 6991   match(Set dst (LoadL mem));
 6992   predicate(!needs_acquiring_load(n));
 6993 
 6994   ins_cost(4 * INSN_COST);
 6995   format %{ &quot;ldr  $dst, $mem\t# int&quot; %}
 6996 
 6997   ins_encode(aarch64_enc_ldr(dst, mem));
 6998 
 6999   ins_pipe(iload_reg_mem);
 7000 %}
 7001 
 7002 // Load Range
 7003 instruct loadRange(iRegINoSp dst, memory4 mem)
 7004 %{
 7005   match(Set dst (LoadRange mem));
 7006 
 7007   ins_cost(4 * INSN_COST);
 7008   format %{ &quot;ldrw  $dst, $mem\t# range&quot; %}
 7009 
 7010   ins_encode(aarch64_enc_ldrw(dst, mem));
 7011 
 7012   ins_pipe(iload_reg_mem);
 7013 %}
 7014 
 7015 // Load Pointer
 7016 instruct loadP(iRegPNoSp dst, memory8 mem)
 7017 %{
 7018   match(Set dst (LoadP mem));
 7019   predicate(!needs_acquiring_load(n) &amp;&amp; (n-&gt;as_Load()-&gt;barrier_data() == 0));
 7020 
 7021   ins_cost(4 * INSN_COST);
 7022   format %{ &quot;ldr  $dst, $mem\t# ptr&quot; %}
 7023 
 7024   ins_encode(aarch64_enc_ldr(dst, mem));
 7025 
 7026   ins_pipe(iload_reg_mem);
 7027 %}
 7028 
 7029 // Load Compressed Pointer
 7030 instruct loadN(iRegNNoSp dst, memory4 mem)
 7031 %{
 7032   match(Set dst (LoadN mem));
 7033   predicate(!needs_acquiring_load(n));
 7034 
 7035   ins_cost(4 * INSN_COST);
 7036   format %{ &quot;ldrw  $dst, $mem\t# compressed ptr&quot; %}
 7037 
 7038   ins_encode(aarch64_enc_ldrw(dst, mem));
 7039 
 7040   ins_pipe(iload_reg_mem);
 7041 %}
 7042 
 7043 // Load Klass Pointer
 7044 instruct loadKlass(iRegPNoSp dst, memory8 mem)
 7045 %{
 7046   match(Set dst (LoadKlass mem));
 7047   predicate(!needs_acquiring_load(n));
 7048 
 7049   ins_cost(4 * INSN_COST);
 7050   format %{ &quot;ldr  $dst, $mem\t# class&quot; %}
 7051 
 7052   ins_encode(aarch64_enc_ldr(dst, mem));
 7053 
 7054   ins_pipe(iload_reg_mem);
 7055 %}
 7056 
 7057 // Load Narrow Klass Pointer
 7058 instruct loadNKlass(iRegNNoSp dst, memory4 mem)
 7059 %{
 7060   match(Set dst (LoadNKlass mem));
 7061   predicate(!needs_acquiring_load(n));
 7062 
 7063   ins_cost(4 * INSN_COST);
 7064   format %{ &quot;ldrw  $dst, $mem\t# compressed class ptr&quot; %}
 7065 
 7066   ins_encode(aarch64_enc_ldrw(dst, mem));
 7067 
 7068   ins_pipe(iload_reg_mem);
 7069 %}
 7070 
 7071 // Load Float
 7072 instruct loadF(vRegF dst, memory4 mem)
 7073 %{
 7074   match(Set dst (LoadF mem));
 7075   predicate(!needs_acquiring_load(n));
 7076 
 7077   ins_cost(4 * INSN_COST);
 7078   format %{ &quot;ldrs  $dst, $mem\t# float&quot; %}
 7079 
 7080   ins_encode( aarch64_enc_ldrs(dst, mem) );
 7081 
 7082   ins_pipe(pipe_class_memory);
 7083 %}
 7084 
 7085 // Load Double
 7086 instruct loadD(vRegD dst, memory8 mem)
 7087 %{
 7088   match(Set dst (LoadD mem));
 7089   predicate(!needs_acquiring_load(n));
 7090 
 7091   ins_cost(4 * INSN_COST);
 7092   format %{ &quot;ldrd  $dst, $mem\t# double&quot; %}
 7093 
 7094   ins_encode( aarch64_enc_ldrd(dst, mem) );
 7095 
 7096   ins_pipe(pipe_class_memory);
 7097 %}
 7098 
 7099 
 7100 // Load Int Constant
 7101 instruct loadConI(iRegINoSp dst, immI src)
 7102 %{
 7103   match(Set dst src);
 7104 
 7105   ins_cost(INSN_COST);
 7106   format %{ &quot;mov $dst, $src\t# int&quot; %}
 7107 
 7108   ins_encode( aarch64_enc_movw_imm(dst, src) );
 7109 
 7110   ins_pipe(ialu_imm);
 7111 %}
 7112 
 7113 // Load Long Constant
 7114 instruct loadConL(iRegLNoSp dst, immL src)
 7115 %{
 7116   match(Set dst src);
 7117 
 7118   ins_cost(INSN_COST);
 7119   format %{ &quot;mov $dst, $src\t# long&quot; %}
 7120 
 7121   ins_encode( aarch64_enc_mov_imm(dst, src) );
 7122 
 7123   ins_pipe(ialu_imm);
 7124 %}
 7125 
 7126 // Load Pointer Constant
 7127 
 7128 instruct loadConP(iRegPNoSp dst, immP con)
 7129 %{
 7130   match(Set dst con);
 7131 
 7132   ins_cost(INSN_COST * 4);
 7133   format %{
 7134     &quot;mov  $dst, $con\t# ptr\n\t&quot;
 7135   %}
 7136 
 7137   ins_encode(aarch64_enc_mov_p(dst, con));
 7138 
 7139   ins_pipe(ialu_imm);
 7140 %}
 7141 
 7142 // Load Null Pointer Constant
 7143 
 7144 instruct loadConP0(iRegPNoSp dst, immP0 con)
 7145 %{
 7146   match(Set dst con);
 7147 
 7148   ins_cost(INSN_COST);
 7149   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7150 
 7151   ins_encode(aarch64_enc_mov_p0(dst, con));
 7152 
 7153   ins_pipe(ialu_imm);
 7154 %}
 7155 
 7156 // Load Pointer Constant One
 7157 
 7158 instruct loadConP1(iRegPNoSp dst, immP_1 con)
 7159 %{
 7160   match(Set dst con);
 7161 
 7162   ins_cost(INSN_COST);
 7163   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7164 
 7165   ins_encode(aarch64_enc_mov_p1(dst, con));
 7166 
 7167   ins_pipe(ialu_imm);
 7168 %}
 7169 
 7170 // Load Byte Map Base Constant
 7171 
 7172 instruct loadByteMapBase(iRegPNoSp dst, immByteMapBase con)
 7173 %{
 7174   match(Set dst con);
 7175 
 7176   ins_cost(INSN_COST);
 7177   format %{ &quot;adr  $dst, $con\t# Byte Map Base&quot; %}
 7178 
 7179   ins_encode(aarch64_enc_mov_byte_map_base(dst, con));
 7180 
 7181   ins_pipe(ialu_imm);
 7182 %}
 7183 
 7184 // Load Narrow Pointer Constant
 7185 
 7186 instruct loadConN(iRegNNoSp dst, immN con)
 7187 %{
 7188   match(Set dst con);
 7189 
 7190   ins_cost(INSN_COST * 4);
 7191   format %{ &quot;mov  $dst, $con\t# compressed ptr&quot; %}
 7192 
 7193   ins_encode(aarch64_enc_mov_n(dst, con));
 7194 
 7195   ins_pipe(ialu_imm);
 7196 %}
 7197 
 7198 // Load Narrow Null Pointer Constant
 7199 
 7200 instruct loadConN0(iRegNNoSp dst, immN0 con)
 7201 %{
 7202   match(Set dst con);
 7203 
 7204   ins_cost(INSN_COST);
 7205   format %{ &quot;mov  $dst, $con\t# compressed NULL ptr&quot; %}
 7206 
 7207   ins_encode(aarch64_enc_mov_n0(dst, con));
 7208 
 7209   ins_pipe(ialu_imm);
 7210 %}
 7211 
 7212 // Load Narrow Klass Constant
 7213 
 7214 instruct loadConNKlass(iRegNNoSp dst, immNKlass con)
 7215 %{
 7216   match(Set dst con);
 7217 
 7218   ins_cost(INSN_COST);
 7219   format %{ &quot;mov  $dst, $con\t# compressed klass ptr&quot; %}
 7220 
 7221   ins_encode(aarch64_enc_mov_nk(dst, con));
 7222 
 7223   ins_pipe(ialu_imm);
 7224 %}
 7225 
 7226 // Load Packed Float Constant
 7227 
 7228 instruct loadConF_packed(vRegF dst, immFPacked con) %{
 7229   match(Set dst con);
 7230   ins_cost(INSN_COST * 4);
 7231   format %{ &quot;fmovs  $dst, $con&quot;%}
 7232   ins_encode %{
 7233     __ fmovs(as_FloatRegister($dst$$reg), (double)$con$$constant);
 7234   %}
 7235 
 7236   ins_pipe(fp_imm_s);
 7237 %}
 7238 
 7239 // Load Float Constant
 7240 
 7241 instruct loadConF(vRegF dst, immF con) %{
 7242   match(Set dst con);
 7243 
 7244   ins_cost(INSN_COST * 4);
 7245 
 7246   format %{
 7247     &quot;ldrs $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7248   %}
 7249 
 7250   ins_encode %{
 7251     __ ldrs(as_FloatRegister($dst$$reg), $constantaddress($con));
 7252   %}
 7253 
 7254   ins_pipe(fp_load_constant_s);
 7255 %}
 7256 
 7257 // Load Packed Double Constant
 7258 
 7259 instruct loadConD_packed(vRegD dst, immDPacked con) %{
 7260   match(Set dst con);
 7261   ins_cost(INSN_COST);
 7262   format %{ &quot;fmovd  $dst, $con&quot;%}
 7263   ins_encode %{
 7264     __ fmovd(as_FloatRegister($dst$$reg), $con$$constant);
 7265   %}
 7266 
 7267   ins_pipe(fp_imm_d);
 7268 %}
 7269 
 7270 // Load Double Constant
 7271 
 7272 instruct loadConD(vRegD dst, immD con) %{
 7273   match(Set dst con);
 7274 
 7275   ins_cost(INSN_COST * 5);
 7276   format %{
 7277     &quot;ldrd $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7278   %}
 7279 
 7280   ins_encode %{
 7281     __ ldrd(as_FloatRegister($dst$$reg), $constantaddress($con));
 7282   %}
 7283 
 7284   ins_pipe(fp_load_constant_d);
 7285 %}
 7286 
 7287 // Store Instructions
 7288 
 7289 // Store CMS card-mark Immediate
 7290 instruct storeimmCM0(immI0 zero, memory1 mem)
 7291 %{
 7292   match(Set mem (StoreCM mem zero));
 7293 
 7294   ins_cost(INSN_COST);
 7295   format %{ &quot;storestore (elided)\n\t&quot;
 7296             &quot;strb zr, $mem\t# byte&quot; %}
 7297 
 7298   ins_encode(aarch64_enc_strb0(mem));
 7299 
 7300   ins_pipe(istore_mem);
 7301 %}
 7302 
 7303 // Store CMS card-mark Immediate with intervening StoreStore
 7304 // needed when using CMS with no conditional card marking
 7305 instruct storeimmCM0_ordered(immI0 zero, memory1 mem)
 7306 %{
 7307   match(Set mem (StoreCM mem zero));
 7308 
 7309   ins_cost(INSN_COST * 2);
 7310   format %{ &quot;storestore\n\t&quot;
 7311             &quot;dmb ishst&quot;
 7312             &quot;\n\tstrb zr, $mem\t# byte&quot; %}
 7313 
 7314   ins_encode(aarch64_enc_strb0_ordered(mem));
 7315 
 7316   ins_pipe(istore_mem);
 7317 %}
 7318 
 7319 // Store Byte
 7320 instruct storeB(iRegIorL2I src, memory1 mem)
 7321 %{
 7322   match(Set mem (StoreB mem src));
 7323   predicate(!needs_releasing_store(n));
 7324 
 7325   ins_cost(INSN_COST);
 7326   format %{ &quot;strb  $src, $mem\t# byte&quot; %}
 7327 
 7328   ins_encode(aarch64_enc_strb(src, mem));
 7329 
 7330   ins_pipe(istore_reg_mem);
 7331 %}
 7332 
 7333 
 7334 instruct storeimmB0(immI0 zero, memory1 mem)
 7335 %{
 7336   match(Set mem (StoreB mem zero));
 7337   predicate(!needs_releasing_store(n));
 7338 
 7339   ins_cost(INSN_COST);
 7340   format %{ &quot;strb rscractch2, $mem\t# byte&quot; %}
 7341 
 7342   ins_encode(aarch64_enc_strb0(mem));
 7343 
 7344   ins_pipe(istore_mem);
 7345 %}
 7346 
 7347 // Store Char/Short
 7348 instruct storeC(iRegIorL2I src, memory2 mem)
 7349 %{
 7350   match(Set mem (StoreC mem src));
 7351   predicate(!needs_releasing_store(n));
 7352 
 7353   ins_cost(INSN_COST);
 7354   format %{ &quot;strh  $src, $mem\t# short&quot; %}
 7355 
 7356   ins_encode(aarch64_enc_strh(src, mem));
 7357 
 7358   ins_pipe(istore_reg_mem);
 7359 %}
 7360 
 7361 instruct storeimmC0(immI0 zero, memory2 mem)
 7362 %{
 7363   match(Set mem (StoreC mem zero));
 7364   predicate(!needs_releasing_store(n));
 7365 
 7366   ins_cost(INSN_COST);
 7367   format %{ &quot;strh  zr, $mem\t# short&quot; %}
 7368 
 7369   ins_encode(aarch64_enc_strh0(mem));
 7370 
 7371   ins_pipe(istore_mem);
 7372 %}
 7373 
 7374 // Store Integer
 7375 
 7376 instruct storeI(iRegIorL2I src, memory4 mem)
 7377 %{
 7378   match(Set mem(StoreI mem src));
 7379   predicate(!needs_releasing_store(n));
 7380 
 7381   ins_cost(INSN_COST);
 7382   format %{ &quot;strw  $src, $mem\t# int&quot; %}
 7383 
 7384   ins_encode(aarch64_enc_strw(src, mem));
 7385 
 7386   ins_pipe(istore_reg_mem);
 7387 %}
 7388 
 7389 instruct storeimmI0(immI0 zero, memory4 mem)
 7390 %{
 7391   match(Set mem(StoreI mem zero));
 7392   predicate(!needs_releasing_store(n));
 7393 
 7394   ins_cost(INSN_COST);
 7395   format %{ &quot;strw  zr, $mem\t# int&quot; %}
 7396 
 7397   ins_encode(aarch64_enc_strw0(mem));
 7398 
 7399   ins_pipe(istore_mem);
 7400 %}
 7401 
 7402 // Store Long (64 bit signed)
 7403 instruct storeL(iRegL src, memory8 mem)
 7404 %{
 7405   match(Set mem (StoreL mem src));
 7406   predicate(!needs_releasing_store(n));
 7407 
 7408   ins_cost(INSN_COST);
 7409   format %{ &quot;str  $src, $mem\t# int&quot; %}
 7410 
 7411   ins_encode(aarch64_enc_str(src, mem));
 7412 
 7413   ins_pipe(istore_reg_mem);
 7414 %}
 7415 
 7416 // Store Long (64 bit signed)
 7417 instruct storeimmL0(immL0 zero, memory8 mem)
 7418 %{
 7419   match(Set mem (StoreL mem zero));
 7420   predicate(!needs_releasing_store(n));
 7421 
 7422   ins_cost(INSN_COST);
 7423   format %{ &quot;str  zr, $mem\t# int&quot; %}
 7424 
 7425   ins_encode(aarch64_enc_str0(mem));
 7426 
 7427   ins_pipe(istore_mem);
 7428 %}
 7429 
 7430 // Store Pointer
 7431 instruct storeP(iRegP src, memory8 mem)
 7432 %{
 7433   match(Set mem (StoreP mem src));
 7434   predicate(!needs_releasing_store(n));
 7435 
 7436   ins_cost(INSN_COST);
 7437   format %{ &quot;str  $src, $mem\t# ptr&quot; %}
 7438 
 7439   ins_encode(aarch64_enc_str(src, mem));
 7440 
 7441   ins_pipe(istore_reg_mem);
 7442 %}
 7443 
 7444 // Store Pointer
 7445 instruct storeimmP0(immP0 zero, memory8 mem)
 7446 %{
 7447   match(Set mem (StoreP mem zero));
 7448   predicate(!needs_releasing_store(n));
 7449 
 7450   ins_cost(INSN_COST);
 7451   format %{ &quot;str zr, $mem\t# ptr&quot; %}
 7452 
 7453   ins_encode(aarch64_enc_str0(mem));
 7454 
 7455   ins_pipe(istore_mem);
 7456 %}
 7457 
 7458 // Store Compressed Pointer
 7459 instruct storeN(iRegN src, memory4 mem)
 7460 %{
 7461   match(Set mem (StoreN mem src));
 7462   predicate(!needs_releasing_store(n));
 7463 
 7464   ins_cost(INSN_COST);
 7465   format %{ &quot;strw  $src, $mem\t# compressed ptr&quot; %}
 7466 
 7467   ins_encode(aarch64_enc_strw(src, mem));
 7468 
 7469   ins_pipe(istore_reg_mem);
 7470 %}
 7471 
 7472 instruct storeImmN0(immN0 zero, memory4 mem)
 7473 %{
 7474   match(Set mem (StoreN mem zero));
 7475   predicate(!needs_releasing_store(n));
 7476 
 7477   ins_cost(INSN_COST);
 7478   format %{ &quot;strw  zr, $mem\t# compressed ptr&quot; %}
 7479 
 7480   ins_encode(aarch64_enc_strw0(mem));
 7481 
 7482   ins_pipe(istore_mem);
 7483 %}
 7484 
 7485 // Store Float
 7486 instruct storeF(vRegF src, memory4 mem)
 7487 %{
 7488   match(Set mem (StoreF mem src));
 7489   predicate(!needs_releasing_store(n));
 7490 
 7491   ins_cost(INSN_COST);
 7492   format %{ &quot;strs  $src, $mem\t# float&quot; %}
 7493 
 7494   ins_encode( aarch64_enc_strs(src, mem) );
 7495 
 7496   ins_pipe(pipe_class_memory);
 7497 %}
 7498 
 7499 // TODO
 7500 // implement storeImmF0 and storeFImmPacked
 7501 
 7502 // Store Double
 7503 instruct storeD(vRegD src, memory8 mem)
 7504 %{
 7505   match(Set mem (StoreD mem src));
 7506   predicate(!needs_releasing_store(n));
 7507 
 7508   ins_cost(INSN_COST);
 7509   format %{ &quot;strd  $src, $mem\t# double&quot; %}
 7510 
 7511   ins_encode( aarch64_enc_strd(src, mem) );
 7512 
 7513   ins_pipe(pipe_class_memory);
 7514 %}
 7515 
 7516 // Store Compressed Klass Pointer
 7517 instruct storeNKlass(iRegN src, memory4 mem)
 7518 %{
 7519   predicate(!needs_releasing_store(n));
 7520   match(Set mem (StoreNKlass mem src));
 7521 
 7522   ins_cost(INSN_COST);
 7523   format %{ &quot;strw  $src, $mem\t# compressed klass ptr&quot; %}
 7524 
 7525   ins_encode(aarch64_enc_strw(src, mem));
 7526 
 7527   ins_pipe(istore_reg_mem);
 7528 %}
 7529 
 7530 // TODO
 7531 // implement storeImmD0 and storeDImmPacked
 7532 
 7533 // prefetch instructions
 7534 // Must be safe to execute with invalid address (cannot fault).
 7535 
 7536 instruct prefetchalloc( memory8 mem ) %{
 7537   match(PrefetchAllocation mem);
 7538 
 7539   ins_cost(INSN_COST);
 7540   format %{ &quot;prfm $mem, PSTL1KEEP\t# Prefetch into level 1 cache write keep&quot; %}
 7541 
 7542   ins_encode( aarch64_enc_prefetchw(mem) );
 7543 
 7544   ins_pipe(iload_prefetch);
 7545 %}
 7546 
 7547 //  ---------------- volatile loads and stores ----------------
 7548 
 7549 // Load Byte (8 bit signed)
 7550 instruct loadB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7551 %{
 7552   match(Set dst (LoadB mem));
 7553 
 7554   ins_cost(VOLATILE_REF_COST);
 7555   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7556 
 7557   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7558 
 7559   ins_pipe(pipe_serial);
 7560 %}
 7561 
 7562 // Load Byte (8 bit signed) into long
 7563 instruct loadB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7564 %{
 7565   match(Set dst (ConvI2L (LoadB mem)));
 7566 
 7567   ins_cost(VOLATILE_REF_COST);
 7568   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7569 
 7570   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7571 
 7572   ins_pipe(pipe_serial);
 7573 %}
 7574 
 7575 // Load Byte (8 bit unsigned)
 7576 instruct loadUB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7577 %{
 7578   match(Set dst (LoadUB mem));
 7579 
 7580   ins_cost(VOLATILE_REF_COST);
 7581   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7582 
 7583   ins_encode(aarch64_enc_ldarb(dst, mem));
 7584 
 7585   ins_pipe(pipe_serial);
 7586 %}
 7587 
 7588 // Load Byte (8 bit unsigned) into long
 7589 instruct loadUB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7590 %{
 7591   match(Set dst (ConvI2L (LoadUB mem)));
 7592 
 7593   ins_cost(VOLATILE_REF_COST);
 7594   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7595 
 7596   ins_encode(aarch64_enc_ldarb(dst, mem));
 7597 
 7598   ins_pipe(pipe_serial);
 7599 %}
 7600 
 7601 // Load Short (16 bit signed)
 7602 instruct loadS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7603 %{
 7604   match(Set dst (LoadS mem));
 7605 
 7606   ins_cost(VOLATILE_REF_COST);
 7607   format %{ &quot;ldarshw  $dst, $mem\t# short&quot; %}
 7608 
 7609   ins_encode(aarch64_enc_ldarshw(dst, mem));
 7610 
 7611   ins_pipe(pipe_serial);
 7612 %}
 7613 
 7614 instruct loadUS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7615 %{
 7616   match(Set dst (LoadUS mem));
 7617 
 7618   ins_cost(VOLATILE_REF_COST);
 7619   format %{ &quot;ldarhw  $dst, $mem\t# short&quot; %}
 7620 
 7621   ins_encode(aarch64_enc_ldarhw(dst, mem));
 7622 
 7623   ins_pipe(pipe_serial);
 7624 %}
 7625 
 7626 // Load Short/Char (16 bit unsigned) into long
 7627 instruct loadUS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7628 %{
 7629   match(Set dst (ConvI2L (LoadUS mem)));
 7630 
 7631   ins_cost(VOLATILE_REF_COST);
 7632   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7633 
 7634   ins_encode(aarch64_enc_ldarh(dst, mem));
 7635 
 7636   ins_pipe(pipe_serial);
 7637 %}
 7638 
 7639 // Load Short/Char (16 bit signed) into long
 7640 instruct loadS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7641 %{
 7642   match(Set dst (ConvI2L (LoadS mem)));
 7643 
 7644   ins_cost(VOLATILE_REF_COST);
 7645   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7646 
 7647   ins_encode(aarch64_enc_ldarsh(dst, mem));
 7648 
 7649   ins_pipe(pipe_serial);
 7650 %}
 7651 
 7652 // Load Integer (32 bit signed)
 7653 instruct loadI_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7654 %{
 7655   match(Set dst (LoadI mem));
 7656 
 7657   ins_cost(VOLATILE_REF_COST);
 7658   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7659 
 7660   ins_encode(aarch64_enc_ldarw(dst, mem));
 7661 
 7662   ins_pipe(pipe_serial);
 7663 %}
 7664 
 7665 // Load Integer (32 bit unsigned) into long
 7666 instruct loadUI2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem, immL_32bits mask)
 7667 %{
 7668   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 7669 
 7670   ins_cost(VOLATILE_REF_COST);
 7671   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7672 
 7673   ins_encode(aarch64_enc_ldarw(dst, mem));
 7674 
 7675   ins_pipe(pipe_serial);
 7676 %}
 7677 
 7678 // Load Long (64 bit signed)
 7679 instruct loadL_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7680 %{
 7681   match(Set dst (LoadL mem));
 7682 
 7683   ins_cost(VOLATILE_REF_COST);
 7684   format %{ &quot;ldar  $dst, $mem\t# int&quot; %}
 7685 
 7686   ins_encode(aarch64_enc_ldar(dst, mem));
 7687 
 7688   ins_pipe(pipe_serial);
 7689 %}
 7690 
 7691 // Load Pointer
 7692 instruct loadP_volatile(iRegPNoSp dst, /* sync_memory*/indirect mem)
 7693 %{
 7694   match(Set dst (LoadP mem));
 7695   predicate(n-&gt;as_Load()-&gt;barrier_data() == 0);
 7696 
 7697   ins_cost(VOLATILE_REF_COST);
 7698   format %{ &quot;ldar  $dst, $mem\t# ptr&quot; %}
 7699 
 7700   ins_encode(aarch64_enc_ldar(dst, mem));
 7701 
 7702   ins_pipe(pipe_serial);
 7703 %}
 7704 
 7705 // Load Compressed Pointer
 7706 instruct loadN_volatile(iRegNNoSp dst, /* sync_memory*/indirect mem)
 7707 %{
 7708   match(Set dst (LoadN mem));
 7709 
 7710   ins_cost(VOLATILE_REF_COST);
 7711   format %{ &quot;ldarw  $dst, $mem\t# compressed ptr&quot; %}
 7712 
 7713   ins_encode(aarch64_enc_ldarw(dst, mem));
 7714 
 7715   ins_pipe(pipe_serial);
 7716 %}
 7717 
 7718 // Load Float
 7719 instruct loadF_volatile(vRegF dst, /* sync_memory*/indirect mem)
 7720 %{
 7721   match(Set dst (LoadF mem));
 7722 
 7723   ins_cost(VOLATILE_REF_COST);
 7724   format %{ &quot;ldars  $dst, $mem\t# float&quot; %}
 7725 
 7726   ins_encode( aarch64_enc_fldars(dst, mem) );
 7727 
 7728   ins_pipe(pipe_serial);
 7729 %}
 7730 
 7731 // Load Double
 7732 instruct loadD_volatile(vRegD dst, /* sync_memory*/indirect mem)
 7733 %{
 7734   match(Set dst (LoadD mem));
 7735 
 7736   ins_cost(VOLATILE_REF_COST);
 7737   format %{ &quot;ldard  $dst, $mem\t# double&quot; %}
 7738 
 7739   ins_encode( aarch64_enc_fldard(dst, mem) );
 7740 
 7741   ins_pipe(pipe_serial);
 7742 %}
 7743 
 7744 // Store Byte
 7745 instruct storeB_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7746 %{
 7747   match(Set mem (StoreB mem src));
 7748 
 7749   ins_cost(VOLATILE_REF_COST);
 7750   format %{ &quot;stlrb  $src, $mem\t# byte&quot; %}
 7751 
 7752   ins_encode(aarch64_enc_stlrb(src, mem));
 7753 
 7754   ins_pipe(pipe_class_memory);
 7755 %}
 7756 
 7757 // Store Char/Short
 7758 instruct storeC_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7759 %{
 7760   match(Set mem (StoreC mem src));
 7761 
 7762   ins_cost(VOLATILE_REF_COST);
 7763   format %{ &quot;stlrh  $src, $mem\t# short&quot; %}
 7764 
 7765   ins_encode(aarch64_enc_stlrh(src, mem));
 7766 
 7767   ins_pipe(pipe_class_memory);
 7768 %}
 7769 
 7770 // Store Integer
 7771 
 7772 instruct storeI_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7773 %{
 7774   match(Set mem(StoreI mem src));
 7775 
 7776   ins_cost(VOLATILE_REF_COST);
 7777   format %{ &quot;stlrw  $src, $mem\t# int&quot; %}
 7778 
 7779   ins_encode(aarch64_enc_stlrw(src, mem));
 7780 
 7781   ins_pipe(pipe_class_memory);
 7782 %}
 7783 
 7784 // Store Long (64 bit signed)
 7785 instruct storeL_volatile(iRegL src, /* sync_memory*/indirect mem)
 7786 %{
 7787   match(Set mem (StoreL mem src));
 7788 
 7789   ins_cost(VOLATILE_REF_COST);
 7790   format %{ &quot;stlr  $src, $mem\t# int&quot; %}
 7791 
 7792   ins_encode(aarch64_enc_stlr(src, mem));
 7793 
 7794   ins_pipe(pipe_class_memory);
 7795 %}
 7796 
 7797 // Store Pointer
 7798 instruct storeP_volatile(iRegP src, /* sync_memory*/indirect mem)
 7799 %{
 7800   match(Set mem (StoreP mem src));
 7801 
 7802   ins_cost(VOLATILE_REF_COST);
 7803   format %{ &quot;stlr  $src, $mem\t# ptr&quot; %}
 7804 
 7805   ins_encode(aarch64_enc_stlr(src, mem));
 7806 
 7807   ins_pipe(pipe_class_memory);
 7808 %}
 7809 
 7810 // Store Compressed Pointer
 7811 instruct storeN_volatile(iRegN src, /* sync_memory*/indirect mem)
 7812 %{
 7813   match(Set mem (StoreN mem src));
 7814 
 7815   ins_cost(VOLATILE_REF_COST);
 7816   format %{ &quot;stlrw  $src, $mem\t# compressed ptr&quot; %}
 7817 
 7818   ins_encode(aarch64_enc_stlrw(src, mem));
 7819 
 7820   ins_pipe(pipe_class_memory);
 7821 %}
 7822 
 7823 // Store Float
 7824 instruct storeF_volatile(vRegF src, /* sync_memory*/indirect mem)
 7825 %{
 7826   match(Set mem (StoreF mem src));
 7827 
 7828   ins_cost(VOLATILE_REF_COST);
 7829   format %{ &quot;stlrs  $src, $mem\t# float&quot; %}
 7830 
 7831   ins_encode( aarch64_enc_fstlrs(src, mem) );
 7832 
 7833   ins_pipe(pipe_class_memory);
 7834 %}
 7835 
 7836 // TODO
 7837 // implement storeImmF0 and storeFImmPacked
 7838 
 7839 // Store Double
 7840 instruct storeD_volatile(vRegD src, /* sync_memory*/indirect mem)
 7841 %{
 7842   match(Set mem (StoreD mem src));
 7843 
 7844   ins_cost(VOLATILE_REF_COST);
 7845   format %{ &quot;stlrd  $src, $mem\t# double&quot; %}
 7846 
 7847   ins_encode( aarch64_enc_fstlrd(src, mem) );
 7848 
 7849   ins_pipe(pipe_class_memory);
 7850 %}
 7851 
 7852 //  ---------------- end of volatile loads and stores ----------------
 7853 
 7854 instruct cacheWB(indirect addr)
 7855 %{
 7856   predicate(VM_Version::supports_data_cache_line_flush());
 7857   match(CacheWB addr);
 7858 
 7859   ins_cost(100);
 7860   format %{&quot;cache wb $addr&quot; %}
 7861   ins_encode %{
 7862     assert($addr-&gt;index_position() &lt; 0, &quot;should be&quot;);
 7863     assert($addr$$disp == 0, &quot;should be&quot;);
 7864     __ cache_wb(Address($addr$$base$$Register, 0));
 7865   %}
 7866   ins_pipe(pipe_slow); // XXX
 7867 %}
 7868 
 7869 instruct cacheWBPreSync()
 7870 %{
 7871   predicate(VM_Version::supports_data_cache_line_flush());
 7872   match(CacheWBPreSync);
 7873 
 7874   ins_cost(100);
 7875   format %{&quot;cache wb presync&quot; %}
 7876   ins_encode %{
 7877     __ cache_wbsync(true);
 7878   %}
 7879   ins_pipe(pipe_slow); // XXX
 7880 %}
 7881 
 7882 instruct cacheWBPostSync()
 7883 %{
 7884   predicate(VM_Version::supports_data_cache_line_flush());
 7885   match(CacheWBPostSync);
 7886 
 7887   ins_cost(100);
 7888   format %{&quot;cache wb postsync&quot; %}
 7889   ins_encode %{
 7890     __ cache_wbsync(false);
 7891   %}
 7892   ins_pipe(pipe_slow); // XXX
 7893 %}
 7894 
 7895 // ============================================================================
 7896 // BSWAP Instructions
 7897 
 7898 instruct bytes_reverse_int(iRegINoSp dst, iRegIorL2I src) %{
 7899   match(Set dst (ReverseBytesI src));
 7900 
 7901   ins_cost(INSN_COST);
 7902   format %{ &quot;revw  $dst, $src&quot; %}
 7903 
 7904   ins_encode %{
 7905     __ revw(as_Register($dst$$reg), as_Register($src$$reg));
 7906   %}
 7907 
 7908   ins_pipe(ialu_reg);
 7909 %}
 7910 
 7911 instruct bytes_reverse_long(iRegLNoSp dst, iRegL src) %{
 7912   match(Set dst (ReverseBytesL src));
 7913 
 7914   ins_cost(INSN_COST);
 7915   format %{ &quot;rev  $dst, $src&quot; %}
 7916 
 7917   ins_encode %{
 7918     __ rev(as_Register($dst$$reg), as_Register($src$$reg));
 7919   %}
 7920 
 7921   ins_pipe(ialu_reg);
 7922 %}
 7923 
 7924 instruct bytes_reverse_unsigned_short(iRegINoSp dst, iRegIorL2I src) %{
 7925   match(Set dst (ReverseBytesUS src));
 7926 
 7927   ins_cost(INSN_COST);
 7928   format %{ &quot;rev16w  $dst, $src&quot; %}
 7929 
 7930   ins_encode %{
 7931     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7932   %}
 7933 
 7934   ins_pipe(ialu_reg);
 7935 %}
 7936 
 7937 instruct bytes_reverse_short(iRegINoSp dst, iRegIorL2I src) %{
 7938   match(Set dst (ReverseBytesS src));
 7939 
 7940   ins_cost(INSN_COST);
 7941   format %{ &quot;rev16w  $dst, $src\n\t&quot;
 7942             &quot;sbfmw $dst, $dst, #0, #15&quot; %}
 7943 
 7944   ins_encode %{
 7945     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7946     __ sbfmw(as_Register($dst$$reg), as_Register($dst$$reg), 0U, 15U);
 7947   %}
 7948 
 7949   ins_pipe(ialu_reg);
 7950 %}
 7951 
 7952 // ============================================================================
 7953 // Zero Count Instructions
 7954 
 7955 instruct countLeadingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 7956   match(Set dst (CountLeadingZerosI src));
 7957 
 7958   ins_cost(INSN_COST);
 7959   format %{ &quot;clzw  $dst, $src&quot; %}
 7960   ins_encode %{
 7961     __ clzw(as_Register($dst$$reg), as_Register($src$$reg));
 7962   %}
 7963 
 7964   ins_pipe(ialu_reg);
 7965 %}
 7966 
 7967 instruct countLeadingZerosL(iRegINoSp dst, iRegL src) %{
 7968   match(Set dst (CountLeadingZerosL src));
 7969 
 7970   ins_cost(INSN_COST);
 7971   format %{ &quot;clz   $dst, $src&quot; %}
 7972   ins_encode %{
 7973     __ clz(as_Register($dst$$reg), as_Register($src$$reg));
 7974   %}
 7975 
 7976   ins_pipe(ialu_reg);
 7977 %}
 7978 
 7979 instruct countTrailingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 7980   match(Set dst (CountTrailingZerosI src));
 7981 
 7982   ins_cost(INSN_COST * 2);
 7983   format %{ &quot;rbitw  $dst, $src\n\t&quot;
 7984             &quot;clzw   $dst, $dst&quot; %}
 7985   ins_encode %{
 7986     __ rbitw(as_Register($dst$$reg), as_Register($src$$reg));
 7987     __ clzw(as_Register($dst$$reg), as_Register($dst$$reg));
 7988   %}
 7989 
 7990   ins_pipe(ialu_reg);
 7991 %}
 7992 
 7993 instruct countTrailingZerosL(iRegINoSp dst, iRegL src) %{
 7994   match(Set dst (CountTrailingZerosL src));
 7995 
 7996   ins_cost(INSN_COST * 2);
 7997   format %{ &quot;rbit   $dst, $src\n\t&quot;
 7998             &quot;clz    $dst, $dst&quot; %}
 7999   ins_encode %{
 8000     __ rbit(as_Register($dst$$reg), as_Register($src$$reg));
 8001     __ clz(as_Register($dst$$reg), as_Register($dst$$reg));
 8002   %}
 8003 
 8004   ins_pipe(ialu_reg);
 8005 %}
 8006 
 8007 //---------- Population Count Instructions -------------------------------------
 8008 //
 8009 
 8010 instruct popCountI(iRegINoSp dst, iRegIorL2I src, vRegF tmp) %{
 8011   predicate(UsePopCountInstruction);
 8012   match(Set dst (PopCountI src));
 8013   effect(TEMP tmp);
 8014   ins_cost(INSN_COST * 13);
 8015 
 8016   format %{ &quot;movw   $src, $src\n\t&quot;
 8017             &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8018             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8019             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8020             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8021   ins_encode %{
 8022     __ movw($src$$Register, $src$$Register); // ensure top 32 bits 0
 8023     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8024     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8025     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8026     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8027   %}
 8028 
 8029   ins_pipe(pipe_class_default);
 8030 %}
 8031 
 8032 instruct popCountI_mem(iRegINoSp dst, memory4 mem, vRegF tmp) %{
 8033   predicate(UsePopCountInstruction);
 8034   match(Set dst (PopCountI (LoadI mem)));
 8035   effect(TEMP tmp);
 8036   ins_cost(INSN_COST * 13);
 8037 
 8038   format %{ &quot;ldrs   $tmp, $mem\n\t&quot;
 8039             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8040             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8041             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8042   ins_encode %{
 8043     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8044     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, tmp_reg, $mem-&gt;opcode(),
 8045               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 8046     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8047     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8048     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8049   %}
 8050 
 8051   ins_pipe(pipe_class_default);
 8052 %}
 8053 
 8054 // Note: Long.bitCount(long) returns an int.
 8055 instruct popCountL(iRegINoSp dst, iRegL src, vRegD tmp) %{
 8056   predicate(UsePopCountInstruction);
 8057   match(Set dst (PopCountL src));
 8058   effect(TEMP tmp);
 8059   ins_cost(INSN_COST * 13);
 8060 
 8061   format %{ &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8062             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8063             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8064             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8065   ins_encode %{
 8066     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8067     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8068     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8069     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8070   %}
 8071 
 8072   ins_pipe(pipe_class_default);
 8073 %}
 8074 
 8075 instruct popCountL_mem(iRegINoSp dst, memory8 mem, vRegD tmp) %{
 8076   predicate(UsePopCountInstruction);
 8077   match(Set dst (PopCountL (LoadL mem)));
 8078   effect(TEMP tmp);
 8079   ins_cost(INSN_COST * 13);
 8080 
 8081   format %{ &quot;ldrd   $tmp, $mem\n\t&quot;
 8082             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8083             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8084             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8085   ins_encode %{
 8086     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8087     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, tmp_reg, $mem-&gt;opcode(),
 8088               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 8089     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8090     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8091     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8092   %}
 8093 
 8094   ins_pipe(pipe_class_default);
 8095 %}
 8096 
 8097 // ============================================================================
 8098 // MemBar Instruction
 8099 
 8100 instruct load_fence() %{
 8101   match(LoadFence);
 8102   ins_cost(VOLATILE_REF_COST);
 8103 
 8104   format %{ &quot;load_fence&quot; %}
 8105 
 8106   ins_encode %{
 8107     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8108   %}
 8109   ins_pipe(pipe_serial);
 8110 %}
 8111 
 8112 instruct unnecessary_membar_acquire() %{
 8113   predicate(unnecessary_acquire(n));
 8114   match(MemBarAcquire);
 8115   ins_cost(0);
 8116 
 8117   format %{ &quot;membar_acquire (elided)&quot; %}
 8118 
 8119   ins_encode %{
 8120     __ block_comment(&quot;membar_acquire (elided)&quot;);
 8121   %}
 8122 
 8123   ins_pipe(pipe_class_empty);
 8124 %}
 8125 
 8126 instruct membar_acquire() %{
 8127   match(MemBarAcquire);
 8128   ins_cost(VOLATILE_REF_COST);
 8129 
 8130   format %{ &quot;membar_acquire\n\t&quot;
 8131             &quot;dmb ish&quot; %}
 8132 
 8133   ins_encode %{
 8134     __ block_comment(&quot;membar_acquire&quot;);
 8135     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8136   %}
 8137 
 8138   ins_pipe(pipe_serial);
 8139 %}
 8140 
 8141 
 8142 instruct membar_acquire_lock() %{
 8143   match(MemBarAcquireLock);
 8144   ins_cost(VOLATILE_REF_COST);
 8145 
 8146   format %{ &quot;membar_acquire_lock (elided)&quot; %}
 8147 
 8148   ins_encode %{
 8149     __ block_comment(&quot;membar_acquire_lock (elided)&quot;);
 8150   %}
 8151 
 8152   ins_pipe(pipe_serial);
 8153 %}
 8154 
 8155 instruct store_fence() %{
 8156   match(StoreFence);
 8157   ins_cost(VOLATILE_REF_COST);
 8158 
 8159   format %{ &quot;store_fence&quot; %}
 8160 
 8161   ins_encode %{
 8162     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8163   %}
 8164   ins_pipe(pipe_serial);
 8165 %}
 8166 
 8167 instruct unnecessary_membar_release() %{
 8168   predicate(unnecessary_release(n));
 8169   match(MemBarRelease);
 8170   ins_cost(0);
 8171 
 8172   format %{ &quot;membar_release (elided)&quot; %}
 8173 
 8174   ins_encode %{
 8175     __ block_comment(&quot;membar_release (elided)&quot;);
 8176   %}
 8177   ins_pipe(pipe_serial);
 8178 %}
 8179 
 8180 instruct membar_release() %{
 8181   match(MemBarRelease);
 8182   ins_cost(VOLATILE_REF_COST);
 8183 
 8184   format %{ &quot;membar_release\n\t&quot;
 8185             &quot;dmb ish&quot; %}
 8186 
 8187   ins_encode %{
 8188     __ block_comment(&quot;membar_release&quot;);
 8189     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8190   %}
 8191   ins_pipe(pipe_serial);
 8192 %}
 8193 
 8194 instruct membar_storestore() %{
 8195   match(MemBarStoreStore);
 8196   ins_cost(VOLATILE_REF_COST);
 8197 
 8198   format %{ &quot;MEMBAR-store-store&quot; %}
 8199 
 8200   ins_encode %{
 8201     __ membar(Assembler::StoreStore);
 8202   %}
 8203   ins_pipe(pipe_serial);
 8204 %}
 8205 
 8206 instruct membar_release_lock() %{
 8207   match(MemBarReleaseLock);
 8208   ins_cost(VOLATILE_REF_COST);
 8209 
 8210   format %{ &quot;membar_release_lock (elided)&quot; %}
 8211 
 8212   ins_encode %{
 8213     __ block_comment(&quot;membar_release_lock (elided)&quot;);
 8214   %}
 8215 
 8216   ins_pipe(pipe_serial);
 8217 %}
 8218 
 8219 instruct unnecessary_membar_volatile() %{
 8220   predicate(unnecessary_volatile(n));
 8221   match(MemBarVolatile);
 8222   ins_cost(0);
 8223 
 8224   format %{ &quot;membar_volatile (elided)&quot; %}
 8225 
 8226   ins_encode %{
 8227     __ block_comment(&quot;membar_volatile (elided)&quot;);
 8228   %}
 8229 
 8230   ins_pipe(pipe_serial);
 8231 %}
 8232 
 8233 instruct membar_volatile() %{
 8234   match(MemBarVolatile);
 8235   ins_cost(VOLATILE_REF_COST*100);
 8236 
 8237   format %{ &quot;membar_volatile\n\t&quot;
 8238              &quot;dmb ish&quot;%}
 8239 
 8240   ins_encode %{
 8241     __ block_comment(&quot;membar_volatile&quot;);
 8242     __ membar(Assembler::StoreLoad);
 8243   %}
 8244 
 8245   ins_pipe(pipe_serial);
 8246 %}
 8247 
 8248 // ============================================================================
 8249 // Cast/Convert Instructions
 8250 
 8251 instruct castX2P(iRegPNoSp dst, iRegL src) %{
 8252   match(Set dst (CastX2P src));
 8253 
 8254   ins_cost(INSN_COST);
 8255   format %{ &quot;mov $dst, $src\t# long -&gt; ptr&quot; %}
 8256 
 8257   ins_encode %{
 8258     if ($dst$$reg != $src$$reg) {
 8259       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8260     }
 8261   %}
 8262 
 8263   ins_pipe(ialu_reg);
 8264 %}
 8265 
 8266 instruct castP2X(iRegLNoSp dst, iRegP src) %{
 8267   match(Set dst (CastP2X src));
 8268 
 8269   ins_cost(INSN_COST);
 8270   format %{ &quot;mov $dst, $src\t# ptr -&gt; long&quot; %}
 8271 
 8272   ins_encode %{
 8273     if ($dst$$reg != $src$$reg) {
 8274       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8275     }
 8276   %}
 8277 
 8278   ins_pipe(ialu_reg);
 8279 %}
 8280 
 8281 // Convert oop into int for vectors alignment masking
 8282 instruct convP2I(iRegINoSp dst, iRegP src) %{
 8283   match(Set dst (ConvL2I (CastP2X src)));
 8284 
 8285   ins_cost(INSN_COST);
 8286   format %{ &quot;movw $dst, $src\t# ptr -&gt; int&quot; %}
 8287   ins_encode %{
 8288     __ movw($dst$$Register, $src$$Register);
 8289   %}
 8290 
 8291   ins_pipe(ialu_reg);
 8292 %}
 8293 
 8294 // Convert compressed oop into int for vectors alignment masking
 8295 // in case of 32bit oops (heap &lt; 4Gb).
 8296 instruct convN2I(iRegINoSp dst, iRegN src)
 8297 %{
 8298   predicate(CompressedOops::shift() == 0);
 8299   match(Set dst (ConvL2I (CastP2X (DecodeN src))));
 8300 
 8301   ins_cost(INSN_COST);
 8302   format %{ &quot;mov dst, $src\t# compressed ptr -&gt; int&quot; %}
 8303   ins_encode %{
 8304     __ movw($dst$$Register, $src$$Register);
 8305   %}
 8306 
 8307   ins_pipe(ialu_reg);
 8308 %}
 8309 
 8310 
 8311 // Convert oop pointer into compressed form
 8312 instruct encodeHeapOop(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8313   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() != TypePtr::NotNull);
 8314   match(Set dst (EncodeP src));
 8315   effect(KILL cr);
 8316   ins_cost(INSN_COST * 3);
 8317   format %{ &quot;encode_heap_oop $dst, $src&quot; %}
 8318   ins_encode %{
 8319     Register s = $src$$Register;
 8320     Register d = $dst$$Register;
 8321     __ encode_heap_oop(d, s);
 8322   %}
 8323   ins_pipe(ialu_reg);
 8324 %}
 8325 
 8326 instruct encodeHeapOop_not_null(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8327   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() == TypePtr::NotNull);
 8328   match(Set dst (EncodeP src));
 8329   ins_cost(INSN_COST * 3);
 8330   format %{ &quot;encode_heap_oop_not_null $dst, $src&quot; %}
 8331   ins_encode %{
 8332     __ encode_heap_oop_not_null($dst$$Register, $src$$Register);
 8333   %}
 8334   ins_pipe(ialu_reg);
 8335 %}
 8336 
 8337 instruct decodeHeapOop(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8338   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::NotNull &amp;&amp;
 8339             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::Constant);
 8340   match(Set dst (DecodeN src));
 8341   ins_cost(INSN_COST * 3);
 8342   format %{ &quot;decode_heap_oop $dst, $src&quot; %}
 8343   ins_encode %{
 8344     Register s = $src$$Register;
 8345     Register d = $dst$$Register;
 8346     __ decode_heap_oop(d, s);
 8347   %}
 8348   ins_pipe(ialu_reg);
 8349 %}
 8350 
 8351 instruct decodeHeapOop_not_null(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8352   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::NotNull ||
 8353             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::Constant);
 8354   match(Set dst (DecodeN src));
 8355   ins_cost(INSN_COST * 3);
 8356   format %{ &quot;decode_heap_oop_not_null $dst, $src&quot; %}
 8357   ins_encode %{
 8358     Register s = $src$$Register;
 8359     Register d = $dst$$Register;
 8360     __ decode_heap_oop_not_null(d, s);
 8361   %}
 8362   ins_pipe(ialu_reg);
 8363 %}
 8364 
 8365 // n.b. AArch64 implementations of encode_klass_not_null and
 8366 // decode_klass_not_null do not modify the flags register so, unlike
 8367 // Intel, we don&#39;t kill CR as a side effect here
 8368 
 8369 instruct encodeKlass_not_null(iRegNNoSp dst, iRegP src) %{
 8370   match(Set dst (EncodePKlass src));
 8371 
 8372   ins_cost(INSN_COST * 3);
 8373   format %{ &quot;encode_klass_not_null $dst,$src&quot; %}
 8374 
 8375   ins_encode %{
 8376     Register src_reg = as_Register($src$$reg);
 8377     Register dst_reg = as_Register($dst$$reg);
 8378     __ encode_klass_not_null(dst_reg, src_reg);
 8379   %}
 8380 
 8381    ins_pipe(ialu_reg);
 8382 %}
 8383 
 8384 instruct decodeKlass_not_null(iRegPNoSp dst, iRegN src) %{
 8385   match(Set dst (DecodeNKlass src));
 8386 
 8387   ins_cost(INSN_COST * 3);
 8388   format %{ &quot;decode_klass_not_null $dst,$src&quot; %}
 8389 
 8390   ins_encode %{
 8391     Register src_reg = as_Register($src$$reg);
 8392     Register dst_reg = as_Register($dst$$reg);
 8393     if (dst_reg != src_reg) {
 8394       __ decode_klass_not_null(dst_reg, src_reg);
 8395     } else {
 8396       __ decode_klass_not_null(dst_reg);
 8397     }
 8398   %}
 8399 
 8400    ins_pipe(ialu_reg);
 8401 %}
 8402 
 8403 instruct checkCastPP(iRegPNoSp dst)
 8404 %{
 8405   match(Set dst (CheckCastPP dst));
 8406 
 8407   size(0);
 8408   format %{ &quot;# checkcastPP of $dst&quot; %}
 8409   ins_encode(/* empty encoding */);
 8410   ins_pipe(pipe_class_empty);
 8411 %}
 8412 
 8413 instruct castPP(iRegPNoSp dst)
 8414 %{
 8415   match(Set dst (CastPP dst));
 8416 
 8417   size(0);
 8418   format %{ &quot;# castPP of $dst&quot; %}
 8419   ins_encode(/* empty encoding */);
 8420   ins_pipe(pipe_class_empty);
 8421 %}
 8422 
 8423 instruct castII(iRegI dst)
 8424 %{
 8425   match(Set dst (CastII dst));
 8426 
 8427   size(0);
 8428   format %{ &quot;# castII of $dst&quot; %}
 8429   ins_encode(/* empty encoding */);
 8430   ins_cost(0);
 8431   ins_pipe(pipe_class_empty);
 8432 %}
 8433 
 8434 // ============================================================================
 8435 // Atomic operation instructions
 8436 //
 8437 // Intel and SPARC both implement Ideal Node LoadPLocked and
 8438 // Store{PIL}Conditional instructions using a normal load for the
 8439 // LoadPLocked and a CAS for the Store{PIL}Conditional.
 8440 //
 8441 // The ideal code appears only to use LoadPLocked/StorePLocked as a
 8442 // pair to lock object allocations from Eden space when not using
 8443 // TLABs.
 8444 //
 8445 // There does not appear to be a Load{IL}Locked Ideal Node and the
 8446 // Ideal code appears to use Store{IL}Conditional as an alias for CAS
 8447 // and to use StoreIConditional only for 32-bit and StoreLConditional
 8448 // only for 64-bit.
 8449 //
 8450 // We implement LoadPLocked and StorePLocked instructions using,
 8451 // respectively the AArch64 hw load-exclusive and store-conditional
 8452 // instructions. Whereas we must implement each of
 8453 // Store{IL}Conditional using a CAS which employs a pair of
 8454 // instructions comprising a load-exclusive followed by a
 8455 // store-conditional.
 8456 
 8457 
 8458 // Locked-load (linked load) of the current heap-top
 8459 // used when updating the eden heap top
 8460 // implemented using ldaxr on AArch64
 8461 
 8462 instruct loadPLocked(iRegPNoSp dst, indirect mem)
 8463 %{
 8464   match(Set dst (LoadPLocked mem));
 8465 
 8466   ins_cost(VOLATILE_REF_COST);
 8467 
 8468   format %{ &quot;ldaxr $dst, $mem\t# ptr linked acquire&quot; %}
 8469 
 8470   ins_encode(aarch64_enc_ldaxr(dst, mem));
 8471 
 8472   ins_pipe(pipe_serial);
 8473 %}
 8474 
 8475 // Conditional-store of the updated heap-top.
 8476 // Used during allocation of the shared heap.
 8477 // Sets flag (EQ) on success.
 8478 // implemented using stlxr on AArch64.
 8479 
 8480 instruct storePConditional(memory8 heap_top_ptr, iRegP oldval, iRegP newval, rFlagsReg cr)
 8481 %{
 8482   match(Set cr (StorePConditional heap_top_ptr (Binary oldval newval)));
 8483 
 8484   ins_cost(VOLATILE_REF_COST);
 8485 
 8486  // TODO
 8487  // do we need to do a store-conditional release or can we just use a
 8488  // plain store-conditional?
 8489 
 8490   format %{
 8491     &quot;stlxr rscratch1, $newval, $heap_top_ptr\t# ptr cond release&quot;
 8492     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8493   %}
 8494 
 8495   ins_encode(aarch64_enc_stlxr(newval, heap_top_ptr));
 8496 
 8497   ins_pipe(pipe_serial);
 8498 %}
 8499 
 8500 
 8501 // storeLConditional is used by PhaseMacroExpand::expand_lock_node
 8502 // when attempting to rebias a lock towards the current thread.  We
 8503 // must use the acquire form of cmpxchg in order to guarantee acquire
 8504 // semantics in this case.
 8505 instruct storeLConditional(indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr)
 8506 %{
 8507   match(Set cr (StoreLConditional mem (Binary oldval newval)));
 8508 
 8509   ins_cost(VOLATILE_REF_COST);
 8510 
 8511   format %{
 8512     &quot;cmpxchg rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8513     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8514   %}
 8515 
 8516   ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval));
 8517 
 8518   ins_pipe(pipe_slow);
 8519 %}
 8520 
 8521 // storeIConditional also has acquire semantics, for no better reason
 8522 // than matching storeLConditional.  At the time of writing this
 8523 // comment storeIConditional was not used anywhere by AArch64.
 8524 instruct storeIConditional(indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr)
 8525 %{
 8526   match(Set cr (StoreIConditional mem (Binary oldval newval)));
 8527 
 8528   ins_cost(VOLATILE_REF_COST);
 8529 
 8530   format %{
 8531     &quot;cmpxchgw rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8532     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8533   %}
 8534 
 8535   ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval));
 8536 
 8537   ins_pipe(pipe_slow);
 8538 %}
 8539 
 8540 // standard CompareAndSwapX when we are using barriers
 8541 // these have higher priority than the rules selected by a predicate
 8542 
 8543 // XXX No flag versions for CompareAndSwap{I,L,P,N} because matcher
 8544 // can&#39;t match them
 8545 
 8546 instruct compareAndSwapB(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8547 
 8548   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8549   ins_cost(2 * VOLATILE_REF_COST);
 8550 
 8551   effect(KILL cr);
 8552 
 8553   format %{
 8554     &quot;cmpxchgb $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8555     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8556   %}
 8557 
 8558   ins_encode(aarch64_enc_cmpxchgb(mem, oldval, newval),
 8559             aarch64_enc_cset_eq(res));
 8560 
 8561   ins_pipe(pipe_slow);
 8562 %}
 8563 
 8564 instruct compareAndSwapS(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8565 
 8566   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8567   ins_cost(2 * VOLATILE_REF_COST);
 8568 
 8569   effect(KILL cr);
 8570 
 8571   format %{
 8572     &quot;cmpxchgs $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8573     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8574   %}
 8575 
 8576   ins_encode(aarch64_enc_cmpxchgs(mem, oldval, newval),
 8577             aarch64_enc_cset_eq(res));
 8578 
 8579   ins_pipe(pipe_slow);
 8580 %}
 8581 
 8582 instruct compareAndSwapI(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8583 
 8584   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8585   ins_cost(2 * VOLATILE_REF_COST);
 8586 
 8587   effect(KILL cr);
 8588 
 8589  format %{
 8590     &quot;cmpxchgw $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8591     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8592  %}
 8593 
 8594  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8595             aarch64_enc_cset_eq(res));
 8596 
 8597   ins_pipe(pipe_slow);
 8598 %}
 8599 
 8600 instruct compareAndSwapL(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8601 
 8602   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8603   ins_cost(2 * VOLATILE_REF_COST);
 8604 
 8605   effect(KILL cr);
 8606 
 8607  format %{
 8608     &quot;cmpxchg $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8609     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8610  %}
 8611 
 8612  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8613             aarch64_enc_cset_eq(res));
 8614 
 8615   ins_pipe(pipe_slow);
 8616 %}
 8617 
 8618 instruct compareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8619 
 8620   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8621   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8622   ins_cost(2 * VOLATILE_REF_COST);
 8623 
 8624   effect(KILL cr);
 8625 
 8626  format %{
 8627     &quot;cmpxchg $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8628     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8629  %}
 8630 
 8631  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8632             aarch64_enc_cset_eq(res));
 8633 
 8634   ins_pipe(pipe_slow);
 8635 %}
 8636 
 8637 instruct compareAndSwapN(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8638 
 8639   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8640   ins_cost(2 * VOLATILE_REF_COST);
 8641 
 8642   effect(KILL cr);
 8643 
 8644  format %{
 8645     &quot;cmpxchgw $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8646     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8647  %}
 8648 
 8649  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8650             aarch64_enc_cset_eq(res));
 8651 
 8652   ins_pipe(pipe_slow);
 8653 %}
 8654 
 8655 // alternative CompareAndSwapX when we are eliding barriers
 8656 
 8657 instruct compareAndSwapBAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8658 
 8659   predicate(needs_acquiring_load_exclusive(n));
 8660   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8661   ins_cost(VOLATILE_REF_COST);
 8662 
 8663   effect(KILL cr);
 8664 
 8665   format %{
 8666     &quot;cmpxchgb_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8667     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8668   %}
 8669 
 8670   ins_encode(aarch64_enc_cmpxchgb_acq(mem, oldval, newval),
 8671             aarch64_enc_cset_eq(res));
 8672 
 8673   ins_pipe(pipe_slow);
 8674 %}
 8675 
 8676 instruct compareAndSwapSAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8677 
 8678   predicate(needs_acquiring_load_exclusive(n));
 8679   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8680   ins_cost(VOLATILE_REF_COST);
 8681 
 8682   effect(KILL cr);
 8683 
 8684   format %{
 8685     &quot;cmpxchgs_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8686     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8687   %}
 8688 
 8689   ins_encode(aarch64_enc_cmpxchgs_acq(mem, oldval, newval),
 8690             aarch64_enc_cset_eq(res));
 8691 
 8692   ins_pipe(pipe_slow);
 8693 %}
 8694 
 8695 instruct compareAndSwapIAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8696 
 8697   predicate(needs_acquiring_load_exclusive(n));
 8698   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8699   ins_cost(VOLATILE_REF_COST);
 8700 
 8701   effect(KILL cr);
 8702 
 8703  format %{
 8704     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8705     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8706  %}
 8707 
 8708  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8709             aarch64_enc_cset_eq(res));
 8710 
 8711   ins_pipe(pipe_slow);
 8712 %}
 8713 
 8714 instruct compareAndSwapLAcq(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8715 
 8716   predicate(needs_acquiring_load_exclusive(n));
 8717   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8718   ins_cost(VOLATILE_REF_COST);
 8719 
 8720   effect(KILL cr);
 8721 
 8722  format %{
 8723     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8724     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8725  %}
 8726 
 8727  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8728             aarch64_enc_cset_eq(res));
 8729 
 8730   ins_pipe(pipe_slow);
 8731 %}
 8732 
 8733 instruct compareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8734 
 8735   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 8736   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8737   ins_cost(VOLATILE_REF_COST);
 8738 
 8739   effect(KILL cr);
 8740 
 8741  format %{
 8742     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8743     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8744  %}
 8745 
 8746  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8747             aarch64_enc_cset_eq(res));
 8748 
 8749   ins_pipe(pipe_slow);
 8750 %}
 8751 
 8752 instruct compareAndSwapNAcq(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8753 
 8754   predicate(needs_acquiring_load_exclusive(n));
 8755   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8756   ins_cost(VOLATILE_REF_COST);
 8757 
 8758   effect(KILL cr);
 8759 
 8760  format %{
 8761     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8762     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8763  %}
 8764 
 8765  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8766             aarch64_enc_cset_eq(res));
 8767 
 8768   ins_pipe(pipe_slow);
 8769 %}
 8770 
 8771 
 8772 // ---------------------------------------------------------------------
 8773 
 8774 
 8775 // BEGIN This section of the file is automatically generated. Do not edit --------------
 8776 
 8777 // Sundry CAS operations.  Note that release is always true,
 8778 // regardless of the memory ordering of the CAS.  This is because we
 8779 // need the volatile case to be sequentially consistent but there is
 8780 // no trailing StoreLoad barrier emitted by C2.  Unfortunately we
 8781 // can&#39;t check the type of memory ordering here, so we always emit a
 8782 // STLXR.
 8783 
 8784 // This section is generated from aarch64_ad_cas.m4
 8785 
 8786 
 8787 
 8788 instruct compareAndExchangeB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8789   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8790   ins_cost(2 * VOLATILE_REF_COST);
 8791   effect(TEMP_DEF res, KILL cr);
 8792   format %{
 8793     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8794   %}
 8795   ins_encode %{
 8796     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8797                Assembler::byte, /*acquire*/ false, /*release*/ true,
 8798                /*weak*/ false, $res$$Register);
 8799     __ sxtbw($res$$Register, $res$$Register);
 8800   %}
 8801   ins_pipe(pipe_slow);
 8802 %}
 8803 
 8804 instruct compareAndExchangeS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8805   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8806   ins_cost(2 * VOLATILE_REF_COST);
 8807   effect(TEMP_DEF res, KILL cr);
 8808   format %{
 8809     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8810   %}
 8811   ins_encode %{
 8812     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8813                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 8814                /*weak*/ false, $res$$Register);
 8815     __ sxthw($res$$Register, $res$$Register);
 8816   %}
 8817   ins_pipe(pipe_slow);
 8818 %}
 8819 
 8820 instruct compareAndExchangeI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8821   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8822   ins_cost(2 * VOLATILE_REF_COST);
 8823   effect(TEMP_DEF res, KILL cr);
 8824   format %{
 8825     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8826   %}
 8827   ins_encode %{
 8828     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8829                Assembler::word, /*acquire*/ false, /*release*/ true,
 8830                /*weak*/ false, $res$$Register);
 8831   %}
 8832   ins_pipe(pipe_slow);
 8833 %}
 8834 
 8835 instruct compareAndExchangeL(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8836   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8837   ins_cost(2 * VOLATILE_REF_COST);
 8838   effect(TEMP_DEF res, KILL cr);
 8839   format %{
 8840     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8841   %}
 8842   ins_encode %{
 8843     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8844                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8845                /*weak*/ false, $res$$Register);
 8846   %}
 8847   ins_pipe(pipe_slow);
 8848 %}
 8849 
 8850 instruct compareAndExchangeN(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8851   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8852   ins_cost(2 * VOLATILE_REF_COST);
 8853   effect(TEMP_DEF res, KILL cr);
 8854   format %{
 8855     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8856   %}
 8857   ins_encode %{
 8858     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8859                Assembler::word, /*acquire*/ false, /*release*/ true,
 8860                /*weak*/ false, $res$$Register);
 8861   %}
 8862   ins_pipe(pipe_slow);
 8863 %}
 8864 
 8865 instruct compareAndExchangeP(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8866   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8867   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 8868   ins_cost(2 * VOLATILE_REF_COST);
 8869   effect(TEMP_DEF res, KILL cr);
 8870   format %{
 8871     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8872   %}
 8873   ins_encode %{
 8874     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8875                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8876                /*weak*/ false, $res$$Register);
 8877   %}
 8878   ins_pipe(pipe_slow);
 8879 %}
 8880 
 8881 instruct compareAndExchangeBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8882   predicate(needs_acquiring_load_exclusive(n));
 8883   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8884   ins_cost(VOLATILE_REF_COST);
 8885   effect(TEMP_DEF res, KILL cr);
 8886   format %{
 8887     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8888   %}
 8889   ins_encode %{
 8890     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8891                Assembler::byte, /*acquire*/ true, /*release*/ true,
 8892                /*weak*/ false, $res$$Register);
 8893     __ sxtbw($res$$Register, $res$$Register);
 8894   %}
 8895   ins_pipe(pipe_slow);
 8896 %}
 8897 
 8898 instruct compareAndExchangeSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8899   predicate(needs_acquiring_load_exclusive(n));
 8900   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8901   ins_cost(VOLATILE_REF_COST);
 8902   effect(TEMP_DEF res, KILL cr);
 8903   format %{
 8904     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8905   %}
 8906   ins_encode %{
 8907     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8908                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 8909                /*weak*/ false, $res$$Register);
 8910     __ sxthw($res$$Register, $res$$Register);
 8911   %}
 8912   ins_pipe(pipe_slow);
 8913 %}
 8914 
 8915 
 8916 instruct compareAndExchangeIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8917   predicate(needs_acquiring_load_exclusive(n));
 8918   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8919   ins_cost(VOLATILE_REF_COST);
 8920   effect(TEMP_DEF res, KILL cr);
 8921   format %{
 8922     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8923   %}
 8924   ins_encode %{
 8925     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8926                Assembler::word, /*acquire*/ true, /*release*/ true,
 8927                /*weak*/ false, $res$$Register);
 8928   %}
 8929   ins_pipe(pipe_slow);
 8930 %}
 8931 
 8932 instruct compareAndExchangeLAcq(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8933   predicate(needs_acquiring_load_exclusive(n));
 8934   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8935   ins_cost(VOLATILE_REF_COST);
 8936   effect(TEMP_DEF res, KILL cr);
 8937   format %{
 8938     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8939   %}
 8940   ins_encode %{
 8941     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8942                Assembler::xword, /*acquire*/ true, /*release*/ true,
 8943                /*weak*/ false, $res$$Register);
 8944   %}
 8945   ins_pipe(pipe_slow);
 8946 %}
 8947 
 8948 
 8949 instruct compareAndExchangeNAcq(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8950   predicate(needs_acquiring_load_exclusive(n));
 8951   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8952   ins_cost(VOLATILE_REF_COST);
 8953   effect(TEMP_DEF res, KILL cr);
 8954   format %{
 8955     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8956   %}
 8957   ins_encode %{
 8958     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8959                Assembler::word, /*acquire*/ true, /*release*/ true,
 8960                /*weak*/ false, $res$$Register);
 8961   %}
 8962   ins_pipe(pipe_slow);
 8963 %}
 8964 
 8965 instruct compareAndExchangePAcq(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8966   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 8967   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 8968   ins_cost(VOLATILE_REF_COST);
 8969   effect(TEMP_DEF res, KILL cr);
 8970   format %{
 8971     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8972   %}
 8973   ins_encode %{
 8974     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8975                Assembler::xword, /*acquire*/ true, /*release*/ true,
 8976                /*weak*/ false, $res$$Register);
 8977   %}
 8978   ins_pipe(pipe_slow);
 8979 %}
 8980 
 8981 instruct weakCompareAndSwapB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8982   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 8983   ins_cost(2 * VOLATILE_REF_COST);
 8984   effect(KILL cr);
 8985   format %{
 8986     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8987     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8988   %}
 8989   ins_encode %{
 8990     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8991                Assembler::byte, /*acquire*/ false, /*release*/ true,
 8992                /*weak*/ true, noreg);
 8993     __ csetw($res$$Register, Assembler::EQ);
 8994   %}
 8995   ins_pipe(pipe_slow);
 8996 %}
 8997 
 8998 instruct weakCompareAndSwapS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8999   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9000   ins_cost(2 * VOLATILE_REF_COST);
 9001   effect(KILL cr);
 9002   format %{
 9003     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9004     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9005   %}
 9006   ins_encode %{
 9007     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9008                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 9009                /*weak*/ true, noreg);
 9010     __ csetw($res$$Register, Assembler::EQ);
 9011   %}
 9012   ins_pipe(pipe_slow);
 9013 %}
 9014 
 9015 instruct weakCompareAndSwapI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9016   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9017   ins_cost(2 * VOLATILE_REF_COST);
 9018   effect(KILL cr);
 9019   format %{
 9020     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9021     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9022   %}
 9023   ins_encode %{
 9024     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9025                Assembler::word, /*acquire*/ false, /*release*/ true,
 9026                /*weak*/ true, noreg);
 9027     __ csetw($res$$Register, Assembler::EQ);
 9028   %}
 9029   ins_pipe(pipe_slow);
 9030 %}
 9031 
 9032 instruct weakCompareAndSwapL(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9033   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9034   ins_cost(2 * VOLATILE_REF_COST);
 9035   effect(KILL cr);
 9036   format %{
 9037     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9038     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9039   %}
 9040   ins_encode %{
 9041     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9042                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9043                /*weak*/ true, noreg);
 9044     __ csetw($res$$Register, Assembler::EQ);
 9045   %}
 9046   ins_pipe(pipe_slow);
 9047 %}
 9048 
 9049 instruct weakCompareAndSwapN(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9050   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9051   ins_cost(2 * VOLATILE_REF_COST);
 9052   effect(KILL cr);
 9053   format %{
 9054     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9055     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9056   %}
 9057   ins_encode %{
 9058     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9059                Assembler::word, /*acquire*/ false, /*release*/ true,
 9060                /*weak*/ true, noreg);
 9061     __ csetw($res$$Register, Assembler::EQ);
 9062   %}
 9063   ins_pipe(pipe_slow);
 9064 %}
 9065 
 9066 instruct weakCompareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9067   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9068   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9069   ins_cost(2 * VOLATILE_REF_COST);
 9070   effect(KILL cr);
 9071   format %{
 9072     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9073     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9074   %}
 9075   ins_encode %{
 9076     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9077                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9078                /*weak*/ true, noreg);
 9079     __ csetw($res$$Register, Assembler::EQ);
 9080   %}
 9081   ins_pipe(pipe_slow);
 9082 %}
 9083 
 9084 instruct weakCompareAndSwapBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9085   predicate(needs_acquiring_load_exclusive(n));
 9086   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9087   ins_cost(VOLATILE_REF_COST);
 9088   effect(KILL cr);
 9089   format %{
 9090     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9091     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9092   %}
 9093   ins_encode %{
 9094     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9095                Assembler::byte, /*acquire*/ true, /*release*/ true,
 9096                /*weak*/ true, noreg);
 9097     __ csetw($res$$Register, Assembler::EQ);
 9098   %}
 9099   ins_pipe(pipe_slow);
 9100 %}
 9101 
 9102 instruct weakCompareAndSwapSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9103   predicate(needs_acquiring_load_exclusive(n));
 9104   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9105   ins_cost(VOLATILE_REF_COST);
 9106   effect(KILL cr);
 9107   format %{
 9108     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9109     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9110   %}
 9111   ins_encode %{
 9112     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9113                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 9114                /*weak*/ true, noreg);
 9115     __ csetw($res$$Register, Assembler::EQ);
 9116   %}
 9117   ins_pipe(pipe_slow);
 9118 %}
 9119 
 9120 instruct weakCompareAndSwapIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9121   predicate(needs_acquiring_load_exclusive(n));
 9122   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9123   ins_cost(VOLATILE_REF_COST);
 9124   effect(KILL cr);
 9125   format %{
 9126     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9127     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9128   %}
 9129   ins_encode %{
 9130     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9131                Assembler::word, /*acquire*/ true, /*release*/ true,
 9132                /*weak*/ true, noreg);
 9133     __ csetw($res$$Register, Assembler::EQ);
 9134   %}
 9135   ins_pipe(pipe_slow);
 9136 %}
 9137 
 9138 instruct weakCompareAndSwapLAcq(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9139   predicate(needs_acquiring_load_exclusive(n));
 9140   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9141   ins_cost(VOLATILE_REF_COST);
 9142   effect(KILL cr);
 9143   format %{
 9144     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9145     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9146   %}
 9147   ins_encode %{
 9148     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9149                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9150                /*weak*/ true, noreg);
 9151     __ csetw($res$$Register, Assembler::EQ);
 9152   %}
 9153   ins_pipe(pipe_slow);
 9154 %}
 9155 
 9156 instruct weakCompareAndSwapNAcq(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9157   predicate(needs_acquiring_load_exclusive(n));
 9158   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9159   ins_cost(VOLATILE_REF_COST);
 9160   effect(KILL cr);
 9161   format %{
 9162     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9163     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9164   %}
 9165   ins_encode %{
 9166     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9167                Assembler::word, /*acquire*/ true, /*release*/ true,
 9168                /*weak*/ true, noreg);
 9169     __ csetw($res$$Register, Assembler::EQ);
 9170   %}
 9171   ins_pipe(pipe_slow);
 9172 %}
 9173 
 9174 instruct weakCompareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9175   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9176   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9177   ins_cost(VOLATILE_REF_COST);
 9178   effect(KILL cr);
 9179   format %{
 9180     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9181     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9182   %}
 9183   ins_encode %{
 9184     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9185                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9186                /*weak*/ true, noreg);
 9187     __ csetw($res$$Register, Assembler::EQ);
 9188   %}
 9189   ins_pipe(pipe_slow);
 9190 %}
 9191 
 9192 // END This section of the file is automatically generated. Do not edit --------------
 9193 // ---------------------------------------------------------------------
 9194 
 9195 instruct get_and_setI(indirect mem, iRegI newv, iRegINoSp prev) %{
 9196   match(Set prev (GetAndSetI mem newv));
 9197   ins_cost(2 * VOLATILE_REF_COST);
 9198   format %{ &quot;atomic_xchgw  $prev, $newv, [$mem]&quot; %}
 9199   ins_encode %{
 9200     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9201   %}
 9202   ins_pipe(pipe_serial);
 9203 %}
 9204 
 9205 instruct get_and_setL(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9206   match(Set prev (GetAndSetL mem newv));
 9207   ins_cost(2 * VOLATILE_REF_COST);
 9208   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9209   ins_encode %{
 9210     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9211   %}
 9212   ins_pipe(pipe_serial);
 9213 %}
 9214 
 9215 instruct get_and_setN(indirect mem, iRegN newv, iRegINoSp prev) %{
 9216   match(Set prev (GetAndSetN mem newv));
 9217   ins_cost(2 * VOLATILE_REF_COST);
 9218   format %{ &quot;atomic_xchgw $prev, $newv, [$mem]&quot; %}
 9219   ins_encode %{
 9220     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9221   %}
 9222   ins_pipe(pipe_serial);
 9223 %}
 9224 
 9225 instruct get_and_setP(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9226   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9227   match(Set prev (GetAndSetP mem newv));
 9228   ins_cost(2 * VOLATILE_REF_COST);
 9229   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9230   ins_encode %{
 9231     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9232   %}
 9233   ins_pipe(pipe_serial);
 9234 %}
 9235 
 9236 instruct get_and_setIAcq(indirect mem, iRegI newv, iRegINoSp prev) %{
 9237   predicate(needs_acquiring_load_exclusive(n));
 9238   match(Set prev (GetAndSetI mem newv));
 9239   ins_cost(VOLATILE_REF_COST);
 9240   format %{ &quot;atomic_xchgw_acq  $prev, $newv, [$mem]&quot; %}
 9241   ins_encode %{
 9242     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9243   %}
 9244   ins_pipe(pipe_serial);
 9245 %}
 9246 
 9247 instruct get_and_setLAcq(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9248   predicate(needs_acquiring_load_exclusive(n));
 9249   match(Set prev (GetAndSetL mem newv));
 9250   ins_cost(VOLATILE_REF_COST);
 9251   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9252   ins_encode %{
 9253     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9254   %}
 9255   ins_pipe(pipe_serial);
 9256 %}
 9257 
 9258 instruct get_and_setNAcq(indirect mem, iRegN newv, iRegINoSp prev) %{
 9259   predicate(needs_acquiring_load_exclusive(n));
 9260   match(Set prev (GetAndSetN mem newv));
 9261   ins_cost(VOLATILE_REF_COST);
 9262   format %{ &quot;atomic_xchgw_acq $prev, $newv, [$mem]&quot; %}
 9263   ins_encode %{
 9264     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9265   %}
 9266   ins_pipe(pipe_serial);
 9267 %}
 9268 
 9269 instruct get_and_setPAcq(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9270   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9271   match(Set prev (GetAndSetP mem newv));
 9272   ins_cost(VOLATILE_REF_COST);
 9273   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9274   ins_encode %{
 9275     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9276   %}
 9277   ins_pipe(pipe_serial);
 9278 %}
 9279 
 9280 
 9281 instruct get_and_addL(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9282   match(Set newval (GetAndAddL mem incr));
 9283   ins_cost(2 * VOLATILE_REF_COST + 1);
 9284   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9285   ins_encode %{
 9286     __ atomic_add($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9287   %}
 9288   ins_pipe(pipe_serial);
 9289 %}
 9290 
 9291 instruct get_and_addL_no_res(indirect mem, Universe dummy, iRegL incr) %{
 9292   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9293   match(Set dummy (GetAndAddL mem incr));
 9294   ins_cost(2 * VOLATILE_REF_COST);
 9295   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9296   ins_encode %{
 9297     __ atomic_add(noreg, $incr$$Register, as_Register($mem$$base));
 9298   %}
 9299   ins_pipe(pipe_serial);
 9300 %}
 9301 
 9302 instruct get_and_addLi(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9303   match(Set newval (GetAndAddL mem incr));
 9304   ins_cost(2 * VOLATILE_REF_COST + 1);
 9305   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9306   ins_encode %{
 9307     __ atomic_add($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9308   %}
 9309   ins_pipe(pipe_serial);
 9310 %}
 9311 
 9312 instruct get_and_addLi_no_res(indirect mem, Universe dummy, immLAddSub incr) %{
 9313   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9314   match(Set dummy (GetAndAddL mem incr));
 9315   ins_cost(2 * VOLATILE_REF_COST);
 9316   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9317   ins_encode %{
 9318     __ atomic_add(noreg, $incr$$constant, as_Register($mem$$base));
 9319   %}
 9320   ins_pipe(pipe_serial);
 9321 %}
 9322 
 9323 instruct get_and_addI(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9324   match(Set newval (GetAndAddI mem incr));
 9325   ins_cost(2 * VOLATILE_REF_COST + 1);
 9326   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9327   ins_encode %{
 9328     __ atomic_addw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9329   %}
 9330   ins_pipe(pipe_serial);
 9331 %}
 9332 
 9333 instruct get_and_addI_no_res(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9334   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9335   match(Set dummy (GetAndAddI mem incr));
 9336   ins_cost(2 * VOLATILE_REF_COST);
 9337   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9338   ins_encode %{
 9339     __ atomic_addw(noreg, $incr$$Register, as_Register($mem$$base));
 9340   %}
 9341   ins_pipe(pipe_serial);
 9342 %}
 9343 
 9344 instruct get_and_addIi(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9345   match(Set newval (GetAndAddI mem incr));
 9346   ins_cost(2 * VOLATILE_REF_COST + 1);
 9347   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9348   ins_encode %{
 9349     __ atomic_addw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9350   %}
 9351   ins_pipe(pipe_serial);
 9352 %}
 9353 
 9354 instruct get_and_addIi_no_res(indirect mem, Universe dummy, immIAddSub incr) %{
 9355   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9356   match(Set dummy (GetAndAddI mem incr));
 9357   ins_cost(2 * VOLATILE_REF_COST);
 9358   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9359   ins_encode %{
 9360     __ atomic_addw(noreg, $incr$$constant, as_Register($mem$$base));
 9361   %}
 9362   ins_pipe(pipe_serial);
 9363 %}
 9364 
 9365 instruct get_and_addLAcq(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9366   predicate(needs_acquiring_load_exclusive(n));
 9367   match(Set newval (GetAndAddL mem incr));
 9368   ins_cost(VOLATILE_REF_COST + 1);
 9369   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9370   ins_encode %{
 9371     __ atomic_addal($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9372   %}
 9373   ins_pipe(pipe_serial);
 9374 %}
 9375 
 9376 instruct get_and_addL_no_resAcq(indirect mem, Universe dummy, iRegL incr) %{
 9377   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9378   match(Set dummy (GetAndAddL mem incr));
 9379   ins_cost(VOLATILE_REF_COST);
 9380   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9381   ins_encode %{
 9382     __ atomic_addal(noreg, $incr$$Register, as_Register($mem$$base));
 9383   %}
 9384   ins_pipe(pipe_serial);
 9385 %}
 9386 
 9387 instruct get_and_addLiAcq(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9388   predicate(needs_acquiring_load_exclusive(n));
 9389   match(Set newval (GetAndAddL mem incr));
 9390   ins_cost(VOLATILE_REF_COST + 1);
 9391   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9392   ins_encode %{
 9393     __ atomic_addal($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9394   %}
 9395   ins_pipe(pipe_serial);
 9396 %}
 9397 
 9398 instruct get_and_addLi_no_resAcq(indirect mem, Universe dummy, immLAddSub incr) %{
 9399   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9400   match(Set dummy (GetAndAddL mem incr));
 9401   ins_cost(VOLATILE_REF_COST);
 9402   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9403   ins_encode %{
 9404     __ atomic_addal(noreg, $incr$$constant, as_Register($mem$$base));
 9405   %}
 9406   ins_pipe(pipe_serial);
 9407 %}
 9408 
 9409 instruct get_and_addIAcq(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9410   predicate(needs_acquiring_load_exclusive(n));
 9411   match(Set newval (GetAndAddI mem incr));
 9412   ins_cost(VOLATILE_REF_COST + 1);
 9413   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9414   ins_encode %{
 9415     __ atomic_addalw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9416   %}
 9417   ins_pipe(pipe_serial);
 9418 %}
 9419 
 9420 instruct get_and_addI_no_resAcq(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9421   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9422   match(Set dummy (GetAndAddI mem incr));
 9423   ins_cost(VOLATILE_REF_COST);
 9424   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9425   ins_encode %{
 9426     __ atomic_addalw(noreg, $incr$$Register, as_Register($mem$$base));
 9427   %}
 9428   ins_pipe(pipe_serial);
 9429 %}
 9430 
 9431 instruct get_and_addIiAcq(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9432   predicate(needs_acquiring_load_exclusive(n));
 9433   match(Set newval (GetAndAddI mem incr));
 9434   ins_cost(VOLATILE_REF_COST + 1);
 9435   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9436   ins_encode %{
 9437     __ atomic_addalw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9438   %}
 9439   ins_pipe(pipe_serial);
 9440 %}
 9441 
 9442 instruct get_and_addIi_no_resAcq(indirect mem, Universe dummy, immIAddSub incr) %{
 9443   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9444   match(Set dummy (GetAndAddI mem incr));
 9445   ins_cost(VOLATILE_REF_COST);
 9446   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9447   ins_encode %{
 9448     __ atomic_addalw(noreg, $incr$$constant, as_Register($mem$$base));
 9449   %}
 9450   ins_pipe(pipe_serial);
 9451 %}
 9452 
 9453 // Manifest a CmpL result in an integer register.
 9454 // (src1 &lt; src2) ? -1 : ((src1 &gt; src2) ? 1 : 0)
 9455 instruct cmpL3_reg_reg(iRegINoSp dst, iRegL src1, iRegL src2, rFlagsReg flags)
 9456 %{
 9457   match(Set dst (CmpL3 src1 src2));
 9458   effect(KILL flags);
 9459 
 9460   ins_cost(INSN_COST * 6);
 9461   format %{
 9462       &quot;cmp $src1, $src2&quot;
 9463       &quot;csetw $dst, ne&quot;
 9464       &quot;cnegw $dst, lt&quot;
 9465   %}
 9466   // format %{ &quot;CmpL3 $dst, $src1, $src2&quot; %}
 9467   ins_encode %{
 9468     __ cmp($src1$$Register, $src2$$Register);
 9469     __ csetw($dst$$Register, Assembler::NE);
 9470     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9471   %}
 9472 
 9473   ins_pipe(pipe_class_default);
 9474 %}
 9475 
 9476 instruct cmpL3_reg_imm(iRegINoSp dst, iRegL src1, immLAddSub src2, rFlagsReg flags)
 9477 %{
 9478   match(Set dst (CmpL3 src1 src2));
 9479   effect(KILL flags);
 9480 
 9481   ins_cost(INSN_COST * 6);
 9482   format %{
 9483       &quot;cmp $src1, $src2&quot;
 9484       &quot;csetw $dst, ne&quot;
 9485       &quot;cnegw $dst, lt&quot;
 9486   %}
 9487   ins_encode %{
 9488     int32_t con = (int32_t)$src2$$constant;
 9489      if (con &lt; 0) {
 9490       __ adds(zr, $src1$$Register, -con);
 9491     } else {
 9492       __ subs(zr, $src1$$Register, con);
 9493     }
 9494     __ csetw($dst$$Register, Assembler::NE);
 9495     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9496   %}
 9497 
 9498   ins_pipe(pipe_class_default);
 9499 %}
 9500 
 9501 // ============================================================================
 9502 // Conditional Move Instructions
 9503 
 9504 // n.b. we have identical rules for both a signed compare op (cmpOp)
 9505 // and an unsigned compare op (cmpOpU). it would be nice if we could
 9506 // define an op class which merged both inputs and use it to type the
 9507 // argument to a single rule. unfortunatelyt his fails because the
 9508 // opclass does not live up to the COND_INTER interface of its
 9509 // component operands. When the generic code tries to negate the
 9510 // operand it ends up running the generci Machoper::negate method
 9511 // which throws a ShouldNotHappen. So, we have to provide two flavours
 9512 // of each rule, one for a cmpOp and a second for a cmpOpU (sigh).
 9513 
 9514 instruct cmovI_reg_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9515   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9516 
 9517   ins_cost(INSN_COST * 2);
 9518   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, int&quot;  %}
 9519 
 9520   ins_encode %{
 9521     __ cselw(as_Register($dst$$reg),
 9522              as_Register($src2$$reg),
 9523              as_Register($src1$$reg),
 9524              (Assembler::Condition)$cmp$$cmpcode);
 9525   %}
 9526 
 9527   ins_pipe(icond_reg_reg);
 9528 %}
 9529 
 9530 instruct cmovUI_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9531   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9532 
 9533   ins_cost(INSN_COST * 2);
 9534   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# unsigned, int&quot;  %}
 9535 
 9536   ins_encode %{
 9537     __ cselw(as_Register($dst$$reg),
 9538              as_Register($src2$$reg),
 9539              as_Register($src1$$reg),
 9540              (Assembler::Condition)$cmp$$cmpcode);
 9541   %}
 9542 
 9543   ins_pipe(icond_reg_reg);
 9544 %}
 9545 
 9546 // special cases where one arg is zero
 9547 
 9548 // n.b. this is selected in preference to the rule above because it
 9549 // avoids loading constant 0 into a source register
 9550 
 9551 // TODO
 9552 // we ought only to be able to cull one of these variants as the ideal
 9553 // transforms ought always to order the zero consistently (to left/right?)
 9554 
 9555 instruct cmovI_zero_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9556   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9557 
 9558   ins_cost(INSN_COST * 2);
 9559   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, int&quot;  %}
 9560 
 9561   ins_encode %{
 9562     __ cselw(as_Register($dst$$reg),
 9563              as_Register($src$$reg),
 9564              zr,
 9565              (Assembler::Condition)$cmp$$cmpcode);
 9566   %}
 9567 
 9568   ins_pipe(icond_reg);
 9569 %}
 9570 
 9571 instruct cmovUI_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9572   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9573 
 9574   ins_cost(INSN_COST * 2);
 9575   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, int&quot;  %}
 9576 
 9577   ins_encode %{
 9578     __ cselw(as_Register($dst$$reg),
 9579              as_Register($src$$reg),
 9580              zr,
 9581              (Assembler::Condition)$cmp$$cmpcode);
 9582   %}
 9583 
 9584   ins_pipe(icond_reg);
 9585 %}
 9586 
 9587 instruct cmovI_reg_zero(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9588   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9589 
 9590   ins_cost(INSN_COST * 2);
 9591   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, int&quot;  %}
 9592 
 9593   ins_encode %{
 9594     __ cselw(as_Register($dst$$reg),
 9595              zr,
 9596              as_Register($src$$reg),
 9597              (Assembler::Condition)$cmp$$cmpcode);
 9598   %}
 9599 
 9600   ins_pipe(icond_reg);
 9601 %}
 9602 
 9603 instruct cmovUI_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9604   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9605 
 9606   ins_cost(INSN_COST * 2);
 9607   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, int&quot;  %}
 9608 
 9609   ins_encode %{
 9610     __ cselw(as_Register($dst$$reg),
 9611              zr,
 9612              as_Register($src$$reg),
 9613              (Assembler::Condition)$cmp$$cmpcode);
 9614   %}
 9615 
 9616   ins_pipe(icond_reg);
 9617 %}
 9618 
 9619 // special case for creating a boolean 0 or 1
 9620 
 9621 // n.b. this is selected in preference to the rule above because it
 9622 // avoids loading constants 0 and 1 into a source register
 9623 
 9624 instruct cmovI_reg_zero_one(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9625   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9626 
 9627   ins_cost(INSN_COST * 2);
 9628   format %{ &quot;csincw $dst, zr, zr $cmp\t# signed, int&quot;  %}
 9629 
 9630   ins_encode %{
 9631     // equivalently
 9632     // cset(as_Register($dst$$reg),
 9633     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9634     __ csincw(as_Register($dst$$reg),
 9635              zr,
 9636              zr,
 9637              (Assembler::Condition)$cmp$$cmpcode);
 9638   %}
 9639 
 9640   ins_pipe(icond_none);
 9641 %}
 9642 
 9643 instruct cmovUI_reg_zero_one(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9644   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9645 
 9646   ins_cost(INSN_COST * 2);
 9647   format %{ &quot;csincw $dst, zr, zr $cmp\t# unsigned, int&quot;  %}
 9648 
 9649   ins_encode %{
 9650     // equivalently
 9651     // cset(as_Register($dst$$reg),
 9652     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9653     __ csincw(as_Register($dst$$reg),
 9654              zr,
 9655              zr,
 9656              (Assembler::Condition)$cmp$$cmpcode);
 9657   %}
 9658 
 9659   ins_pipe(icond_none);
 9660 %}
 9661 
 9662 instruct cmovL_reg_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9663   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9664 
 9665   ins_cost(INSN_COST * 2);
 9666   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, long&quot;  %}
 9667 
 9668   ins_encode %{
 9669     __ csel(as_Register($dst$$reg),
 9670             as_Register($src2$$reg),
 9671             as_Register($src1$$reg),
 9672             (Assembler::Condition)$cmp$$cmpcode);
 9673   %}
 9674 
 9675   ins_pipe(icond_reg_reg);
 9676 %}
 9677 
 9678 instruct cmovUL_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9679   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9680 
 9681   ins_cost(INSN_COST * 2);
 9682   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, long&quot;  %}
 9683 
 9684   ins_encode %{
 9685     __ csel(as_Register($dst$$reg),
 9686             as_Register($src2$$reg),
 9687             as_Register($src1$$reg),
 9688             (Assembler::Condition)$cmp$$cmpcode);
 9689   %}
 9690 
 9691   ins_pipe(icond_reg_reg);
 9692 %}
 9693 
 9694 // special cases where one arg is zero
 9695 
 9696 instruct cmovL_reg_zero(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9697   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9698 
 9699   ins_cost(INSN_COST * 2);
 9700   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, long&quot;  %}
 9701 
 9702   ins_encode %{
 9703     __ csel(as_Register($dst$$reg),
 9704             zr,
 9705             as_Register($src$$reg),
 9706             (Assembler::Condition)$cmp$$cmpcode);
 9707   %}
 9708 
 9709   ins_pipe(icond_reg);
 9710 %}
 9711 
 9712 instruct cmovUL_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9713   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9714 
 9715   ins_cost(INSN_COST * 2);
 9716   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, long&quot;  %}
 9717 
 9718   ins_encode %{
 9719     __ csel(as_Register($dst$$reg),
 9720             zr,
 9721             as_Register($src$$reg),
 9722             (Assembler::Condition)$cmp$$cmpcode);
 9723   %}
 9724 
 9725   ins_pipe(icond_reg);
 9726 %}
 9727 
 9728 instruct cmovL_zero_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9729   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9730 
 9731   ins_cost(INSN_COST * 2);
 9732   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, long&quot;  %}
 9733 
 9734   ins_encode %{
 9735     __ csel(as_Register($dst$$reg),
 9736             as_Register($src$$reg),
 9737             zr,
 9738             (Assembler::Condition)$cmp$$cmpcode);
 9739   %}
 9740 
 9741   ins_pipe(icond_reg);
 9742 %}
 9743 
 9744 instruct cmovUL_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9745   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9746 
 9747   ins_cost(INSN_COST * 2);
 9748   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, long&quot;  %}
 9749 
 9750   ins_encode %{
 9751     __ csel(as_Register($dst$$reg),
 9752             as_Register($src$$reg),
 9753             zr,
 9754             (Assembler::Condition)$cmp$$cmpcode);
 9755   %}
 9756 
 9757   ins_pipe(icond_reg);
 9758 %}
 9759 
 9760 instruct cmovP_reg_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9761   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9762 
 9763   ins_cost(INSN_COST * 2);
 9764   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, ptr&quot;  %}
 9765 
 9766   ins_encode %{
 9767     __ csel(as_Register($dst$$reg),
 9768             as_Register($src2$$reg),
 9769             as_Register($src1$$reg),
 9770             (Assembler::Condition)$cmp$$cmpcode);
 9771   %}
 9772 
 9773   ins_pipe(icond_reg_reg);
 9774 %}
 9775 
 9776 instruct cmovUP_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9777   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9778 
 9779   ins_cost(INSN_COST * 2);
 9780   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, ptr&quot;  %}
 9781 
 9782   ins_encode %{
 9783     __ csel(as_Register($dst$$reg),
 9784             as_Register($src2$$reg),
 9785             as_Register($src1$$reg),
 9786             (Assembler::Condition)$cmp$$cmpcode);
 9787   %}
 9788 
 9789   ins_pipe(icond_reg_reg);
 9790 %}
 9791 
 9792 // special cases where one arg is zero
 9793 
 9794 instruct cmovP_reg_zero(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9795   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9796 
 9797   ins_cost(INSN_COST * 2);
 9798   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, ptr&quot;  %}
 9799 
 9800   ins_encode %{
 9801     __ csel(as_Register($dst$$reg),
 9802             zr,
 9803             as_Register($src$$reg),
 9804             (Assembler::Condition)$cmp$$cmpcode);
 9805   %}
 9806 
 9807   ins_pipe(icond_reg);
 9808 %}
 9809 
 9810 instruct cmovUP_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9811   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9812 
 9813   ins_cost(INSN_COST * 2);
 9814   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, ptr&quot;  %}
 9815 
 9816   ins_encode %{
 9817     __ csel(as_Register($dst$$reg),
 9818             zr,
 9819             as_Register($src$$reg),
 9820             (Assembler::Condition)$cmp$$cmpcode);
 9821   %}
 9822 
 9823   ins_pipe(icond_reg);
 9824 %}
 9825 
 9826 instruct cmovP_zero_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9827   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9828 
 9829   ins_cost(INSN_COST * 2);
 9830   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, ptr&quot;  %}
 9831 
 9832   ins_encode %{
 9833     __ csel(as_Register($dst$$reg),
 9834             as_Register($src$$reg),
 9835             zr,
 9836             (Assembler::Condition)$cmp$$cmpcode);
 9837   %}
 9838 
 9839   ins_pipe(icond_reg);
 9840 %}
 9841 
 9842 instruct cmovUP_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9843   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9844 
 9845   ins_cost(INSN_COST * 2);
 9846   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, ptr&quot;  %}
 9847 
 9848   ins_encode %{
 9849     __ csel(as_Register($dst$$reg),
 9850             as_Register($src$$reg),
 9851             zr,
 9852             (Assembler::Condition)$cmp$$cmpcode);
 9853   %}
 9854 
 9855   ins_pipe(icond_reg);
 9856 %}
 9857 
 9858 instruct cmovN_reg_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9859   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9860 
 9861   ins_cost(INSN_COST * 2);
 9862   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9863 
 9864   ins_encode %{
 9865     __ cselw(as_Register($dst$$reg),
 9866              as_Register($src2$$reg),
 9867              as_Register($src1$$reg),
 9868              (Assembler::Condition)$cmp$$cmpcode);
 9869   %}
 9870 
 9871   ins_pipe(icond_reg_reg);
 9872 %}
 9873 
 9874 instruct cmovUN_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9875   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9876 
 9877   ins_cost(INSN_COST * 2);
 9878   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9879 
 9880   ins_encode %{
 9881     __ cselw(as_Register($dst$$reg),
 9882              as_Register($src2$$reg),
 9883              as_Register($src1$$reg),
 9884              (Assembler::Condition)$cmp$$cmpcode);
 9885   %}
 9886 
 9887   ins_pipe(icond_reg_reg);
 9888 %}
 9889 
 9890 // special cases where one arg is zero
 9891 
 9892 instruct cmovN_reg_zero(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9893   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9894 
 9895   ins_cost(INSN_COST * 2);
 9896   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, compressed ptr&quot;  %}
 9897 
 9898   ins_encode %{
 9899     __ cselw(as_Register($dst$$reg),
 9900              zr,
 9901              as_Register($src$$reg),
 9902              (Assembler::Condition)$cmp$$cmpcode);
 9903   %}
 9904 
 9905   ins_pipe(icond_reg);
 9906 %}
 9907 
 9908 instruct cmovUN_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9909   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9910 
 9911   ins_cost(INSN_COST * 2);
 9912   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, compressed ptr&quot;  %}
 9913 
 9914   ins_encode %{
 9915     __ cselw(as_Register($dst$$reg),
 9916              zr,
 9917              as_Register($src$$reg),
 9918              (Assembler::Condition)$cmp$$cmpcode);
 9919   %}
 9920 
 9921   ins_pipe(icond_reg);
 9922 %}
 9923 
 9924 instruct cmovN_zero_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
 9925   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
 9926 
 9927   ins_cost(INSN_COST * 2);
 9928   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, compressed ptr&quot;  %}
 9929 
 9930   ins_encode %{
 9931     __ cselw(as_Register($dst$$reg),
 9932              as_Register($src$$reg),
 9933              zr,
 9934              (Assembler::Condition)$cmp$$cmpcode);
 9935   %}
 9936 
 9937   ins_pipe(icond_reg);
 9938 %}
 9939 
 9940 instruct cmovUN_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
 9941   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
 9942 
 9943   ins_cost(INSN_COST * 2);
 9944   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, compressed ptr&quot;  %}
 9945 
 9946   ins_encode %{
 9947     __ cselw(as_Register($dst$$reg),
 9948              as_Register($src$$reg),
 9949              zr,
 9950              (Assembler::Condition)$cmp$$cmpcode);
 9951   %}
 9952 
 9953   ins_pipe(icond_reg);
 9954 %}
 9955 
 9956 instruct cmovF_reg(cmpOp cmp, rFlagsReg cr, vRegF dst, vRegF src1,  vRegF src2)
 9957 %{
 9958   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
 9959 
 9960   ins_cost(INSN_COST * 3);
 9961 
 9962   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
 9963   ins_encode %{
 9964     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
 9965     __ fcsels(as_FloatRegister($dst$$reg),
 9966               as_FloatRegister($src2$$reg),
 9967               as_FloatRegister($src1$$reg),
 9968               cond);
 9969   %}
 9970 
 9971   ins_pipe(fp_cond_reg_reg_s);
 9972 %}
 9973 
 9974 instruct cmovUF_reg(cmpOpU cmp, rFlagsRegU cr, vRegF dst, vRegF src1,  vRegF src2)
 9975 %{
 9976   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
 9977 
 9978   ins_cost(INSN_COST * 3);
 9979 
 9980   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
 9981   ins_encode %{
 9982     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
 9983     __ fcsels(as_FloatRegister($dst$$reg),
 9984               as_FloatRegister($src2$$reg),
 9985               as_FloatRegister($src1$$reg),
 9986               cond);
 9987   %}
 9988 
 9989   ins_pipe(fp_cond_reg_reg_s);
 9990 %}
 9991 
 9992 instruct cmovD_reg(cmpOp cmp, rFlagsReg cr, vRegD dst, vRegD src1,  vRegD src2)
 9993 %{
 9994   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
 9995 
 9996   ins_cost(INSN_COST * 3);
 9997 
 9998   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
 9999   ins_encode %{
10000     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10001     __ fcseld(as_FloatRegister($dst$$reg),
10002               as_FloatRegister($src2$$reg),
10003               as_FloatRegister($src1$$reg),
10004               cond);
10005   %}
10006 
10007   ins_pipe(fp_cond_reg_reg_d);
10008 %}
10009 
10010 instruct cmovUD_reg(cmpOpU cmp, rFlagsRegU cr, vRegD dst, vRegD src1,  vRegD src2)
10011 %{
10012   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10013 
10014   ins_cost(INSN_COST * 3);
10015 
10016   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10017   ins_encode %{
10018     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10019     __ fcseld(as_FloatRegister($dst$$reg),
10020               as_FloatRegister($src2$$reg),
10021               as_FloatRegister($src1$$reg),
10022               cond);
10023   %}
10024 
10025   ins_pipe(fp_cond_reg_reg_d);
10026 %}
10027 
10028 // ============================================================================
10029 // Arithmetic Instructions
10030 //
10031 
10032 // Integer Addition
10033 
10034 // TODO
10035 // these currently employ operations which do not set CR and hence are
10036 // not flagged as killing CR but we would like to isolate the cases
10037 // where we want to set flags from those where we don&#39;t. need to work
10038 // out how to do that.
10039 
10040 instruct addI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10041   match(Set dst (AddI src1 src2));
10042 
10043   ins_cost(INSN_COST);
10044   format %{ &quot;addw  $dst, $src1, $src2&quot; %}
10045 
10046   ins_encode %{
10047     __ addw(as_Register($dst$$reg),
10048             as_Register($src1$$reg),
10049             as_Register($src2$$reg));
10050   %}
10051 
10052   ins_pipe(ialu_reg_reg);
10053 %}
10054 
10055 instruct addI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10056   match(Set dst (AddI src1 src2));
10057 
10058   ins_cost(INSN_COST);
10059   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10060 
10061   // use opcode to indicate that this is an add not a sub
10062   opcode(0x0);
10063 
10064   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10065 
10066   ins_pipe(ialu_reg_imm);
10067 %}
10068 
10069 instruct addI_reg_imm_i2l(iRegINoSp dst, iRegL src1, immIAddSub src2) %{
10070   match(Set dst (AddI (ConvL2I src1) src2));
10071 
10072   ins_cost(INSN_COST);
10073   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10074 
10075   // use opcode to indicate that this is an add not a sub
10076   opcode(0x0);
10077 
10078   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10079 
10080   ins_pipe(ialu_reg_imm);
10081 %}
10082 
10083 // Pointer Addition
10084 instruct addP_reg_reg(iRegPNoSp dst, iRegP src1, iRegL src2) %{
10085   match(Set dst (AddP src1 src2));
10086 
10087   ins_cost(INSN_COST);
10088   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10089 
10090   ins_encode %{
10091     __ add(as_Register($dst$$reg),
10092            as_Register($src1$$reg),
10093            as_Register($src2$$reg));
10094   %}
10095 
10096   ins_pipe(ialu_reg_reg);
10097 %}
10098 
10099 instruct addP_reg_reg_ext(iRegPNoSp dst, iRegP src1, iRegIorL2I src2) %{
10100   match(Set dst (AddP src1 (ConvI2L src2)));
10101 
10102   ins_cost(1.9 * INSN_COST);
10103   format %{ &quot;add $dst, $src1, $src2, sxtw\t# ptr&quot; %}
10104 
10105   ins_encode %{
10106     __ add(as_Register($dst$$reg),
10107            as_Register($src1$$reg),
10108            as_Register($src2$$reg), ext::sxtw);
10109   %}
10110 
10111   ins_pipe(ialu_reg_reg);
10112 %}
10113 
10114 instruct addP_reg_reg_lsl(iRegPNoSp dst, iRegP src1, iRegL src2, immIScale scale) %{
10115   match(Set dst (AddP src1 (LShiftL src2 scale)));
10116 
10117   ins_cost(1.9 * INSN_COST);
10118   format %{ &quot;add $dst, $src1, $src2, LShiftL $scale\t# ptr&quot; %}
10119 
10120   ins_encode %{
10121     __ lea(as_Register($dst$$reg),
10122            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10123                    Address::lsl($scale$$constant)));
10124   %}
10125 
10126   ins_pipe(ialu_reg_reg_shift);
10127 %}
10128 
10129 instruct addP_reg_reg_ext_shift(iRegPNoSp dst, iRegP src1, iRegIorL2I src2, immIScale scale) %{
10130   match(Set dst (AddP src1 (LShiftL (ConvI2L src2) scale)));
10131 
10132   ins_cost(1.9 * INSN_COST);
10133   format %{ &quot;add $dst, $src1, $src2, I2L $scale\t# ptr&quot; %}
10134 
10135   ins_encode %{
10136     __ lea(as_Register($dst$$reg),
10137            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10138                    Address::sxtw($scale$$constant)));
10139   %}
10140 
10141   ins_pipe(ialu_reg_reg_shift);
10142 %}
10143 
10144 instruct lshift_ext(iRegLNoSp dst, iRegIorL2I src, immI scale, rFlagsReg cr) %{
10145   match(Set dst (LShiftL (ConvI2L src) scale));
10146 
10147   ins_cost(INSN_COST);
10148   format %{ &quot;sbfiz $dst, $src, $scale &amp; 63, -$scale &amp; 63\t&quot; %}
10149 
10150   ins_encode %{
10151     __ sbfiz(as_Register($dst$$reg),
10152           as_Register($src$$reg),
10153           $scale$$constant &amp; 63, MIN(32, (-$scale$$constant) &amp; 63));
10154   %}
10155 
10156   ins_pipe(ialu_reg_shift);
10157 %}
10158 
10159 // Pointer Immediate Addition
10160 // n.b. this needs to be more expensive than using an indirect memory
10161 // operand
10162 instruct addP_reg_imm(iRegPNoSp dst, iRegP src1, immLAddSub src2) %{
10163   match(Set dst (AddP src1 src2));
10164 
10165   ins_cost(INSN_COST);
10166   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10167 
10168   // use opcode to indicate that this is an add not a sub
10169   opcode(0x0);
10170 
10171   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10172 
10173   ins_pipe(ialu_reg_imm);
10174 %}
10175 
10176 // Long Addition
10177 instruct addL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10178 
10179   match(Set dst (AddL src1 src2));
10180 
10181   ins_cost(INSN_COST);
10182   format %{ &quot;add  $dst, $src1, $src2&quot; %}
10183 
10184   ins_encode %{
10185     __ add(as_Register($dst$$reg),
10186            as_Register($src1$$reg),
10187            as_Register($src2$$reg));
10188   %}
10189 
10190   ins_pipe(ialu_reg_reg);
10191 %}
10192 
10193 // No constant pool entries requiredLong Immediate Addition.
10194 instruct addL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10195   match(Set dst (AddL src1 src2));
10196 
10197   ins_cost(INSN_COST);
10198   format %{ &quot;add $dst, $src1, $src2&quot; %}
10199 
10200   // use opcode to indicate that this is an add not a sub
10201   opcode(0x0);
10202 
10203   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10204 
10205   ins_pipe(ialu_reg_imm);
10206 %}
10207 
10208 // Integer Subtraction
10209 instruct subI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10210   match(Set dst (SubI src1 src2));
10211 
10212   ins_cost(INSN_COST);
10213   format %{ &quot;subw  $dst, $src1, $src2&quot; %}
10214 
10215   ins_encode %{
10216     __ subw(as_Register($dst$$reg),
10217             as_Register($src1$$reg),
10218             as_Register($src2$$reg));
10219   %}
10220 
10221   ins_pipe(ialu_reg_reg);
10222 %}
10223 
10224 // Immediate Subtraction
10225 instruct subI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10226   match(Set dst (SubI src1 src2));
10227 
10228   ins_cost(INSN_COST);
10229   format %{ &quot;subw $dst, $src1, $src2&quot; %}
10230 
10231   // use opcode to indicate that this is a sub not an add
10232   opcode(0x1);
10233 
10234   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10235 
10236   ins_pipe(ialu_reg_imm);
10237 %}
10238 
10239 // Long Subtraction
10240 instruct subL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10241 
10242   match(Set dst (SubL src1 src2));
10243 
10244   ins_cost(INSN_COST);
10245   format %{ &quot;sub  $dst, $src1, $src2&quot; %}
10246 
10247   ins_encode %{
10248     __ sub(as_Register($dst$$reg),
10249            as_Register($src1$$reg),
10250            as_Register($src2$$reg));
10251   %}
10252 
10253   ins_pipe(ialu_reg_reg);
10254 %}
10255 
10256 // No constant pool entries requiredLong Immediate Subtraction.
10257 instruct subL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10258   match(Set dst (SubL src1 src2));
10259 
10260   ins_cost(INSN_COST);
10261   format %{ &quot;sub$dst, $src1, $src2&quot; %}
10262 
10263   // use opcode to indicate that this is a sub not an add
10264   opcode(0x1);
10265 
10266   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10267 
10268   ins_pipe(ialu_reg_imm);
10269 %}
10270 
10271 // Integer Negation (special case for sub)
10272 
10273 instruct negI_reg(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr) %{
10274   match(Set dst (SubI zero src));
10275 
10276   ins_cost(INSN_COST);
10277   format %{ &quot;negw $dst, $src\t# int&quot; %}
10278 
10279   ins_encode %{
10280     __ negw(as_Register($dst$$reg),
10281             as_Register($src$$reg));
10282   %}
10283 
10284   ins_pipe(ialu_reg);
10285 %}
10286 
10287 // Long Negation
10288 
10289 instruct negL_reg(iRegLNoSp dst, iRegL src, immL0 zero, rFlagsReg cr) %{
10290   match(Set dst (SubL zero src));
10291 
10292   ins_cost(INSN_COST);
10293   format %{ &quot;neg $dst, $src\t# long&quot; %}
10294 
10295   ins_encode %{
10296     __ neg(as_Register($dst$$reg),
10297            as_Register($src$$reg));
10298   %}
10299 
10300   ins_pipe(ialu_reg);
10301 %}
10302 
10303 // Integer Multiply
10304 
10305 instruct mulI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10306   match(Set dst (MulI src1 src2));
10307 
10308   ins_cost(INSN_COST * 3);
10309   format %{ &quot;mulw  $dst, $src1, $src2&quot; %}
10310 
10311   ins_encode %{
10312     __ mulw(as_Register($dst$$reg),
10313             as_Register($src1$$reg),
10314             as_Register($src2$$reg));
10315   %}
10316 
10317   ins_pipe(imul_reg_reg);
10318 %}
10319 
10320 instruct smulI(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10321   match(Set dst (MulL (ConvI2L src1) (ConvI2L src2)));
10322 
10323   ins_cost(INSN_COST * 3);
10324   format %{ &quot;smull  $dst, $src1, $src2&quot; %}
10325 
10326   ins_encode %{
10327     __ smull(as_Register($dst$$reg),
10328              as_Register($src1$$reg),
10329              as_Register($src2$$reg));
10330   %}
10331 
10332   ins_pipe(imul_reg_reg);
10333 %}
10334 
10335 // Long Multiply
10336 
10337 instruct mulL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10338   match(Set dst (MulL src1 src2));
10339 
10340   ins_cost(INSN_COST * 5);
10341   format %{ &quot;mul  $dst, $src1, $src2&quot; %}
10342 
10343   ins_encode %{
10344     __ mul(as_Register($dst$$reg),
10345            as_Register($src1$$reg),
10346            as_Register($src2$$reg));
10347   %}
10348 
10349   ins_pipe(lmul_reg_reg);
10350 %}
10351 
10352 instruct mulHiL_rReg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr)
10353 %{
10354   match(Set dst (MulHiL src1 src2));
10355 
10356   ins_cost(INSN_COST * 7);
10357   format %{ &quot;smulh   $dst, $src1, $src2, \t# mulhi&quot; %}
10358 
10359   ins_encode %{
10360     __ smulh(as_Register($dst$$reg),
10361              as_Register($src1$$reg),
10362              as_Register($src2$$reg));
10363   %}
10364 
10365   ins_pipe(lmul_reg_reg);
10366 %}
10367 
10368 // Combined Integer Multiply &amp; Add/Sub
10369 
10370 instruct maddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10371   match(Set dst (AddI src3 (MulI src1 src2)));
10372 
10373   ins_cost(INSN_COST * 3);
10374   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10375 
10376   ins_encode %{
10377     __ maddw(as_Register($dst$$reg),
10378              as_Register($src1$$reg),
10379              as_Register($src2$$reg),
10380              as_Register($src3$$reg));
10381   %}
10382 
10383   ins_pipe(imac_reg_reg);
10384 %}
10385 
10386 instruct msubI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10387   match(Set dst (SubI src3 (MulI src1 src2)));
10388 
10389   ins_cost(INSN_COST * 3);
10390   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10391 
10392   ins_encode %{
10393     __ msubw(as_Register($dst$$reg),
10394              as_Register($src1$$reg),
10395              as_Register($src2$$reg),
10396              as_Register($src3$$reg));
10397   %}
10398 
10399   ins_pipe(imac_reg_reg);
10400 %}
10401 
10402 // Combined Integer Multiply &amp; Neg
10403 
10404 instruct mnegI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI0 zero) %{
10405   match(Set dst (MulI (SubI zero src1) src2));
10406   match(Set dst (MulI src1 (SubI zero src2)));
10407 
10408   ins_cost(INSN_COST * 3);
10409   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10410 
10411   ins_encode %{
10412     __ mnegw(as_Register($dst$$reg),
10413              as_Register($src1$$reg),
10414              as_Register($src2$$reg));
10415   %}
10416 
10417   ins_pipe(imac_reg_reg);
10418 %}
10419 
10420 // Combined Long Multiply &amp; Add/Sub
10421 
10422 instruct maddL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10423   match(Set dst (AddL src3 (MulL src1 src2)));
10424 
10425   ins_cost(INSN_COST * 5);
10426   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10427 
10428   ins_encode %{
10429     __ madd(as_Register($dst$$reg),
10430             as_Register($src1$$reg),
10431             as_Register($src2$$reg),
10432             as_Register($src3$$reg));
10433   %}
10434 
10435   ins_pipe(lmac_reg_reg);
10436 %}
10437 
10438 instruct msubL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10439   match(Set dst (SubL src3 (MulL src1 src2)));
10440 
10441   ins_cost(INSN_COST * 5);
10442   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10443 
10444   ins_encode %{
10445     __ msub(as_Register($dst$$reg),
10446             as_Register($src1$$reg),
10447             as_Register($src2$$reg),
10448             as_Register($src3$$reg));
10449   %}
10450 
10451   ins_pipe(lmac_reg_reg);
10452 %}
10453 
10454 // Combined Long Multiply &amp; Neg
10455 
10456 instruct mnegL(iRegLNoSp dst, iRegL src1, iRegL src2, immL0 zero) %{
10457   match(Set dst (MulL (SubL zero src1) src2));
10458   match(Set dst (MulL src1 (SubL zero src2)));
10459 
10460   ins_cost(INSN_COST * 5);
10461   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10462 
10463   ins_encode %{
10464     __ mneg(as_Register($dst$$reg),
10465             as_Register($src1$$reg),
10466             as_Register($src2$$reg));
10467   %}
10468 
10469   ins_pipe(lmac_reg_reg);
10470 %}
10471 
10472 // Combine Integer Signed Multiply &amp; Add/Sub/Neg Long
10473 
10474 instruct smaddL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10475   match(Set dst (AddL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10476 
10477   ins_cost(INSN_COST * 3);
10478   format %{ &quot;smaddl  $dst, $src1, $src2, $src3&quot; %}
10479 
10480   ins_encode %{
10481     __ smaddl(as_Register($dst$$reg),
10482               as_Register($src1$$reg),
10483               as_Register($src2$$reg),
10484               as_Register($src3$$reg));
10485   %}
10486 
10487   ins_pipe(imac_reg_reg);
10488 %}
10489 
10490 instruct smsubL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10491   match(Set dst (SubL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10492 
10493   ins_cost(INSN_COST * 3);
10494   format %{ &quot;smsubl  $dst, $src1, $src2, $src3&quot; %}
10495 
10496   ins_encode %{
10497     __ smsubl(as_Register($dst$$reg),
10498               as_Register($src1$$reg),
10499               as_Register($src2$$reg),
10500               as_Register($src3$$reg));
10501   %}
10502 
10503   ins_pipe(imac_reg_reg);
10504 %}
10505 
10506 instruct smnegL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, immL0 zero) %{
10507   match(Set dst (MulL (SubL zero (ConvI2L src1)) (ConvI2L src2)));
10508   match(Set dst (MulL (ConvI2L src1) (SubL zero (ConvI2L src2))));
10509 
10510   ins_cost(INSN_COST * 3);
10511   format %{ &quot;smnegl  $dst, $src1, $src2&quot; %}
10512 
10513   ins_encode %{
10514     __ smnegl(as_Register($dst$$reg),
10515               as_Register($src1$$reg),
10516               as_Register($src2$$reg));
10517   %}
10518 
10519   ins_pipe(imac_reg_reg);
10520 %}
10521 
10522 // Combined Multiply-Add Shorts into Integer (dst = src1 * src2 + src3 * src4)
10523 
10524 instruct muladdS2I(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3, iRegIorL2I src4) %{
10525   match(Set dst (MulAddS2I (Binary src1 src2) (Binary src3 src4)));
10526 
10527   ins_cost(INSN_COST * 5);
10528   format %{ &quot;mulw  rscratch1, $src1, $src2\n\t&quot;
10529             &quot;maddw $dst, $src3, $src4, rscratch1&quot; %}
10530 
10531   ins_encode %{
10532     __ mulw(rscratch1, as_Register($src1$$reg), as_Register($src2$$reg));
10533     __ maddw(as_Register($dst$$reg), as_Register($src3$$reg), as_Register($src4$$reg), rscratch1); %}
10534 
10535   ins_pipe(imac_reg_reg);
10536 %}
10537 
10538 // Integer Divide
10539 
10540 instruct divI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10541   match(Set dst (DivI src1 src2));
10542 
10543   ins_cost(INSN_COST * 19);
10544   format %{ &quot;sdivw  $dst, $src1, $src2&quot; %}
10545 
10546   ins_encode(aarch64_enc_divw(dst, src1, src2));
10547   ins_pipe(idiv_reg_reg);
10548 %}
10549 
10550 // Long Divide
10551 
10552 instruct divL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10553   match(Set dst (DivL src1 src2));
10554 
10555   ins_cost(INSN_COST * 35);
10556   format %{ &quot;sdiv   $dst, $src1, $src2&quot; %}
10557 
10558   ins_encode(aarch64_enc_div(dst, src1, src2));
10559   ins_pipe(ldiv_reg_reg);
10560 %}
10561 
10562 // Integer Remainder
10563 
10564 instruct modI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10565   match(Set dst (ModI src1 src2));
10566 
10567   ins_cost(INSN_COST * 22);
10568   format %{ &quot;sdivw  rscratch1, $src1, $src2\n\t&quot;
10569             &quot;msubw($dst, rscratch1, $src2, $src1&quot; %}
10570 
10571   ins_encode(aarch64_enc_modw(dst, src1, src2));
10572   ins_pipe(idiv_reg_reg);
10573 %}
10574 
10575 // Long Remainder
10576 
10577 instruct modL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10578   match(Set dst (ModL src1 src2));
10579 
10580   ins_cost(INSN_COST * 38);
10581   format %{ &quot;sdiv   rscratch1, $src1, $src2\n&quot;
10582             &quot;msub($dst, rscratch1, $src2, $src1&quot; %}
10583 
10584   ins_encode(aarch64_enc_mod(dst, src1, src2));
10585   ins_pipe(ldiv_reg_reg);
10586 %}
10587 
10588 // Integer Shifts
10589 
10590 // Shift Left Register
10591 instruct lShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10592   match(Set dst (LShiftI src1 src2));
10593 
10594   ins_cost(INSN_COST * 2);
10595   format %{ &quot;lslvw  $dst, $src1, $src2&quot; %}
10596 
10597   ins_encode %{
10598     __ lslvw(as_Register($dst$$reg),
10599              as_Register($src1$$reg),
10600              as_Register($src2$$reg));
10601   %}
10602 
10603   ins_pipe(ialu_reg_reg_vshift);
10604 %}
10605 
10606 // Shift Left Immediate
10607 instruct lShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10608   match(Set dst (LShiftI src1 src2));
10609 
10610   ins_cost(INSN_COST);
10611   format %{ &quot;lslw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10612 
10613   ins_encode %{
10614     __ lslw(as_Register($dst$$reg),
10615             as_Register($src1$$reg),
10616             $src2$$constant &amp; 0x1f);
10617   %}
10618 
10619   ins_pipe(ialu_reg_shift);
10620 %}
10621 
10622 // Shift Right Logical Register
10623 instruct urShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10624   match(Set dst (URShiftI src1 src2));
10625 
10626   ins_cost(INSN_COST * 2);
10627   format %{ &quot;lsrvw  $dst, $src1, $src2&quot; %}
10628 
10629   ins_encode %{
10630     __ lsrvw(as_Register($dst$$reg),
10631              as_Register($src1$$reg),
10632              as_Register($src2$$reg));
10633   %}
10634 
10635   ins_pipe(ialu_reg_reg_vshift);
10636 %}
10637 
10638 // Shift Right Logical Immediate
10639 instruct urShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10640   match(Set dst (URShiftI src1 src2));
10641 
10642   ins_cost(INSN_COST);
10643   format %{ &quot;lsrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10644 
10645   ins_encode %{
10646     __ lsrw(as_Register($dst$$reg),
10647             as_Register($src1$$reg),
10648             $src2$$constant &amp; 0x1f);
10649   %}
10650 
10651   ins_pipe(ialu_reg_shift);
10652 %}
10653 
10654 // Shift Right Arithmetic Register
10655 instruct rShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10656   match(Set dst (RShiftI src1 src2));
10657 
10658   ins_cost(INSN_COST * 2);
10659   format %{ &quot;asrvw  $dst, $src1, $src2&quot; %}
10660 
10661   ins_encode %{
10662     __ asrvw(as_Register($dst$$reg),
10663              as_Register($src1$$reg),
10664              as_Register($src2$$reg));
10665   %}
10666 
10667   ins_pipe(ialu_reg_reg_vshift);
10668 %}
10669 
10670 // Shift Right Arithmetic Immediate
10671 instruct rShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10672   match(Set dst (RShiftI src1 src2));
10673 
10674   ins_cost(INSN_COST);
10675   format %{ &quot;asrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10676 
10677   ins_encode %{
10678     __ asrw(as_Register($dst$$reg),
10679             as_Register($src1$$reg),
10680             $src2$$constant &amp; 0x1f);
10681   %}
10682 
10683   ins_pipe(ialu_reg_shift);
10684 %}
10685 
10686 // Combined Int Mask and Right Shift (using UBFM)
10687 // TODO
10688 
10689 // Long Shifts
10690 
10691 // Shift Left Register
10692 instruct lShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10693   match(Set dst (LShiftL src1 src2));
10694 
10695   ins_cost(INSN_COST * 2);
10696   format %{ &quot;lslv  $dst, $src1, $src2&quot; %}
10697 
10698   ins_encode %{
10699     __ lslv(as_Register($dst$$reg),
10700             as_Register($src1$$reg),
10701             as_Register($src2$$reg));
10702   %}
10703 
10704   ins_pipe(ialu_reg_reg_vshift);
10705 %}
10706 
10707 // Shift Left Immediate
10708 instruct lShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10709   match(Set dst (LShiftL src1 src2));
10710 
10711   ins_cost(INSN_COST);
10712   format %{ &quot;lsl $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10713 
10714   ins_encode %{
10715     __ lsl(as_Register($dst$$reg),
10716             as_Register($src1$$reg),
10717             $src2$$constant &amp; 0x3f);
10718   %}
10719 
10720   ins_pipe(ialu_reg_shift);
10721 %}
10722 
10723 // Shift Right Logical Register
10724 instruct urShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10725   match(Set dst (URShiftL src1 src2));
10726 
10727   ins_cost(INSN_COST * 2);
10728   format %{ &quot;lsrv  $dst, $src1, $src2&quot; %}
10729 
10730   ins_encode %{
10731     __ lsrv(as_Register($dst$$reg),
10732             as_Register($src1$$reg),
10733             as_Register($src2$$reg));
10734   %}
10735 
10736   ins_pipe(ialu_reg_reg_vshift);
10737 %}
10738 
10739 // Shift Right Logical Immediate
10740 instruct urShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10741   match(Set dst (URShiftL src1 src2));
10742 
10743   ins_cost(INSN_COST);
10744   format %{ &quot;lsr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10745 
10746   ins_encode %{
10747     __ lsr(as_Register($dst$$reg),
10748            as_Register($src1$$reg),
10749            $src2$$constant &amp; 0x3f);
10750   %}
10751 
10752   ins_pipe(ialu_reg_shift);
10753 %}
10754 
10755 // A special-case pattern for card table stores.
10756 instruct urShiftP_reg_imm(iRegLNoSp dst, iRegP src1, immI src2) %{
10757   match(Set dst (URShiftL (CastP2X src1) src2));
10758 
10759   ins_cost(INSN_COST);
10760   format %{ &quot;lsr $dst, p2x($src1), ($src2 &amp; 0x3f)&quot; %}
10761 
10762   ins_encode %{
10763     __ lsr(as_Register($dst$$reg),
10764            as_Register($src1$$reg),
10765            $src2$$constant &amp; 0x3f);
10766   %}
10767 
10768   ins_pipe(ialu_reg_shift);
10769 %}
10770 
10771 // Shift Right Arithmetic Register
10772 instruct rShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10773   match(Set dst (RShiftL src1 src2));
10774 
10775   ins_cost(INSN_COST * 2);
10776   format %{ &quot;asrv  $dst, $src1, $src2&quot; %}
10777 
10778   ins_encode %{
10779     __ asrv(as_Register($dst$$reg),
10780             as_Register($src1$$reg),
10781             as_Register($src2$$reg));
10782   %}
10783 
10784   ins_pipe(ialu_reg_reg_vshift);
10785 %}
10786 
10787 // Shift Right Arithmetic Immediate
10788 instruct rShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10789   match(Set dst (RShiftL src1 src2));
10790 
10791   ins_cost(INSN_COST);
10792   format %{ &quot;asr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10793 
10794   ins_encode %{
10795     __ asr(as_Register($dst$$reg),
10796            as_Register($src1$$reg),
10797            $src2$$constant &amp; 0x3f);
10798   %}
10799 
10800   ins_pipe(ialu_reg_shift);
10801 %}
10802 
10803 // BEGIN This section of the file is automatically generated. Do not edit --------------
10804 
10805 instruct regL_not_reg(iRegLNoSp dst,
10806                          iRegL src1, immL_M1 m1,
10807                          rFlagsReg cr) %{
10808   match(Set dst (XorL src1 m1));
10809   ins_cost(INSN_COST);
10810   format %{ &quot;eon  $dst, $src1, zr&quot; %}
10811 
10812   ins_encode %{
10813     __ eon(as_Register($dst$$reg),
10814               as_Register($src1$$reg),
10815               zr,
10816               Assembler::LSL, 0);
10817   %}
10818 
10819   ins_pipe(ialu_reg);
10820 %}
10821 instruct regI_not_reg(iRegINoSp dst,
10822                          iRegIorL2I src1, immI_M1 m1,
10823                          rFlagsReg cr) %{
10824   match(Set dst (XorI src1 m1));
10825   ins_cost(INSN_COST);
10826   format %{ &quot;eonw  $dst, $src1, zr&quot; %}
10827 
10828   ins_encode %{
10829     __ eonw(as_Register($dst$$reg),
10830               as_Register($src1$$reg),
10831               zr,
10832               Assembler::LSL, 0);
10833   %}
10834 
10835   ins_pipe(ialu_reg);
10836 %}
10837 
10838 instruct AndI_reg_not_reg(iRegINoSp dst,
10839                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10840                          rFlagsReg cr) %{
10841   match(Set dst (AndI src1 (XorI src2 m1)));
10842   ins_cost(INSN_COST);
10843   format %{ &quot;bicw  $dst, $src1, $src2&quot; %}
10844 
10845   ins_encode %{
10846     __ bicw(as_Register($dst$$reg),
10847               as_Register($src1$$reg),
10848               as_Register($src2$$reg),
10849               Assembler::LSL, 0);
10850   %}
10851 
10852   ins_pipe(ialu_reg_reg);
10853 %}
10854 
10855 instruct AndL_reg_not_reg(iRegLNoSp dst,
10856                          iRegL src1, iRegL src2, immL_M1 m1,
10857                          rFlagsReg cr) %{
10858   match(Set dst (AndL src1 (XorL src2 m1)));
10859   ins_cost(INSN_COST);
10860   format %{ &quot;bic  $dst, $src1, $src2&quot; %}
10861 
10862   ins_encode %{
10863     __ bic(as_Register($dst$$reg),
10864               as_Register($src1$$reg),
10865               as_Register($src2$$reg),
10866               Assembler::LSL, 0);
10867   %}
10868 
10869   ins_pipe(ialu_reg_reg);
10870 %}
10871 
10872 instruct OrI_reg_not_reg(iRegINoSp dst,
10873                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10874                          rFlagsReg cr) %{
10875   match(Set dst (OrI src1 (XorI src2 m1)));
10876   ins_cost(INSN_COST);
10877   format %{ &quot;ornw  $dst, $src1, $src2&quot; %}
10878 
10879   ins_encode %{
10880     __ ornw(as_Register($dst$$reg),
10881               as_Register($src1$$reg),
10882               as_Register($src2$$reg),
10883               Assembler::LSL, 0);
10884   %}
10885 
10886   ins_pipe(ialu_reg_reg);
10887 %}
10888 
10889 instruct OrL_reg_not_reg(iRegLNoSp dst,
10890                          iRegL src1, iRegL src2, immL_M1 m1,
10891                          rFlagsReg cr) %{
10892   match(Set dst (OrL src1 (XorL src2 m1)));
10893   ins_cost(INSN_COST);
10894   format %{ &quot;orn  $dst, $src1, $src2&quot; %}
10895 
10896   ins_encode %{
10897     __ orn(as_Register($dst$$reg),
10898               as_Register($src1$$reg),
10899               as_Register($src2$$reg),
10900               Assembler::LSL, 0);
10901   %}
10902 
10903   ins_pipe(ialu_reg_reg);
10904 %}
10905 
10906 instruct XorI_reg_not_reg(iRegINoSp dst,
10907                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10908                          rFlagsReg cr) %{
10909   match(Set dst (XorI m1 (XorI src2 src1)));
10910   ins_cost(INSN_COST);
10911   format %{ &quot;eonw  $dst, $src1, $src2&quot; %}
10912 
10913   ins_encode %{
10914     __ eonw(as_Register($dst$$reg),
10915               as_Register($src1$$reg),
10916               as_Register($src2$$reg),
10917               Assembler::LSL, 0);
10918   %}
10919 
10920   ins_pipe(ialu_reg_reg);
10921 %}
10922 
10923 instruct XorL_reg_not_reg(iRegLNoSp dst,
10924                          iRegL src1, iRegL src2, immL_M1 m1,
10925                          rFlagsReg cr) %{
10926   match(Set dst (XorL m1 (XorL src2 src1)));
10927   ins_cost(INSN_COST);
10928   format %{ &quot;eon  $dst, $src1, $src2&quot; %}
10929 
10930   ins_encode %{
10931     __ eon(as_Register($dst$$reg),
10932               as_Register($src1$$reg),
10933               as_Register($src2$$reg),
10934               Assembler::LSL, 0);
10935   %}
10936 
10937   ins_pipe(ialu_reg_reg);
10938 %}
10939 
10940 instruct AndI_reg_URShift_not_reg(iRegINoSp dst,
10941                          iRegIorL2I src1, iRegIorL2I src2,
10942                          immI src3, immI_M1 src4, rFlagsReg cr) %{
10943   match(Set dst (AndI src1 (XorI(URShiftI src2 src3) src4)));
10944   ins_cost(1.9 * INSN_COST);
10945   format %{ &quot;bicw  $dst, $src1, $src2, LSR $src3&quot; %}
10946 
10947   ins_encode %{
10948     __ bicw(as_Register($dst$$reg),
10949               as_Register($src1$$reg),
10950               as_Register($src2$$reg),
10951               Assembler::LSR,
10952               $src3$$constant &amp; 0x1f);
10953   %}
10954 
10955   ins_pipe(ialu_reg_reg_shift);
10956 %}
10957 
10958 instruct AndL_reg_URShift_not_reg(iRegLNoSp dst,
10959                          iRegL src1, iRegL src2,
10960                          immI src3, immL_M1 src4, rFlagsReg cr) %{
10961   match(Set dst (AndL src1 (XorL(URShiftL src2 src3) src4)));
10962   ins_cost(1.9 * INSN_COST);
10963   format %{ &quot;bic  $dst, $src1, $src2, LSR $src3&quot; %}
10964 
10965   ins_encode %{
10966     __ bic(as_Register($dst$$reg),
10967               as_Register($src1$$reg),
10968               as_Register($src2$$reg),
10969               Assembler::LSR,
10970               $src3$$constant &amp; 0x3f);
10971   %}
10972 
10973   ins_pipe(ialu_reg_reg_shift);
10974 %}
10975 
10976 instruct AndI_reg_RShift_not_reg(iRegINoSp dst,
10977                          iRegIorL2I src1, iRegIorL2I src2,
10978                          immI src3, immI_M1 src4, rFlagsReg cr) %{
10979   match(Set dst (AndI src1 (XorI(RShiftI src2 src3) src4)));
10980   ins_cost(1.9 * INSN_COST);
10981   format %{ &quot;bicw  $dst, $src1, $src2, ASR $src3&quot; %}
10982 
10983   ins_encode %{
10984     __ bicw(as_Register($dst$$reg),
10985               as_Register($src1$$reg),
10986               as_Register($src2$$reg),
10987               Assembler::ASR,
10988               $src3$$constant &amp; 0x1f);
10989   %}
10990 
10991   ins_pipe(ialu_reg_reg_shift);
10992 %}
10993 
10994 instruct AndL_reg_RShift_not_reg(iRegLNoSp dst,
10995                          iRegL src1, iRegL src2,
10996                          immI src3, immL_M1 src4, rFlagsReg cr) %{
10997   match(Set dst (AndL src1 (XorL(RShiftL src2 src3) src4)));
10998   ins_cost(1.9 * INSN_COST);
10999   format %{ &quot;bic  $dst, $src1, $src2, ASR $src3&quot; %}
11000 
11001   ins_encode %{
11002     __ bic(as_Register($dst$$reg),
11003               as_Register($src1$$reg),
11004               as_Register($src2$$reg),
11005               Assembler::ASR,
11006               $src3$$constant &amp; 0x3f);
11007   %}
11008 
11009   ins_pipe(ialu_reg_reg_shift);
11010 %}
11011 
11012 instruct AndI_reg_LShift_not_reg(iRegINoSp dst,
11013                          iRegIorL2I src1, iRegIorL2I src2,
11014                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11015   match(Set dst (AndI src1 (XorI(LShiftI src2 src3) src4)));
11016   ins_cost(1.9 * INSN_COST);
11017   format %{ &quot;bicw  $dst, $src1, $src2, LSL $src3&quot; %}
11018 
11019   ins_encode %{
11020     __ bicw(as_Register($dst$$reg),
11021               as_Register($src1$$reg),
11022               as_Register($src2$$reg),
11023               Assembler::LSL,
11024               $src3$$constant &amp; 0x1f);
11025   %}
11026 
11027   ins_pipe(ialu_reg_reg_shift);
11028 %}
11029 
11030 instruct AndL_reg_LShift_not_reg(iRegLNoSp dst,
11031                          iRegL src1, iRegL src2,
11032                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11033   match(Set dst (AndL src1 (XorL(LShiftL src2 src3) src4)));
11034   ins_cost(1.9 * INSN_COST);
11035   format %{ &quot;bic  $dst, $src1, $src2, LSL $src3&quot; %}
11036 
11037   ins_encode %{
11038     __ bic(as_Register($dst$$reg),
11039               as_Register($src1$$reg),
11040               as_Register($src2$$reg),
11041               Assembler::LSL,
11042               $src3$$constant &amp; 0x3f);
11043   %}
11044 
11045   ins_pipe(ialu_reg_reg_shift);
11046 %}
11047 
11048 instruct XorI_reg_URShift_not_reg(iRegINoSp dst,
11049                          iRegIorL2I src1, iRegIorL2I src2,
11050                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11051   match(Set dst (XorI src4 (XorI(URShiftI src2 src3) src1)));
11052   ins_cost(1.9 * INSN_COST);
11053   format %{ &quot;eonw  $dst, $src1, $src2, LSR $src3&quot; %}
11054 
11055   ins_encode %{
11056     __ eonw(as_Register($dst$$reg),
11057               as_Register($src1$$reg),
11058               as_Register($src2$$reg),
11059               Assembler::LSR,
11060               $src3$$constant &amp; 0x1f);
11061   %}
11062 
11063   ins_pipe(ialu_reg_reg_shift);
11064 %}
11065 
11066 instruct XorL_reg_URShift_not_reg(iRegLNoSp dst,
11067                          iRegL src1, iRegL src2,
11068                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11069   match(Set dst (XorL src4 (XorL(URShiftL src2 src3) src1)));
11070   ins_cost(1.9 * INSN_COST);
11071   format %{ &quot;eon  $dst, $src1, $src2, LSR $src3&quot; %}
11072 
11073   ins_encode %{
11074     __ eon(as_Register($dst$$reg),
11075               as_Register($src1$$reg),
11076               as_Register($src2$$reg),
11077               Assembler::LSR,
11078               $src3$$constant &amp; 0x3f);
11079   %}
11080 
11081   ins_pipe(ialu_reg_reg_shift);
11082 %}
11083 
11084 instruct XorI_reg_RShift_not_reg(iRegINoSp dst,
11085                          iRegIorL2I src1, iRegIorL2I src2,
11086                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11087   match(Set dst (XorI src4 (XorI(RShiftI src2 src3) src1)));
11088   ins_cost(1.9 * INSN_COST);
11089   format %{ &quot;eonw  $dst, $src1, $src2, ASR $src3&quot; %}
11090 
11091   ins_encode %{
11092     __ eonw(as_Register($dst$$reg),
11093               as_Register($src1$$reg),
11094               as_Register($src2$$reg),
11095               Assembler::ASR,
11096               $src3$$constant &amp; 0x1f);
11097   %}
11098 
11099   ins_pipe(ialu_reg_reg_shift);
11100 %}
11101 
11102 instruct XorL_reg_RShift_not_reg(iRegLNoSp dst,
11103                          iRegL src1, iRegL src2,
11104                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11105   match(Set dst (XorL src4 (XorL(RShiftL src2 src3) src1)));
11106   ins_cost(1.9 * INSN_COST);
11107   format %{ &quot;eon  $dst, $src1, $src2, ASR $src3&quot; %}
11108 
11109   ins_encode %{
11110     __ eon(as_Register($dst$$reg),
11111               as_Register($src1$$reg),
11112               as_Register($src2$$reg),
11113               Assembler::ASR,
11114               $src3$$constant &amp; 0x3f);
11115   %}
11116 
11117   ins_pipe(ialu_reg_reg_shift);
11118 %}
11119 
11120 instruct XorI_reg_LShift_not_reg(iRegINoSp dst,
11121                          iRegIorL2I src1, iRegIorL2I src2,
11122                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11123   match(Set dst (XorI src4 (XorI(LShiftI src2 src3) src1)));
11124   ins_cost(1.9 * INSN_COST);
11125   format %{ &quot;eonw  $dst, $src1, $src2, LSL $src3&quot; %}
11126 
11127   ins_encode %{
11128     __ eonw(as_Register($dst$$reg),
11129               as_Register($src1$$reg),
11130               as_Register($src2$$reg),
11131               Assembler::LSL,
11132               $src3$$constant &amp; 0x1f);
11133   %}
11134 
11135   ins_pipe(ialu_reg_reg_shift);
11136 %}
11137 
11138 instruct XorL_reg_LShift_not_reg(iRegLNoSp dst,
11139                          iRegL src1, iRegL src2,
11140                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11141   match(Set dst (XorL src4 (XorL(LShiftL src2 src3) src1)));
11142   ins_cost(1.9 * INSN_COST);
11143   format %{ &quot;eon  $dst, $src1, $src2, LSL $src3&quot; %}
11144 
11145   ins_encode %{
11146     __ eon(as_Register($dst$$reg),
11147               as_Register($src1$$reg),
11148               as_Register($src2$$reg),
11149               Assembler::LSL,
11150               $src3$$constant &amp; 0x3f);
11151   %}
11152 
11153   ins_pipe(ialu_reg_reg_shift);
11154 %}
11155 
11156 instruct OrI_reg_URShift_not_reg(iRegINoSp dst,
11157                          iRegIorL2I src1, iRegIorL2I src2,
11158                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11159   match(Set dst (OrI src1 (XorI(URShiftI src2 src3) src4)));
11160   ins_cost(1.9 * INSN_COST);
11161   format %{ &quot;ornw  $dst, $src1, $src2, LSR $src3&quot; %}
11162 
11163   ins_encode %{
11164     __ ornw(as_Register($dst$$reg),
11165               as_Register($src1$$reg),
11166               as_Register($src2$$reg),
11167               Assembler::LSR,
11168               $src3$$constant &amp; 0x1f);
11169   %}
11170 
11171   ins_pipe(ialu_reg_reg_shift);
11172 %}
11173 
11174 instruct OrL_reg_URShift_not_reg(iRegLNoSp dst,
11175                          iRegL src1, iRegL src2,
11176                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11177   match(Set dst (OrL src1 (XorL(URShiftL src2 src3) src4)));
11178   ins_cost(1.9 * INSN_COST);
11179   format %{ &quot;orn  $dst, $src1, $src2, LSR $src3&quot; %}
11180 
11181   ins_encode %{
11182     __ orn(as_Register($dst$$reg),
11183               as_Register($src1$$reg),
11184               as_Register($src2$$reg),
11185               Assembler::LSR,
11186               $src3$$constant &amp; 0x3f);
11187   %}
11188 
11189   ins_pipe(ialu_reg_reg_shift);
11190 %}
11191 
11192 instruct OrI_reg_RShift_not_reg(iRegINoSp dst,
11193                          iRegIorL2I src1, iRegIorL2I src2,
11194                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11195   match(Set dst (OrI src1 (XorI(RShiftI src2 src3) src4)));
11196   ins_cost(1.9 * INSN_COST);
11197   format %{ &quot;ornw  $dst, $src1, $src2, ASR $src3&quot; %}
11198 
11199   ins_encode %{
11200     __ ornw(as_Register($dst$$reg),
11201               as_Register($src1$$reg),
11202               as_Register($src2$$reg),
11203               Assembler::ASR,
11204               $src3$$constant &amp; 0x1f);
11205   %}
11206 
11207   ins_pipe(ialu_reg_reg_shift);
11208 %}
11209 
11210 instruct OrL_reg_RShift_not_reg(iRegLNoSp dst,
11211                          iRegL src1, iRegL src2,
11212                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11213   match(Set dst (OrL src1 (XorL(RShiftL src2 src3) src4)));
11214   ins_cost(1.9 * INSN_COST);
11215   format %{ &quot;orn  $dst, $src1, $src2, ASR $src3&quot; %}
11216 
11217   ins_encode %{
11218     __ orn(as_Register($dst$$reg),
11219               as_Register($src1$$reg),
11220               as_Register($src2$$reg),
11221               Assembler::ASR,
11222               $src3$$constant &amp; 0x3f);
11223   %}
11224 
11225   ins_pipe(ialu_reg_reg_shift);
11226 %}
11227 
11228 instruct OrI_reg_LShift_not_reg(iRegINoSp dst,
11229                          iRegIorL2I src1, iRegIorL2I src2,
11230                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11231   match(Set dst (OrI src1 (XorI(LShiftI src2 src3) src4)));
11232   ins_cost(1.9 * INSN_COST);
11233   format %{ &quot;ornw  $dst, $src1, $src2, LSL $src3&quot; %}
11234 
11235   ins_encode %{
11236     __ ornw(as_Register($dst$$reg),
11237               as_Register($src1$$reg),
11238               as_Register($src2$$reg),
11239               Assembler::LSL,
11240               $src3$$constant &amp; 0x1f);
11241   %}
11242 
11243   ins_pipe(ialu_reg_reg_shift);
11244 %}
11245 
11246 instruct OrL_reg_LShift_not_reg(iRegLNoSp dst,
11247                          iRegL src1, iRegL src2,
11248                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11249   match(Set dst (OrL src1 (XorL(LShiftL src2 src3) src4)));
11250   ins_cost(1.9 * INSN_COST);
11251   format %{ &quot;orn  $dst, $src1, $src2, LSL $src3&quot; %}
11252 
11253   ins_encode %{
11254     __ orn(as_Register($dst$$reg),
11255               as_Register($src1$$reg),
11256               as_Register($src2$$reg),
11257               Assembler::LSL,
11258               $src3$$constant &amp; 0x3f);
11259   %}
11260 
11261   ins_pipe(ialu_reg_reg_shift);
11262 %}
11263 
11264 instruct AndI_reg_URShift_reg(iRegINoSp dst,
11265                          iRegIorL2I src1, iRegIorL2I src2,
11266                          immI src3, rFlagsReg cr) %{
11267   match(Set dst (AndI src1 (URShiftI src2 src3)));
11268 
11269   ins_cost(1.9 * INSN_COST);
11270   format %{ &quot;andw  $dst, $src1, $src2, LSR $src3&quot; %}
11271 
11272   ins_encode %{
11273     __ andw(as_Register($dst$$reg),
11274               as_Register($src1$$reg),
11275               as_Register($src2$$reg),
11276               Assembler::LSR,
11277               $src3$$constant &amp; 0x1f);
11278   %}
11279 
11280   ins_pipe(ialu_reg_reg_shift);
11281 %}
11282 
11283 instruct AndL_reg_URShift_reg(iRegLNoSp dst,
11284                          iRegL src1, iRegL src2,
11285                          immI src3, rFlagsReg cr) %{
11286   match(Set dst (AndL src1 (URShiftL src2 src3)));
11287 
11288   ins_cost(1.9 * INSN_COST);
11289   format %{ &quot;andr  $dst, $src1, $src2, LSR $src3&quot; %}
11290 
11291   ins_encode %{
11292     __ andr(as_Register($dst$$reg),
11293               as_Register($src1$$reg),
11294               as_Register($src2$$reg),
11295               Assembler::LSR,
11296               $src3$$constant &amp; 0x3f);
11297   %}
11298 
11299   ins_pipe(ialu_reg_reg_shift);
11300 %}
11301 
11302 instruct AndI_reg_RShift_reg(iRegINoSp dst,
11303                          iRegIorL2I src1, iRegIorL2I src2,
11304                          immI src3, rFlagsReg cr) %{
11305   match(Set dst (AndI src1 (RShiftI src2 src3)));
11306 
11307   ins_cost(1.9 * INSN_COST);
11308   format %{ &quot;andw  $dst, $src1, $src2, ASR $src3&quot; %}
11309 
11310   ins_encode %{
11311     __ andw(as_Register($dst$$reg),
11312               as_Register($src1$$reg),
11313               as_Register($src2$$reg),
11314               Assembler::ASR,
11315               $src3$$constant &amp; 0x1f);
11316   %}
11317 
11318   ins_pipe(ialu_reg_reg_shift);
11319 %}
11320 
11321 instruct AndL_reg_RShift_reg(iRegLNoSp dst,
11322                          iRegL src1, iRegL src2,
11323                          immI src3, rFlagsReg cr) %{
11324   match(Set dst (AndL src1 (RShiftL src2 src3)));
11325 
11326   ins_cost(1.9 * INSN_COST);
11327   format %{ &quot;andr  $dst, $src1, $src2, ASR $src3&quot; %}
11328 
11329   ins_encode %{
11330     __ andr(as_Register($dst$$reg),
11331               as_Register($src1$$reg),
11332               as_Register($src2$$reg),
11333               Assembler::ASR,
11334               $src3$$constant &amp; 0x3f);
11335   %}
11336 
11337   ins_pipe(ialu_reg_reg_shift);
11338 %}
11339 
11340 instruct AndI_reg_LShift_reg(iRegINoSp dst,
11341                          iRegIorL2I src1, iRegIorL2I src2,
11342                          immI src3, rFlagsReg cr) %{
11343   match(Set dst (AndI src1 (LShiftI src2 src3)));
11344 
11345   ins_cost(1.9 * INSN_COST);
11346   format %{ &quot;andw  $dst, $src1, $src2, LSL $src3&quot; %}
11347 
11348   ins_encode %{
11349     __ andw(as_Register($dst$$reg),
11350               as_Register($src1$$reg),
11351               as_Register($src2$$reg),
11352               Assembler::LSL,
11353               $src3$$constant &amp; 0x1f);
11354   %}
11355 
11356   ins_pipe(ialu_reg_reg_shift);
11357 %}
11358 
11359 instruct AndL_reg_LShift_reg(iRegLNoSp dst,
11360                          iRegL src1, iRegL src2,
11361                          immI src3, rFlagsReg cr) %{
11362   match(Set dst (AndL src1 (LShiftL src2 src3)));
11363 
11364   ins_cost(1.9 * INSN_COST);
11365   format %{ &quot;andr  $dst, $src1, $src2, LSL $src3&quot; %}
11366 
11367   ins_encode %{
11368     __ andr(as_Register($dst$$reg),
11369               as_Register($src1$$reg),
11370               as_Register($src2$$reg),
11371               Assembler::LSL,
11372               $src3$$constant &amp; 0x3f);
11373   %}
11374 
11375   ins_pipe(ialu_reg_reg_shift);
11376 %}
11377 
11378 instruct XorI_reg_URShift_reg(iRegINoSp dst,
11379                          iRegIorL2I src1, iRegIorL2I src2,
11380                          immI src3, rFlagsReg cr) %{
11381   match(Set dst (XorI src1 (URShiftI src2 src3)));
11382 
11383   ins_cost(1.9 * INSN_COST);
11384   format %{ &quot;eorw  $dst, $src1, $src2, LSR $src3&quot; %}
11385 
11386   ins_encode %{
11387     __ eorw(as_Register($dst$$reg),
11388               as_Register($src1$$reg),
11389               as_Register($src2$$reg),
11390               Assembler::LSR,
11391               $src3$$constant &amp; 0x1f);
11392   %}
11393 
11394   ins_pipe(ialu_reg_reg_shift);
11395 %}
11396 
11397 instruct XorL_reg_URShift_reg(iRegLNoSp dst,
11398                          iRegL src1, iRegL src2,
11399                          immI src3, rFlagsReg cr) %{
11400   match(Set dst (XorL src1 (URShiftL src2 src3)));
11401 
11402   ins_cost(1.9 * INSN_COST);
11403   format %{ &quot;eor  $dst, $src1, $src2, LSR $src3&quot; %}
11404 
11405   ins_encode %{
11406     __ eor(as_Register($dst$$reg),
11407               as_Register($src1$$reg),
11408               as_Register($src2$$reg),
11409               Assembler::LSR,
11410               $src3$$constant &amp; 0x3f);
11411   %}
11412 
11413   ins_pipe(ialu_reg_reg_shift);
11414 %}
11415 
11416 instruct XorI_reg_RShift_reg(iRegINoSp dst,
11417                          iRegIorL2I src1, iRegIorL2I src2,
11418                          immI src3, rFlagsReg cr) %{
11419   match(Set dst (XorI src1 (RShiftI src2 src3)));
11420 
11421   ins_cost(1.9 * INSN_COST);
11422   format %{ &quot;eorw  $dst, $src1, $src2, ASR $src3&quot; %}
11423 
11424   ins_encode %{
11425     __ eorw(as_Register($dst$$reg),
11426               as_Register($src1$$reg),
11427               as_Register($src2$$reg),
11428               Assembler::ASR,
11429               $src3$$constant &amp; 0x1f);
11430   %}
11431 
11432   ins_pipe(ialu_reg_reg_shift);
11433 %}
11434 
11435 instruct XorL_reg_RShift_reg(iRegLNoSp dst,
11436                          iRegL src1, iRegL src2,
11437                          immI src3, rFlagsReg cr) %{
11438   match(Set dst (XorL src1 (RShiftL src2 src3)));
11439 
11440   ins_cost(1.9 * INSN_COST);
11441   format %{ &quot;eor  $dst, $src1, $src2, ASR $src3&quot; %}
11442 
11443   ins_encode %{
11444     __ eor(as_Register($dst$$reg),
11445               as_Register($src1$$reg),
11446               as_Register($src2$$reg),
11447               Assembler::ASR,
11448               $src3$$constant &amp; 0x3f);
11449   %}
11450 
11451   ins_pipe(ialu_reg_reg_shift);
11452 %}
11453 
11454 instruct XorI_reg_LShift_reg(iRegINoSp dst,
11455                          iRegIorL2I src1, iRegIorL2I src2,
11456                          immI src3, rFlagsReg cr) %{
11457   match(Set dst (XorI src1 (LShiftI src2 src3)));
11458 
11459   ins_cost(1.9 * INSN_COST);
11460   format %{ &quot;eorw  $dst, $src1, $src2, LSL $src3&quot; %}
11461 
11462   ins_encode %{
11463     __ eorw(as_Register($dst$$reg),
11464               as_Register($src1$$reg),
11465               as_Register($src2$$reg),
11466               Assembler::LSL,
11467               $src3$$constant &amp; 0x1f);
11468   %}
11469 
11470   ins_pipe(ialu_reg_reg_shift);
11471 %}
11472 
11473 instruct XorL_reg_LShift_reg(iRegLNoSp dst,
11474                          iRegL src1, iRegL src2,
11475                          immI src3, rFlagsReg cr) %{
11476   match(Set dst (XorL src1 (LShiftL src2 src3)));
11477 
11478   ins_cost(1.9 * INSN_COST);
11479   format %{ &quot;eor  $dst, $src1, $src2, LSL $src3&quot; %}
11480 
11481   ins_encode %{
11482     __ eor(as_Register($dst$$reg),
11483               as_Register($src1$$reg),
11484               as_Register($src2$$reg),
11485               Assembler::LSL,
11486               $src3$$constant &amp; 0x3f);
11487   %}
11488 
11489   ins_pipe(ialu_reg_reg_shift);
11490 %}
11491 
11492 instruct OrI_reg_URShift_reg(iRegINoSp dst,
11493                          iRegIorL2I src1, iRegIorL2I src2,
11494                          immI src3, rFlagsReg cr) %{
11495   match(Set dst (OrI src1 (URShiftI src2 src3)));
11496 
11497   ins_cost(1.9 * INSN_COST);
11498   format %{ &quot;orrw  $dst, $src1, $src2, LSR $src3&quot; %}
11499 
11500   ins_encode %{
11501     __ orrw(as_Register($dst$$reg),
11502               as_Register($src1$$reg),
11503               as_Register($src2$$reg),
11504               Assembler::LSR,
11505               $src3$$constant &amp; 0x1f);
11506   %}
11507 
11508   ins_pipe(ialu_reg_reg_shift);
11509 %}
11510 
11511 instruct OrL_reg_URShift_reg(iRegLNoSp dst,
11512                          iRegL src1, iRegL src2,
11513                          immI src3, rFlagsReg cr) %{
11514   match(Set dst (OrL src1 (URShiftL src2 src3)));
11515 
11516   ins_cost(1.9 * INSN_COST);
11517   format %{ &quot;orr  $dst, $src1, $src2, LSR $src3&quot; %}
11518 
11519   ins_encode %{
11520     __ orr(as_Register($dst$$reg),
11521               as_Register($src1$$reg),
11522               as_Register($src2$$reg),
11523               Assembler::LSR,
11524               $src3$$constant &amp; 0x3f);
11525   %}
11526 
11527   ins_pipe(ialu_reg_reg_shift);
11528 %}
11529 
11530 instruct OrI_reg_RShift_reg(iRegINoSp dst,
11531                          iRegIorL2I src1, iRegIorL2I src2,
11532                          immI src3, rFlagsReg cr) %{
11533   match(Set dst (OrI src1 (RShiftI src2 src3)));
11534 
11535   ins_cost(1.9 * INSN_COST);
11536   format %{ &quot;orrw  $dst, $src1, $src2, ASR $src3&quot; %}
11537 
11538   ins_encode %{
11539     __ orrw(as_Register($dst$$reg),
11540               as_Register($src1$$reg),
11541               as_Register($src2$$reg),
11542               Assembler::ASR,
11543               $src3$$constant &amp; 0x1f);
11544   %}
11545 
11546   ins_pipe(ialu_reg_reg_shift);
11547 %}
11548 
11549 instruct OrL_reg_RShift_reg(iRegLNoSp dst,
11550                          iRegL src1, iRegL src2,
11551                          immI src3, rFlagsReg cr) %{
11552   match(Set dst (OrL src1 (RShiftL src2 src3)));
11553 
11554   ins_cost(1.9 * INSN_COST);
11555   format %{ &quot;orr  $dst, $src1, $src2, ASR $src3&quot; %}
11556 
11557   ins_encode %{
11558     __ orr(as_Register($dst$$reg),
11559               as_Register($src1$$reg),
11560               as_Register($src2$$reg),
11561               Assembler::ASR,
11562               $src3$$constant &amp; 0x3f);
11563   %}
11564 
11565   ins_pipe(ialu_reg_reg_shift);
11566 %}
11567 
11568 instruct OrI_reg_LShift_reg(iRegINoSp dst,
11569                          iRegIorL2I src1, iRegIorL2I src2,
11570                          immI src3, rFlagsReg cr) %{
11571   match(Set dst (OrI src1 (LShiftI src2 src3)));
11572 
11573   ins_cost(1.9 * INSN_COST);
11574   format %{ &quot;orrw  $dst, $src1, $src2, LSL $src3&quot; %}
11575 
11576   ins_encode %{
11577     __ orrw(as_Register($dst$$reg),
11578               as_Register($src1$$reg),
11579               as_Register($src2$$reg),
11580               Assembler::LSL,
11581               $src3$$constant &amp; 0x1f);
11582   %}
11583 
11584   ins_pipe(ialu_reg_reg_shift);
11585 %}
11586 
11587 instruct OrL_reg_LShift_reg(iRegLNoSp dst,
11588                          iRegL src1, iRegL src2,
11589                          immI src3, rFlagsReg cr) %{
11590   match(Set dst (OrL src1 (LShiftL src2 src3)));
11591 
11592   ins_cost(1.9 * INSN_COST);
11593   format %{ &quot;orr  $dst, $src1, $src2, LSL $src3&quot; %}
11594 
11595   ins_encode %{
11596     __ orr(as_Register($dst$$reg),
11597               as_Register($src1$$reg),
11598               as_Register($src2$$reg),
11599               Assembler::LSL,
11600               $src3$$constant &amp; 0x3f);
11601   %}
11602 
11603   ins_pipe(ialu_reg_reg_shift);
11604 %}
11605 
11606 instruct AddI_reg_URShift_reg(iRegINoSp dst,
11607                          iRegIorL2I src1, iRegIorL2I src2,
11608                          immI src3, rFlagsReg cr) %{
11609   match(Set dst (AddI src1 (URShiftI src2 src3)));
11610 
11611   ins_cost(1.9 * INSN_COST);
11612   format %{ &quot;addw  $dst, $src1, $src2, LSR $src3&quot; %}
11613 
11614   ins_encode %{
11615     __ addw(as_Register($dst$$reg),
11616               as_Register($src1$$reg),
11617               as_Register($src2$$reg),
11618               Assembler::LSR,
11619               $src3$$constant &amp; 0x1f);
11620   %}
11621 
11622   ins_pipe(ialu_reg_reg_shift);
11623 %}
11624 
11625 instruct AddL_reg_URShift_reg(iRegLNoSp dst,
11626                          iRegL src1, iRegL src2,
11627                          immI src3, rFlagsReg cr) %{
11628   match(Set dst (AddL src1 (URShiftL src2 src3)));
11629 
11630   ins_cost(1.9 * INSN_COST);
11631   format %{ &quot;add  $dst, $src1, $src2, LSR $src3&quot; %}
11632 
11633   ins_encode %{
11634     __ add(as_Register($dst$$reg),
11635               as_Register($src1$$reg),
11636               as_Register($src2$$reg),
11637               Assembler::LSR,
11638               $src3$$constant &amp; 0x3f);
11639   %}
11640 
11641   ins_pipe(ialu_reg_reg_shift);
11642 %}
11643 
11644 instruct AddI_reg_RShift_reg(iRegINoSp dst,
11645                          iRegIorL2I src1, iRegIorL2I src2,
11646                          immI src3, rFlagsReg cr) %{
11647   match(Set dst (AddI src1 (RShiftI src2 src3)));
11648 
11649   ins_cost(1.9 * INSN_COST);
11650   format %{ &quot;addw  $dst, $src1, $src2, ASR $src3&quot; %}
11651 
11652   ins_encode %{
11653     __ addw(as_Register($dst$$reg),
11654               as_Register($src1$$reg),
11655               as_Register($src2$$reg),
11656               Assembler::ASR,
11657               $src3$$constant &amp; 0x1f);
11658   %}
11659 
11660   ins_pipe(ialu_reg_reg_shift);
11661 %}
11662 
11663 instruct AddL_reg_RShift_reg(iRegLNoSp dst,
11664                          iRegL src1, iRegL src2,
11665                          immI src3, rFlagsReg cr) %{
11666   match(Set dst (AddL src1 (RShiftL src2 src3)));
11667 
11668   ins_cost(1.9 * INSN_COST);
11669   format %{ &quot;add  $dst, $src1, $src2, ASR $src3&quot; %}
11670 
11671   ins_encode %{
11672     __ add(as_Register($dst$$reg),
11673               as_Register($src1$$reg),
11674               as_Register($src2$$reg),
11675               Assembler::ASR,
11676               $src3$$constant &amp; 0x3f);
11677   %}
11678 
11679   ins_pipe(ialu_reg_reg_shift);
11680 %}
11681 
11682 instruct AddI_reg_LShift_reg(iRegINoSp dst,
11683                          iRegIorL2I src1, iRegIorL2I src2,
11684                          immI src3, rFlagsReg cr) %{
11685   match(Set dst (AddI src1 (LShiftI src2 src3)));
11686 
11687   ins_cost(1.9 * INSN_COST);
11688   format %{ &quot;addw  $dst, $src1, $src2, LSL $src3&quot; %}
11689 
11690   ins_encode %{
11691     __ addw(as_Register($dst$$reg),
11692               as_Register($src1$$reg),
11693               as_Register($src2$$reg),
11694               Assembler::LSL,
11695               $src3$$constant &amp; 0x1f);
11696   %}
11697 
11698   ins_pipe(ialu_reg_reg_shift);
11699 %}
11700 
11701 instruct AddL_reg_LShift_reg(iRegLNoSp dst,
11702                          iRegL src1, iRegL src2,
11703                          immI src3, rFlagsReg cr) %{
11704   match(Set dst (AddL src1 (LShiftL src2 src3)));
11705 
11706   ins_cost(1.9 * INSN_COST);
11707   format %{ &quot;add  $dst, $src1, $src2, LSL $src3&quot; %}
11708 
11709   ins_encode %{
11710     __ add(as_Register($dst$$reg),
11711               as_Register($src1$$reg),
11712               as_Register($src2$$reg),
11713               Assembler::LSL,
11714               $src3$$constant &amp; 0x3f);
11715   %}
11716 
11717   ins_pipe(ialu_reg_reg_shift);
11718 %}
11719 
11720 instruct SubI_reg_URShift_reg(iRegINoSp dst,
11721                          iRegIorL2I src1, iRegIorL2I src2,
11722                          immI src3, rFlagsReg cr) %{
11723   match(Set dst (SubI src1 (URShiftI src2 src3)));
11724 
11725   ins_cost(1.9 * INSN_COST);
11726   format %{ &quot;subw  $dst, $src1, $src2, LSR $src3&quot; %}
11727 
11728   ins_encode %{
11729     __ subw(as_Register($dst$$reg),
11730               as_Register($src1$$reg),
11731               as_Register($src2$$reg),
11732               Assembler::LSR,
11733               $src3$$constant &amp; 0x1f);
11734   %}
11735 
11736   ins_pipe(ialu_reg_reg_shift);
11737 %}
11738 
11739 instruct SubL_reg_URShift_reg(iRegLNoSp dst,
11740                          iRegL src1, iRegL src2,
11741                          immI src3, rFlagsReg cr) %{
11742   match(Set dst (SubL src1 (URShiftL src2 src3)));
11743 
11744   ins_cost(1.9 * INSN_COST);
11745   format %{ &quot;sub  $dst, $src1, $src2, LSR $src3&quot; %}
11746 
11747   ins_encode %{
11748     __ sub(as_Register($dst$$reg),
11749               as_Register($src1$$reg),
11750               as_Register($src2$$reg),
11751               Assembler::LSR,
11752               $src3$$constant &amp; 0x3f);
11753   %}
11754 
11755   ins_pipe(ialu_reg_reg_shift);
11756 %}
11757 
11758 instruct SubI_reg_RShift_reg(iRegINoSp dst,
11759                          iRegIorL2I src1, iRegIorL2I src2,
11760                          immI src3, rFlagsReg cr) %{
11761   match(Set dst (SubI src1 (RShiftI src2 src3)));
11762 
11763   ins_cost(1.9 * INSN_COST);
11764   format %{ &quot;subw  $dst, $src1, $src2, ASR $src3&quot; %}
11765 
11766   ins_encode %{
11767     __ subw(as_Register($dst$$reg),
11768               as_Register($src1$$reg),
11769               as_Register($src2$$reg),
11770               Assembler::ASR,
11771               $src3$$constant &amp; 0x1f);
11772   %}
11773 
11774   ins_pipe(ialu_reg_reg_shift);
11775 %}
11776 
11777 instruct SubL_reg_RShift_reg(iRegLNoSp dst,
11778                          iRegL src1, iRegL src2,
11779                          immI src3, rFlagsReg cr) %{
11780   match(Set dst (SubL src1 (RShiftL src2 src3)));
11781 
11782   ins_cost(1.9 * INSN_COST);
11783   format %{ &quot;sub  $dst, $src1, $src2, ASR $src3&quot; %}
11784 
11785   ins_encode %{
11786     __ sub(as_Register($dst$$reg),
11787               as_Register($src1$$reg),
11788               as_Register($src2$$reg),
11789               Assembler::ASR,
11790               $src3$$constant &amp; 0x3f);
11791   %}
11792 
11793   ins_pipe(ialu_reg_reg_shift);
11794 %}
11795 
11796 instruct SubI_reg_LShift_reg(iRegINoSp dst,
11797                          iRegIorL2I src1, iRegIorL2I src2,
11798                          immI src3, rFlagsReg cr) %{
11799   match(Set dst (SubI src1 (LShiftI src2 src3)));
11800 
11801   ins_cost(1.9 * INSN_COST);
11802   format %{ &quot;subw  $dst, $src1, $src2, LSL $src3&quot; %}
11803 
11804   ins_encode %{
11805     __ subw(as_Register($dst$$reg),
11806               as_Register($src1$$reg),
11807               as_Register($src2$$reg),
11808               Assembler::LSL,
11809               $src3$$constant &amp; 0x1f);
11810   %}
11811 
11812   ins_pipe(ialu_reg_reg_shift);
11813 %}
11814 
11815 instruct SubL_reg_LShift_reg(iRegLNoSp dst,
11816                          iRegL src1, iRegL src2,
11817                          immI src3, rFlagsReg cr) %{
11818   match(Set dst (SubL src1 (LShiftL src2 src3)));
11819 
11820   ins_cost(1.9 * INSN_COST);
11821   format %{ &quot;sub  $dst, $src1, $src2, LSL $src3&quot; %}
11822 
11823   ins_encode %{
11824     __ sub(as_Register($dst$$reg),
11825               as_Register($src1$$reg),
11826               as_Register($src2$$reg),
11827               Assembler::LSL,
11828               $src3$$constant &amp; 0x3f);
11829   %}
11830 
11831   ins_pipe(ialu_reg_reg_shift);
11832 %}
11833 
11834 
11835 
11836 // Shift Left followed by Shift Right.
11837 // This idiom is used by the compiler for the i2b bytecode etc.
11838 instruct sbfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11839 %{
11840   match(Set dst (RShiftL (LShiftL src lshift_count) rshift_count));
11841   ins_cost(INSN_COST * 2);
11842   format %{ &quot;sbfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11843   ins_encode %{
11844     int lshift = $lshift_count$$constant &amp; 63;
11845     int rshift = $rshift_count$$constant &amp; 63;
11846     int s = 63 - lshift;
11847     int r = (rshift - lshift) &amp; 63;
11848     __ sbfm(as_Register($dst$$reg),
11849             as_Register($src$$reg),
11850             r, s);
11851   %}
11852 
11853   ins_pipe(ialu_reg_shift);
11854 %}
11855 
11856 // Shift Left followed by Shift Right.
11857 // This idiom is used by the compiler for the i2b bytecode etc.
11858 instruct sbfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11859 %{
11860   match(Set dst (RShiftI (LShiftI src lshift_count) rshift_count));
11861   ins_cost(INSN_COST * 2);
11862   format %{ &quot;sbfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
11863   ins_encode %{
11864     int lshift = $lshift_count$$constant &amp; 31;
11865     int rshift = $rshift_count$$constant &amp; 31;
11866     int s = 31 - lshift;
11867     int r = (rshift - lshift) &amp; 31;
11868     __ sbfmw(as_Register($dst$$reg),
11869             as_Register($src$$reg),
11870             r, s);
11871   %}
11872 
11873   ins_pipe(ialu_reg_shift);
11874 %}
11875 
11876 // Shift Left followed by Shift Right.
11877 // This idiom is used by the compiler for the i2b bytecode etc.
11878 instruct ubfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11879 %{
11880   match(Set dst (URShiftL (LShiftL src lshift_count) rshift_count));
11881   ins_cost(INSN_COST * 2);
11882   format %{ &quot;ubfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11883   ins_encode %{
11884     int lshift = $lshift_count$$constant &amp; 63;
11885     int rshift = $rshift_count$$constant &amp; 63;
11886     int s = 63 - lshift;
11887     int r = (rshift - lshift) &amp; 63;
11888     __ ubfm(as_Register($dst$$reg),
11889             as_Register($src$$reg),
11890             r, s);
11891   %}
11892 
11893   ins_pipe(ialu_reg_shift);
11894 %}
11895 
11896 // Shift Left followed by Shift Right.
11897 // This idiom is used by the compiler for the i2b bytecode etc.
11898 instruct ubfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11899 %{
11900   match(Set dst (URShiftI (LShiftI src lshift_count) rshift_count));
11901   ins_cost(INSN_COST * 2);
11902   format %{ &quot;ubfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
11903   ins_encode %{
11904     int lshift = $lshift_count$$constant &amp; 31;
11905     int rshift = $rshift_count$$constant &amp; 31;
11906     int s = 31 - lshift;
11907     int r = (rshift - lshift) &amp; 31;
11908     __ ubfmw(as_Register($dst$$reg),
11909             as_Register($src$$reg),
11910             r, s);
11911   %}
11912 
11913   ins_pipe(ialu_reg_shift);
11914 %}
11915 // Bitfield extract with shift &amp; mask
11916 
11917 instruct ubfxwI(iRegINoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
11918 %{
11919   match(Set dst (AndI (URShiftI src rshift) mask));
11920   // Make sure we are not going to exceed what ubfxw can do.
11921   predicate((exact_log2(n-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
11922 
11923   ins_cost(INSN_COST);
11924   format %{ &quot;ubfxw $dst, $src, $rshift, $mask&quot; %}
11925   ins_encode %{
11926     int rshift = $rshift$$constant &amp; 31;
11927     long mask = $mask$$constant;
11928     int width = exact_log2(mask+1);
11929     __ ubfxw(as_Register($dst$$reg),
11930             as_Register($src$$reg), rshift, width);
11931   %}
11932   ins_pipe(ialu_reg_shift);
11933 %}
11934 instruct ubfxL(iRegLNoSp dst, iRegL src, immI rshift, immL_bitmask mask)
11935 %{
11936   match(Set dst (AndL (URShiftL src rshift) mask));
11937   // Make sure we are not going to exceed what ubfx can do.
11938   predicate((exact_log2_long(n-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
11939 
11940   ins_cost(INSN_COST);
11941   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
11942   ins_encode %{
11943     int rshift = $rshift$$constant &amp; 63;
11944     long mask = $mask$$constant;
11945     int width = exact_log2_long(mask+1);
11946     __ ubfx(as_Register($dst$$reg),
11947             as_Register($src$$reg), rshift, width);
11948   %}
11949   ins_pipe(ialu_reg_shift);
11950 %}
11951 
11952 // We can use ubfx when extending an And with a mask when we know mask
11953 // is positive.  We know that because immI_bitmask guarantees it.
11954 instruct ubfxIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
11955 %{
11956   match(Set dst (ConvI2L (AndI (URShiftI src rshift) mask)));
11957   // Make sure we are not going to exceed what ubfxw can do.
11958   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
11959 
11960   ins_cost(INSN_COST * 2);
11961   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
11962   ins_encode %{
11963     int rshift = $rshift$$constant &amp; 31;
11964     long mask = $mask$$constant;
11965     int width = exact_log2(mask+1);
11966     __ ubfx(as_Register($dst$$reg),
11967             as_Register($src$$reg), rshift, width);
11968   %}
11969   ins_pipe(ialu_reg_shift);
11970 %}
11971 
11972 // We can use ubfiz when masking by a positive number and then left shifting the result.
11973 // We know that the mask is positive because immI_bitmask guarantees it.
11974 instruct ubfizwI(iRegINoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
11975 %{
11976   match(Set dst (LShiftI (AndI src mask) lshift));
11977   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
11978 
11979   ins_cost(INSN_COST);
11980   format %{ &quot;ubfizw $dst, $src, $lshift, $mask&quot; %}
11981   ins_encode %{
11982     int lshift = $lshift$$constant &amp; 31;
11983     long mask = $mask$$constant;
11984     int width = exact_log2(mask+1);
11985     __ ubfizw(as_Register($dst$$reg),
11986           as_Register($src$$reg), lshift, width);
11987   %}
11988   ins_pipe(ialu_reg_shift);
11989 %}
11990 // We can use ubfiz when masking by a positive number and then left shifting the result.
11991 // We know that the mask is positive because immL_bitmask guarantees it.
11992 instruct ubfizL(iRegLNoSp dst, iRegL src, immI lshift, immL_bitmask mask)
11993 %{
11994   match(Set dst (LShiftL (AndL src mask) lshift));
11995   predicate((exact_log2_long(n-&gt;in(1)-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
11996 
11997   ins_cost(INSN_COST);
11998   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
11999   ins_encode %{
12000     int lshift = $lshift$$constant &amp; 63;
12001     long mask = $mask$$constant;
12002     int width = exact_log2_long(mask+1);
12003     __ ubfiz(as_Register($dst$$reg),
12004           as_Register($src$$reg), lshift, width);
12005   %}
12006   ins_pipe(ialu_reg_shift);
12007 %}
12008 
12009 // If there is a convert I to L block between and AndI and a LShiftL, we can also match ubfiz
12010 instruct ubfizIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12011 %{
12012   match(Set dst (LShiftL (ConvI2L (AndI src mask)) lshift));
12013   predicate((exact_log2(n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12014 
12015   ins_cost(INSN_COST);
12016   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12017   ins_encode %{
12018     int lshift = $lshift$$constant &amp; 63;
12019     long mask = $mask$$constant;
12020     int width = exact_log2(mask+1);
12021     __ ubfiz(as_Register($dst$$reg),
12022              as_Register($src$$reg), lshift, width);
12023   %}
12024   ins_pipe(ialu_reg_shift);
12025 %}
12026 
12027 // Rotations
12028 
12029 instruct extrOrL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12030 %{
12031   match(Set dst (OrL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12032   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12033 
12034   ins_cost(INSN_COST);
12035   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12036 
12037   ins_encode %{
12038     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12039             $rshift$$constant &amp; 63);
12040   %}
12041   ins_pipe(ialu_reg_reg_extr);
12042 %}
12043 
12044 instruct extrOrI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12045 %{
12046   match(Set dst (OrI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12047   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12048 
12049   ins_cost(INSN_COST);
12050   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12051 
12052   ins_encode %{
12053     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12054             $rshift$$constant &amp; 31);
12055   %}
12056   ins_pipe(ialu_reg_reg_extr);
12057 %}
12058 
12059 instruct extrAddL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12060 %{
12061   match(Set dst (AddL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12062   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12063 
12064   ins_cost(INSN_COST);
12065   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12066 
12067   ins_encode %{
12068     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12069             $rshift$$constant &amp; 63);
12070   %}
12071   ins_pipe(ialu_reg_reg_extr);
12072 %}
12073 
12074 instruct extrAddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12075 %{
12076   match(Set dst (AddI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12077   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12078 
12079   ins_cost(INSN_COST);
12080   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12081 
12082   ins_encode %{
12083     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12084             $rshift$$constant &amp; 31);
12085   %}
12086   ins_pipe(ialu_reg_reg_extr);
12087 %}
12088 
12089 
12090 // rol expander
12091 
12092 instruct rolL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12093 %{
12094   effect(DEF dst, USE src, USE shift);
12095 
12096   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12097   ins_cost(INSN_COST * 3);
12098   ins_encode %{
12099     __ subw(rscratch1, zr, as_Register($shift$$reg));
12100     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12101             rscratch1);
12102     %}
12103   ins_pipe(ialu_reg_reg_vshift);
12104 %}
12105 
12106 // rol expander
12107 
12108 instruct rolI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12109 %{
12110   effect(DEF dst, USE src, USE shift);
12111 
12112   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12113   ins_cost(INSN_COST * 3);
12114   ins_encode %{
12115     __ subw(rscratch1, zr, as_Register($shift$$reg));
12116     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12117             rscratch1);
12118     %}
12119   ins_pipe(ialu_reg_reg_vshift);
12120 %}
12121 
12122 instruct rolL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12123 %{
12124   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c_64 shift))));
12125 
12126   expand %{
12127     rolL_rReg(dst, src, shift, cr);
12128   %}
12129 %}
12130 
12131 instruct rolL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12132 %{
12133   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c0 shift))));
12134 
12135   expand %{
12136     rolL_rReg(dst, src, shift, cr);
12137   %}
12138 %}
12139 
12140 instruct rolI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12141 %{
12142   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c_32 shift))));
12143 
12144   expand %{
12145     rolI_rReg(dst, src, shift, cr);
12146   %}
12147 %}
12148 
12149 instruct rolI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12150 %{
12151   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c0 shift))));
12152 
12153   expand %{
12154     rolI_rReg(dst, src, shift, cr);
12155   %}
12156 %}
12157 
12158 // ror expander
12159 
12160 instruct rorL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12161 %{
12162   effect(DEF dst, USE src, USE shift);
12163 
12164   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12165   ins_cost(INSN_COST);
12166   ins_encode %{
12167     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12168             as_Register($shift$$reg));
12169     %}
12170   ins_pipe(ialu_reg_reg_vshift);
12171 %}
12172 
12173 // ror expander
12174 
12175 instruct rorI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12176 %{
12177   effect(DEF dst, USE src, USE shift);
12178 
12179   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12180   ins_cost(INSN_COST);
12181   ins_encode %{
12182     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12183             as_Register($shift$$reg));
12184     %}
12185   ins_pipe(ialu_reg_reg_vshift);
12186 %}
12187 
12188 instruct rorL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12189 %{
12190   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c_64 shift))));
12191 
12192   expand %{
12193     rorL_rReg(dst, src, shift, cr);
12194   %}
12195 %}
12196 
12197 instruct rorL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12198 %{
12199   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c0 shift))));
12200 
12201   expand %{
12202     rorL_rReg(dst, src, shift, cr);
12203   %}
12204 %}
12205 
12206 instruct rorI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12207 %{
12208   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c_32 shift))));
12209 
12210   expand %{
12211     rorI_rReg(dst, src, shift, cr);
12212   %}
12213 %}
12214 
12215 instruct rorI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12216 %{
12217   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c0 shift))));
12218 
12219   expand %{
12220     rorI_rReg(dst, src, shift, cr);
12221   %}
12222 %}
12223 
12224 // Add/subtract (extended)
12225 
12226 instruct AddExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12227 %{
12228   match(Set dst (AddL src1 (ConvI2L src2)));
12229   ins_cost(INSN_COST);
12230   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12231 
12232    ins_encode %{
12233      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12234             as_Register($src2$$reg), ext::sxtw);
12235    %}
12236   ins_pipe(ialu_reg_reg);
12237 %};
12238 
12239 instruct SubExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12240 %{
12241   match(Set dst (SubL src1 (ConvI2L src2)));
12242   ins_cost(INSN_COST);
12243   format %{ &quot;sub  $dst, $src1, $src2, sxtw&quot; %}
12244 
12245    ins_encode %{
12246      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12247             as_Register($src2$$reg), ext::sxtw);
12248    %}
12249   ins_pipe(ialu_reg_reg);
12250 %};
12251 
12252 
12253 instruct AddExtI_sxth(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_16 lshift, immI_16 rshift, rFlagsReg cr)
12254 %{
12255   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12256   ins_cost(INSN_COST);
12257   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12258 
12259    ins_encode %{
12260      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12261             as_Register($src2$$reg), ext::sxth);
12262    %}
12263   ins_pipe(ialu_reg_reg);
12264 %}
12265 
12266 instruct AddExtI_sxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12267 %{
12268   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12269   ins_cost(INSN_COST);
12270   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12271 
12272    ins_encode %{
12273      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12274             as_Register($src2$$reg), ext::sxtb);
12275    %}
12276   ins_pipe(ialu_reg_reg);
12277 %}
12278 
12279 instruct AddExtI_uxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12280 %{
12281   match(Set dst (AddI src1 (URShiftI (LShiftI src2 lshift) rshift)));
12282   ins_cost(INSN_COST);
12283   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12284 
12285    ins_encode %{
12286      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12287             as_Register($src2$$reg), ext::uxtb);
12288    %}
12289   ins_pipe(ialu_reg_reg);
12290 %}
12291 
12292 instruct AddExtL_sxth(iRegLNoSp dst, iRegL src1, iRegL src2, immI_48 lshift, immI_48 rshift, rFlagsReg cr)
12293 %{
12294   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12295   ins_cost(INSN_COST);
12296   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12297 
12298    ins_encode %{
12299      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12300             as_Register($src2$$reg), ext::sxth);
12301    %}
12302   ins_pipe(ialu_reg_reg);
12303 %}
12304 
12305 instruct AddExtL_sxtw(iRegLNoSp dst, iRegL src1, iRegL src2, immI_32 lshift, immI_32 rshift, rFlagsReg cr)
12306 %{
12307   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12308   ins_cost(INSN_COST);
12309   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12310 
12311    ins_encode %{
12312      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12313             as_Register($src2$$reg), ext::sxtw);
12314    %}
12315   ins_pipe(ialu_reg_reg);
12316 %}
12317 
12318 instruct AddExtL_sxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12319 %{
12320   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12321   ins_cost(INSN_COST);
12322   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12323 
12324    ins_encode %{
12325      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12326             as_Register($src2$$reg), ext::sxtb);
12327    %}
12328   ins_pipe(ialu_reg_reg);
12329 %}
12330 
12331 instruct AddExtL_uxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12332 %{
12333   match(Set dst (AddL src1 (URShiftL (LShiftL src2 lshift) rshift)));
12334   ins_cost(INSN_COST);
12335   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12336 
12337    ins_encode %{
12338      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12339             as_Register($src2$$reg), ext::uxtb);
12340    %}
12341   ins_pipe(ialu_reg_reg);
12342 %}
12343 
12344 
12345 instruct AddExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12346 %{
12347   match(Set dst (AddI src1 (AndI src2 mask)));
12348   ins_cost(INSN_COST);
12349   format %{ &quot;addw  $dst, $src1, $src2, uxtb&quot; %}
12350 
12351    ins_encode %{
12352      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12353             as_Register($src2$$reg), ext::uxtb);
12354    %}
12355   ins_pipe(ialu_reg_reg);
12356 %}
12357 
12358 instruct AddExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12359 %{
12360   match(Set dst (AddI src1 (AndI src2 mask)));
12361   ins_cost(INSN_COST);
12362   format %{ &quot;addw  $dst, $src1, $src2, uxth&quot; %}
12363 
12364    ins_encode %{
12365      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12366             as_Register($src2$$reg), ext::uxth);
12367    %}
12368   ins_pipe(ialu_reg_reg);
12369 %}
12370 
12371 instruct AddExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12372 %{
12373   match(Set dst (AddL src1 (AndL src2 mask)));
12374   ins_cost(INSN_COST);
12375   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12376 
12377    ins_encode %{
12378      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12379             as_Register($src2$$reg), ext::uxtb);
12380    %}
12381   ins_pipe(ialu_reg_reg);
12382 %}
12383 
12384 instruct AddExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12385 %{
12386   match(Set dst (AddL src1 (AndL src2 mask)));
12387   ins_cost(INSN_COST);
12388   format %{ &quot;add  $dst, $src1, $src2, uxth&quot; %}
12389 
12390    ins_encode %{
12391      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12392             as_Register($src2$$reg), ext::uxth);
12393    %}
12394   ins_pipe(ialu_reg_reg);
12395 %}
12396 
12397 instruct AddExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12398 %{
12399   match(Set dst (AddL src1 (AndL src2 mask)));
12400   ins_cost(INSN_COST);
12401   format %{ &quot;add  $dst, $src1, $src2, uxtw&quot; %}
12402 
12403    ins_encode %{
12404      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12405             as_Register($src2$$reg), ext::uxtw);
12406    %}
12407   ins_pipe(ialu_reg_reg);
12408 %}
12409 
12410 instruct SubExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12411 %{
12412   match(Set dst (SubI src1 (AndI src2 mask)));
12413   ins_cost(INSN_COST);
12414   format %{ &quot;subw  $dst, $src1, $src2, uxtb&quot; %}
12415 
12416    ins_encode %{
12417      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12418             as_Register($src2$$reg), ext::uxtb);
12419    %}
12420   ins_pipe(ialu_reg_reg);
12421 %}
12422 
12423 instruct SubExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12424 %{
12425   match(Set dst (SubI src1 (AndI src2 mask)));
12426   ins_cost(INSN_COST);
12427   format %{ &quot;subw  $dst, $src1, $src2, uxth&quot; %}
12428 
12429    ins_encode %{
12430      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12431             as_Register($src2$$reg), ext::uxth);
12432    %}
12433   ins_pipe(ialu_reg_reg);
12434 %}
12435 
12436 instruct SubExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12437 %{
12438   match(Set dst (SubL src1 (AndL src2 mask)));
12439   ins_cost(INSN_COST);
12440   format %{ &quot;sub  $dst, $src1, $src2, uxtb&quot; %}
12441 
12442    ins_encode %{
12443      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12444             as_Register($src2$$reg), ext::uxtb);
12445    %}
12446   ins_pipe(ialu_reg_reg);
12447 %}
12448 
12449 instruct SubExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12450 %{
12451   match(Set dst (SubL src1 (AndL src2 mask)));
12452   ins_cost(INSN_COST);
12453   format %{ &quot;sub  $dst, $src1, $src2, uxth&quot; %}
12454 
12455    ins_encode %{
12456      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12457             as_Register($src2$$reg), ext::uxth);
12458    %}
12459   ins_pipe(ialu_reg_reg);
12460 %}
12461 
12462 instruct SubExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12463 %{
12464   match(Set dst (SubL src1 (AndL src2 mask)));
12465   ins_cost(INSN_COST);
12466   format %{ &quot;sub  $dst, $src1, $src2, uxtw&quot; %}
12467 
12468    ins_encode %{
12469      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12470             as_Register($src2$$reg), ext::uxtw);
12471    %}
12472   ins_pipe(ialu_reg_reg);
12473 %}
12474 
12475 
12476 instruct AddExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12477 %{
12478   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12479   ins_cost(1.9 * INSN_COST);
12480   format %{ &quot;add  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12481 
12482    ins_encode %{
12483      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12484             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12485    %}
12486   ins_pipe(ialu_reg_reg_shift);
12487 %}
12488 
12489 instruct AddExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12490 %{
12491   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12492   ins_cost(1.9 * INSN_COST);
12493   format %{ &quot;add  $dst, $src1, $src2, sxth #lshift2&quot; %}
12494 
12495    ins_encode %{
12496      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12497             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12498    %}
12499   ins_pipe(ialu_reg_reg_shift);
12500 %}
12501 
12502 instruct AddExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12503 %{
12504   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12505   ins_cost(1.9 * INSN_COST);
12506   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12507 
12508    ins_encode %{
12509      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12510             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12511    %}
12512   ins_pipe(ialu_reg_reg_shift);
12513 %}
12514 
12515 instruct SubExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12516 %{
12517   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12518   ins_cost(1.9 * INSN_COST);
12519   format %{ &quot;sub  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12520 
12521    ins_encode %{
12522      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12523             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12524    %}
12525   ins_pipe(ialu_reg_reg_shift);
12526 %}
12527 
12528 instruct SubExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12529 %{
12530   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12531   ins_cost(1.9 * INSN_COST);
12532   format %{ &quot;sub  $dst, $src1, $src2, sxth #lshift2&quot; %}
12533 
12534    ins_encode %{
12535      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12536             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12537    %}
12538   ins_pipe(ialu_reg_reg_shift);
12539 %}
12540 
12541 instruct SubExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12542 %{
12543   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12544   ins_cost(1.9 * INSN_COST);
12545   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12546 
12547    ins_encode %{
12548      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12549             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12550    %}
12551   ins_pipe(ialu_reg_reg_shift);
12552 %}
12553 
12554 instruct AddExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12555 %{
12556   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12557   ins_cost(1.9 * INSN_COST);
12558   format %{ &quot;addw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12559 
12560    ins_encode %{
12561      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12562             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12563    %}
12564   ins_pipe(ialu_reg_reg_shift);
12565 %}
12566 
12567 instruct AddExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12568 %{
12569   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12570   ins_cost(1.9 * INSN_COST);
12571   format %{ &quot;addw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12572 
12573    ins_encode %{
12574      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12575             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12576    %}
12577   ins_pipe(ialu_reg_reg_shift);
12578 %}
12579 
12580 instruct SubExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12581 %{
12582   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12583   ins_cost(1.9 * INSN_COST);
12584   format %{ &quot;subw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12585 
12586    ins_encode %{
12587      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12588             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12589    %}
12590   ins_pipe(ialu_reg_reg_shift);
12591 %}
12592 
12593 instruct SubExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12594 %{
12595   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12596   ins_cost(1.9 * INSN_COST);
12597   format %{ &quot;subw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12598 
12599    ins_encode %{
12600      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12601             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12602    %}
12603   ins_pipe(ialu_reg_reg_shift);
12604 %}
12605 
12606 
12607 instruct AddExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12608 %{
12609   match(Set dst (AddL src1 (LShiftL (ConvI2L src2) lshift)));
12610   ins_cost(1.9 * INSN_COST);
12611   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift&quot; %}
12612 
12613    ins_encode %{
12614      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12615             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12616    %}
12617   ins_pipe(ialu_reg_reg_shift);
12618 %};
12619 
12620 instruct SubExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12621 %{
12622   match(Set dst (SubL src1 (LShiftL (ConvI2L src2) lshift)));
12623   ins_cost(1.9 * INSN_COST);
12624   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift&quot; %}
12625 
12626    ins_encode %{
12627      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12628             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12629    %}
12630   ins_pipe(ialu_reg_reg_shift);
12631 %};
12632 
12633 
12634 instruct AddExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12635 %{
12636   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12637   ins_cost(1.9 * INSN_COST);
12638   format %{ &quot;add  $dst, $src1, $src2, uxtb #lshift&quot; %}
12639 
12640    ins_encode %{
12641      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12642             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12643    %}
12644   ins_pipe(ialu_reg_reg_shift);
12645 %}
12646 
12647 instruct AddExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12648 %{
12649   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12650   ins_cost(1.9 * INSN_COST);
12651   format %{ &quot;add  $dst, $src1, $src2, uxth #lshift&quot; %}
12652 
12653    ins_encode %{
12654      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12655             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12656    %}
12657   ins_pipe(ialu_reg_reg_shift);
12658 %}
12659 
12660 instruct AddExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12661 %{
12662   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12663   ins_cost(1.9 * INSN_COST);
12664   format %{ &quot;add  $dst, $src1, $src2, uxtw #lshift&quot; %}
12665 
12666    ins_encode %{
12667      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12668             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12669    %}
12670   ins_pipe(ialu_reg_reg_shift);
12671 %}
12672 
12673 instruct SubExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12674 %{
12675   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12676   ins_cost(1.9 * INSN_COST);
12677   format %{ &quot;sub  $dst, $src1, $src2, uxtb #lshift&quot; %}
12678 
12679    ins_encode %{
12680      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12681             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12682    %}
12683   ins_pipe(ialu_reg_reg_shift);
12684 %}
12685 
12686 instruct SubExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12687 %{
12688   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12689   ins_cost(1.9 * INSN_COST);
12690   format %{ &quot;sub  $dst, $src1, $src2, uxth #lshift&quot; %}
12691 
12692    ins_encode %{
12693      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12694             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12695    %}
12696   ins_pipe(ialu_reg_reg_shift);
12697 %}
12698 
12699 instruct SubExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12700 %{
12701   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12702   ins_cost(1.9 * INSN_COST);
12703   format %{ &quot;sub  $dst, $src1, $src2, uxtw #lshift&quot; %}
12704 
12705    ins_encode %{
12706      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12707             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12708    %}
12709   ins_pipe(ialu_reg_reg_shift);
12710 %}
12711 
12712 instruct AddExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12713 %{
12714   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12715   ins_cost(1.9 * INSN_COST);
12716   format %{ &quot;addw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12717 
12718    ins_encode %{
12719      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12720             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12721    %}
12722   ins_pipe(ialu_reg_reg_shift);
12723 %}
12724 
12725 instruct AddExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12726 %{
12727   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12728   ins_cost(1.9 * INSN_COST);
12729   format %{ &quot;addw  $dst, $src1, $src2, uxth #lshift&quot; %}
12730 
12731    ins_encode %{
12732      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12733             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12734    %}
12735   ins_pipe(ialu_reg_reg_shift);
12736 %}
12737 
12738 instruct SubExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12739 %{
12740   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12741   ins_cost(1.9 * INSN_COST);
12742   format %{ &quot;subw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12743 
12744    ins_encode %{
12745      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12746             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12747    %}
12748   ins_pipe(ialu_reg_reg_shift);
12749 %}
12750 
12751 instruct SubExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12752 %{
12753   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12754   ins_cost(1.9 * INSN_COST);
12755   format %{ &quot;subw  $dst, $src1, $src2, uxth #lshift&quot; %}
12756 
12757    ins_encode %{
12758      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12759             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12760    %}
12761   ins_pipe(ialu_reg_reg_shift);
12762 %}
12763 // END This section of the file is automatically generated. Do not edit --------------
12764 
12765 // ============================================================================
12766 // Floating Point Arithmetic Instructions
12767 
12768 instruct addF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12769   match(Set dst (AddF src1 src2));
12770 
12771   ins_cost(INSN_COST * 5);
12772   format %{ &quot;fadds   $dst, $src1, $src2&quot; %}
12773 
12774   ins_encode %{
12775     __ fadds(as_FloatRegister($dst$$reg),
12776              as_FloatRegister($src1$$reg),
12777              as_FloatRegister($src2$$reg));
12778   %}
12779 
12780   ins_pipe(fp_dop_reg_reg_s);
12781 %}
12782 
12783 instruct addD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12784   match(Set dst (AddD src1 src2));
12785 
12786   ins_cost(INSN_COST * 5);
12787   format %{ &quot;faddd   $dst, $src1, $src2&quot; %}
12788 
12789   ins_encode %{
12790     __ faddd(as_FloatRegister($dst$$reg),
12791              as_FloatRegister($src1$$reg),
12792              as_FloatRegister($src2$$reg));
12793   %}
12794 
12795   ins_pipe(fp_dop_reg_reg_d);
12796 %}
12797 
12798 instruct subF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12799   match(Set dst (SubF src1 src2));
12800 
12801   ins_cost(INSN_COST * 5);
12802   format %{ &quot;fsubs   $dst, $src1, $src2&quot; %}
12803 
12804   ins_encode %{
12805     __ fsubs(as_FloatRegister($dst$$reg),
12806              as_FloatRegister($src1$$reg),
12807              as_FloatRegister($src2$$reg));
12808   %}
12809 
12810   ins_pipe(fp_dop_reg_reg_s);
12811 %}
12812 
12813 instruct subD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12814   match(Set dst (SubD src1 src2));
12815 
12816   ins_cost(INSN_COST * 5);
12817   format %{ &quot;fsubd   $dst, $src1, $src2&quot; %}
12818 
12819   ins_encode %{
12820     __ fsubd(as_FloatRegister($dst$$reg),
12821              as_FloatRegister($src1$$reg),
12822              as_FloatRegister($src2$$reg));
12823   %}
12824 
12825   ins_pipe(fp_dop_reg_reg_d);
12826 %}
12827 
12828 instruct mulF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12829   match(Set dst (MulF src1 src2));
12830 
12831   ins_cost(INSN_COST * 6);
12832   format %{ &quot;fmuls   $dst, $src1, $src2&quot; %}
12833 
12834   ins_encode %{
12835     __ fmuls(as_FloatRegister($dst$$reg),
12836              as_FloatRegister($src1$$reg),
12837              as_FloatRegister($src2$$reg));
12838   %}
12839 
12840   ins_pipe(fp_dop_reg_reg_s);
12841 %}
12842 
12843 instruct mulD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12844   match(Set dst (MulD src1 src2));
12845 
12846   ins_cost(INSN_COST * 6);
12847   format %{ &quot;fmuld   $dst, $src1, $src2&quot; %}
12848 
12849   ins_encode %{
12850     __ fmuld(as_FloatRegister($dst$$reg),
12851              as_FloatRegister($src1$$reg),
12852              as_FloatRegister($src2$$reg));
12853   %}
12854 
12855   ins_pipe(fp_dop_reg_reg_d);
12856 %}
12857 
12858 // src1 * src2 + src3
12859 instruct maddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12860   predicate(UseFMA);
12861   match(Set dst (FmaF src3 (Binary src1 src2)));
12862 
12863   format %{ &quot;fmadds   $dst, $src1, $src2, $src3&quot; %}
12864 
12865   ins_encode %{
12866     __ fmadds(as_FloatRegister($dst$$reg),
12867              as_FloatRegister($src1$$reg),
12868              as_FloatRegister($src2$$reg),
12869              as_FloatRegister($src3$$reg));
12870   %}
12871 
12872   ins_pipe(pipe_class_default);
12873 %}
12874 
12875 // src1 * src2 + src3
12876 instruct maddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
12877   predicate(UseFMA);
12878   match(Set dst (FmaD src3 (Binary src1 src2)));
12879 
12880   format %{ &quot;fmaddd   $dst, $src1, $src2, $src3&quot; %}
12881 
12882   ins_encode %{
12883     __ fmaddd(as_FloatRegister($dst$$reg),
12884              as_FloatRegister($src1$$reg),
12885              as_FloatRegister($src2$$reg),
12886              as_FloatRegister($src3$$reg));
12887   %}
12888 
12889   ins_pipe(pipe_class_default);
12890 %}
12891 
12892 // -src1 * src2 + src3
12893 instruct msubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12894   predicate(UseFMA);
12895   match(Set dst (FmaF src3 (Binary (NegF src1) src2)));
12896   match(Set dst (FmaF src3 (Binary src1 (NegF src2))));
12897 
12898   format %{ &quot;fmsubs   $dst, $src1, $src2, $src3&quot; %}
12899 
12900   ins_encode %{
12901     __ fmsubs(as_FloatRegister($dst$$reg),
12902               as_FloatRegister($src1$$reg),
12903               as_FloatRegister($src2$$reg),
12904               as_FloatRegister($src3$$reg));
12905   %}
12906 
12907   ins_pipe(pipe_class_default);
12908 %}
12909 
12910 // -src1 * src2 + src3
12911 instruct msubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
12912   predicate(UseFMA);
12913   match(Set dst (FmaD src3 (Binary (NegD src1) src2)));
12914   match(Set dst (FmaD src3 (Binary src1 (NegD src2))));
12915 
12916   format %{ &quot;fmsubd   $dst, $src1, $src2, $src3&quot; %}
12917 
12918   ins_encode %{
12919     __ fmsubd(as_FloatRegister($dst$$reg),
12920               as_FloatRegister($src1$$reg),
12921               as_FloatRegister($src2$$reg),
12922               as_FloatRegister($src3$$reg));
12923   %}
12924 
12925   ins_pipe(pipe_class_default);
12926 %}
12927 
12928 // -src1 * src2 - src3
12929 instruct mnaddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12930   predicate(UseFMA);
12931   match(Set dst (FmaF (NegF src3) (Binary (NegF src1) src2)));
12932   match(Set dst (FmaF (NegF src3) (Binary src1 (NegF src2))));
12933 
12934   format %{ &quot;fnmadds  $dst, $src1, $src2, $src3&quot; %}
12935 
12936   ins_encode %{
12937     __ fnmadds(as_FloatRegister($dst$$reg),
12938                as_FloatRegister($src1$$reg),
12939                as_FloatRegister($src2$$reg),
12940                as_FloatRegister($src3$$reg));
12941   %}
12942 
12943   ins_pipe(pipe_class_default);
12944 %}
12945 
12946 // -src1 * src2 - src3
12947 instruct mnaddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
12948   predicate(UseFMA);
12949   match(Set dst (FmaD (NegD src3) (Binary (NegD src1) src2)));
12950   match(Set dst (FmaD (NegD src3) (Binary src1 (NegD src2))));
12951 
12952   format %{ &quot;fnmaddd   $dst, $src1, $src2, $src3&quot; %}
12953 
12954   ins_encode %{
12955     __ fnmaddd(as_FloatRegister($dst$$reg),
12956                as_FloatRegister($src1$$reg),
12957                as_FloatRegister($src2$$reg),
12958                as_FloatRegister($src3$$reg));
12959   %}
12960 
12961   ins_pipe(pipe_class_default);
12962 %}
12963 
12964 // src1 * src2 - src3
12965 instruct mnsubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3, immF0 zero) %{
12966   predicate(UseFMA);
12967   match(Set dst (FmaF (NegF src3) (Binary src1 src2)));
12968 
12969   format %{ &quot;fnmsubs  $dst, $src1, $src2, $src3&quot; %}
12970 
12971   ins_encode %{
12972     __ fnmsubs(as_FloatRegister($dst$$reg),
12973                as_FloatRegister($src1$$reg),
12974                as_FloatRegister($src2$$reg),
12975                as_FloatRegister($src3$$reg));
12976   %}
12977 
12978   ins_pipe(pipe_class_default);
12979 %}
12980 
12981 // src1 * src2 - src3
12982 instruct mnsubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3, immD0 zero) %{
12983   predicate(UseFMA);
12984   match(Set dst (FmaD (NegD src3) (Binary src1 src2)));
12985 
12986   format %{ &quot;fnmsubd   $dst, $src1, $src2, $src3&quot; %}
12987 
12988   ins_encode %{
12989   // n.b. insn name should be fnmsubd
12990     __ fnmsub(as_FloatRegister($dst$$reg),
12991               as_FloatRegister($src1$$reg),
12992               as_FloatRegister($src2$$reg),
12993               as_FloatRegister($src3$$reg));
12994   %}
12995 
12996   ins_pipe(pipe_class_default);
12997 %}
12998 
12999 
13000 // Math.max(FF)F
13001 instruct maxF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13002   match(Set dst (MaxF src1 src2));
13003 
13004   format %{ &quot;fmaxs   $dst, $src1, $src2&quot; %}
13005   ins_encode %{
13006     __ fmaxs(as_FloatRegister($dst$$reg),
13007              as_FloatRegister($src1$$reg),
13008              as_FloatRegister($src2$$reg));
13009   %}
13010 
13011   ins_pipe(fp_dop_reg_reg_s);
13012 %}
13013 
13014 // Math.min(FF)F
13015 instruct minF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13016   match(Set dst (MinF src1 src2));
13017 
13018   format %{ &quot;fmins   $dst, $src1, $src2&quot; %}
13019   ins_encode %{
13020     __ fmins(as_FloatRegister($dst$$reg),
13021              as_FloatRegister($src1$$reg),
13022              as_FloatRegister($src2$$reg));
13023   %}
13024 
13025   ins_pipe(fp_dop_reg_reg_s);
13026 %}
13027 
13028 // Math.max(DD)D
13029 instruct maxD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13030   match(Set dst (MaxD src1 src2));
13031 
13032   format %{ &quot;fmaxd   $dst, $src1, $src2&quot; %}
13033   ins_encode %{
13034     __ fmaxd(as_FloatRegister($dst$$reg),
13035              as_FloatRegister($src1$$reg),
13036              as_FloatRegister($src2$$reg));
13037   %}
13038 
13039   ins_pipe(fp_dop_reg_reg_d);
13040 %}
13041 
13042 // Math.min(DD)D
13043 instruct minD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13044   match(Set dst (MinD src1 src2));
13045 
13046   format %{ &quot;fmind   $dst, $src1, $src2&quot; %}
13047   ins_encode %{
13048     __ fmind(as_FloatRegister($dst$$reg),
13049              as_FloatRegister($src1$$reg),
13050              as_FloatRegister($src2$$reg));
13051   %}
13052 
13053   ins_pipe(fp_dop_reg_reg_d);
13054 %}
13055 
13056 
13057 instruct divF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13058   match(Set dst (DivF src1  src2));
13059 
13060   ins_cost(INSN_COST * 18);
13061   format %{ &quot;fdivs   $dst, $src1, $src2&quot; %}
13062 
13063   ins_encode %{
13064     __ fdivs(as_FloatRegister($dst$$reg),
13065              as_FloatRegister($src1$$reg),
13066              as_FloatRegister($src2$$reg));
13067   %}
13068 
13069   ins_pipe(fp_div_s);
13070 %}
13071 
13072 instruct divD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13073   match(Set dst (DivD src1  src2));
13074 
13075   ins_cost(INSN_COST * 32);
13076   format %{ &quot;fdivd   $dst, $src1, $src2&quot; %}
13077 
13078   ins_encode %{
13079     __ fdivd(as_FloatRegister($dst$$reg),
13080              as_FloatRegister($src1$$reg),
13081              as_FloatRegister($src2$$reg));
13082   %}
13083 
13084   ins_pipe(fp_div_d);
13085 %}
13086 
13087 instruct negF_reg_reg(vRegF dst, vRegF src) %{
13088   match(Set dst (NegF src));
13089 
13090   ins_cost(INSN_COST * 3);
13091   format %{ &quot;fneg   $dst, $src&quot; %}
13092 
13093   ins_encode %{
13094     __ fnegs(as_FloatRegister($dst$$reg),
13095              as_FloatRegister($src$$reg));
13096   %}
13097 
13098   ins_pipe(fp_uop_s);
13099 %}
13100 
13101 instruct negD_reg_reg(vRegD dst, vRegD src) %{
13102   match(Set dst (NegD src));
13103 
13104   ins_cost(INSN_COST * 3);
13105   format %{ &quot;fnegd   $dst, $src&quot; %}
13106 
13107   ins_encode %{
13108     __ fnegd(as_FloatRegister($dst$$reg),
13109              as_FloatRegister($src$$reg));
13110   %}
13111 
13112   ins_pipe(fp_uop_d);
13113 %}
13114 
13115 instruct absI_reg(iRegINoSp dst, iRegIorL2I src, rFlagsReg cr)
13116 %{
13117   match(Set dst (AbsI src));
13118 
13119   effect(KILL cr);
13120   ins_cost(INSN_COST * 2);
13121   format %{ &quot;cmpw  $src, zr\n\t&quot;
13122             &quot;cnegw $dst, $src, Assembler::LT\t# int abs&quot;
13123   %}
13124 
13125   ins_encode %{
13126     __ cmpw(as_Register($src$$reg), zr);
13127     __ cnegw(as_Register($dst$$reg), as_Register($src$$reg), Assembler::LT);
13128   %}
13129   ins_pipe(pipe_class_default);
13130 %}
13131 
13132 instruct absL_reg(iRegLNoSp dst, iRegL src, rFlagsReg cr)
13133 %{
13134   match(Set dst (AbsL src));
13135 
13136   effect(KILL cr);
13137   ins_cost(INSN_COST * 2);
13138   format %{ &quot;cmp  $src, zr\n\t&quot;
13139             &quot;cneg $dst, $src, Assembler::LT\t# long abs&quot;
13140   %}
13141 
13142   ins_encode %{
13143     __ cmp(as_Register($src$$reg), zr);
13144     __ cneg(as_Register($dst$$reg), as_Register($src$$reg), Assembler::LT);
13145   %}
13146   ins_pipe(pipe_class_default);
13147 %}
13148 
13149 instruct absF_reg(vRegF dst, vRegF src) %{
13150   match(Set dst (AbsF src));
13151 
13152   ins_cost(INSN_COST * 3);
13153   format %{ &quot;fabss   $dst, $src&quot; %}
13154   ins_encode %{
13155     __ fabss(as_FloatRegister($dst$$reg),
13156              as_FloatRegister($src$$reg));
13157   %}
13158 
13159   ins_pipe(fp_uop_s);
13160 %}
13161 
13162 instruct absD_reg(vRegD dst, vRegD src) %{
13163   match(Set dst (AbsD src));
13164 
13165   ins_cost(INSN_COST * 3);
13166   format %{ &quot;fabsd   $dst, $src&quot; %}
13167   ins_encode %{
13168     __ fabsd(as_FloatRegister($dst$$reg),
13169              as_FloatRegister($src$$reg));
13170   %}
13171 
13172   ins_pipe(fp_uop_d);
13173 %}
13174 
13175 instruct sqrtD_reg(vRegD dst, vRegD src) %{
13176   match(Set dst (SqrtD src));
13177 
13178   ins_cost(INSN_COST * 50);
13179   format %{ &quot;fsqrtd  $dst, $src&quot; %}
13180   ins_encode %{
13181     __ fsqrtd(as_FloatRegister($dst$$reg),
13182              as_FloatRegister($src$$reg));
13183   %}
13184 
13185   ins_pipe(fp_div_s);
13186 %}
13187 
13188 instruct sqrtF_reg(vRegF dst, vRegF src) %{
13189   match(Set dst (SqrtF src));
13190 
13191   ins_cost(INSN_COST * 50);
13192   format %{ &quot;fsqrts  $dst, $src&quot; %}
13193   ins_encode %{
13194     __ fsqrts(as_FloatRegister($dst$$reg),
13195              as_FloatRegister($src$$reg));
13196   %}
13197 
13198   ins_pipe(fp_div_d);
13199 %}
13200 
13201 // Math.rint, floor, ceil
13202 instruct roundD_reg(vRegD dst, vRegD src, immI rmode) %{
13203   match(Set dst (RoundDoubleMode src rmode));
13204   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
13205   ins_encode %{
13206     switch ($rmode$$constant) {
13207       case RoundDoubleModeNode::rmode_rint:
13208         __ frintnd(as_FloatRegister($dst$$reg),
13209                    as_FloatRegister($src$$reg));
13210         break;
13211       case RoundDoubleModeNode::rmode_floor:
13212         __ frintmd(as_FloatRegister($dst$$reg),
13213                    as_FloatRegister($src$$reg));
13214         break;
13215       case RoundDoubleModeNode::rmode_ceil:
13216         __ frintpd(as_FloatRegister($dst$$reg),
13217                    as_FloatRegister($src$$reg));
13218         break;
13219     }
13220   %}
13221   ins_pipe(fp_uop_d);
13222 %}
13223 
13224 // ============================================================================
13225 // Logical Instructions
13226 
13227 // Integer Logical Instructions
13228 
13229 // And Instructions
13230 
13231 
13232 instruct andI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, rFlagsReg cr) %{
13233   match(Set dst (AndI src1 src2));
13234 
13235   format %{ &quot;andw  $dst, $src1, $src2\t# int&quot; %}
13236 
13237   ins_cost(INSN_COST);
13238   ins_encode %{
13239     __ andw(as_Register($dst$$reg),
13240             as_Register($src1$$reg),
13241             as_Register($src2$$reg));
13242   %}
13243 
13244   ins_pipe(ialu_reg_reg);
13245 %}
13246 
13247 instruct andI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2, rFlagsReg cr) %{
13248   match(Set dst (AndI src1 src2));
13249 
13250   format %{ &quot;andsw  $dst, $src1, $src2\t# int&quot; %}
13251 
13252   ins_cost(INSN_COST);
13253   ins_encode %{
13254     __ andw(as_Register($dst$$reg),
13255             as_Register($src1$$reg),
13256             (unsigned long)($src2$$constant));
13257   %}
13258 
13259   ins_pipe(ialu_reg_imm);
13260 %}
13261 
13262 // Or Instructions
13263 
13264 instruct orI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13265   match(Set dst (OrI src1 src2));
13266 
13267   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13268 
13269   ins_cost(INSN_COST);
13270   ins_encode %{
13271     __ orrw(as_Register($dst$$reg),
13272             as_Register($src1$$reg),
13273             as_Register($src2$$reg));
13274   %}
13275 
13276   ins_pipe(ialu_reg_reg);
13277 %}
13278 
13279 instruct orI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13280   match(Set dst (OrI src1 src2));
13281 
13282   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13283 
13284   ins_cost(INSN_COST);
13285   ins_encode %{
13286     __ orrw(as_Register($dst$$reg),
13287             as_Register($src1$$reg),
13288             (unsigned long)($src2$$constant));
13289   %}
13290 
13291   ins_pipe(ialu_reg_imm);
13292 %}
13293 
13294 // Xor Instructions
13295 
13296 instruct xorI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13297   match(Set dst (XorI src1 src2));
13298 
13299   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13300 
13301   ins_cost(INSN_COST);
13302   ins_encode %{
13303     __ eorw(as_Register($dst$$reg),
13304             as_Register($src1$$reg),
13305             as_Register($src2$$reg));
13306   %}
13307 
13308   ins_pipe(ialu_reg_reg);
13309 %}
13310 
13311 instruct xorI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13312   match(Set dst (XorI src1 src2));
13313 
13314   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13315 
13316   ins_cost(INSN_COST);
13317   ins_encode %{
13318     __ eorw(as_Register($dst$$reg),
13319             as_Register($src1$$reg),
13320             (unsigned long)($src2$$constant));
13321   %}
13322 
13323   ins_pipe(ialu_reg_imm);
13324 %}
13325 
13326 // Long Logical Instructions
13327 // TODO
13328 
13329 instruct andL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr) %{
13330   match(Set dst (AndL src1 src2));
13331 
13332   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13333 
13334   ins_cost(INSN_COST);
13335   ins_encode %{
13336     __ andr(as_Register($dst$$reg),
13337             as_Register($src1$$reg),
13338             as_Register($src2$$reg));
13339   %}
13340 
13341   ins_pipe(ialu_reg_reg);
13342 %}
13343 
13344 instruct andL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2, rFlagsReg cr) %{
13345   match(Set dst (AndL src1 src2));
13346 
13347   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13348 
13349   ins_cost(INSN_COST);
13350   ins_encode %{
13351     __ andr(as_Register($dst$$reg),
13352             as_Register($src1$$reg),
13353             (unsigned long)($src2$$constant));
13354   %}
13355 
13356   ins_pipe(ialu_reg_imm);
13357 %}
13358 
13359 // Or Instructions
13360 
13361 instruct orL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13362   match(Set dst (OrL src1 src2));
13363 
13364   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13365 
13366   ins_cost(INSN_COST);
13367   ins_encode %{
13368     __ orr(as_Register($dst$$reg),
13369            as_Register($src1$$reg),
13370            as_Register($src2$$reg));
13371   %}
13372 
13373   ins_pipe(ialu_reg_reg);
13374 %}
13375 
13376 instruct orL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13377   match(Set dst (OrL src1 src2));
13378 
13379   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13380 
13381   ins_cost(INSN_COST);
13382   ins_encode %{
13383     __ orr(as_Register($dst$$reg),
13384            as_Register($src1$$reg),
13385            (unsigned long)($src2$$constant));
13386   %}
13387 
13388   ins_pipe(ialu_reg_imm);
13389 %}
13390 
13391 // Xor Instructions
13392 
13393 instruct xorL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13394   match(Set dst (XorL src1 src2));
13395 
13396   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13397 
13398   ins_cost(INSN_COST);
13399   ins_encode %{
13400     __ eor(as_Register($dst$$reg),
13401            as_Register($src1$$reg),
13402            as_Register($src2$$reg));
13403   %}
13404 
13405   ins_pipe(ialu_reg_reg);
13406 %}
13407 
13408 instruct xorL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13409   match(Set dst (XorL src1 src2));
13410 
13411   ins_cost(INSN_COST);
13412   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13413 
13414   ins_encode %{
13415     __ eor(as_Register($dst$$reg),
13416            as_Register($src1$$reg),
13417            (unsigned long)($src2$$constant));
13418   %}
13419 
13420   ins_pipe(ialu_reg_imm);
13421 %}
13422 
13423 instruct convI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src)
13424 %{
13425   match(Set dst (ConvI2L src));
13426 
13427   ins_cost(INSN_COST);
13428   format %{ &quot;sxtw  $dst, $src\t# i2l&quot; %}
13429   ins_encode %{
13430     __ sbfm($dst$$Register, $src$$Register, 0, 31);
13431   %}
13432   ins_pipe(ialu_reg_shift);
13433 %}
13434 
13435 // this pattern occurs in bigmath arithmetic
13436 instruct convUI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src, immL_32bits mask)
13437 %{
13438   match(Set dst (AndL (ConvI2L src) mask));
13439 
13440   ins_cost(INSN_COST);
13441   format %{ &quot;ubfm  $dst, $src, 0, 31\t# ui2l&quot; %}
13442   ins_encode %{
13443     __ ubfm($dst$$Register, $src$$Register, 0, 31);
13444   %}
13445 
13446   ins_pipe(ialu_reg_shift);
13447 %}
13448 
13449 instruct convL2I_reg(iRegINoSp dst, iRegL src) %{
13450   match(Set dst (ConvL2I src));
13451 
13452   ins_cost(INSN_COST);
13453   format %{ &quot;movw  $dst, $src \t// l2i&quot; %}
13454 
13455   ins_encode %{
13456     __ movw(as_Register($dst$$reg), as_Register($src$$reg));
13457   %}
13458 
13459   ins_pipe(ialu_reg);
13460 %}
13461 
13462 instruct convI2B(iRegINoSp dst, iRegIorL2I src, rFlagsReg cr)
13463 %{
13464   match(Set dst (Conv2B src));
13465   effect(KILL cr);
13466 
13467   format %{
13468     &quot;cmpw $src, zr\n\t&quot;
13469     &quot;cset $dst, ne&quot;
13470   %}
13471 
13472   ins_encode %{
13473     __ cmpw(as_Register($src$$reg), zr);
13474     __ cset(as_Register($dst$$reg), Assembler::NE);
13475   %}
13476 
13477   ins_pipe(ialu_reg);
13478 %}
13479 
13480 instruct convP2B(iRegINoSp dst, iRegP src, rFlagsReg cr)
13481 %{
13482   match(Set dst (Conv2B src));
13483   effect(KILL cr);
13484 
13485   format %{
13486     &quot;cmp  $src, zr\n\t&quot;
13487     &quot;cset $dst, ne&quot;
13488   %}
13489 
13490   ins_encode %{
13491     __ cmp(as_Register($src$$reg), zr);
13492     __ cset(as_Register($dst$$reg), Assembler::NE);
13493   %}
13494 
13495   ins_pipe(ialu_reg);
13496 %}
13497 
13498 instruct convD2F_reg(vRegF dst, vRegD src) %{
13499   match(Set dst (ConvD2F src));
13500 
13501   ins_cost(INSN_COST * 5);
13502   format %{ &quot;fcvtd  $dst, $src \t// d2f&quot; %}
13503 
13504   ins_encode %{
13505     __ fcvtd(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13506   %}
13507 
13508   ins_pipe(fp_d2f);
13509 %}
13510 
13511 instruct convF2D_reg(vRegD dst, vRegF src) %{
13512   match(Set dst (ConvF2D src));
13513 
13514   ins_cost(INSN_COST * 5);
13515   format %{ &quot;fcvts  $dst, $src \t// f2d&quot; %}
13516 
13517   ins_encode %{
13518     __ fcvts(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13519   %}
13520 
13521   ins_pipe(fp_f2d);
13522 %}
13523 
13524 instruct convF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13525   match(Set dst (ConvF2I src));
13526 
13527   ins_cost(INSN_COST * 5);
13528   format %{ &quot;fcvtzsw  $dst, $src \t// f2i&quot; %}
13529 
13530   ins_encode %{
13531     __ fcvtzsw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13532   %}
13533 
13534   ins_pipe(fp_f2i);
13535 %}
13536 
13537 instruct convF2L_reg_reg(iRegLNoSp dst, vRegF src) %{
13538   match(Set dst (ConvF2L src));
13539 
13540   ins_cost(INSN_COST * 5);
13541   format %{ &quot;fcvtzs  $dst, $src \t// f2l&quot; %}
13542 
13543   ins_encode %{
13544     __ fcvtzs(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13545   %}
13546 
13547   ins_pipe(fp_f2l);
13548 %}
13549 
13550 instruct convI2F_reg_reg(vRegF dst, iRegIorL2I src) %{
13551   match(Set dst (ConvI2F src));
13552 
13553   ins_cost(INSN_COST * 5);
13554   format %{ &quot;scvtfws  $dst, $src \t// i2f&quot; %}
13555 
13556   ins_encode %{
13557     __ scvtfws(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13558   %}
13559 
13560   ins_pipe(fp_i2f);
13561 %}
13562 
13563 instruct convL2F_reg_reg(vRegF dst, iRegL src) %{
13564   match(Set dst (ConvL2F src));
13565 
13566   ins_cost(INSN_COST * 5);
13567   format %{ &quot;scvtfs  $dst, $src \t// l2f&quot; %}
13568 
13569   ins_encode %{
13570     __ scvtfs(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13571   %}
13572 
13573   ins_pipe(fp_l2f);
13574 %}
13575 
13576 instruct convD2I_reg_reg(iRegINoSp dst, vRegD src) %{
13577   match(Set dst (ConvD2I src));
13578 
13579   ins_cost(INSN_COST * 5);
13580   format %{ &quot;fcvtzdw  $dst, $src \t// d2i&quot; %}
13581 
13582   ins_encode %{
13583     __ fcvtzdw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13584   %}
13585 
13586   ins_pipe(fp_d2i);
13587 %}
13588 
13589 instruct convD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13590   match(Set dst (ConvD2L src));
13591 
13592   ins_cost(INSN_COST * 5);
13593   format %{ &quot;fcvtzd  $dst, $src \t// d2l&quot; %}
13594 
13595   ins_encode %{
13596     __ fcvtzd(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13597   %}
13598 
13599   ins_pipe(fp_d2l);
13600 %}
13601 
13602 instruct convI2D_reg_reg(vRegD dst, iRegIorL2I src) %{
13603   match(Set dst (ConvI2D src));
13604 
13605   ins_cost(INSN_COST * 5);
13606   format %{ &quot;scvtfwd  $dst, $src \t// i2d&quot; %}
13607 
13608   ins_encode %{
13609     __ scvtfwd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13610   %}
13611 
13612   ins_pipe(fp_i2d);
13613 %}
13614 
13615 instruct convL2D_reg_reg(vRegD dst, iRegL src) %{
13616   match(Set dst (ConvL2D src));
13617 
13618   ins_cost(INSN_COST * 5);
13619   format %{ &quot;scvtfd  $dst, $src \t// l2d&quot; %}
13620 
13621   ins_encode %{
13622     __ scvtfd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13623   %}
13624 
13625   ins_pipe(fp_l2d);
13626 %}
13627 
13628 // stack &lt;-&gt; reg and reg &lt;-&gt; reg shuffles with no conversion
13629 
13630 instruct MoveF2I_stack_reg(iRegINoSp dst, stackSlotF src) %{
13631 
13632   match(Set dst (MoveF2I src));
13633 
13634   effect(DEF dst, USE src);
13635 
13636   ins_cost(4 * INSN_COST);
13637 
13638   format %{ &quot;ldrw $dst, $src\t# MoveF2I_stack_reg&quot; %}
13639 
13640   ins_encode %{
13641     __ ldrw($dst$$Register, Address(sp, $src$$disp));
13642   %}
13643 
13644   ins_pipe(iload_reg_reg);
13645 
13646 %}
13647 
13648 instruct MoveI2F_stack_reg(vRegF dst, stackSlotI src) %{
13649 
13650   match(Set dst (MoveI2F src));
13651 
13652   effect(DEF dst, USE src);
13653 
13654   ins_cost(4 * INSN_COST);
13655 
13656   format %{ &quot;ldrs $dst, $src\t# MoveI2F_stack_reg&quot; %}
13657 
13658   ins_encode %{
13659     __ ldrs(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13660   %}
13661 
13662   ins_pipe(pipe_class_memory);
13663 
13664 %}
13665 
13666 instruct MoveD2L_stack_reg(iRegLNoSp dst, stackSlotD src) %{
13667 
13668   match(Set dst (MoveD2L src));
13669 
13670   effect(DEF dst, USE src);
13671 
13672   ins_cost(4 * INSN_COST);
13673 
13674   format %{ &quot;ldr $dst, $src\t# MoveD2L_stack_reg&quot; %}
13675 
13676   ins_encode %{
13677     __ ldr($dst$$Register, Address(sp, $src$$disp));
13678   %}
13679 
13680   ins_pipe(iload_reg_reg);
13681 
13682 %}
13683 
13684 instruct MoveL2D_stack_reg(vRegD dst, stackSlotL src) %{
13685 
13686   match(Set dst (MoveL2D src));
13687 
13688   effect(DEF dst, USE src);
13689 
13690   ins_cost(4 * INSN_COST);
13691 
13692   format %{ &quot;ldrd $dst, $src\t# MoveL2D_stack_reg&quot; %}
13693 
13694   ins_encode %{
13695     __ ldrd(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13696   %}
13697 
13698   ins_pipe(pipe_class_memory);
13699 
13700 %}
13701 
13702 instruct MoveF2I_reg_stack(stackSlotI dst, vRegF src) %{
13703 
13704   match(Set dst (MoveF2I src));
13705 
13706   effect(DEF dst, USE src);
13707 
13708   ins_cost(INSN_COST);
13709 
13710   format %{ &quot;strs $src, $dst\t# MoveF2I_reg_stack&quot; %}
13711 
13712   ins_encode %{
13713     __ strs(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13714   %}
13715 
13716   ins_pipe(pipe_class_memory);
13717 
13718 %}
13719 
13720 instruct MoveI2F_reg_stack(stackSlotF dst, iRegI src) %{
13721 
13722   match(Set dst (MoveI2F src));
13723 
13724   effect(DEF dst, USE src);
13725 
13726   ins_cost(INSN_COST);
13727 
13728   format %{ &quot;strw $src, $dst\t# MoveI2F_reg_stack&quot; %}
13729 
13730   ins_encode %{
13731     __ strw($src$$Register, Address(sp, $dst$$disp));
13732   %}
13733 
13734   ins_pipe(istore_reg_reg);
13735 
13736 %}
13737 
13738 instruct MoveD2L_reg_stack(stackSlotL dst, vRegD src) %{
13739 
13740   match(Set dst (MoveD2L src));
13741 
13742   effect(DEF dst, USE src);
13743 
13744   ins_cost(INSN_COST);
13745 
13746   format %{ &quot;strd $dst, $src\t# MoveD2L_reg_stack&quot; %}
13747 
13748   ins_encode %{
13749     __ strd(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13750   %}
13751 
13752   ins_pipe(pipe_class_memory);
13753 
13754 %}
13755 
13756 instruct MoveL2D_reg_stack(stackSlotD dst, iRegL src) %{
13757 
13758   match(Set dst (MoveL2D src));
13759 
13760   effect(DEF dst, USE src);
13761 
13762   ins_cost(INSN_COST);
13763 
13764   format %{ &quot;str $src, $dst\t# MoveL2D_reg_stack&quot; %}
13765 
13766   ins_encode %{
13767     __ str($src$$Register, Address(sp, $dst$$disp));
13768   %}
13769 
13770   ins_pipe(istore_reg_reg);
13771 
13772 %}
13773 
13774 instruct MoveF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13775 
13776   match(Set dst (MoveF2I src));
13777 
13778   effect(DEF dst, USE src);
13779 
13780   ins_cost(INSN_COST);
13781 
13782   format %{ &quot;fmovs $dst, $src\t# MoveF2I_reg_reg&quot; %}
13783 
13784   ins_encode %{
13785     __ fmovs($dst$$Register, as_FloatRegister($src$$reg));
13786   %}
13787 
13788   ins_pipe(fp_f2i);
13789 
13790 %}
13791 
13792 instruct MoveI2F_reg_reg(vRegF dst, iRegI src) %{
13793 
13794   match(Set dst (MoveI2F src));
13795 
13796   effect(DEF dst, USE src);
13797 
13798   ins_cost(INSN_COST);
13799 
13800   format %{ &quot;fmovs $dst, $src\t# MoveI2F_reg_reg&quot; %}
13801 
13802   ins_encode %{
13803     __ fmovs(as_FloatRegister($dst$$reg), $src$$Register);
13804   %}
13805 
13806   ins_pipe(fp_i2f);
13807 
13808 %}
13809 
13810 instruct MoveD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13811 
13812   match(Set dst (MoveD2L src));
13813 
13814   effect(DEF dst, USE src);
13815 
13816   ins_cost(INSN_COST);
13817 
13818   format %{ &quot;fmovd $dst, $src\t# MoveD2L_reg_reg&quot; %}
13819 
13820   ins_encode %{
13821     __ fmovd($dst$$Register, as_FloatRegister($src$$reg));
13822   %}
13823 
13824   ins_pipe(fp_d2l);
13825 
13826 %}
13827 
13828 instruct MoveL2D_reg_reg(vRegD dst, iRegL src) %{
13829 
13830   match(Set dst (MoveL2D src));
13831 
13832   effect(DEF dst, USE src);
13833 
13834   ins_cost(INSN_COST);
13835 
13836   format %{ &quot;fmovd $dst, $src\t# MoveL2D_reg_reg&quot; %}
13837 
13838   ins_encode %{
13839     __ fmovd(as_FloatRegister($dst$$reg), $src$$Register);
13840   %}
13841 
13842   ins_pipe(fp_l2d);
13843 
13844 %}
13845 
13846 // ============================================================================
13847 // clearing of an array
13848 
13849 instruct clearArray_reg_reg(iRegL_R11 cnt, iRegP_R10 base, Universe dummy, rFlagsReg cr)
13850 %{
13851   match(Set dummy (ClearArray cnt base));
13852   effect(USE_KILL cnt, USE_KILL base, KILL cr);
13853 
13854   ins_cost(4 * INSN_COST);
13855   format %{ &quot;ClearArray $cnt, $base&quot; %}
13856 
13857   ins_encode %{
13858     __ zero_words($base$$Register, $cnt$$Register);
13859   %}
13860 
13861   ins_pipe(pipe_class_memory);
13862 %}
13863 
13864 instruct clearArray_imm_reg(immL cnt, iRegP_R10 base, Universe dummy, rFlagsReg cr)
13865 %{
13866   predicate((uint64_t)n-&gt;in(2)-&gt;get_long()
13867             &lt; (uint64_t)(BlockZeroingLowLimit &gt;&gt; LogBytesPerWord));
13868   match(Set dummy (ClearArray cnt base));
13869   effect(USE_KILL base);
13870 
13871   ins_cost(4 * INSN_COST);
13872   format %{ &quot;ClearArray $cnt, $base&quot; %}
13873 
13874   ins_encode %{
13875     __ zero_words($base$$Register, (uint64_t)$cnt$$constant);
13876   %}
13877 
13878   ins_pipe(pipe_class_memory);
13879 %}
13880 
13881 // ============================================================================
13882 // Overflow Math Instructions
13883 
13884 instruct overflowAddI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
13885 %{
13886   match(Set cr (OverflowAddI op1 op2));
13887 
13888   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13889   ins_cost(INSN_COST);
13890   ins_encode %{
13891     __ cmnw($op1$$Register, $op2$$Register);
13892   %}
13893 
13894   ins_pipe(icmp_reg_reg);
13895 %}
13896 
13897 instruct overflowAddI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
13898 %{
13899   match(Set cr (OverflowAddI op1 op2));
13900 
13901   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13902   ins_cost(INSN_COST);
13903   ins_encode %{
13904     __ cmnw($op1$$Register, $op2$$constant);
13905   %}
13906 
13907   ins_pipe(icmp_reg_imm);
13908 %}
13909 
13910 instruct overflowAddL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
13911 %{
13912   match(Set cr (OverflowAddL op1 op2));
13913 
13914   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
13915   ins_cost(INSN_COST);
13916   ins_encode %{
13917     __ cmn($op1$$Register, $op2$$Register);
13918   %}
13919 
13920   ins_pipe(icmp_reg_reg);
13921 %}
13922 
13923 instruct overflowAddL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
13924 %{
13925   match(Set cr (OverflowAddL op1 op2));
13926 
13927   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
13928   ins_cost(INSN_COST);
13929   ins_encode %{
13930     __ cmn($op1$$Register, $op2$$constant);
13931   %}
13932 
13933   ins_pipe(icmp_reg_imm);
13934 %}
13935 
13936 instruct overflowSubI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
13937 %{
13938   match(Set cr (OverflowSubI op1 op2));
13939 
13940   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
13941   ins_cost(INSN_COST);
13942   ins_encode %{
13943     __ cmpw($op1$$Register, $op2$$Register);
13944   %}
13945 
13946   ins_pipe(icmp_reg_reg);
13947 %}
13948 
13949 instruct overflowSubI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
13950 %{
13951   match(Set cr (OverflowSubI op1 op2));
13952 
13953   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
13954   ins_cost(INSN_COST);
13955   ins_encode %{
13956     __ cmpw($op1$$Register, $op2$$constant);
13957   %}
13958 
13959   ins_pipe(icmp_reg_imm);
13960 %}
13961 
13962 instruct overflowSubL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
13963 %{
13964   match(Set cr (OverflowSubL op1 op2));
13965 
13966   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
13967   ins_cost(INSN_COST);
13968   ins_encode %{
13969     __ cmp($op1$$Register, $op2$$Register);
13970   %}
13971 
13972   ins_pipe(icmp_reg_reg);
13973 %}
13974 
13975 instruct overflowSubL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
13976 %{
13977   match(Set cr (OverflowSubL op1 op2));
13978 
13979   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
13980   ins_cost(INSN_COST);
13981   ins_encode %{
13982     __ subs(zr, $op1$$Register, $op2$$constant);
13983   %}
13984 
13985   ins_pipe(icmp_reg_imm);
13986 %}
13987 
13988 instruct overflowNegI_reg(rFlagsReg cr, immI0 zero, iRegIorL2I op1)
13989 %{
13990   match(Set cr (OverflowSubI zero op1));
13991 
13992   format %{ &quot;cmpw  zr, $op1\t# overflow check int&quot; %}
13993   ins_cost(INSN_COST);
13994   ins_encode %{
13995     __ cmpw(zr, $op1$$Register);
13996   %}
13997 
13998   ins_pipe(icmp_reg_imm);
13999 %}
14000 
14001 instruct overflowNegL_reg(rFlagsReg cr, immI0 zero, iRegL op1)
14002 %{
14003   match(Set cr (OverflowSubL zero op1));
14004 
14005   format %{ &quot;cmp   zr, $op1\t# overflow check long&quot; %}
14006   ins_cost(INSN_COST);
14007   ins_encode %{
14008     __ cmp(zr, $op1$$Register);
14009   %}
14010 
14011   ins_pipe(icmp_reg_imm);
14012 %}
14013 
14014 instruct overflowMulI_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14015 %{
14016   match(Set cr (OverflowMulI op1 op2));
14017 
14018   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14019             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14020             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14021             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14022             &quot;cmpw  rscratch1, #1&quot; %}
14023   ins_cost(5 * INSN_COST);
14024   ins_encode %{
14025     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14026     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14027     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14028     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14029     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14030   %}
14031 
14032   ins_pipe(pipe_slow);
14033 %}
14034 
14035 instruct overflowMulI_reg_branch(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, label labl, rFlagsReg cr)
14036 %{
14037   match(If cmp (OverflowMulI op1 op2));
14038   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14039             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14040   effect(USE labl, KILL cr);
14041 
14042   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14043             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14044             &quot;b$cmp   $labl&quot; %}
14045   ins_cost(3 * INSN_COST); // Branch is rare so treat as INSN_COST
14046   ins_encode %{
14047     Label* L = $labl$$label;
14048     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14049     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14050     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14051     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14052   %}
14053 
14054   ins_pipe(pipe_serial);
14055 %}
14056 
14057 instruct overflowMulL_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14058 %{
14059   match(Set cr (OverflowMulL op1 op2));
14060 
14061   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14062             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14063             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14064             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14065             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14066             &quot;cmpw  rscratch1, #1&quot; %}
14067   ins_cost(6 * INSN_COST);
14068   ins_encode %{
14069     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14070     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14071     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14072     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14073     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14074     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14075   %}
14076 
14077   ins_pipe(pipe_slow);
14078 %}
14079 
14080 instruct overflowMulL_reg_branch(cmpOp cmp, iRegL op1, iRegL op2, label labl, rFlagsReg cr)
14081 %{
14082   match(If cmp (OverflowMulL op1 op2));
14083   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14084             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14085   effect(USE labl, KILL cr);
14086 
14087   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14088             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14089             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14090             &quot;b$cmp $labl&quot; %}
14091   ins_cost(4 * INSN_COST); // Branch is rare so treat as INSN_COST
14092   ins_encode %{
14093     Label* L = $labl$$label;
14094     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14095     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14096     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14097     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14098     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14099   %}
14100 
14101   ins_pipe(pipe_serial);
14102 %}
14103 
14104 // ============================================================================
14105 // Compare Instructions
14106 
14107 instruct compI_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
14108 %{
14109   match(Set cr (CmpI op1 op2));
14110 
14111   effect(DEF cr, USE op1, USE op2);
14112 
14113   ins_cost(INSN_COST);
14114   format %{ &quot;cmpw  $op1, $op2&quot; %}
14115 
14116   ins_encode(aarch64_enc_cmpw(op1, op2));
14117 
14118   ins_pipe(icmp_reg_reg);
14119 %}
14120 
14121 instruct compI_reg_immI0(rFlagsReg cr, iRegI op1, immI0 zero)
14122 %{
14123   match(Set cr (CmpI op1 zero));
14124 
14125   effect(DEF cr, USE op1);
14126 
14127   ins_cost(INSN_COST);
14128   format %{ &quot;cmpw $op1, 0&quot; %}
14129 
14130   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14131 
14132   ins_pipe(icmp_reg_imm);
14133 %}
14134 
14135 instruct compI_reg_immIAddSub(rFlagsReg cr, iRegI op1, immIAddSub op2)
14136 %{
14137   match(Set cr (CmpI op1 op2));
14138 
14139   effect(DEF cr, USE op1);
14140 
14141   ins_cost(INSN_COST);
14142   format %{ &quot;cmpw  $op1, $op2&quot; %}
14143 
14144   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14145 
14146   ins_pipe(icmp_reg_imm);
14147 %}
14148 
14149 instruct compI_reg_immI(rFlagsReg cr, iRegI op1, immI op2)
14150 %{
14151   match(Set cr (CmpI op1 op2));
14152 
14153   effect(DEF cr, USE op1);
14154 
14155   ins_cost(INSN_COST * 2);
14156   format %{ &quot;cmpw  $op1, $op2&quot; %}
14157 
14158   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14159 
14160   ins_pipe(icmp_reg_imm);
14161 %}
14162 
14163 // Unsigned compare Instructions; really, same as signed compare
14164 // except it should only be used to feed an If or a CMovI which takes a
14165 // cmpOpU.
14166 
14167 instruct compU_reg_reg(rFlagsRegU cr, iRegI op1, iRegI op2)
14168 %{
14169   match(Set cr (CmpU op1 op2));
14170 
14171   effect(DEF cr, USE op1, USE op2);
14172 
14173   ins_cost(INSN_COST);
14174   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14175 
14176   ins_encode(aarch64_enc_cmpw(op1, op2));
14177 
14178   ins_pipe(icmp_reg_reg);
14179 %}
14180 
14181 instruct compU_reg_immI0(rFlagsRegU cr, iRegI op1, immI0 zero)
14182 %{
14183   match(Set cr (CmpU op1 zero));
14184 
14185   effect(DEF cr, USE op1);
14186 
14187   ins_cost(INSN_COST);
14188   format %{ &quot;cmpw $op1, #0\t# unsigned&quot; %}
14189 
14190   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14191 
14192   ins_pipe(icmp_reg_imm);
14193 %}
14194 
14195 instruct compU_reg_immIAddSub(rFlagsRegU cr, iRegI op1, immIAddSub op2)
14196 %{
14197   match(Set cr (CmpU op1 op2));
14198 
14199   effect(DEF cr, USE op1);
14200 
14201   ins_cost(INSN_COST);
14202   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14203 
14204   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14205 
14206   ins_pipe(icmp_reg_imm);
14207 %}
14208 
14209 instruct compU_reg_immI(rFlagsRegU cr, iRegI op1, immI op2)
14210 %{
14211   match(Set cr (CmpU op1 op2));
14212 
14213   effect(DEF cr, USE op1);
14214 
14215   ins_cost(INSN_COST * 2);
14216   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14217 
14218   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14219 
14220   ins_pipe(icmp_reg_imm);
14221 %}
14222 
14223 instruct compL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14224 %{
14225   match(Set cr (CmpL op1 op2));
14226 
14227   effect(DEF cr, USE op1, USE op2);
14228 
14229   ins_cost(INSN_COST);
14230   format %{ &quot;cmp  $op1, $op2&quot; %}
14231 
14232   ins_encode(aarch64_enc_cmp(op1, op2));
14233 
14234   ins_pipe(icmp_reg_reg);
14235 %}
14236 
14237 instruct compL_reg_immL0(rFlagsReg cr, iRegL op1, immL0 zero)
14238 %{
14239   match(Set cr (CmpL op1 zero));
14240 
14241   effect(DEF cr, USE op1);
14242 
14243   ins_cost(INSN_COST);
14244   format %{ &quot;tst  $op1&quot; %}
14245 
14246   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14247 
14248   ins_pipe(icmp_reg_imm);
14249 %}
14250 
14251 instruct compL_reg_immLAddSub(rFlagsReg cr, iRegL op1, immLAddSub op2)
14252 %{
14253   match(Set cr (CmpL op1 op2));
14254 
14255   effect(DEF cr, USE op1);
14256 
14257   ins_cost(INSN_COST);
14258   format %{ &quot;cmp  $op1, $op2&quot; %}
14259 
14260   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14261 
14262   ins_pipe(icmp_reg_imm);
14263 %}
14264 
14265 instruct compL_reg_immL(rFlagsReg cr, iRegL op1, immL op2)
14266 %{
14267   match(Set cr (CmpL op1 op2));
14268 
14269   effect(DEF cr, USE op1);
14270 
14271   ins_cost(INSN_COST * 2);
14272   format %{ &quot;cmp  $op1, $op2&quot; %}
14273 
14274   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14275 
14276   ins_pipe(icmp_reg_imm);
14277 %}
14278 
14279 instruct compUL_reg_reg(rFlagsRegU cr, iRegL op1, iRegL op2)
14280 %{
14281   match(Set cr (CmpUL op1 op2));
14282 
14283   effect(DEF cr, USE op1, USE op2);
14284 
14285   ins_cost(INSN_COST);
14286   format %{ &quot;cmp  $op1, $op2&quot; %}
14287 
14288   ins_encode(aarch64_enc_cmp(op1, op2));
14289 
14290   ins_pipe(icmp_reg_reg);
14291 %}
14292 
14293 instruct compUL_reg_immL0(rFlagsRegU cr, iRegL op1, immL0 zero)
14294 %{
14295   match(Set cr (CmpUL op1 zero));
14296 
14297   effect(DEF cr, USE op1);
14298 
14299   ins_cost(INSN_COST);
14300   format %{ &quot;tst  $op1&quot; %}
14301 
14302   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14303 
14304   ins_pipe(icmp_reg_imm);
14305 %}
14306 
14307 instruct compUL_reg_immLAddSub(rFlagsRegU cr, iRegL op1, immLAddSub op2)
14308 %{
14309   match(Set cr (CmpUL op1 op2));
14310 
14311   effect(DEF cr, USE op1);
14312 
14313   ins_cost(INSN_COST);
14314   format %{ &quot;cmp  $op1, $op2&quot; %}
14315 
14316   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14317 
14318   ins_pipe(icmp_reg_imm);
14319 %}
14320 
14321 instruct compUL_reg_immL(rFlagsRegU cr, iRegL op1, immL op2)
14322 %{
14323   match(Set cr (CmpUL op1 op2));
14324 
14325   effect(DEF cr, USE op1);
14326 
14327   ins_cost(INSN_COST * 2);
14328   format %{ &quot;cmp  $op1, $op2&quot; %}
14329 
14330   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14331 
14332   ins_pipe(icmp_reg_imm);
14333 %}
14334 
14335 instruct compP_reg_reg(rFlagsRegU cr, iRegP op1, iRegP op2)
14336 %{
14337   match(Set cr (CmpP op1 op2));
14338 
14339   effect(DEF cr, USE op1, USE op2);
14340 
14341   ins_cost(INSN_COST);
14342   format %{ &quot;cmp  $op1, $op2\t // ptr&quot; %}
14343 
14344   ins_encode(aarch64_enc_cmpp(op1, op2));
14345 
14346   ins_pipe(icmp_reg_reg);
14347 %}
14348 
14349 instruct compN_reg_reg(rFlagsRegU cr, iRegN op1, iRegN op2)
14350 %{
14351   match(Set cr (CmpN op1 op2));
14352 
14353   effect(DEF cr, USE op1, USE op2);
14354 
14355   ins_cost(INSN_COST);
14356   format %{ &quot;cmp  $op1, $op2\t // compressed ptr&quot; %}
14357 
14358   ins_encode(aarch64_enc_cmpn(op1, op2));
14359 
14360   ins_pipe(icmp_reg_reg);
14361 %}
14362 
14363 instruct testP_reg(rFlagsRegU cr, iRegP op1, immP0 zero)
14364 %{
14365   match(Set cr (CmpP op1 zero));
14366 
14367   effect(DEF cr, USE op1, USE zero);
14368 
14369   ins_cost(INSN_COST);
14370   format %{ &quot;cmp  $op1, 0\t // ptr&quot; %}
14371 
14372   ins_encode(aarch64_enc_testp(op1));
14373 
14374   ins_pipe(icmp_reg_imm);
14375 %}
14376 
14377 instruct testN_reg(rFlagsRegU cr, iRegN op1, immN0 zero)
14378 %{
14379   match(Set cr (CmpN op1 zero));
14380 
14381   effect(DEF cr, USE op1, USE zero);
14382 
14383   ins_cost(INSN_COST);
14384   format %{ &quot;cmp  $op1, 0\t // compressed ptr&quot; %}
14385 
14386   ins_encode(aarch64_enc_testn(op1));
14387 
14388   ins_pipe(icmp_reg_imm);
14389 %}
14390 
14391 // FP comparisons
14392 //
14393 // n.b. CmpF/CmpD set a normal flags reg which then gets compared
14394 // using normal cmpOp. See declaration of rFlagsReg for details.
14395 
14396 instruct compF_reg_reg(rFlagsReg cr, vRegF src1, vRegF src2)
14397 %{
14398   match(Set cr (CmpF src1 src2));
14399 
14400   ins_cost(3 * INSN_COST);
14401   format %{ &quot;fcmps $src1, $src2&quot; %}
14402 
14403   ins_encode %{
14404     __ fcmps(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14405   %}
14406 
14407   ins_pipe(pipe_class_compare);
14408 %}
14409 
14410 instruct compF_reg_zero(rFlagsReg cr, vRegF src1, immF0 src2)
14411 %{
14412   match(Set cr (CmpF src1 src2));
14413 
14414   ins_cost(3 * INSN_COST);
14415   format %{ &quot;fcmps $src1, 0.0&quot; %}
14416 
14417   ins_encode %{
14418     __ fcmps(as_FloatRegister($src1$$reg), 0.0);
14419   %}
14420 
14421   ins_pipe(pipe_class_compare);
14422 %}
14423 // FROM HERE
14424 
14425 instruct compD_reg_reg(rFlagsReg cr, vRegD src1, vRegD src2)
14426 %{
14427   match(Set cr (CmpD src1 src2));
14428 
14429   ins_cost(3 * INSN_COST);
14430   format %{ &quot;fcmpd $src1, $src2&quot; %}
14431 
14432   ins_encode %{
14433     __ fcmpd(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14434   %}
14435 
14436   ins_pipe(pipe_class_compare);
14437 %}
14438 
14439 instruct compD_reg_zero(rFlagsReg cr, vRegD src1, immD0 src2)
14440 %{
14441   match(Set cr (CmpD src1 src2));
14442 
14443   ins_cost(3 * INSN_COST);
14444   format %{ &quot;fcmpd $src1, 0.0&quot; %}
14445 
14446   ins_encode %{
14447     __ fcmpd(as_FloatRegister($src1$$reg), 0.0);
14448   %}
14449 
14450   ins_pipe(pipe_class_compare);
14451 %}
14452 
14453 instruct compF3_reg_reg(iRegINoSp dst, vRegF src1, vRegF src2, rFlagsReg cr)
14454 %{
14455   match(Set dst (CmpF3 src1 src2));
14456   effect(KILL cr);
14457 
14458   ins_cost(5 * INSN_COST);
14459   format %{ &quot;fcmps $src1, $src2\n\t&quot;
14460             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14461             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14462   %}
14463 
14464   ins_encode %{
14465     Label done;
14466     FloatRegister s1 = as_FloatRegister($src1$$reg);
14467     FloatRegister s2 = as_FloatRegister($src2$$reg);
14468     Register d = as_Register($dst$$reg);
14469     __ fcmps(s1, s2);
14470     // installs 0 if EQ else -1
14471     __ csinvw(d, zr, zr, Assembler::EQ);
14472     // keeps -1 if less or unordered else installs 1
14473     __ csnegw(d, d, d, Assembler::LT);
14474     __ bind(done);
14475   %}
14476 
14477   ins_pipe(pipe_class_default);
14478 
14479 %}
14480 
14481 instruct compD3_reg_reg(iRegINoSp dst, vRegD src1, vRegD src2, rFlagsReg cr)
14482 %{
14483   match(Set dst (CmpD3 src1 src2));
14484   effect(KILL cr);
14485 
14486   ins_cost(5 * INSN_COST);
14487   format %{ &quot;fcmpd $src1, $src2\n\t&quot;
14488             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14489             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14490   %}
14491 
14492   ins_encode %{
14493     Label done;
14494     FloatRegister s1 = as_FloatRegister($src1$$reg);
14495     FloatRegister s2 = as_FloatRegister($src2$$reg);
14496     Register d = as_Register($dst$$reg);
14497     __ fcmpd(s1, s2);
14498     // installs 0 if EQ else -1
14499     __ csinvw(d, zr, zr, Assembler::EQ);
14500     // keeps -1 if less or unordered else installs 1
14501     __ csnegw(d, d, d, Assembler::LT);
14502     __ bind(done);
14503   %}
14504   ins_pipe(pipe_class_default);
14505 
14506 %}
14507 
14508 instruct compF3_reg_immF0(iRegINoSp dst, vRegF src1, immF0 zero, rFlagsReg cr)
14509 %{
14510   match(Set dst (CmpF3 src1 zero));
14511   effect(KILL cr);
14512 
14513   ins_cost(5 * INSN_COST);
14514   format %{ &quot;fcmps $src1, 0.0\n\t&quot;
14515             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14516             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14517   %}
14518 
14519   ins_encode %{
14520     Label done;
14521     FloatRegister s1 = as_FloatRegister($src1$$reg);
14522     Register d = as_Register($dst$$reg);
14523     __ fcmps(s1, 0.0);
14524     // installs 0 if EQ else -1
14525     __ csinvw(d, zr, zr, Assembler::EQ);
14526     // keeps -1 if less or unordered else installs 1
14527     __ csnegw(d, d, d, Assembler::LT);
14528     __ bind(done);
14529   %}
14530 
14531   ins_pipe(pipe_class_default);
14532 
14533 %}
14534 
14535 instruct compD3_reg_immD0(iRegINoSp dst, vRegD src1, immD0 zero, rFlagsReg cr)
14536 %{
14537   match(Set dst (CmpD3 src1 zero));
14538   effect(KILL cr);
14539 
14540   ins_cost(5 * INSN_COST);
14541   format %{ &quot;fcmpd $src1, 0.0\n\t&quot;
14542             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14543             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14544   %}
14545 
14546   ins_encode %{
14547     Label done;
14548     FloatRegister s1 = as_FloatRegister($src1$$reg);
14549     Register d = as_Register($dst$$reg);
14550     __ fcmpd(s1, 0.0);
14551     // installs 0 if EQ else -1
14552     __ csinvw(d, zr, zr, Assembler::EQ);
14553     // keeps -1 if less or unordered else installs 1
14554     __ csnegw(d, d, d, Assembler::LT);
14555     __ bind(done);
14556   %}
14557   ins_pipe(pipe_class_default);
14558 
14559 %}
14560 
14561 instruct cmpLTMask_reg_reg(iRegINoSp dst, iRegIorL2I p, iRegIorL2I q, rFlagsReg cr)
14562 %{
14563   match(Set dst (CmpLTMask p q));
14564   effect(KILL cr);
14565 
14566   ins_cost(3 * INSN_COST);
14567 
14568   format %{ &quot;cmpw $p, $q\t# cmpLTMask\n\t&quot;
14569             &quot;csetw $dst, lt\n\t&quot;
14570             &quot;subw $dst, zr, $dst&quot;
14571   %}
14572 
14573   ins_encode %{
14574     __ cmpw(as_Register($p$$reg), as_Register($q$$reg));
14575     __ csetw(as_Register($dst$$reg), Assembler::LT);
14576     __ subw(as_Register($dst$$reg), zr, as_Register($dst$$reg));
14577   %}
14578 
14579   ins_pipe(ialu_reg_reg);
14580 %}
14581 
14582 instruct cmpLTMask_reg_zero(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr)
14583 %{
14584   match(Set dst (CmpLTMask src zero));
14585   effect(KILL cr);
14586 
14587   ins_cost(INSN_COST);
14588 
14589   format %{ &quot;asrw $dst, $src, #31\t# cmpLTMask0&quot; %}
14590 
14591   ins_encode %{
14592     __ asrw(as_Register($dst$$reg), as_Register($src$$reg), 31);
14593   %}
14594 
14595   ins_pipe(ialu_reg_shift);
14596 %}
14597 
14598 // ============================================================================
14599 // Max and Min
14600 
14601 instruct cmovI_reg_reg_lt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14602 %{
14603   effect( DEF dst, USE src1, USE src2, USE cr );
14604 
14605   ins_cost(INSN_COST * 2);
14606   format %{ &quot;cselw $dst, $src1, $src2 lt\t&quot;  %}
14607 
14608   ins_encode %{
14609     __ cselw(as_Register($dst$$reg),
14610              as_Register($src1$$reg),
14611              as_Register($src2$$reg),
14612              Assembler::LT);
14613   %}
14614 
14615   ins_pipe(icond_reg_reg);
14616 %}
14617 
14618 instruct minI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14619 %{
14620   match(Set dst (MinI src1 src2));
14621   ins_cost(INSN_COST * 3);
14622 
14623   expand %{
14624     rFlagsReg cr;
14625     compI_reg_reg(cr, src1, src2);
14626     cmovI_reg_reg_lt(dst, src1, src2, cr);
14627   %}
14628 
14629 %}
14630 // FROM HERE
14631 
14632 instruct cmovI_reg_reg_gt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14633 %{
14634   effect( DEF dst, USE src1, USE src2, USE cr );
14635 
14636   ins_cost(INSN_COST * 2);
14637   format %{ &quot;cselw $dst, $src1, $src2 gt\t&quot;  %}
14638 
14639   ins_encode %{
14640     __ cselw(as_Register($dst$$reg),
14641              as_Register($src1$$reg),
14642              as_Register($src2$$reg),
14643              Assembler::GT);
14644   %}
14645 
14646   ins_pipe(icond_reg_reg);
14647 %}
14648 
14649 instruct maxI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14650 %{
14651   match(Set dst (MaxI src1 src2));
14652   ins_cost(INSN_COST * 3);
14653   expand %{
14654     rFlagsReg cr;
14655     compI_reg_reg(cr, src1, src2);
14656     cmovI_reg_reg_gt(dst, src1, src2, cr);
14657   %}
14658 %}
14659 
14660 // ============================================================================
14661 // Branch Instructions
14662 
14663 // Direct Branch.
14664 instruct branch(label lbl)
14665 %{
14666   match(Goto);
14667 
14668   effect(USE lbl);
14669 
14670   ins_cost(BRANCH_COST);
14671   format %{ &quot;b  $lbl&quot; %}
14672 
14673   ins_encode(aarch64_enc_b(lbl));
14674 
14675   ins_pipe(pipe_branch);
14676 %}
14677 
14678 // Conditional Near Branch
14679 instruct branchCon(cmpOp cmp, rFlagsReg cr, label lbl)
14680 %{
14681   // Same match rule as `branchConFar&#39;.
14682   match(If cmp cr);
14683 
14684   effect(USE lbl);
14685 
14686   ins_cost(BRANCH_COST);
14687   // If set to 1 this indicates that the current instruction is a
14688   // short variant of a long branch. This avoids using this
14689   // instruction in first-pass matching. It will then only be used in
14690   // the `Shorten_branches&#39; pass.
14691   // ins_short_branch(1);
14692   format %{ &quot;b$cmp  $lbl&quot; %}
14693 
14694   ins_encode(aarch64_enc_br_con(cmp, lbl));
14695 
14696   ins_pipe(pipe_branch_cond);
14697 %}
14698 
14699 // Conditional Near Branch Unsigned
14700 instruct branchConU(cmpOpU cmp, rFlagsRegU cr, label lbl)
14701 %{
14702   // Same match rule as `branchConFar&#39;.
14703   match(If cmp cr);
14704 
14705   effect(USE lbl);
14706 
14707   ins_cost(BRANCH_COST);
14708   // If set to 1 this indicates that the current instruction is a
14709   // short variant of a long branch. This avoids using this
14710   // instruction in first-pass matching. It will then only be used in
14711   // the `Shorten_branches&#39; pass.
14712   // ins_short_branch(1);
14713   format %{ &quot;b$cmp  $lbl\t# unsigned&quot; %}
14714 
14715   ins_encode(aarch64_enc_br_conU(cmp, lbl));
14716 
14717   ins_pipe(pipe_branch_cond);
14718 %}
14719 
14720 // Make use of CBZ and CBNZ.  These instructions, as well as being
14721 // shorter than (cmp; branch), have the additional benefit of not
14722 // killing the flags.
14723 
14724 instruct cmpI_imm0_branch(cmpOpEqNe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsReg cr) %{
14725   match(If cmp (CmpI op1 op2));
14726   effect(USE labl);
14727 
14728   ins_cost(BRANCH_COST);
14729   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14730   ins_encode %{
14731     Label* L = $labl$$label;
14732     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14733     if (cond == Assembler::EQ)
14734       __ cbzw($op1$$Register, *L);
14735     else
14736       __ cbnzw($op1$$Register, *L);
14737   %}
14738   ins_pipe(pipe_cmp_branch);
14739 %}
14740 
14741 instruct cmpL_imm0_branch(cmpOpEqNe cmp, iRegL op1, immL0 op2, label labl, rFlagsReg cr) %{
14742   match(If cmp (CmpL op1 op2));
14743   effect(USE labl);
14744 
14745   ins_cost(BRANCH_COST);
14746   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14747   ins_encode %{
14748     Label* L = $labl$$label;
14749     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14750     if (cond == Assembler::EQ)
14751       __ cbz($op1$$Register, *L);
14752     else
14753       __ cbnz($op1$$Register, *L);
14754   %}
14755   ins_pipe(pipe_cmp_branch);
14756 %}
14757 
14758 instruct cmpP_imm0_branch(cmpOpEqNe cmp, iRegP op1, immP0 op2, label labl, rFlagsReg cr) %{
14759   match(If cmp (CmpP op1 op2));
14760   effect(USE labl);
14761 
14762   ins_cost(BRANCH_COST);
14763   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14764   ins_encode %{
14765     Label* L = $labl$$label;
14766     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14767     if (cond == Assembler::EQ)
14768       __ cbz($op1$$Register, *L);
14769     else
14770       __ cbnz($op1$$Register, *L);
14771   %}
14772   ins_pipe(pipe_cmp_branch);
14773 %}
14774 
14775 instruct cmpN_imm0_branch(cmpOpEqNe cmp, iRegN op1, immN0 op2, label labl, rFlagsReg cr) %{
14776   match(If cmp (CmpN op1 op2));
14777   effect(USE labl);
14778 
14779   ins_cost(BRANCH_COST);
14780   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14781   ins_encode %{
14782     Label* L = $labl$$label;
14783     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14784     if (cond == Assembler::EQ)
14785       __ cbzw($op1$$Register, *L);
14786     else
14787       __ cbnzw($op1$$Register, *L);
14788   %}
14789   ins_pipe(pipe_cmp_branch);
14790 %}
14791 
14792 instruct cmpP_narrowOop_imm0_branch(cmpOpEqNe cmp, iRegN oop, immP0 zero, label labl, rFlagsReg cr) %{
14793   match(If cmp (CmpP (DecodeN oop) zero));
14794   effect(USE labl);
14795 
14796   ins_cost(BRANCH_COST);
14797   format %{ &quot;cb$cmp   $oop, $labl&quot; %}
14798   ins_encode %{
14799     Label* L = $labl$$label;
14800     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14801     if (cond == Assembler::EQ)
14802       __ cbzw($oop$$Register, *L);
14803     else
14804       __ cbnzw($oop$$Register, *L);
14805   %}
14806   ins_pipe(pipe_cmp_branch);
14807 %}
14808 
14809 instruct cmpUI_imm0_branch(cmpOpUEqNeLtGe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsRegU cr) %{
14810   match(If cmp (CmpU op1 op2));
14811   effect(USE labl);
14812 
14813   ins_cost(BRANCH_COST);
14814   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14815   ins_encode %{
14816     Label* L = $labl$$label;
14817     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14818     if (cond == Assembler::EQ || cond == Assembler::LS)
14819       __ cbzw($op1$$Register, *L);
14820     else
14821       __ cbnzw($op1$$Register, *L);
14822   %}
14823   ins_pipe(pipe_cmp_branch);
14824 %}
14825 
14826 instruct cmpUL_imm0_branch(cmpOpUEqNeLtGe cmp, iRegL op1, immL0 op2, label labl, rFlagsRegU cr) %{
14827   match(If cmp (CmpUL op1 op2));
14828   effect(USE labl);
14829 
14830   ins_cost(BRANCH_COST);
14831   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14832   ins_encode %{
14833     Label* L = $labl$$label;
14834     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14835     if (cond == Assembler::EQ || cond == Assembler::LS)
14836       __ cbz($op1$$Register, *L);
14837     else
14838       __ cbnz($op1$$Register, *L);
14839   %}
14840   ins_pipe(pipe_cmp_branch);
14841 %}
14842 
14843 // Test bit and Branch
14844 
14845 // Patterns for short (&lt; 32KiB) variants
14846 instruct cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14847   match(If cmp (CmpL op1 op2));
14848   effect(USE labl);
14849 
14850   ins_cost(BRANCH_COST);
14851   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14852   ins_encode %{
14853     Label* L = $labl$$label;
14854     Assembler::Condition cond =
14855       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14856     __ tbr(cond, $op1$$Register, 63, *L);
14857   %}
14858   ins_pipe(pipe_cmp_branch);
14859   ins_short_branch(1);
14860 %}
14861 
14862 instruct cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14863   match(If cmp (CmpI op1 op2));
14864   effect(USE labl);
14865 
14866   ins_cost(BRANCH_COST);
14867   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14868   ins_encode %{
14869     Label* L = $labl$$label;
14870     Assembler::Condition cond =
14871       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14872     __ tbr(cond, $op1$$Register, 31, *L);
14873   %}
14874   ins_pipe(pipe_cmp_branch);
14875   ins_short_branch(1);
14876 %}
14877 
14878 instruct cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14879   match(If cmp (CmpL (AndL op1 op2) op3));
14880   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14881   effect(USE labl);
14882 
14883   ins_cost(BRANCH_COST);
14884   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14885   ins_encode %{
14886     Label* L = $labl$$label;
14887     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14888     int bit = exact_log2_long($op2$$constant);
14889     __ tbr(cond, $op1$$Register, bit, *L);
14890   %}
14891   ins_pipe(pipe_cmp_branch);
14892   ins_short_branch(1);
14893 %}
14894 
14895 instruct cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14896   match(If cmp (CmpI (AndI op1 op2) op3));
14897   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
14898   effect(USE labl);
14899 
14900   ins_cost(BRANCH_COST);
14901   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14902   ins_encode %{
14903     Label* L = $labl$$label;
14904     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14905     int bit = exact_log2((juint)$op2$$constant);
14906     __ tbr(cond, $op1$$Register, bit, *L);
14907   %}
14908   ins_pipe(pipe_cmp_branch);
14909   ins_short_branch(1);
14910 %}
14911 
14912 // And far variants
14913 instruct far_cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14914   match(If cmp (CmpL op1 op2));
14915   effect(USE labl);
14916 
14917   ins_cost(BRANCH_COST);
14918   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14919   ins_encode %{
14920     Label* L = $labl$$label;
14921     Assembler::Condition cond =
14922       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14923     __ tbr(cond, $op1$$Register, 63, *L, /*far*/true);
14924   %}
14925   ins_pipe(pipe_cmp_branch);
14926 %}
14927 
14928 instruct far_cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14929   match(If cmp (CmpI op1 op2));
14930   effect(USE labl);
14931 
14932   ins_cost(BRANCH_COST);
14933   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14934   ins_encode %{
14935     Label* L = $labl$$label;
14936     Assembler::Condition cond =
14937       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14938     __ tbr(cond, $op1$$Register, 31, *L, /*far*/true);
14939   %}
14940   ins_pipe(pipe_cmp_branch);
14941 %}
14942 
14943 instruct far_cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14944   match(If cmp (CmpL (AndL op1 op2) op3));
14945   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14946   effect(USE labl);
14947 
14948   ins_cost(BRANCH_COST);
14949   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14950   ins_encode %{
14951     Label* L = $labl$$label;
14952     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14953     int bit = exact_log2_long($op2$$constant);
14954     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
14955   %}
14956   ins_pipe(pipe_cmp_branch);
14957 %}
14958 
14959 instruct far_cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14960   match(If cmp (CmpI (AndI op1 op2) op3));
14961   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
14962   effect(USE labl);
14963 
14964   ins_cost(BRANCH_COST);
14965   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14966   ins_encode %{
14967     Label* L = $labl$$label;
14968     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14969     int bit = exact_log2((juint)$op2$$constant);
14970     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
14971   %}
14972   ins_pipe(pipe_cmp_branch);
14973 %}
14974 
14975 // Test bits
14976 
14977 instruct cmpL_and(cmpOp cmp, iRegL op1, immL op2, immL0 op3, rFlagsReg cr) %{
14978   match(Set cr (CmpL (AndL op1 op2) op3));
14979   predicate(Assembler::operand_valid_for_logical_immediate
14980             (/*is_32*/false, n-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14981 
14982   ins_cost(INSN_COST);
14983   format %{ &quot;tst $op1, $op2 # long&quot; %}
14984   ins_encode %{
14985     __ tst($op1$$Register, $op2$$constant);
14986   %}
14987   ins_pipe(ialu_reg_reg);
14988 %}
14989 
14990 instruct cmpI_and(cmpOp cmp, iRegIorL2I op1, immI op2, immI0 op3, rFlagsReg cr) %{
14991   match(Set cr (CmpI (AndI op1 op2) op3));
14992   predicate(Assembler::operand_valid_for_logical_immediate
14993             (/*is_32*/true, n-&gt;in(1)-&gt;in(2)-&gt;get_int()));
14994 
14995   ins_cost(INSN_COST);
14996   format %{ &quot;tst $op1, $op2 # int&quot; %}
14997   ins_encode %{
14998     __ tstw($op1$$Register, $op2$$constant);
14999   %}
15000   ins_pipe(ialu_reg_reg);
15001 %}
15002 
15003 instruct cmpL_and_reg(cmpOp cmp, iRegL op1, iRegL op2, immL0 op3, rFlagsReg cr) %{
15004   match(Set cr (CmpL (AndL op1 op2) op3));
15005 
15006   ins_cost(INSN_COST);
15007   format %{ &quot;tst $op1, $op2 # long&quot; %}
15008   ins_encode %{
15009     __ tst($op1$$Register, $op2$$Register);
15010   %}
15011   ins_pipe(ialu_reg_reg);
15012 %}
15013 
15014 instruct cmpI_and_reg(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, immI0 op3, rFlagsReg cr) %{
15015   match(Set cr (CmpI (AndI op1 op2) op3));
15016 
15017   ins_cost(INSN_COST);
15018   format %{ &quot;tstw $op1, $op2 # int&quot; %}
15019   ins_encode %{
15020     __ tstw($op1$$Register, $op2$$Register);
15021   %}
15022   ins_pipe(ialu_reg_reg);
15023 %}
15024 
15025 
15026 // Conditional Far Branch
15027 // Conditional Far Branch Unsigned
15028 // TODO: fixme
15029 
15030 // counted loop end branch near
15031 instruct branchLoopEnd(cmpOp cmp, rFlagsReg cr, label lbl)
15032 %{
15033   match(CountedLoopEnd cmp cr);
15034 
15035   effect(USE lbl);
15036 
15037   ins_cost(BRANCH_COST);
15038   // short variant.
15039   // ins_short_branch(1);
15040   format %{ &quot;b$cmp $lbl \t// counted loop end&quot; %}
15041 
15042   ins_encode(aarch64_enc_br_con(cmp, lbl));
15043 
15044   ins_pipe(pipe_branch);
15045 %}
15046 
15047 // counted loop end branch near Unsigned
15048 instruct branchLoopEndU(cmpOpU cmp, rFlagsRegU cr, label lbl)
15049 %{
15050   match(CountedLoopEnd cmp cr);
15051 
15052   effect(USE lbl);
15053 
15054   ins_cost(BRANCH_COST);
15055   // short variant.
15056   // ins_short_branch(1);
15057   format %{ &quot;b$cmp $lbl \t// counted loop end unsigned&quot; %}
15058 
15059   ins_encode(aarch64_enc_br_conU(cmp, lbl));
15060 
15061   ins_pipe(pipe_branch);
15062 %}
15063 
15064 // counted loop end branch far
15065 // counted loop end branch far unsigned
15066 // TODO: fixme
15067 
15068 // ============================================================================
15069 // inlined locking and unlocking
15070 
15071 instruct cmpFastLock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15072 %{
15073   match(Set cr (FastLock object box));
15074   effect(TEMP tmp, TEMP tmp2);
15075 
15076   // TODO
15077   // identify correct cost
15078   ins_cost(5 * INSN_COST);
15079   format %{ &quot;fastlock $object,$box\t! kills $tmp,$tmp2&quot; %}
15080 
15081   ins_encode(aarch64_enc_fast_lock(object, box, tmp, tmp2));
15082 
15083   ins_pipe(pipe_serial);
15084 %}
15085 
15086 instruct cmpFastUnlock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15087 %{
15088   match(Set cr (FastUnlock object box));
15089   effect(TEMP tmp, TEMP tmp2);
15090 
15091   ins_cost(5 * INSN_COST);
15092   format %{ &quot;fastunlock $object,$box\t! kills $tmp, $tmp2&quot; %}
15093 
15094   ins_encode(aarch64_enc_fast_unlock(object, box, tmp, tmp2));
15095 
15096   ins_pipe(pipe_serial);
15097 %}
15098 
15099 
15100 // ============================================================================
15101 // Safepoint Instructions
15102 
15103 // TODO
15104 // provide a near and far version of this code
15105 
15106 instruct safePoint(rFlagsReg cr, iRegP poll)
15107 %{
15108   match(SafePoint poll);
15109   effect(KILL cr);
15110 
15111   format %{
15112     &quot;ldrw zr, [$poll]\t# Safepoint: poll for GC&quot;
15113   %}
15114   ins_encode %{
15115     __ read_polling_page(as_Register($poll$$reg), relocInfo::poll_type);
15116   %}
15117   ins_pipe(pipe_serial); // ins_pipe(iload_reg_mem);
15118 %}
15119 
15120 
15121 // ============================================================================
15122 // Procedure Call/Return Instructions
15123 
15124 // Call Java Static Instruction
15125 
15126 instruct CallStaticJavaDirect(method meth)
15127 %{
15128   match(CallStaticJava);
15129 
15130   effect(USE meth);
15131 
15132   ins_cost(CALL_COST);
15133 
15134   format %{ &quot;call,static $meth \t// ==&gt; &quot; %}
15135 
15136   ins_encode( aarch64_enc_java_static_call(meth),
15137               aarch64_enc_call_epilog );
15138 
15139   ins_pipe(pipe_class_call);
15140 %}
15141 
15142 // TO HERE
15143 
15144 // Call Java Dynamic Instruction
15145 instruct CallDynamicJavaDirect(method meth)
15146 %{
15147   match(CallDynamicJava);
15148 
15149   effect(USE meth);
15150 
15151   ins_cost(CALL_COST);
15152 
15153   format %{ &quot;CALL,dynamic $meth \t// ==&gt; &quot; %}
15154 
15155   ins_encode( aarch64_enc_java_dynamic_call(meth),
15156                aarch64_enc_call_epilog );
15157 
15158   ins_pipe(pipe_class_call);
15159 %}
15160 
15161 // Call Runtime Instruction
15162 
15163 instruct CallRuntimeDirect(method meth)
15164 %{
15165   match(CallRuntime);
15166 
15167   effect(USE meth);
15168 
15169   ins_cost(CALL_COST);
15170 
15171   format %{ &quot;CALL, runtime $meth&quot; %}
15172 
15173   ins_encode( aarch64_enc_java_to_runtime(meth) );
15174 
15175   ins_pipe(pipe_class_call);
15176 %}
15177 
15178 // Call Runtime Instruction
15179 
15180 instruct CallLeafDirect(method meth)
15181 %{
15182   match(CallLeaf);
15183 
15184   effect(USE meth);
15185 
15186   ins_cost(CALL_COST);
15187 
15188   format %{ &quot;CALL, runtime leaf $meth&quot; %}
15189 
15190   ins_encode( aarch64_enc_java_to_runtime(meth) );
15191 
15192   ins_pipe(pipe_class_call);
15193 %}
15194 
15195 // Call Runtime Instruction
15196 
15197 instruct CallLeafNoFPDirect(method meth)
15198 %{
15199   match(CallLeafNoFP);
15200 
15201   effect(USE meth);
15202 
15203   ins_cost(CALL_COST);
15204 
15205   format %{ &quot;CALL, runtime leaf nofp $meth&quot; %}
15206 
15207   ins_encode( aarch64_enc_java_to_runtime(meth) );
15208 
15209   ins_pipe(pipe_class_call);
15210 %}
15211 
15212 // Tail Call; Jump from runtime stub to Java code.
15213 // Also known as an &#39;interprocedural jump&#39;.
15214 // Target of jump will eventually return to caller.
15215 // TailJump below removes the return address.
15216 instruct TailCalljmpInd(iRegPNoSp jump_target, inline_cache_RegP method_oop)
15217 %{
15218   match(TailCall jump_target method_oop);
15219 
15220   ins_cost(CALL_COST);
15221 
15222   format %{ &quot;br $jump_target\t# $method_oop holds method oop&quot; %}
15223 
15224   ins_encode(aarch64_enc_tail_call(jump_target));
15225 
15226   ins_pipe(pipe_class_call);
15227 %}
15228 
15229 instruct TailjmpInd(iRegPNoSp jump_target, iRegP_R0 ex_oop)
15230 %{
15231   match(TailJump jump_target ex_oop);
15232 
15233   ins_cost(CALL_COST);
15234 
15235   format %{ &quot;br $jump_target\t# $ex_oop holds exception oop&quot; %}
15236 
15237   ins_encode(aarch64_enc_tail_jmp(jump_target));
15238 
15239   ins_pipe(pipe_class_call);
15240 %}
15241 
15242 // Create exception oop: created by stack-crawling runtime code.
15243 // Created exception is now available to this handler, and is setup
15244 // just prior to jumping to this handler. No code emitted.
15245 // TODO check
15246 // should ex_oop be in r0? intel uses rax, ppc cannot use r0 so uses rarg1
15247 instruct CreateException(iRegP_R0 ex_oop)
15248 %{
15249   match(Set ex_oop (CreateEx));
15250 
15251   format %{ &quot; -- \t// exception oop; no code emitted&quot; %}
15252 
15253   size(0);
15254 
15255   ins_encode( /*empty*/ );
15256 
15257   ins_pipe(pipe_class_empty);
15258 %}
15259 
15260 // Rethrow exception: The exception oop will come in the first
15261 // argument position. Then JUMP (not call) to the rethrow stub code.
15262 instruct RethrowException() %{
15263   match(Rethrow);
15264   ins_cost(CALL_COST);
15265 
15266   format %{ &quot;b rethrow_stub&quot; %}
15267 
15268   ins_encode( aarch64_enc_rethrow() );
15269 
15270   ins_pipe(pipe_class_call);
15271 %}
15272 
15273 
15274 // Return Instruction
15275 // epilog node loads ret address into lr as part of frame pop
15276 instruct Ret()
15277 %{
15278   match(Return);
15279 
15280   format %{ &quot;ret\t// return register&quot; %}
15281 
15282   ins_encode( aarch64_enc_ret() );
15283 
15284   ins_pipe(pipe_branch);
15285 %}
15286 
15287 // Die now.
15288 instruct ShouldNotReachHere() %{
15289   match(Halt);
15290 
15291   ins_cost(CALL_COST);
15292   format %{ &quot;ShouldNotReachHere&quot; %}
15293 
15294   ins_encode %{
15295     if (is_reachable()) {
15296       __ stop(_halt_reason);
15297     }
15298   %}
15299 
15300   ins_pipe(pipe_class_default);
15301 %}
15302 
15303 // ============================================================================
15304 // Partial Subtype Check
15305 //
15306 // superklass array for an instance of the superklass.  Set a hidden
15307 // internal cache on a hit (cache is checked with exposed code in
15308 // gen_subtype_check()).  Return NZ for a miss or zero for a hit.  The
15309 // encoding ALSO sets flags.
15310 
15311 instruct partialSubtypeCheck(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, rFlagsReg cr)
15312 %{
15313   match(Set result (PartialSubtypeCheck sub super));
15314   effect(KILL cr, KILL temp);
15315 
15316   ins_cost(1100);  // slightly larger than the next version
15317   format %{ &quot;partialSubtypeCheck $result, $sub, $super&quot; %}
15318 
15319   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15320 
15321   opcode(0x1); // Force zero of result reg on hit
15322 
15323   ins_pipe(pipe_class_memory);
15324 %}
15325 
15326 instruct partialSubtypeCheckVsZero(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, immP0 zero, rFlagsReg cr)
15327 %{
15328   match(Set cr (CmpP (PartialSubtypeCheck sub super) zero));
15329   effect(KILL temp, KILL result);
15330 
15331   ins_cost(1100);  // slightly larger than the next version
15332   format %{ &quot;partialSubtypeCheck $result, $sub, $super == 0&quot; %}
15333 
15334   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15335 
15336   opcode(0x0); // Don&#39;t zero result reg on hit
15337 
15338   ins_pipe(pipe_class_memory);
15339 %}
15340 
15341 instruct string_compareU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15342                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15343 %{
15344   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15345   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15346   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15347 
15348   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15349   ins_encode %{
15350     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15351     __ string_compare($str1$$Register, $str2$$Register,
15352                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15353                       $tmp1$$Register, $tmp2$$Register,
15354                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::UU);
15355   %}
15356   ins_pipe(pipe_class_memory);
15357 %}
15358 
15359 instruct string_compareL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15360                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15361 %{
15362   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15363   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15364   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15365 
15366   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15367   ins_encode %{
15368     __ string_compare($str1$$Register, $str2$$Register,
15369                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15370                       $tmp1$$Register, $tmp2$$Register,
15371                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::LL);
15372   %}
15373   ins_pipe(pipe_class_memory);
15374 %}
15375 
15376 instruct string_compareUL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15377                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15378                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15379 %{
15380   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15381   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15382   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15383          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15384 
15385   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15386   ins_encode %{
15387     __ string_compare($str1$$Register, $str2$$Register,
15388                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15389                       $tmp1$$Register, $tmp2$$Register,
15390                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15391                       $vtmp3$$FloatRegister, StrIntrinsicNode::UL);
15392   %}
15393   ins_pipe(pipe_class_memory);
15394 %}
15395 
15396 instruct string_compareLU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15397                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15398                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15399 %{
15400   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LU);
15401   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15402   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15403          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15404 
15405   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15406   ins_encode %{
15407     __ string_compare($str1$$Register, $str2$$Register,
15408                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15409                       $tmp1$$Register, $tmp2$$Register,
15410                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15411                       $vtmp3$$FloatRegister,StrIntrinsicNode::LU);
15412   %}
15413   ins_pipe(pipe_class_memory);
15414 %}
15415 
15416 instruct string_indexofUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15417        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15418        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15419 %{
15420   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15421   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15422   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15423          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15424   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UU)&quot; %}
15425 
15426   ins_encode %{
15427     __ string_indexof($str1$$Register, $str2$$Register,
15428                       $cnt1$$Register, $cnt2$$Register,
15429                       $tmp1$$Register, $tmp2$$Register,
15430                       $tmp3$$Register, $tmp4$$Register,
15431                       $tmp5$$Register, $tmp6$$Register,
15432                       -1, $result$$Register, StrIntrinsicNode::UU);
15433   %}
15434   ins_pipe(pipe_class_memory);
15435 %}
15436 
15437 instruct string_indexofLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15438        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15439        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15440 %{
15441   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15442   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15443   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15444          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15445   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (LL)&quot; %}
15446 
15447   ins_encode %{
15448     __ string_indexof($str1$$Register, $str2$$Register,
15449                       $cnt1$$Register, $cnt2$$Register,
15450                       $tmp1$$Register, $tmp2$$Register,
15451                       $tmp3$$Register, $tmp4$$Register,
15452                       $tmp5$$Register, $tmp6$$Register,
15453                       -1, $result$$Register, StrIntrinsicNode::LL);
15454   %}
15455   ins_pipe(pipe_class_memory);
15456 %}
15457 
15458 instruct string_indexofUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15459        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15460        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15461 %{
15462   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15463   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15464   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15465          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15466   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UL)&quot; %}
15467 
15468   ins_encode %{
15469     __ string_indexof($str1$$Register, $str2$$Register,
15470                       $cnt1$$Register, $cnt2$$Register,
15471                       $tmp1$$Register, $tmp2$$Register,
15472                       $tmp3$$Register, $tmp4$$Register,
15473                       $tmp5$$Register, $tmp6$$Register,
15474                       -1, $result$$Register, StrIntrinsicNode::UL);
15475   %}
15476   ins_pipe(pipe_class_memory);
15477 %}
15478 
15479 instruct string_indexof_conUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15480                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15481                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15482 %{
15483   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15484   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15485   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15486          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15487   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UU)&quot; %}
15488 
15489   ins_encode %{
15490     int icnt2 = (int)$int_cnt2$$constant;
15491     __ string_indexof($str1$$Register, $str2$$Register,
15492                       $cnt1$$Register, zr,
15493                       $tmp1$$Register, $tmp2$$Register,
15494                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15495                       icnt2, $result$$Register, StrIntrinsicNode::UU);
15496   %}
15497   ins_pipe(pipe_class_memory);
15498 %}
15499 
15500 instruct string_indexof_conLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15501                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15502                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15503 %{
15504   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15505   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15506   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15507          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15508   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (LL)&quot; %}
15509 
15510   ins_encode %{
15511     int icnt2 = (int)$int_cnt2$$constant;
15512     __ string_indexof($str1$$Register, $str2$$Register,
15513                       $cnt1$$Register, zr,
15514                       $tmp1$$Register, $tmp2$$Register,
15515                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15516                       icnt2, $result$$Register, StrIntrinsicNode::LL);
15517   %}
15518   ins_pipe(pipe_class_memory);
15519 %}
15520 
15521 instruct string_indexof_conUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15522                  immI_1 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15523                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15524 %{
15525   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15526   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15527   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15528          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15529   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UL)&quot; %}
15530 
15531   ins_encode %{
15532     int icnt2 = (int)$int_cnt2$$constant;
15533     __ string_indexof($str1$$Register, $str2$$Register,
15534                       $cnt1$$Register, zr,
15535                       $tmp1$$Register, $tmp2$$Register,
15536                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15537                       icnt2, $result$$Register, StrIntrinsicNode::UL);
15538   %}
15539   ins_pipe(pipe_class_memory);
15540 %}
15541 
15542 instruct string_indexofU_char(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,
15543                               iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15544                               iRegINoSp tmp3, rFlagsReg cr)
15545 %{
15546   match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));
15547   effect(USE_KILL str1, USE_KILL cnt1, USE_KILL ch,
15548          TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15549 
15550   format %{ &quot;String IndexOf char[] $str1,$cnt1,$ch -&gt; $result&quot; %}
15551 
15552   ins_encode %{
15553     __ string_indexof_char($str1$$Register, $cnt1$$Register, $ch$$Register,
15554                            $result$$Register, $tmp1$$Register, $tmp2$$Register,
15555                            $tmp3$$Register);
15556   %}
15557   ins_pipe(pipe_class_memory);
15558 %}
15559 
15560 instruct string_equalsL(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15561                         iRegI_R0 result, rFlagsReg cr)
15562 %{
15563   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15564   match(Set result (StrEquals (Binary str1 str2) cnt));
15565   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15566 
15567   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15568   ins_encode %{
15569     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15570     __ string_equals($str1$$Register, $str2$$Register,
15571                      $result$$Register, $cnt$$Register, 1);
15572   %}
15573   ins_pipe(pipe_class_memory);
15574 %}
15575 
15576 instruct string_equalsU(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15577                         iRegI_R0 result, rFlagsReg cr)
15578 %{
15579   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15580   match(Set result (StrEquals (Binary str1 str2) cnt));
15581   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15582 
15583   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15584   ins_encode %{
15585     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15586     __ string_equals($str1$$Register, $str2$$Register,
15587                      $result$$Register, $cnt$$Register, 2);
15588   %}
15589   ins_pipe(pipe_class_memory);
15590 %}
15591 
15592 instruct array_equalsB(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15593                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15594                        iRegP_R10 tmp, rFlagsReg cr)
15595 %{
15596   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15597   match(Set result (AryEq ary1 ary2));
15598   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15599 
15600   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15601   ins_encode %{
15602     __ arrays_equals($ary1$$Register, $ary2$$Register,
15603                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15604                      $result$$Register, $tmp$$Register, 1);
15605     %}
15606   ins_pipe(pipe_class_memory);
15607 %}
15608 
15609 instruct array_equalsC(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15610                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15611                        iRegP_R10 tmp, rFlagsReg cr)
15612 %{
15613   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15614   match(Set result (AryEq ary1 ary2));
15615   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15616 
15617   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15618   ins_encode %{
15619     __ arrays_equals($ary1$$Register, $ary2$$Register,
15620                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15621                      $result$$Register, $tmp$$Register, 2);
15622   %}
15623   ins_pipe(pipe_class_memory);
15624 %}
15625 
15626 instruct has_negatives(iRegP_R1 ary1, iRegI_R2 len, iRegI_R0 result, rFlagsReg cr)
15627 %{
15628   match(Set result (HasNegatives ary1 len));
15629   effect(USE_KILL ary1, USE_KILL len, KILL cr);
15630   format %{ &quot;has negatives byte[] $ary1,$len -&gt; $result&quot; %}
15631   ins_encode %{
15632     __ has_negatives($ary1$$Register, $len$$Register, $result$$Register);
15633   %}
15634   ins_pipe( pipe_slow );
15635 %}
15636 
15637 // fast char[] to byte[] compression
15638 instruct string_compress(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15639                          vRegD_V0 tmp1, vRegD_V1 tmp2,
15640                          vRegD_V2 tmp3, vRegD_V3 tmp4,
15641                          iRegI_R0 result, rFlagsReg cr)
15642 %{
15643   match(Set result (StrCompressedCopy src (Binary dst len)));
15644   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15645 
15646   format %{ &quot;String Compress $src,$dst -&gt; $result    // KILL R1, R2, R3, R4&quot; %}
15647   ins_encode %{
15648     __ char_array_compress($src$$Register, $dst$$Register, $len$$Register,
15649                            $tmp1$$FloatRegister, $tmp2$$FloatRegister,
15650                            $tmp3$$FloatRegister, $tmp4$$FloatRegister,
15651                            $result$$Register);
15652   %}
15653   ins_pipe( pipe_slow );
15654 %}
15655 
15656 // fast byte[] to char[] inflation
15657 instruct string_inflate(Universe dummy, iRegP_R0 src, iRegP_R1 dst, iRegI_R2 len,
15658                         vRegD_V0 tmp1, vRegD_V1 tmp2, vRegD_V2 tmp3, iRegP_R3 tmp4, rFlagsReg cr)
15659 %{
15660   match(Set dummy (StrInflatedCopy src (Binary dst len)));
15661   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15662 
15663   format %{ &quot;String Inflate $src,$dst    // KILL $tmp1, $tmp2&quot; %}
15664   ins_encode %{
15665     __ byte_array_inflate($src$$Register, $dst$$Register, $len$$Register,
15666                           $tmp1$$FloatRegister, $tmp2$$FloatRegister, $tmp3$$FloatRegister, $tmp4$$Register);
15667   %}
15668   ins_pipe(pipe_class_memory);
15669 %}
15670 
15671 // encode char[] to byte[] in ISO_8859_1
15672 instruct encode_iso_array(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15673                           vRegD_V0 Vtmp1, vRegD_V1 Vtmp2,
15674                           vRegD_V2 Vtmp3, vRegD_V3 Vtmp4,
15675                           iRegI_R0 result, rFlagsReg cr)
15676 %{
15677   match(Set result (EncodeISOArray src (Binary dst len)));
15678   effect(USE_KILL src, USE_KILL dst, USE_KILL len,
15679          KILL Vtmp1, KILL Vtmp2, KILL Vtmp3, KILL Vtmp4, KILL cr);
15680 
15681   format %{ &quot;Encode array $src,$dst,$len -&gt; $result&quot; %}
15682   ins_encode %{
15683     __ encode_iso_array($src$$Register, $dst$$Register, $len$$Register,
15684          $result$$Register, $Vtmp1$$FloatRegister,  $Vtmp2$$FloatRegister,
15685          $Vtmp3$$FloatRegister,  $Vtmp4$$FloatRegister);
15686   %}
15687   ins_pipe( pipe_class_memory );
15688 %}
15689 
15690 // ============================================================================
15691 // This name is KNOWN by the ADLC and cannot be changed.
15692 // The ADLC forces a &#39;TypeRawPtr::BOTTOM&#39; output type
15693 // for this guy.
15694 instruct tlsLoadP(thread_RegP dst)
15695 %{
15696   match(Set dst (ThreadLocal));
15697 
15698   ins_cost(0);
15699 
15700   format %{ &quot; -- \t// $dst=Thread::current(), empty&quot; %}
15701 
15702   size(0);
15703 
15704   ins_encode( /*empty*/ );
15705 
15706   ins_pipe(pipe_class_empty);
15707 %}
15708 
15709 // ====================VECTOR INSTRUCTIONS=====================================
15710 
15711 // Load vector (32 bits)
15712 instruct loadV4(vecD dst, vmem4 mem)
15713 %{
15714   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 4);
15715   match(Set dst (LoadVector mem));
15716   ins_cost(4 * INSN_COST);
15717   format %{ &quot;ldrs   $dst,$mem\t# vector (32 bits)&quot; %}
15718   ins_encode( aarch64_enc_ldrvS(dst, mem) );
15719   ins_pipe(vload_reg_mem64);
15720 %}
15721 
15722 // Load vector (64 bits)
15723 instruct loadV8(vecD dst, vmem8 mem)
15724 %{
15725   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 8);
15726   match(Set dst (LoadVector mem));
15727   ins_cost(4 * INSN_COST);
15728   format %{ &quot;ldrd   $dst,$mem\t# vector (64 bits)&quot; %}
15729   ins_encode( aarch64_enc_ldrvD(dst, mem) );
15730   ins_pipe(vload_reg_mem64);
15731 %}
15732 
15733 // Load Vector (128 bits)
15734 instruct loadV16(vecX dst, vmem16 mem)
15735 %{
15736   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 16);
15737   match(Set dst (LoadVector mem));
15738   ins_cost(4 * INSN_COST);
15739   format %{ &quot;ldrq   $dst,$mem\t# vector (128 bits)&quot; %}
15740   ins_encode( aarch64_enc_ldrvQ(dst, mem) );
15741   ins_pipe(vload_reg_mem128);
15742 %}
15743 
15744 // Store Vector (32 bits)
15745 instruct storeV4(vecD src, vmem4 mem)
15746 %{
15747   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 4);
15748   match(Set mem (StoreVector mem src));
15749   ins_cost(4 * INSN_COST);
15750   format %{ &quot;strs   $mem,$src\t# vector (32 bits)&quot; %}
15751   ins_encode( aarch64_enc_strvS(src, mem) );
15752   ins_pipe(vstore_reg_mem64);
15753 %}
15754 
15755 // Store Vector (64 bits)
15756 instruct storeV8(vecD src, vmem8 mem)
15757 %{
15758   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 8);
15759   match(Set mem (StoreVector mem src));
15760   ins_cost(4 * INSN_COST);
15761   format %{ &quot;strd   $mem,$src\t# vector (64 bits)&quot; %}
15762   ins_encode( aarch64_enc_strvD(src, mem) );
15763   ins_pipe(vstore_reg_mem64);
15764 %}
15765 
15766 // Store Vector (128 bits)
15767 instruct storeV16(vecX src, vmem16 mem)
15768 %{
15769   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 16);
15770   match(Set mem (StoreVector mem src));
15771   ins_cost(4 * INSN_COST);
15772   format %{ &quot;strq   $mem,$src\t# vector (128 bits)&quot; %}
15773   ins_encode( aarch64_enc_strvQ(src, mem) );
15774   ins_pipe(vstore_reg_mem128);
15775 %}
15776 
15777 instruct replicate8B(vecD dst, iRegIorL2I src)
15778 %{
15779   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15780             n-&gt;as_Vector()-&gt;length() == 8);
15781   match(Set dst (ReplicateB src));
15782   ins_cost(INSN_COST);
15783   format %{ &quot;dup  $dst, $src\t# vector (8B)&quot; %}
15784   ins_encode %{
15785     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($src$$reg));
15786   %}
15787   ins_pipe(vdup_reg_reg64);
15788 %}
15789 
15790 instruct replicate16B(vecX dst, iRegIorL2I src)
15791 %{
15792   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15793   match(Set dst (ReplicateB src));
15794   ins_cost(INSN_COST);
15795   format %{ &quot;dup  $dst, $src\t# vector (16B)&quot; %}
15796   ins_encode %{
15797     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($src$$reg));
15798   %}
15799   ins_pipe(vdup_reg_reg128);
15800 %}
15801 
15802 instruct replicate8B_imm(vecD dst, immI con)
15803 %{
15804   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15805             n-&gt;as_Vector()-&gt;length() == 8);
15806   match(Set dst (ReplicateB con));
15807   ins_cost(INSN_COST);
15808   format %{ &quot;movi  $dst, $con\t# vector(8B)&quot; %}
15809   ins_encode %{
15810     __ mov(as_FloatRegister($dst$$reg), __ T8B, $con$$constant &amp; 0xff);
15811   %}
15812   ins_pipe(vmovi_reg_imm64);
15813 %}
15814 
15815 instruct replicate16B_imm(vecX dst, immI con)
15816 %{
15817   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15818   match(Set dst (ReplicateB con));
15819   ins_cost(INSN_COST);
15820   format %{ &quot;movi  $dst, $con\t# vector(16B)&quot; %}
15821   ins_encode %{
15822     __ mov(as_FloatRegister($dst$$reg), __ T16B, $con$$constant &amp; 0xff);
15823   %}
15824   ins_pipe(vmovi_reg_imm128);
15825 %}
15826 
15827 instruct replicate4S(vecD dst, iRegIorL2I src)
15828 %{
15829   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15830             n-&gt;as_Vector()-&gt;length() == 4);
15831   match(Set dst (ReplicateS src));
15832   ins_cost(INSN_COST);
15833   format %{ &quot;dup  $dst, $src\t# vector (4S)&quot; %}
15834   ins_encode %{
15835     __ dup(as_FloatRegister($dst$$reg), __ T4H, as_Register($src$$reg));
15836   %}
15837   ins_pipe(vdup_reg_reg64);
15838 %}
15839 
15840 instruct replicate8S(vecX dst, iRegIorL2I src)
15841 %{
15842   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15843   match(Set dst (ReplicateS src));
15844   ins_cost(INSN_COST);
15845   format %{ &quot;dup  $dst, $src\t# vector (8S)&quot; %}
15846   ins_encode %{
15847     __ dup(as_FloatRegister($dst$$reg), __ T8H, as_Register($src$$reg));
15848   %}
15849   ins_pipe(vdup_reg_reg128);
15850 %}
15851 
15852 instruct replicate4S_imm(vecD dst, immI con)
15853 %{
15854   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15855             n-&gt;as_Vector()-&gt;length() == 4);
15856   match(Set dst (ReplicateS con));
15857   ins_cost(INSN_COST);
15858   format %{ &quot;movi  $dst, $con\t# vector(4H)&quot; %}
15859   ins_encode %{
15860     __ mov(as_FloatRegister($dst$$reg), __ T4H, $con$$constant &amp; 0xffff);
15861   %}
15862   ins_pipe(vmovi_reg_imm64);
15863 %}
15864 
15865 instruct replicate8S_imm(vecX dst, immI con)
15866 %{
15867   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15868   match(Set dst (ReplicateS con));
15869   ins_cost(INSN_COST);
15870   format %{ &quot;movi  $dst, $con\t# vector(8H)&quot; %}
15871   ins_encode %{
15872     __ mov(as_FloatRegister($dst$$reg), __ T8H, $con$$constant &amp; 0xffff);
15873   %}
15874   ins_pipe(vmovi_reg_imm128);
15875 %}
15876 
15877 instruct replicate2I(vecD dst, iRegIorL2I src)
15878 %{
15879   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15880   match(Set dst (ReplicateI src));
15881   ins_cost(INSN_COST);
15882   format %{ &quot;dup  $dst, $src\t# vector (2I)&quot; %}
15883   ins_encode %{
15884     __ dup(as_FloatRegister($dst$$reg), __ T2S, as_Register($src$$reg));
15885   %}
15886   ins_pipe(vdup_reg_reg64);
15887 %}
15888 
15889 instruct replicate4I(vecX dst, iRegIorL2I src)
15890 %{
15891   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15892   match(Set dst (ReplicateI src));
15893   ins_cost(INSN_COST);
15894   format %{ &quot;dup  $dst, $src\t# vector (4I)&quot; %}
15895   ins_encode %{
15896     __ dup(as_FloatRegister($dst$$reg), __ T4S, as_Register($src$$reg));
15897   %}
15898   ins_pipe(vdup_reg_reg128);
15899 %}
15900 
15901 instruct replicate2I_imm(vecD dst, immI con)
15902 %{
15903   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15904   match(Set dst (ReplicateI con));
15905   ins_cost(INSN_COST);
15906   format %{ &quot;movi  $dst, $con\t# vector(2I)&quot; %}
15907   ins_encode %{
15908     __ mov(as_FloatRegister($dst$$reg), __ T2S, $con$$constant);
15909   %}
15910   ins_pipe(vmovi_reg_imm64);
15911 %}
15912 
15913 instruct replicate4I_imm(vecX dst, immI con)
15914 %{
15915   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15916   match(Set dst (ReplicateI con));
15917   ins_cost(INSN_COST);
15918   format %{ &quot;movi  $dst, $con\t# vector(4I)&quot; %}
15919   ins_encode %{
15920     __ mov(as_FloatRegister($dst$$reg), __ T4S, $con$$constant);
15921   %}
15922   ins_pipe(vmovi_reg_imm128);
15923 %}
15924 
15925 instruct replicate2L(vecX dst, iRegL src)
15926 %{
15927   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15928   match(Set dst (ReplicateL src));
15929   ins_cost(INSN_COST);
15930   format %{ &quot;dup  $dst, $src\t# vector (2L)&quot; %}
15931   ins_encode %{
15932     __ dup(as_FloatRegister($dst$$reg), __ T2D, as_Register($src$$reg));
15933   %}
15934   ins_pipe(vdup_reg_reg128);
15935 %}
15936 
15937 instruct replicate2L_zero(vecX dst, immI0 zero)
15938 %{
15939   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15940   match(Set dst (ReplicateI zero));
15941   ins_cost(INSN_COST);
15942   format %{ &quot;movi  $dst, $zero\t# vector(4I)&quot; %}
15943   ins_encode %{
15944     __ eor(as_FloatRegister($dst$$reg), __ T16B,
15945            as_FloatRegister($dst$$reg),
15946            as_FloatRegister($dst$$reg));
15947   %}
15948   ins_pipe(vmovi_reg_imm128);
15949 %}
15950 
15951 instruct replicate2F(vecD dst, vRegF src)
15952 %{
15953   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15954   match(Set dst (ReplicateF src));
15955   ins_cost(INSN_COST);
15956   format %{ &quot;dup  $dst, $src\t# vector (2F)&quot; %}
15957   ins_encode %{
15958     __ dup(as_FloatRegister($dst$$reg), __ T2S,
15959            as_FloatRegister($src$$reg));
15960   %}
15961   ins_pipe(vdup_reg_freg64);
15962 %}
15963 
15964 instruct replicate4F(vecX dst, vRegF src)
15965 %{
15966   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15967   match(Set dst (ReplicateF src));
15968   ins_cost(INSN_COST);
15969   format %{ &quot;dup  $dst, $src\t# vector (4F)&quot; %}
15970   ins_encode %{
15971     __ dup(as_FloatRegister($dst$$reg), __ T4S,
15972            as_FloatRegister($src$$reg));
15973   %}
15974   ins_pipe(vdup_reg_freg128);
15975 %}
15976 
15977 instruct replicate2D(vecX dst, vRegD src)
15978 %{
15979   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15980   match(Set dst (ReplicateD src));
15981   ins_cost(INSN_COST);
15982   format %{ &quot;dup  $dst, $src\t# vector (2D)&quot; %}
15983   ins_encode %{
15984     __ dup(as_FloatRegister($dst$$reg), __ T2D,
15985            as_FloatRegister($src$$reg));
15986   %}
15987   ins_pipe(vdup_reg_dreg128);
15988 %}
15989 
15990 // ====================REDUCTION ARITHMETIC====================================
15991 
15992 instruct reduce_add2I(iRegINoSp dst, iRegIorL2I isrc, vecD vsrc, iRegINoSp tmp, iRegINoSp tmp2)
15993 %{
15994   match(Set dst (AddReductionVI isrc vsrc));
15995   ins_cost(INSN_COST);
15996   effect(TEMP tmp, TEMP tmp2);
15997   format %{ &quot;umov  $tmp, $vsrc, S, 0\n\t&quot;
15998             &quot;umov  $tmp2, $vsrc, S, 1\n\t&quot;
15999             &quot;addw  $tmp, $isrc, $tmp\n\t&quot;
16000             &quot;addw  $dst, $tmp, $tmp2\t# add reduction2I&quot;
16001   %}
16002   ins_encode %{
16003     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 0);
16004     __ umov($tmp2$$Register, as_FloatRegister($vsrc$$reg), __ S, 1);
16005     __ addw($tmp$$Register, $isrc$$Register, $tmp$$Register);
16006     __ addw($dst$$Register, $tmp$$Register, $tmp2$$Register);
16007   %}
16008   ins_pipe(pipe_class_default);
16009 %}
16010 
16011 instruct reduce_add4I(iRegINoSp dst, iRegIorL2I isrc, vecX vsrc, vecX vtmp, iRegINoSp itmp)
16012 %{
16013   match(Set dst (AddReductionVI isrc vsrc));
16014   ins_cost(INSN_COST);
16015   effect(TEMP vtmp, TEMP itmp);
16016   format %{ &quot;addv  $vtmp, T4S, $vsrc\n\t&quot;
16017             &quot;umov  $itmp, $vtmp, S, 0\n\t&quot;
16018             &quot;addw  $dst, $itmp, $isrc\t# add reduction4I&quot;
16019   %}
16020   ins_encode %{
16021     __ addv(as_FloatRegister($vtmp$$reg), __ T4S,
16022             as_FloatRegister($vsrc$$reg));
16023     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 0);
16024     __ addw($dst$$Register, $itmp$$Register, $isrc$$Register);
16025   %}
16026   ins_pipe(pipe_class_default);
16027 %}
16028 
16029 instruct reduce_mul2I(iRegINoSp dst, iRegIorL2I isrc, vecD vsrc, iRegINoSp tmp)
16030 %{
16031   match(Set dst (MulReductionVI isrc vsrc));
16032   ins_cost(INSN_COST);
16033   effect(TEMP tmp, TEMP dst);
16034   format %{ &quot;umov  $tmp, $vsrc, S, 0\n\t&quot;
16035             &quot;mul   $dst, $tmp, $isrc\n\t&quot;
16036             &quot;umov  $tmp, $vsrc, S, 1\n\t&quot;
16037             &quot;mul   $dst, $tmp, $dst\t# mul reduction2I&quot;
16038   %}
16039   ins_encode %{
16040     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 0);
16041     __ mul($dst$$Register, $tmp$$Register, $isrc$$Register);
16042     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 1);
16043     __ mul($dst$$Register, $tmp$$Register, $dst$$Register);
16044   %}
16045   ins_pipe(pipe_class_default);
16046 %}
16047 
16048 instruct reduce_mul4I(iRegINoSp dst, iRegIorL2I isrc, vecX vsrc, vecX vtmp, iRegINoSp itmp)
16049 %{
16050   match(Set dst (MulReductionVI isrc vsrc));
16051   ins_cost(INSN_COST);
16052   effect(TEMP vtmp, TEMP itmp, TEMP dst);
16053   format %{ &quot;ins   $vtmp, D, $vsrc, 0, 1\n\t&quot;
16054             &quot;mulv  $vtmp, T2S, $vtmp, $vsrc\n\t&quot;
16055             &quot;umov  $itmp, $vtmp, S, 0\n\t&quot;
16056             &quot;mul   $dst, $itmp, $isrc\n\t&quot;
16057             &quot;umov  $itmp, $vtmp, S, 1\n\t&quot;
16058             &quot;mul   $dst, $itmp, $dst\t# mul reduction4I&quot;
16059   %}
16060   ins_encode %{
16061     __ ins(as_FloatRegister($vtmp$$reg), __ D,
16062            as_FloatRegister($vsrc$$reg), 0, 1);
16063     __ mulv(as_FloatRegister($vtmp$$reg), __ T2S,
16064             as_FloatRegister($vtmp$$reg), as_FloatRegister($vsrc$$reg));
16065     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 0);
16066     __ mul($dst$$Register, $itmp$$Register, $isrc$$Register);
16067     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 1);
16068     __ mul($dst$$Register, $itmp$$Register, $dst$$Register);
16069   %}
16070   ins_pipe(pipe_class_default);
16071 %}
16072 
16073 instruct reduce_add2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp)
16074 %{
16075   match(Set dst (AddReductionVF fsrc vsrc));
16076   ins_cost(INSN_COST);
16077   effect(TEMP tmp, TEMP dst);
16078   format %{ &quot;fadds $dst, $fsrc, $vsrc\n\t&quot;
16079             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16080             &quot;fadds $dst, $dst, $tmp\t# add reduction2F&quot;
16081   %}
16082   ins_encode %{
16083     __ fadds(as_FloatRegister($dst$$reg),
16084              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16085     __ ins(as_FloatRegister($tmp$$reg), __ S,
16086            as_FloatRegister($vsrc$$reg), 0, 1);
16087     __ fadds(as_FloatRegister($dst$$reg),
16088              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16089   %}
16090   ins_pipe(pipe_class_default);
16091 %}
16092 
16093 instruct reduce_add4F(vRegF dst, vRegF fsrc, vecX vsrc, vecX tmp)
16094 %{
16095   match(Set dst (AddReductionVF fsrc vsrc));
16096   ins_cost(INSN_COST);
16097   effect(TEMP tmp, TEMP dst);
16098   format %{ &quot;fadds $dst, $fsrc, $vsrc\n\t&quot;
16099             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16100             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16101             &quot;ins   $tmp, S, $vsrc, 0, 2\n\t&quot;
16102             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16103             &quot;ins   $tmp, S, $vsrc, 0, 3\n\t&quot;
16104             &quot;fadds $dst, $dst, $tmp\t# add reduction4F&quot;
16105   %}
16106   ins_encode %{
16107     __ fadds(as_FloatRegister($dst$$reg),
16108              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16109     __ ins(as_FloatRegister($tmp$$reg), __ S,
16110            as_FloatRegister($vsrc$$reg), 0, 1);
16111     __ fadds(as_FloatRegister($dst$$reg),
16112              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16113     __ ins(as_FloatRegister($tmp$$reg), __ S,
16114            as_FloatRegister($vsrc$$reg), 0, 2);
16115     __ fadds(as_FloatRegister($dst$$reg),
16116              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16117     __ ins(as_FloatRegister($tmp$$reg), __ S,
16118            as_FloatRegister($vsrc$$reg), 0, 3);
16119     __ fadds(as_FloatRegister($dst$$reg),
16120              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16121   %}
16122   ins_pipe(pipe_class_default);
16123 %}
16124 
16125 instruct reduce_mul2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp)
16126 %{
16127   match(Set dst (MulReductionVF fsrc vsrc));
16128   ins_cost(INSN_COST);
16129   effect(TEMP tmp, TEMP dst);
16130   format %{ &quot;fmuls $dst, $fsrc, $vsrc\n\t&quot;
16131             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16132             &quot;fmuls $dst, $dst, $tmp\t# mul reduction2F&quot;
16133   %}
16134   ins_encode %{
16135     __ fmuls(as_FloatRegister($dst$$reg),
16136              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16137     __ ins(as_FloatRegister($tmp$$reg), __ S,
16138            as_FloatRegister($vsrc$$reg), 0, 1);
16139     __ fmuls(as_FloatRegister($dst$$reg),
16140              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16141   %}
16142   ins_pipe(pipe_class_default);
16143 %}
16144 
16145 instruct reduce_mul4F(vRegF dst, vRegF fsrc, vecX vsrc, vecX tmp)
16146 %{
16147   match(Set dst (MulReductionVF fsrc vsrc));
16148   ins_cost(INSN_COST);
16149   effect(TEMP tmp, TEMP dst);
16150   format %{ &quot;fmuls $dst, $fsrc, $vsrc\n\t&quot;
16151             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16152             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16153             &quot;ins   $tmp, S, $vsrc, 0, 2\n\t&quot;
16154             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16155             &quot;ins   $tmp, S, $vsrc, 0, 3\n\t&quot;
16156             &quot;fmuls $dst, $dst, $tmp\t# mul reduction4F&quot;
16157   %}
16158   ins_encode %{
16159     __ fmuls(as_FloatRegister($dst$$reg),
16160              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16161     __ ins(as_FloatRegister($tmp$$reg), __ S,
16162            as_FloatRegister($vsrc$$reg), 0, 1);
16163     __ fmuls(as_FloatRegister($dst$$reg),
16164              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16165     __ ins(as_FloatRegister($tmp$$reg), __ S,
16166            as_FloatRegister($vsrc$$reg), 0, 2);
16167     __ fmuls(as_FloatRegister($dst$$reg),
16168              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16169     __ ins(as_FloatRegister($tmp$$reg), __ S,
16170            as_FloatRegister($vsrc$$reg), 0, 3);
16171     __ fmuls(as_FloatRegister($dst$$reg),
16172              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16173   %}
16174   ins_pipe(pipe_class_default);
16175 %}
16176 
16177 instruct reduce_add2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp)
16178 %{
16179   match(Set dst (AddReductionVD dsrc vsrc));
16180   ins_cost(INSN_COST);
16181   effect(TEMP tmp, TEMP dst);
16182   format %{ &quot;faddd $dst, $dsrc, $vsrc\n\t&quot;
16183             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16184             &quot;faddd $dst, $dst, $tmp\t# add reduction2D&quot;
16185   %}
16186   ins_encode %{
16187     __ faddd(as_FloatRegister($dst$$reg),
16188              as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16189     __ ins(as_FloatRegister($tmp$$reg), __ D,
16190            as_FloatRegister($vsrc$$reg), 0, 1);
16191     __ faddd(as_FloatRegister($dst$$reg),
16192              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16193   %}
16194   ins_pipe(pipe_class_default);
16195 %}
16196 
16197 instruct reduce_mul2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp)
16198 %{
16199   match(Set dst (MulReductionVD dsrc vsrc));
16200   ins_cost(INSN_COST);
16201   effect(TEMP tmp, TEMP dst);
16202   format %{ &quot;fmuld $dst, $dsrc, $vsrc\n\t&quot;
16203             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16204             &quot;fmuld $dst, $dst, $tmp\t# mul reduction2D&quot;
16205   %}
16206   ins_encode %{
16207     __ fmuld(as_FloatRegister($dst$$reg),
16208              as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16209     __ ins(as_FloatRegister($tmp$$reg), __ D,
16210            as_FloatRegister($vsrc$$reg), 0, 1);
16211     __ fmuld(as_FloatRegister($dst$$reg),
16212              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16213   %}
16214   ins_pipe(pipe_class_default);
16215 %}
16216 
16217 instruct reduce_max2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp) %{
16218   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16219   match(Set dst (MaxReductionV fsrc vsrc));
16220   ins_cost(INSN_COST);
16221   effect(TEMP_DEF dst, TEMP tmp);
16222   format %{ &quot;fmaxs $dst, $fsrc, $vsrc\n\t&quot;
16223             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16224             &quot;fmaxs $dst, $dst, $tmp\t# max reduction2F&quot; %}
16225   ins_encode %{
16226     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16227     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($vsrc$$reg), 0, 1);
16228     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16229   %}
16230   ins_pipe(pipe_class_default);
16231 %}
16232 
16233 instruct reduce_max4F(vRegF dst, vRegF fsrc, vecX vsrc) %{
16234   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16235   match(Set dst (MaxReductionV fsrc vsrc));
16236   ins_cost(INSN_COST);
16237   effect(TEMP_DEF dst);
16238   format %{ &quot;fmaxv $dst, T4S, $vsrc\n\t&quot;
16239             &quot;fmaxs $dst, $dst, $fsrc\t# max reduction4F&quot; %}
16240   ins_encode %{
16241     __ fmaxv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($vsrc$$reg));
16242     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));
16243   %}
16244   ins_pipe(pipe_class_default);
16245 %}
16246 
16247 instruct reduce_max2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp) %{
16248   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16249   match(Set dst (MaxReductionV dsrc vsrc));
16250   ins_cost(INSN_COST);
16251   effect(TEMP_DEF dst, TEMP tmp);
16252   format %{ &quot;fmaxd $dst, $dsrc, $vsrc\n\t&quot;
16253             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16254             &quot;fmaxd $dst, $dst, $tmp\t# max reduction2D&quot; %}
16255   ins_encode %{
16256     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16257     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($vsrc$$reg), 0, 1);
16258     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16259   %}
16260   ins_pipe(pipe_class_default);
16261 %}
16262 
16263 instruct reduce_min2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp) %{
16264   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16265   match(Set dst (MinReductionV fsrc vsrc));
16266   ins_cost(INSN_COST);
16267   effect(TEMP_DEF dst, TEMP tmp);
16268   format %{ &quot;fmins $dst, $fsrc, $vsrc\n\t&quot;
16269             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16270             &quot;fmins $dst, $dst, $tmp\t# min reduction2F&quot; %}
16271   ins_encode %{
16272     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16273     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($vsrc$$reg), 0, 1);
16274     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16275   %}
16276   ins_pipe(pipe_class_default);
16277 %}
16278 
16279 instruct reduce_min4F(vRegF dst, vRegF fsrc, vecX vsrc) %{
16280   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16281   match(Set dst (MinReductionV fsrc vsrc));
16282   ins_cost(INSN_COST);
16283   effect(TEMP_DEF dst);
16284   format %{ &quot;fminv $dst, T4S, $vsrc\n\t&quot;
16285             &quot;fmins $dst, $dst, $fsrc\t# min reduction4F&quot; %}
16286   ins_encode %{
16287     __ fminv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($vsrc$$reg));
16288     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));
16289   %}
16290   ins_pipe(pipe_class_default);
16291 %}
16292 
16293 instruct reduce_min2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp) %{
16294   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16295   match(Set dst (MinReductionV dsrc vsrc));
16296   ins_cost(INSN_COST);
16297   effect(TEMP_DEF dst, TEMP tmp);
16298   format %{ &quot;fmind $dst, $dsrc, $vsrc\n\t&quot;
16299             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16300             &quot;fmind $dst, $dst, $tmp\t# min reduction2D&quot; %}
16301   ins_encode %{
16302     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16303     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($vsrc$$reg), 0, 1);
16304     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16305   %}
16306   ins_pipe(pipe_class_default);
16307 %}
16308 
16309 // ====================VECTOR ARITHMETIC=======================================
16310 
16311 // --------------------------------- ADD --------------------------------------
16312 
16313 instruct vadd8B(vecD dst, vecD src1, vecD src2)
16314 %{
16315   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16316             n-&gt;as_Vector()-&gt;length() == 8);
16317   match(Set dst (AddVB src1 src2));
16318   ins_cost(INSN_COST);
16319   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16320   ins_encode %{
16321     __ addv(as_FloatRegister($dst$$reg), __ T8B,
16322             as_FloatRegister($src1$$reg),
16323             as_FloatRegister($src2$$reg));
16324   %}
16325   ins_pipe(vdop64);
16326 %}
16327 
16328 instruct vadd16B(vecX dst, vecX src1, vecX src2)
16329 %{
16330   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16331   match(Set dst (AddVB src1 src2));
16332   ins_cost(INSN_COST);
16333   format %{ &quot;addv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16334   ins_encode %{
16335     __ addv(as_FloatRegister($dst$$reg), __ T16B,
16336             as_FloatRegister($src1$$reg),
16337             as_FloatRegister($src2$$reg));
16338   %}
16339   ins_pipe(vdop128);
16340 %}
16341 
16342 instruct vadd4S(vecD dst, vecD src1, vecD src2)
16343 %{
16344   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16345             n-&gt;as_Vector()-&gt;length() == 4);
16346   match(Set dst (AddVS src1 src2));
16347   ins_cost(INSN_COST);
16348   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16349   ins_encode %{
16350     __ addv(as_FloatRegister($dst$$reg), __ T4H,
16351             as_FloatRegister($src1$$reg),
16352             as_FloatRegister($src2$$reg));
16353   %}
16354   ins_pipe(vdop64);
16355 %}
16356 
16357 instruct vadd8S(vecX dst, vecX src1, vecX src2)
16358 %{
16359   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16360   match(Set dst (AddVS src1 src2));
16361   ins_cost(INSN_COST);
16362   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16363   ins_encode %{
16364     __ addv(as_FloatRegister($dst$$reg), __ T8H,
16365             as_FloatRegister($src1$$reg),
16366             as_FloatRegister($src2$$reg));
16367   %}
16368   ins_pipe(vdop128);
16369 %}
16370 
16371 instruct vadd2I(vecD dst, vecD src1, vecD src2)
16372 %{
16373   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16374   match(Set dst (AddVI src1 src2));
16375   ins_cost(INSN_COST);
16376   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16377   ins_encode %{
16378     __ addv(as_FloatRegister($dst$$reg), __ T2S,
16379             as_FloatRegister($src1$$reg),
16380             as_FloatRegister($src2$$reg));
16381   %}
16382   ins_pipe(vdop64);
16383 %}
16384 
16385 instruct vadd4I(vecX dst, vecX src1, vecX src2)
16386 %{
16387   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16388   match(Set dst (AddVI src1 src2));
16389   ins_cost(INSN_COST);
16390   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16391   ins_encode %{
16392     __ addv(as_FloatRegister($dst$$reg), __ T4S,
16393             as_FloatRegister($src1$$reg),
16394             as_FloatRegister($src2$$reg));
16395   %}
16396   ins_pipe(vdop128);
16397 %}
16398 
16399 instruct vadd2L(vecX dst, vecX src1, vecX src2)
16400 %{
16401   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16402   match(Set dst (AddVL src1 src2));
16403   ins_cost(INSN_COST);
16404   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16405   ins_encode %{
16406     __ addv(as_FloatRegister($dst$$reg), __ T2D,
16407             as_FloatRegister($src1$$reg),
16408             as_FloatRegister($src2$$reg));
16409   %}
16410   ins_pipe(vdop128);
16411 %}
16412 
16413 instruct vadd2F(vecD dst, vecD src1, vecD src2)
16414 %{
16415   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16416   match(Set dst (AddVF src1 src2));
16417   ins_cost(INSN_COST);
16418   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2S)&quot; %}
16419   ins_encode %{
16420     __ fadd(as_FloatRegister($dst$$reg), __ T2S,
16421             as_FloatRegister($src1$$reg),
16422             as_FloatRegister($src2$$reg));
16423   %}
16424   ins_pipe(vdop_fp64);
16425 %}
16426 
16427 instruct vadd4F(vecX dst, vecX src1, vecX src2)
16428 %{
16429   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16430   match(Set dst (AddVF src1 src2));
16431   ins_cost(INSN_COST);
16432   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (4S)&quot; %}
16433   ins_encode %{
16434     __ fadd(as_FloatRegister($dst$$reg), __ T4S,
16435             as_FloatRegister($src1$$reg),
16436             as_FloatRegister($src2$$reg));
16437   %}
16438   ins_pipe(vdop_fp128);
16439 %}
16440 
16441 instruct vadd2D(vecX dst, vecX src1, vecX src2)
16442 %{
16443   match(Set dst (AddVD src1 src2));
16444   ins_cost(INSN_COST);
16445   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2D)&quot; %}
16446   ins_encode %{
16447     __ fadd(as_FloatRegister($dst$$reg), __ T2D,
16448             as_FloatRegister($src1$$reg),
16449             as_FloatRegister($src2$$reg));
16450   %}
16451   ins_pipe(vdop_fp128);
16452 %}
16453 
16454 // --------------------------------- SUB --------------------------------------
16455 
16456 instruct vsub8B(vecD dst, vecD src1, vecD src2)
16457 %{
16458   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16459             n-&gt;as_Vector()-&gt;length() == 8);
16460   match(Set dst (SubVB src1 src2));
16461   ins_cost(INSN_COST);
16462   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16463   ins_encode %{
16464     __ subv(as_FloatRegister($dst$$reg), __ T8B,
16465             as_FloatRegister($src1$$reg),
16466             as_FloatRegister($src2$$reg));
16467   %}
16468   ins_pipe(vdop64);
16469 %}
16470 
16471 instruct vsub16B(vecX dst, vecX src1, vecX src2)
16472 %{
16473   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16474   match(Set dst (SubVB src1 src2));
16475   ins_cost(INSN_COST);
16476   format %{ &quot;subv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16477   ins_encode %{
16478     __ subv(as_FloatRegister($dst$$reg), __ T16B,
16479             as_FloatRegister($src1$$reg),
16480             as_FloatRegister($src2$$reg));
16481   %}
16482   ins_pipe(vdop128);
16483 %}
16484 
16485 instruct vsub4S(vecD dst, vecD src1, vecD src2)
16486 %{
16487   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16488             n-&gt;as_Vector()-&gt;length() == 4);
16489   match(Set dst (SubVS src1 src2));
16490   ins_cost(INSN_COST);
16491   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16492   ins_encode %{
16493     __ subv(as_FloatRegister($dst$$reg), __ T4H,
16494             as_FloatRegister($src1$$reg),
16495             as_FloatRegister($src2$$reg));
16496   %}
16497   ins_pipe(vdop64);
16498 %}
16499 
16500 instruct vsub8S(vecX dst, vecX src1, vecX src2)
16501 %{
16502   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16503   match(Set dst (SubVS src1 src2));
16504   ins_cost(INSN_COST);
16505   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16506   ins_encode %{
16507     __ subv(as_FloatRegister($dst$$reg), __ T8H,
16508             as_FloatRegister($src1$$reg),
16509             as_FloatRegister($src2$$reg));
16510   %}
16511   ins_pipe(vdop128);
16512 %}
16513 
16514 instruct vsub2I(vecD dst, vecD src1, vecD src2)
16515 %{
16516   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16517   match(Set dst (SubVI src1 src2));
16518   ins_cost(INSN_COST);
16519   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16520   ins_encode %{
16521     __ subv(as_FloatRegister($dst$$reg), __ T2S,
16522             as_FloatRegister($src1$$reg),
16523             as_FloatRegister($src2$$reg));
16524   %}
16525   ins_pipe(vdop64);
16526 %}
16527 
16528 instruct vsub4I(vecX dst, vecX src1, vecX src2)
16529 %{
16530   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16531   match(Set dst (SubVI src1 src2));
16532   ins_cost(INSN_COST);
16533   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16534   ins_encode %{
16535     __ subv(as_FloatRegister($dst$$reg), __ T4S,
16536             as_FloatRegister($src1$$reg),
16537             as_FloatRegister($src2$$reg));
16538   %}
16539   ins_pipe(vdop128);
16540 %}
16541 
16542 instruct vsub2L(vecX dst, vecX src1, vecX src2)
16543 %{
16544   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16545   match(Set dst (SubVL src1 src2));
16546   ins_cost(INSN_COST);
16547   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16548   ins_encode %{
16549     __ subv(as_FloatRegister($dst$$reg), __ T2D,
16550             as_FloatRegister($src1$$reg),
16551             as_FloatRegister($src2$$reg));
16552   %}
16553   ins_pipe(vdop128);
16554 %}
16555 
16556 instruct vsub2F(vecD dst, vecD src1, vecD src2)
16557 %{
16558   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16559   match(Set dst (SubVF src1 src2));
16560   ins_cost(INSN_COST);
16561   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2S)&quot; %}
16562   ins_encode %{
16563     __ fsub(as_FloatRegister($dst$$reg), __ T2S,
16564             as_FloatRegister($src1$$reg),
16565             as_FloatRegister($src2$$reg));
16566   %}
16567   ins_pipe(vdop_fp64);
16568 %}
16569 
16570 instruct vsub4F(vecX dst, vecX src1, vecX src2)
16571 %{
16572   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16573   match(Set dst (SubVF src1 src2));
16574   ins_cost(INSN_COST);
16575   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (4S)&quot; %}
16576   ins_encode %{
16577     __ fsub(as_FloatRegister($dst$$reg), __ T4S,
16578             as_FloatRegister($src1$$reg),
16579             as_FloatRegister($src2$$reg));
16580   %}
16581   ins_pipe(vdop_fp128);
16582 %}
16583 
16584 instruct vsub2D(vecX dst, vecX src1, vecX src2)
16585 %{
16586   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16587   match(Set dst (SubVD src1 src2));
16588   ins_cost(INSN_COST);
16589   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2D)&quot; %}
16590   ins_encode %{
16591     __ fsub(as_FloatRegister($dst$$reg), __ T2D,
16592             as_FloatRegister($src1$$reg),
16593             as_FloatRegister($src2$$reg));
16594   %}
16595   ins_pipe(vdop_fp128);
16596 %}
16597 
16598 // --------------------------------- MUL --------------------------------------
16599 
16600 instruct vmul8B(vecD dst, vecD src1, vecD src2)
16601 %{
16602   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16603             n-&gt;as_Vector()-&gt;length() == 8);
16604   match(Set dst (MulVB src1 src2));
16605   ins_cost(INSN_COST);
16606   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16607   ins_encode %{
16608     __ mulv(as_FloatRegister($dst$$reg), __ T8B,
16609             as_FloatRegister($src1$$reg),
16610             as_FloatRegister($src2$$reg));
16611   %}
16612   ins_pipe(vmul64);
16613 %}
16614 
16615 instruct vmul16B(vecX dst, vecX src1, vecX src2)
16616 %{
16617   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16618   match(Set dst (MulVB src1 src2));
16619   ins_cost(INSN_COST);
16620   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16621   ins_encode %{
16622     __ mulv(as_FloatRegister($dst$$reg), __ T16B,
16623             as_FloatRegister($src1$$reg),
16624             as_FloatRegister($src2$$reg));
16625   %}
16626   ins_pipe(vmul128);
16627 %}
16628 
16629 instruct vmul4S(vecD dst, vecD src1, vecD src2)
16630 %{
16631   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16632             n-&gt;as_Vector()-&gt;length() == 4);
16633   match(Set dst (MulVS src1 src2));
16634   ins_cost(INSN_COST);
16635   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16636   ins_encode %{
16637     __ mulv(as_FloatRegister($dst$$reg), __ T4H,
16638             as_FloatRegister($src1$$reg),
16639             as_FloatRegister($src2$$reg));
16640   %}
16641   ins_pipe(vmul64);
16642 %}
16643 
16644 instruct vmul8S(vecX dst, vecX src1, vecX src2)
16645 %{
16646   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16647   match(Set dst (MulVS src1 src2));
16648   ins_cost(INSN_COST);
16649   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16650   ins_encode %{
16651     __ mulv(as_FloatRegister($dst$$reg), __ T8H,
16652             as_FloatRegister($src1$$reg),
16653             as_FloatRegister($src2$$reg));
16654   %}
16655   ins_pipe(vmul128);
16656 %}
16657 
16658 instruct vmul2I(vecD dst, vecD src1, vecD src2)
16659 %{
16660   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16661   match(Set dst (MulVI src1 src2));
16662   ins_cost(INSN_COST);
16663   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16664   ins_encode %{
16665     __ mulv(as_FloatRegister($dst$$reg), __ T2S,
16666             as_FloatRegister($src1$$reg),
16667             as_FloatRegister($src2$$reg));
16668   %}
16669   ins_pipe(vmul64);
16670 %}
16671 
16672 instruct vmul4I(vecX dst, vecX src1, vecX src2)
16673 %{
16674   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16675   match(Set dst (MulVI src1 src2));
16676   ins_cost(INSN_COST);
16677   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16678   ins_encode %{
16679     __ mulv(as_FloatRegister($dst$$reg), __ T4S,
16680             as_FloatRegister($src1$$reg),
16681             as_FloatRegister($src2$$reg));
16682   %}
16683   ins_pipe(vmul128);
16684 %}
16685 
16686 instruct vmul2F(vecD dst, vecD src1, vecD src2)
16687 %{
16688   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16689   match(Set dst (MulVF src1 src2));
16690   ins_cost(INSN_COST);
16691   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2S)&quot; %}
16692   ins_encode %{
16693     __ fmul(as_FloatRegister($dst$$reg), __ T2S,
16694             as_FloatRegister($src1$$reg),
16695             as_FloatRegister($src2$$reg));
16696   %}
16697   ins_pipe(vmuldiv_fp64);
16698 %}
16699 
16700 instruct vmul4F(vecX dst, vecX src1, vecX src2)
16701 %{
16702   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16703   match(Set dst (MulVF src1 src2));
16704   ins_cost(INSN_COST);
16705   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (4S)&quot; %}
16706   ins_encode %{
16707     __ fmul(as_FloatRegister($dst$$reg), __ T4S,
16708             as_FloatRegister($src1$$reg),
16709             as_FloatRegister($src2$$reg));
16710   %}
16711   ins_pipe(vmuldiv_fp128);
16712 %}
16713 
16714 instruct vmul2D(vecX dst, vecX src1, vecX src2)
16715 %{
16716   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16717   match(Set dst (MulVD src1 src2));
16718   ins_cost(INSN_COST);
16719   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2D)&quot; %}
16720   ins_encode %{
16721     __ fmul(as_FloatRegister($dst$$reg), __ T2D,
16722             as_FloatRegister($src1$$reg),
16723             as_FloatRegister($src2$$reg));
16724   %}
16725   ins_pipe(vmuldiv_fp128);
16726 %}
16727 
16728 // --------------------------------- MLA --------------------------------------
16729 
16730 instruct vmla4S(vecD dst, vecD src1, vecD src2)
16731 %{
16732   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16733             n-&gt;as_Vector()-&gt;length() == 4);
16734   match(Set dst (AddVS dst (MulVS src1 src2)));
16735   ins_cost(INSN_COST);
16736   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4H)&quot; %}
16737   ins_encode %{
16738     __ mlav(as_FloatRegister($dst$$reg), __ T4H,
16739             as_FloatRegister($src1$$reg),
16740             as_FloatRegister($src2$$reg));
16741   %}
16742   ins_pipe(vmla64);
16743 %}
16744 
16745 instruct vmla8S(vecX dst, vecX src1, vecX src2)
16746 %{
16747   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16748   match(Set dst (AddVS dst (MulVS src1 src2)));
16749   ins_cost(INSN_COST);
16750   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (8H)&quot; %}
16751   ins_encode %{
16752     __ mlav(as_FloatRegister($dst$$reg), __ T8H,
16753             as_FloatRegister($src1$$reg),
16754             as_FloatRegister($src2$$reg));
16755   %}
16756   ins_pipe(vmla128);
16757 %}
16758 
16759 instruct vmla2I(vecD dst, vecD src1, vecD src2)
16760 %{
16761   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16762   match(Set dst (AddVI dst (MulVI src1 src2)));
16763   ins_cost(INSN_COST);
16764   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (2S)&quot; %}
16765   ins_encode %{
16766     __ mlav(as_FloatRegister($dst$$reg), __ T2S,
16767             as_FloatRegister($src1$$reg),
16768             as_FloatRegister($src2$$reg));
16769   %}
16770   ins_pipe(vmla64);
16771 %}
16772 
16773 instruct vmla4I(vecX dst, vecX src1, vecX src2)
16774 %{
16775   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16776   match(Set dst (AddVI dst (MulVI src1 src2)));
16777   ins_cost(INSN_COST);
16778   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4S)&quot; %}
16779   ins_encode %{
16780     __ mlav(as_FloatRegister($dst$$reg), __ T4S,
16781             as_FloatRegister($src1$$reg),
16782             as_FloatRegister($src2$$reg));
16783   %}
16784   ins_pipe(vmla128);
16785 %}
16786 
16787 // dst + src1 * src2
16788 instruct vmla2F(vecD dst, vecD src1, vecD src2) %{
16789   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16790   match(Set dst (FmaVF  dst (Binary src1 src2)));
16791   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2S)&quot; %}
16792   ins_cost(INSN_COST);
16793   ins_encode %{
16794     __ fmla(as_FloatRegister($dst$$reg), __ T2S,
16795             as_FloatRegister($src1$$reg),
16796             as_FloatRegister($src2$$reg));
16797   %}
16798   ins_pipe(vmuldiv_fp64);
16799 %}
16800 
16801 // dst + src1 * src2
16802 instruct vmla4F(vecX dst, vecX src1, vecX src2) %{
16803   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16804   match(Set dst (FmaVF  dst (Binary src1 src2)));
16805   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (4S)&quot; %}
16806   ins_cost(INSN_COST);
16807   ins_encode %{
16808     __ fmla(as_FloatRegister($dst$$reg), __ T4S,
16809             as_FloatRegister($src1$$reg),
16810             as_FloatRegister($src2$$reg));
16811   %}
16812   ins_pipe(vmuldiv_fp128);
16813 %}
16814 
16815 // dst + src1 * src2
16816 instruct vmla2D(vecX dst, vecX src1, vecX src2) %{
16817   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16818   match(Set dst (FmaVD  dst (Binary src1 src2)));
16819   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2D)&quot; %}
16820   ins_cost(INSN_COST);
16821   ins_encode %{
16822     __ fmla(as_FloatRegister($dst$$reg), __ T2D,
16823             as_FloatRegister($src1$$reg),
16824             as_FloatRegister($src2$$reg));
16825   %}
16826   ins_pipe(vmuldiv_fp128);
16827 %}
16828 
16829 // --------------------------------- MLS --------------------------------------
16830 
16831 instruct vmls4S(vecD dst, vecD src1, vecD src2)
16832 %{
16833   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16834             n-&gt;as_Vector()-&gt;length() == 4);
16835   match(Set dst (SubVS dst (MulVS src1 src2)));
16836   ins_cost(INSN_COST);
16837   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16838   ins_encode %{
16839     __ mlsv(as_FloatRegister($dst$$reg), __ T4H,
16840             as_FloatRegister($src1$$reg),
16841             as_FloatRegister($src2$$reg));
16842   %}
16843   ins_pipe(vmla64);
16844 %}
16845 
16846 instruct vmls8S(vecX dst, vecX src1, vecX src2)
16847 %{
16848   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16849   match(Set dst (SubVS dst (MulVS src1 src2)));
16850   ins_cost(INSN_COST);
16851   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16852   ins_encode %{
16853     __ mlsv(as_FloatRegister($dst$$reg), __ T8H,
16854             as_FloatRegister($src1$$reg),
16855             as_FloatRegister($src2$$reg));
16856   %}
16857   ins_pipe(vmla128);
16858 %}
16859 
16860 instruct vmls2I(vecD dst, vecD src1, vecD src2)
16861 %{
16862   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16863   match(Set dst (SubVI dst (MulVI src1 src2)));
16864   ins_cost(INSN_COST);
16865   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16866   ins_encode %{
16867     __ mlsv(as_FloatRegister($dst$$reg), __ T2S,
16868             as_FloatRegister($src1$$reg),
16869             as_FloatRegister($src2$$reg));
16870   %}
16871   ins_pipe(vmla64);
16872 %}
16873 
16874 instruct vmls4I(vecX dst, vecX src1, vecX src2)
16875 %{
16876   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16877   match(Set dst (SubVI dst (MulVI src1 src2)));
16878   ins_cost(INSN_COST);
16879   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16880   ins_encode %{
16881     __ mlsv(as_FloatRegister($dst$$reg), __ T4S,
16882             as_FloatRegister($src1$$reg),
16883             as_FloatRegister($src2$$reg));
16884   %}
16885   ins_pipe(vmla128);
16886 %}
16887 
16888 // dst - src1 * src2
16889 instruct vmls2F(vecD dst, vecD src1, vecD src2) %{
16890   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16891   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16892   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16893   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2S)&quot; %}
16894   ins_cost(INSN_COST);
16895   ins_encode %{
16896     __ fmls(as_FloatRegister($dst$$reg), __ T2S,
16897             as_FloatRegister($src1$$reg),
16898             as_FloatRegister($src2$$reg));
16899   %}
16900   ins_pipe(vmuldiv_fp64);
16901 %}
16902 
16903 // dst - src1 * src2
16904 instruct vmls4F(vecX dst, vecX src1, vecX src2) %{
16905   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16906   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16907   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16908   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (4S)&quot; %}
16909   ins_cost(INSN_COST);
16910   ins_encode %{
16911     __ fmls(as_FloatRegister($dst$$reg), __ T4S,
16912             as_FloatRegister($src1$$reg),
16913             as_FloatRegister($src2$$reg));
16914   %}
16915   ins_pipe(vmuldiv_fp128);
16916 %}
16917 
16918 // dst - src1 * src2
16919 instruct vmls2D(vecX dst, vecX src1, vecX src2) %{
16920   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16921   match(Set dst (FmaVD  dst (Binary (NegVD src1) src2)));
16922   match(Set dst (FmaVD  dst (Binary src1 (NegVD src2))));
16923   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2D)&quot; %}
16924   ins_cost(INSN_COST);
16925   ins_encode %{
16926     __ fmls(as_FloatRegister($dst$$reg), __ T2D,
16927             as_FloatRegister($src1$$reg),
16928             as_FloatRegister($src2$$reg));
16929   %}
16930   ins_pipe(vmuldiv_fp128);
16931 %}
16932 
16933 // --------------- Vector Multiply-Add Shorts into Integer --------------------
16934 
16935 instruct vmuladdS2I(vecX dst, vecX src1, vecX src2, vecX tmp) %{
16936   predicate(n-&gt;in(1)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_SHORT);
16937   match(Set dst (MulAddVS2VI src1 src2));
16938   ins_cost(INSN_COST);
16939   effect(TEMP_DEF dst, TEMP tmp);
16940   format %{ &quot;smullv  $tmp, $src1, $src2\t# vector (4H)\n\t&quot;
16941             &quot;smullv  $dst, $src1, $src2\t# vector (8H)\n\t&quot;
16942             &quot;addpv   $dst, $tmp, $dst\t# vector (4S)\n\t&quot; %}
16943   ins_encode %{
16944     __ smullv(as_FloatRegister($tmp$$reg), __ T4H,
16945               as_FloatRegister($src1$$reg),
16946               as_FloatRegister($src2$$reg));
16947     __ smullv(as_FloatRegister($dst$$reg), __ T8H,
16948               as_FloatRegister($src1$$reg),
16949               as_FloatRegister($src2$$reg));
16950     __ addpv(as_FloatRegister($dst$$reg), __ T4S,
16951              as_FloatRegister($tmp$$reg),
16952              as_FloatRegister($dst$$reg));
16953   %}
16954   ins_pipe(vmuldiv_fp128);
16955 %}
16956 
16957 // --------------------------------- DIV --------------------------------------
16958 
16959 instruct vdiv2F(vecD dst, vecD src1, vecD src2)
16960 %{
16961   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16962   match(Set dst (DivVF src1 src2));
16963   ins_cost(INSN_COST);
16964   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16965   ins_encode %{
16966     __ fdiv(as_FloatRegister($dst$$reg), __ T2S,
16967             as_FloatRegister($src1$$reg),
16968             as_FloatRegister($src2$$reg));
16969   %}
16970   ins_pipe(vmuldiv_fp64);
16971 %}
16972 
16973 instruct vdiv4F(vecX dst, vecX src1, vecX src2)
16974 %{
16975   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16976   match(Set dst (DivVF src1 src2));
16977   ins_cost(INSN_COST);
16978   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16979   ins_encode %{
16980     __ fdiv(as_FloatRegister($dst$$reg), __ T4S,
16981             as_FloatRegister($src1$$reg),
16982             as_FloatRegister($src2$$reg));
16983   %}
16984   ins_pipe(vmuldiv_fp128);
16985 %}
16986 
16987 instruct vdiv2D(vecX dst, vecX src1, vecX src2)
16988 %{
16989   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16990   match(Set dst (DivVD src1 src2));
16991   ins_cost(INSN_COST);
16992   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2D)&quot; %}
16993   ins_encode %{
16994     __ fdiv(as_FloatRegister($dst$$reg), __ T2D,
16995             as_FloatRegister($src1$$reg),
16996             as_FloatRegister($src2$$reg));
16997   %}
16998   ins_pipe(vmuldiv_fp128);
16999 %}
17000 
17001 // --------------------------------- SQRT -------------------------------------
17002 
17003 instruct vsqrt2F(vecD dst, vecD src)
17004 %{
17005   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17006   match(Set dst (SqrtVF src));
17007   format %{ &quot;fsqrt  $dst, $src\t# vector (2F)&quot; %}
17008   ins_encode %{
17009     __ fsqrt(as_FloatRegister($dst$$reg), __ T2S, as_FloatRegister($src$$reg));
17010   %}
17011   ins_pipe(vunop_fp64);
17012 %}
17013 
17014 instruct vsqrt4F(vecX dst, vecX src)
17015 %{
17016   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17017   match(Set dst (SqrtVF src));
17018   format %{ &quot;fsqrt  $dst, $src\t# vector (4F)&quot; %}
17019   ins_encode %{
17020     __ fsqrt(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src$$reg));
17021   %}
17022   ins_pipe(vsqrt_fp128);
17023 %}
17024 
17025 instruct vsqrt2D(vecX dst, vecX src)
17026 %{
17027   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17028   match(Set dst (SqrtVD src));
17029   format %{ &quot;fsqrt  $dst, $src\t# vector (2D)&quot; %}
17030   ins_encode %{
17031     __ fsqrt(as_FloatRegister($dst$$reg), __ T2D,
17032              as_FloatRegister($src$$reg));
17033   %}
17034   ins_pipe(vsqrt_fp128);
17035 %}
17036 
17037 // --------------------------------- ABS --------------------------------------
17038 
17039 instruct vabs8B(vecD dst, vecD src)
17040 %{
17041   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17042             n-&gt;as_Vector()-&gt;length() == 8);
17043   match(Set dst (AbsVB src));
17044   ins_cost(INSN_COST);
17045   format %{ &quot;abs  $dst, $src\t# vector (8B)&quot; %}
17046   ins_encode %{
17047     __ absr(as_FloatRegister($dst$$reg), __ T8B, as_FloatRegister($src$$reg));
17048   %}
17049   ins_pipe(vlogical64);
17050 %}
17051 
17052 instruct vabs16B(vecX dst, vecX src)
17053 %{
17054   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17055   match(Set dst (AbsVB src));
17056   ins_cost(INSN_COST);
17057   format %{ &quot;abs  $dst, $src\t# vector (16B)&quot; %}
17058   ins_encode %{
17059     __ absr(as_FloatRegister($dst$$reg), __ T16B, as_FloatRegister($src$$reg));
17060   %}
17061   ins_pipe(vlogical128);
17062 %}
17063 
17064 instruct vabs4S(vecD dst, vecD src)
17065 %{
17066   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17067   match(Set dst (AbsVS src));
17068   ins_cost(INSN_COST);
17069   format %{ &quot;abs  $dst, $src\t# vector (4H)&quot; %}
17070   ins_encode %{
17071     __ absr(as_FloatRegister($dst$$reg), __ T4H, as_FloatRegister($src$$reg));
17072   %}
17073   ins_pipe(vlogical64);
17074 %}
17075 
17076 instruct vabs8S(vecX dst, vecX src)
17077 %{
17078   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17079   match(Set dst (AbsVS src));
17080   ins_cost(INSN_COST);
17081   format %{ &quot;abs  $dst, $src\t# vector (8H)&quot; %}
17082   ins_encode %{
17083     __ absr(as_FloatRegister($dst$$reg), __ T8H, as_FloatRegister($src$$reg));
17084   %}
17085   ins_pipe(vlogical128);
17086 %}
17087 
17088 instruct vabs2I(vecD dst, vecD src)
17089 %{
17090   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17091   match(Set dst (AbsVI src));
17092   ins_cost(INSN_COST);
17093   format %{ &quot;abs  $dst, $src\t# vector (2S)&quot; %}
17094   ins_encode %{
17095     __ absr(as_FloatRegister($dst$$reg), __ T2S, as_FloatRegister($src$$reg));
17096   %}
17097   ins_pipe(vlogical64);
17098 %}
17099 
17100 instruct vabs4I(vecX dst, vecX src)
17101 %{
17102   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17103   match(Set dst (AbsVI src));
17104   ins_cost(INSN_COST);
17105   format %{ &quot;abs  $dst, $src\t# vector (4S)&quot; %}
17106   ins_encode %{
17107     __ absr(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src$$reg));
17108   %}
17109   ins_pipe(vlogical128);
17110 %}
17111 
17112 instruct vabs2L(vecX dst, vecX src)
17113 %{
17114   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17115   match(Set dst (AbsVL src));
17116   ins_cost(INSN_COST);
17117   format %{ &quot;abs  $dst, $src\t# vector (2D)&quot; %}
17118   ins_encode %{
17119     __ absr(as_FloatRegister($dst$$reg), __ T2D, as_FloatRegister($src$$reg));
17120   %}
17121   ins_pipe(vlogical128);
17122 %}
17123 
17124 instruct vabs2F(vecD dst, vecD src)
17125 %{
17126   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17127   match(Set dst (AbsVF src));
17128   ins_cost(INSN_COST * 3);
17129   format %{ &quot;fabs  $dst,$src\t# vector (2S)&quot; %}
17130   ins_encode %{
17131     __ fabs(as_FloatRegister($dst$$reg), __ T2S,
17132             as_FloatRegister($src$$reg));
17133   %}
17134   ins_pipe(vunop_fp64);
17135 %}
17136 
17137 instruct vabs4F(vecX dst, vecX src)
17138 %{
17139   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17140   match(Set dst (AbsVF src));
17141   ins_cost(INSN_COST * 3);
17142   format %{ &quot;fabs  $dst,$src\t# vector (4S)&quot; %}
17143   ins_encode %{
17144     __ fabs(as_FloatRegister($dst$$reg), __ T4S,
17145             as_FloatRegister($src$$reg));
17146   %}
17147   ins_pipe(vunop_fp128);
17148 %}
17149 
17150 instruct vabs2D(vecX dst, vecX src)
17151 %{
17152   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17153   match(Set dst (AbsVD src));
17154   ins_cost(INSN_COST * 3);
17155   format %{ &quot;fabs  $dst,$src\t# vector (2D)&quot; %}
17156   ins_encode %{
17157     __ fabs(as_FloatRegister($dst$$reg), __ T2D,
17158             as_FloatRegister($src$$reg));
17159   %}
17160   ins_pipe(vunop_fp128);
17161 %}
17162 
17163 // --------------------------------- NEG --------------------------------------
17164 
17165 instruct vneg2F(vecD dst, vecD src)
17166 %{
17167   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17168   match(Set dst (NegVF src));
17169   ins_cost(INSN_COST * 3);
17170   format %{ &quot;fneg  $dst,$src\t# vector (2S)&quot; %}
17171   ins_encode %{
17172     __ fneg(as_FloatRegister($dst$$reg), __ T2S,
17173             as_FloatRegister($src$$reg));
17174   %}
17175   ins_pipe(vunop_fp64);
17176 %}
17177 
17178 instruct vneg4F(vecX dst, vecX src)
17179 %{
17180   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17181   match(Set dst (NegVF src));
17182   ins_cost(INSN_COST * 3);
17183   format %{ &quot;fneg  $dst,$src\t# vector (4S)&quot; %}
17184   ins_encode %{
17185     __ fneg(as_FloatRegister($dst$$reg), __ T4S,
17186             as_FloatRegister($src$$reg));
17187   %}
17188   ins_pipe(vunop_fp128);
17189 %}
17190 
17191 instruct vneg2D(vecX dst, vecX src)
17192 %{
17193   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17194   match(Set dst (NegVD src));
17195   ins_cost(INSN_COST * 3);
17196   format %{ &quot;fneg  $dst,$src\t# vector (2D)&quot; %}
17197   ins_encode %{
17198     __ fneg(as_FloatRegister($dst$$reg), __ T2D,
17199             as_FloatRegister($src$$reg));
17200   %}
17201   ins_pipe(vunop_fp128);
17202 %}
17203 
17204 // --------------------------------- AND --------------------------------------
17205 
17206 instruct vand8B(vecD dst, vecD src1, vecD src2)
17207 %{
17208   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17209             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17210   match(Set dst (AndV src1 src2));
17211   ins_cost(INSN_COST);
17212   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17213   ins_encode %{
17214     __ andr(as_FloatRegister($dst$$reg), __ T8B,
17215             as_FloatRegister($src1$$reg),
17216             as_FloatRegister($src2$$reg));
17217   %}
17218   ins_pipe(vlogical64);
17219 %}
17220 
17221 instruct vand16B(vecX dst, vecX src1, vecX src2)
17222 %{
17223   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17224   match(Set dst (AndV src1 src2));
17225   ins_cost(INSN_COST);
17226   format %{ &quot;and  $dst,$src1,$src2\t# vector (16B)&quot; %}
17227   ins_encode %{
17228     __ andr(as_FloatRegister($dst$$reg), __ T16B,
17229             as_FloatRegister($src1$$reg),
17230             as_FloatRegister($src2$$reg));
17231   %}
17232   ins_pipe(vlogical128);
17233 %}
17234 
17235 // --------------------------------- OR ---------------------------------------
17236 
17237 instruct vor8B(vecD dst, vecD src1, vecD src2)
17238 %{
17239   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17240             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17241   match(Set dst (OrV src1 src2));
17242   ins_cost(INSN_COST);
17243   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17244   ins_encode %{
17245     __ orr(as_FloatRegister($dst$$reg), __ T8B,
17246             as_FloatRegister($src1$$reg),
17247             as_FloatRegister($src2$$reg));
17248   %}
17249   ins_pipe(vlogical64);
17250 %}
17251 
17252 instruct vor16B(vecX dst, vecX src1, vecX src2)
17253 %{
17254   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17255   match(Set dst (OrV src1 src2));
17256   ins_cost(INSN_COST);
17257   format %{ &quot;orr  $dst,$src1,$src2\t# vector (16B)&quot; %}
17258   ins_encode %{
17259     __ orr(as_FloatRegister($dst$$reg), __ T16B,
17260             as_FloatRegister($src1$$reg),
17261             as_FloatRegister($src2$$reg));
17262   %}
17263   ins_pipe(vlogical128);
17264 %}
17265 
17266 // --------------------------------- XOR --------------------------------------
17267 
17268 instruct vxor8B(vecD dst, vecD src1, vecD src2)
17269 %{
17270   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17271             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17272   match(Set dst (XorV src1 src2));
17273   ins_cost(INSN_COST);
17274   format %{ &quot;xor  $dst,$src1,$src2\t# vector (8B)&quot; %}
17275   ins_encode %{
17276     __ eor(as_FloatRegister($dst$$reg), __ T8B,
17277             as_FloatRegister($src1$$reg),
17278             as_FloatRegister($src2$$reg));
17279   %}
17280   ins_pipe(vlogical64);
17281 %}
17282 
17283 instruct vxor16B(vecX dst, vecX src1, vecX src2)
17284 %{
17285   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17286   match(Set dst (XorV src1 src2));
17287   ins_cost(INSN_COST);
17288   format %{ &quot;xor  $dst,$src1,$src2\t# vector (16B)&quot; %}
17289   ins_encode %{
17290     __ eor(as_FloatRegister($dst$$reg), __ T16B,
17291             as_FloatRegister($src1$$reg),
17292             as_FloatRegister($src2$$reg));
17293   %}
17294   ins_pipe(vlogical128);
17295 %}
17296 
17297 // ------------------------------ Shift ---------------------------------------
17298 instruct vshiftcnt8B(vecD dst, iRegIorL2I cnt) %{
17299   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17300   match(Set dst (LShiftCntV cnt));
17301   match(Set dst (RShiftCntV cnt));
17302   format %{ &quot;dup  $dst, $cnt\t# shift count vector (8B)&quot; %}
17303   ins_encode %{
17304     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($cnt$$reg));
17305   %}
17306   ins_pipe(vdup_reg_reg64);
17307 %}
17308 
17309 instruct vshiftcnt16B(vecX dst, iRegIorL2I cnt) %{
17310   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17311   match(Set dst (LShiftCntV cnt));
17312   match(Set dst (RShiftCntV cnt));
17313   format %{ &quot;dup  $dst, $cnt\t# shift count vector (16B)&quot; %}
17314   ins_encode %{
17315     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($cnt$$reg));
17316   %}
17317   ins_pipe(vdup_reg_reg128);
17318 %}
17319 
17320 instruct vsll8B(vecD dst, vecD src, vecD shift) %{
17321   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17322             n-&gt;as_Vector()-&gt;length() == 8);
17323   match(Set dst (LShiftVB src shift));
17324   ins_cost(INSN_COST);
17325   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8B)&quot; %}
17326   ins_encode %{
17327     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17328             as_FloatRegister($src$$reg),
17329             as_FloatRegister($shift$$reg));
17330   %}
17331   ins_pipe(vshift64);
17332 %}
17333 
17334 instruct vsll16B(vecX dst, vecX src, vecX shift) %{
17335   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17336   match(Set dst (LShiftVB src shift));
17337   ins_cost(INSN_COST);
17338   format %{ &quot;sshl  $dst,$src,$shift\t# vector (16B)&quot; %}
17339   ins_encode %{
17340     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17341             as_FloatRegister($src$$reg),
17342             as_FloatRegister($shift$$reg));
17343   %}
17344   ins_pipe(vshift128);
17345 %}
17346 
17347 // Right shifts with vector shift count on aarch64 SIMD are implemented
17348 // as left shift by negative shift count.
17349 // There are two cases for vector shift count.
17350 //
17351 // Case 1: The vector shift count is from replication.
17352 //        |            |
17353 //    LoadVector  RShiftCntV
17354 //        |       /
17355 //     RShiftVI
17356 // Note: In inner loop, multiple neg instructions are used, which can be
17357 // moved to outer loop and merge into one neg instruction.
17358 //
17359 // Case 2: The vector shift count is from loading.
17360 // This case isn&#39;t supported by middle-end now. But it&#39;s supported by
17361 // panama/vectorIntrinsics(JEP 338: Vector API).
17362 //        |            |
17363 //    LoadVector  LoadVector
17364 //        |       /
17365 //     RShiftVI
17366 //
17367 
17368 instruct vsra8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17369   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17370             n-&gt;as_Vector()-&gt;length() == 8);
17371   match(Set dst (RShiftVB src shift));
17372   ins_cost(INSN_COST);
17373   effect(TEMP tmp);
17374   format %{ &quot;negr  $tmp,$shift\t&quot;
17375             &quot;sshl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17376   ins_encode %{
17377     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17378             as_FloatRegister($shift$$reg));
17379     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17380             as_FloatRegister($src$$reg),
17381             as_FloatRegister($tmp$$reg));
17382   %}
17383   ins_pipe(vshift64);
17384 %}
17385 
17386 instruct vsra16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17387   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17388   match(Set dst (RShiftVB src shift));
17389   ins_cost(INSN_COST);
17390   effect(TEMP tmp);
17391   format %{ &quot;negr  $tmp,$shift\t&quot;
17392             &quot;sshl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17393   ins_encode %{
17394     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17395             as_FloatRegister($shift$$reg));
17396     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17397             as_FloatRegister($src$$reg),
17398             as_FloatRegister($tmp$$reg));
17399   %}
17400   ins_pipe(vshift128);
17401 %}
17402 
17403 instruct vsrl8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17404   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17405             n-&gt;as_Vector()-&gt;length() == 8);
17406   match(Set dst (URShiftVB src shift));
17407   ins_cost(INSN_COST);
17408   effect(TEMP tmp);
17409   format %{ &quot;negr  $tmp,$shift\t&quot;
17410             &quot;ushl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17411   ins_encode %{
17412     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17413             as_FloatRegister($shift$$reg));
17414     __ ushl(as_FloatRegister($dst$$reg), __ T8B,
17415             as_FloatRegister($src$$reg),
17416             as_FloatRegister($tmp$$reg));
17417   %}
17418   ins_pipe(vshift64);
17419 %}
17420 
17421 instruct vsrl16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17422   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17423   match(Set dst (URShiftVB src shift));
17424   ins_cost(INSN_COST);
17425   effect(TEMP tmp);
17426   format %{ &quot;negr  $tmp,$shift\t&quot;
17427             &quot;ushl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17428   ins_encode %{
17429     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17430             as_FloatRegister($shift$$reg));
17431     __ ushl(as_FloatRegister($dst$$reg), __ T16B,
17432             as_FloatRegister($src$$reg),
17433             as_FloatRegister($tmp$$reg));
17434   %}
17435   ins_pipe(vshift128);
17436 %}
17437 
17438 instruct vsll8B_imm(vecD dst, vecD src, immI shift) %{
17439   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17440             n-&gt;as_Vector()-&gt;length() == 8);
17441   match(Set dst (LShiftVB src (LShiftCntV shift)));
17442   ins_cost(INSN_COST);
17443   format %{ &quot;shl    $dst, $src, $shift\t# vector (8B)&quot; %}
17444   ins_encode %{
17445     int sh = (int)$shift$$constant;
17446     if (sh &gt;= 8) {
17447       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17448              as_FloatRegister($src$$reg),
17449              as_FloatRegister($src$$reg));
17450     } else {
17451       __ shl(as_FloatRegister($dst$$reg), __ T8B,
17452              as_FloatRegister($src$$reg), sh);
17453     }
17454   %}
17455   ins_pipe(vshift64_imm);
17456 %}
17457 
17458 instruct vsll16B_imm(vecX dst, vecX src, immI shift) %{
17459   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17460   match(Set dst (LShiftVB src (LShiftCntV shift)));
17461   ins_cost(INSN_COST);
17462   format %{ &quot;shl    $dst, $src, $shift\t# vector (16B)&quot; %}
17463   ins_encode %{
17464     int sh = (int)$shift$$constant;
17465     if (sh &gt;= 8) {
17466       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17467              as_FloatRegister($src$$reg),
17468              as_FloatRegister($src$$reg));
17469     } else {
17470       __ shl(as_FloatRegister($dst$$reg), __ T16B,
17471              as_FloatRegister($src$$reg), sh);
17472     }
17473   %}
17474   ins_pipe(vshift128_imm);
17475 %}
17476 
17477 instruct vsra8B_imm(vecD dst, vecD src, immI shift) %{
17478   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17479             n-&gt;as_Vector()-&gt;length() == 8);
17480   match(Set dst (RShiftVB src (RShiftCntV shift)));
17481   ins_cost(INSN_COST);
17482   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8B)&quot; %}
17483   ins_encode %{
17484     int sh = (int)$shift$$constant;
17485     if (sh &gt;= 8) sh = 7;
17486     __ sshr(as_FloatRegister($dst$$reg), __ T8B,
17487            as_FloatRegister($src$$reg), sh);
17488   %}
17489   ins_pipe(vshift64_imm);
17490 %}
17491 
17492 instruct vsra16B_imm(vecX dst, vecX src, immI shift) %{
17493   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17494   match(Set dst (RShiftVB src (RShiftCntV shift)));
17495   ins_cost(INSN_COST);
17496   format %{ &quot;sshr    $dst, $src, $shift\t# vector (16B)&quot; %}
17497   ins_encode %{
17498     int sh = (int)$shift$$constant;
17499     if (sh &gt;= 8) sh = 7;
17500     __ sshr(as_FloatRegister($dst$$reg), __ T16B,
17501            as_FloatRegister($src$$reg), sh);
17502   %}
17503   ins_pipe(vshift128_imm);
17504 %}
17505 
17506 instruct vsrl8B_imm(vecD dst, vecD src, immI shift) %{
17507   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17508             n-&gt;as_Vector()-&gt;length() == 8);
17509   match(Set dst (URShiftVB src (RShiftCntV shift)));
17510   ins_cost(INSN_COST);
17511   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8B)&quot; %}
17512   ins_encode %{
17513     int sh = (int)$shift$$constant;
17514     if (sh &gt;= 8) {
17515       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17516              as_FloatRegister($src$$reg),
17517              as_FloatRegister($src$$reg));
17518     } else {
17519       __ ushr(as_FloatRegister($dst$$reg), __ T8B,
17520              as_FloatRegister($src$$reg), sh);
17521     }
17522   %}
17523   ins_pipe(vshift64_imm);
17524 %}
17525 
17526 instruct vsrl16B_imm(vecX dst, vecX src, immI shift) %{
17527   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17528   match(Set dst (URShiftVB src (RShiftCntV shift)));
17529   ins_cost(INSN_COST);
17530   format %{ &quot;ushr    $dst, $src, $shift\t# vector (16B)&quot; %}
17531   ins_encode %{
17532     int sh = (int)$shift$$constant;
17533     if (sh &gt;= 8) {
17534       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17535              as_FloatRegister($src$$reg),
17536              as_FloatRegister($src$$reg));
17537     } else {
17538       __ ushr(as_FloatRegister($dst$$reg), __ T16B,
17539              as_FloatRegister($src$$reg), sh);
17540     }
17541   %}
17542   ins_pipe(vshift128_imm);
17543 %}
17544 
17545 instruct vsll4S(vecD dst, vecD src, vecD shift) %{
17546   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17547             n-&gt;as_Vector()-&gt;length() == 4);
17548   match(Set dst (LShiftVS src shift));
17549   ins_cost(INSN_COST);
17550   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4H)&quot; %}
17551   ins_encode %{
17552     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17553             as_FloatRegister($src$$reg),
17554             as_FloatRegister($shift$$reg));
17555   %}
17556   ins_pipe(vshift64);
17557 %}
17558 
17559 instruct vsll8S(vecX dst, vecX src, vecX shift) %{
17560   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17561   match(Set dst (LShiftVS src shift));
17562   ins_cost(INSN_COST);
17563   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8H)&quot; %}
17564   ins_encode %{
17565     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17566             as_FloatRegister($src$$reg),
17567             as_FloatRegister($shift$$reg));
17568   %}
17569   ins_pipe(vshift128);
17570 %}
17571 
17572 instruct vsra4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17573   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17574             n-&gt;as_Vector()-&gt;length() == 4);
17575   match(Set dst (RShiftVS src shift));
17576   ins_cost(INSN_COST);
17577   effect(TEMP tmp);
17578   format %{ &quot;negr  $tmp,$shift\t&quot;
17579             &quot;sshl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17580   ins_encode %{
17581     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17582             as_FloatRegister($shift$$reg));
17583     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17584             as_FloatRegister($src$$reg),
17585             as_FloatRegister($tmp$$reg));
17586   %}
17587   ins_pipe(vshift64);
17588 %}
17589 
17590 instruct vsra8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17591   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17592   match(Set dst (RShiftVS src shift));
17593   ins_cost(INSN_COST);
17594   effect(TEMP tmp);
17595   format %{ &quot;negr  $tmp,$shift\t&quot;
17596             &quot;sshl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17597   ins_encode %{
17598     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17599             as_FloatRegister($shift$$reg));
17600     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17601             as_FloatRegister($src$$reg),
17602             as_FloatRegister($tmp$$reg));
17603   %}
17604   ins_pipe(vshift128);
17605 %}
17606 
17607 instruct vsrl4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17608   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17609             n-&gt;as_Vector()-&gt;length() == 4);
17610   match(Set dst (URShiftVS src shift));
17611   ins_cost(INSN_COST);
17612   effect(TEMP tmp);
17613   format %{ &quot;negr  $tmp,$shift\t&quot;
17614             &quot;ushl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17615   ins_encode %{
17616     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17617             as_FloatRegister($shift$$reg));
17618     __ ushl(as_FloatRegister($dst$$reg), __ T4H,
17619             as_FloatRegister($src$$reg),
17620             as_FloatRegister($tmp$$reg));
17621   %}
17622   ins_pipe(vshift64);
17623 %}
17624 
17625 instruct vsrl8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17626   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17627   match(Set dst (URShiftVS src shift));
17628   ins_cost(INSN_COST);
17629   effect(TEMP tmp);
17630   format %{ &quot;negr  $tmp,$shift\t&quot;
17631             &quot;ushl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17632   ins_encode %{
17633     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17634             as_FloatRegister($shift$$reg));
17635     __ ushl(as_FloatRegister($dst$$reg), __ T8H,
17636             as_FloatRegister($src$$reg),
17637             as_FloatRegister($tmp$$reg));
17638   %}
17639   ins_pipe(vshift128);
17640 %}
17641 
17642 instruct vsll4S_imm(vecD dst, vecD src, immI shift) %{
17643   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17644             n-&gt;as_Vector()-&gt;length() == 4);
17645   match(Set dst (LShiftVS src (LShiftCntV shift)));
17646   ins_cost(INSN_COST);
17647   format %{ &quot;shl    $dst, $src, $shift\t# vector (4H)&quot; %}
17648   ins_encode %{
17649     int sh = (int)$shift$$constant;
17650     if (sh &gt;= 16) {
17651       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17652              as_FloatRegister($src$$reg),
17653              as_FloatRegister($src$$reg));
17654     } else {
17655       __ shl(as_FloatRegister($dst$$reg), __ T4H,
17656              as_FloatRegister($src$$reg), sh);
17657     }
17658   %}
17659   ins_pipe(vshift64_imm);
17660 %}
17661 
17662 instruct vsll8S_imm(vecX dst, vecX src, immI shift) %{
17663   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17664   match(Set dst (LShiftVS src (LShiftCntV shift)));
17665   ins_cost(INSN_COST);
17666   format %{ &quot;shl    $dst, $src, $shift\t# vector (8H)&quot; %}
17667   ins_encode %{
17668     int sh = (int)$shift$$constant;
17669     if (sh &gt;= 16) {
17670       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17671              as_FloatRegister($src$$reg),
17672              as_FloatRegister($src$$reg));
17673     } else {
17674       __ shl(as_FloatRegister($dst$$reg), __ T8H,
17675              as_FloatRegister($src$$reg), sh);
17676     }
17677   %}
17678   ins_pipe(vshift128_imm);
17679 %}
17680 
17681 instruct vsra4S_imm(vecD dst, vecD src, immI shift) %{
17682   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17683             n-&gt;as_Vector()-&gt;length() == 4);
17684   match(Set dst (RShiftVS src (RShiftCntV shift)));
17685   ins_cost(INSN_COST);
17686   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4H)&quot; %}
17687   ins_encode %{
17688     int sh = (int)$shift$$constant;
17689     if (sh &gt;= 16) sh = 15;
17690     __ sshr(as_FloatRegister($dst$$reg), __ T4H,
17691            as_FloatRegister($src$$reg), sh);
17692   %}
17693   ins_pipe(vshift64_imm);
17694 %}
17695 
17696 instruct vsra8S_imm(vecX dst, vecX src, immI shift) %{
17697   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17698   match(Set dst (RShiftVS src (RShiftCntV shift)));
17699   ins_cost(INSN_COST);
17700   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8H)&quot; %}
17701   ins_encode %{
17702     int sh = (int)$shift$$constant;
17703     if (sh &gt;= 16) sh = 15;
17704     __ sshr(as_FloatRegister($dst$$reg), __ T8H,
17705            as_FloatRegister($src$$reg), sh);
17706   %}
17707   ins_pipe(vshift128_imm);
17708 %}
17709 
17710 instruct vsrl4S_imm(vecD dst, vecD src, immI shift) %{
17711   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17712             n-&gt;as_Vector()-&gt;length() == 4);
17713   match(Set dst (URShiftVS src (RShiftCntV shift)));
17714   ins_cost(INSN_COST);
17715   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4H)&quot; %}
17716   ins_encode %{
17717     int sh = (int)$shift$$constant;
17718     if (sh &gt;= 16) {
17719       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17720              as_FloatRegister($src$$reg),
17721              as_FloatRegister($src$$reg));
17722     } else {
17723       __ ushr(as_FloatRegister($dst$$reg), __ T4H,
17724              as_FloatRegister($src$$reg), sh);
17725     }
17726   %}
17727   ins_pipe(vshift64_imm);
17728 %}
17729 
17730 instruct vsrl8S_imm(vecX dst, vecX src, immI shift) %{
17731   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17732   match(Set dst (URShiftVS src (RShiftCntV shift)));
17733   ins_cost(INSN_COST);
17734   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8H)&quot; %}
17735   ins_encode %{
17736     int sh = (int)$shift$$constant;
17737     if (sh &gt;= 16) {
17738       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17739              as_FloatRegister($src$$reg),
17740              as_FloatRegister($src$$reg));
17741     } else {
17742       __ ushr(as_FloatRegister($dst$$reg), __ T8H,
17743              as_FloatRegister($src$$reg), sh);
17744     }
17745   %}
17746   ins_pipe(vshift128_imm);
17747 %}
17748 
17749 instruct vsll2I(vecD dst, vecD src, vecD shift) %{
17750   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17751   match(Set dst (LShiftVI src shift));
17752   ins_cost(INSN_COST);
17753   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2S)&quot; %}
17754   ins_encode %{
17755     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17756             as_FloatRegister($src$$reg),
17757             as_FloatRegister($shift$$reg));
17758   %}
17759   ins_pipe(vshift64);
17760 %}
17761 
17762 instruct vsll4I(vecX dst, vecX src, vecX shift) %{
17763   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17764   match(Set dst (LShiftVI src shift));
17765   ins_cost(INSN_COST);
17766   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4S)&quot; %}
17767   ins_encode %{
17768     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17769             as_FloatRegister($src$$reg),
17770             as_FloatRegister($shift$$reg));
17771   %}
17772   ins_pipe(vshift128);
17773 %}
17774 
17775 instruct vsra2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17776   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17777   match(Set dst (RShiftVI src shift));
17778   ins_cost(INSN_COST);
17779   effect(TEMP tmp);
17780   format %{ &quot;negr  $tmp,$shift\t&quot;
17781             &quot;sshl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17782   ins_encode %{
17783     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17784             as_FloatRegister($shift$$reg));
17785     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17786             as_FloatRegister($src$$reg),
17787             as_FloatRegister($tmp$$reg));
17788   %}
17789   ins_pipe(vshift64);
17790 %}
17791 
17792 instruct vsra4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17793   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17794   match(Set dst (RShiftVI src shift));
17795   ins_cost(INSN_COST);
17796   effect(TEMP tmp);
17797   format %{ &quot;negr  $tmp,$shift\t&quot;
17798             &quot;sshl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17799   ins_encode %{
17800     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17801             as_FloatRegister($shift$$reg));
17802     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17803             as_FloatRegister($src$$reg),
17804             as_FloatRegister($tmp$$reg));
17805   %}
17806   ins_pipe(vshift128);
17807 %}
17808 
17809 instruct vsrl2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17810   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17811   match(Set dst (URShiftVI src shift));
17812   ins_cost(INSN_COST);
17813   effect(TEMP tmp);
17814   format %{ &quot;negr  $tmp,$shift\t&quot;
17815             &quot;ushl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17816   ins_encode %{
17817     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17818             as_FloatRegister($shift$$reg));
17819     __ ushl(as_FloatRegister($dst$$reg), __ T2S,
17820             as_FloatRegister($src$$reg),
17821             as_FloatRegister($tmp$$reg));
17822   %}
17823   ins_pipe(vshift64);
17824 %}
17825 
17826 instruct vsrl4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17827   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17828   match(Set dst (URShiftVI src shift));
17829   ins_cost(INSN_COST);
17830   effect(TEMP tmp);
17831   format %{ &quot;negr  $tmp,$shift\t&quot;
17832             &quot;ushl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17833   ins_encode %{
17834     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17835             as_FloatRegister($shift$$reg));
17836     __ ushl(as_FloatRegister($dst$$reg), __ T4S,
17837             as_FloatRegister($src$$reg),
17838             as_FloatRegister($tmp$$reg));
17839   %}
17840   ins_pipe(vshift128);
17841 %}
17842 
17843 instruct vsll2I_imm(vecD dst, vecD src, immI shift) %{
17844   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17845   match(Set dst (LShiftVI src (LShiftCntV shift)));
17846   ins_cost(INSN_COST);
17847   format %{ &quot;shl    $dst, $src, $shift\t# vector (2S)&quot; %}
17848   ins_encode %{
17849     __ shl(as_FloatRegister($dst$$reg), __ T2S,
17850            as_FloatRegister($src$$reg),
17851            (int)$shift$$constant);
17852   %}
17853   ins_pipe(vshift64_imm);
17854 %}
17855 
17856 instruct vsll4I_imm(vecX dst, vecX src, immI shift) %{
17857   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17858   match(Set dst (LShiftVI src (LShiftCntV shift)));
17859   ins_cost(INSN_COST);
17860   format %{ &quot;shl    $dst, $src, $shift\t# vector (4S)&quot; %}
17861   ins_encode %{
17862     __ shl(as_FloatRegister($dst$$reg), __ T4S,
17863            as_FloatRegister($src$$reg),
17864            (int)$shift$$constant);
17865   %}
17866   ins_pipe(vshift128_imm);
17867 %}
17868 
17869 instruct vsra2I_imm(vecD dst, vecD src, immI shift) %{
17870   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17871   match(Set dst (RShiftVI src (RShiftCntV shift)));
17872   ins_cost(INSN_COST);
17873   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2S)&quot; %}
17874   ins_encode %{
17875     __ sshr(as_FloatRegister($dst$$reg), __ T2S,
17876             as_FloatRegister($src$$reg),
17877             (int)$shift$$constant);
17878   %}
17879   ins_pipe(vshift64_imm);
17880 %}
17881 
17882 instruct vsra4I_imm(vecX dst, vecX src, immI shift) %{
17883   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17884   match(Set dst (RShiftVI src (RShiftCntV shift)));
17885   ins_cost(INSN_COST);
17886   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4S)&quot; %}
17887   ins_encode %{
17888     __ sshr(as_FloatRegister($dst$$reg), __ T4S,
17889             as_FloatRegister($src$$reg),
17890             (int)$shift$$constant);
17891   %}
17892   ins_pipe(vshift128_imm);
17893 %}
17894 
17895 instruct vsrl2I_imm(vecD dst, vecD src, immI shift) %{
17896   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17897   match(Set dst (URShiftVI src (RShiftCntV shift)));
17898   ins_cost(INSN_COST);
17899   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2S)&quot; %}
17900   ins_encode %{
17901     __ ushr(as_FloatRegister($dst$$reg), __ T2S,
17902             as_FloatRegister($src$$reg),
17903             (int)$shift$$constant);
17904   %}
17905   ins_pipe(vshift64_imm);
17906 %}
17907 
17908 instruct vsrl4I_imm(vecX dst, vecX src, immI shift) %{
17909   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17910   match(Set dst (URShiftVI src (RShiftCntV shift)));
17911   ins_cost(INSN_COST);
17912   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4S)&quot; %}
17913   ins_encode %{
17914     __ ushr(as_FloatRegister($dst$$reg), __ T4S,
17915             as_FloatRegister($src$$reg),
17916             (int)$shift$$constant);
17917   %}
17918   ins_pipe(vshift128_imm);
17919 %}
17920 
17921 instruct vsll2L(vecX dst, vecX src, vecX shift) %{
17922   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17923   match(Set dst (LShiftVL src shift));
17924   ins_cost(INSN_COST);
17925   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2D)&quot; %}
17926   ins_encode %{
17927     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17928             as_FloatRegister($src$$reg),
17929             as_FloatRegister($shift$$reg));
17930   %}
17931   ins_pipe(vshift128);
17932 %}
17933 
17934 instruct vsra2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17935   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17936   match(Set dst (RShiftVL src shift));
17937   ins_cost(INSN_COST);
17938   effect(TEMP tmp);
17939   format %{ &quot;negr  $tmp,$shift\t&quot;
17940             &quot;sshl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17941   ins_encode %{
17942     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17943             as_FloatRegister($shift$$reg));
17944     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17945             as_FloatRegister($src$$reg),
17946             as_FloatRegister($tmp$$reg));
17947   %}
17948   ins_pipe(vshift128);
17949 %}
17950 
17951 instruct vsrl2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17952   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17953   match(Set dst (URShiftVL src shift));
17954   ins_cost(INSN_COST);
17955   effect(TEMP tmp);
17956   format %{ &quot;negr  $tmp,$shift\t&quot;
17957             &quot;ushl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17958   ins_encode %{
17959     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17960             as_FloatRegister($shift$$reg));
17961     __ ushl(as_FloatRegister($dst$$reg), __ T2D,
17962             as_FloatRegister($src$$reg),
17963             as_FloatRegister($tmp$$reg));
17964   %}
17965   ins_pipe(vshift128);
17966 %}
17967 
17968 instruct vsll2L_imm(vecX dst, vecX src, immI shift) %{
17969   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17970   match(Set dst (LShiftVL src (LShiftCntV shift)));
17971   ins_cost(INSN_COST);
17972   format %{ &quot;shl    $dst, $src, $shift\t# vector (2D)&quot; %}
17973   ins_encode %{
17974     __ shl(as_FloatRegister($dst$$reg), __ T2D,
17975            as_FloatRegister($src$$reg),
17976            (int)$shift$$constant);
17977   %}
17978   ins_pipe(vshift128_imm);
17979 %}
17980 
17981 instruct vsra2L_imm(vecX dst, vecX src, immI shift) %{
17982   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17983   match(Set dst (RShiftVL src (RShiftCntV shift)));
17984   ins_cost(INSN_COST);
17985   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2D)&quot; %}
17986   ins_encode %{
17987     __ sshr(as_FloatRegister($dst$$reg), __ T2D,
17988             as_FloatRegister($src$$reg),
17989             (int)$shift$$constant);
17990   %}
17991   ins_pipe(vshift128_imm);
17992 %}
17993 
17994 instruct vsrl2L_imm(vecX dst, vecX src, immI shift) %{
17995   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17996   match(Set dst (URShiftVL src (RShiftCntV shift)));
17997   ins_cost(INSN_COST);
17998   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2D)&quot; %}
17999   ins_encode %{
18000     __ ushr(as_FloatRegister($dst$$reg), __ T2D,
18001             as_FloatRegister($src$$reg),
18002             (int)$shift$$constant);
18003   %}
18004   ins_pipe(vshift128_imm);
18005 %}
18006 
18007 instruct vmax2F(vecD dst, vecD src1, vecD src2)
18008 %{
18009   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18010   match(Set dst (MaxV src1 src2));
18011   ins_cost(INSN_COST);
18012   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2F)&quot; %}
18013   ins_encode %{
18014     __ fmax(as_FloatRegister($dst$$reg), __ T2S,
18015             as_FloatRegister($src1$$reg),
18016             as_FloatRegister($src2$$reg));
18017   %}
18018   ins_pipe(vdop_fp64);
18019 %}
18020 
18021 instruct vmax4F(vecX dst, vecX src1, vecX src2)
18022 %{
18023   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18024   match(Set dst (MaxV src1 src2));
18025   ins_cost(INSN_COST);
18026   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (4S)&quot; %}
18027   ins_encode %{
18028     __ fmax(as_FloatRegister($dst$$reg), __ T4S,
18029             as_FloatRegister($src1$$reg),
18030             as_FloatRegister($src2$$reg));
18031   %}
18032   ins_pipe(vdop_fp128);
18033 %}
18034 
18035 instruct vmax2D(vecX dst, vecX src1, vecX src2)
18036 %{
18037   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18038   match(Set dst (MaxV src1 src2));
18039   ins_cost(INSN_COST);
18040   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2D)&quot; %}
18041   ins_encode %{
18042     __ fmax(as_FloatRegister($dst$$reg), __ T2D,
18043             as_FloatRegister($src1$$reg),
18044             as_FloatRegister($src2$$reg));
18045   %}
18046   ins_pipe(vdop_fp128);
18047 %}
18048 
18049 instruct vmin2F(vecD dst, vecD src1, vecD src2)
18050 %{
18051   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18052   match(Set dst (MinV src1 src2));
18053   ins_cost(INSN_COST);
18054   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2F)&quot; %}
18055   ins_encode %{
18056     __ fmin(as_FloatRegister($dst$$reg), __ T2S,
18057             as_FloatRegister($src1$$reg),
18058             as_FloatRegister($src2$$reg));
18059   %}
18060   ins_pipe(vdop_fp64);
18061 %}
18062 
18063 instruct vmin4F(vecX dst, vecX src1, vecX src2)
18064 %{
18065   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18066   match(Set dst (MinV src1 src2));
18067   ins_cost(INSN_COST);
18068   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (4S)&quot; %}
18069   ins_encode %{
18070     __ fmin(as_FloatRegister($dst$$reg), __ T4S,
18071             as_FloatRegister($src1$$reg),
18072             as_FloatRegister($src2$$reg));
18073   %}
18074   ins_pipe(vdop_fp128);
18075 %}
18076 
18077 instruct vmin2D(vecX dst, vecX src1, vecX src2)
18078 %{
18079   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18080   match(Set dst (MinV src1 src2));
18081   ins_cost(INSN_COST);
18082   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2D)&quot; %}
18083   ins_encode %{
18084     __ fmin(as_FloatRegister($dst$$reg), __ T2D,
18085             as_FloatRegister($src1$$reg),
18086             as_FloatRegister($src2$$reg));
18087   %}
18088   ins_pipe(vdop_fp128);
18089 %}
18090 
18091 instruct vround2D_reg(vecX dst, vecX src, immI rmode) %{
18092   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18093   match(Set dst (RoundDoubleModeV src rmode));
18094   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
18095   ins_encode %{
18096     switch ($rmode$$constant) {
18097       case RoundDoubleModeNode::rmode_rint:
18098         __ frintn(as_FloatRegister($dst$$reg), __ T2D,
18099                   as_FloatRegister($src$$reg));
18100         break;
18101       case RoundDoubleModeNode::rmode_floor:
18102         __ frintm(as_FloatRegister($dst$$reg), __ T2D,
18103                   as_FloatRegister($src$$reg));
18104         break;
18105       case RoundDoubleModeNode::rmode_ceil:
18106         __ frintp(as_FloatRegister($dst$$reg), __ T2D,
18107                   as_FloatRegister($src$$reg));
18108         break;
18109     }
18110   %}
18111   ins_pipe(vdop_fp128);
18112 %}
18113 
18114 instruct vpopcount4I(vecX dst, vecX src) %{
18115   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
18116   match(Set dst (PopCountVI src));
18117   format %{
18118     &quot;cnt     $dst, $src\t# vector (16B)\n\t&quot;
18119     &quot;uaddlp  $dst, $dst\t# vector (16B)\n\t&quot;
18120     &quot;uaddlp  $dst, $dst\t# vector (8H)&quot;
18121   %}
18122   ins_encode %{
18123      __ cnt(as_FloatRegister($dst$$reg), __ T16B,
18124             as_FloatRegister($src$$reg));
18125      __ uaddlp(as_FloatRegister($dst$$reg), __ T16B,
18126                as_FloatRegister($dst$$reg));
18127      __ uaddlp(as_FloatRegister($dst$$reg), __ T8H,
18128                as_FloatRegister($dst$$reg));
18129   %}
18130   ins_pipe(pipe_class_default);
18131 %}
18132 
18133 instruct vpopcount2I(vecD dst, vecD src) %{
18134   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
18135   match(Set dst (PopCountVI src));
18136   format %{
18137     &quot;cnt     $dst, $src\t# vector (8B)\n\t&quot;
18138     &quot;uaddlp  $dst, $dst\t# vector (8B)\n\t&quot;
18139     &quot;uaddlp  $dst, $dst\t# vector (4H)&quot;
18140   %}
18141   ins_encode %{
18142      __ cnt(as_FloatRegister($dst$$reg), __ T8B,
18143             as_FloatRegister($src$$reg));
18144      __ uaddlp(as_FloatRegister($dst$$reg), __ T8B,
18145                as_FloatRegister($dst$$reg));
18146      __ uaddlp(as_FloatRegister($dst$$reg), __ T4H,
18147                as_FloatRegister($dst$$reg));
18148   %}
18149   ins_pipe(pipe_class_default);
18150 %}
18151 
18152 //----------PEEPHOLE RULES-----------------------------------------------------
18153 // These must follow all instruction definitions as they use the names
18154 // defined in the instructions definitions.
18155 //
18156 // peepmatch ( root_instr_name [preceding_instruction]* );
18157 //
18158 // peepconstraint %{
18159 // (instruction_number.operand_name relational_op instruction_number.operand_name
18160 //  [, ...] );
18161 // // instruction numbers are zero-based using left to right order in peepmatch
18162 //
18163 // peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
18164 // // provide an instruction_number.operand_name for each operand that appears
18165 // // in the replacement instruction&#39;s match rule
18166 //
18167 // ---------VM FLAGS---------------------------------------------------------
18168 //
18169 // All peephole optimizations can be turned off using -XX:-OptoPeephole
18170 //
18171 // Each peephole rule is given an identifying number starting with zero and
18172 // increasing by one in the order seen by the parser.  An individual peephole
18173 // can be enabled, and all others disabled, by using -XX:OptoPeepholeAt=#
18174 // on the command-line.
18175 //
18176 // ---------CURRENT LIMITATIONS----------------------------------------------
18177 //
18178 // Only match adjacent instructions in same basic block
18179 // Only equality constraints
18180 // Only constraints between operands, not (0.dest_reg == RAX_enc)
18181 // Only one replacement instruction
18182 //
18183 // ---------EXAMPLE----------------------------------------------------------
18184 //
18185 // // pertinent parts of existing instructions in architecture description
18186 // instruct movI(iRegINoSp dst, iRegI src)
18187 // %{
18188 //   match(Set dst (CopyI src));
18189 // %}
18190 //
18191 // instruct incI_iReg(iRegINoSp dst, immI1 src, rFlagsReg cr)
18192 // %{
18193 //   match(Set dst (AddI dst src));
18194 //   effect(KILL cr);
18195 // %}
18196 //
18197 // // Change (inc mov) to lea
18198 // peephole %{
18199 //   // increment preceeded by register-register move
18200 //   peepmatch ( incI_iReg movI );
18201 //   // require that the destination register of the increment
18202 //   // match the destination register of the move
18203 //   peepconstraint ( 0.dst == 1.dst );
18204 //   // construct a replacement instruction that sets
18205 //   // the destination to ( move&#39;s source register + one )
18206 //   peepreplace ( leaI_iReg_immI( 0.dst 1.src 0.src ) );
18207 // %}
18208 //
18209 
18210 // Implementation no longer uses movX instructions since
18211 // machine-independent system no longer uses CopyX nodes.
18212 //
18213 // peephole
18214 // %{
18215 //   peepmatch (incI_iReg movI);
18216 //   peepconstraint (0.dst == 1.dst);
18217 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18218 // %}
18219 
18220 // peephole
18221 // %{
18222 //   peepmatch (decI_iReg movI);
18223 //   peepconstraint (0.dst == 1.dst);
18224 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18225 // %}
18226 
18227 // peephole
18228 // %{
18229 //   peepmatch (addI_iReg_imm movI);
18230 //   peepconstraint (0.dst == 1.dst);
18231 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18232 // %}
18233 
18234 // peephole
18235 // %{
18236 //   peepmatch (incL_iReg movL);
18237 //   peepconstraint (0.dst == 1.dst);
18238 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18239 // %}
18240 
18241 // peephole
18242 // %{
18243 //   peepmatch (decL_iReg movL);
18244 //   peepconstraint (0.dst == 1.dst);
18245 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18246 // %}
18247 
18248 // peephole
18249 // %{
18250 //   peepmatch (addL_iReg_imm movL);
18251 //   peepconstraint (0.dst == 1.dst);
18252 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18253 // %}
18254 
18255 // peephole
18256 // %{
18257 //   peepmatch (addP_iReg_imm movP);
18258 //   peepconstraint (0.dst == 1.dst);
18259 //   peepreplace (leaP_iReg_imm(0.dst 1.src 0.src));
18260 // %}
18261 
18262 // // Change load of spilled value to only a spill
18263 // instruct storeI(memory mem, iRegI src)
18264 // %{
18265 //   match(Set mem (StoreI mem src));
18266 // %}
18267 //
18268 // instruct loadI(iRegINoSp dst, memory mem)
18269 // %{
18270 //   match(Set dst (LoadI mem));
18271 // %}
18272 //
18273 
18274 //----------SMARTSPILL RULES---------------------------------------------------
18275 // These must follow all instruction definitions as they use the names
18276 // defined in the instructions definitions.
18277 
18278 // Local Variables:
18279 // mode: c++
18280 // End:
    </pre>
  </body>
</html>