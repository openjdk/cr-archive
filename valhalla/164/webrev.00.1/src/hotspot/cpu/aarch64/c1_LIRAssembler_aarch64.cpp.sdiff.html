<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/aarch64/c1_LIRAssembler_aarch64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="aarch64.ad.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_aarch64.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/aarch64/c1_LIRAssembler_aarch64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  16  * You should have received a copy of the GNU General Public License version
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
  23  *
  24  */
  25 
  26 #include &quot;precompiled.hpp&quot;
  27 #include &quot;asm/macroAssembler.inline.hpp&quot;
  28 #include &quot;asm/assembler.hpp&quot;
  29 #include &quot;c1/c1_CodeStubs.hpp&quot;
  30 #include &quot;c1/c1_Compilation.hpp&quot;
  31 #include &quot;c1/c1_LIRAssembler.hpp&quot;
  32 #include &quot;c1/c1_MacroAssembler.hpp&quot;
  33 #include &quot;c1/c1_Runtime1.hpp&quot;
  34 #include &quot;c1/c1_ValueStack.hpp&quot;
  35 #include &quot;ci/ciArrayKlass.hpp&quot;

  36 #include &quot;ci/ciInstance.hpp&quot;
  37 #include &quot;code/compiledIC.hpp&quot;
  38 #include &quot;gc/shared/collectedHeap.hpp&quot;
  39 #include &quot;nativeInst_aarch64.hpp&quot;
  40 #include &quot;oops/objArrayKlass.hpp&quot;

  41 #include &quot;runtime/frame.inline.hpp&quot;
  42 #include &quot;runtime/sharedRuntime.hpp&quot;
  43 #include &quot;utilities/powerOfTwo.hpp&quot;
  44 #include &quot;vmreg_aarch64.inline.hpp&quot;
  45 
  46 
  47 #ifndef PRODUCT
  48 #define COMMENT(x)   do { __ block_comment(x); } while (0)
  49 #else
  50 #define COMMENT(x)
  51 #endif
  52 
  53 NEEDS_CLEANUP // remove this definitions ?
  54 const Register IC_Klass    = rscratch2;   // where the IC klass is cached
  55 const Register SYNC_header = r0;   // synchronization header
  56 const Register SHIFT_count = r0;   // where count for shift operations must be
  57 
  58 #define __ _masm-&gt;
  59 
  60 
</pre>
<hr />
<pre>
 211   // FIXME: This needs to be much more clever.  See x86.
 212 }
 213 
 214 
 215 void LIR_Assembler::osr_entry() {
 216   offsets()-&gt;set_value(CodeOffsets::OSR_Entry, code_offset());
 217   BlockBegin* osr_entry = compilation()-&gt;hir()-&gt;osr_entry();
 218   ValueStack* entry_state = osr_entry-&gt;state();
 219   int number_of_locks = entry_state-&gt;locks_size();
 220 
 221   // we jump here if osr happens with the interpreter
 222   // state set up to continue at the beginning of the
 223   // loop that triggered osr - in particular, we have
 224   // the following registers setup:
 225   //
 226   // r2: osr buffer
 227   //
 228 
 229   // build frame
 230   ciMethod* m = compilation()-&gt;method();
<span class="line-modified"> 231   __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes());</span>
 232 
 233   // OSR buffer is
 234   //
 235   // locals[nlocals-1..0]
 236   // monitors[0..number_of_locks]
 237   //
 238   // locals is a direct copy of the interpreter frame so in the osr buffer
 239   // so first slot in the local array is the last local from the interpreter
 240   // and last slot is local[0] (receiver) from the interpreter
 241   //
 242   // Similarly with locks. The first lock slot in the osr buffer is the nth lock
 243   // from the interpreter frame, the nth lock slot in the osr buffer is 0th lock
 244   // in the interpreter frame (the method lock if a sync method)
 245 
 246   // Initialize monitors in the compiled activation.
 247   //   r2: pointer to osr buffer
 248   //
 249   // All other registers are dead at this point and the locals will be
 250   // copied into place by code emitted in the IR.
 251 
</pre>
<hr />
<pre>
 426   MonitorExitStub* stub = NULL;
 427   if (method()-&gt;is_synchronized()) {
 428     monitor_address(0, FrameMap::r0_opr);
 429     stub = new MonitorExitStub(FrameMap::r0_opr, true, 0);
 430     __ unlock_object(r5, r4, r0, *stub-&gt;entry());
 431     __ bind(*stub-&gt;continuation());
 432   }
 433 
 434   if (compilation()-&gt;env()-&gt;dtrace_method_probes()) {
 435     __ mov(c_rarg0, rthread);
 436     __ mov_metadata(c_rarg1, method()-&gt;constant_encoding());
 437     __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_method_exit), c_rarg0, c_rarg1);
 438   }
 439 
 440   if (method()-&gt;is_synchronized() || compilation()-&gt;env()-&gt;dtrace_method_probes()) {
 441     __ mov(r0, r19);  // Restore the exception
 442   }
 443 
 444   // remove the activation and dispatch to the unwind handler
 445   __ block_comment(&quot;remove_frame and dispatch to the unwind handler&quot;);
<span class="line-modified"> 446   __ remove_frame(initial_frame_size_in_bytes());</span>
 447   __ far_jump(RuntimeAddress(Runtime1::entry_for(Runtime1::unwind_exception_id)));
 448 
 449   // Emit the slow path assembly
 450   if (stub != NULL) {
 451     stub-&gt;emit_code(this);
 452   }
 453 
 454   return offset;
 455 }
 456 
 457 
 458 int LIR_Assembler::emit_deopt_handler() {
 459   // if the last instruction is a call (typically to do a throw which
 460   // is coming at the end after block reordering) the return address
 461   // must still point into the code area in order to avoid assertion
 462   // failures when searching for the corresponding bci =&gt; add a nop
 463   // (was bug 5/14/1999 - gri)
 464   __ nop();
 465 
 466   // generate code for exception handler
</pre>
<hr />
<pre>
 477   __ far_jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 478   guarantee(code_offset() - offset &lt;= deopt_handler_size(), &quot;overflow&quot;);
 479   __ end_a_stub();
 480 
 481   return offset;
 482 }
 483 
 484 void LIR_Assembler::add_debug_info_for_branch(address adr, CodeEmitInfo* info) {
 485   _masm-&gt;code_section()-&gt;relocate(adr, relocInfo::poll_type);
 486   int pc_offset = code_offset();
 487   flush_debug_info(pc_offset);
 488   info-&gt;record_debug_info(compilation()-&gt;debug_info_recorder(), pc_offset);
 489   if (info-&gt;exception_handlers() != NULL) {
 490     compilation()-&gt;add_exception_handlers_for_pco(pc_offset, info-&gt;exception_handlers());
 491   }
 492 }
 493 
 494 void LIR_Assembler::return_op(LIR_Opr result) {
 495   assert(result-&gt;is_illegal() || !result-&gt;is_single_cpu() || result-&gt;as_register() == r0, &quot;word returns are in r0,&quot;);
 496 















 497   // Pop the stack before the safepoint code
<span class="line-modified"> 498   __ remove_frame(initial_frame_size_in_bytes());</span>
 499 
 500   if (StackReservedPages &gt; 0 &amp;&amp; compilation()-&gt;has_reserved_stack_access()) {
 501     __ reserved_stack_check();
 502   }
 503 
 504   __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);
 505   __ ret(lr);
 506 }
 507 




 508 int LIR_Assembler::safepoint_poll(LIR_Opr tmp, CodeEmitInfo* info) {
 509   guarantee(info != NULL, &quot;Shouldn&#39;t be NULL&quot;);
 510   __ get_polling_page(rscratch1, relocInfo::poll_type);
 511   add_debug_info_for_branch(info);  // This isn&#39;t just debug info:
 512                                     // it&#39;s the oop map
 513   __ read_polling_page(rscratch1, relocInfo::poll_type);
 514   return __ offset();
 515 }
 516 
 517 
 518 void LIR_Assembler::move_regs(Register from_reg, Register to_reg) {
 519   if (from_reg == r31_sp)
 520     from_reg = sp;
 521   if (to_reg == r31_sp)
 522     to_reg = sp;
 523   __ mov(to_reg, from_reg);
 524 }
 525 
 526 void LIR_Assembler::swap_reg(Register a, Register b) { Unimplemented(); }
 527 
</pre>
<hr />
<pre>
 533 
 534   switch (c-&gt;type()) {
 535     case T_INT: {
 536       assert(patch_code == lir_patch_none, &quot;no patching handled here&quot;);
 537       __ movw(dest-&gt;as_register(), c-&gt;as_jint());
 538       break;
 539     }
 540 
 541     case T_ADDRESS: {
 542       assert(patch_code == lir_patch_none, &quot;no patching handled here&quot;);
 543       __ mov(dest-&gt;as_register(), c-&gt;as_jint());
 544       break;
 545     }
 546 
 547     case T_LONG: {
 548       assert(patch_code == lir_patch_none, &quot;no patching handled here&quot;);
 549       __ mov(dest-&gt;as_register_lo(), (intptr_t)c-&gt;as_jlong());
 550       break;
 551     }
 552 

 553     case T_OBJECT: {
<span class="line-modified"> 554         if (patch_code == lir_patch_none) {</span>
<span class="line-removed"> 555           jobject2reg(c-&gt;as_jobject(), dest-&gt;as_register());</span>
<span class="line-removed"> 556         } else {</span>
 557           jobject2reg_with_patching(dest-&gt;as_register(), info);


 558         }
 559       break;
 560     }
 561 
 562     case T_METADATA: {
 563       if (patch_code != lir_patch_none) {
 564         klass2reg_with_patching(dest-&gt;as_register(), info);
 565       } else {
 566         __ mov_metadata(dest-&gt;as_register(), c-&gt;as_metadata());
 567       }
 568       break;
 569     }
 570 
 571     case T_FLOAT: {
 572       if (__ operand_valid_for_float_immediate(c-&gt;as_jfloat())) {
 573         __ fmovs(dest-&gt;as_float_reg(), (c-&gt;as_jfloat()));
 574       } else {
 575         __ adr(rscratch1, InternalAddress(float_constant(c-&gt;as_jfloat())));
 576         __ ldrs(dest-&gt;as_float_reg(), Address(rscratch1));
 577       }
</pre>
<hr />
<pre>
 579     }
 580 
 581     case T_DOUBLE: {
 582       if (__ operand_valid_for_float_immediate(c-&gt;as_jdouble())) {
 583         __ fmovd(dest-&gt;as_double_reg(), (c-&gt;as_jdouble()));
 584       } else {
 585         __ adr(rscratch1, InternalAddress(double_constant(c-&gt;as_jdouble())));
 586         __ ldrd(dest-&gt;as_double_reg(), Address(rscratch1));
 587       }
 588       break;
 589     }
 590 
 591     default:
 592       ShouldNotReachHere();
 593   }
 594 }
 595 
 596 void LIR_Assembler::const2stack(LIR_Opr src, LIR_Opr dest) {
 597   LIR_Const* c = src-&gt;as_constant_ptr();
 598   switch (c-&gt;type()) {

 599   case T_OBJECT:
 600     {
 601       if (! c-&gt;as_jobject())
 602         __ str(zr, frame_map()-&gt;address_for_slot(dest-&gt;single_stack_ix()));
 603       else {
 604         const2reg(src, FrameMap::rscratch1_opr, lir_patch_none, NULL);
 605         reg2stack(FrameMap::rscratch1_opr, dest, c-&gt;type(), false);
 606       }
 607     }
 608     break;
 609   case T_ADDRESS:
 610     {
 611       const2reg(src, FrameMap::rscratch1_opr, lir_patch_none, NULL);
 612       reg2stack(FrameMap::rscratch1_opr, dest, c-&gt;type(), false);
 613     }
 614   case T_INT:
 615   case T_FLOAT:
 616     {
 617       Register reg = zr;
 618       if (c-&gt;as_jint_bits() == 0)
</pre>
<hr />
<pre>
 645 void LIR_Assembler::const2mem(LIR_Opr src, LIR_Opr dest, BasicType type, CodeEmitInfo* info, bool wide) {
 646   assert(src-&gt;is_constant(), &quot;should not call otherwise&quot;);
 647   LIR_Const* c = src-&gt;as_constant_ptr();
 648   LIR_Address* to_addr = dest-&gt;as_address_ptr();
 649 
 650   void (Assembler::* insn)(Register Rt, const Address &amp;adr);
 651 
 652   switch (type) {
 653   case T_ADDRESS:
 654     assert(c-&gt;as_jint() == 0, &quot;should be&quot;);
 655     insn = &amp;Assembler::str;
 656     break;
 657   case T_LONG:
 658     assert(c-&gt;as_jlong() == 0, &quot;should be&quot;);
 659     insn = &amp;Assembler::str;
 660     break;
 661   case T_INT:
 662     assert(c-&gt;as_jint() == 0, &quot;should be&quot;);
 663     insn = &amp;Assembler::strw;
 664     break;

 665   case T_OBJECT:
 666   case T_ARRAY:


 667     assert(c-&gt;as_jobject() == 0, &quot;should be&quot;);
 668     if (UseCompressedOops &amp;&amp; !wide) {
 669       insn = &amp;Assembler::strw;
 670     } else {
 671       insn = &amp;Assembler::str;
 672     }
 673     break;
 674   case T_CHAR:
 675   case T_SHORT:
 676     assert(c-&gt;as_jint() == 0, &quot;should be&quot;);
 677     insn = &amp;Assembler::strh;
 678     break;
 679   case T_BOOLEAN:
 680   case T_BYTE:
 681     assert(c-&gt;as_jint() == 0, &quot;should be&quot;);
 682     insn = &amp;Assembler::strb;
 683     break;
 684   default:
 685     ShouldNotReachHere();
 686     insn = &amp;Assembler::str;  // unreachable
 687   }
 688 
 689   if (info) add_debug_info_for_null_check_here(info);
 690   (_masm-&gt;*insn)(zr, as_Address(to_addr, rscratch1));
 691 }
 692 
 693 void LIR_Assembler::reg2reg(LIR_Opr src, LIR_Opr dest) {
 694   assert(src-&gt;is_register(), &quot;should not call otherwise&quot;);
 695   assert(dest-&gt;is_register(), &quot;should not call otherwise&quot;);
 696 
 697   // move between cpu-registers
 698   if (dest-&gt;is_single_cpu()) {
 699     if (src-&gt;type() == T_LONG) {
 700       // Can do LONG -&gt; OBJECT
 701       move_regs(src-&gt;as_register_lo(), dest-&gt;as_register());
 702       return;
 703     }
 704     assert(src-&gt;is_single_cpu(), &quot;must match&quot;);
<span class="line-modified"> 705     if (src-&gt;type() == T_OBJECT) {</span>
 706       __ verify_oop(src-&gt;as_register());
 707     }
 708     move_regs(src-&gt;as_register(), dest-&gt;as_register());
 709 
 710   } else if (dest-&gt;is_double_cpu()) {
 711     if (is_reference_type(src-&gt;type())) {
 712       // Surprising to me but we can see move of a long to t_object
 713       __ verify_oop(src-&gt;as_register());
 714       move_regs(src-&gt;as_register(), dest-&gt;as_register_lo());
 715       return;
 716     }
 717     assert(src-&gt;is_double_cpu(), &quot;must match&quot;);
 718     Register f_lo = src-&gt;as_register_lo();
 719     Register f_hi = src-&gt;as_register_hi();
 720     Register t_lo = dest-&gt;as_register_lo();
 721     Register t_hi = dest-&gt;as_register_hi();
 722     assert(f_hi == f_lo, &quot;must be same&quot;);
 723     assert(t_hi == t_lo, &quot;must be same&quot;);
 724     move_regs(f_lo, t_lo);
 725 
</pre>
<hr />
<pre>
 779 
 780     if (UseCompressedOops &amp;&amp; !wide) {
 781       __ encode_heap_oop(compressed_src, src-&gt;as_register());
 782     } else {
 783       compressed_src = src-&gt;as_register();
 784     }
 785   }
 786 
 787   int null_check_here = code_offset();
 788   switch (type) {
 789     case T_FLOAT: {
 790       __ strs(src-&gt;as_float_reg(), as_Address(to_addr));
 791       break;
 792     }
 793 
 794     case T_DOUBLE: {
 795       __ strd(src-&gt;as_double_reg(), as_Address(to_addr));
 796       break;
 797     }
 798 

 799     case T_ARRAY:   // fall through
 800     case T_OBJECT:  // fall through
 801       if (UseCompressedOops &amp;&amp; !wide) {
 802         __ strw(compressed_src, as_Address(to_addr, rscratch2));
 803       } else {
 804          __ str(compressed_src, as_Address(to_addr));
 805       }
 806       break;
 807     case T_METADATA:
 808       // We get here to store a method pointer to the stack to pass to
 809       // a dtrace runtime call. This can&#39;t work on 64 bit with
 810       // compressed klass ptrs: T_METADATA can be a compressed klass
 811       // ptr or a 64 bit method pointer.
 812       ShouldNotReachHere();
 813       __ str(src-&gt;as_register(), as_Address(to_addr));
 814       break;
 815     case T_ADDRESS:
 816       __ str(src-&gt;as_register(), as_Address(to_addr));
 817       break;
 818     case T_INT:
</pre>
<hr />
<pre>
 904   add_call_info_here(info);
 905 }
 906 
 907 void LIR_Assembler::stack2stack(LIR_Opr src, LIR_Opr dest, BasicType type) {
 908 
 909   LIR_Opr temp;
 910   if (type == T_LONG || type == T_DOUBLE)
 911     temp = FrameMap::rscratch1_long_opr;
 912   else
 913     temp = FrameMap::rscratch1_opr;
 914 
 915   stack2reg(src, temp, src-&gt;type());
 916   reg2stack(temp, dest, dest-&gt;type(), false);
 917 }
 918 
 919 
 920 void LIR_Assembler::mem2reg(LIR_Opr src, LIR_Opr dest, BasicType type, LIR_PatchCode patch_code, CodeEmitInfo* info, bool wide, bool /* unaligned */) {
 921   LIR_Address* addr = src-&gt;as_address_ptr();
 922   LIR_Address* from_addr = src-&gt;as_address_ptr();
 923 
<span class="line-modified"> 924   if (addr-&gt;base()-&gt;type() == T_OBJECT) {</span>
 925     __ verify_oop(addr-&gt;base()-&gt;as_pointer_register());
 926   }
 927 
 928   if (patch_code != lir_patch_none) {
 929     deoptimize_trap(info);
 930     return;
 931   }
 932 
 933   if (info != NULL) {
 934     add_debug_info_for_null_check_here(info);
 935   }
 936   int null_check_here = code_offset();
 937   switch (type) {
 938     case T_FLOAT: {
 939       __ ldrs(dest-&gt;as_float_reg(), as_Address(from_addr));
 940       break;
 941     }
 942 
 943     case T_DOUBLE: {
 944       __ ldrd(dest-&gt;as_double_reg(), as_Address(from_addr));
 945       break;
 946     }
 947 

 948     case T_ARRAY:   // fall through
 949     case T_OBJECT:  // fall through
 950       if (UseCompressedOops &amp;&amp; !wide) {
 951         __ ldrw(dest-&gt;as_register(), as_Address(from_addr));
 952       } else {
 953          __ ldr(dest-&gt;as_register(), as_Address(from_addr));
 954       }
 955       break;
 956     case T_METADATA:
 957       // We get here to store a method pointer to the stack to pass to
 958       // a dtrace runtime call. This can&#39;t work on 64 bit with
 959       // compressed klass ptrs: T_METADATA can be a compressed klass
 960       // ptr or a 64 bit method pointer.
 961       ShouldNotReachHere();
 962       __ ldr(dest-&gt;as_register(), as_Address(from_addr));
 963       break;
 964     case T_ADDRESS:
 965       // FIXME: OMG this is a horrible kludge.  Any offset from an
 966       // address that matches klass_offset_in_bytes() will be loaded
 967       // as a word, not a long.
</pre>
<hr />
<pre>
 993       break;
 994     case T_SHORT:
 995       __ ldrsh(dest-&gt;as_register(), as_Address(from_addr));
 996       break;
 997 
 998     default:
 999       ShouldNotReachHere();
1000   }
1001 
1002   if (is_reference_type(type)) {
1003     if (UseCompressedOops &amp;&amp; !wide) {
1004       __ decode_heap_oop(dest-&gt;as_register());
1005     }
1006 
1007     if (!UseZGC) {
1008       // Load barrier has not yet been applied, so ZGC can&#39;t verify the oop here
1009       __ verify_oop(dest-&gt;as_register());
1010     }
1011   } else if (type == T_ADDRESS &amp;&amp; addr-&gt;disp() == oopDesc::klass_offset_in_bytes()) {
1012     if (UseCompressedClassPointers) {

1013       __ decode_klass_not_null(dest-&gt;as_register());


1014     }
1015   }
1016 }
1017 














1018 
1019 int LIR_Assembler::array_element_size(BasicType type) const {
1020   int elem_size = type2aelembytes(type);
1021   return exact_log2(elem_size);
1022 }
1023 
1024 
1025 void LIR_Assembler::emit_op3(LIR_Op3* op) {
1026   switch (op-&gt;code()) {
1027   case lir_idiv:
1028   case lir_irem:
1029     arithmetic_idiv(op-&gt;code(),
1030                     op-&gt;in_opr1(),
1031                     op-&gt;in_opr2(),
1032                     op-&gt;in_opr3(),
1033                     op-&gt;result_opr(),
1034                     op-&gt;info());
1035     break;
1036   case lir_fmad:
1037     __ fmaddd(op-&gt;result_opr()-&gt;as_double_reg(),
</pre>
<hr />
<pre>
1189     __ ldrb(rscratch1, Address(op-&gt;klass()-&gt;as_register(),
1190                                InstanceKlass::init_state_offset()));
1191     __ cmpw(rscratch1, InstanceKlass::fully_initialized);
1192     add_debug_info_for_null_check_here(op-&gt;stub()-&gt;info());
1193     __ br(Assembler::NE, *op-&gt;stub()-&gt;entry());
1194   }
1195   __ allocate_object(op-&gt;obj()-&gt;as_register(),
1196                      op-&gt;tmp1()-&gt;as_register(),
1197                      op-&gt;tmp2()-&gt;as_register(),
1198                      op-&gt;header_size(),
1199                      op-&gt;object_size(),
1200                      op-&gt;klass()-&gt;as_register(),
1201                      *op-&gt;stub()-&gt;entry());
1202   __ bind(*op-&gt;stub()-&gt;continuation());
1203 }
1204 
1205 void LIR_Assembler::emit_alloc_array(LIR_OpAllocArray* op) {
1206   Register len =  op-&gt;len()-&gt;as_register();
1207   __ uxtw(len, len);
1208 
<span class="line-modified">1209   if (UseSlowPath ||</span>
1210       (!UseFastNewObjectArray &amp;&amp; is_reference_type(op-&gt;type())) ||
1211       (!UseFastNewTypeArray   &amp;&amp; !is_reference_type(op-&gt;type()))) {
1212     __ b(*op-&gt;stub()-&gt;entry());
1213   } else {
1214     Register tmp1 = op-&gt;tmp1()-&gt;as_register();
1215     Register tmp2 = op-&gt;tmp2()-&gt;as_register();
1216     Register tmp3 = op-&gt;tmp3()-&gt;as_register();
1217     if (len == tmp1) {
1218       tmp1 = tmp3;
1219     } else if (len == tmp2) {
1220       tmp2 = tmp3;
1221     } else if (len == tmp3) {
1222       // everything is ok
1223     } else {
1224       __ mov(tmp3, len);
1225     }
1226     __ allocate_array(op-&gt;obj()-&gt;as_register(),
1227                       len,
1228                       tmp1,
1229                       tmp2,
</pre>
<hr />
<pre>
1501     __ bind(success);
1502     if (dst != obj) {
1503       __ mov(dst, obj);
1504     }
1505   } else if (code == lir_instanceof) {
1506     Register obj = op-&gt;object()-&gt;as_register();
1507     Register dst = op-&gt;result_opr()-&gt;as_register();
1508     Label success, failure, done;
1509     emit_typecheck_helper(op, &amp;success, &amp;failure, &amp;failure);
1510     __ bind(failure);
1511     __ mov(dst, zr);
1512     __ b(done);
1513     __ bind(success);
1514     __ mov(dst, 1);
1515     __ bind(done);
1516   } else {
1517     ShouldNotReachHere();
1518   }
1519 }
1520 


























































































































1521 void LIR_Assembler::casw(Register addr, Register newval, Register cmpval) {
1522   __ cmpxchg(addr, cmpval, newval, Assembler::word, /* acquire*/ true, /* release*/ true, /* weak*/ false, rscratch1);
1523   __ cset(rscratch1, Assembler::NE);
1524   __ membar(__ AnyAny);
1525 }
1526 
1527 void LIR_Assembler::casl(Register addr, Register newval, Register cmpval) {
1528   __ cmpxchg(addr, cmpval, newval, Assembler::xword, /* acquire*/ true, /* release*/ true, /* weak*/ false, rscratch1);
1529   __ cset(rscratch1, Assembler::NE);
1530   __ membar(__ AnyAny);
1531 }
1532 
1533 
1534 void LIR_Assembler::emit_compare_and_swap(LIR_OpCompareAndSwap* op) {
1535   assert(VM_Version::supports_cx8(), &quot;wrong machine&quot;);
1536   Register addr;
1537   if (op-&gt;addr()-&gt;is_register()) {
1538     addr = as_reg(op-&gt;addr());
1539   } else {
1540     assert(op-&gt;addr()-&gt;is_address(), &quot;what else?&quot;);
</pre>
<hr />
<pre>
1944     }
1945 
1946     if (opr2-&gt;is_constant()) {
1947       bool is_32bit = false; // width of register operand
1948       jlong imm;
1949 
1950       switch(opr2-&gt;type()) {
1951       case T_INT:
1952         imm = opr2-&gt;as_constant_ptr()-&gt;as_jint();
1953         is_32bit = true;
1954         break;
1955       case T_LONG:
1956         imm = opr2-&gt;as_constant_ptr()-&gt;as_jlong();
1957         break;
1958       case T_ADDRESS:
1959         imm = opr2-&gt;as_constant_ptr()-&gt;as_jint();
1960         break;
1961       case T_METADATA:
1962         imm = (intptr_t)(opr2-&gt;as_constant_ptr()-&gt;as_metadata());
1963         break;

1964       case T_OBJECT:
1965       case T_ARRAY:
1966         jobject2reg(opr2-&gt;as_constant_ptr()-&gt;as_jobject(), rscratch1);
1967         __ cmpoop(reg1, rscratch1);
1968         return;
1969       default:
1970         ShouldNotReachHere();
1971         imm = 0;  // unreachable
1972         break;
1973       }
1974 
1975       if (Assembler::operand_valid_for_add_sub_immediate(imm)) {
1976         if (is_32bit)
1977           __ cmpw(reg1, imm);
1978         else
1979           __ subs(zr, reg1, imm);
1980         return;
1981       } else {
1982         __ mov(rscratch1, imm);
1983         if (is_32bit)
</pre>
<hr />
<pre>
2110   __ b(_unwind_handler_entry);
2111 }
2112 
2113 
2114 void LIR_Assembler::shift_op(LIR_Code code, LIR_Opr left, LIR_Opr count, LIR_Opr dest, LIR_Opr tmp) {
2115   Register lreg = left-&gt;is_single_cpu() ? left-&gt;as_register() : left-&gt;as_register_lo();
2116   Register dreg = dest-&gt;is_single_cpu() ? dest-&gt;as_register() : dest-&gt;as_register_lo();
2117 
2118   switch (left-&gt;type()) {
2119     case T_INT: {
2120       switch (code) {
2121       case lir_shl:  __ lslvw (dreg, lreg, count-&gt;as_register()); break;
2122       case lir_shr:  __ asrvw (dreg, lreg, count-&gt;as_register()); break;
2123       case lir_ushr: __ lsrvw (dreg, lreg, count-&gt;as_register()); break;
2124       default:
2125         ShouldNotReachHere();
2126         break;
2127       }
2128       break;
2129     case T_LONG:

2130     case T_ADDRESS:
2131     case T_OBJECT:
2132       switch (code) {
2133       case lir_shl:  __ lslv (dreg, lreg, count-&gt;as_register()); break;
2134       case lir_shr:  __ asrv (dreg, lreg, count-&gt;as_register()); break;
2135       case lir_ushr: __ lsrv (dreg, lreg, count-&gt;as_register()); break;
2136       default:
2137         ShouldNotReachHere();
2138         break;
2139       }
2140       break;
2141     default:
2142       ShouldNotReachHere();
2143       break;
2144     }
2145   }
2146 }
2147 
2148 
2149 void LIR_Assembler::shift_op(LIR_Code code, LIR_Opr left, jint count, LIR_Opr dest) {
2150   Register dreg = dest-&gt;is_single_cpu() ? dest-&gt;as_register() : dest-&gt;as_register_lo();
2151   Register lreg = left-&gt;is_single_cpu() ? left-&gt;as_register() : left-&gt;as_register_lo();
2152 
2153   switch (left-&gt;type()) {
2154     case T_INT: {
2155       switch (code) {
2156       case lir_shl:  __ lslw (dreg, lreg, count); break;
2157       case lir_shr:  __ asrw (dreg, lreg, count); break;
2158       case lir_ushr: __ lsrw (dreg, lreg, count); break;
2159       default:
2160         ShouldNotReachHere();
2161         break;
2162       }
2163       break;
2164     case T_LONG:
2165     case T_ADDRESS:

2166     case T_OBJECT:
2167       switch (code) {
2168       case lir_shl:  __ lsl (dreg, lreg, count); break;
2169       case lir_shr:  __ asr (dreg, lreg, count); break;
2170       case lir_ushr: __ lsr (dreg, lreg, count); break;
2171       default:
2172         ShouldNotReachHere();
2173         break;
2174       }
2175       break;
2176     default:
2177       ShouldNotReachHere();
2178       break;
2179     }
2180   }
2181 }
2182 
2183 
2184 void LIR_Assembler::store_parameter(Register r, int offset_from_rsp_in_words) {
2185   assert(offset_from_rsp_in_words &gt;= 0, &quot;invalid offset from rsp&quot;);
</pre>
<hr />
<pre>
2190 
2191 
2192 void LIR_Assembler::store_parameter(jint c,     int offset_from_rsp_in_words) {
2193   assert(offset_from_rsp_in_words &gt;= 0, &quot;invalid offset from rsp&quot;);
2194   int offset_from_rsp_in_bytes = offset_from_rsp_in_words * BytesPerWord;
2195   assert(offset_from_rsp_in_bytes &lt; frame_map()-&gt;reserved_argument_area_size(), &quot;invalid offset&quot;);
2196   __ mov (rscratch1, c);
2197   __ str (rscratch1, Address(sp, offset_from_rsp_in_bytes));
2198 }
2199 
2200 
2201 void LIR_Assembler::store_parameter(jobject o,  int offset_from_rsp_in_words) {
2202   ShouldNotReachHere();
2203   assert(offset_from_rsp_in_words &gt;= 0, &quot;invalid offset from rsp&quot;);
2204   int offset_from_rsp_in_bytes = offset_from_rsp_in_words * BytesPerWord;
2205   assert(offset_from_rsp_in_bytes &lt; frame_map()-&gt;reserved_argument_area_size(), &quot;invalid offset&quot;);
2206   __ lea(rscratch1, __ constant_oop_address(o));
2207   __ str(rscratch1, Address(sp, offset_from_rsp_in_bytes));
2208 }
2209 













2210 
2211 // This code replaces a call to arraycopy; no exception may
2212 // be thrown in this code, they must be thrown in the System.arraycopy
2213 // activation frame; we could save some checks if this would not be the case
2214 void LIR_Assembler::emit_arraycopy(LIR_OpArrayCopy* op) {
2215   ciArrayKlass* default_type = op-&gt;expected_type();
2216   Register src = op-&gt;src()-&gt;as_register();
2217   Register dst = op-&gt;dst()-&gt;as_register();
2218   Register src_pos = op-&gt;src_pos()-&gt;as_register();
2219   Register dst_pos = op-&gt;dst_pos()-&gt;as_register();
2220   Register length  = op-&gt;length()-&gt;as_register();
2221   Register tmp = op-&gt;tmp()-&gt;as_register();
2222 
2223   __ resolve(ACCESS_READ, src);
2224   __ resolve(ACCESS_WRITE, dst);
2225 
2226   CodeStub* stub = op-&gt;stub();
2227   int flags = op-&gt;flags();
2228   BasicType basic_type = default_type != NULL ? default_type-&gt;element_type()-&gt;basic_type() : T_ILLEGAL;
2229   if (is_reference_type(basic_type)) basic_type = T_OBJECT;
2230 
















2231   // if we don&#39;t know anything, just go through the generic arraycopy
2232   if (default_type == NULL // || basic_type == T_OBJECT
2233       ) {
2234     Label done;
2235     assert(src == r1 &amp;&amp; src_pos == r2, &quot;mismatch in calling convention&quot;);
2236 
2237     // Save the arguments in case the generic arraycopy fails and we
2238     // have to fall back to the JNI stub
2239     __ stp(dst,     dst_pos, Address(sp, 0*BytesPerWord));
2240     __ stp(length,  src_pos, Address(sp, 2*BytesPerWord));
2241     __ str(src,              Address(sp, 4*BytesPerWord));
2242 
2243     address copyfunc_addr = StubRoutines::generic_arraycopy();
2244     assert(copyfunc_addr != NULL, &quot;generic arraycopy stub required&quot;);
2245 
2246     // The arguments are in java calling convention so we shift them
2247     // to C convention
2248     assert_different_registers(c_rarg0, j_rarg1, j_rarg2, j_rarg3, j_rarg4);
2249     __ mov(c_rarg0, j_rarg0);
2250     assert_different_registers(c_rarg1, j_rarg2, j_rarg3, j_rarg4);
</pre>
<hr />
<pre>
3111 #endif
3112 }
3113 
3114 void LIR_Assembler::atomic_op(LIR_Code code, LIR_Opr src, LIR_Opr data, LIR_Opr dest, LIR_Opr tmp_op) {
3115   Address addr = as_Address(src-&gt;as_address_ptr());
3116   BasicType type = src-&gt;type();
3117   bool is_oop = is_reference_type(type);
3118 
3119   void (MacroAssembler::* add)(Register prev, RegisterOrConstant incr, Register addr);
3120   void (MacroAssembler::* xchg)(Register prev, Register newv, Register addr);
3121 
3122   switch(type) {
3123   case T_INT:
3124     xchg = &amp;MacroAssembler::atomic_xchgalw;
3125     add = &amp;MacroAssembler::atomic_addalw;
3126     break;
3127   case T_LONG:
3128     xchg = &amp;MacroAssembler::atomic_xchgal;
3129     add = &amp;MacroAssembler::atomic_addal;
3130     break;

3131   case T_OBJECT:
3132   case T_ARRAY:
3133     if (UseCompressedOops) {
3134       xchg = &amp;MacroAssembler::atomic_xchgalw;
3135       add = &amp;MacroAssembler::atomic_addalw;
3136     } else {
3137       xchg = &amp;MacroAssembler::atomic_xchgal;
3138       add = &amp;MacroAssembler::atomic_addal;
3139     }
3140     break;
3141   default:
3142     ShouldNotReachHere();
3143     xchg = &amp;MacroAssembler::atomic_xchgal;
3144     add = &amp;MacroAssembler::atomic_addal; // unreachable
3145   }
3146 
3147   switch (code) {
3148   case lir_xadd:
3149     {
3150       RegisterOrConstant inc;
</pre>
</td>
<td>
<hr />
<pre>
  16  * You should have received a copy of the GNU General Public License version
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
  23  *
  24  */
  25 
  26 #include &quot;precompiled.hpp&quot;
  27 #include &quot;asm/macroAssembler.inline.hpp&quot;
  28 #include &quot;asm/assembler.hpp&quot;
  29 #include &quot;c1/c1_CodeStubs.hpp&quot;
  30 #include &quot;c1/c1_Compilation.hpp&quot;
  31 #include &quot;c1/c1_LIRAssembler.hpp&quot;
  32 #include &quot;c1/c1_MacroAssembler.hpp&quot;
  33 #include &quot;c1/c1_Runtime1.hpp&quot;
  34 #include &quot;c1/c1_ValueStack.hpp&quot;
  35 #include &quot;ci/ciArrayKlass.hpp&quot;
<span class="line-added">  36 #include &quot;ci/ciInlineKlass.hpp&quot;</span>
  37 #include &quot;ci/ciInstance.hpp&quot;
  38 #include &quot;code/compiledIC.hpp&quot;
  39 #include &quot;gc/shared/collectedHeap.hpp&quot;
  40 #include &quot;nativeInst_aarch64.hpp&quot;
  41 #include &quot;oops/objArrayKlass.hpp&quot;
<span class="line-added">  42 #include &quot;oops/oop.inline.hpp&quot;</span>
  43 #include &quot;runtime/frame.inline.hpp&quot;
  44 #include &quot;runtime/sharedRuntime.hpp&quot;
  45 #include &quot;utilities/powerOfTwo.hpp&quot;
  46 #include &quot;vmreg_aarch64.inline.hpp&quot;
  47 
  48 
  49 #ifndef PRODUCT
  50 #define COMMENT(x)   do { __ block_comment(x); } while (0)
  51 #else
  52 #define COMMENT(x)
  53 #endif
  54 
  55 NEEDS_CLEANUP // remove this definitions ?
  56 const Register IC_Klass    = rscratch2;   // where the IC klass is cached
  57 const Register SYNC_header = r0;   // synchronization header
  58 const Register SHIFT_count = r0;   // where count for shift operations must be
  59 
  60 #define __ _masm-&gt;
  61 
  62 
</pre>
<hr />
<pre>
 213   // FIXME: This needs to be much more clever.  See x86.
 214 }
 215 
 216 
 217 void LIR_Assembler::osr_entry() {
 218   offsets()-&gt;set_value(CodeOffsets::OSR_Entry, code_offset());
 219   BlockBegin* osr_entry = compilation()-&gt;hir()-&gt;osr_entry();
 220   ValueStack* entry_state = osr_entry-&gt;state();
 221   int number_of_locks = entry_state-&gt;locks_size();
 222 
 223   // we jump here if osr happens with the interpreter
 224   // state set up to continue at the beginning of the
 225   // loop that triggered osr - in particular, we have
 226   // the following registers setup:
 227   //
 228   // r2: osr buffer
 229   //
 230 
 231   // build frame
 232   ciMethod* m = compilation()-&gt;method();
<span class="line-modified"> 233   __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes(), needs_stack_repair(), NULL);</span>
 234 
 235   // OSR buffer is
 236   //
 237   // locals[nlocals-1..0]
 238   // monitors[0..number_of_locks]
 239   //
 240   // locals is a direct copy of the interpreter frame so in the osr buffer
 241   // so first slot in the local array is the last local from the interpreter
 242   // and last slot is local[0] (receiver) from the interpreter
 243   //
 244   // Similarly with locks. The first lock slot in the osr buffer is the nth lock
 245   // from the interpreter frame, the nth lock slot in the osr buffer is 0th lock
 246   // in the interpreter frame (the method lock if a sync method)
 247 
 248   // Initialize monitors in the compiled activation.
 249   //   r2: pointer to osr buffer
 250   //
 251   // All other registers are dead at this point and the locals will be
 252   // copied into place by code emitted in the IR.
 253 
</pre>
<hr />
<pre>
 428   MonitorExitStub* stub = NULL;
 429   if (method()-&gt;is_synchronized()) {
 430     monitor_address(0, FrameMap::r0_opr);
 431     stub = new MonitorExitStub(FrameMap::r0_opr, true, 0);
 432     __ unlock_object(r5, r4, r0, *stub-&gt;entry());
 433     __ bind(*stub-&gt;continuation());
 434   }
 435 
 436   if (compilation()-&gt;env()-&gt;dtrace_method_probes()) {
 437     __ mov(c_rarg0, rthread);
 438     __ mov_metadata(c_rarg1, method()-&gt;constant_encoding());
 439     __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_method_exit), c_rarg0, c_rarg1);
 440   }
 441 
 442   if (method()-&gt;is_synchronized() || compilation()-&gt;env()-&gt;dtrace_method_probes()) {
 443     __ mov(r0, r19);  // Restore the exception
 444   }
 445 
 446   // remove the activation and dispatch to the unwind handler
 447   __ block_comment(&quot;remove_frame and dispatch to the unwind handler&quot;);
<span class="line-modified"> 448   __ remove_frame(initial_frame_size_in_bytes(), needs_stack_repair());</span>
 449   __ far_jump(RuntimeAddress(Runtime1::entry_for(Runtime1::unwind_exception_id)));
 450 
 451   // Emit the slow path assembly
 452   if (stub != NULL) {
 453     stub-&gt;emit_code(this);
 454   }
 455 
 456   return offset;
 457 }
 458 
 459 
 460 int LIR_Assembler::emit_deopt_handler() {
 461   // if the last instruction is a call (typically to do a throw which
 462   // is coming at the end after block reordering) the return address
 463   // must still point into the code area in order to avoid assertion
 464   // failures when searching for the corresponding bci =&gt; add a nop
 465   // (was bug 5/14/1999 - gri)
 466   __ nop();
 467 
 468   // generate code for exception handler
</pre>
<hr />
<pre>
 479   __ far_jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 480   guarantee(code_offset() - offset &lt;= deopt_handler_size(), &quot;overflow&quot;);
 481   __ end_a_stub();
 482 
 483   return offset;
 484 }
 485 
 486 void LIR_Assembler::add_debug_info_for_branch(address adr, CodeEmitInfo* info) {
 487   _masm-&gt;code_section()-&gt;relocate(adr, relocInfo::poll_type);
 488   int pc_offset = code_offset();
 489   flush_debug_info(pc_offset);
 490   info-&gt;record_debug_info(compilation()-&gt;debug_info_recorder(), pc_offset);
 491   if (info-&gt;exception_handlers() != NULL) {
 492     compilation()-&gt;add_exception_handlers_for_pco(pc_offset, info-&gt;exception_handlers());
 493   }
 494 }
 495 
 496 void LIR_Assembler::return_op(LIR_Opr result) {
 497   assert(result-&gt;is_illegal() || !result-&gt;is_single_cpu() || result-&gt;as_register() == r0, &quot;word returns are in r0,&quot;);
 498 
<span class="line-added"> 499   ciMethod* method = compilation()-&gt;method();</span>
<span class="line-added"> 500 </span>
<span class="line-added"> 501   ciType* return_type = method-&gt;return_type();</span>
<span class="line-added"> 502   if (InlineTypeReturnedAsFields &amp;&amp; return_type-&gt;is_inlinetype()) {</span>
<span class="line-added"> 503     ciInlineKlass* vk = return_type-&gt;as_inline_klass();</span>
<span class="line-added"> 504     if (vk-&gt;can_be_returned_as_fields()) {</span>
<span class="line-added"> 505       address unpack_handler = vk-&gt;unpack_handler();</span>
<span class="line-added"> 506       assert(unpack_handler != NULL, &quot;must be&quot;);</span>
<span class="line-added"> 507       __ far_call(RuntimeAddress(unpack_handler));</span>
<span class="line-added"> 508       // At this point, rax points to the value object (for interpreter or C1 caller).</span>
<span class="line-added"> 509       // The fields of the object are copied into registers (for C2 caller).</span>
<span class="line-added"> 510     }</span>
<span class="line-added"> 511   }</span>
<span class="line-added"> 512 </span>
<span class="line-added"> 513 </span>
 514   // Pop the stack before the safepoint code
<span class="line-modified"> 515   __ remove_frame(initial_frame_size_in_bytes(), needs_stack_repair());</span>
 516 
 517   if (StackReservedPages &gt; 0 &amp;&amp; compilation()-&gt;has_reserved_stack_access()) {
 518     __ reserved_stack_check();
 519   }
 520 
 521   __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);
 522   __ ret(lr);
 523 }
 524 
<span class="line-added"> 525 int LIR_Assembler::store_inline_type_fields_to_buf(ciInlineKlass* vk) {</span>
<span class="line-added"> 526   return (__ store_inline_type_fields_to_buf(vk, false));</span>
<span class="line-added"> 527 }</span>
<span class="line-added"> 528 </span>
 529 int LIR_Assembler::safepoint_poll(LIR_Opr tmp, CodeEmitInfo* info) {
 530   guarantee(info != NULL, &quot;Shouldn&#39;t be NULL&quot;);
 531   __ get_polling_page(rscratch1, relocInfo::poll_type);
 532   add_debug_info_for_branch(info);  // This isn&#39;t just debug info:
 533                                     // it&#39;s the oop map
 534   __ read_polling_page(rscratch1, relocInfo::poll_type);
 535   return __ offset();
 536 }
 537 
 538 
 539 void LIR_Assembler::move_regs(Register from_reg, Register to_reg) {
 540   if (from_reg == r31_sp)
 541     from_reg = sp;
 542   if (to_reg == r31_sp)
 543     to_reg = sp;
 544   __ mov(to_reg, from_reg);
 545 }
 546 
 547 void LIR_Assembler::swap_reg(Register a, Register b) { Unimplemented(); }
 548 
</pre>
<hr />
<pre>
 554 
 555   switch (c-&gt;type()) {
 556     case T_INT: {
 557       assert(patch_code == lir_patch_none, &quot;no patching handled here&quot;);
 558       __ movw(dest-&gt;as_register(), c-&gt;as_jint());
 559       break;
 560     }
 561 
 562     case T_ADDRESS: {
 563       assert(patch_code == lir_patch_none, &quot;no patching handled here&quot;);
 564       __ mov(dest-&gt;as_register(), c-&gt;as_jint());
 565       break;
 566     }
 567 
 568     case T_LONG: {
 569       assert(patch_code == lir_patch_none, &quot;no patching handled here&quot;);
 570       __ mov(dest-&gt;as_register_lo(), (intptr_t)c-&gt;as_jlong());
 571       break;
 572     }
 573 
<span class="line-added"> 574     case T_INLINE_TYPE:</span>
 575     case T_OBJECT: {
<span class="line-modified"> 576         if (patch_code != lir_patch_none) {</span>


 577           jobject2reg_with_patching(dest-&gt;as_register(), info);
<span class="line-added"> 578         } else {</span>
<span class="line-added"> 579           jobject2reg(c-&gt;as_jobject(), dest-&gt;as_register());</span>
 580         }
 581       break;
 582     }
 583 
 584     case T_METADATA: {
 585       if (patch_code != lir_patch_none) {
 586         klass2reg_with_patching(dest-&gt;as_register(), info);
 587       } else {
 588         __ mov_metadata(dest-&gt;as_register(), c-&gt;as_metadata());
 589       }
 590       break;
 591     }
 592 
 593     case T_FLOAT: {
 594       if (__ operand_valid_for_float_immediate(c-&gt;as_jfloat())) {
 595         __ fmovs(dest-&gt;as_float_reg(), (c-&gt;as_jfloat()));
 596       } else {
 597         __ adr(rscratch1, InternalAddress(float_constant(c-&gt;as_jfloat())));
 598         __ ldrs(dest-&gt;as_float_reg(), Address(rscratch1));
 599       }
</pre>
<hr />
<pre>
 601     }
 602 
 603     case T_DOUBLE: {
 604       if (__ operand_valid_for_float_immediate(c-&gt;as_jdouble())) {
 605         __ fmovd(dest-&gt;as_double_reg(), (c-&gt;as_jdouble()));
 606       } else {
 607         __ adr(rscratch1, InternalAddress(double_constant(c-&gt;as_jdouble())));
 608         __ ldrd(dest-&gt;as_double_reg(), Address(rscratch1));
 609       }
 610       break;
 611     }
 612 
 613     default:
 614       ShouldNotReachHere();
 615   }
 616 }
 617 
 618 void LIR_Assembler::const2stack(LIR_Opr src, LIR_Opr dest) {
 619   LIR_Const* c = src-&gt;as_constant_ptr();
 620   switch (c-&gt;type()) {
<span class="line-added"> 621   case T_INLINE_TYPE:</span>
 622   case T_OBJECT:
 623     {
 624       if (! c-&gt;as_jobject())
 625         __ str(zr, frame_map()-&gt;address_for_slot(dest-&gt;single_stack_ix()));
 626       else {
 627         const2reg(src, FrameMap::rscratch1_opr, lir_patch_none, NULL);
 628         reg2stack(FrameMap::rscratch1_opr, dest, c-&gt;type(), false);
 629       }
 630     }
 631     break;
 632   case T_ADDRESS:
 633     {
 634       const2reg(src, FrameMap::rscratch1_opr, lir_patch_none, NULL);
 635       reg2stack(FrameMap::rscratch1_opr, dest, c-&gt;type(), false);
 636     }
 637   case T_INT:
 638   case T_FLOAT:
 639     {
 640       Register reg = zr;
 641       if (c-&gt;as_jint_bits() == 0)
</pre>
<hr />
<pre>
 668 void LIR_Assembler::const2mem(LIR_Opr src, LIR_Opr dest, BasicType type, CodeEmitInfo* info, bool wide) {
 669   assert(src-&gt;is_constant(), &quot;should not call otherwise&quot;);
 670   LIR_Const* c = src-&gt;as_constant_ptr();
 671   LIR_Address* to_addr = dest-&gt;as_address_ptr();
 672 
 673   void (Assembler::* insn)(Register Rt, const Address &amp;adr);
 674 
 675   switch (type) {
 676   case T_ADDRESS:
 677     assert(c-&gt;as_jint() == 0, &quot;should be&quot;);
 678     insn = &amp;Assembler::str;
 679     break;
 680   case T_LONG:
 681     assert(c-&gt;as_jlong() == 0, &quot;should be&quot;);
 682     insn = &amp;Assembler::str;
 683     break;
 684   case T_INT:
 685     assert(c-&gt;as_jint() == 0, &quot;should be&quot;);
 686     insn = &amp;Assembler::strw;
 687     break;
<span class="line-added"> 688   case T_INLINE_TYPE:</span>
 689   case T_OBJECT:
 690   case T_ARRAY:
<span class="line-added"> 691     // Non-null case is not handled on aarch64 but handled on x86</span>
<span class="line-added"> 692     // FIXME: do we need to add it here?</span>
 693     assert(c-&gt;as_jobject() == 0, &quot;should be&quot;);
 694     if (UseCompressedOops &amp;&amp; !wide) {
 695       insn = &amp;Assembler::strw;
 696     } else {
 697       insn = &amp;Assembler::str;
 698     }
 699     break;
 700   case T_CHAR:
 701   case T_SHORT:
 702     assert(c-&gt;as_jint() == 0, &quot;should be&quot;);
 703     insn = &amp;Assembler::strh;
 704     break;
 705   case T_BOOLEAN:
 706   case T_BYTE:
 707     assert(c-&gt;as_jint() == 0, &quot;should be&quot;);
 708     insn = &amp;Assembler::strb;
 709     break;
 710   default:
 711     ShouldNotReachHere();
 712     insn = &amp;Assembler::str;  // unreachable
 713   }
 714 
 715   if (info) add_debug_info_for_null_check_here(info);
 716   (_masm-&gt;*insn)(zr, as_Address(to_addr, rscratch1));
 717 }
 718 
 719 void LIR_Assembler::reg2reg(LIR_Opr src, LIR_Opr dest) {
 720   assert(src-&gt;is_register(), &quot;should not call otherwise&quot;);
 721   assert(dest-&gt;is_register(), &quot;should not call otherwise&quot;);
 722 
 723   // move between cpu-registers
 724   if (dest-&gt;is_single_cpu()) {
 725     if (src-&gt;type() == T_LONG) {
 726       // Can do LONG -&gt; OBJECT
 727       move_regs(src-&gt;as_register_lo(), dest-&gt;as_register());
 728       return;
 729     }
 730     assert(src-&gt;is_single_cpu(), &quot;must match&quot;);
<span class="line-modified"> 731     if (src-&gt;type() == T_OBJECT || src-&gt;type() == T_INLINE_TYPE) {</span>
 732       __ verify_oop(src-&gt;as_register());
 733     }
 734     move_regs(src-&gt;as_register(), dest-&gt;as_register());
 735 
 736   } else if (dest-&gt;is_double_cpu()) {
 737     if (is_reference_type(src-&gt;type())) {
 738       // Surprising to me but we can see move of a long to t_object
 739       __ verify_oop(src-&gt;as_register());
 740       move_regs(src-&gt;as_register(), dest-&gt;as_register_lo());
 741       return;
 742     }
 743     assert(src-&gt;is_double_cpu(), &quot;must match&quot;);
 744     Register f_lo = src-&gt;as_register_lo();
 745     Register f_hi = src-&gt;as_register_hi();
 746     Register t_lo = dest-&gt;as_register_lo();
 747     Register t_hi = dest-&gt;as_register_hi();
 748     assert(f_hi == f_lo, &quot;must be same&quot;);
 749     assert(t_hi == t_lo, &quot;must be same&quot;);
 750     move_regs(f_lo, t_lo);
 751 
</pre>
<hr />
<pre>
 805 
 806     if (UseCompressedOops &amp;&amp; !wide) {
 807       __ encode_heap_oop(compressed_src, src-&gt;as_register());
 808     } else {
 809       compressed_src = src-&gt;as_register();
 810     }
 811   }
 812 
 813   int null_check_here = code_offset();
 814   switch (type) {
 815     case T_FLOAT: {
 816       __ strs(src-&gt;as_float_reg(), as_Address(to_addr));
 817       break;
 818     }
 819 
 820     case T_DOUBLE: {
 821       __ strd(src-&gt;as_double_reg(), as_Address(to_addr));
 822       break;
 823     }
 824 
<span class="line-added"> 825     case T_INLINE_TYPE: // fall through</span>
 826     case T_ARRAY:   // fall through
 827     case T_OBJECT:  // fall through
 828       if (UseCompressedOops &amp;&amp; !wide) {
 829         __ strw(compressed_src, as_Address(to_addr, rscratch2));
 830       } else {
 831          __ str(compressed_src, as_Address(to_addr));
 832       }
 833       break;
 834     case T_METADATA:
 835       // We get here to store a method pointer to the stack to pass to
 836       // a dtrace runtime call. This can&#39;t work on 64 bit with
 837       // compressed klass ptrs: T_METADATA can be a compressed klass
 838       // ptr or a 64 bit method pointer.
 839       ShouldNotReachHere();
 840       __ str(src-&gt;as_register(), as_Address(to_addr));
 841       break;
 842     case T_ADDRESS:
 843       __ str(src-&gt;as_register(), as_Address(to_addr));
 844       break;
 845     case T_INT:
</pre>
<hr />
<pre>
 931   add_call_info_here(info);
 932 }
 933 
 934 void LIR_Assembler::stack2stack(LIR_Opr src, LIR_Opr dest, BasicType type) {
 935 
 936   LIR_Opr temp;
 937   if (type == T_LONG || type == T_DOUBLE)
 938     temp = FrameMap::rscratch1_long_opr;
 939   else
 940     temp = FrameMap::rscratch1_opr;
 941 
 942   stack2reg(src, temp, src-&gt;type());
 943   reg2stack(temp, dest, dest-&gt;type(), false);
 944 }
 945 
 946 
 947 void LIR_Assembler::mem2reg(LIR_Opr src, LIR_Opr dest, BasicType type, LIR_PatchCode patch_code, CodeEmitInfo* info, bool wide, bool /* unaligned */) {
 948   LIR_Address* addr = src-&gt;as_address_ptr();
 949   LIR_Address* from_addr = src-&gt;as_address_ptr();
 950 
<span class="line-modified"> 951   if (addr-&gt;base()-&gt;type() == T_OBJECT || addr-&gt;base()-&gt;type() == T_INLINE_TYPE) {</span>
 952     __ verify_oop(addr-&gt;base()-&gt;as_pointer_register());
 953   }
 954 
 955   if (patch_code != lir_patch_none) {
 956     deoptimize_trap(info);
 957     return;
 958   }
 959 
 960   if (info != NULL) {
 961     add_debug_info_for_null_check_here(info);
 962   }
 963   int null_check_here = code_offset();
 964   switch (type) {
 965     case T_FLOAT: {
 966       __ ldrs(dest-&gt;as_float_reg(), as_Address(from_addr));
 967       break;
 968     }
 969 
 970     case T_DOUBLE: {
 971       __ ldrd(dest-&gt;as_double_reg(), as_Address(from_addr));
 972       break;
 973     }
 974 
<span class="line-added"> 975     case T_INLINE_TYPE: // fall through</span>
 976     case T_ARRAY:   // fall through
 977     case T_OBJECT:  // fall through
 978       if (UseCompressedOops &amp;&amp; !wide) {
 979         __ ldrw(dest-&gt;as_register(), as_Address(from_addr));
 980       } else {
 981          __ ldr(dest-&gt;as_register(), as_Address(from_addr));
 982       }
 983       break;
 984     case T_METADATA:
 985       // We get here to store a method pointer to the stack to pass to
 986       // a dtrace runtime call. This can&#39;t work on 64 bit with
 987       // compressed klass ptrs: T_METADATA can be a compressed klass
 988       // ptr or a 64 bit method pointer.
 989       ShouldNotReachHere();
 990       __ ldr(dest-&gt;as_register(), as_Address(from_addr));
 991       break;
 992     case T_ADDRESS:
 993       // FIXME: OMG this is a horrible kludge.  Any offset from an
 994       // address that matches klass_offset_in_bytes() will be loaded
 995       // as a word, not a long.
</pre>
<hr />
<pre>
1021       break;
1022     case T_SHORT:
1023       __ ldrsh(dest-&gt;as_register(), as_Address(from_addr));
1024       break;
1025 
1026     default:
1027       ShouldNotReachHere();
1028   }
1029 
1030   if (is_reference_type(type)) {
1031     if (UseCompressedOops &amp;&amp; !wide) {
1032       __ decode_heap_oop(dest-&gt;as_register());
1033     }
1034 
1035     if (!UseZGC) {
1036       // Load barrier has not yet been applied, so ZGC can&#39;t verify the oop here
1037       __ verify_oop(dest-&gt;as_register());
1038     }
1039   } else if (type == T_ADDRESS &amp;&amp; addr-&gt;disp() == oopDesc::klass_offset_in_bytes()) {
1040     if (UseCompressedClassPointers) {
<span class="line-added">1041       __ andr(dest-&gt;as_register(), dest-&gt;as_register(), oopDesc::compressed_klass_mask());</span>
1042       __ decode_klass_not_null(dest-&gt;as_register());
<span class="line-added">1043     } else {</span>
<span class="line-added">1044       __   ubfm(dest-&gt;as_register(), dest-&gt;as_register(), 0, 63 - oopDesc::storage_props_nof_bits);</span>
1045     }
1046   }
1047 }
1048 
<span class="line-added">1049 void LIR_Assembler::move(LIR_Opr src, LIR_Opr dst) {</span>
<span class="line-added">1050   assert(dst-&gt;is_cpu_register(), &quot;must be&quot;);</span>
<span class="line-added">1051   assert(dst-&gt;type() == src-&gt;type(), &quot;must be&quot;);</span>
<span class="line-added">1052 </span>
<span class="line-added">1053   if (src-&gt;is_cpu_register()) {</span>
<span class="line-added">1054     reg2reg(src, dst);</span>
<span class="line-added">1055   } else if (src-&gt;is_stack()) {</span>
<span class="line-added">1056     stack2reg(src, dst, dst-&gt;type());</span>
<span class="line-added">1057   } else if (src-&gt;is_constant()) {</span>
<span class="line-added">1058     const2reg(src, dst, lir_patch_none, NULL);</span>
<span class="line-added">1059   } else {</span>
<span class="line-added">1060     ShouldNotReachHere();</span>
<span class="line-added">1061   }</span>
<span class="line-added">1062 }</span>
1063 
1064 int LIR_Assembler::array_element_size(BasicType type) const {
1065   int elem_size = type2aelembytes(type);
1066   return exact_log2(elem_size);
1067 }
1068 
1069 
1070 void LIR_Assembler::emit_op3(LIR_Op3* op) {
1071   switch (op-&gt;code()) {
1072   case lir_idiv:
1073   case lir_irem:
1074     arithmetic_idiv(op-&gt;code(),
1075                     op-&gt;in_opr1(),
1076                     op-&gt;in_opr2(),
1077                     op-&gt;in_opr3(),
1078                     op-&gt;result_opr(),
1079                     op-&gt;info());
1080     break;
1081   case lir_fmad:
1082     __ fmaddd(op-&gt;result_opr()-&gt;as_double_reg(),
</pre>
<hr />
<pre>
1234     __ ldrb(rscratch1, Address(op-&gt;klass()-&gt;as_register(),
1235                                InstanceKlass::init_state_offset()));
1236     __ cmpw(rscratch1, InstanceKlass::fully_initialized);
1237     add_debug_info_for_null_check_here(op-&gt;stub()-&gt;info());
1238     __ br(Assembler::NE, *op-&gt;stub()-&gt;entry());
1239   }
1240   __ allocate_object(op-&gt;obj()-&gt;as_register(),
1241                      op-&gt;tmp1()-&gt;as_register(),
1242                      op-&gt;tmp2()-&gt;as_register(),
1243                      op-&gt;header_size(),
1244                      op-&gt;object_size(),
1245                      op-&gt;klass()-&gt;as_register(),
1246                      *op-&gt;stub()-&gt;entry());
1247   __ bind(*op-&gt;stub()-&gt;continuation());
1248 }
1249 
1250 void LIR_Assembler::emit_alloc_array(LIR_OpAllocArray* op) {
1251   Register len =  op-&gt;len()-&gt;as_register();
1252   __ uxtw(len, len);
1253 
<span class="line-modified">1254   if (UseSlowPath || op-&gt;type() == T_INLINE_TYPE ||</span>
1255       (!UseFastNewObjectArray &amp;&amp; is_reference_type(op-&gt;type())) ||
1256       (!UseFastNewTypeArray   &amp;&amp; !is_reference_type(op-&gt;type()))) {
1257     __ b(*op-&gt;stub()-&gt;entry());
1258   } else {
1259     Register tmp1 = op-&gt;tmp1()-&gt;as_register();
1260     Register tmp2 = op-&gt;tmp2()-&gt;as_register();
1261     Register tmp3 = op-&gt;tmp3()-&gt;as_register();
1262     if (len == tmp1) {
1263       tmp1 = tmp3;
1264     } else if (len == tmp2) {
1265       tmp2 = tmp3;
1266     } else if (len == tmp3) {
1267       // everything is ok
1268     } else {
1269       __ mov(tmp3, len);
1270     }
1271     __ allocate_array(op-&gt;obj()-&gt;as_register(),
1272                       len,
1273                       tmp1,
1274                       tmp2,
</pre>
<hr />
<pre>
1546     __ bind(success);
1547     if (dst != obj) {
1548       __ mov(dst, obj);
1549     }
1550   } else if (code == lir_instanceof) {
1551     Register obj = op-&gt;object()-&gt;as_register();
1552     Register dst = op-&gt;result_opr()-&gt;as_register();
1553     Label success, failure, done;
1554     emit_typecheck_helper(op, &amp;success, &amp;failure, &amp;failure);
1555     __ bind(failure);
1556     __ mov(dst, zr);
1557     __ b(done);
1558     __ bind(success);
1559     __ mov(dst, 1);
1560     __ bind(done);
1561   } else {
1562     ShouldNotReachHere();
1563   }
1564 }
1565 
<span class="line-added">1566 void LIR_Assembler::emit_opFlattenedArrayCheck(LIR_OpFlattenedArrayCheck* op) {</span>
<span class="line-added">1567   // We are loading/storing an array that *may* be a flattened array (the declared type</span>
<span class="line-added">1568   // Object[], interface[], or VT?[]). If this array is flattened, take slow path.</span>
<span class="line-added">1569 </span>
<span class="line-added">1570   __ load_storage_props(op-&gt;tmp()-&gt;as_register(), op-&gt;array()-&gt;as_register());</span>
<span class="line-added">1571   __ tst(op-&gt;tmp()-&gt;as_register(), ArrayStorageProperties::flattened_value);</span>
<span class="line-added">1572   __ br(Assembler::NE, *op-&gt;stub()-&gt;entry());</span>
<span class="line-added">1573   if (!op-&gt;value()-&gt;is_illegal()) {</span>
<span class="line-added">1574     // We are storing into the array.</span>
<span class="line-added">1575     Label skip;</span>
<span class="line-added">1576     __ tst(op-&gt;tmp()-&gt;as_register(), ArrayStorageProperties::null_free_value);</span>
<span class="line-added">1577     __ br(Assembler::EQ, skip);</span>
<span class="line-added">1578     // The array is not flattened, but it is null_free. If we are storing</span>
<span class="line-added">1579     // a null, take the slow path (which will throw NPE).</span>
<span class="line-added">1580     __ cbz(op-&gt;value()-&gt;as_register(), *op-&gt;stub()-&gt;entry());</span>
<span class="line-added">1581     __ bind(skip);</span>
<span class="line-added">1582   }</span>
<span class="line-added">1583 </span>
<span class="line-added">1584 }</span>
<span class="line-added">1585 </span>
<span class="line-added">1586 void LIR_Assembler::emit_opNullFreeArrayCheck(LIR_OpNullFreeArrayCheck* op) {</span>
<span class="line-added">1587   // This is called when we use aastore into a an array declared as &quot;[LVT;&quot;,</span>
<span class="line-added">1588   // where we know VT is not flattened (due to FlatArrayElementMaxSize, etc).</span>
<span class="line-added">1589   // However, we need to do a NULL check if the actual array is a &quot;[QVT;&quot;.</span>
<span class="line-added">1590 </span>
<span class="line-added">1591   __ load_storage_props(op-&gt;tmp()-&gt;as_register(), op-&gt;array()-&gt;as_register());</span>
<span class="line-added">1592   __ mov(rscratch1, (uint64_t) ArrayStorageProperties::null_free_value);</span>
<span class="line-added">1593   __ cmp(op-&gt;tmp()-&gt;as_register(), rscratch1);</span>
<span class="line-added">1594 }</span>
<span class="line-added">1595 </span>
<span class="line-added">1596 void LIR_Assembler::emit_opSubstitutabilityCheck(LIR_OpSubstitutabilityCheck* op) {</span>
<span class="line-added">1597   Label L_oops_equal;</span>
<span class="line-added">1598   Label L_oops_not_equal;</span>
<span class="line-added">1599   Label L_end;</span>
<span class="line-added">1600 </span>
<span class="line-added">1601   Register left  = op-&gt;left()-&gt;as_register();</span>
<span class="line-added">1602   Register right = op-&gt;right()-&gt;as_register();</span>
<span class="line-added">1603 </span>
<span class="line-added">1604   __ cmp(left, right);</span>
<span class="line-added">1605   __ br(Assembler::EQ, L_oops_equal);</span>
<span class="line-added">1606 </span>
<span class="line-added">1607   // (1) Null check -- if one of the operands is null, the other must not be null (because</span>
<span class="line-added">1608   //     the two references are not equal), so they are not substitutable,</span>
<span class="line-added">1609   //     FIXME: do null check only if the operand is nullable</span>
<span class="line-added">1610   {</span>
<span class="line-added">1611     __ cbz(left, L_oops_not_equal);</span>
<span class="line-added">1612     __ cbz(right, L_oops_not_equal);</span>
<span class="line-added">1613   }</span>
<span class="line-added">1614 </span>
<span class="line-added">1615 </span>
<span class="line-added">1616   ciKlass* left_klass = op-&gt;left_klass();</span>
<span class="line-added">1617   ciKlass* right_klass = op-&gt;right_klass();</span>
<span class="line-added">1618 </span>
<span class="line-added">1619   // (2) Value object check -- if either of the operands is not a value object,</span>
<span class="line-added">1620   //     they are not substitutable. We do this only if we are not sure that the</span>
<span class="line-added">1621   //     operands are value objects</span>
<span class="line-added">1622   if ((left_klass == NULL || right_klass == NULL) ||// The klass is still unloaded, or came from a Phi node.</span>
<span class="line-added">1623       !left_klass-&gt;is_inlinetype() || !right_klass-&gt;is_inlinetype()) {</span>
<span class="line-added">1624     Register tmp1  = rscratch1; /* op-&gt;tmp1()-&gt;as_register(); */</span>
<span class="line-added">1625     Register tmp2  = rscratch2; /* op-&gt;tmp2()-&gt;as_register(); */</span>
<span class="line-added">1626 </span>
<span class="line-added">1627     __ mov(tmp1, (intptr_t)markWord::always_locked_pattern);</span>
<span class="line-added">1628 </span>
<span class="line-added">1629     __ ldr(tmp2, Address(left, oopDesc::mark_offset_in_bytes()));</span>
<span class="line-added">1630     __ andr(tmp1, tmp1, tmp2);</span>
<span class="line-added">1631 </span>
<span class="line-added">1632     __ ldr(tmp2, Address(right, oopDesc::mark_offset_in_bytes()));</span>
<span class="line-added">1633     __ andr(tmp1, tmp1, tmp2);</span>
<span class="line-added">1634 </span>
<span class="line-added">1635     __ mov(tmp2, (intptr_t)markWord::always_locked_pattern);</span>
<span class="line-added">1636     __ cmp(tmp1, tmp2);</span>
<span class="line-added">1637     __ br(Assembler::NE, L_oops_not_equal);</span>
<span class="line-added">1638   }</span>
<span class="line-added">1639 </span>
<span class="line-added">1640   // (3) Same klass check: if the operands are of different klasses, they are not substitutable.</span>
<span class="line-added">1641   if (left_klass != NULL &amp;&amp; left_klass-&gt;is_inlinetype() &amp;&amp; left_klass == right_klass) {</span>
<span class="line-added">1642     // No need to load klass -- the operands are statically known to be the same inline klass.</span>
<span class="line-added">1643     __ b(*op-&gt;stub()-&gt;entry());</span>
<span class="line-added">1644   } else {</span>
<span class="line-added">1645     Register left_klass_op = op-&gt;left_klass_op()-&gt;as_register();</span>
<span class="line-added">1646     Register right_klass_op = op-&gt;right_klass_op()-&gt;as_register();</span>
<span class="line-added">1647 </span>
<span class="line-added">1648     if (UseCompressedOops) {</span>
<span class="line-added">1649       __ ldrw(left_klass_op,  Address(left,  oopDesc::klass_offset_in_bytes()));</span>
<span class="line-added">1650       __ ldrw(right_klass_op, Address(right, oopDesc::klass_offset_in_bytes()));</span>
<span class="line-added">1651       __ cmpw(left_klass_op, right_klass_op);</span>
<span class="line-added">1652     } else {</span>
<span class="line-added">1653       __ ldr(left_klass_op,  Address(left,  oopDesc::klass_offset_in_bytes()));</span>
<span class="line-added">1654       __ ldr(right_klass_op, Address(right, oopDesc::klass_offset_in_bytes()));</span>
<span class="line-added">1655       __ cmp(left_klass_op, right_klass_op);</span>
<span class="line-added">1656     }</span>
<span class="line-added">1657 </span>
<span class="line-added">1658     __ br(Assembler::EQ, *op-&gt;stub()-&gt;entry()); // same klass -&gt; do slow check</span>
<span class="line-added">1659     // fall through to L_oops_not_equal</span>
<span class="line-added">1660   }</span>
<span class="line-added">1661 </span>
<span class="line-added">1662   __ bind(L_oops_not_equal);</span>
<span class="line-added">1663   move(op-&gt;not_equal_result(), op-&gt;result_opr());</span>
<span class="line-added">1664   __ b(L_end);</span>
<span class="line-added">1665 </span>
<span class="line-added">1666   __ bind(L_oops_equal);</span>
<span class="line-added">1667   move(op-&gt;equal_result(), op-&gt;result_opr());</span>
<span class="line-added">1668   __ b(L_end);</span>
<span class="line-added">1669 </span>
<span class="line-added">1670   // We&#39;ve returned from the stub. op-&gt;result_opr() contains 0x0 IFF the two</span>
<span class="line-added">1671   // operands are not substitutable. (Don&#39;t compare against 0x1 in case the</span>
<span class="line-added">1672   // C compiler is naughty)</span>
<span class="line-added">1673   __ bind(*op-&gt;stub()-&gt;continuation());</span>
<span class="line-added">1674 </span>
<span class="line-added">1675   if (op-&gt;result_opr()-&gt;type() == T_LONG) {</span>
<span class="line-added">1676     __ cbzw(op-&gt;result_opr()-&gt;as_register(), L_oops_not_equal); // (call_stub() == 0x0) -&gt; not_equal</span>
<span class="line-added">1677   } else {</span>
<span class="line-added">1678     __ cbz(op-&gt;result_opr()-&gt;as_register(), L_oops_not_equal); // (call_stub() == 0x0) -&gt; not_equal</span>
<span class="line-added">1679   }</span>
<span class="line-added">1680 </span>
<span class="line-added">1681   move(op-&gt;equal_result(), op-&gt;result_opr()); // (call_stub() != 0x0) -&gt; equal</span>
<span class="line-added">1682   // fall-through</span>
<span class="line-added">1683   __ bind(L_end);</span>
<span class="line-added">1684 </span>
<span class="line-added">1685 }</span>
<span class="line-added">1686 </span>
<span class="line-added">1687 </span>
1688 void LIR_Assembler::casw(Register addr, Register newval, Register cmpval) {
1689   __ cmpxchg(addr, cmpval, newval, Assembler::word, /* acquire*/ true, /* release*/ true, /* weak*/ false, rscratch1);
1690   __ cset(rscratch1, Assembler::NE);
1691   __ membar(__ AnyAny);
1692 }
1693 
1694 void LIR_Assembler::casl(Register addr, Register newval, Register cmpval) {
1695   __ cmpxchg(addr, cmpval, newval, Assembler::xword, /* acquire*/ true, /* release*/ true, /* weak*/ false, rscratch1);
1696   __ cset(rscratch1, Assembler::NE);
1697   __ membar(__ AnyAny);
1698 }
1699 
1700 
1701 void LIR_Assembler::emit_compare_and_swap(LIR_OpCompareAndSwap* op) {
1702   assert(VM_Version::supports_cx8(), &quot;wrong machine&quot;);
1703   Register addr;
1704   if (op-&gt;addr()-&gt;is_register()) {
1705     addr = as_reg(op-&gt;addr());
1706   } else {
1707     assert(op-&gt;addr()-&gt;is_address(), &quot;what else?&quot;);
</pre>
<hr />
<pre>
2111     }
2112 
2113     if (opr2-&gt;is_constant()) {
2114       bool is_32bit = false; // width of register operand
2115       jlong imm;
2116 
2117       switch(opr2-&gt;type()) {
2118       case T_INT:
2119         imm = opr2-&gt;as_constant_ptr()-&gt;as_jint();
2120         is_32bit = true;
2121         break;
2122       case T_LONG:
2123         imm = opr2-&gt;as_constant_ptr()-&gt;as_jlong();
2124         break;
2125       case T_ADDRESS:
2126         imm = opr2-&gt;as_constant_ptr()-&gt;as_jint();
2127         break;
2128       case T_METADATA:
2129         imm = (intptr_t)(opr2-&gt;as_constant_ptr()-&gt;as_metadata());
2130         break;
<span class="line-added">2131       case T_INLINE_TYPE:</span>
2132       case T_OBJECT:
2133       case T_ARRAY:
2134         jobject2reg(opr2-&gt;as_constant_ptr()-&gt;as_jobject(), rscratch1);
2135         __ cmpoop(reg1, rscratch1);
2136         return;
2137       default:
2138         ShouldNotReachHere();
2139         imm = 0;  // unreachable
2140         break;
2141       }
2142 
2143       if (Assembler::operand_valid_for_add_sub_immediate(imm)) {
2144         if (is_32bit)
2145           __ cmpw(reg1, imm);
2146         else
2147           __ subs(zr, reg1, imm);
2148         return;
2149       } else {
2150         __ mov(rscratch1, imm);
2151         if (is_32bit)
</pre>
<hr />
<pre>
2278   __ b(_unwind_handler_entry);
2279 }
2280 
2281 
2282 void LIR_Assembler::shift_op(LIR_Code code, LIR_Opr left, LIR_Opr count, LIR_Opr dest, LIR_Opr tmp) {
2283   Register lreg = left-&gt;is_single_cpu() ? left-&gt;as_register() : left-&gt;as_register_lo();
2284   Register dreg = dest-&gt;is_single_cpu() ? dest-&gt;as_register() : dest-&gt;as_register_lo();
2285 
2286   switch (left-&gt;type()) {
2287     case T_INT: {
2288       switch (code) {
2289       case lir_shl:  __ lslvw (dreg, lreg, count-&gt;as_register()); break;
2290       case lir_shr:  __ asrvw (dreg, lreg, count-&gt;as_register()); break;
2291       case lir_ushr: __ lsrvw (dreg, lreg, count-&gt;as_register()); break;
2292       default:
2293         ShouldNotReachHere();
2294         break;
2295       }
2296       break;
2297     case T_LONG:
<span class="line-added">2298     case T_INLINE_TYPE:</span>
2299     case T_ADDRESS:
2300     case T_OBJECT:
2301       switch (code) {
2302       case lir_shl:  __ lslv (dreg, lreg, count-&gt;as_register()); break;
2303       case lir_shr:  __ asrv (dreg, lreg, count-&gt;as_register()); break;
2304       case lir_ushr: __ lsrv (dreg, lreg, count-&gt;as_register()); break;
2305       default:
2306         ShouldNotReachHere();
2307         break;
2308       }
2309       break;
2310     default:
2311       ShouldNotReachHere();
2312       break;
2313     }
2314   }
2315 }
2316 
2317 
2318 void LIR_Assembler::shift_op(LIR_Code code, LIR_Opr left, jint count, LIR_Opr dest) {
2319   Register dreg = dest-&gt;is_single_cpu() ? dest-&gt;as_register() : dest-&gt;as_register_lo();
2320   Register lreg = left-&gt;is_single_cpu() ? left-&gt;as_register() : left-&gt;as_register_lo();
2321 
2322   switch (left-&gt;type()) {
2323     case T_INT: {
2324       switch (code) {
2325       case lir_shl:  __ lslw (dreg, lreg, count); break;
2326       case lir_shr:  __ asrw (dreg, lreg, count); break;
2327       case lir_ushr: __ lsrw (dreg, lreg, count); break;
2328       default:
2329         ShouldNotReachHere();
2330         break;
2331       }
2332       break;
2333     case T_LONG:
2334     case T_ADDRESS:
<span class="line-added">2335     case T_INLINE_TYPE:</span>
2336     case T_OBJECT:
2337       switch (code) {
2338       case lir_shl:  __ lsl (dreg, lreg, count); break;
2339       case lir_shr:  __ asr (dreg, lreg, count); break;
2340       case lir_ushr: __ lsr (dreg, lreg, count); break;
2341       default:
2342         ShouldNotReachHere();
2343         break;
2344       }
2345       break;
2346     default:
2347       ShouldNotReachHere();
2348       break;
2349     }
2350   }
2351 }
2352 
2353 
2354 void LIR_Assembler::store_parameter(Register r, int offset_from_rsp_in_words) {
2355   assert(offset_from_rsp_in_words &gt;= 0, &quot;invalid offset from rsp&quot;);
</pre>
<hr />
<pre>
2360 
2361 
2362 void LIR_Assembler::store_parameter(jint c,     int offset_from_rsp_in_words) {
2363   assert(offset_from_rsp_in_words &gt;= 0, &quot;invalid offset from rsp&quot;);
2364   int offset_from_rsp_in_bytes = offset_from_rsp_in_words * BytesPerWord;
2365   assert(offset_from_rsp_in_bytes &lt; frame_map()-&gt;reserved_argument_area_size(), &quot;invalid offset&quot;);
2366   __ mov (rscratch1, c);
2367   __ str (rscratch1, Address(sp, offset_from_rsp_in_bytes));
2368 }
2369 
2370 
2371 void LIR_Assembler::store_parameter(jobject o,  int offset_from_rsp_in_words) {
2372   ShouldNotReachHere();
2373   assert(offset_from_rsp_in_words &gt;= 0, &quot;invalid offset from rsp&quot;);
2374   int offset_from_rsp_in_bytes = offset_from_rsp_in_words * BytesPerWord;
2375   assert(offset_from_rsp_in_bytes &lt; frame_map()-&gt;reserved_argument_area_size(), &quot;invalid offset&quot;);
2376   __ lea(rscratch1, __ constant_oop_address(o));
2377   __ str(rscratch1, Address(sp, offset_from_rsp_in_bytes));
2378 }
2379 
<span class="line-added">2380 void LIR_Assembler::arraycopy_inlinetype_check(Register obj, Register tmp, CodeStub* slow_path, bool is_dest) {</span>
<span class="line-added">2381   __ load_storage_props(tmp, obj);</span>
<span class="line-added">2382   if (is_dest) {</span>
<span class="line-added">2383     // We also take slow path if it&#39;s a null_free destination array, just in case the source array</span>
<span class="line-added">2384     // contains NULLs.</span>
<span class="line-added">2385     __ tst(tmp, ArrayStorageProperties::flattened_value | ArrayStorageProperties::null_free_value);</span>
<span class="line-added">2386   } else {</span>
<span class="line-added">2387     __ tst(tmp, ArrayStorageProperties::flattened_value);</span>
<span class="line-added">2388   }</span>
<span class="line-added">2389   __ br(Assembler::NE, *slow_path-&gt;entry());</span>
<span class="line-added">2390 }</span>
<span class="line-added">2391 </span>
<span class="line-added">2392 </span>
2393 
2394 // This code replaces a call to arraycopy; no exception may
2395 // be thrown in this code, they must be thrown in the System.arraycopy
2396 // activation frame; we could save some checks if this would not be the case
2397 void LIR_Assembler::emit_arraycopy(LIR_OpArrayCopy* op) {
2398   ciArrayKlass* default_type = op-&gt;expected_type();
2399   Register src = op-&gt;src()-&gt;as_register();
2400   Register dst = op-&gt;dst()-&gt;as_register();
2401   Register src_pos = op-&gt;src_pos()-&gt;as_register();
2402   Register dst_pos = op-&gt;dst_pos()-&gt;as_register();
2403   Register length  = op-&gt;length()-&gt;as_register();
2404   Register tmp = op-&gt;tmp()-&gt;as_register();
2405 
2406   __ resolve(ACCESS_READ, src);
2407   __ resolve(ACCESS_WRITE, dst);
2408 
2409   CodeStub* stub = op-&gt;stub();
2410   int flags = op-&gt;flags();
2411   BasicType basic_type = default_type != NULL ? default_type-&gt;element_type()-&gt;basic_type() : T_ILLEGAL;
2412   if (is_reference_type(basic_type)) basic_type = T_OBJECT;
2413 
<span class="line-added">2414   if (flags &amp; LIR_OpArrayCopy::always_slow_path) {</span>
<span class="line-added">2415     __ b(*stub-&gt;entry());</span>
<span class="line-added">2416     __ bind(*stub-&gt;continuation());</span>
<span class="line-added">2417     return;</span>
<span class="line-added">2418   }</span>
<span class="line-added">2419 </span>
<span class="line-added">2420   if (flags &amp; LIR_OpArrayCopy::src_inlinetype_check) {</span>
<span class="line-added">2421     arraycopy_inlinetype_check(src, tmp, stub, false);</span>
<span class="line-added">2422   }</span>
<span class="line-added">2423 </span>
<span class="line-added">2424   if (flags &amp; LIR_OpArrayCopy::dst_inlinetype_check) {</span>
<span class="line-added">2425     arraycopy_inlinetype_check(dst, tmp, stub, true);</span>
<span class="line-added">2426   }</span>
<span class="line-added">2427 </span>
<span class="line-added">2428 </span>
<span class="line-added">2429 </span>
2430   // if we don&#39;t know anything, just go through the generic arraycopy
2431   if (default_type == NULL // || basic_type == T_OBJECT
2432       ) {
2433     Label done;
2434     assert(src == r1 &amp;&amp; src_pos == r2, &quot;mismatch in calling convention&quot;);
2435 
2436     // Save the arguments in case the generic arraycopy fails and we
2437     // have to fall back to the JNI stub
2438     __ stp(dst,     dst_pos, Address(sp, 0*BytesPerWord));
2439     __ stp(length,  src_pos, Address(sp, 2*BytesPerWord));
2440     __ str(src,              Address(sp, 4*BytesPerWord));
2441 
2442     address copyfunc_addr = StubRoutines::generic_arraycopy();
2443     assert(copyfunc_addr != NULL, &quot;generic arraycopy stub required&quot;);
2444 
2445     // The arguments are in java calling convention so we shift them
2446     // to C convention
2447     assert_different_registers(c_rarg0, j_rarg1, j_rarg2, j_rarg3, j_rarg4);
2448     __ mov(c_rarg0, j_rarg0);
2449     assert_different_registers(c_rarg1, j_rarg2, j_rarg3, j_rarg4);
</pre>
<hr />
<pre>
3310 #endif
3311 }
3312 
3313 void LIR_Assembler::atomic_op(LIR_Code code, LIR_Opr src, LIR_Opr data, LIR_Opr dest, LIR_Opr tmp_op) {
3314   Address addr = as_Address(src-&gt;as_address_ptr());
3315   BasicType type = src-&gt;type();
3316   bool is_oop = is_reference_type(type);
3317 
3318   void (MacroAssembler::* add)(Register prev, RegisterOrConstant incr, Register addr);
3319   void (MacroAssembler::* xchg)(Register prev, Register newv, Register addr);
3320 
3321   switch(type) {
3322   case T_INT:
3323     xchg = &amp;MacroAssembler::atomic_xchgalw;
3324     add = &amp;MacroAssembler::atomic_addalw;
3325     break;
3326   case T_LONG:
3327     xchg = &amp;MacroAssembler::atomic_xchgal;
3328     add = &amp;MacroAssembler::atomic_addal;
3329     break;
<span class="line-added">3330   case T_INLINE_TYPE:</span>
3331   case T_OBJECT:
3332   case T_ARRAY:
3333     if (UseCompressedOops) {
3334       xchg = &amp;MacroAssembler::atomic_xchgalw;
3335       add = &amp;MacroAssembler::atomic_addalw;
3336     } else {
3337       xchg = &amp;MacroAssembler::atomic_xchgal;
3338       add = &amp;MacroAssembler::atomic_addal;
3339     }
3340     break;
3341   default:
3342     ShouldNotReachHere();
3343     xchg = &amp;MacroAssembler::atomic_xchgal;
3344     add = &amp;MacroAssembler::atomic_addal; // unreachable
3345   }
3346 
3347   switch (code) {
3348   case lir_xadd:
3349     {
3350       RegisterOrConstant inc;
</pre>
</td>
</tr>
</table>
<center><a href="aarch64.ad.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_aarch64.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>