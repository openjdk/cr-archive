<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff src/hotspot/cpu/aarch64/c1_LIRAssembler_aarch64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="aarch64.ad.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_aarch64.cpp.cdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/aarch64/c1_LIRAssembler_aarch64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 31,15 ***</span>
<span class="line-new-header">--- 31,17 ---</span>
  #include &quot;c1/c1_LIRAssembler.hpp&quot;
  #include &quot;c1/c1_MacroAssembler.hpp&quot;
  #include &quot;c1/c1_Runtime1.hpp&quot;
  #include &quot;c1/c1_ValueStack.hpp&quot;
  #include &quot;ci/ciArrayKlass.hpp&quot;
<span class="line-added">+ #include &quot;ci/ciInlineKlass.hpp&quot;</span>
  #include &quot;ci/ciInstance.hpp&quot;
  #include &quot;code/compiledIC.hpp&quot;
  #include &quot;gc/shared/collectedHeap.hpp&quot;
  #include &quot;nativeInst_aarch64.hpp&quot;
  #include &quot;oops/objArrayKlass.hpp&quot;
<span class="line-added">+ #include &quot;oops/oop.inline.hpp&quot;</span>
  #include &quot;runtime/frame.inline.hpp&quot;
  #include &quot;runtime/sharedRuntime.hpp&quot;
  #include &quot;utilities/powerOfTwo.hpp&quot;
  #include &quot;vmreg_aarch64.inline.hpp&quot;
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 226,11 ***</span>
    // r2: osr buffer
    //
  
    // build frame
    ciMethod* m = compilation()-&gt;method();
<span class="line-modified">!   __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes());</span>
  
    // OSR buffer is
    //
    // locals[nlocals-1..0]
    // monitors[0..number_of_locks]
<span class="line-new-header">--- 228,11 ---</span>
    // r2: osr buffer
    //
  
    // build frame
    ciMethod* m = compilation()-&gt;method();
<span class="line-modified">!   __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes(), needs_stack_repair(), NULL);</span>
  
    // OSR buffer is
    //
    // locals[nlocals-1..0]
    // monitors[0..number_of_locks]
</pre>
<hr />
<pre>
<span class="line-old-header">*** 441,11 ***</span>
      __ mov(r0, r19);  // Restore the exception
    }
  
    // remove the activation and dispatch to the unwind handler
    __ block_comment(&quot;remove_frame and dispatch to the unwind handler&quot;);
<span class="line-modified">!   __ remove_frame(initial_frame_size_in_bytes());</span>
    __ far_jump(RuntimeAddress(Runtime1::entry_for(Runtime1::unwind_exception_id)));
  
    // Emit the slow path assembly
    if (stub != NULL) {
      stub-&gt;emit_code(this);
<span class="line-new-header">--- 443,11 ---</span>
      __ mov(r0, r19);  // Restore the exception
    }
  
    // remove the activation and dispatch to the unwind handler
    __ block_comment(&quot;remove_frame and dispatch to the unwind handler&quot;);
<span class="line-modified">!   __ remove_frame(initial_frame_size_in_bytes(), needs_stack_repair());</span>
    __ far_jump(RuntimeAddress(Runtime1::entry_for(Runtime1::unwind_exception_id)));
  
    // Emit the slow path assembly
    if (stub != NULL) {
      stub-&gt;emit_code(this);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 492,21 ***</span>
  }
  
  void LIR_Assembler::return_op(LIR_Opr result) {
    assert(result-&gt;is_illegal() || !result-&gt;is_single_cpu() || result-&gt;as_register() == r0, &quot;word returns are in r0,&quot;);
  
    // Pop the stack before the safepoint code
<span class="line-modified">!   __ remove_frame(initial_frame_size_in_bytes());</span>
  
    if (StackReservedPages &gt; 0 &amp;&amp; compilation()-&gt;has_reserved_stack_access()) {
      __ reserved_stack_check();
    }
  
    __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);
    __ ret(lr);
  }
  
  int LIR_Assembler::safepoint_poll(LIR_Opr tmp, CodeEmitInfo* info) {
    guarantee(info != NULL, &quot;Shouldn&#39;t be NULL&quot;);
    __ get_polling_page(rscratch1, relocInfo::poll_type);
    add_debug_info_for_branch(info);  // This isn&#39;t just debug info:
                                      // it&#39;s the oop map
<span class="line-new-header">--- 494,40 ---</span>
  }
  
  void LIR_Assembler::return_op(LIR_Opr result) {
    assert(result-&gt;is_illegal() || !result-&gt;is_single_cpu() || result-&gt;as_register() == r0, &quot;word returns are in r0,&quot;);
  
<span class="line-added">+   ciMethod* method = compilation()-&gt;method();</span>
<span class="line-added">+ </span>
<span class="line-added">+   ciType* return_type = method-&gt;return_type();</span>
<span class="line-added">+   if (InlineTypeReturnedAsFields &amp;&amp; return_type-&gt;is_inlinetype()) {</span>
<span class="line-added">+     ciInlineKlass* vk = return_type-&gt;as_inline_klass();</span>
<span class="line-added">+     if (vk-&gt;can_be_returned_as_fields()) {</span>
<span class="line-added">+       address unpack_handler = vk-&gt;unpack_handler();</span>
<span class="line-added">+       assert(unpack_handler != NULL, &quot;must be&quot;);</span>
<span class="line-added">+       __ far_call(RuntimeAddress(unpack_handler));</span>
<span class="line-added">+       // At this point, rax points to the value object (for interpreter or C1 caller).</span>
<span class="line-added">+       // The fields of the object are copied into registers (for C2 caller).</span>
<span class="line-added">+     }</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+ </span>
    // Pop the stack before the safepoint code
<span class="line-modified">!   __ remove_frame(initial_frame_size_in_bytes(), needs_stack_repair());</span>
  
    if (StackReservedPages &gt; 0 &amp;&amp; compilation()-&gt;has_reserved_stack_access()) {
      __ reserved_stack_check();
    }
  
    __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);
    __ ret(lr);
  }
  
<span class="line-added">+ int LIR_Assembler::store_inline_type_fields_to_buf(ciInlineKlass* vk) {</span>
<span class="line-added">+   return (__ store_inline_type_fields_to_buf(vk, false));</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
  int LIR_Assembler::safepoint_poll(LIR_Opr tmp, CodeEmitInfo* info) {
    guarantee(info != NULL, &quot;Shouldn&#39;t be NULL&quot;);
    __ get_polling_page(rscratch1, relocInfo::poll_type);
    add_debug_info_for_branch(info);  // This isn&#39;t just debug info:
                                      // it&#39;s the oop map
</pre>
<hr />
<pre>
<span class="line-old-header">*** 548,15 ***</span>
        assert(patch_code == lir_patch_none, &quot;no patching handled here&quot;);
        __ mov(dest-&gt;as_register_lo(), (intptr_t)c-&gt;as_jlong());
        break;
      }
  
      case T_OBJECT: {
<span class="line-modified">!         if (patch_code == lir_patch_none) {</span>
<span class="line-removed">-           jobject2reg(c-&gt;as_jobject(), dest-&gt;as_register());</span>
<span class="line-removed">-         } else {</span>
            jobject2reg_with_patching(dest-&gt;as_register(), info);
          }
        break;
      }
  
      case T_METADATA: {
<span class="line-new-header">--- 569,16 ---</span>
        assert(patch_code == lir_patch_none, &quot;no patching handled here&quot;);
        __ mov(dest-&gt;as_register_lo(), (intptr_t)c-&gt;as_jlong());
        break;
      }
  
<span class="line-added">+     case T_INLINE_TYPE:</span>
      case T_OBJECT: {
<span class="line-modified">!         if (patch_code != lir_patch_none) {</span>
            jobject2reg_with_patching(dest-&gt;as_register(), info);
<span class="line-added">+         } else {</span>
<span class="line-added">+           jobject2reg(c-&gt;as_jobject(), dest-&gt;as_register());</span>
          }
        break;
      }
  
      case T_METADATA: {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 594,10 ***</span>
<span class="line-new-header">--- 616,11 ---</span>
  }
  
  void LIR_Assembler::const2stack(LIR_Opr src, LIR_Opr dest) {
    LIR_Const* c = src-&gt;as_constant_ptr();
    switch (c-&gt;type()) {
<span class="line-added">+   case T_INLINE_TYPE:</span>
    case T_OBJECT:
      {
        if (! c-&gt;as_jobject())
          __ str(zr, frame_map()-&gt;address_for_slot(dest-&gt;single_stack_ix()));
        else {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 660,12 ***</span>
<span class="line-new-header">--- 683,15 ---</span>
      break;
    case T_INT:
      assert(c-&gt;as_jint() == 0, &quot;should be&quot;);
      insn = &amp;Assembler::strw;
      break;
<span class="line-added">+   case T_INLINE_TYPE:</span>
    case T_OBJECT:
    case T_ARRAY:
<span class="line-added">+     // Non-null case is not handled on aarch64 but handled on x86</span>
<span class="line-added">+     // FIXME: do we need to add it here?</span>
      assert(c-&gt;as_jobject() == 0, &quot;should be&quot;);
      if (UseCompressedOops &amp;&amp; !wide) {
        insn = &amp;Assembler::strw;
      } else {
        insn = &amp;Assembler::str;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 700,11 ***</span>
        // Can do LONG -&gt; OBJECT
        move_regs(src-&gt;as_register_lo(), dest-&gt;as_register());
        return;
      }
      assert(src-&gt;is_single_cpu(), &quot;must match&quot;);
<span class="line-modified">!     if (src-&gt;type() == T_OBJECT) {</span>
        __ verify_oop(src-&gt;as_register());
      }
      move_regs(src-&gt;as_register(), dest-&gt;as_register());
  
    } else if (dest-&gt;is_double_cpu()) {
<span class="line-new-header">--- 726,11 ---</span>
        // Can do LONG -&gt; OBJECT
        move_regs(src-&gt;as_register_lo(), dest-&gt;as_register());
        return;
      }
      assert(src-&gt;is_single_cpu(), &quot;must match&quot;);
<span class="line-modified">!     if (src-&gt;type() == T_OBJECT || src-&gt;type() == T_INLINE_TYPE) {</span>
        __ verify_oop(src-&gt;as_register());
      }
      move_regs(src-&gt;as_register(), dest-&gt;as_register());
  
    } else if (dest-&gt;is_double_cpu()) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 794,10 ***</span>
<span class="line-new-header">--- 820,11 ---</span>
      case T_DOUBLE: {
        __ strd(src-&gt;as_double_reg(), as_Address(to_addr));
        break;
      }
  
<span class="line-added">+     case T_INLINE_TYPE: // fall through</span>
      case T_ARRAY:   // fall through
      case T_OBJECT:  // fall through
        if (UseCompressedOops &amp;&amp; !wide) {
          __ strw(compressed_src, as_Address(to_addr, rscratch2));
        } else {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 919,11 ***</span>
  
  void LIR_Assembler::mem2reg(LIR_Opr src, LIR_Opr dest, BasicType type, LIR_PatchCode patch_code, CodeEmitInfo* info, bool wide, bool /* unaligned */) {
    LIR_Address* addr = src-&gt;as_address_ptr();
    LIR_Address* from_addr = src-&gt;as_address_ptr();
  
<span class="line-modified">!   if (addr-&gt;base()-&gt;type() == T_OBJECT) {</span>
      __ verify_oop(addr-&gt;base()-&gt;as_pointer_register());
    }
  
    if (patch_code != lir_patch_none) {
      deoptimize_trap(info);
<span class="line-new-header">--- 946,11 ---</span>
  
  void LIR_Assembler::mem2reg(LIR_Opr src, LIR_Opr dest, BasicType type, LIR_PatchCode patch_code, CodeEmitInfo* info, bool wide, bool /* unaligned */) {
    LIR_Address* addr = src-&gt;as_address_ptr();
    LIR_Address* from_addr = src-&gt;as_address_ptr();
  
<span class="line-modified">!   if (addr-&gt;base()-&gt;type() == T_OBJECT || addr-&gt;base()-&gt;type() == T_INLINE_TYPE) {</span>
      __ verify_oop(addr-&gt;base()-&gt;as_pointer_register());
    }
  
    if (patch_code != lir_patch_none) {
      deoptimize_trap(info);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 943,10 ***</span>
<span class="line-new-header">--- 970,11 ---</span>
      case T_DOUBLE: {
        __ ldrd(dest-&gt;as_double_reg(), as_Address(from_addr));
        break;
      }
  
<span class="line-added">+     case T_INLINE_TYPE: // fall through</span>
      case T_ARRAY:   // fall through
      case T_OBJECT:  // fall through
        if (UseCompressedOops &amp;&amp; !wide) {
          __ ldrw(dest-&gt;as_register(), as_Address(from_addr));
        } else {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1008,15 ***</span>
<span class="line-new-header">--- 1036,32 ---</span>
        // Load barrier has not yet been applied, so ZGC can&#39;t verify the oop here
        __ verify_oop(dest-&gt;as_register());
      }
    } else if (type == T_ADDRESS &amp;&amp; addr-&gt;disp() == oopDesc::klass_offset_in_bytes()) {
      if (UseCompressedClassPointers) {
<span class="line-added">+       __ andr(dest-&gt;as_register(), dest-&gt;as_register(), oopDesc::compressed_klass_mask());</span>
        __ decode_klass_not_null(dest-&gt;as_register());
<span class="line-added">+     } else {</span>
<span class="line-added">+       __   ubfm(dest-&gt;as_register(), dest-&gt;as_register(), 0, 63 - oopDesc::storage_props_nof_bits);</span>
      }
    }
  }
  
<span class="line-added">+ void LIR_Assembler::move(LIR_Opr src, LIR_Opr dst) {</span>
<span class="line-added">+   assert(dst-&gt;is_cpu_register(), &quot;must be&quot;);</span>
<span class="line-added">+   assert(dst-&gt;type() == src-&gt;type(), &quot;must be&quot;);</span>
<span class="line-added">+ </span>
<span class="line-added">+   if (src-&gt;is_cpu_register()) {</span>
<span class="line-added">+     reg2reg(src, dst);</span>
<span class="line-added">+   } else if (src-&gt;is_stack()) {</span>
<span class="line-added">+     stack2reg(src, dst, dst-&gt;type());</span>
<span class="line-added">+   } else if (src-&gt;is_constant()) {</span>
<span class="line-added">+     const2reg(src, dst, lir_patch_none, NULL);</span>
<span class="line-added">+   } else {</span>
<span class="line-added">+     ShouldNotReachHere();</span>
<span class="line-added">+   }</span>
<span class="line-added">+ }</span>
  
  int LIR_Assembler::array_element_size(BasicType type) const {
    int elem_size = type2aelembytes(type);
    return exact_log2(elem_size);
  }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1204,11 ***</span>
  
  void LIR_Assembler::emit_alloc_array(LIR_OpAllocArray* op) {
    Register len =  op-&gt;len()-&gt;as_register();
    __ uxtw(len, len);
  
<span class="line-modified">!   if (UseSlowPath ||</span>
        (!UseFastNewObjectArray &amp;&amp; is_reference_type(op-&gt;type())) ||
        (!UseFastNewTypeArray   &amp;&amp; !is_reference_type(op-&gt;type()))) {
      __ b(*op-&gt;stub()-&gt;entry());
    } else {
      Register tmp1 = op-&gt;tmp1()-&gt;as_register();
<span class="line-new-header">--- 1249,11 ---</span>
  
  void LIR_Assembler::emit_alloc_array(LIR_OpAllocArray* op) {
    Register len =  op-&gt;len()-&gt;as_register();
    __ uxtw(len, len);
  
<span class="line-modified">!   if (UseSlowPath || op-&gt;type() == T_INLINE_TYPE ||</span>
        (!UseFastNewObjectArray &amp;&amp; is_reference_type(op-&gt;type())) ||
        (!UseFastNewTypeArray   &amp;&amp; !is_reference_type(op-&gt;type()))) {
      __ b(*op-&gt;stub()-&gt;entry());
    } else {
      Register tmp1 = op-&gt;tmp1()-&gt;as_register();
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1516,10 ***</span>
<span class="line-new-header">--- 1561,132 ---</span>
    } else {
      ShouldNotReachHere();
    }
  }
  
<span class="line-added">+ void LIR_Assembler::emit_opFlattenedArrayCheck(LIR_OpFlattenedArrayCheck* op) {</span>
<span class="line-added">+   // We are loading/storing an array that *may* be a flattened array (the declared type</span>
<span class="line-added">+   // Object[], interface[], or VT?[]). If this array is flattened, take slow path.</span>
<span class="line-added">+ </span>
<span class="line-added">+   __ load_storage_props(op-&gt;tmp()-&gt;as_register(), op-&gt;array()-&gt;as_register());</span>
<span class="line-added">+   __ tst(op-&gt;tmp()-&gt;as_register(), ArrayStorageProperties::flattened_value);</span>
<span class="line-added">+   __ br(Assembler::NE, *op-&gt;stub()-&gt;entry());</span>
<span class="line-added">+   if (!op-&gt;value()-&gt;is_illegal()) {</span>
<span class="line-added">+     // We are storing into the array.</span>
<span class="line-added">+     Label skip;</span>
<span class="line-added">+     __ tst(op-&gt;tmp()-&gt;as_register(), ArrayStorageProperties::null_free_value);</span>
<span class="line-added">+     __ br(Assembler::EQ, skip);</span>
<span class="line-added">+     // The array is not flattened, but it is null_free. If we are storing</span>
<span class="line-added">+     // a null, take the slow path (which will throw NPE).</span>
<span class="line-added">+     __ cbz(op-&gt;value()-&gt;as_register(), *op-&gt;stub()-&gt;entry());</span>
<span class="line-added">+     __ bind(skip);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ void LIR_Assembler::emit_opNullFreeArrayCheck(LIR_OpNullFreeArrayCheck* op) {</span>
<span class="line-added">+   // This is called when we use aastore into a an array declared as &quot;[LVT;&quot;,</span>
<span class="line-added">+   // where we know VT is not flattened (due to FlatArrayElementMaxSize, etc).</span>
<span class="line-added">+   // However, we need to do a NULL check if the actual array is a &quot;[QVT;&quot;.</span>
<span class="line-added">+ </span>
<span class="line-added">+   __ load_storage_props(op-&gt;tmp()-&gt;as_register(), op-&gt;array()-&gt;as_register());</span>
<span class="line-added">+   __ mov(rscratch1, (uint64_t) ArrayStorageProperties::null_free_value);</span>
<span class="line-added">+   __ cmp(op-&gt;tmp()-&gt;as_register(), rscratch1);</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ void LIR_Assembler::emit_opSubstitutabilityCheck(LIR_OpSubstitutabilityCheck* op) {</span>
<span class="line-added">+   Label L_oops_equal;</span>
<span class="line-added">+   Label L_oops_not_equal;</span>
<span class="line-added">+   Label L_end;</span>
<span class="line-added">+ </span>
<span class="line-added">+   Register left  = op-&gt;left()-&gt;as_register();</span>
<span class="line-added">+   Register right = op-&gt;right()-&gt;as_register();</span>
<span class="line-added">+ </span>
<span class="line-added">+   __ cmp(left, right);</span>
<span class="line-added">+   __ br(Assembler::EQ, L_oops_equal);</span>
<span class="line-added">+ </span>
<span class="line-added">+   // (1) Null check -- if one of the operands is null, the other must not be null (because</span>
<span class="line-added">+   //     the two references are not equal), so they are not substitutable,</span>
<span class="line-added">+   //     FIXME: do null check only if the operand is nullable</span>
<span class="line-added">+   {</span>
<span class="line-added">+     __ cbz(left, L_oops_not_equal);</span>
<span class="line-added">+     __ cbz(right, L_oops_not_equal);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+ </span>
<span class="line-added">+   ciKlass* left_klass = op-&gt;left_klass();</span>
<span class="line-added">+   ciKlass* right_klass = op-&gt;right_klass();</span>
<span class="line-added">+ </span>
<span class="line-added">+   // (2) Value object check -- if either of the operands is not a value object,</span>
<span class="line-added">+   //     they are not substitutable. We do this only if we are not sure that the</span>
<span class="line-added">+   //     operands are value objects</span>
<span class="line-added">+   if ((left_klass == NULL || right_klass == NULL) ||// The klass is still unloaded, or came from a Phi node.</span>
<span class="line-added">+       !left_klass-&gt;is_inlinetype() || !right_klass-&gt;is_inlinetype()) {</span>
<span class="line-added">+     Register tmp1  = rscratch1; /* op-&gt;tmp1()-&gt;as_register(); */</span>
<span class="line-added">+     Register tmp2  = rscratch2; /* op-&gt;tmp2()-&gt;as_register(); */</span>
<span class="line-added">+ </span>
<span class="line-added">+     __ mov(tmp1, (intptr_t)markWord::always_locked_pattern);</span>
<span class="line-added">+ </span>
<span class="line-added">+     __ ldr(tmp2, Address(left, oopDesc::mark_offset_in_bytes()));</span>
<span class="line-added">+     __ andr(tmp1, tmp1, tmp2);</span>
<span class="line-added">+ </span>
<span class="line-added">+     __ ldr(tmp2, Address(right, oopDesc::mark_offset_in_bytes()));</span>
<span class="line-added">+     __ andr(tmp1, tmp1, tmp2);</span>
<span class="line-added">+ </span>
<span class="line-added">+     __ mov(tmp2, (intptr_t)markWord::always_locked_pattern);</span>
<span class="line-added">+     __ cmp(tmp1, tmp2);</span>
<span class="line-added">+     __ br(Assembler::NE, L_oops_not_equal);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   // (3) Same klass check: if the operands are of different klasses, they are not substitutable.</span>
<span class="line-added">+   if (left_klass != NULL &amp;&amp; left_klass-&gt;is_inlinetype() &amp;&amp; left_klass == right_klass) {</span>
<span class="line-added">+     // No need to load klass -- the operands are statically known to be the same inline klass.</span>
<span class="line-added">+     __ b(*op-&gt;stub()-&gt;entry());</span>
<span class="line-added">+   } else {</span>
<span class="line-added">+     Register left_klass_op = op-&gt;left_klass_op()-&gt;as_register();</span>
<span class="line-added">+     Register right_klass_op = op-&gt;right_klass_op()-&gt;as_register();</span>
<span class="line-added">+ </span>
<span class="line-added">+     if (UseCompressedOops) {</span>
<span class="line-added">+       __ ldrw(left_klass_op,  Address(left,  oopDesc::klass_offset_in_bytes()));</span>
<span class="line-added">+       __ ldrw(right_klass_op, Address(right, oopDesc::klass_offset_in_bytes()));</span>
<span class="line-added">+       __ cmpw(left_klass_op, right_klass_op);</span>
<span class="line-added">+     } else {</span>
<span class="line-added">+       __ ldr(left_klass_op,  Address(left,  oopDesc::klass_offset_in_bytes()));</span>
<span class="line-added">+       __ ldr(right_klass_op, Address(right, oopDesc::klass_offset_in_bytes()));</span>
<span class="line-added">+       __ cmp(left_klass_op, right_klass_op);</span>
<span class="line-added">+     }</span>
<span class="line-added">+ </span>
<span class="line-added">+     __ br(Assembler::EQ, *op-&gt;stub()-&gt;entry()); // same klass -&gt; do slow check</span>
<span class="line-added">+     // fall through to L_oops_not_equal</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   __ bind(L_oops_not_equal);</span>
<span class="line-added">+   move(op-&gt;not_equal_result(), op-&gt;result_opr());</span>
<span class="line-added">+   __ b(L_end);</span>
<span class="line-added">+ </span>
<span class="line-added">+   __ bind(L_oops_equal);</span>
<span class="line-added">+   move(op-&gt;equal_result(), op-&gt;result_opr());</span>
<span class="line-added">+   __ b(L_end);</span>
<span class="line-added">+ </span>
<span class="line-added">+   // We&#39;ve returned from the stub. op-&gt;result_opr() contains 0x0 IFF the two</span>
<span class="line-added">+   // operands are not substitutable. (Don&#39;t compare against 0x1 in case the</span>
<span class="line-added">+   // C compiler is naughty)</span>
<span class="line-added">+   __ bind(*op-&gt;stub()-&gt;continuation());</span>
<span class="line-added">+ </span>
<span class="line-added">+   if (op-&gt;result_opr()-&gt;type() == T_LONG) {</span>
<span class="line-added">+     __ cbzw(op-&gt;result_opr()-&gt;as_register(), L_oops_not_equal); // (call_stub() == 0x0) -&gt; not_equal</span>
<span class="line-added">+   } else {</span>
<span class="line-added">+     __ cbz(op-&gt;result_opr()-&gt;as_register(), L_oops_not_equal); // (call_stub() == 0x0) -&gt; not_equal</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   move(op-&gt;equal_result(), op-&gt;result_opr()); // (call_stub() != 0x0) -&gt; equal</span>
<span class="line-added">+   // fall-through</span>
<span class="line-added">+   __ bind(L_end);</span>
<span class="line-added">+ </span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ </span>
  void LIR_Assembler::casw(Register addr, Register newval, Register cmpval) {
    __ cmpxchg(addr, cmpval, newval, Assembler::word, /* acquire*/ true, /* release*/ true, /* weak*/ false, rscratch1);
    __ cset(rscratch1, Assembler::NE);
    __ membar(__ AnyAny);
  }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1959,10 ***</span>
<span class="line-new-header">--- 2126,11 ---</span>
          imm = opr2-&gt;as_constant_ptr()-&gt;as_jint();
          break;
        case T_METADATA:
          imm = (intptr_t)(opr2-&gt;as_constant_ptr()-&gt;as_metadata());
          break;
<span class="line-added">+       case T_INLINE_TYPE:</span>
        case T_OBJECT:
        case T_ARRAY:
          jobject2reg(opr2-&gt;as_constant_ptr()-&gt;as_jobject(), rscratch1);
          __ cmpoop(reg1, rscratch1);
          return;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2125,10 ***</span>
<span class="line-new-header">--- 2293,11 ---</span>
          ShouldNotReachHere();
          break;
        }
        break;
      case T_LONG:
<span class="line-added">+     case T_INLINE_TYPE:</span>
      case T_ADDRESS:
      case T_OBJECT:
        switch (code) {
        case lir_shl:  __ lslv (dreg, lreg, count-&gt;as_register()); break;
        case lir_shr:  __ asrv (dreg, lreg, count-&gt;as_register()); break;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2161,10 ***</span>
<span class="line-new-header">--- 2330,11 ---</span>
          break;
        }
        break;
      case T_LONG:
      case T_ADDRESS:
<span class="line-added">+     case T_INLINE_TYPE:</span>
      case T_OBJECT:
        switch (code) {
        case lir_shl:  __ lsl (dreg, lreg, count); break;
        case lir_shr:  __ asr (dreg, lreg, count); break;
        case lir_ushr: __ lsr (dreg, lreg, count); break;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2205,10 ***</span>
<span class="line-new-header">--- 2375,23 ---</span>
    assert(offset_from_rsp_in_bytes &lt; frame_map()-&gt;reserved_argument_area_size(), &quot;invalid offset&quot;);
    __ lea(rscratch1, __ constant_oop_address(o));
    __ str(rscratch1, Address(sp, offset_from_rsp_in_bytes));
  }
  
<span class="line-added">+ void LIR_Assembler::arraycopy_inlinetype_check(Register obj, Register tmp, CodeStub* slow_path, bool is_dest) {</span>
<span class="line-added">+   __ load_storage_props(tmp, obj);</span>
<span class="line-added">+   if (is_dest) {</span>
<span class="line-added">+     // We also take slow path if it&#39;s a null_free destination array, just in case the source array</span>
<span class="line-added">+     // contains NULLs.</span>
<span class="line-added">+     __ tst(tmp, ArrayStorageProperties::flattened_value | ArrayStorageProperties::null_free_value);</span>
<span class="line-added">+   } else {</span>
<span class="line-added">+     __ tst(tmp, ArrayStorageProperties::flattened_value);</span>
<span class="line-added">+   }</span>
<span class="line-added">+   __ br(Assembler::NE, *slow_path-&gt;entry());</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ </span>
  
  // This code replaces a call to arraycopy; no exception may
  // be thrown in this code, they must be thrown in the System.arraycopy
  // activation frame; we could save some checks if this would not be the case
  void LIR_Assembler::emit_arraycopy(LIR_OpArrayCopy* op) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2226,10 ***</span>
<span class="line-new-header">--- 2409,26 ---</span>
    CodeStub* stub = op-&gt;stub();
    int flags = op-&gt;flags();
    BasicType basic_type = default_type != NULL ? default_type-&gt;element_type()-&gt;basic_type() : T_ILLEGAL;
    if (is_reference_type(basic_type)) basic_type = T_OBJECT;
  
<span class="line-added">+   if (flags &amp; LIR_OpArrayCopy::always_slow_path) {</span>
<span class="line-added">+     __ b(*stub-&gt;entry());</span>
<span class="line-added">+     __ bind(*stub-&gt;continuation());</span>
<span class="line-added">+     return;</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   if (flags &amp; LIR_OpArrayCopy::src_inlinetype_check) {</span>
<span class="line-added">+     arraycopy_inlinetype_check(src, tmp, stub, false);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   if (flags &amp; LIR_OpArrayCopy::dst_inlinetype_check) {</span>
<span class="line-added">+     arraycopy_inlinetype_check(dst, tmp, stub, true);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+ </span>
<span class="line-added">+ </span>
    // if we don&#39;t know anything, just go through the generic arraycopy
    if (default_type == NULL // || basic_type == T_OBJECT
        ) {
      Label done;
      assert(src == r1 &amp;&amp; src_pos == r2, &quot;mismatch in calling convention&quot;);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3126,10 ***</span>
<span class="line-new-header">--- 3325,11 ---</span>
      break;
    case T_LONG:
      xchg = &amp;MacroAssembler::atomic_xchgal;
      add = &amp;MacroAssembler::atomic_addal;
      break;
<span class="line-added">+   case T_INLINE_TYPE:</span>
    case T_OBJECT:
    case T_ARRAY:
      if (UseCompressedOops) {
        xchg = &amp;MacroAssembler::atomic_xchgalw;
        add = &amp;MacroAssembler::atomic_addalw;
</pre>
<center><a href="aarch64.ad.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_aarch64.cpp.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>