<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/cpu/aarch64/aarch64.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>    1 //
    2 // Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.
    3 // Copyright (c) 2014, 2020, Red Hat, Inc. All rights reserved.
    4 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    5 //
    6 // This code is free software; you can redistribute it and/or modify it
    7 // under the terms of the GNU General Public License version 2 only, as
    8 // published by the Free Software Foundation.
    9 //
   10 // This code is distributed in the hope that it will be useful, but WITHOUT
   11 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   12 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   13 // version 2 for more details (a copy is included in the LICENSE file that
   14 // accompanied this code).
   15 //
   16 // You should have received a copy of the GNU General Public License version
   17 // 2 along with this work; if not, write to the Free Software Foundation,
   18 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   19 //
   20 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   21 // or visit www.oracle.com if you need additional information or have any
   22 // questions.
   23 //
   24 //
   25 
   26 // AArch64 Architecture Description File
   27 
   28 //----------REGISTER DEFINITION BLOCK------------------------------------------
   29 // This information is used by the matcher and the register allocator to
   30 // describe individual registers and classes of registers within the target
   31 // archtecture.
   32 
   33 register %{
   34 //----------Architecture Description Register Definitions----------------------
   35 // General Registers
   36 // &quot;reg_def&quot;  name ( register save type, C convention save type,
   37 //                   ideal register type, encoding );
   38 // Register Save Types:
   39 //
   40 // NS  = No-Save:       The register allocator assumes that these registers
   41 //                      can be used without saving upon entry to the method, &amp;
   42 //                      that they do not need to be saved at call sites.
   43 //
   44 // SOC = Save-On-Call:  The register allocator assumes that these registers
   45 //                      can be used without saving upon entry to the method,
   46 //                      but that they must be saved at call sites.
   47 //
   48 // SOE = Save-On-Entry: The register allocator assumes that these registers
   49 //                      must be saved before using them upon entry to the
   50 //                      method, but they do not need to be saved at call
   51 //                      sites.
   52 //
   53 // AS  = Always-Save:   The register allocator assumes that these registers
   54 //                      must be saved before using them upon entry to the
   55 //                      method, &amp; that they must be saved at call sites.
   56 //
   57 // Ideal Register Type is used to determine how to save &amp; restore a
   58 // register.  Op_RegI will get spilled with LoadI/StoreI, Op_RegP will get
   59 // spilled with LoadP/StoreP.  If the register supports both, use Op_RegI.
   60 //
   61 // The encoding number is the actual bit-pattern placed into the opcodes.
   62 
   63 // We must define the 64 bit int registers in two 32 bit halves, the
   64 // real lower register and a virtual upper half register. upper halves
   65 // are used by the register allocator but are not actually supplied as
   66 // operands to memory ops.
   67 //
   68 // follow the C1 compiler in making registers
   69 //
   70 //   r0-r7,r10-r26 volatile (caller save)
   71 //   r27-r32 system (no save, no allocate)
   72 //   r8-r9 invisible to the allocator (so we can use them as scratch regs)
   73 //
   74 // as regards Java usage. we don&#39;t use any callee save registers
   75 // because this makes it difficult to de-optimise a frame (see comment
   76 // in x86 implementation of Deoptimization::unwind_callee_save_values)
   77 //
   78 
   79 // General Registers
   80 
   81 reg_def R0      ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()         );
   82 reg_def R0_H    ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()-&gt;next() );
   83 reg_def R1      ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()         );
   84 reg_def R1_H    ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()-&gt;next() );
   85 reg_def R2      ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()         );
   86 reg_def R2_H    ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()-&gt;next() );
   87 reg_def R3      ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()         );
   88 reg_def R3_H    ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()-&gt;next() );
   89 reg_def R4      ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()         );
   90 reg_def R4_H    ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()-&gt;next() );
   91 reg_def R5      ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()         );
   92 reg_def R5_H    ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()-&gt;next() );
   93 reg_def R6      ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()         );
   94 reg_def R6_H    ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()-&gt;next() );
   95 reg_def R7      ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()         );
   96 reg_def R7_H    ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()-&gt;next() );
   97 reg_def R10     ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()        );
   98 reg_def R10_H   ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()-&gt;next());
   99 reg_def R11     ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()        );
  100 reg_def R11_H   ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()-&gt;next());
  101 reg_def R12     ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()        );
  102 reg_def R12_H   ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()-&gt;next());
  103 reg_def R13     ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()        );
  104 reg_def R13_H   ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()-&gt;next());
  105 reg_def R14     ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()        );
  106 reg_def R14_H   ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()-&gt;next());
  107 reg_def R15     ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()        );
  108 reg_def R15_H   ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()-&gt;next());
  109 reg_def R16     ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()        );
  110 reg_def R16_H   ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()-&gt;next());
  111 reg_def R17     ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()        );
  112 reg_def R17_H   ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()-&gt;next());
  113 reg_def R18     ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()        );
  114 reg_def R18_H   ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()-&gt;next());
  115 reg_def R19     ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()        );
  116 reg_def R19_H   ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()-&gt;next());
  117 reg_def R20     ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()        ); // caller esp
  118 reg_def R20_H   ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()-&gt;next());
  119 reg_def R21     ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()        );
  120 reg_def R21_H   ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()-&gt;next());
  121 reg_def R22     ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()        );
  122 reg_def R22_H   ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()-&gt;next());
  123 reg_def R23     ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()        );
  124 reg_def R23_H   ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()-&gt;next());
  125 reg_def R24     ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()        );
  126 reg_def R24_H   ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()-&gt;next());
  127 reg_def R25     ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()        );
  128 reg_def R25_H   ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()-&gt;next());
  129 reg_def R26     ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()        );
  130 reg_def R26_H   ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()-&gt;next());
  131 reg_def R27     ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()        ); // heapbase
  132 reg_def R27_H   ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()-&gt;next());
  133 reg_def R28     (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()        ); // thread
  134 reg_def R28_H   (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()-&gt;next());
  135 reg_def R29     (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()        ); // fp
  136 reg_def R29_H   (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()-&gt;next());
  137 reg_def R30     (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()        ); // lr
  138 reg_def R30_H   (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()-&gt;next());
  139 reg_def R31     (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()     ); // sp
  140 reg_def R31_H   (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()-&gt;next());
  141 
  142 // ----------------------------
  143 // Float/Double Registers
  144 // ----------------------------
  145 
  146 // Double Registers
  147 
  148 // The rules of ADL require that double registers be defined in pairs.
  149 // Each pair must be two 32-bit values, but not necessarily a pair of
  150 // single float registers. In each pair, ADLC-assigned register numbers
  151 // must be adjacent, with the lower number even. Finally, when the
  152 // CPU stores such a register pair to memory, the word associated with
  153 // the lower ADLC-assigned number must be stored to the lower address.
  154 
  155 // AArch64 has 32 floating-point registers. Each can store a vector of
  156 // single or double precision floating-point values up to 8 * 32
  157 // floats, 4 * 64 bit floats or 2 * 128 bit floats.  We currently only
  158 // use the first float or double element of the vector.
  159 
  160 // for Java use float registers v0-v15 are always save on call whereas
  161 // the platform ABI treats v8-v15 as callee save). float registers
  162 // v16-v31 are SOC as per the platform spec
  163 
  164   reg_def V0   ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()          );
  165   reg_def V0_H ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next()  );
  166   reg_def V0_J ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(2) );
  167   reg_def V0_K ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(3) );
  168 
  169   reg_def V1   ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()          );
  170   reg_def V1_H ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next()  );
  171   reg_def V1_J ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(2) );
  172   reg_def V1_K ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(3) );
  173 
  174   reg_def V2   ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()          );
  175   reg_def V2_H ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next()  );
  176   reg_def V2_J ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(2) );
  177   reg_def V2_K ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(3) );
  178 
  179   reg_def V3   ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()          );
  180   reg_def V3_H ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next()  );
  181   reg_def V3_J ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(2) );
  182   reg_def V3_K ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(3) );
  183 
  184   reg_def V4   ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()          );
  185   reg_def V4_H ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next()  );
  186   reg_def V4_J ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(2) );
  187   reg_def V4_K ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(3) );
  188 
  189   reg_def V5   ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()          );
  190   reg_def V5_H ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next()  );
  191   reg_def V5_J ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(2) );
  192   reg_def V5_K ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(3) );
  193 
  194   reg_def V6   ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()          );
  195   reg_def V6_H ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next()  );
  196   reg_def V6_J ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(2) );
  197   reg_def V6_K ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(3) );
  198 
  199   reg_def V7   ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()          );
  200   reg_def V7_H ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next()  );
  201   reg_def V7_J ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(2) );
  202   reg_def V7_K ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(3) );
  203 
  204   reg_def V8   ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()          );
  205   reg_def V8_H ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next()  );
  206   reg_def V8_J ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(2) );
  207   reg_def V8_K ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(3) );
  208 
  209   reg_def V9   ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()          );
  210   reg_def V9_H ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next()  );
  211   reg_def V9_J ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(2) );
  212   reg_def V9_K ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(3) );
  213 
  214   reg_def V10  ( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()         );
  215   reg_def V10_H( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next() );
  216   reg_def V10_J( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(2));
  217   reg_def V10_K( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(3));
  218 
  219   reg_def V11  ( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()         );
  220   reg_def V11_H( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next() );
  221   reg_def V11_J( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(2));
  222   reg_def V11_K( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(3));
  223 
  224   reg_def V12  ( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()         );
  225   reg_def V12_H( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next() );
  226   reg_def V12_J( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(2));
  227   reg_def V12_K( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(3));
  228 
  229   reg_def V13  ( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()         );
  230   reg_def V13_H( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next() );
  231   reg_def V13_J( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(2));
  232   reg_def V13_K( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(3));
  233 
  234   reg_def V14  ( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()         );
  235   reg_def V14_H( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next() );
  236   reg_def V14_J( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(2));
  237   reg_def V14_K( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(3));
  238 
  239   reg_def V15  ( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()         );
  240   reg_def V15_H( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next() );
  241   reg_def V15_J( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(2));
  242   reg_def V15_K( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(3));
  243 
  244   reg_def V16  ( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()         );
  245   reg_def V16_H( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next() );
  246   reg_def V16_J( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(2));
  247   reg_def V16_K( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(3));
  248 
  249   reg_def V17  ( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()         );
  250   reg_def V17_H( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next() );
  251   reg_def V17_J( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(2));
  252   reg_def V17_K( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(3));
  253 
  254   reg_def V18  ( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()         );
  255   reg_def V18_H( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next() );
  256   reg_def V18_J( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(2));
  257   reg_def V18_K( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(3));
  258 
  259   reg_def V19  ( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()         );
  260   reg_def V19_H( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next() );
  261   reg_def V19_J( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(2));
  262   reg_def V19_K( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(3));
  263 
  264   reg_def V20  ( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()         );
  265   reg_def V20_H( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next() );
  266   reg_def V20_J( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(2));
  267   reg_def V20_K( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(3));
  268 
  269   reg_def V21  ( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()         );
  270   reg_def V21_H( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next() );
  271   reg_def V21_J( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(2));
  272   reg_def V21_K( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(3));
  273 
  274   reg_def V22  ( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()         );
  275   reg_def V22_H( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next() );
  276   reg_def V22_J( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(2));
  277   reg_def V22_K( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(3));
  278 
  279   reg_def V23  ( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()         );
  280   reg_def V23_H( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next() );
  281   reg_def V23_J( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(2));
  282   reg_def V23_K( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(3));
  283 
  284   reg_def V24  ( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()         );
  285   reg_def V24_H( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next() );
  286   reg_def V24_J( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(2));
  287   reg_def V24_K( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(3));
  288 
  289   reg_def V25  ( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()         );
  290   reg_def V25_H( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next() );
  291   reg_def V25_J( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(2));
  292   reg_def V25_K( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(3));
  293 
  294   reg_def V26  ( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()         );
  295   reg_def V26_H( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next() );
  296   reg_def V26_J( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(2));
  297   reg_def V26_K( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(3));
  298 
  299   reg_def V27  ( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()         );
  300   reg_def V27_H( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next() );
  301   reg_def V27_J( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(2));
  302   reg_def V27_K( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(3));
  303 
  304   reg_def V28  ( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()         );
  305   reg_def V28_H( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next() );
  306   reg_def V28_J( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(2));
  307   reg_def V28_K( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(3));
  308 
  309   reg_def V29  ( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()         );
  310   reg_def V29_H( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next() );
  311   reg_def V29_J( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(2));
  312   reg_def V29_K( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(3));
  313 
  314   reg_def V30  ( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()         );
  315   reg_def V30_H( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next() );
  316   reg_def V30_J( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(2));
  317   reg_def V30_K( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(3));
  318 
  319   reg_def V31  ( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()         );
  320   reg_def V31_H( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next() );
  321   reg_def V31_J( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(2));
  322   reg_def V31_K( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(3));
  323 
  324 // ----------------------------
  325 // Special Registers
  326 // ----------------------------
  327 
  328 // the AArch64 CSPR status flag register is not directly acessible as
  329 // instruction operand. the FPSR status flag register is a system
  330 // register which can be written/read using MSR/MRS but again does not
  331 // appear as an operand (a code identifying the FSPR occurs as an
  332 // immediate value in the instruction).
  333 
  334 reg_def RFLAGS(SOC, SOC, 0, 32, VMRegImpl::Bad());
  335 
  336 
  337 // Specify priority of register selection within phases of register
  338 // allocation.  Highest priority is first.  A useful heuristic is to
  339 // give registers a low priority when they are required by machine
  340 // instructions, like EAX and EDX on I486, and choose no-save registers
  341 // before save-on-call, &amp; save-on-call before save-on-entry.  Registers
  342 // which participate in fixed calling sequences should come last.
  343 // Registers which are used as pairs must fall on an even boundary.
  344 
  345 alloc_class chunk0(
  346     // volatiles
  347     R10, R10_H,
  348     R11, R11_H,
  349     R12, R12_H,
  350     R13, R13_H,
  351     R14, R14_H,
  352     R15, R15_H,
  353     R16, R16_H,
  354     R17, R17_H,
  355     R18, R18_H,
  356 
  357     // arg registers
  358     R0, R0_H,
  359     R1, R1_H,
  360     R2, R2_H,
  361     R3, R3_H,
  362     R4, R4_H,
  363     R5, R5_H,
  364     R6, R6_H,
  365     R7, R7_H,
  366 
  367     // non-volatiles
  368     R19, R19_H,
  369     R20, R20_H,
  370     R21, R21_H,
  371     R22, R22_H,
  372     R23, R23_H,
  373     R24, R24_H,
  374     R25, R25_H,
  375     R26, R26_H,
  376 
  377     // non-allocatable registers
  378 
  379     R27, R27_H, // heapbase
  380     R28, R28_H, // thread
  381     R29, R29_H, // fp
  382     R30, R30_H, // lr
  383     R31, R31_H, // sp
  384 );
  385 
  386 alloc_class chunk1(
  387 
  388     // no save
  389     V16, V16_H, V16_J, V16_K,
  390     V17, V17_H, V17_J, V17_K,
  391     V18, V18_H, V18_J, V18_K,
  392     V19, V19_H, V19_J, V19_K,
  393     V20, V20_H, V20_J, V20_K,
  394     V21, V21_H, V21_J, V21_K,
  395     V22, V22_H, V22_J, V22_K,
  396     V23, V23_H, V23_J, V23_K,
  397     V24, V24_H, V24_J, V24_K,
  398     V25, V25_H, V25_J, V25_K,
  399     V26, V26_H, V26_J, V26_K,
  400     V27, V27_H, V27_J, V27_K,
  401     V28, V28_H, V28_J, V28_K,
  402     V29, V29_H, V29_J, V29_K,
  403     V30, V30_H, V30_J, V30_K,
  404     V31, V31_H, V31_J, V31_K,
  405 
  406     // arg registers
  407     V0, V0_H, V0_J, V0_K,
  408     V1, V1_H, V1_J, V1_K,
  409     V2, V2_H, V2_J, V2_K,
  410     V3, V3_H, V3_J, V3_K,
  411     V4, V4_H, V4_J, V4_K,
  412     V5, V5_H, V5_J, V5_K,
  413     V6, V6_H, V6_J, V6_K,
  414     V7, V7_H, V7_J, V7_K,
  415 
  416     // non-volatiles
  417     V8, V8_H, V8_J, V8_K,
  418     V9, V9_H, V9_J, V9_K,
  419     V10, V10_H, V10_J, V10_K,
  420     V11, V11_H, V11_J, V11_K,
  421     V12, V12_H, V12_J, V12_K,
  422     V13, V13_H, V13_J, V13_K,
  423     V14, V14_H, V14_J, V14_K,
  424     V15, V15_H, V15_J, V15_K,
  425 );
  426 
  427 alloc_class chunk2(RFLAGS);
  428 
  429 //----------Architecture Description Register Classes--------------------------
  430 // Several register classes are automatically defined based upon information in
  431 // this architecture description.
  432 // 1) reg_class inline_cache_reg           ( /* as def&#39;d in frame section */ )
  433 // 2) reg_class compiler_method_oop_reg    ( /* as def&#39;d in frame section */ )
  434 // 2) reg_class interpreter_method_oop_reg ( /* as def&#39;d in frame section */ )
  435 // 3) reg_class stack_slots( /* one chunk of stack-based &quot;registers&quot; */ )
  436 //
  437 
  438 // Class for all 32 bit general purpose registers
  439 reg_class all_reg32(
  440     R0,
  441     R1,
  442     R2,
  443     R3,
  444     R4,
  445     R5,
  446     R6,
  447     R7,
  448     R10,
  449     R11,
  450     R12,
  451     R13,
  452     R14,
  453     R15,
  454     R16,
  455     R17,
  456     R18,
  457     R19,
  458     R20,
  459     R21,
  460     R22,
  461     R23,
  462     R24,
  463     R25,
  464     R26,
  465     R27,
  466     R28,
  467     R29,
  468     R30,
  469     R31
  470 );
  471 
  472 
  473 // Class for all 32 bit integer registers (excluding SP which
  474 // will never be used as an integer register)
  475 reg_class any_reg32 %{
  476   return _ANY_REG32_mask;
  477 %}
  478 
  479 // Singleton class for R0 int register
  480 reg_class int_r0_reg(R0);
  481 
  482 // Singleton class for R2 int register
  483 reg_class int_r2_reg(R2);
  484 
  485 // Singleton class for R3 int register
  486 reg_class int_r3_reg(R3);
  487 
  488 // Singleton class for R4 int register
  489 reg_class int_r4_reg(R4);
  490 
  491 // Singleton class for R31 int register
  492 reg_class int_r31_reg(R31);
  493 
  494 // Class for all 64 bit general purpose registers
  495 reg_class all_reg(
  496     R0, R0_H,
  497     R1, R1_H,
  498     R2, R2_H,
  499     R3, R3_H,
  500     R4, R4_H,
  501     R5, R5_H,
  502     R6, R6_H,
  503     R7, R7_H,
  504     R10, R10_H,
  505     R11, R11_H,
  506     R12, R12_H,
  507     R13, R13_H,
  508     R14, R14_H,
  509     R15, R15_H,
  510     R16, R16_H,
  511     R17, R17_H,
  512     R18, R18_H,
  513     R19, R19_H,
  514     R20, R20_H,
  515     R21, R21_H,
  516     R22, R22_H,
  517     R23, R23_H,
  518     R24, R24_H,
  519     R25, R25_H,
  520     R26, R26_H,
  521     R27, R27_H,
  522     R28, R28_H,
  523     R29, R29_H,
  524     R30, R30_H,
  525     R31, R31_H
  526 );
  527 
  528 // Class for all long integer registers (including SP)
  529 reg_class any_reg %{
  530   return _ANY_REG_mask;
  531 %}
  532 
  533 // Class for non-allocatable 32 bit registers
  534 reg_class non_allocatable_reg32(
  535     R28,                        // thread
  536     R30,                        // lr
  537     R31                         // sp
  538 );
  539 
  540 // Class for non-allocatable 64 bit registers
  541 reg_class non_allocatable_reg(
  542     R28, R28_H,                 // thread
  543     R30, R30_H,                 // lr
  544     R31, R31_H                  // sp
  545 );
  546 
  547 // Class for all non-special integer registers
  548 reg_class no_special_reg32 %{
  549   return _NO_SPECIAL_REG32_mask;
  550 %}
  551 
  552 // Class for all non-special long integer registers
  553 reg_class no_special_reg %{
  554   return _NO_SPECIAL_REG_mask;
  555 %}
  556 
  557 // Class for 64 bit register r0
  558 reg_class r0_reg(
  559     R0, R0_H
  560 );
  561 
  562 // Class for 64 bit register r1
  563 reg_class r1_reg(
  564     R1, R1_H
  565 );
  566 
  567 // Class for 64 bit register r2
  568 reg_class r2_reg(
  569     R2, R2_H
  570 );
  571 
  572 // Class for 64 bit register r3
  573 reg_class r3_reg(
  574     R3, R3_H
  575 );
  576 
  577 // Class for 64 bit register r4
  578 reg_class r4_reg(
  579     R4, R4_H
  580 );
  581 
  582 // Class for 64 bit register r5
  583 reg_class r5_reg(
  584     R5, R5_H
  585 );
  586 
  587 // Class for 64 bit register r10
  588 reg_class r10_reg(
  589     R10, R10_H
  590 );
  591 
  592 // Class for 64 bit register r11
  593 reg_class r11_reg(
  594     R11, R11_H
  595 );
  596 
  597 // Class for method register
  598 reg_class method_reg(
  599     R12, R12_H
  600 );
  601 
  602 // Class for heapbase register
  603 reg_class heapbase_reg(
  604     R27, R27_H
  605 );
  606 
  607 // Class for thread register
  608 reg_class thread_reg(
  609     R28, R28_H
  610 );
  611 
  612 // Class for frame pointer register
  613 reg_class fp_reg(
  614     R29, R29_H
  615 );
  616 
  617 // Class for link register
  618 reg_class lr_reg(
  619     R30, R30_H
  620 );
  621 
  622 // Class for long sp register
  623 reg_class sp_reg(
  624   R31, R31_H
  625 );
  626 
  627 // Class for all pointer registers
  628 reg_class ptr_reg %{
  629   return _PTR_REG_mask;
  630 %}
  631 
  632 // Class for all non_special pointer registers
  633 reg_class no_special_ptr_reg %{
  634   return _NO_SPECIAL_PTR_REG_mask;
  635 %}
  636 
  637 // Class for all float registers
  638 reg_class float_reg(
  639     V0,
  640     V1,
  641     V2,
  642     V3,
  643     V4,
  644     V5,
  645     V6,
  646     V7,
  647     V8,
  648     V9,
  649     V10,
  650     V11,
  651     V12,
  652     V13,
  653     V14,
  654     V15,
  655     V16,
  656     V17,
  657     V18,
  658     V19,
  659     V20,
  660     V21,
  661     V22,
  662     V23,
  663     V24,
  664     V25,
  665     V26,
  666     V27,
  667     V28,
  668     V29,
  669     V30,
  670     V31
  671 );
  672 
  673 // Double precision float registers have virtual `high halves&#39; that
  674 // are needed by the allocator.
  675 // Class for all double registers
  676 reg_class double_reg(
  677     V0, V0_H,
  678     V1, V1_H,
  679     V2, V2_H,
  680     V3, V3_H,
  681     V4, V4_H,
  682     V5, V5_H,
  683     V6, V6_H,
  684     V7, V7_H,
  685     V8, V8_H,
  686     V9, V9_H,
  687     V10, V10_H,
  688     V11, V11_H,
  689     V12, V12_H,
  690     V13, V13_H,
  691     V14, V14_H,
  692     V15, V15_H,
  693     V16, V16_H,
  694     V17, V17_H,
  695     V18, V18_H,
  696     V19, V19_H,
  697     V20, V20_H,
  698     V21, V21_H,
  699     V22, V22_H,
  700     V23, V23_H,
  701     V24, V24_H,
  702     V25, V25_H,
  703     V26, V26_H,
  704     V27, V27_H,
  705     V28, V28_H,
  706     V29, V29_H,
  707     V30, V30_H,
  708     V31, V31_H
  709 );
  710 
  711 // Class for all 64bit vector registers
  712 reg_class vectord_reg(
  713     V0, V0_H,
  714     V1, V1_H,
  715     V2, V2_H,
  716     V3, V3_H,
  717     V4, V4_H,
  718     V5, V5_H,
  719     V6, V6_H,
  720     V7, V7_H,
  721     V8, V8_H,
  722     V9, V9_H,
  723     V10, V10_H,
  724     V11, V11_H,
  725     V12, V12_H,
  726     V13, V13_H,
  727     V14, V14_H,
  728     V15, V15_H,
  729     V16, V16_H,
  730     V17, V17_H,
  731     V18, V18_H,
  732     V19, V19_H,
  733     V20, V20_H,
  734     V21, V21_H,
  735     V22, V22_H,
  736     V23, V23_H,
  737     V24, V24_H,
  738     V25, V25_H,
  739     V26, V26_H,
  740     V27, V27_H,
  741     V28, V28_H,
  742     V29, V29_H,
  743     V30, V30_H,
  744     V31, V31_H
  745 );
  746 
  747 // Class for all 128bit vector registers
  748 reg_class vectorx_reg(
  749     V0, V0_H, V0_J, V0_K,
  750     V1, V1_H, V1_J, V1_K,
  751     V2, V2_H, V2_J, V2_K,
  752     V3, V3_H, V3_J, V3_K,
  753     V4, V4_H, V4_J, V4_K,
  754     V5, V5_H, V5_J, V5_K,
  755     V6, V6_H, V6_J, V6_K,
  756     V7, V7_H, V7_J, V7_K,
  757     V8, V8_H, V8_J, V8_K,
  758     V9, V9_H, V9_J, V9_K,
  759     V10, V10_H, V10_J, V10_K,
  760     V11, V11_H, V11_J, V11_K,
  761     V12, V12_H, V12_J, V12_K,
  762     V13, V13_H, V13_J, V13_K,
  763     V14, V14_H, V14_J, V14_K,
  764     V15, V15_H, V15_J, V15_K,
  765     V16, V16_H, V16_J, V16_K,
  766     V17, V17_H, V17_J, V17_K,
  767     V18, V18_H, V18_J, V18_K,
  768     V19, V19_H, V19_J, V19_K,
  769     V20, V20_H, V20_J, V20_K,
  770     V21, V21_H, V21_J, V21_K,
  771     V22, V22_H, V22_J, V22_K,
  772     V23, V23_H, V23_J, V23_K,
  773     V24, V24_H, V24_J, V24_K,
  774     V25, V25_H, V25_J, V25_K,
  775     V26, V26_H, V26_J, V26_K,
  776     V27, V27_H, V27_J, V27_K,
  777     V28, V28_H, V28_J, V28_K,
  778     V29, V29_H, V29_J, V29_K,
  779     V30, V30_H, V30_J, V30_K,
  780     V31, V31_H, V31_J, V31_K
  781 );
  782 
  783 // Class for 128 bit register v0
  784 reg_class v0_reg(
  785     V0, V0_H
  786 );
  787 
  788 // Class for 128 bit register v1
  789 reg_class v1_reg(
  790     V1, V1_H
  791 );
  792 
  793 // Class for 128 bit register v2
  794 reg_class v2_reg(
  795     V2, V2_H
  796 );
  797 
  798 // Class for 128 bit register v3
  799 reg_class v3_reg(
  800     V3, V3_H
  801 );
  802 
  803 // Class for 128 bit register v4
  804 reg_class v4_reg(
  805     V4, V4_H
  806 );
  807 
  808 // Class for 128 bit register v5
  809 reg_class v5_reg(
  810     V5, V5_H
  811 );
  812 
  813 // Class for 128 bit register v6
  814 reg_class v6_reg(
  815     V6, V6_H
  816 );
  817 
  818 // Class for 128 bit register v7
  819 reg_class v7_reg(
  820     V7, V7_H
  821 );
  822 
  823 // Class for 128 bit register v8
  824 reg_class v8_reg(
  825     V8, V8_H
  826 );
  827 
  828 // Class for 128 bit register v9
  829 reg_class v9_reg(
  830     V9, V9_H
  831 );
  832 
  833 // Class for 128 bit register v10
  834 reg_class v10_reg(
  835     V10, V10_H
  836 );
  837 
  838 // Class for 128 bit register v11
  839 reg_class v11_reg(
  840     V11, V11_H
  841 );
  842 
  843 // Class for 128 bit register v12
  844 reg_class v12_reg(
  845     V12, V12_H
  846 );
  847 
  848 // Class for 128 bit register v13
  849 reg_class v13_reg(
  850     V13, V13_H
  851 );
  852 
  853 // Class for 128 bit register v14
  854 reg_class v14_reg(
  855     V14, V14_H
  856 );
  857 
  858 // Class for 128 bit register v15
  859 reg_class v15_reg(
  860     V15, V15_H
  861 );
  862 
  863 // Class for 128 bit register v16
  864 reg_class v16_reg(
  865     V16, V16_H
  866 );
  867 
  868 // Class for 128 bit register v17
  869 reg_class v17_reg(
  870     V17, V17_H
  871 );
  872 
  873 // Class for 128 bit register v18
  874 reg_class v18_reg(
  875     V18, V18_H
  876 );
  877 
  878 // Class for 128 bit register v19
  879 reg_class v19_reg(
  880     V19, V19_H
  881 );
  882 
  883 // Class for 128 bit register v20
  884 reg_class v20_reg(
  885     V20, V20_H
  886 );
  887 
  888 // Class for 128 bit register v21
  889 reg_class v21_reg(
  890     V21, V21_H
  891 );
  892 
  893 // Class for 128 bit register v22
  894 reg_class v22_reg(
  895     V22, V22_H
  896 );
  897 
  898 // Class for 128 bit register v23
  899 reg_class v23_reg(
  900     V23, V23_H
  901 );
  902 
  903 // Class for 128 bit register v24
  904 reg_class v24_reg(
  905     V24, V24_H
  906 );
  907 
  908 // Class for 128 bit register v25
  909 reg_class v25_reg(
  910     V25, V25_H
  911 );
  912 
  913 // Class for 128 bit register v26
  914 reg_class v26_reg(
  915     V26, V26_H
  916 );
  917 
  918 // Class for 128 bit register v27
  919 reg_class v27_reg(
  920     V27, V27_H
  921 );
  922 
  923 // Class for 128 bit register v28
  924 reg_class v28_reg(
  925     V28, V28_H
  926 );
  927 
  928 // Class for 128 bit register v29
  929 reg_class v29_reg(
  930     V29, V29_H
  931 );
  932 
  933 // Class for 128 bit register v30
  934 reg_class v30_reg(
  935     V30, V30_H
  936 );
  937 
  938 // Class for 128 bit register v31
  939 reg_class v31_reg(
  940     V31, V31_H
  941 );
  942 
  943 // Singleton class for condition codes
  944 reg_class int_flags(RFLAGS);
  945 
  946 %}
  947 
  948 //----------DEFINITION BLOCK---------------------------------------------------
  949 // Define name --&gt; value mappings to inform the ADLC of an integer valued name
  950 // Current support includes integer values in the range [0, 0x7FFFFFFF]
  951 // Format:
  952 //        int_def  &lt;name&gt;         ( &lt;int_value&gt;, &lt;expression&gt;);
  953 // Generated Code in ad_&lt;arch&gt;.hpp
  954 //        #define  &lt;name&gt;   (&lt;expression&gt;)
  955 //        // value == &lt;int_value&gt;
  956 // Generated code in ad_&lt;arch&gt;.cpp adlc_verification()
  957 //        assert( &lt;name&gt; == &lt;int_value&gt;, &quot;Expect (&lt;expression&gt;) to equal &lt;int_value&gt;&quot;);
  958 //
  959 
  960 // we follow the ppc-aix port in using a simple cost model which ranks
  961 // register operations as cheap, memory ops as more expensive and
  962 // branches as most expensive. the first two have a low as well as a
  963 // normal cost. huge cost appears to be a way of saying don&#39;t do
  964 // something
  965 
  966 definitions %{
  967   // The default cost (of a register move instruction).
  968   int_def INSN_COST            (    100,     100);
  969   int_def BRANCH_COST          (    200,     2 * INSN_COST);
  970   int_def CALL_COST            (    200,     2 * INSN_COST);
  971   int_def VOLATILE_REF_COST    (   1000,     10 * INSN_COST);
  972 %}
  973 
  974 
  975 //----------SOURCE BLOCK-------------------------------------------------------
  976 // This is a block of C++ code which provides values, functions, and
  977 // definitions necessary in the rest of the architecture description
  978 
  979 source_hpp %{
  980 
  981 #include &quot;asm/macroAssembler.hpp&quot;
  982 #include &quot;gc/shared/cardTable.hpp&quot;
  983 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;
  984 #include &quot;gc/shared/collectedHeap.hpp&quot;
  985 #include &quot;opto/addnode.hpp&quot;
  986 #include &quot;opto/convertnode.hpp&quot;
  987 
  988 extern RegMask _ANY_REG32_mask;
  989 extern RegMask _ANY_REG_mask;
  990 extern RegMask _PTR_REG_mask;
  991 extern RegMask _NO_SPECIAL_REG32_mask;
  992 extern RegMask _NO_SPECIAL_REG_mask;
  993 extern RegMask _NO_SPECIAL_PTR_REG_mask;
  994 
  995 class CallStubImpl {
  996 
  997   //--------------------------------------------------------------
  998   //---&lt;  Used for optimization in Compile::shorten_branches  &gt;---
  999   //--------------------------------------------------------------
 1000 
 1001  public:
 1002   // Size of call trampoline stub.
 1003   static uint size_call_trampoline() {
 1004     return 0; // no call trampolines on this platform
 1005   }
 1006 
 1007   // number of relocations needed by a call trampoline stub
 1008   static uint reloc_call_trampoline() {
 1009     return 0; // no call trampolines on this platform
 1010   }
 1011 };
 1012 
 1013 class HandlerImpl {
 1014 
 1015  public:
 1016 
 1017   static int emit_exception_handler(CodeBuffer &amp;cbuf);
 1018   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
 1019 
 1020   static uint size_exception_handler() {
 1021     return MacroAssembler::far_branch_size();
 1022   }
 1023 
 1024   static uint size_deopt_handler() {
 1025     // count one adr and one far branch instruction
 1026     return 4 * NativeInstruction::instruction_size;
 1027   }
 1028 };
 1029 
 1030 class Node::PD {
 1031 public:
 1032   enum NodeFlags {
 1033     _last_flag = Node::_last_flag
 1034   };
 1035 };
 1036 
 1037  bool is_CAS(int opcode, bool maybe_volatile);
 1038 
 1039   // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1040 
 1041   bool unnecessary_acquire(const Node *barrier);
 1042   bool needs_acquiring_load(const Node *load);
 1043 
 1044   // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1045 
 1046   bool unnecessary_release(const Node *barrier);
 1047   bool unnecessary_volatile(const Node *barrier);
 1048   bool needs_releasing_store(const Node *store);
 1049 
 1050   // predicate controlling translation of CompareAndSwapX
 1051   bool needs_acquiring_load_exclusive(const Node *load);
 1052 
 1053   // predicate controlling addressing modes
 1054   bool size_fits_all_mem_uses(AddPNode* addp, int shift);
 1055 %}
 1056 
 1057 source %{
 1058 
 1059   // Derived RegMask with conditionally allocatable registers
 1060 
 1061   void PhaseOutput::pd_perform_mach_node_analysis() {
 1062   }
 1063 
 1064   int MachNode::pd_alignment_required() const {
 1065     return 1;
 1066   }
 1067 
 1068   int MachNode::compute_padding(int current_offset) const {
 1069     return 0;
 1070   }
 1071 
 1072   RegMask _ANY_REG32_mask;
 1073   RegMask _ANY_REG_mask;
 1074   RegMask _PTR_REG_mask;
 1075   RegMask _NO_SPECIAL_REG32_mask;
 1076   RegMask _NO_SPECIAL_REG_mask;
 1077   RegMask _NO_SPECIAL_PTR_REG_mask;
 1078 
 1079   void reg_mask_init() {
 1080     // We derive below RegMask(s) from the ones which are auto-generated from
 1081     // adlc register classes to make AArch64 rheapbase (r27) and rfp (r29)
 1082     // registers conditionally reserved.
 1083 
 1084     _ANY_REG32_mask = _ALL_REG32_mask;
 1085     _ANY_REG32_mask.Remove(OptoReg::as_OptoReg(r31_sp-&gt;as_VMReg()));
 1086 
 1087     _ANY_REG_mask = _ALL_REG_mask;
 1088 
 1089     _PTR_REG_mask = _ALL_REG_mask;
 1090 
 1091     _NO_SPECIAL_REG32_mask = _ALL_REG32_mask;
 1092     _NO_SPECIAL_REG32_mask.SUBTRACT(_NON_ALLOCATABLE_REG32_mask);
 1093 
 1094     _NO_SPECIAL_REG_mask = _ALL_REG_mask;
 1095     _NO_SPECIAL_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1096 
 1097     _NO_SPECIAL_PTR_REG_mask = _ALL_REG_mask;
 1098     _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1099 
 1100     // r27 is not allocatable when compressed oops is on and heapbase is not
 1101     // zero, compressed klass pointers doesn&#39;t use r27 after JDK-8234794
 1102     if (UseCompressedOops &amp;&amp; CompressedOops::ptrs_base() != NULL) {
 1103       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r27-&gt;as_VMReg()));
 1104       _NO_SPECIAL_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1105       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1106     }
 1107 
 1108     // r29 is not allocatable when PreserveFramePointer is on
 1109     if (PreserveFramePointer) {
 1110       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r29-&gt;as_VMReg()));
 1111       _NO_SPECIAL_REG_mask.SUBTRACT(_FP_REG_mask);
 1112       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_FP_REG_mask);
 1113     }
 1114   }
 1115 
 1116   // Optimizaton of volatile gets and puts
 1117   // -------------------------------------
 1118   //
 1119   // AArch64 has ldar&lt;x&gt; and stlr&lt;x&gt; instructions which we can safely
 1120   // use to implement volatile reads and writes. For a volatile read
 1121   // we simply need
 1122   //
 1123   //   ldar&lt;x&gt;
 1124   //
 1125   // and for a volatile write we need
 1126   //
 1127   //   stlr&lt;x&gt;
 1128   //
 1129   // Alternatively, we can implement them by pairing a normal
 1130   // load/store with a memory barrier. For a volatile read we need
 1131   //
 1132   //   ldr&lt;x&gt;
 1133   //   dmb ishld
 1134   //
 1135   // for a volatile write
 1136   //
 1137   //   dmb ish
 1138   //   str&lt;x&gt;
 1139   //   dmb ish
 1140   //
 1141   // We can also use ldaxr and stlxr to implement compare and swap CAS
 1142   // sequences. These are normally translated to an instruction
 1143   // sequence like the following
 1144   //
 1145   //   dmb      ish
 1146   // retry:
 1147   //   ldxr&lt;x&gt;   rval raddr
 1148   //   cmp       rval rold
 1149   //   b.ne done
 1150   //   stlxr&lt;x&gt;  rval, rnew, rold
 1151   //   cbnz      rval retry
 1152   // done:
 1153   //   cset      r0, eq
 1154   //   dmb ishld
 1155   //
 1156   // Note that the exclusive store is already using an stlxr
 1157   // instruction. That is required to ensure visibility to other
 1158   // threads of the exclusive write (assuming it succeeds) before that
 1159   // of any subsequent writes.
 1160   //
 1161   // The following instruction sequence is an improvement on the above
 1162   //
 1163   // retry:
 1164   //   ldaxr&lt;x&gt;  rval raddr
 1165   //   cmp       rval rold
 1166   //   b.ne done
 1167   //   stlxr&lt;x&gt;  rval, rnew, rold
 1168   //   cbnz      rval retry
 1169   // done:
 1170   //   cset      r0, eq
 1171   //
 1172   // We don&#39;t need the leading dmb ish since the stlxr guarantees
 1173   // visibility of prior writes in the case that the swap is
 1174   // successful. Crucially we don&#39;t have to worry about the case where
 1175   // the swap is not successful since no valid program should be
 1176   // relying on visibility of prior changes by the attempting thread
 1177   // in the case where the CAS fails.
 1178   //
 1179   // Similarly, we don&#39;t need the trailing dmb ishld if we substitute
 1180   // an ldaxr instruction since that will provide all the guarantees we
 1181   // require regarding observation of changes made by other threads
 1182   // before any change to the CAS address observed by the load.
 1183   //
 1184   // In order to generate the desired instruction sequence we need to
 1185   // be able to identify specific &#39;signature&#39; ideal graph node
 1186   // sequences which i) occur as a translation of a volatile reads or
 1187   // writes or CAS operations and ii) do not occur through any other
 1188   // translation or graph transformation. We can then provide
 1189   // alternative aldc matching rules which translate these node
 1190   // sequences to the desired machine code sequences. Selection of the
 1191   // alternative rules can be implemented by predicates which identify
 1192   // the relevant node sequences.
 1193   //
 1194   // The ideal graph generator translates a volatile read to the node
 1195   // sequence
 1196   //
 1197   //   LoadX[mo_acquire]
 1198   //   MemBarAcquire
 1199   //
 1200   // As a special case when using the compressed oops optimization we
 1201   // may also see this variant
 1202   //
 1203   //   LoadN[mo_acquire]
 1204   //   DecodeN
 1205   //   MemBarAcquire
 1206   //
 1207   // A volatile write is translated to the node sequence
 1208   //
 1209   //   MemBarRelease
 1210   //   StoreX[mo_release] {CardMark}-optional
 1211   //   MemBarVolatile
 1212   //
 1213   // n.b. the above node patterns are generated with a strict
 1214   // &#39;signature&#39; configuration of input and output dependencies (see
 1215   // the predicates below for exact details). The card mark may be as
 1216   // simple as a few extra nodes or, in a few GC configurations, may
 1217   // include more complex control flow between the leading and
 1218   // trailing memory barriers. However, whatever the card mark
 1219   // configuration these signatures are unique to translated volatile
 1220   // reads/stores -- they will not appear as a result of any other
 1221   // bytecode translation or inlining nor as a consequence of
 1222   // optimizing transforms.
 1223   //
 1224   // We also want to catch inlined unsafe volatile gets and puts and
 1225   // be able to implement them using either ldar&lt;x&gt;/stlr&lt;x&gt; or some
 1226   // combination of ldr&lt;x&gt;/stlr&lt;x&gt; and dmb instructions.
 1227   //
 1228   // Inlined unsafe volatiles puts manifest as a minor variant of the
 1229   // normal volatile put node sequence containing an extra cpuorder
 1230   // membar
 1231   //
 1232   //   MemBarRelease
 1233   //   MemBarCPUOrder
 1234   //   StoreX[mo_release] {CardMark}-optional
 1235   //   MemBarCPUOrder
 1236   //   MemBarVolatile
 1237   //
 1238   // n.b. as an aside, a cpuorder membar is not itself subject to
 1239   // matching and translation by adlc rules.  However, the rule
 1240   // predicates need to detect its presence in order to correctly
 1241   // select the desired adlc rules.
 1242   //
 1243   // Inlined unsafe volatile gets manifest as a slightly different
 1244   // node sequence to a normal volatile get because of the
 1245   // introduction of some CPUOrder memory barriers to bracket the
 1246   // Load. However, but the same basic skeleton of a LoadX feeding a
 1247   // MemBarAcquire, possibly thorugh an optional DecodeN, is still
 1248   // present
 1249   //
 1250   //   MemBarCPUOrder
 1251   //        ||       \\
 1252   //   MemBarCPUOrder LoadX[mo_acquire]
 1253   //        ||            |
 1254   //        ||       {DecodeN} optional
 1255   //        ||       /
 1256   //     MemBarAcquire
 1257   //
 1258   // In this case the acquire membar does not directly depend on the
 1259   // load. However, we can be sure that the load is generated from an
 1260   // inlined unsafe volatile get if we see it dependent on this unique
 1261   // sequence of membar nodes. Similarly, given an acquire membar we
 1262   // can know that it was added because of an inlined unsafe volatile
 1263   // get if it is fed and feeds a cpuorder membar and if its feed
 1264   // membar also feeds an acquiring load.
 1265   //
 1266   // Finally an inlined (Unsafe) CAS operation is translated to the
 1267   // following ideal graph
 1268   //
 1269   //   MemBarRelease
 1270   //   MemBarCPUOrder
 1271   //   CompareAndSwapX {CardMark}-optional
 1272   //   MemBarCPUOrder
 1273   //   MemBarAcquire
 1274   //
 1275   // So, where we can identify these volatile read and write
 1276   // signatures we can choose to plant either of the above two code
 1277   // sequences. For a volatile read we can simply plant a normal
 1278   // ldr&lt;x&gt; and translate the MemBarAcquire to a dmb. However, we can
 1279   // also choose to inhibit translation of the MemBarAcquire and
 1280   // inhibit planting of the ldr&lt;x&gt;, instead planting an ldar&lt;x&gt;.
 1281   //
 1282   // When we recognise a volatile store signature we can choose to
 1283   // plant at a dmb ish as a translation for the MemBarRelease, a
 1284   // normal str&lt;x&gt; and then a dmb ish for the MemBarVolatile.
 1285   // Alternatively, we can inhibit translation of the MemBarRelease
 1286   // and MemBarVolatile and instead plant a simple stlr&lt;x&gt;
 1287   // instruction.
 1288   //
 1289   // when we recognise a CAS signature we can choose to plant a dmb
 1290   // ish as a translation for the MemBarRelease, the conventional
 1291   // macro-instruction sequence for the CompareAndSwap node (which
 1292   // uses ldxr&lt;x&gt;) and then a dmb ishld for the MemBarAcquire.
 1293   // Alternatively, we can elide generation of the dmb instructions
 1294   // and plant the alternative CompareAndSwap macro-instruction
 1295   // sequence (which uses ldaxr&lt;x&gt;).
 1296   //
 1297   // Of course, the above only applies when we see these signature
 1298   // configurations. We still want to plant dmb instructions in any
 1299   // other cases where we may see a MemBarAcquire, MemBarRelease or
 1300   // MemBarVolatile. For example, at the end of a constructor which
 1301   // writes final/volatile fields we will see a MemBarRelease
 1302   // instruction and this needs a &#39;dmb ish&#39; lest we risk the
 1303   // constructed object being visible without making the
 1304   // final/volatile field writes visible.
 1305   //
 1306   // n.b. the translation rules below which rely on detection of the
 1307   // volatile signatures and insert ldar&lt;x&gt; or stlr&lt;x&gt; are failsafe.
 1308   // If we see anything other than the signature configurations we
 1309   // always just translate the loads and stores to ldr&lt;x&gt; and str&lt;x&gt;
 1310   // and translate acquire, release and volatile membars to the
 1311   // relevant dmb instructions.
 1312   //
 1313 
 1314   // is_CAS(int opcode, bool maybe_volatile)
 1315   //
 1316   // return true if opcode is one of the possible CompareAndSwapX
 1317   // values otherwise false.
 1318 
 1319   bool is_CAS(int opcode, bool maybe_volatile)
 1320   {
 1321     switch(opcode) {
 1322       // We handle these
 1323     case Op_CompareAndSwapI:
 1324     case Op_CompareAndSwapL:
 1325     case Op_CompareAndSwapP:
 1326     case Op_CompareAndSwapN:
 1327     case Op_ShenandoahCompareAndSwapP:
 1328     case Op_ShenandoahCompareAndSwapN:
 1329     case Op_CompareAndSwapB:
 1330     case Op_CompareAndSwapS:
 1331     case Op_GetAndSetI:
 1332     case Op_GetAndSetL:
 1333     case Op_GetAndSetP:
 1334     case Op_GetAndSetN:
 1335     case Op_GetAndAddI:
 1336     case Op_GetAndAddL:
 1337       return true;
 1338     case Op_CompareAndExchangeI:
 1339     case Op_CompareAndExchangeN:
 1340     case Op_CompareAndExchangeB:
 1341     case Op_CompareAndExchangeS:
 1342     case Op_CompareAndExchangeL:
 1343     case Op_CompareAndExchangeP:
 1344     case Op_WeakCompareAndSwapB:
 1345     case Op_WeakCompareAndSwapS:
 1346     case Op_WeakCompareAndSwapI:
 1347     case Op_WeakCompareAndSwapL:
 1348     case Op_WeakCompareAndSwapP:
 1349     case Op_WeakCompareAndSwapN:
 1350     case Op_ShenandoahWeakCompareAndSwapP:
 1351     case Op_ShenandoahWeakCompareAndSwapN:
 1352     case Op_ShenandoahCompareAndExchangeP:
 1353     case Op_ShenandoahCompareAndExchangeN:
 1354       return maybe_volatile;
 1355     default:
 1356       return false;
 1357     }
 1358   }
 1359 
 1360   // helper to determine the maximum number of Phi nodes we may need to
 1361   // traverse when searching from a card mark membar for the merge mem
 1362   // feeding a trailing membar or vice versa
 1363 
 1364 // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt;
 1365 
 1366 bool unnecessary_acquire(const Node *barrier)
 1367 {
 1368   assert(barrier-&gt;is_MemBar(), &quot;expecting a membar&quot;);
 1369 
 1370   MemBarNode* mb = barrier-&gt;as_MemBar();
 1371 
 1372   if (mb-&gt;trailing_load()) {
 1373     return true;
 1374   }
 1375 
 1376   if (mb-&gt;trailing_load_store()) {
 1377     Node* load_store = mb-&gt;in(MemBarNode::Precedent);
 1378     assert(load_store-&gt;is_LoadStore(), &quot;unexpected graph shape&quot;);
 1379     return is_CAS(load_store-&gt;Opcode(), true);
 1380   }
 1381 
 1382   return false;
 1383 }
 1384 
 1385 bool needs_acquiring_load(const Node *n)
 1386 {
 1387   assert(n-&gt;is_Load(), &quot;expecting a load&quot;);
 1388   LoadNode *ld = n-&gt;as_Load();
 1389   return ld-&gt;is_acquire();
 1390 }
 1391 
 1392 bool unnecessary_release(const Node *n)
 1393 {
 1394   assert((n-&gt;is_MemBar() &amp;&amp;
 1395           n-&gt;Opcode() == Op_MemBarRelease),
 1396          &quot;expecting a release membar&quot;);
 1397 
 1398   MemBarNode *barrier = n-&gt;as_MemBar();
 1399   if (!barrier-&gt;leading()) {
 1400     return false;
 1401   } else {
 1402     Node* trailing = barrier-&gt;trailing_membar();
 1403     MemBarNode* trailing_mb = trailing-&gt;as_MemBar();
 1404     assert(trailing_mb-&gt;trailing(), &quot;Not a trailing membar?&quot;);
 1405     assert(trailing_mb-&gt;leading_membar() == n, &quot;inconsistent leading/trailing membars&quot;);
 1406 
 1407     Node* mem = trailing_mb-&gt;in(MemBarNode::Precedent);
 1408     if (mem-&gt;is_Store()) {
 1409       assert(mem-&gt;as_Store()-&gt;is_release(), &quot;&quot;);
 1410       assert(trailing_mb-&gt;Opcode() == Op_MemBarVolatile, &quot;&quot;);
 1411       return true;
 1412     } else {
 1413       assert(mem-&gt;is_LoadStore(), &quot;&quot;);
 1414       assert(trailing_mb-&gt;Opcode() == Op_MemBarAcquire, &quot;&quot;);
 1415       return is_CAS(mem-&gt;Opcode(), true);
 1416     }
 1417   }
 1418   return false;
 1419 }
 1420 
 1421 bool unnecessary_volatile(const Node *n)
 1422 {
 1423   // assert n-&gt;is_MemBar();
 1424   MemBarNode *mbvol = n-&gt;as_MemBar();
 1425 
 1426   bool release = mbvol-&gt;trailing_store();
 1427   assert(!release || (mbvol-&gt;in(MemBarNode::Precedent)-&gt;is_Store() &amp;&amp; mbvol-&gt;in(MemBarNode::Precedent)-&gt;as_Store()-&gt;is_release()), &quot;&quot;);
 1428 #ifdef ASSERT
 1429   if (release) {
 1430     Node* leading = mbvol-&gt;leading_membar();
 1431     assert(leading-&gt;Opcode() == Op_MemBarRelease, &quot;&quot;);
 1432     assert(leading-&gt;as_MemBar()-&gt;leading_store(), &quot;&quot;);
 1433     assert(leading-&gt;as_MemBar()-&gt;trailing_membar() == mbvol, &quot;&quot;);
 1434   }
 1435 #endif
 1436 
 1437   return release;
 1438 }
 1439 
 1440 // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt;
 1441 
 1442 bool needs_releasing_store(const Node *n)
 1443 {
 1444   // assert n-&gt;is_Store();
 1445   StoreNode *st = n-&gt;as_Store();
 1446   return st-&gt;trailing_membar() != NULL;
 1447 }
 1448 
 1449 // predicate controlling translation of CAS
 1450 //
 1451 // returns true if CAS needs to use an acquiring load otherwise false
 1452 
 1453 bool needs_acquiring_load_exclusive(const Node *n)
 1454 {
 1455   assert(is_CAS(n-&gt;Opcode(), true), &quot;expecting a compare and swap&quot;);
 1456   LoadStoreNode* ldst = n-&gt;as_LoadStore();
 1457   if (is_CAS(n-&gt;Opcode(), false)) {
 1458     assert(ldst-&gt;trailing_membar() != NULL, &quot;expected trailing membar&quot;);
 1459   } else {
 1460     return ldst-&gt;trailing_membar() != NULL;
 1461   }
 1462 
 1463   // so we can just return true here
 1464   return true;
 1465 }
 1466 
 1467 #define __ _masm.
 1468 
 1469 // advance declarations for helper functions to convert register
 1470 // indices to register objects
 1471 
 1472 // the ad file has to provide implementations of certain methods
 1473 // expected by the generic code
 1474 //
 1475 // REQUIRED FUNCTIONALITY
 1476 
 1477 //=============================================================================
 1478 
 1479 // !!!!! Special hack to get all types of calls to specify the byte offset
 1480 //       from the start of the call to the point where the return address
 1481 //       will point.
 1482 
 1483 int MachCallStaticJavaNode::ret_addr_offset()
 1484 {
 1485   // call should be a simple bl
 1486   int off = 4;
 1487   return off;
 1488 }
 1489 
 1490 int MachCallDynamicJavaNode::ret_addr_offset()
 1491 {
 1492   return 16; // movz, movk, movk, bl
 1493 }
 1494 
 1495 int MachCallRuntimeNode::ret_addr_offset() {
 1496   // for generated stubs the call will be
 1497   //   far_call(addr)
 1498   // for real runtime callouts it will be six instructions
 1499   // see aarch64_enc_java_to_runtime
 1500   //   adr(rscratch2, retaddr)
 1501   //   lea(rscratch1, RuntimeAddress(addr)
 1502   //   stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)))
 1503   //   blr(rscratch1)
 1504   CodeBlob *cb = CodeCache::find_blob(_entry_point);
 1505   if (cb) {
 1506     return MacroAssembler::far_branch_size();
 1507   } else {
 1508     return 6 * NativeInstruction::instruction_size;
 1509   }
 1510 }
 1511 
 1512 // Indicate if the safepoint node needs the polling page as an input
 1513 
 1514 // the shared code plants the oop data at the start of the generated
 1515 // code for the safepoint node and that needs ot be at the load
 1516 // instruction itself. so we cannot plant a mov of the safepoint poll
 1517 // address followed by a load. setting this to true means the mov is
 1518 // scheduled as a prior instruction. that&#39;s better for scheduling
 1519 // anyway.
 1520 
 1521 bool SafePointNode::needs_polling_address_input()
 1522 {
 1523   return true;
 1524 }
 1525 
 1526 //=============================================================================
 1527 
 1528 #ifndef PRODUCT
 1529 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1530   st-&gt;print(&quot;BREAKPOINT&quot;);
 1531 }
 1532 #endif
 1533 
 1534 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1535   C2_MacroAssembler _masm(&amp;cbuf);
 1536   __ brk(0);
 1537 }
 1538 
 1539 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
 1540   return MachNode::size(ra_);
 1541 }
 1542 
 1543 //=============================================================================
 1544 
 1545 #ifndef PRODUCT
 1546   void MachNopNode::format(PhaseRegAlloc*, outputStream* st) const {
 1547     st-&gt;print(&quot;nop \t# %d bytes pad for loops and calls&quot;, _count);
 1548   }
 1549 #endif
 1550 
 1551   void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc*) const {
 1552     C2_MacroAssembler _masm(&amp;cbuf);
 1553     for (int i = 0; i &lt; _count; i++) {
 1554       __ nop();
 1555     }
 1556   }
 1557 
 1558   uint MachNopNode::size(PhaseRegAlloc*) const {
 1559     return _count * NativeInstruction::instruction_size;
 1560   }
 1561 
 1562 //=============================================================================
 1563 const RegMask&amp; MachConstantBaseNode::_out_RegMask = RegMask::Empty;
 1564 
 1565 int ConstantTable::calculate_table_base_offset() const {
 1566   return 0;  // absolute addressing, no offset
 1567 }
 1568 
 1569 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
 1570 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1571   ShouldNotReachHere();
 1572 }
 1573 
 1574 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1575   // Empty encoding
 1576 }
 1577 
 1578 uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
 1579   return 0;
 1580 }
 1581 
 1582 #ifndef PRODUCT
 1583 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1584   st-&gt;print(&quot;-- \t// MachConstantBaseNode (empty encoding)&quot;);
 1585 }
 1586 #endif
 1587 
 1588 #ifndef PRODUCT
 1589 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1590   Compile* C = ra_-&gt;C;
 1591 
 1592   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1593 
 1594   if (C-&gt;output()-&gt;need_stack_bang(framesize))
 1595     st-&gt;print(&quot;# stack bang size=%d\n\t&quot;, framesize);
 1596 
 1597   if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1598     st-&gt;print(&quot;sub  sp, sp, #%d\n\t&quot;, framesize);
 1599     st-&gt;print(&quot;stp  rfp, lr, [sp, #%d]&quot;, framesize - 2 * wordSize);
 1600     if (PreserveFramePointer) st-&gt;print(&quot;\n\tadd  rfp, sp, #%d&quot;, framesize - 2 * wordSize);
 1601   } else {
 1602     st-&gt;print(&quot;stp  lr, rfp, [sp, #%d]!\n\t&quot;, -(2 * wordSize));
 1603     if (PreserveFramePointer) st-&gt;print(&quot;mov  rfp, sp\n\t&quot;);
 1604     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1605     st-&gt;print(&quot;sub  sp, sp, rscratch1&quot;);
 1606   }
 1607   if (C-&gt;stub_function() == NULL &amp;&amp; BarrierSet::barrier_set()-&gt;barrier_set_nmethod() != NULL) {
 1608     st-&gt;print(&quot;\n\t&quot;);
 1609     st-&gt;print(&quot;ldr  rscratch1, [guard]\n\t&quot;);
 1610     st-&gt;print(&quot;dmb ishld\n\t&quot;);
 1611     st-&gt;print(&quot;ldr  rscratch2, [rthread, #thread_disarmed_offset]\n\t&quot;);
 1612     st-&gt;print(&quot;cmp  rscratch1, rscratch2\n\t&quot;);
 1613     st-&gt;print(&quot;b.eq skip&quot;);
 1614     st-&gt;print(&quot;\n\t&quot;);
 1615     st-&gt;print(&quot;blr #nmethod_entry_barrier_stub\n\t&quot;);
 1616     st-&gt;print(&quot;b skip\n\t&quot;);
 1617     st-&gt;print(&quot;guard: int\n\t&quot;);
 1618     st-&gt;print(&quot;\n\t&quot;);
 1619     st-&gt;print(&quot;skip:\n\t&quot;);
 1620   }
 1621 }
 1622 #endif
 1623 
 1624 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1625   Compile* C = ra_-&gt;C;
 1626   C2_MacroAssembler _masm(&amp;cbuf);
 1627 
<a name="1" id="anc1"></a><span class="line-added"> 1628   __ verified_entry(C, 0);</span>
<span class="line-added"> 1629   __ bind(*_verified_entry);</span>
 1630   // n.b. frame size includes space for return pc and rfp
 1631   const long framesize = C-&gt;output()-&gt;frame_size_in_bytes();
 1632   assert(framesize%(2*wordSize) == 0, &quot;must preserve 2*wordSize alignment&quot;);
 1633 
 1634   // insert a nop at the start of the prolog so we can patch in a
 1635   // branch if we need to invalidate the method later
 1636   __ nop();
 1637 
 1638   if (C-&gt;clinit_barrier_on_entry()) {
 1639     assert(!C-&gt;method()-&gt;holder()-&gt;is_not_initialized(), &quot;initialization should have been started&quot;);
 1640 
 1641     Label L_skip_barrier;
 1642 
 1643     __ mov_metadata(rscratch2, C-&gt;method()-&gt;holder()-&gt;constant_encoding());
 1644     __ clinit_barrier(rscratch2, rscratch1, &amp;L_skip_barrier);
 1645     __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));
 1646     __ bind(L_skip_barrier);
 1647   }
 1648 
 1649   int bangsize = C-&gt;output()-&gt;bang_size_in_bytes();
 1650   if (C-&gt;output()-&gt;need_stack_bang(bangsize) &amp;&amp; UseStackBanging)
 1651     __ generate_stack_overflow_check(bangsize);
 1652 
 1653   __ build_frame(framesize);
 1654 
 1655   if (C-&gt;stub_function() == NULL) {
 1656     BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
 1657     bs-&gt;nmethod_entry_barrier(&amp;_masm);
 1658   }
 1659 
 1660   if (VerifyStackAtCalls) {
 1661     Unimplemented();
 1662   }
 1663 
 1664   C-&gt;output()-&gt;set_frame_complete(cbuf.insts_size());
 1665 
 1666   if (C-&gt;has_mach_constant_base_node()) {
 1667     // NOTE: We set the table base offset here because users might be
 1668     // emitted before MachConstantBaseNode.
 1669     ConstantTable&amp; constant_table = C-&gt;output()-&gt;constant_table();
 1670     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
 1671   }
 1672 }
 1673 
 1674 uint MachPrologNode::size(PhaseRegAlloc* ra_) const
 1675 {
 1676   return MachNode::size(ra_); // too many variables; just compute it
 1677                               // the hard way
 1678 }
 1679 
 1680 int MachPrologNode::reloc() const
 1681 {
 1682   return 0;
 1683 }
 1684 
 1685 //=============================================================================
 1686 
 1687 #ifndef PRODUCT
 1688 void MachEpilogNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1689   Compile* C = ra_-&gt;C;
 1690   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1691 
 1692   st-&gt;print(&quot;# pop frame %d\n\t&quot;,framesize);
 1693 
 1694   if (framesize == 0) {
 1695     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1696   } else if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1697     st-&gt;print(&quot;ldp  lr, rfp, [sp,#%d]\n\t&quot;, framesize - 2 * wordSize);
 1698     st-&gt;print(&quot;add  sp, sp, #%d\n\t&quot;, framesize);
 1699   } else {
 1700     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1701     st-&gt;print(&quot;add  sp, sp, rscratch1\n\t&quot;);
 1702     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1703   }
 1704 
 1705   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1706     st-&gt;print(&quot;# touch polling page\n\t&quot;);
 1707     st-&gt;print(&quot;ldr rscratch1, [rthread],#polling_page_offset\n\t&quot;);
 1708     st-&gt;print(&quot;ldr zr, [rscratch1]&quot;);
 1709   }
 1710 }
 1711 #endif
 1712 
 1713 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1714   Compile* C = ra_-&gt;C;
 1715   C2_MacroAssembler _masm(&amp;cbuf);
 1716   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1717 
 1718   __ remove_frame(framesize);
 1719 
 1720   if (StackReservedPages &gt; 0 &amp;&amp; C-&gt;has_reserved_stack_access()) {
 1721     __ reserved_stack_check();
 1722   }
 1723 
 1724   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1725     __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);
 1726   }
 1727 }
 1728 
 1729 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
 1730   // Variable size. Determine dynamically.
 1731   return MachNode::size(ra_);
 1732 }
 1733 
 1734 int MachEpilogNode::reloc() const {
 1735   // Return number of relocatable values contained in this instruction.
 1736   return 1; // 1 for polling page.
 1737 }
 1738 
 1739 const Pipeline * MachEpilogNode::pipeline() const {
 1740   return MachNode::pipeline_class();
 1741 }
 1742 
 1743 //=============================================================================
 1744 
 1745 // Figure out which register class each belongs in: rc_int, rc_float or
 1746 // rc_stack.
 1747 enum RC { rc_bad, rc_int, rc_float, rc_stack };
 1748 
 1749 static enum RC rc_class(OptoReg::Name reg) {
 1750 
 1751   if (reg == OptoReg::Bad) {
 1752     return rc_bad;
 1753   }
 1754 
 1755   // we have 30 int registers * 2 halves
 1756   // (rscratch1 and rscratch2 are omitted)
 1757   int slots_of_int_registers = RegisterImpl::max_slots_per_register * (RegisterImpl::number_of_registers - 2);
 1758 
 1759   if (reg &lt; slots_of_int_registers) {
 1760     return rc_int;
 1761   }
 1762 
 1763   // we have 32 float register * 4 halves
 1764   if (reg &lt; slots_of_int_registers + FloatRegisterImpl::max_slots_per_register * FloatRegisterImpl::number_of_registers) {
 1765     return rc_float;
 1766   }
 1767 
 1768   // Between float regs &amp; stack is the flags regs.
 1769   assert(OptoReg::is_stack(reg), &quot;blow up if spilling flags&quot;);
 1770 
 1771   return rc_stack;
 1772 }
 1773 
 1774 uint MachSpillCopyNode::implementation(CodeBuffer *cbuf, PhaseRegAlloc *ra_, bool do_size, outputStream *st) const {
 1775   Compile* C = ra_-&gt;C;
 1776 
 1777   // Get registers to move.
 1778   OptoReg::Name src_hi = ra_-&gt;get_reg_second(in(1));
 1779   OptoReg::Name src_lo = ra_-&gt;get_reg_first(in(1));
 1780   OptoReg::Name dst_hi = ra_-&gt;get_reg_second(this);
 1781   OptoReg::Name dst_lo = ra_-&gt;get_reg_first(this);
 1782 
 1783   enum RC src_hi_rc = rc_class(src_hi);
 1784   enum RC src_lo_rc = rc_class(src_lo);
 1785   enum RC dst_hi_rc = rc_class(dst_hi);
 1786   enum RC dst_lo_rc = rc_class(dst_lo);
 1787 
 1788   assert(src_lo != OptoReg::Bad &amp;&amp; dst_lo != OptoReg::Bad, &quot;must move at least 1 register&quot;);
 1789 
 1790   if (src_hi != OptoReg::Bad) {
 1791     assert((src_lo&amp;1)==0 &amp;&amp; src_lo+1==src_hi &amp;&amp;
 1792            (dst_lo&amp;1)==0 &amp;&amp; dst_lo+1==dst_hi,
 1793            &quot;expected aligned-adjacent pairs&quot;);
 1794   }
 1795 
 1796   if (src_lo == dst_lo &amp;&amp; src_hi == dst_hi) {
 1797     return 0;            // Self copy, no move.
 1798   }
 1799 
 1800   bool is64 = (src_lo &amp; 1) == 0 &amp;&amp; src_lo + 1 == src_hi &amp;&amp;
 1801               (dst_lo &amp; 1) == 0 &amp;&amp; dst_lo + 1 == dst_hi;
 1802   int src_offset = ra_-&gt;reg2offset(src_lo);
 1803   int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1804 
 1805   if (bottom_type()-&gt;isa_vect() != NULL) {
 1806     uint ireg = ideal_reg();
 1807     assert(ireg == Op_VecD || ireg == Op_VecX, &quot;must be 64 bit or 128 bit vector&quot;);
 1808     if (cbuf) {
 1809       C2_MacroAssembler _masm(cbuf);
 1810       assert((src_lo_rc != rc_int &amp;&amp; dst_lo_rc != rc_int), &quot;sanity&quot;);
 1811       if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1812         // stack-&gt;stack
 1813         assert((src_offset &amp; 7) == 0 &amp;&amp; (dst_offset &amp; 7) == 0, &quot;unaligned stack offset&quot;);
 1814         if (ireg == Op_VecD) {
 1815           __ unspill(rscratch1, true, src_offset);
 1816           __ spill(rscratch1, true, dst_offset);
 1817         } else {
 1818           __ spill_copy128(src_offset, dst_offset);
 1819         }
 1820       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_float) {
 1821         __ mov(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1822                ireg == Op_VecD ? __ T8B : __ T16B,
 1823                as_FloatRegister(Matcher::_regEncode[src_lo]));
 1824       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_stack) {
 1825         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1826                        ireg == Op_VecD ? __ D : __ Q,
 1827                        ra_-&gt;reg2offset(dst_lo));
 1828       } else if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_float) {
 1829         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1830                        ireg == Op_VecD ? __ D : __ Q,
 1831                        ra_-&gt;reg2offset(src_lo));
 1832       } else {
 1833         ShouldNotReachHere();
 1834       }
 1835     }
 1836   } else if (cbuf) {
 1837     C2_MacroAssembler _masm(cbuf);
 1838     switch (src_lo_rc) {
 1839     case rc_int:
 1840       if (dst_lo_rc == rc_int) {  // gpr --&gt; gpr copy
 1841         if (is64) {
 1842             __ mov(as_Register(Matcher::_regEncode[dst_lo]),
 1843                    as_Register(Matcher::_regEncode[src_lo]));
 1844         } else {
 1845             C2_MacroAssembler _masm(cbuf);
 1846             __ movw(as_Register(Matcher::_regEncode[dst_lo]),
 1847                     as_Register(Matcher::_regEncode[src_lo]));
 1848         }
 1849       } else if (dst_lo_rc == rc_float) { // gpr --&gt; fpr copy
 1850         if (is64) {
 1851             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1852                      as_Register(Matcher::_regEncode[src_lo]));
 1853         } else {
 1854             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1855                      as_Register(Matcher::_regEncode[src_lo]));
 1856         }
 1857       } else {                    // gpr --&gt; stack spill
 1858         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1859         __ spill(as_Register(Matcher::_regEncode[src_lo]), is64, dst_offset);
 1860       }
 1861       break;
 1862     case rc_float:
 1863       if (dst_lo_rc == rc_int) {  // fpr --&gt; gpr copy
 1864         if (is64) {
 1865             __ fmovd(as_Register(Matcher::_regEncode[dst_lo]),
 1866                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1867         } else {
 1868             __ fmovs(as_Register(Matcher::_regEncode[dst_lo]),
 1869                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1870         }
 1871       } else if (dst_lo_rc == rc_float) { // fpr --&gt; fpr copy
 1872           if (cbuf) {
 1873             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1874                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1875         } else {
 1876             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1877                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1878         }
 1879       } else {                    // fpr --&gt; stack spill
 1880         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1881         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1882                  is64 ? __ D : __ S, dst_offset);
 1883       }
 1884       break;
 1885     case rc_stack:
 1886       if (dst_lo_rc == rc_int) {  // stack --&gt; gpr load
 1887         __ unspill(as_Register(Matcher::_regEncode[dst_lo]), is64, src_offset);
 1888       } else if (dst_lo_rc == rc_float) { // stack --&gt; fpr load
 1889         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1890                    is64 ? __ D : __ S, src_offset);
 1891       } else {                    // stack --&gt; stack copy
 1892         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1893         __ unspill(rscratch1, is64, src_offset);
 1894         __ spill(rscratch1, is64, dst_offset);
 1895       }
 1896       break;
 1897     default:
 1898       assert(false, &quot;bad rc_class for spill&quot;);
 1899       ShouldNotReachHere();
 1900     }
 1901   }
 1902 
 1903   if (st) {
 1904     st-&gt;print(&quot;spill &quot;);
 1905     if (src_lo_rc == rc_stack) {
 1906       st-&gt;print(&quot;[sp, #%d] -&gt; &quot;, ra_-&gt;reg2offset(src_lo));
 1907     } else {
 1908       st-&gt;print(&quot;%s -&gt; &quot;, Matcher::regName[src_lo]);
 1909     }
 1910     if (dst_lo_rc == rc_stack) {
 1911       st-&gt;print(&quot;[sp, #%d]&quot;, ra_-&gt;reg2offset(dst_lo));
 1912     } else {
 1913       st-&gt;print(&quot;%s&quot;, Matcher::regName[dst_lo]);
 1914     }
 1915     if (bottom_type()-&gt;isa_vect() != NULL) {
 1916       st-&gt;print(&quot;\t# vector spill size = %d&quot;, ideal_reg()==Op_VecD ? 64:128);
 1917     } else {
 1918       st-&gt;print(&quot;\t# spill size = %d&quot;, is64 ? 64:32);
 1919     }
 1920   }
 1921 
 1922   return 0;
 1923 
 1924 }
 1925 
 1926 #ifndef PRODUCT
 1927 void MachSpillCopyNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1928   if (!ra_)
 1929     st-&gt;print(&quot;N%d = SpillCopy(N%d)&quot;, _idx, in(1)-&gt;_idx);
 1930   else
 1931     implementation(NULL, ra_, false, st);
 1932 }
 1933 #endif
 1934 
 1935 void MachSpillCopyNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1936   implementation(&amp;cbuf, ra_, false, NULL);
 1937 }
 1938 
 1939 uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
 1940   return MachNode::size(ra_);
 1941 }
 1942 
 1943 //=============================================================================
 1944 
 1945 #ifndef PRODUCT
 1946 void BoxLockNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1947   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1948   int reg = ra_-&gt;get_reg_first(this);
 1949   st-&gt;print(&quot;add %s, rsp, #%d]\t# box lock&quot;,
 1950             Matcher::regName[reg], offset);
 1951 }
 1952 #endif
 1953 
 1954 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1955   C2_MacroAssembler _masm(&amp;cbuf);
 1956 
 1957   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1958   int reg    = ra_-&gt;get_encode(this);
 1959 
 1960   // This add will handle any 24-bit signed offset. 24 bits allows an
 1961   // 8 megabyte stack frame.
 1962   __ add(as_Register(reg), sp, offset);
 1963 }
 1964 
 1965 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 1966   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_).
 1967   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1968 
 1969   if (Assembler::operand_valid_for_add_sub_immediate(offset)) {
 1970     return NativeInstruction::instruction_size;
 1971   } else {
 1972     return 2 * NativeInstruction::instruction_size;
 1973   }
 1974 }
 1975 
<a name="2" id="anc2"></a><span class="line-modified"> 1976 ///=============================================================================</span>
<span class="line-added"> 1977 #ifndef PRODUCT</span>
<span class="line-added"> 1978 void MachVEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const</span>
<span class="line-added"> 1979 {</span>
<span class="line-added"> 1980   st-&gt;print_cr(&quot;# MachVEPNode&quot;);</span>
<span class="line-added"> 1981   if (!_verified) {</span>
<span class="line-added"> 1982     st-&gt;print_cr(&quot;\t load_class&quot;);</span>
<span class="line-added"> 1983   } else {</span>
<span class="line-added"> 1984     st-&gt;print_cr(&quot;\t unpack_inline_arg&quot;);</span>
<span class="line-added"> 1985   }</span>
<span class="line-added"> 1986 }</span>
<span class="line-added"> 1987 #endif</span>
<span class="line-added"> 1988 </span>
<span class="line-added"> 1989 void MachVEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const</span>
<span class="line-added"> 1990 {</span>
<span class="line-added"> 1991   MacroAssembler _masm(&amp;cbuf);</span>
<span class="line-added"> 1992 </span>
<span class="line-added"> 1993   if (!_verified) {</span>
<span class="line-added"> 1994     Label skip;</span>
<span class="line-added"> 1995     __ cmp_klass(j_rarg0, rscratch2, rscratch1);</span>
<span class="line-added"> 1996     __ br(Assembler::EQ, skip);</span>
<span class="line-added"> 1997       __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));</span>
<span class="line-added"> 1998     __ bind(skip);</span>
<span class="line-added"> 1999 </span>
<span class="line-added"> 2000   } else {</span>
<span class="line-added"> 2001     // Unpack inline type args passed as oop and then jump to</span>
<span class="line-added"> 2002     // the verified entry point (skipping the unverified entry).</span>
<span class="line-added"> 2003     __ unpack_inline_args(ra_-&gt;C, _receiver_only);</span>
<span class="line-added"> 2004     __ b(*_verified_entry);</span>
<span class="line-added"> 2005   }</span>
<span class="line-added"> 2006 }</span>
 2007 
<a name="3" id="anc3"></a><span class="line-added"> 2008 </span>
<span class="line-added"> 2009 uint MachVEPNode::size(PhaseRegAlloc* ra_) const</span>
<span class="line-added"> 2010 {</span>
<span class="line-added"> 2011   return MachNode::size(ra_); // too many variables; just compute it the hard way</span>
<span class="line-added"> 2012 }</span>
<span class="line-added"> 2013 </span>
<span class="line-added"> 2014 </span>
<span class="line-added"> 2015 //=============================================================================</span>
 2016 #ifndef PRODUCT
 2017 void MachUEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 2018 {
 2019   st-&gt;print_cr(&quot;# MachUEPNode&quot;);
 2020   if (UseCompressedClassPointers) {
 2021     st-&gt;print_cr(&quot;\tldrw rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 2022     if (CompressedKlassPointers::shift() != 0) {
 2023       st-&gt;print_cr(&quot;\tdecode_klass_not_null rscratch1, rscratch1&quot;);
 2024     }
 2025   } else {
 2026    st-&gt;print_cr(&quot;\tldr rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 2027   }
 2028   st-&gt;print_cr(&quot;\tcmp r0, rscratch1\t # Inline cache check&quot;);
 2029   st-&gt;print_cr(&quot;\tbne, SharedRuntime::_ic_miss_stub&quot;);
 2030 }
 2031 #endif
 2032 
 2033 void MachUEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 2034 {
 2035   // This is the unverified entry point.
 2036   C2_MacroAssembler _masm(&amp;cbuf);
<a name="4" id="anc4"></a><span class="line-added"> 2037   Label skip;</span>
 2038 
<a name="5" id="anc5"></a><span class="line-added"> 2039   // UseCompressedClassPointers logic are inside cmp_klass</span>
 2040   __ cmp_klass(j_rarg0, rscratch2, rscratch1);
<a name="6" id="anc6"></a><span class="line-modified"> 2041 </span>
 2042   // TODO
 2043   // can we avoid this skip and still use a reloc?
 2044   __ br(Assembler::EQ, skip);
 2045   __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 2046   __ bind(skip);
 2047 }
 2048 
 2049 uint MachUEPNode::size(PhaseRegAlloc* ra_) const
 2050 {
 2051   return MachNode::size(ra_);
 2052 }
 2053 
 2054 // REQUIRED EMIT CODE
 2055 
 2056 //=============================================================================
 2057 
 2058 // Emit exception handler code.
 2059 int HandlerImpl::emit_exception_handler(CodeBuffer&amp; cbuf)
 2060 {
 2061   // mov rscratch1 #exception_blob_entry_point
 2062   // br rscratch1
 2063   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2064   // That&#39;s why we must use the macroassembler to generate a handler.
 2065   C2_MacroAssembler _masm(&amp;cbuf);
 2066   address base = __ start_a_stub(size_exception_handler());
 2067   if (base == NULL) {
 2068     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2069     return 0;  // CodeBuffer::expand failed
 2070   }
 2071   int offset = __ offset();
 2072   __ far_jump(RuntimeAddress(OptoRuntime::exception_blob()-&gt;entry_point()));
 2073   assert(__ offset() - offset &lt;= (int) size_exception_handler(), &quot;overflow&quot;);
 2074   __ end_a_stub();
 2075   return offset;
 2076 }
 2077 
 2078 // Emit deopt handler code.
 2079 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf)
 2080 {
 2081   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2082   // That&#39;s why we must use the macroassembler to generate a handler.
 2083   C2_MacroAssembler _masm(&amp;cbuf);
 2084   address base = __ start_a_stub(size_deopt_handler());
 2085   if (base == NULL) {
 2086     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2087     return 0;  // CodeBuffer::expand failed
 2088   }
 2089   int offset = __ offset();
 2090 
 2091   __ adr(lr, __ pc());
 2092   __ far_jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 2093 
 2094   assert(__ offset() - offset &lt;= (int) size_deopt_handler(), &quot;overflow&quot;);
 2095   __ end_a_stub();
 2096   return offset;
 2097 }
 2098 
 2099 // REQUIRED MATCHER CODE
 2100 
 2101 //=============================================================================
 2102 
 2103 const bool Matcher::match_rule_supported(int opcode) {
 2104   if (!has_match_rule(opcode))
 2105     return false;
 2106 
 2107   bool ret_value = true;
 2108   switch (opcode) {
 2109     case Op_CacheWB:
 2110     case Op_CacheWBPreSync:
 2111     case Op_CacheWBPostSync:
 2112       if (!VM_Version::supports_data_cache_line_flush()) {
 2113         ret_value = false;
 2114       }
 2115       break;
 2116   }
 2117 
 2118   return ret_value; // Per default match rules are supported.
 2119 }
 2120 
 2121 // Identify extra cases that we might want to provide match rules for vector nodes and
 2122 // other intrinsics guarded with vector length (vlen) and element type (bt).
 2123 const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {
 2124   if (!match_rule_supported(opcode)) {
 2125     return false;
 2126   }
 2127 
 2128   // Special cases which require vector length
 2129   switch (opcode) {
 2130     case Op_MulAddVS2VI: {
 2131       if (vlen != 4) {
 2132         return false;
 2133       }
 2134       break;
 2135     }
 2136   }
 2137 
 2138   return true; // Per default match rules are supported.
 2139 }
 2140 
 2141 const bool Matcher::has_predicated_vectors(void) {
 2142   return false;
 2143 }
 2144 
 2145 const int Matcher::float_pressure(int default_pressure_threshold) {
 2146   return default_pressure_threshold;
 2147 }
 2148 
 2149 int Matcher::regnum_to_fpu_offset(int regnum)
 2150 {
 2151   Unimplemented();
 2152   return 0;
 2153 }
 2154 
 2155 // Is this branch offset short enough that a short branch can be used?
 2156 //
 2157 // NOTE: If the platform does not provide any short branch variants, then
 2158 //       this method should return false for offset 0.
 2159 bool Matcher::is_short_branch_offset(int rule, int br_size, int offset) {
 2160   // The passed offset is relative to address of the branch.
 2161 
 2162   return (-32768 &lt;= offset &amp;&amp; offset &lt; 32768);
 2163 }
 2164 
 2165 const bool Matcher::isSimpleConstant64(jlong value) {
 2166   // Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.
 2167   // Probably always true, even if a temp register is required.
 2168   return true;
 2169 }
 2170 
 2171 // true just means we have fast l2f conversion
 2172 const bool Matcher::convL2FSupported(void) {
 2173   return true;
 2174 }
 2175 
 2176 // Vector width in bytes.
 2177 const int Matcher::vector_width_in_bytes(BasicType bt) {
 2178   int size = MIN2(16,(int)MaxVectorSize);
 2179   // Minimum 2 values in vector
 2180   if (size &lt; 2*type2aelembytes(bt)) size = 0;
 2181   // But never &lt; 4
 2182   if (size &lt; 4) size = 0;
 2183   return size;
 2184 }
 2185 
 2186 // Limits on vector size (number of elements) loaded into vector.
 2187 const int Matcher::max_vector_size(const BasicType bt) {
 2188   return vector_width_in_bytes(bt)/type2aelembytes(bt);
 2189 }
 2190 const int Matcher::min_vector_size(const BasicType bt) {
 2191 //  For the moment limit the vector size to 8 bytes
 2192     int size = 8 / type2aelembytes(bt);
 2193     if (size &lt; 2) size = 2;
 2194     return size;
 2195 }
 2196 
 2197 // Vector ideal reg.
 2198 const uint Matcher::vector_ideal_reg(int len) {
 2199   switch(len) {
 2200     case  8: return Op_VecD;
 2201     case 16: return Op_VecX;
 2202   }
 2203   ShouldNotReachHere();
 2204   return 0;
 2205 }
 2206 
 2207 // AES support not yet implemented
 2208 const bool Matcher::pass_original_key_for_aes() {
 2209   return false;
 2210 }
 2211 
 2212 // aarch64 supports misaligned vectors store/load.
 2213 const bool Matcher::misaligned_vectors_ok() {
 2214   return true;
 2215 }
 2216 
 2217 // false =&gt; size gets scaled to BytesPerLong, ok.
 2218 const bool Matcher::init_array_count_is_in_bytes = false;
 2219 
 2220 // Use conditional move (CMOVL)
 2221 const int Matcher::long_cmove_cost() {
 2222   // long cmoves are no more expensive than int cmoves
 2223   return 0;
 2224 }
 2225 
 2226 const int Matcher::float_cmove_cost() {
 2227   // float cmoves are no more expensive than int cmoves
 2228   return 0;
 2229 }
 2230 
 2231 // Does the CPU require late expand (see block.cpp for description of late expand)?
 2232 const bool Matcher::require_postalloc_expand = false;
 2233 
 2234 // Do we need to mask the count passed to shift instructions or does
 2235 // the cpu only look at the lower 5/6 bits anyway?
 2236 const bool Matcher::need_masked_shift_count = false;
 2237 
 2238 // No support for generic vector operands.
 2239 const bool Matcher::supports_generic_vector_operands  = false;
 2240 
 2241 MachOper* Matcher::pd_specialize_generic_vector_operand(MachOper* original_opnd, uint ideal_reg, bool is_temp) {
 2242   ShouldNotReachHere(); // generic vector operands not supported
 2243   return NULL;
 2244 }
 2245 
 2246 bool Matcher::is_generic_reg2reg_move(MachNode* m) {
 2247   ShouldNotReachHere();  // generic vector operands not supported
 2248   return false;
 2249 }
 2250 
 2251 bool Matcher::is_generic_vector(MachOper* opnd)  {
 2252   ShouldNotReachHere();  // generic vector operands not supported
 2253   return false;
 2254 }
 2255 
 2256 // This affects two different things:
 2257 //  - how Decode nodes are matched
 2258 //  - how ImplicitNullCheck opportunities are recognized
 2259 // If true, the matcher will try to remove all Decodes and match them
 2260 // (as operands) into nodes. NullChecks are not prepared to deal with
 2261 // Decodes by final_graph_reshaping().
 2262 // If false, final_graph_reshaping() forces the decode behind the Cmp
 2263 // for a NullCheck. The matcher matches the Decode node into a register.
 2264 // Implicit_null_check optimization moves the Decode along with the
 2265 // memory operation back up before the NullCheck.
 2266 bool Matcher::narrow_oop_use_complex_address() {
 2267   return CompressedOops::shift() == 0;
 2268 }
 2269 
 2270 bool Matcher::narrow_klass_use_complex_address() {
 2271 // TODO
 2272 // decide whether we need to set this to true
 2273   return false;
 2274 }
 2275 
 2276 bool Matcher::const_oop_prefer_decode() {
 2277   // Prefer ConN+DecodeN over ConP in simple compressed oops mode.
 2278   return CompressedOops::base() == NULL;
 2279 }
 2280 
 2281 bool Matcher::const_klass_prefer_decode() {
 2282   // Prefer ConNKlass+DecodeNKlass over ConP in simple compressed klass mode.
 2283   return CompressedKlassPointers::base() == NULL;
 2284 }
 2285 
 2286 // Is it better to copy float constants, or load them directly from
 2287 // memory?  Intel can load a float constant from a direct address,
 2288 // requiring no extra registers.  Most RISCs will have to materialize
 2289 // an address into a register first, so they would do better to copy
 2290 // the constant from stack.
 2291 const bool Matcher::rematerialize_float_constants = false;
 2292 
 2293 // If CPU can load and store mis-aligned doubles directly then no
 2294 // fixup is needed.  Else we split the double into 2 integer pieces
 2295 // and move it piece-by-piece.  Only happens when passing doubles into
 2296 // C code as the Java calling convention forces doubles to be aligned.
 2297 const bool Matcher::misaligned_doubles_ok = true;
 2298 
 2299 // No-op on amd64
 2300 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 2301   Unimplemented();
 2302 }
 2303 
 2304 // Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.
 2305 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 2306 
 2307 // Are floats converted to double when stored to stack during
 2308 // deoptimization?
 2309 bool Matcher::float_in_double() { return false; }
 2310 
 2311 // Do ints take an entire long register or just half?
 2312 // The relevant question is how the int is callee-saved:
 2313 // the whole long is written but de-opt&#39;ing will have to extract
 2314 // the relevant 32 bits.
 2315 const bool Matcher::int_in_long = true;
 2316 
 2317 // Return whether or not this register is ever used as an argument.
 2318 // This function is used on startup to build the trampoline stubs in
 2319 // generateOptoStub.  Registers not mentioned will be killed by the VM
 2320 // call in the trampoline, and arguments in those registers not be
 2321 // available to the callee.
 2322 bool Matcher::can_be_java_arg(int reg)
 2323 {
 2324   return
 2325     reg ==  R0_num || reg == R0_H_num ||
 2326     reg ==  R1_num || reg == R1_H_num ||
 2327     reg ==  R2_num || reg == R2_H_num ||
 2328     reg ==  R3_num || reg == R3_H_num ||
 2329     reg ==  R4_num || reg == R4_H_num ||
 2330     reg ==  R5_num || reg == R5_H_num ||
 2331     reg ==  R6_num || reg == R6_H_num ||
 2332     reg ==  R7_num || reg == R7_H_num ||
 2333     reg ==  V0_num || reg == V0_H_num ||
 2334     reg ==  V1_num || reg == V1_H_num ||
 2335     reg ==  V2_num || reg == V2_H_num ||
 2336     reg ==  V3_num || reg == V3_H_num ||
 2337     reg ==  V4_num || reg == V4_H_num ||
 2338     reg ==  V5_num || reg == V5_H_num ||
 2339     reg ==  V6_num || reg == V6_H_num ||
 2340     reg ==  V7_num || reg == V7_H_num;
 2341 }
 2342 
 2343 bool Matcher::is_spillable_arg(int reg)
 2344 {
 2345   return can_be_java_arg(reg);
 2346 }
 2347 
 2348 bool Matcher::use_asm_for_ldiv_by_con(jlong divisor) {
 2349   return false;
 2350 }
 2351 
 2352 RegMask Matcher::divI_proj_mask() {
 2353   ShouldNotReachHere();
 2354   return RegMask();
 2355 }
 2356 
 2357 // Register for MODI projection of divmodI.
 2358 RegMask Matcher::modI_proj_mask() {
 2359   ShouldNotReachHere();
 2360   return RegMask();
 2361 }
 2362 
 2363 // Register for DIVL projection of divmodL.
 2364 RegMask Matcher::divL_proj_mask() {
 2365   ShouldNotReachHere();
 2366   return RegMask();
 2367 }
 2368 
 2369 // Register for MODL projection of divmodL.
 2370 RegMask Matcher::modL_proj_mask() {
 2371   ShouldNotReachHere();
 2372   return RegMask();
 2373 }
 2374 
 2375 const RegMask Matcher::method_handle_invoke_SP_save_mask() {
 2376   return FP_REG_mask();
 2377 }
 2378 
 2379 bool size_fits_all_mem_uses(AddPNode* addp, int shift) {
 2380   for (DUIterator_Fast imax, i = addp-&gt;fast_outs(imax); i &lt; imax; i++) {
 2381     Node* u = addp-&gt;fast_out(i);
 2382     if (u-&gt;is_Mem()) {
 2383       int opsize = u-&gt;as_Mem()-&gt;memory_size();
 2384       assert(opsize &gt; 0, &quot;unexpected memory operand size&quot;);
 2385       if (u-&gt;as_Mem()-&gt;memory_size() != (1&lt;&lt;shift)) {
 2386         return false;
 2387       }
 2388     }
 2389   }
 2390   return true;
 2391 }
 2392 
 2393 const bool Matcher::convi2l_type_required = false;
 2394 
 2395 // Should the matcher clone input &#39;m&#39; of node &#39;n&#39;?
 2396 bool Matcher::pd_clone_node(Node* n, Node* m, Matcher::MStack&amp; mstack) {
 2397   if (is_vshift_con_pattern(n, m)) { // ShiftV src (ShiftCntV con)
 2398     mstack.push(m, Visit);           // m = ShiftCntV
 2399     return true;
 2400   }
 2401   return false;
 2402 }
 2403 
 2404 // Should the Matcher clone shifts on addressing modes, expecting them
 2405 // to be subsumed into complex addressing expressions or compute them
 2406 // into registers?
 2407 bool Matcher::pd_clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
 2408   if (clone_base_plus_offset_address(m, mstack, address_visited)) {
 2409     return true;
 2410   }
 2411 
 2412   Node *off = m-&gt;in(AddPNode::Offset);
 2413   if (off-&gt;Opcode() == Op_LShiftL &amp;&amp; off-&gt;in(2)-&gt;is_Con() &amp;&amp;
 2414       size_fits_all_mem_uses(m, off-&gt;in(2)-&gt;get_int()) &amp;&amp;
 2415       // Are there other uses besides address expressions?
 2416       !is_visited(off)) {
 2417     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2418     mstack.push(off-&gt;in(2), Visit);
 2419     Node *conv = off-&gt;in(1);
 2420     if (conv-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2421         // Are there other uses besides address expressions?
 2422         !is_visited(conv)) {
 2423       address_visited.set(conv-&gt;_idx); // Flag as address_visited
 2424       mstack.push(conv-&gt;in(1), Pre_Visit);
 2425     } else {
 2426       mstack.push(conv, Pre_Visit);
 2427     }
 2428     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2429     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2430     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2431     return true;
 2432   } else if (off-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2433              // Are there other uses besides address expressions?
 2434              !is_visited(off)) {
 2435     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2436     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2437     mstack.push(off-&gt;in(1), Pre_Visit);
 2438     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2439     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2440     return true;
 2441   }
 2442   return false;
 2443 }
 2444 
 2445 void Compile::reshape_address(AddPNode* addp) {
 2446 }
 2447 
<a name="7" id="anc7"></a>
 2448 #define MOV_VOLATILE(REG, BASE, INDEX, SCALE, DISP, SCRATCH, INSN)      \
 2449   C2_MacroAssembler _masm(&amp;cbuf);                                       \
 2450   {                                                                     \
 2451     guarantee(INDEX == -1, &quot;mode not permitted for volatile&quot;);          \
 2452     guarantee(DISP == 0, &quot;mode not permitted for volatile&quot;);            \
 2453     guarantee(SCALE == 0, &quot;mode not permitted for volatile&quot;);           \
 2454     __ INSN(REG, as_Register(BASE));                                    \
 2455   }
 2456 
 2457 
 2458 static Address mem2address(int opcode, Register base, int index, int size, int disp)
 2459   {
 2460     Address::extend scale;
 2461 
 2462     // Hooboy, this is fugly.  We need a way to communicate to the
 2463     // encoder that the index needs to be sign extended, so we have to
 2464     // enumerate all the cases.
 2465     switch (opcode) {
 2466     case INDINDEXSCALEDI2L:
 2467     case INDINDEXSCALEDI2LN:
 2468     case INDINDEXI2L:
 2469     case INDINDEXI2LN:
 2470       scale = Address::sxtw(size);
 2471       break;
 2472     default:
 2473       scale = Address::lsl(size);
 2474     }
 2475 
 2476     if (index == -1) {
 2477       return Address(base, disp);
 2478     } else {
 2479       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2480       return Address(base, as_Register(index), scale);
 2481     }
 2482   }
 2483 
 2484 
 2485 typedef void (MacroAssembler::* mem_insn)(Register Rt, const Address &amp;adr);
 2486 typedef void (MacroAssembler::* mem_insn2)(Register Rt, Register adr);
 2487 typedef void (MacroAssembler::* mem_float_insn)(FloatRegister Rt, const Address &amp;adr);
 2488 typedef void (MacroAssembler::* mem_vector_insn)(FloatRegister Rt,
 2489                                   MacroAssembler::SIMD_RegVariant T, const Address &amp;adr);
 2490 
 2491   // Used for all non-volatile memory accesses.  The use of
 2492   // $mem-&gt;opcode() to discover whether this pattern uses sign-extended
 2493   // offsets is something of a kludge.
 2494   static void loadStore(C2_MacroAssembler masm, mem_insn insn,
 2495                         Register reg, int opcode,
 2496                         Register base, int index, int scale, int disp,
 2497                         int size_in_memory)
 2498   {
 2499     Address addr = mem2address(opcode, base, index, scale, disp);
 2500     if (addr.getMode() == Address::base_plus_offset) {
 2501       /* If we get an out-of-range offset it is a bug in the compiler,
 2502          so we assert here. */
 2503       assert(Address::offset_ok_for_immed(addr.offset(), exact_log2(size_in_memory)),
 2504              &quot;c2 compiler bug&quot;);
 2505       /* Fix up any out-of-range offsets. */
 2506       assert_different_registers(rscratch1, base);
 2507       assert_different_registers(rscratch1, reg);
 2508       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2509     }
 2510     (masm.*insn)(reg, addr);
 2511   }
 2512 
 2513   static void loadStore(C2_MacroAssembler masm, mem_float_insn insn,
 2514                         FloatRegister reg, int opcode,
 2515                         Register base, int index, int size, int disp,
 2516                         int size_in_memory)
 2517   {
 2518     Address::extend scale;
 2519 
 2520     switch (opcode) {
 2521     case INDINDEXSCALEDI2L:
 2522     case INDINDEXSCALEDI2LN:
 2523       scale = Address::sxtw(size);
 2524       break;
 2525     default:
 2526       scale = Address::lsl(size);
 2527     }
 2528 
 2529     if (index == -1) {
 2530       /* If we get an out-of-range offset it is a bug in the compiler,
 2531          so we assert here. */
 2532       assert(Address::offset_ok_for_immed(disp, exact_log2(size_in_memory)), &quot;c2 compiler bug&quot;);
 2533       /* Fix up any out-of-range offsets. */
 2534       assert_different_registers(rscratch1, base);
 2535       Address addr = Address(base, disp);
 2536       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2537       (masm.*insn)(reg, addr);
 2538     } else {
 2539       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2540       (masm.*insn)(reg, Address(base, as_Register(index), scale));
 2541     }
 2542   }
 2543 
 2544   static void loadStore(C2_MacroAssembler masm, mem_vector_insn insn,
 2545                         FloatRegister reg, MacroAssembler::SIMD_RegVariant T,
 2546                         int opcode, Register base, int index, int size, int disp)
 2547   {
 2548     if (index == -1) {
 2549       (masm.*insn)(reg, T, Address(base, disp));
 2550     } else {
 2551       assert(disp == 0, &quot;unsupported address mode&quot;);
 2552       (masm.*insn)(reg, T, Address(base, as_Register(index), Address::lsl(size)));
 2553     }
 2554   }
 2555 
 2556 %}
 2557 
 2558 
 2559 
 2560 //----------ENCODING BLOCK-----------------------------------------------------
 2561 // This block specifies the encoding classes used by the compiler to
 2562 // output byte streams.  Encoding classes are parameterized macros
 2563 // used by Machine Instruction Nodes in order to generate the bit
 2564 // encoding of the instruction.  Operands specify their base encoding
 2565 // interface with the interface keyword.  There are currently
 2566 // supported four interfaces, REG_INTER, CONST_INTER, MEMORY_INTER, &amp;
 2567 // COND_INTER.  REG_INTER causes an operand to generate a function
 2568 // which returns its register number when queried.  CONST_INTER causes
 2569 // an operand to generate a function which returns the value of the
 2570 // constant when queried.  MEMORY_INTER causes an operand to generate
 2571 // four functions which return the Base Register, the Index Register,
 2572 // the Scale Value, and the Offset Value of the operand when queried.
 2573 // COND_INTER causes an operand to generate six functions which return
 2574 // the encoding code (ie - encoding bits for the instruction)
 2575 // associated with each basic boolean condition for a conditional
 2576 // instruction.
 2577 //
 2578 // Instructions specify two basic values for encoding.  Again, a
 2579 // function is available to check if the constant displacement is an
 2580 // oop. They use the ins_encode keyword to specify their encoding
 2581 // classes (which must be a sequence of enc_class names, and their
 2582 // parameters, specified in the encoding block), and they use the
 2583 // opcode keyword to specify, in order, their primary, secondary, and
 2584 // tertiary opcode.  Only the opcode sections which a particular
 2585 // instruction needs for encoding need to be specified.
 2586 encode %{
 2587   // Build emit functions for each basic byte or larger field in the
 2588   // intel encoding scheme (opcode, rm, sib, immediate), and call them
 2589   // from C++ code in the enc_class source block.  Emit functions will
 2590   // live in the main source block for now.  In future, we can
 2591   // generalize this by adding a syntax that specifies the sizes of
 2592   // fields in an order, so that the adlc can build the emit functions
 2593   // automagically
 2594 
 2595   // catch all for unimplemented encodings
 2596   enc_class enc_unimplemented %{
 2597     C2_MacroAssembler _masm(&amp;cbuf);
 2598     __ unimplemented(&quot;C2 catch all&quot;);
 2599   %}
 2600 
 2601   // BEGIN Non-volatile memory access
 2602 
 2603   // This encoding class is generated automatically from ad_encode.m4.
 2604   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2605   enc_class aarch64_enc_ldrsbw(iRegI dst, memory1 mem) %{
 2606     Register dst_reg = as_Register($dst$$reg);
 2607     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsbw, dst_reg, $mem-&gt;opcode(),
 2608                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2609   %}
 2610 
 2611   // This encoding class is generated automatically from ad_encode.m4.
 2612   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2613   enc_class aarch64_enc_ldrsb(iRegI dst, memory1 mem) %{
 2614     Register dst_reg = as_Register($dst$$reg);
 2615     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsb, dst_reg, $mem-&gt;opcode(),
 2616                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2617   %}
 2618 
 2619   // This encoding class is generated automatically from ad_encode.m4.
 2620   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2621   enc_class aarch64_enc_ldrb(iRegI dst, memory1 mem) %{
 2622     Register dst_reg = as_Register($dst$$reg);
 2623     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2624                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2625   %}
 2626 
 2627   // This encoding class is generated automatically from ad_encode.m4.
 2628   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2629   enc_class aarch64_enc_ldrb(iRegL dst, memory1 mem) %{
 2630     Register dst_reg = as_Register($dst$$reg);
 2631     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2632                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2633   %}
 2634 
 2635   // This encoding class is generated automatically from ad_encode.m4.
 2636   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2637   enc_class aarch64_enc_ldrshw(iRegI dst, memory2 mem) %{
 2638     Register dst_reg = as_Register($dst$$reg);
 2639     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrshw, dst_reg, $mem-&gt;opcode(),
 2640                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2641   %}
 2642 
 2643   // This encoding class is generated automatically from ad_encode.m4.
 2644   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2645   enc_class aarch64_enc_ldrsh(iRegI dst, memory2 mem) %{
 2646     Register dst_reg = as_Register($dst$$reg);
 2647     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsh, dst_reg, $mem-&gt;opcode(),
 2648                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2649   %}
 2650 
 2651   // This encoding class is generated automatically from ad_encode.m4.
 2652   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2653   enc_class aarch64_enc_ldrh(iRegI dst, memory2 mem) %{
 2654     Register dst_reg = as_Register($dst$$reg);
 2655     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2656                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2657   %}
 2658 
 2659   // This encoding class is generated automatically from ad_encode.m4.
 2660   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2661   enc_class aarch64_enc_ldrh(iRegL dst, memory2 mem) %{
 2662     Register dst_reg = as_Register($dst$$reg);
 2663     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2664                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2665   %}
 2666 
 2667   // This encoding class is generated automatically from ad_encode.m4.
 2668   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2669   enc_class aarch64_enc_ldrw(iRegI dst, memory4 mem) %{
 2670     Register dst_reg = as_Register($dst$$reg);
 2671     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2672                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2673   %}
 2674 
 2675   // This encoding class is generated automatically from ad_encode.m4.
 2676   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2677   enc_class aarch64_enc_ldrw(iRegL dst, memory4 mem) %{
 2678     Register dst_reg = as_Register($dst$$reg);
 2679     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2680                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2681   %}
 2682 
 2683   // This encoding class is generated automatically from ad_encode.m4.
 2684   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2685   enc_class aarch64_enc_ldrsw(iRegL dst, memory4 mem) %{
 2686     Register dst_reg = as_Register($dst$$reg);
 2687     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsw, dst_reg, $mem-&gt;opcode(),
 2688                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2689   %}
 2690 
 2691   // This encoding class is generated automatically from ad_encode.m4.
 2692   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2693   enc_class aarch64_enc_ldr(iRegL dst, memory8 mem) %{
 2694     Register dst_reg = as_Register($dst$$reg);
 2695     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, $mem-&gt;opcode(),
 2696                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2697   %}
 2698 
 2699   // This encoding class is generated automatically from ad_encode.m4.
 2700   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2701   enc_class aarch64_enc_ldrs(vRegF dst, memory4 mem) %{
 2702     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2703     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, dst_reg, $mem-&gt;opcode(),
 2704                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2705   %}
 2706 
 2707   // This encoding class is generated automatically from ad_encode.m4.
 2708   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2709   enc_class aarch64_enc_ldrd(vRegD dst, memory8 mem) %{
 2710     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2711     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, dst_reg, $mem-&gt;opcode(),
 2712                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2713   %}
 2714 
 2715   // This encoding class is generated automatically from ad_encode.m4.
 2716   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2717   enc_class aarch64_enc_strb(iRegI src, memory1 mem) %{
 2718     Register src_reg = as_Register($src$$reg);
 2719     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strb, src_reg, $mem-&gt;opcode(),
 2720                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2721   %}
 2722 
 2723   // This encoding class is generated automatically from ad_encode.m4.
 2724   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2725   enc_class aarch64_enc_strb0(memory1 mem) %{
 2726     C2_MacroAssembler _masm(&amp;cbuf);
 2727     loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2728                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2729   %}
 2730 
 2731   // This encoding class is generated automatically from ad_encode.m4.
 2732   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2733   enc_class aarch64_enc_strh(iRegI src, memory2 mem) %{
 2734     Register src_reg = as_Register($src$$reg);
 2735     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strh, src_reg, $mem-&gt;opcode(),
 2736                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2737   %}
 2738 
 2739   // This encoding class is generated automatically from ad_encode.m4.
 2740   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2741   enc_class aarch64_enc_strh0(memory2 mem) %{
 2742     C2_MacroAssembler _masm(&amp;cbuf);
 2743     loadStore(_masm, &amp;MacroAssembler::strh, zr, $mem-&gt;opcode(),
 2744                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2745   %}
 2746 
 2747   // This encoding class is generated automatically from ad_encode.m4.
 2748   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2749   enc_class aarch64_enc_strw(iRegI src, memory4 mem) %{
 2750     Register src_reg = as_Register($src$$reg);
 2751     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strw, src_reg, $mem-&gt;opcode(),
 2752                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2753   %}
 2754 
 2755   // This encoding class is generated automatically from ad_encode.m4.
 2756   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2757   enc_class aarch64_enc_strw0(memory4 mem) %{
 2758     C2_MacroAssembler _masm(&amp;cbuf);
 2759     loadStore(_masm, &amp;MacroAssembler::strw, zr, $mem-&gt;opcode(),
 2760                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2761   %}
 2762 
 2763   // This encoding class is generated automatically from ad_encode.m4.
 2764   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2765   enc_class aarch64_enc_str(iRegL src, memory8 mem) %{
 2766     Register src_reg = as_Register($src$$reg);
 2767     // we sometimes get asked to store the stack pointer into the
 2768     // current thread -- we cannot do that directly on AArch64
 2769     if (src_reg == r31_sp) {
 2770       C2_MacroAssembler _masm(&amp;cbuf);
 2771       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2772       __ mov(rscratch2, sp);
 2773       src_reg = rscratch2;
 2774     }
 2775     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, $mem-&gt;opcode(),
 2776                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2777   %}
 2778 
 2779   // This encoding class is generated automatically from ad_encode.m4.
 2780   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2781   enc_class aarch64_enc_str0(memory8 mem) %{
 2782     C2_MacroAssembler _masm(&amp;cbuf);
 2783     loadStore(_masm, &amp;MacroAssembler::str, zr, $mem-&gt;opcode(),
 2784                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2785   %}
 2786 
 2787   // This encoding class is generated automatically from ad_encode.m4.
 2788   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2789   enc_class aarch64_enc_strs(vRegF src, memory4 mem) %{
 2790     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2791     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strs, src_reg, $mem-&gt;opcode(),
 2792                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2793   %}
 2794 
 2795   // This encoding class is generated automatically from ad_encode.m4.
 2796   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2797   enc_class aarch64_enc_strd(vRegD src, memory8 mem) %{
 2798     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2799     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strd, src_reg, $mem-&gt;opcode(),
 2800                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2801   %}
 2802 
 2803   // This encoding class is generated automatically from ad_encode.m4.
 2804   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2805   enc_class aarch64_enc_strw_immn(immN src, memory1 mem) %{
 2806     C2_MacroAssembler _masm(&amp;cbuf);
 2807     address con = (address)$src$$constant;
 2808     // need to do this the hard way until we can manage relocs
 2809     // for 32 bit constants
 2810     __ movoop(rscratch2, (jobject)con);
 2811     if (con) __ encode_heap_oop_not_null(rscratch2);
 2812     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2813                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2814   %}
 2815 
 2816   // This encoding class is generated automatically from ad_encode.m4.
 2817   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2818   enc_class aarch64_enc_strw_immnk(immN src, memory4 mem) %{
 2819     C2_MacroAssembler _masm(&amp;cbuf);
 2820     address con = (address)$src$$constant;
 2821     // need to do this the hard way until we can manage relocs
 2822     // for 32 bit constants
 2823     __ movoop(rscratch2, (jobject)con);
 2824     __ encode_klass_not_null(rscratch2);
 2825     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2826                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2827   %}
 2828 
 2829   // This encoding class is generated automatically from ad_encode.m4.
 2830   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2831   enc_class aarch64_enc_strb0_ordered(memory4 mem) %{
 2832       C2_MacroAssembler _masm(&amp;cbuf);
 2833       __ membar(Assembler::StoreStore);
 2834       loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2835                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2836   %}
 2837 
 2838   // END Non-volatile memory access
 2839 
 2840   // Vector loads and stores
 2841   enc_class aarch64_enc_ldrvS(vecD dst, memory mem) %{
 2842     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2843     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::S,
 2844        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2845   %}
 2846 
 2847   enc_class aarch64_enc_ldrvD(vecD dst, memory mem) %{
 2848     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2849     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::D,
 2850        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2851   %}
 2852 
 2853   enc_class aarch64_enc_ldrvQ(vecX dst, memory mem) %{
 2854     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2855     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::Q,
 2856        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2857   %}
 2858 
 2859   enc_class aarch64_enc_strvS(vecD src, memory mem) %{
 2860     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2861     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::S,
 2862        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2863   %}
 2864 
 2865   enc_class aarch64_enc_strvD(vecD src, memory mem) %{
 2866     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2867     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::D,
 2868        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2869   %}
 2870 
 2871   enc_class aarch64_enc_strvQ(vecX src, memory mem) %{
 2872     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2873     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::Q,
 2874        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2875   %}
 2876 
 2877   // volatile loads and stores
 2878 
 2879   enc_class aarch64_enc_stlrb(iRegI src, memory mem) %{
 2880     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2881                  rscratch1, stlrb);
 2882   %}
 2883 
 2884   enc_class aarch64_enc_stlrh(iRegI src, memory mem) %{
 2885     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2886                  rscratch1, stlrh);
 2887   %}
 2888 
 2889   enc_class aarch64_enc_stlrw(iRegI src, memory mem) %{
 2890     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2891                  rscratch1, stlrw);
 2892   %}
 2893 
 2894 
 2895   enc_class aarch64_enc_ldarsbw(iRegI dst, memory mem) %{
 2896     Register dst_reg = as_Register($dst$$reg);
 2897     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2898              rscratch1, ldarb);
 2899     __ sxtbw(dst_reg, dst_reg);
 2900   %}
 2901 
 2902   enc_class aarch64_enc_ldarsb(iRegL dst, memory mem) %{
 2903     Register dst_reg = as_Register($dst$$reg);
 2904     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2905              rscratch1, ldarb);
 2906     __ sxtb(dst_reg, dst_reg);
 2907   %}
 2908 
 2909   enc_class aarch64_enc_ldarbw(iRegI dst, memory mem) %{
 2910     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2911              rscratch1, ldarb);
 2912   %}
 2913 
 2914   enc_class aarch64_enc_ldarb(iRegL dst, memory mem) %{
 2915     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2916              rscratch1, ldarb);
 2917   %}
 2918 
 2919   enc_class aarch64_enc_ldarshw(iRegI dst, memory mem) %{
 2920     Register dst_reg = as_Register($dst$$reg);
 2921     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2922              rscratch1, ldarh);
 2923     __ sxthw(dst_reg, dst_reg);
 2924   %}
 2925 
 2926   enc_class aarch64_enc_ldarsh(iRegL dst, memory mem) %{
 2927     Register dst_reg = as_Register($dst$$reg);
 2928     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2929              rscratch1, ldarh);
 2930     __ sxth(dst_reg, dst_reg);
 2931   %}
 2932 
 2933   enc_class aarch64_enc_ldarhw(iRegI dst, memory mem) %{
 2934     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2935              rscratch1, ldarh);
 2936   %}
 2937 
 2938   enc_class aarch64_enc_ldarh(iRegL dst, memory mem) %{
 2939     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2940              rscratch1, ldarh);
 2941   %}
 2942 
 2943   enc_class aarch64_enc_ldarw(iRegI dst, memory mem) %{
 2944     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2945              rscratch1, ldarw);
 2946   %}
 2947 
 2948   enc_class aarch64_enc_ldarw(iRegL dst, memory mem) %{
 2949     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2950              rscratch1, ldarw);
 2951   %}
 2952 
 2953   enc_class aarch64_enc_ldar(iRegL dst, memory mem) %{
 2954     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2955              rscratch1, ldar);
 2956   %}
 2957 
 2958   enc_class aarch64_enc_fldars(vRegF dst, memory mem) %{
 2959     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2960              rscratch1, ldarw);
 2961     __ fmovs(as_FloatRegister($dst$$reg), rscratch1);
 2962   %}
 2963 
 2964   enc_class aarch64_enc_fldard(vRegD dst, memory mem) %{
 2965     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2966              rscratch1, ldar);
 2967     __ fmovd(as_FloatRegister($dst$$reg), rscratch1);
 2968   %}
 2969 
 2970   enc_class aarch64_enc_stlr(iRegL src, memory mem) %{
 2971     Register src_reg = as_Register($src$$reg);
 2972     // we sometimes get asked to store the stack pointer into the
 2973     // current thread -- we cannot do that directly on AArch64
 2974     if (src_reg == r31_sp) {
 2975       C2_MacroAssembler _masm(&amp;cbuf);
 2976       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2977       __ mov(rscratch2, sp);
 2978       src_reg = rscratch2;
 2979     }
 2980     MOV_VOLATILE(src_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2981                  rscratch1, stlr);
 2982   %}
 2983 
 2984   enc_class aarch64_enc_fstlrs(vRegF src, memory mem) %{
 2985     {
 2986       C2_MacroAssembler _masm(&amp;cbuf);
 2987       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2988       __ fmovs(rscratch2, src_reg);
 2989     }
 2990     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2991                  rscratch1, stlrw);
 2992   %}
 2993 
 2994   enc_class aarch64_enc_fstlrd(vRegD src, memory mem) %{
 2995     {
 2996       C2_MacroAssembler _masm(&amp;cbuf);
 2997       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2998       __ fmovd(rscratch2, src_reg);
 2999     }
 3000     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 3001                  rscratch1, stlr);
 3002   %}
 3003 
 3004   // synchronized read/update encodings
 3005 
 3006   enc_class aarch64_enc_ldaxr(iRegL dst, memory8 mem) %{
 3007     C2_MacroAssembler _masm(&amp;cbuf);
 3008     Register dst_reg = as_Register($dst$$reg);
 3009     Register base = as_Register($mem$$base);
 3010     int index = $mem$$index;
 3011     int scale = $mem$$scale;
 3012     int disp = $mem$$disp;
 3013     if (index == -1) {
 3014        if (disp != 0) {
 3015         __ lea(rscratch1, Address(base, disp));
 3016         __ ldaxr(dst_reg, rscratch1);
 3017       } else {
 3018         // TODO
 3019         // should we ever get anything other than this case?
 3020         __ ldaxr(dst_reg, base);
 3021       }
 3022     } else {
 3023       Register index_reg = as_Register(index);
 3024       if (disp == 0) {
 3025         __ lea(rscratch1, Address(base, index_reg, Address::lsl(scale)));
 3026         __ ldaxr(dst_reg, rscratch1);
 3027       } else {
 3028         __ lea(rscratch1, Address(base, disp));
 3029         __ lea(rscratch1, Address(rscratch1, index_reg, Address::lsl(scale)));
 3030         __ ldaxr(dst_reg, rscratch1);
 3031       }
 3032     }
 3033   %}
 3034 
 3035   enc_class aarch64_enc_stlxr(iRegLNoSp src, memory8 mem) %{
 3036     C2_MacroAssembler _masm(&amp;cbuf);
 3037     Register src_reg = as_Register($src$$reg);
 3038     Register base = as_Register($mem$$base);
 3039     int index = $mem$$index;
 3040     int scale = $mem$$scale;
 3041     int disp = $mem$$disp;
 3042     if (index == -1) {
 3043        if (disp != 0) {
 3044         __ lea(rscratch2, Address(base, disp));
 3045         __ stlxr(rscratch1, src_reg, rscratch2);
 3046       } else {
 3047         // TODO
 3048         // should we ever get anything other than this case?
 3049         __ stlxr(rscratch1, src_reg, base);
 3050       }
 3051     } else {
 3052       Register index_reg = as_Register(index);
 3053       if (disp == 0) {
 3054         __ lea(rscratch2, Address(base, index_reg, Address::lsl(scale)));
 3055         __ stlxr(rscratch1, src_reg, rscratch2);
 3056       } else {
 3057         __ lea(rscratch2, Address(base, disp));
 3058         __ lea(rscratch2, Address(rscratch2, index_reg, Address::lsl(scale)));
 3059         __ stlxr(rscratch1, src_reg, rscratch2);
 3060       }
 3061     }
 3062     __ cmpw(rscratch1, zr);
 3063   %}
 3064 
 3065   enc_class aarch64_enc_cmpxchg(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3066     C2_MacroAssembler _masm(&amp;cbuf);
 3067     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3068     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3069                Assembler::xword, /*acquire*/ false, /*release*/ true,
 3070                /*weak*/ false, noreg);
 3071   %}
 3072 
 3073   enc_class aarch64_enc_cmpxchgw(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3074     C2_MacroAssembler _masm(&amp;cbuf);
 3075     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3076     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3077                Assembler::word, /*acquire*/ false, /*release*/ true,
 3078                /*weak*/ false, noreg);
 3079   %}
 3080 
 3081   enc_class aarch64_enc_cmpxchgs(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3082     C2_MacroAssembler _masm(&amp;cbuf);
 3083     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3084     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3085                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 3086                /*weak*/ false, noreg);
 3087   %}
 3088 
 3089   enc_class aarch64_enc_cmpxchgb(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3090     C2_MacroAssembler _masm(&amp;cbuf);
 3091     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3092     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3093                Assembler::byte, /*acquire*/ false, /*release*/ true,
 3094                /*weak*/ false, noreg);
 3095   %}
 3096 
 3097 
 3098   // The only difference between aarch64_enc_cmpxchg and
 3099   // aarch64_enc_cmpxchg_acq is that we use load-acquire in the
 3100   // CompareAndSwap sequence to serve as a barrier on acquiring a
 3101   // lock.
 3102   enc_class aarch64_enc_cmpxchg_acq(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3103     C2_MacroAssembler _masm(&amp;cbuf);
 3104     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3105     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3106                Assembler::xword, /*acquire*/ true, /*release*/ true,
 3107                /*weak*/ false, noreg);
 3108   %}
 3109 
 3110   enc_class aarch64_enc_cmpxchgw_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3111     C2_MacroAssembler _masm(&amp;cbuf);
 3112     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3113     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3114                Assembler::word, /*acquire*/ true, /*release*/ true,
 3115                /*weak*/ false, noreg);
 3116   %}
 3117 
 3118   enc_class aarch64_enc_cmpxchgs_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3119     C2_MacroAssembler _masm(&amp;cbuf);
 3120     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3121     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3122                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 3123                /*weak*/ false, noreg);
 3124   %}
 3125 
 3126   enc_class aarch64_enc_cmpxchgb_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3127     C2_MacroAssembler _masm(&amp;cbuf);
 3128     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3129     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3130                Assembler::byte, /*acquire*/ true, /*release*/ true,
 3131                /*weak*/ false, noreg);
 3132   %}
 3133 
 3134   // auxiliary used for CompareAndSwapX to set result register
 3135   enc_class aarch64_enc_cset_eq(iRegINoSp res) %{
 3136     C2_MacroAssembler _masm(&amp;cbuf);
 3137     Register res_reg = as_Register($res$$reg);
 3138     __ cset(res_reg, Assembler::EQ);
 3139   %}
 3140 
 3141   // prefetch encodings
 3142 
 3143   enc_class aarch64_enc_prefetchw(memory mem) %{
 3144     C2_MacroAssembler _masm(&amp;cbuf);
 3145     Register base = as_Register($mem$$base);
 3146     int index = $mem$$index;
 3147     int scale = $mem$$scale;
 3148     int disp = $mem$$disp;
 3149     if (index == -1) {
 3150       __ prfm(Address(base, disp), PSTL1KEEP);
 3151     } else {
 3152       Register index_reg = as_Register(index);
 3153       if (disp == 0) {
 3154         __ prfm(Address(base, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3155       } else {
 3156         __ lea(rscratch1, Address(base, disp));
 3157 	__ prfm(Address(rscratch1, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3158       }
 3159     }
 3160   %}
 3161 
 3162   /// mov envcodings
 3163 
 3164   enc_class aarch64_enc_movw_imm(iRegI dst, immI src) %{
 3165     C2_MacroAssembler _masm(&amp;cbuf);
 3166     uint32_t con = (uint32_t)$src$$constant;
 3167     Register dst_reg = as_Register($dst$$reg);
 3168     if (con == 0) {
 3169       __ movw(dst_reg, zr);
 3170     } else {
 3171       __ movw(dst_reg, con);
 3172     }
 3173   %}
 3174 
 3175   enc_class aarch64_enc_mov_imm(iRegL dst, immL src) %{
 3176     C2_MacroAssembler _masm(&amp;cbuf);
 3177     Register dst_reg = as_Register($dst$$reg);
 3178     uint64_t con = (uint64_t)$src$$constant;
 3179     if (con == 0) {
 3180       __ mov(dst_reg, zr);
 3181     } else {
 3182       __ mov(dst_reg, con);
 3183     }
 3184   %}
 3185 
 3186   enc_class aarch64_enc_mov_p(iRegP dst, immP src) %{
 3187     C2_MacroAssembler _masm(&amp;cbuf);
 3188     Register dst_reg = as_Register($dst$$reg);
 3189     address con = (address)$src$$constant;
 3190     if (con == NULL || con == (address)1) {
 3191       ShouldNotReachHere();
 3192     } else {
 3193       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3194       if (rtype == relocInfo::oop_type) {
 3195         __ movoop(dst_reg, (jobject)con, /*immediate*/true);
 3196       } else if (rtype == relocInfo::metadata_type) {
 3197         __ mov_metadata(dst_reg, (Metadata*)con);
 3198       } else {
 3199         assert(rtype == relocInfo::none, &quot;unexpected reloc type&quot;);
 3200         if (con &lt; (address)(uintptr_t)os::vm_page_size()) {
 3201           __ mov(dst_reg, con);
 3202         } else {
 3203           unsigned long offset;
 3204           __ adrp(dst_reg, con, offset);
 3205           __ add(dst_reg, dst_reg, offset);
 3206         }
 3207       }
 3208     }
 3209   %}
 3210 
 3211   enc_class aarch64_enc_mov_p0(iRegP dst, immP0 src) %{
 3212     C2_MacroAssembler _masm(&amp;cbuf);
 3213     Register dst_reg = as_Register($dst$$reg);
 3214     __ mov(dst_reg, zr);
 3215   %}
 3216 
 3217   enc_class aarch64_enc_mov_p1(iRegP dst, immP_1 src) %{
 3218     C2_MacroAssembler _masm(&amp;cbuf);
 3219     Register dst_reg = as_Register($dst$$reg);
 3220     __ mov(dst_reg, (uint64_t)1);
 3221   %}
 3222 
 3223   enc_class aarch64_enc_mov_byte_map_base(iRegP dst, immByteMapBase src) %{
 3224     C2_MacroAssembler _masm(&amp;cbuf);
 3225     __ load_byte_map_base($dst$$Register);
 3226   %}
 3227 
 3228   enc_class aarch64_enc_mov_n(iRegN dst, immN src) %{
 3229     C2_MacroAssembler _masm(&amp;cbuf);
 3230     Register dst_reg = as_Register($dst$$reg);
 3231     address con = (address)$src$$constant;
 3232     if (con == NULL) {
 3233       ShouldNotReachHere();
 3234     } else {
 3235       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3236       assert(rtype == relocInfo::oop_type, &quot;unexpected reloc type&quot;);
 3237       __ set_narrow_oop(dst_reg, (jobject)con);
 3238     }
 3239   %}
 3240 
 3241   enc_class aarch64_enc_mov_n0(iRegN dst, immN0 src) %{
 3242     C2_MacroAssembler _masm(&amp;cbuf);
 3243     Register dst_reg = as_Register($dst$$reg);
 3244     __ mov(dst_reg, zr);
 3245   %}
 3246 
 3247   enc_class aarch64_enc_mov_nk(iRegN dst, immNKlass src) %{
 3248     C2_MacroAssembler _masm(&amp;cbuf);
 3249     Register dst_reg = as_Register($dst$$reg);
 3250     address con = (address)$src$$constant;
 3251     if (con == NULL) {
 3252       ShouldNotReachHere();
 3253     } else {
 3254       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3255       assert(rtype == relocInfo::metadata_type, &quot;unexpected reloc type&quot;);
 3256       __ set_narrow_klass(dst_reg, (Klass *)con);
 3257     }
 3258   %}
 3259 
 3260   // arithmetic encodings
 3261 
 3262   enc_class aarch64_enc_addsubw_imm(iRegI dst, iRegI src1, immIAddSub src2) %{
 3263     C2_MacroAssembler _masm(&amp;cbuf);
 3264     Register dst_reg = as_Register($dst$$reg);
 3265     Register src_reg = as_Register($src1$$reg);
 3266     int32_t con = (int32_t)$src2$$constant;
 3267     // add has primary == 0, subtract has primary == 1
 3268     if ($primary) { con = -con; }
 3269     if (con &lt; 0) {
 3270       __ subw(dst_reg, src_reg, -con);
 3271     } else {
 3272       __ addw(dst_reg, src_reg, con);
 3273     }
 3274   %}
 3275 
 3276   enc_class aarch64_enc_addsub_imm(iRegL dst, iRegL src1, immLAddSub src2) %{
 3277     C2_MacroAssembler _masm(&amp;cbuf);
 3278     Register dst_reg = as_Register($dst$$reg);
 3279     Register src_reg = as_Register($src1$$reg);
 3280     int32_t con = (int32_t)$src2$$constant;
 3281     // add has primary == 0, subtract has primary == 1
 3282     if ($primary) { con = -con; }
 3283     if (con &lt; 0) {
 3284       __ sub(dst_reg, src_reg, -con);
 3285     } else {
 3286       __ add(dst_reg, src_reg, con);
 3287     }
 3288   %}
 3289 
 3290   enc_class aarch64_enc_divw(iRegI dst, iRegI src1, iRegI src2) %{
 3291     C2_MacroAssembler _masm(&amp;cbuf);
 3292    Register dst_reg = as_Register($dst$$reg);
 3293    Register src1_reg = as_Register($src1$$reg);
 3294    Register src2_reg = as_Register($src2$$reg);
 3295     __ corrected_idivl(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3296   %}
 3297 
 3298   enc_class aarch64_enc_div(iRegI dst, iRegI src1, iRegI src2) %{
 3299     C2_MacroAssembler _masm(&amp;cbuf);
 3300    Register dst_reg = as_Register($dst$$reg);
 3301    Register src1_reg = as_Register($src1$$reg);
 3302    Register src2_reg = as_Register($src2$$reg);
 3303     __ corrected_idivq(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3304   %}
 3305 
 3306   enc_class aarch64_enc_modw(iRegI dst, iRegI src1, iRegI src2) %{
 3307     C2_MacroAssembler _masm(&amp;cbuf);
 3308    Register dst_reg = as_Register($dst$$reg);
 3309    Register src1_reg = as_Register($src1$$reg);
 3310    Register src2_reg = as_Register($src2$$reg);
 3311     __ corrected_idivl(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3312   %}
 3313 
 3314   enc_class aarch64_enc_mod(iRegI dst, iRegI src1, iRegI src2) %{
 3315     C2_MacroAssembler _masm(&amp;cbuf);
 3316    Register dst_reg = as_Register($dst$$reg);
 3317    Register src1_reg = as_Register($src1$$reg);
 3318    Register src2_reg = as_Register($src2$$reg);
 3319     __ corrected_idivq(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3320   %}
 3321 
 3322   // compare instruction encodings
 3323 
 3324   enc_class aarch64_enc_cmpw(iRegI src1, iRegI src2) %{
 3325     C2_MacroAssembler _masm(&amp;cbuf);
 3326     Register reg1 = as_Register($src1$$reg);
 3327     Register reg2 = as_Register($src2$$reg);
 3328     __ cmpw(reg1, reg2);
 3329   %}
 3330 
 3331   enc_class aarch64_enc_cmpw_imm_addsub(iRegI src1, immIAddSub src2) %{
 3332     C2_MacroAssembler _masm(&amp;cbuf);
 3333     Register reg = as_Register($src1$$reg);
 3334     int32_t val = $src2$$constant;
 3335     if (val &gt;= 0) {
 3336       __ subsw(zr, reg, val);
 3337     } else {
 3338       __ addsw(zr, reg, -val);
 3339     }
 3340   %}
 3341 
 3342   enc_class aarch64_enc_cmpw_imm(iRegI src1, immI src2) %{
 3343     C2_MacroAssembler _masm(&amp;cbuf);
 3344     Register reg1 = as_Register($src1$$reg);
 3345     uint32_t val = (uint32_t)$src2$$constant;
 3346     __ movw(rscratch1, val);
 3347     __ cmpw(reg1, rscratch1);
 3348   %}
 3349 
 3350   enc_class aarch64_enc_cmp(iRegL src1, iRegL src2) %{
 3351     C2_MacroAssembler _masm(&amp;cbuf);
 3352     Register reg1 = as_Register($src1$$reg);
 3353     Register reg2 = as_Register($src2$$reg);
 3354     __ cmp(reg1, reg2);
 3355   %}
 3356 
 3357   enc_class aarch64_enc_cmp_imm_addsub(iRegL src1, immL12 src2) %{
 3358     C2_MacroAssembler _masm(&amp;cbuf);
 3359     Register reg = as_Register($src1$$reg);
 3360     int64_t val = $src2$$constant;
 3361     if (val &gt;= 0) {
 3362       __ subs(zr, reg, val);
 3363     } else if (val != -val) {
 3364       __ adds(zr, reg, -val);
 3365     } else {
 3366     // aargh, Long.MIN_VALUE is a special case
 3367       __ orr(rscratch1, zr, (uint64_t)val);
 3368       __ subs(zr, reg, rscratch1);
 3369     }
 3370   %}
 3371 
 3372   enc_class aarch64_enc_cmp_imm(iRegL src1, immL src2) %{
 3373     C2_MacroAssembler _masm(&amp;cbuf);
 3374     Register reg1 = as_Register($src1$$reg);
 3375     uint64_t val = (uint64_t)$src2$$constant;
 3376     __ mov(rscratch1, val);
 3377     __ cmp(reg1, rscratch1);
 3378   %}
 3379 
 3380   enc_class aarch64_enc_cmpp(iRegP src1, iRegP src2) %{
 3381     C2_MacroAssembler _masm(&amp;cbuf);
 3382     Register reg1 = as_Register($src1$$reg);
 3383     Register reg2 = as_Register($src2$$reg);
 3384     __ cmp(reg1, reg2);
 3385   %}
 3386 
 3387   enc_class aarch64_enc_cmpn(iRegN src1, iRegN src2) %{
 3388     C2_MacroAssembler _masm(&amp;cbuf);
 3389     Register reg1 = as_Register($src1$$reg);
 3390     Register reg2 = as_Register($src2$$reg);
 3391     __ cmpw(reg1, reg2);
 3392   %}
 3393 
 3394   enc_class aarch64_enc_testp(iRegP src) %{
 3395     C2_MacroAssembler _masm(&amp;cbuf);
 3396     Register reg = as_Register($src$$reg);
 3397     __ cmp(reg, zr);
 3398   %}
 3399 
 3400   enc_class aarch64_enc_testn(iRegN src) %{
 3401     C2_MacroAssembler _masm(&amp;cbuf);
 3402     Register reg = as_Register($src$$reg);
 3403     __ cmpw(reg, zr);
 3404   %}
 3405 
 3406   enc_class aarch64_enc_b(label lbl) %{
 3407     C2_MacroAssembler _masm(&amp;cbuf);
 3408     Label *L = $lbl$$label;
 3409     __ b(*L);
 3410   %}
 3411 
 3412   enc_class aarch64_enc_br_con(cmpOp cmp, label lbl) %{
 3413     C2_MacroAssembler _masm(&amp;cbuf);
 3414     Label *L = $lbl$$label;
 3415     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3416   %}
 3417 
 3418   enc_class aarch64_enc_br_conU(cmpOpU cmp, label lbl) %{
 3419     C2_MacroAssembler _masm(&amp;cbuf);
 3420     Label *L = $lbl$$label;
 3421     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3422   %}
 3423 
 3424   enc_class aarch64_enc_partial_subtype_check(iRegP sub, iRegP super, iRegP temp, iRegP result)
 3425   %{
 3426      Register sub_reg = as_Register($sub$$reg);
 3427      Register super_reg = as_Register($super$$reg);
 3428      Register temp_reg = as_Register($temp$$reg);
 3429      Register result_reg = as_Register($result$$reg);
 3430 
 3431      Label miss;
 3432      C2_MacroAssembler _masm(&amp;cbuf);
 3433      __ check_klass_subtype_slow_path(sub_reg, super_reg, temp_reg, result_reg,
 3434                                      NULL, &amp;miss,
 3435                                      /*set_cond_codes:*/ true);
 3436      if ($primary) {
 3437        __ mov(result_reg, zr);
 3438      }
 3439      __ bind(miss);
 3440   %}
 3441 
 3442   enc_class aarch64_enc_java_static_call(method meth) %{
 3443     C2_MacroAssembler _masm(&amp;cbuf);
 3444 
 3445     address addr = (address)$meth$$method;
 3446     address call;
 3447     if (!_method) {
 3448       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
 3449       call = __ trampoline_call(Address(addr, relocInfo::runtime_call_type), &amp;cbuf);
 3450     } else {
 3451       int method_index = resolved_method_index(cbuf);
 3452       RelocationHolder rspec = _optimized_virtual ? opt_virtual_call_Relocation::spec(method_index)
 3453                                                   : static_call_Relocation::spec(method_index);
 3454       call = __ trampoline_call(Address(addr, rspec), &amp;cbuf);
 3455 
 3456       // Emit stub for static call
 3457       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 3458       if (stub == NULL) {
 3459         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3460         return;
 3461       }
 3462     }
 3463     if (call == NULL) {
 3464       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3465       return;
 3466     }
 3467   %}
 3468 
 3469   enc_class aarch64_enc_java_dynamic_call(method meth) %{
 3470     C2_MacroAssembler _masm(&amp;cbuf);
 3471     int method_index = resolved_method_index(cbuf);
 3472     address call = __ ic_call((address)$meth$$method, method_index);
 3473     if (call == NULL) {
 3474       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3475       return;
 3476     }
 3477   %}
 3478 
 3479   enc_class aarch64_enc_call_epilog() %{
 3480     C2_MacroAssembler _masm(&amp;cbuf);
 3481     if (VerifyStackAtCalls) {
 3482       // Check that stack depth is unchanged: find majik cookie on stack
 3483       __ call_Unimplemented();
 3484     }
 3485   %}
 3486 
 3487   enc_class aarch64_enc_java_to_runtime(method meth) %{
 3488     C2_MacroAssembler _masm(&amp;cbuf);
 3489 
 3490     // some calls to generated routines (arraycopy code) are scheduled
 3491     // by C2 as runtime calls. if so we can call them using a br (they
 3492     // will be in a reachable segment) otherwise we have to use a blr
 3493     // which loads the absolute address into a register.
 3494     address entry = (address)$meth$$method;
 3495     CodeBlob *cb = CodeCache::find_blob(entry);
 3496     if (cb) {
 3497       address call = __ trampoline_call(Address(entry, relocInfo::runtime_call_type));
 3498       if (call == NULL) {
 3499         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3500         return;
 3501       }
 3502     } else {
 3503       Label retaddr;
 3504       __ adr(rscratch2, retaddr);
 3505       __ lea(rscratch1, RuntimeAddress(entry));
 3506       // Leave a breadcrumb for JavaFrameAnchor::capture_last_Java_pc()
 3507       __ stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)));
 3508       __ blr(rscratch1);
 3509       __ bind(retaddr);
 3510       __ add(sp, sp, 2 * wordSize);
 3511     }
 3512   %}
 3513 
 3514   enc_class aarch64_enc_rethrow() %{
 3515     C2_MacroAssembler _masm(&amp;cbuf);
 3516     __ far_jump(RuntimeAddress(OptoRuntime::rethrow_stub()));
 3517   %}
 3518 
 3519   enc_class aarch64_enc_ret() %{
 3520     C2_MacroAssembler _masm(&amp;cbuf);
 3521     __ ret(lr);
 3522   %}
 3523 
 3524   enc_class aarch64_enc_tail_call(iRegP jump_target) %{
 3525     C2_MacroAssembler _masm(&amp;cbuf);
 3526     Register target_reg = as_Register($jump_target$$reg);
 3527     __ br(target_reg);
 3528   %}
 3529 
 3530   enc_class aarch64_enc_tail_jmp(iRegP jump_target) %{
 3531     C2_MacroAssembler _masm(&amp;cbuf);
 3532     Register target_reg = as_Register($jump_target$$reg);
 3533     // exception oop should be in r0
 3534     // ret addr has been popped into lr
 3535     // callee expects it in r3
 3536     __ mov(r3, lr);
 3537     __ br(target_reg);
 3538   %}
 3539 
 3540   enc_class aarch64_enc_fast_lock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3541     C2_MacroAssembler _masm(&amp;cbuf);
 3542     Register oop = as_Register($object$$reg);
 3543     Register box = as_Register($box$$reg);
 3544     Register disp_hdr = as_Register($tmp$$reg);
 3545     Register tmp = as_Register($tmp2$$reg);
 3546     Label cont;
 3547     Label object_has_monitor;
 3548     Label cas_failed;
 3549 
 3550     assert_different_registers(oop, box, tmp, disp_hdr);
 3551 
 3552     // Load markWord from object into displaced_header.
 3553     __ ldr(disp_hdr, Address(oop, oopDesc::mark_offset_in_bytes()));
 3554 
 3555     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3556       __ biased_locking_enter(box, oop, disp_hdr, tmp, true, cont);
 3557     }
 3558 
 3559     // Check for existing monitor
 3560     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3561 
 3562     // Set tmp to be (markWord of object | UNLOCK_VALUE).
 3563     __ orr(tmp, disp_hdr, markWord::unlocked_value);
 3564 
 3565     // Initialize the box. (Must happen before we update the object mark!)
 3566     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3567 
 3568     // Compare object markWord with an unlocked value (tmp) and if
 3569     // equal exchange the stack address of our box with object markWord.
 3570     // On failure disp_hdr contains the possibly locked markWord.
 3571     __ cmpxchg(oop, tmp, box, Assembler::xword, /*acquire*/ true,
 3572                /*release*/ true, /*weak*/ false, disp_hdr);
 3573     __ br(Assembler::EQ, cont);
 3574 
 3575     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3576 
 3577     // If the compare-and-exchange succeeded, then we found an unlocked
 3578     // object, will have now locked it will continue at label cont
 3579 
 3580     __ bind(cas_failed);
 3581     // We did not see an unlocked object so try the fast recursive case.
 3582 
 3583     // Check if the owner is self by comparing the value in the
 3584     // markWord of object (disp_hdr) with the stack pointer.
 3585     __ mov(rscratch1, sp);
 3586     __ sub(disp_hdr, disp_hdr, rscratch1);
 3587     __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));
 3588     // If condition is true we are cont and hence we can store 0 as the
 3589     // displaced header in the box, which indicates that it is a recursive lock.
 3590     __ ands(tmp/*==0?*/, disp_hdr, tmp);   // Sets flags for result
 3591     __ str(tmp/*==0, perhaps*/, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3592 
 3593     __ b(cont);
 3594 
 3595     // Handle existing monitor.
 3596     __ bind(object_has_monitor);
 3597 
 3598     // The object&#39;s monitor m is unlocked iff m-&gt;owner == NULL,
 3599     // otherwise m-&gt;owner may contain a thread or a stack address.
 3600     //
 3601     // Try to CAS m-&gt;owner from NULL to current thread.
 3602     __ add(tmp, disp_hdr, (ObjectMonitor::owner_offset_in_bytes()-markWord::monitor_value));
 3603     __ cmpxchg(tmp, zr, rthread, Assembler::xword, /*acquire*/ true,
 3604                /*release*/ true, /*weak*/ false, noreg); // Sets flags for result
 3605 
 3606     // Store a non-null value into the box to avoid looking like a re-entrant
 3607     // lock. The fast-path monitor unlock code checks for
 3608     // markWord::monitor_value so use markWord::unused_mark which has the
 3609     // relevant bit set, and also matches ObjectSynchronizer::enter.
 3610     __ mov(tmp, (address)markWord::unused_mark().value());
 3611     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3612 
 3613     __ bind(cont);
 3614     // flag == EQ indicates success
 3615     // flag == NE indicates failure
 3616   %}
 3617 
 3618   enc_class aarch64_enc_fast_unlock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3619     C2_MacroAssembler _masm(&amp;cbuf);
 3620     Register oop = as_Register($object$$reg);
 3621     Register box = as_Register($box$$reg);
 3622     Register disp_hdr = as_Register($tmp$$reg);
 3623     Register tmp = as_Register($tmp2$$reg);
 3624     Label cont;
 3625     Label object_has_monitor;
 3626 
 3627     assert_different_registers(oop, box, tmp, disp_hdr);
 3628 
 3629     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3630       __ biased_locking_exit(oop, tmp, cont);
 3631     }
 3632 
 3633     // Find the lock address and load the displaced header from the stack.
 3634     __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3635 
 3636     // If the displaced header is 0, we have a recursive unlock.
 3637     __ cmp(disp_hdr, zr);
 3638     __ br(Assembler::EQ, cont);
 3639 
 3640     // Handle existing monitor.
 3641     __ ldr(tmp, Address(oop, oopDesc::mark_offset_in_bytes()));
 3642     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3643 
 3644     // Check if it is still a light weight lock, this is is true if we
 3645     // see the stack address of the basicLock in the markWord of the
 3646     // object.
 3647 
 3648     __ cmpxchg(oop, box, disp_hdr, Assembler::xword, /*acquire*/ false,
 3649                /*release*/ true, /*weak*/ false, tmp);
 3650     __ b(cont);
 3651 
 3652     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3653 
 3654     // Handle existing monitor.
 3655     __ bind(object_has_monitor);
 3656     STATIC_ASSERT(markWord::monitor_value &lt;= INT_MAX);
 3657     __ add(tmp, tmp, -(int)markWord::monitor_value); // monitor
 3658     __ ldr(rscratch1, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3659     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::recursions_offset_in_bytes()));
 3660     __ eor(rscratch1, rscratch1, rthread); // Will be 0 if we are the owner.
 3661     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if there are 0 recursions
 3662     __ cmp(rscratch1, zr); // Sets flags for result
 3663     __ br(Assembler::NE, cont);
 3664 
 3665     __ ldr(rscratch1, Address(tmp, ObjectMonitor::EntryList_offset_in_bytes()));
 3666     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::cxq_offset_in_bytes()));
 3667     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if both are 0.
 3668     __ cmp(rscratch1, zr); // Sets flags for result
 3669     __ cbnz(rscratch1, cont);
 3670     // need a release store here
 3671     __ lea(tmp, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3672     __ stlr(zr, tmp); // set unowned
 3673 
 3674     __ bind(cont);
 3675     // flag == EQ indicates success
 3676     // flag == NE indicates failure
 3677   %}
 3678 
 3679 %}
 3680 
 3681 //----------FRAME--------------------------------------------------------------
 3682 // Definition of frame structure and management information.
 3683 //
 3684 //  S T A C K   L A Y O U T    Allocators stack-slot number
 3685 //                             |   (to get allocators register number
 3686 //  G  Owned by    |        |  v    add OptoReg::stack0())
 3687 //  r   CALLER     |        |
 3688 //  o     |        +--------+      pad to even-align allocators stack-slot
 3689 //  w     V        |  pad0  |        numbers; owned by CALLER
 3690 //  t   -----------+--------+----&gt; Matcher::_in_arg_limit, unaligned
 3691 //  h     ^        |   in   |  5
 3692 //        |        |  args  |  4   Holes in incoming args owned by SELF
 3693 //  |     |        |        |  3
 3694 //  |     |        +--------+
 3695 //  V     |        | old out|      Empty on Intel, window on Sparc
 3696 //        |    old |preserve|      Must be even aligned.
 3697 //        |     SP-+--------+----&gt; Matcher::_old_SP, even aligned
 3698 //        |        |   in   |  3   area for Intel ret address
 3699 //     Owned by    |preserve|      Empty on Sparc.
 3700 //       SELF      +--------+
 3701 //        |        |  pad2  |  2   pad to align old SP
 3702 //        |        +--------+  1
 3703 //        |        | locks  |  0
 3704 //        |        +--------+----&gt; OptoReg::stack0(), even aligned
 3705 //        |        |  pad1  | 11   pad to align new SP
 3706 //        |        +--------+
 3707 //        |        |        | 10
 3708 //        |        | spills |  9   spills
 3709 //        V        |        |  8   (pad0 slot for callee)
 3710 //      -----------+--------+----&gt; Matcher::_out_arg_limit, unaligned
 3711 //        ^        |  out   |  7
 3712 //        |        |  args  |  6   Holes in outgoing args owned by CALLEE
 3713 //     Owned by    +--------+
 3714 //      CALLEE     | new out|  6   Empty on Intel, window on Sparc
 3715 //        |    new |preserve|      Must be even-aligned.
 3716 //        |     SP-+--------+----&gt; Matcher::_new_SP, even aligned
 3717 //        |        |        |
 3718 //
 3719 // Note 1: Only region 8-11 is determined by the allocator.  Region 0-5 is
 3720 //         known from SELF&#39;s arguments and the Java calling convention.
 3721 //         Region 6-7 is determined per call site.
 3722 // Note 2: If the calling convention leaves holes in the incoming argument
 3723 //         area, those holes are owned by SELF.  Holes in the outgoing area
 3724 //         are owned by the CALLEE.  Holes should not be nessecary in the
 3725 //         incoming area, as the Java calling convention is completely under
 3726 //         the control of the AD file.  Doubles can be sorted and packed to
 3727 //         avoid holes.  Holes in the outgoing arguments may be nessecary for
 3728 //         varargs C calling conventions.
 3729 // Note 3: Region 0-3 is even aligned, with pad2 as needed.  Region 3-5 is
 3730 //         even aligned with pad0 as needed.
 3731 //         Region 6 is even aligned.  Region 6-7 is NOT even aligned;
 3732 //           (the latter is true on Intel but is it false on AArch64?)
 3733 //         region 6-11 is even aligned; it may be padded out more so that
 3734 //         the region from SP to FP meets the minimum stack alignment.
 3735 // Note 4: For I2C adapters, the incoming FP may not meet the minimum stack
 3736 //         alignment.  Region 11, pad1, may be dynamically extended so that
 3737 //         SP meets the minimum alignment.
 3738 
 3739 frame %{
 3740   // What direction does stack grow in (assumed to be same for C &amp; Java)
 3741   stack_direction(TOWARDS_LOW);
 3742 
 3743   // These three registers define part of the calling convention
 3744   // between compiled code and the interpreter.
 3745 
 3746   // Inline Cache Register or methodOop for I2C.
 3747   inline_cache_reg(R12);
 3748 
 3749   // Method Oop Register when calling interpreter.
 3750   interpreter_method_oop_reg(R12);
 3751 
 3752   // Number of stack slots consumed by locking an object
 3753   sync_stack_slots(2);
 3754 
 3755   // Compiled code&#39;s Frame Pointer
 3756   frame_pointer(R31);
 3757 
 3758   // Interpreter stores its frame pointer in a register which is
 3759   // stored to the stack by I2CAdaptors.
 3760   // I2CAdaptors convert from interpreted java to compiled java.
 3761   interpreter_frame_pointer(R29);
 3762 
 3763   // Stack alignment requirement
 3764   stack_alignment(StackAlignmentInBytes); // Alignment size in bytes (128-bit -&gt; 16 bytes)
 3765 
 3766   // Number of stack slots between incoming argument block and the start of
 3767   // a new frame.  The PROLOG must add this many slots to the stack.  The
 3768   // EPILOG must remove this many slots. aarch64 needs two slots for
 3769   // return address and fp.
 3770   // TODO think this is correct but check
 3771   in_preserve_stack_slots(4);
 3772 
 3773   // Number of outgoing stack slots killed above the out_preserve_stack_slots
 3774   // for calls to C.  Supports the var-args backing area for register parms.
 3775   varargs_C_out_slots_killed(frame::arg_reg_save_area_bytes/BytesPerInt);
 3776 
 3777   // The after-PROLOG location of the return address.  Location of
 3778   // return address specifies a type (REG or STACK) and a number
 3779   // representing the register number (i.e. - use a register name) or
 3780   // stack slot.
 3781   // Ret Addr is on stack in slot 0 if no locks or verification or alignment.
 3782   // Otherwise, it is above the locks and verification slot and alignment word
 3783   // TODO this may well be correct but need to check why that - 2 is there
 3784   // ppc port uses 0 but we definitely need to allow for fixed_slots
 3785   // which folds in the space used for monitors
 3786   return_addr(STACK - 2 +
 3787               align_up((Compile::current()-&gt;in_preserve_stack_slots() +
 3788                         Compile::current()-&gt;fixed_slots()),
 3789                        stack_alignment_in_slots()));
 3790 
 3791   // Body of function which returns an integer array locating
 3792   // arguments either in registers or in stack slots.  Passed an array
 3793   // of ideal registers called &quot;sig&quot; and a &quot;length&quot; count.  Stack-slot
 3794   // offsets are based on outgoing arguments, i.e. a CALLER setting up
 3795   // arguments for a CALLEE.  Incoming stack arguments are
 3796   // automatically biased by the preserve_stack_slots field above.
 3797 
 3798   calling_convention
 3799   %{
 3800     // No difference between ingoing/outgoing just pass false
 3801     SharedRuntime::java_calling_convention(sig_bt, regs, length, false);
 3802   %}
 3803 
 3804   c_calling_convention
 3805   %{
 3806     // This is obviously always outgoing
 3807     (void) SharedRuntime::c_calling_convention(sig_bt, regs, NULL, length);
 3808   %}
 3809 
 3810   // Location of compiled Java return values.  Same as C for now.
 3811   return_value
 3812   %{
 3813     // TODO do we allow ideal_reg == Op_RegN???
 3814     assert(ideal_reg &gt;= Op_RegI &amp;&amp; ideal_reg &lt;= Op_RegL,
 3815            &quot;only return normal values&quot;);
 3816 
 3817     static const int lo[Op_RegL + 1] = { // enum name
 3818       0,                                 // Op_Node
 3819       0,                                 // Op_Set
 3820       R0_num,                            // Op_RegN
 3821       R0_num,                            // Op_RegI
 3822       R0_num,                            // Op_RegP
 3823       V0_num,                            // Op_RegF
 3824       V0_num,                            // Op_RegD
 3825       R0_num                             // Op_RegL
 3826     };
 3827 
 3828     static const int hi[Op_RegL + 1] = { // enum name
 3829       0,                                 // Op_Node
 3830       0,                                 // Op_Set
 3831       OptoReg::Bad,                      // Op_RegN
 3832       OptoReg::Bad,                      // Op_RegI
 3833       R0_H_num,                          // Op_RegP
 3834       OptoReg::Bad,                      // Op_RegF
 3835       V0_H_num,                          // Op_RegD
 3836       R0_H_num                           // Op_RegL
 3837     };
 3838 
 3839     return OptoRegPair(hi[ideal_reg], lo[ideal_reg]);
 3840   %}
 3841 %}
 3842 
 3843 //----------ATTRIBUTES---------------------------------------------------------
 3844 //----------Operand Attributes-------------------------------------------------
 3845 op_attrib op_cost(1);        // Required cost attribute
 3846 
 3847 //----------Instruction Attributes---------------------------------------------
 3848 ins_attrib ins_cost(INSN_COST); // Required cost attribute
 3849 ins_attrib ins_size(32);        // Required size attribute (in bits)
 3850 ins_attrib ins_short_branch(0); // Required flag: is this instruction
 3851                                 // a non-matching short branch variant
 3852                                 // of some long branch?
 3853 ins_attrib ins_alignment(4);    // Required alignment attribute (must
 3854                                 // be a power of 2) specifies the
 3855                                 // alignment that some part of the
 3856                                 // instruction (not necessarily the
 3857                                 // start) requires.  If &gt; 1, a
 3858                                 // compute_padding() function must be
 3859                                 // provided for the instruction
 3860 
 3861 //----------OPERANDS-----------------------------------------------------------
 3862 // Operand definitions must precede instruction definitions for correct parsing
 3863 // in the ADLC because operands constitute user defined types which are used in
 3864 // instruction definitions.
 3865 
 3866 //----------Simple Operands----------------------------------------------------
 3867 
 3868 // Integer operands 32 bit
 3869 // 32 bit immediate
 3870 operand immI()
 3871 %{
 3872   match(ConI);
 3873 
 3874   op_cost(0);
 3875   format %{ %}
 3876   interface(CONST_INTER);
 3877 %}
 3878 
 3879 // 32 bit zero
 3880 operand immI0()
 3881 %{
 3882   predicate(n-&gt;get_int() == 0);
 3883   match(ConI);
 3884 
 3885   op_cost(0);
 3886   format %{ %}
 3887   interface(CONST_INTER);
 3888 %}
 3889 
 3890 // 32 bit unit increment
 3891 operand immI_1()
 3892 %{
 3893   predicate(n-&gt;get_int() == 1);
 3894   match(ConI);
 3895 
 3896   op_cost(0);
 3897   format %{ %}
 3898   interface(CONST_INTER);
 3899 %}
 3900 
 3901 // 32 bit unit decrement
 3902 operand immI_M1()
 3903 %{
 3904   predicate(n-&gt;get_int() == -1);
 3905   match(ConI);
 3906 
 3907   op_cost(0);
 3908   format %{ %}
 3909   interface(CONST_INTER);
 3910 %}
 3911 
 3912 // Shift values for add/sub extension shift
 3913 operand immIExt()
 3914 %{
 3915   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 4));
 3916   match(ConI);
 3917 
 3918   op_cost(0);
 3919   format %{ %}
 3920   interface(CONST_INTER);
 3921 %}
 3922 
 3923 operand immI_le_4()
 3924 %{
 3925   predicate(n-&gt;get_int() &lt;= 4);
 3926   match(ConI);
 3927 
 3928   op_cost(0);
 3929   format %{ %}
 3930   interface(CONST_INTER);
 3931 %}
 3932 
 3933 operand immI_31()
 3934 %{
 3935   predicate(n-&gt;get_int() == 31);
 3936   match(ConI);
 3937 
 3938   op_cost(0);
 3939   format %{ %}
 3940   interface(CONST_INTER);
 3941 %}
 3942 
 3943 operand immI_8()
 3944 %{
 3945   predicate(n-&gt;get_int() == 8);
 3946   match(ConI);
 3947 
 3948   op_cost(0);
 3949   format %{ %}
 3950   interface(CONST_INTER);
 3951 %}
 3952 
 3953 operand immI_16()
 3954 %{
 3955   predicate(n-&gt;get_int() == 16);
 3956   match(ConI);
 3957 
 3958   op_cost(0);
 3959   format %{ %}
 3960   interface(CONST_INTER);
 3961 %}
 3962 
 3963 operand immI_24()
 3964 %{
 3965   predicate(n-&gt;get_int() == 24);
 3966   match(ConI);
 3967 
 3968   op_cost(0);
 3969   format %{ %}
 3970   interface(CONST_INTER);
 3971 %}
 3972 
 3973 operand immI_32()
 3974 %{
 3975   predicate(n-&gt;get_int() == 32);
 3976   match(ConI);
 3977 
 3978   op_cost(0);
 3979   format %{ %}
 3980   interface(CONST_INTER);
 3981 %}
 3982 
 3983 operand immI_48()
 3984 %{
 3985   predicate(n-&gt;get_int() == 48);
 3986   match(ConI);
 3987 
 3988   op_cost(0);
 3989   format %{ %}
 3990   interface(CONST_INTER);
 3991 %}
 3992 
 3993 operand immI_56()
 3994 %{
 3995   predicate(n-&gt;get_int() == 56);
 3996   match(ConI);
 3997 
 3998   op_cost(0);
 3999   format %{ %}
 4000   interface(CONST_INTER);
 4001 %}
 4002 
 4003 operand immI_63()
 4004 %{
 4005   predicate(n-&gt;get_int() == 63);
 4006   match(ConI);
 4007 
 4008   op_cost(0);
 4009   format %{ %}
 4010   interface(CONST_INTER);
 4011 %}
 4012 
 4013 operand immI_64()
 4014 %{
 4015   predicate(n-&gt;get_int() == 64);
 4016   match(ConI);
 4017 
 4018   op_cost(0);
 4019   format %{ %}
 4020   interface(CONST_INTER);
 4021 %}
 4022 
 4023 operand immI_255()
 4024 %{
 4025   predicate(n-&gt;get_int() == 255);
 4026   match(ConI);
 4027 
 4028   op_cost(0);
 4029   format %{ %}
 4030   interface(CONST_INTER);
 4031 %}
 4032 
 4033 operand immI_65535()
 4034 %{
 4035   predicate(n-&gt;get_int() == 65535);
 4036   match(ConI);
 4037 
 4038   op_cost(0);
 4039   format %{ %}
 4040   interface(CONST_INTER);
 4041 %}
 4042 
 4043 operand immL_255()
 4044 %{
 4045   predicate(n-&gt;get_long() == 255L);
 4046   match(ConL);
 4047 
 4048   op_cost(0);
 4049   format %{ %}
 4050   interface(CONST_INTER);
 4051 %}
 4052 
 4053 operand immL_65535()
 4054 %{
 4055   predicate(n-&gt;get_long() == 65535L);
 4056   match(ConL);
 4057 
 4058   op_cost(0);
 4059   format %{ %}
 4060   interface(CONST_INTER);
 4061 %}
 4062 
 4063 operand immL_4294967295()
 4064 %{
 4065   predicate(n-&gt;get_long() == 4294967295L);
 4066   match(ConL);
 4067 
 4068   op_cost(0);
 4069   format %{ %}
 4070   interface(CONST_INTER);
 4071 %}
 4072 
 4073 operand immL_bitmask()
 4074 %{
 4075   predicate((n-&gt;get_long() != 0)
 4076             &amp;&amp; ((n-&gt;get_long() &amp; 0xc000000000000000l) == 0)
 4077             &amp;&amp; is_power_of_2(n-&gt;get_long() + 1));
 4078   match(ConL);
 4079 
 4080   op_cost(0);
 4081   format %{ %}
 4082   interface(CONST_INTER);
 4083 %}
 4084 
 4085 operand immI_bitmask()
 4086 %{
 4087   predicate((n-&gt;get_int() != 0)
 4088             &amp;&amp; ((n-&gt;get_int() &amp; 0xc0000000) == 0)
 4089             &amp;&amp; is_power_of_2(n-&gt;get_int() + 1));
 4090   match(ConI);
 4091 
 4092   op_cost(0);
 4093   format %{ %}
 4094   interface(CONST_INTER);
 4095 %}
 4096 
 4097 // Scale values for scaled offset addressing modes (up to long but not quad)
 4098 operand immIScale()
 4099 %{
 4100   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 3));
 4101   match(ConI);
 4102 
 4103   op_cost(0);
 4104   format %{ %}
 4105   interface(CONST_INTER);
 4106 %}
 4107 
 4108 // 26 bit signed offset -- for pc-relative branches
 4109 operand immI26()
 4110 %{
 4111   predicate(((-(1 &lt;&lt; 25)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 25)));
 4112   match(ConI);
 4113 
 4114   op_cost(0);
 4115   format %{ %}
 4116   interface(CONST_INTER);
 4117 %}
 4118 
 4119 // 19 bit signed offset -- for pc-relative loads
 4120 operand immI19()
 4121 %{
 4122   predicate(((-(1 &lt;&lt; 18)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 18)));
 4123   match(ConI);
 4124 
 4125   op_cost(0);
 4126   format %{ %}
 4127   interface(CONST_INTER);
 4128 %}
 4129 
 4130 // 12 bit unsigned offset -- for base plus immediate loads
 4131 operand immIU12()
 4132 %{
 4133   predicate((0 &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 12)));
 4134   match(ConI);
 4135 
 4136   op_cost(0);
 4137   format %{ %}
 4138   interface(CONST_INTER);
 4139 %}
 4140 
 4141 operand immLU12()
 4142 %{
 4143   predicate((0 &lt;= n-&gt;get_long()) &amp;&amp; (n-&gt;get_long() &lt; (1 &lt;&lt; 12)));
 4144   match(ConL);
 4145 
 4146   op_cost(0);
 4147   format %{ %}
 4148   interface(CONST_INTER);
 4149 %}
 4150 
 4151 // Offset for scaled or unscaled immediate loads and stores
 4152 operand immIOffset()
 4153 %{
 4154   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4155   match(ConI);
 4156 
 4157   op_cost(0);
 4158   format %{ %}
 4159   interface(CONST_INTER);
 4160 %}
 4161 
 4162 operand immIOffset1()
 4163 %{
 4164   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4165   match(ConI);
 4166 
 4167   op_cost(0);
 4168   format %{ %}
 4169   interface(CONST_INTER);
 4170 %}
 4171 
 4172 operand immIOffset2()
 4173 %{
 4174   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 1));
 4175   match(ConI);
 4176 
 4177   op_cost(0);
 4178   format %{ %}
 4179   interface(CONST_INTER);
 4180 %}
 4181 
 4182 operand immIOffset4()
 4183 %{
 4184   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 2));
 4185   match(ConI);
 4186 
 4187   op_cost(0);
 4188   format %{ %}
 4189   interface(CONST_INTER);
 4190 %}
 4191 
 4192 operand immIOffset8()
 4193 %{
 4194   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 3));
 4195   match(ConI);
 4196 
 4197   op_cost(0);
 4198   format %{ %}
 4199   interface(CONST_INTER);
 4200 %}
 4201 
 4202 operand immIOffset16()
 4203 %{
 4204   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 4));
 4205   match(ConI);
 4206 
 4207   op_cost(0);
 4208   format %{ %}
 4209   interface(CONST_INTER);
 4210 %}
 4211 
 4212 operand immLoffset()
 4213 %{
 4214   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4215   match(ConL);
 4216 
 4217   op_cost(0);
 4218   format %{ %}
 4219   interface(CONST_INTER);
 4220 %}
 4221 
 4222 operand immLoffset1()
 4223 %{
 4224   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4225   match(ConL);
 4226 
 4227   op_cost(0);
 4228   format %{ %}
 4229   interface(CONST_INTER);
 4230 %}
 4231 
 4232 operand immLoffset2()
 4233 %{
 4234   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 1));
 4235   match(ConL);
 4236 
 4237   op_cost(0);
 4238   format %{ %}
 4239   interface(CONST_INTER);
 4240 %}
 4241 
 4242 operand immLoffset4()
 4243 %{
 4244   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 2));
 4245   match(ConL);
 4246 
 4247   op_cost(0);
 4248   format %{ %}
 4249   interface(CONST_INTER);
 4250 %}
 4251 
 4252 operand immLoffset8()
 4253 %{
 4254   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 3));
 4255   match(ConL);
 4256 
 4257   op_cost(0);
 4258   format %{ %}
 4259   interface(CONST_INTER);
 4260 %}
 4261 
 4262 operand immLoffset16()
 4263 %{
 4264   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 4));
 4265   match(ConL);
 4266 
 4267   op_cost(0);
 4268   format %{ %}
 4269   interface(CONST_INTER);
 4270 %}
 4271 
 4272 // 32 bit integer valid for add sub immediate
 4273 operand immIAddSub()
 4274 %{
 4275   predicate(Assembler::operand_valid_for_add_sub_immediate((long)n-&gt;get_int()));
 4276   match(ConI);
 4277   op_cost(0);
 4278   format %{ %}
 4279   interface(CONST_INTER);
 4280 %}
 4281 
 4282 // 32 bit unsigned integer valid for logical immediate
 4283 // TODO -- check this is right when e.g the mask is 0x80000000
 4284 operand immILog()
 4285 %{
 4286   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/true, (unsigned long)n-&gt;get_int()));
 4287   match(ConI);
 4288 
 4289   op_cost(0);
 4290   format %{ %}
 4291   interface(CONST_INTER);
 4292 %}
 4293 
 4294 // Integer operands 64 bit
 4295 // 64 bit immediate
 4296 operand immL()
 4297 %{
 4298   match(ConL);
 4299 
 4300   op_cost(0);
 4301   format %{ %}
 4302   interface(CONST_INTER);
 4303 %}
 4304 
 4305 // 64 bit zero
 4306 operand immL0()
 4307 %{
 4308   predicate(n-&gt;get_long() == 0);
 4309   match(ConL);
 4310 
 4311   op_cost(0);
 4312   format %{ %}
 4313   interface(CONST_INTER);
 4314 %}
 4315 
 4316 // 64 bit unit increment
 4317 operand immL_1()
 4318 %{
 4319   predicate(n-&gt;get_long() == 1);
 4320   match(ConL);
 4321 
 4322   op_cost(0);
 4323   format %{ %}
 4324   interface(CONST_INTER);
 4325 %}
 4326 
 4327 // 64 bit unit decrement
 4328 operand immL_M1()
 4329 %{
 4330   predicate(n-&gt;get_long() == -1);
 4331   match(ConL);
 4332 
 4333   op_cost(0);
 4334   format %{ %}
 4335   interface(CONST_INTER);
 4336 %}
 4337 
 4338 // 32 bit offset of pc in thread anchor
 4339 
 4340 operand immL_pc_off()
 4341 %{
 4342   predicate(n-&gt;get_long() == in_bytes(JavaThread::frame_anchor_offset()) +
 4343                              in_bytes(JavaFrameAnchor::last_Java_pc_offset()));
 4344   match(ConL);
 4345 
 4346   op_cost(0);
 4347   format %{ %}
 4348   interface(CONST_INTER);
 4349 %}
 4350 
 4351 // 64 bit integer valid for add sub immediate
 4352 operand immLAddSub()
 4353 %{
 4354   predicate(Assembler::operand_valid_for_add_sub_immediate(n-&gt;get_long()));
 4355   match(ConL);
 4356   op_cost(0);
 4357   format %{ %}
 4358   interface(CONST_INTER);
 4359 %}
 4360 
 4361 // 64 bit integer valid for logical immediate
 4362 operand immLLog()
 4363 %{
 4364   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/false, (unsigned long)n-&gt;get_long()));
 4365   match(ConL);
 4366   op_cost(0);
 4367   format %{ %}
 4368   interface(CONST_INTER);
 4369 %}
 4370 
 4371 // Long Immediate: low 32-bit mask
 4372 operand immL_32bits()
 4373 %{
 4374   predicate(n-&gt;get_long() == 0xFFFFFFFFL);
 4375   match(ConL);
 4376   op_cost(0);
 4377   format %{ %}
 4378   interface(CONST_INTER);
 4379 %}
 4380 
 4381 // Pointer operands
 4382 // Pointer Immediate
 4383 operand immP()
 4384 %{
 4385   match(ConP);
 4386 
 4387   op_cost(0);
 4388   format %{ %}
 4389   interface(CONST_INTER);
 4390 %}
 4391 
 4392 // NULL Pointer Immediate
 4393 operand immP0()
 4394 %{
 4395   predicate(n-&gt;get_ptr() == 0);
 4396   match(ConP);
 4397 
 4398   op_cost(0);
 4399   format %{ %}
 4400   interface(CONST_INTER);
 4401 %}
 4402 
 4403 // Pointer Immediate One
 4404 // this is used in object initialization (initial object header)
 4405 operand immP_1()
 4406 %{
 4407   predicate(n-&gt;get_ptr() == 1);
 4408   match(ConP);
 4409 
 4410   op_cost(0);
 4411   format %{ %}
 4412   interface(CONST_INTER);
 4413 %}
 4414 
 4415 // Card Table Byte Map Base
 4416 operand immByteMapBase()
 4417 %{
 4418   // Get base of card map
 4419   predicate(BarrierSet::barrier_set()-&gt;is_a(BarrierSet::CardTableBarrierSet) &amp;&amp;
 4420             (CardTable::CardValue*)n-&gt;get_ptr() == ((CardTableBarrierSet*)(BarrierSet::barrier_set()))-&gt;card_table()-&gt;byte_map_base());
 4421   match(ConP);
 4422 
 4423   op_cost(0);
 4424   format %{ %}
 4425   interface(CONST_INTER);
 4426 %}
 4427 
 4428 // Pointer Immediate Minus One
 4429 // this is used when we want to write the current PC to the thread anchor
 4430 operand immP_M1()
 4431 %{
 4432   predicate(n-&gt;get_ptr() == -1);
 4433   match(ConP);
 4434 
 4435   op_cost(0);
 4436   format %{ %}
 4437   interface(CONST_INTER);
 4438 %}
 4439 
 4440 // Pointer Immediate Minus Two
 4441 // this is used when we want to write the current PC to the thread anchor
 4442 operand immP_M2()
 4443 %{
 4444   predicate(n-&gt;get_ptr() == -2);
 4445   match(ConP);
 4446 
 4447   op_cost(0);
 4448   format %{ %}
 4449   interface(CONST_INTER);
 4450 %}
 4451 
 4452 // Float and Double operands
 4453 // Double Immediate
 4454 operand immD()
 4455 %{
 4456   match(ConD);
 4457   op_cost(0);
 4458   format %{ %}
 4459   interface(CONST_INTER);
 4460 %}
 4461 
 4462 // Double Immediate: +0.0d
 4463 operand immD0()
 4464 %{
 4465   predicate(jlong_cast(n-&gt;getd()) == 0);
 4466   match(ConD);
 4467 
 4468   op_cost(0);
 4469   format %{ %}
 4470   interface(CONST_INTER);
 4471 %}
 4472 
 4473 // constant &#39;double +0.0&#39;.
 4474 operand immDPacked()
 4475 %{
 4476   predicate(Assembler::operand_valid_for_float_immediate(n-&gt;getd()));
 4477   match(ConD);
 4478   op_cost(0);
 4479   format %{ %}
 4480   interface(CONST_INTER);
 4481 %}
 4482 
 4483 // Float Immediate
 4484 operand immF()
 4485 %{
 4486   match(ConF);
 4487   op_cost(0);
 4488   format %{ %}
 4489   interface(CONST_INTER);
 4490 %}
 4491 
 4492 // Float Immediate: +0.0f.
 4493 operand immF0()
 4494 %{
 4495   predicate(jint_cast(n-&gt;getf()) == 0);
 4496   match(ConF);
 4497 
 4498   op_cost(0);
 4499   format %{ %}
 4500   interface(CONST_INTER);
 4501 %}
 4502 
 4503 //
 4504 operand immFPacked()
 4505 %{
 4506   predicate(Assembler::operand_valid_for_float_immediate((double)n-&gt;getf()));
 4507   match(ConF);
 4508   op_cost(0);
 4509   format %{ %}
 4510   interface(CONST_INTER);
 4511 %}
 4512 
 4513 // Narrow pointer operands
 4514 // Narrow Pointer Immediate
 4515 operand immN()
 4516 %{
 4517   match(ConN);
 4518 
 4519   op_cost(0);
 4520   format %{ %}
 4521   interface(CONST_INTER);
 4522 %}
 4523 
 4524 // Narrow NULL Pointer Immediate
 4525 operand immN0()
 4526 %{
 4527   predicate(n-&gt;get_narrowcon() == 0);
 4528   match(ConN);
 4529 
 4530   op_cost(0);
 4531   format %{ %}
 4532   interface(CONST_INTER);
 4533 %}
 4534 
 4535 operand immNKlass()
 4536 %{
 4537   match(ConNKlass);
 4538 
 4539   op_cost(0);
 4540   format %{ %}
 4541   interface(CONST_INTER);
 4542 %}
 4543 
 4544 // Integer 32 bit Register Operands
 4545 // Integer 32 bitRegister (excludes SP)
 4546 operand iRegI()
 4547 %{
 4548   constraint(ALLOC_IN_RC(any_reg32));
 4549   match(RegI);
 4550   match(iRegINoSp);
 4551   op_cost(0);
 4552   format %{ %}
 4553   interface(REG_INTER);
 4554 %}
 4555 
 4556 // Integer 32 bit Register not Special
 4557 operand iRegINoSp()
 4558 %{
 4559   constraint(ALLOC_IN_RC(no_special_reg32));
 4560   match(RegI);
 4561   op_cost(0);
 4562   format %{ %}
 4563   interface(REG_INTER);
 4564 %}
 4565 
 4566 // Integer 64 bit Register Operands
 4567 // Integer 64 bit Register (includes SP)
 4568 operand iRegL()
 4569 %{
 4570   constraint(ALLOC_IN_RC(any_reg));
 4571   match(RegL);
 4572   match(iRegLNoSp);
 4573   op_cost(0);
 4574   format %{ %}
 4575   interface(REG_INTER);
 4576 %}
 4577 
 4578 // Integer 64 bit Register not Special
 4579 operand iRegLNoSp()
 4580 %{
 4581   constraint(ALLOC_IN_RC(no_special_reg));
 4582   match(RegL);
 4583   match(iRegL_R0);
 4584   format %{ %}
 4585   interface(REG_INTER);
 4586 %}
 4587 
 4588 // Pointer Register Operands
 4589 // Pointer Register
 4590 operand iRegP()
 4591 %{
 4592   constraint(ALLOC_IN_RC(ptr_reg));
 4593   match(RegP);
 4594   match(iRegPNoSp);
 4595   match(iRegP_R0);
 4596   //match(iRegP_R2);
 4597   //match(iRegP_R4);
 4598   //match(iRegP_R5);
 4599   match(thread_RegP);
 4600   op_cost(0);
 4601   format %{ %}
 4602   interface(REG_INTER);
 4603 %}
 4604 
 4605 // Pointer 64 bit Register not Special
 4606 operand iRegPNoSp()
 4607 %{
 4608   constraint(ALLOC_IN_RC(no_special_ptr_reg));
 4609   match(RegP);
 4610   // match(iRegP);
 4611   // match(iRegP_R0);
 4612   // match(iRegP_R2);
 4613   // match(iRegP_R4);
 4614   // match(iRegP_R5);
 4615   // match(thread_RegP);
 4616   op_cost(0);
 4617   format %{ %}
 4618   interface(REG_INTER);
 4619 %}
 4620 
 4621 // Pointer 64 bit Register R0 only
 4622 operand iRegP_R0()
 4623 %{
 4624   constraint(ALLOC_IN_RC(r0_reg));
 4625   match(RegP);
 4626   // match(iRegP);
 4627   match(iRegPNoSp);
 4628   op_cost(0);
 4629   format %{ %}
 4630   interface(REG_INTER);
 4631 %}
 4632 
 4633 // Pointer 64 bit Register R1 only
 4634 operand iRegP_R1()
 4635 %{
 4636   constraint(ALLOC_IN_RC(r1_reg));
 4637   match(RegP);
 4638   // match(iRegP);
 4639   match(iRegPNoSp);
 4640   op_cost(0);
 4641   format %{ %}
 4642   interface(REG_INTER);
 4643 %}
 4644 
 4645 // Pointer 64 bit Register R2 only
 4646 operand iRegP_R2()
 4647 %{
 4648   constraint(ALLOC_IN_RC(r2_reg));
 4649   match(RegP);
 4650   // match(iRegP);
 4651   match(iRegPNoSp);
 4652   op_cost(0);
 4653   format %{ %}
 4654   interface(REG_INTER);
 4655 %}
 4656 
 4657 // Pointer 64 bit Register R3 only
 4658 operand iRegP_R3()
 4659 %{
 4660   constraint(ALLOC_IN_RC(r3_reg));
 4661   match(RegP);
 4662   // match(iRegP);
 4663   match(iRegPNoSp);
 4664   op_cost(0);
 4665   format %{ %}
 4666   interface(REG_INTER);
 4667 %}
 4668 
 4669 // Pointer 64 bit Register R4 only
 4670 operand iRegP_R4()
 4671 %{
 4672   constraint(ALLOC_IN_RC(r4_reg));
 4673   match(RegP);
 4674   // match(iRegP);
 4675   match(iRegPNoSp);
 4676   op_cost(0);
 4677   format %{ %}
 4678   interface(REG_INTER);
 4679 %}
 4680 
 4681 // Pointer 64 bit Register R5 only
 4682 operand iRegP_R5()
 4683 %{
 4684   constraint(ALLOC_IN_RC(r5_reg));
 4685   match(RegP);
 4686   // match(iRegP);
 4687   match(iRegPNoSp);
 4688   op_cost(0);
 4689   format %{ %}
 4690   interface(REG_INTER);
 4691 %}
 4692 
 4693 // Pointer 64 bit Register R10 only
 4694 operand iRegP_R10()
 4695 %{
 4696   constraint(ALLOC_IN_RC(r10_reg));
 4697   match(RegP);
 4698   // match(iRegP);
 4699   match(iRegPNoSp);
 4700   op_cost(0);
 4701   format %{ %}
 4702   interface(REG_INTER);
 4703 %}
 4704 
 4705 // Long 64 bit Register R0 only
 4706 operand iRegL_R0()
 4707 %{
 4708   constraint(ALLOC_IN_RC(r0_reg));
 4709   match(RegL);
 4710   match(iRegLNoSp);
 4711   op_cost(0);
 4712   format %{ %}
 4713   interface(REG_INTER);
 4714 %}
 4715 
 4716 // Long 64 bit Register R2 only
 4717 operand iRegL_R2()
 4718 %{
 4719   constraint(ALLOC_IN_RC(r2_reg));
 4720   match(RegL);
 4721   match(iRegLNoSp);
 4722   op_cost(0);
 4723   format %{ %}
 4724   interface(REG_INTER);
 4725 %}
 4726 
 4727 // Long 64 bit Register R3 only
 4728 operand iRegL_R3()
 4729 %{
 4730   constraint(ALLOC_IN_RC(r3_reg));
 4731   match(RegL);
 4732   match(iRegLNoSp);
 4733   op_cost(0);
 4734   format %{ %}
 4735   interface(REG_INTER);
 4736 %}
 4737 
 4738 // Long 64 bit Register R11 only
 4739 operand iRegL_R11()
 4740 %{
 4741   constraint(ALLOC_IN_RC(r11_reg));
 4742   match(RegL);
 4743   match(iRegLNoSp);
 4744   op_cost(0);
 4745   format %{ %}
 4746   interface(REG_INTER);
 4747 %}
 4748 
 4749 // Pointer 64 bit Register FP only
 4750 operand iRegP_FP()
 4751 %{
 4752   constraint(ALLOC_IN_RC(fp_reg));
 4753   match(RegP);
 4754   // match(iRegP);
 4755   op_cost(0);
 4756   format %{ %}
 4757   interface(REG_INTER);
 4758 %}
 4759 
 4760 // Register R0 only
 4761 operand iRegI_R0()
 4762 %{
 4763   constraint(ALLOC_IN_RC(int_r0_reg));
 4764   match(RegI);
 4765   match(iRegINoSp);
 4766   op_cost(0);
 4767   format %{ %}
 4768   interface(REG_INTER);
 4769 %}
 4770 
 4771 // Register R2 only
 4772 operand iRegI_R2()
 4773 %{
 4774   constraint(ALLOC_IN_RC(int_r2_reg));
 4775   match(RegI);
 4776   match(iRegINoSp);
 4777   op_cost(0);
 4778   format %{ %}
 4779   interface(REG_INTER);
 4780 %}
 4781 
 4782 // Register R3 only
 4783 operand iRegI_R3()
 4784 %{
 4785   constraint(ALLOC_IN_RC(int_r3_reg));
 4786   match(RegI);
 4787   match(iRegINoSp);
 4788   op_cost(0);
 4789   format %{ %}
 4790   interface(REG_INTER);
 4791 %}
 4792 
 4793 
 4794 // Register R4 only
 4795 operand iRegI_R4()
 4796 %{
 4797   constraint(ALLOC_IN_RC(int_r4_reg));
 4798   match(RegI);
 4799   match(iRegINoSp);
 4800   op_cost(0);
 4801   format %{ %}
 4802   interface(REG_INTER);
 4803 %}
 4804 
 4805 
 4806 // Pointer Register Operands
 4807 // Narrow Pointer Register
 4808 operand iRegN()
 4809 %{
 4810   constraint(ALLOC_IN_RC(any_reg32));
 4811   match(RegN);
 4812   match(iRegNNoSp);
 4813   op_cost(0);
 4814   format %{ %}
 4815   interface(REG_INTER);
 4816 %}
 4817 
 4818 operand iRegN_R0()
 4819 %{
 4820   constraint(ALLOC_IN_RC(r0_reg));
 4821   match(iRegN);
 4822   op_cost(0);
 4823   format %{ %}
 4824   interface(REG_INTER);
 4825 %}
 4826 
 4827 operand iRegN_R2()
 4828 %{
 4829   constraint(ALLOC_IN_RC(r2_reg));
 4830   match(iRegN);
 4831   op_cost(0);
 4832   format %{ %}
 4833   interface(REG_INTER);
 4834 %}
 4835 
 4836 operand iRegN_R3()
 4837 %{
 4838   constraint(ALLOC_IN_RC(r3_reg));
 4839   match(iRegN);
 4840   op_cost(0);
 4841   format %{ %}
 4842   interface(REG_INTER);
 4843 %}
 4844 
 4845 // Integer 64 bit Register not Special
 4846 operand iRegNNoSp()
 4847 %{
 4848   constraint(ALLOC_IN_RC(no_special_reg32));
 4849   match(RegN);
 4850   op_cost(0);
 4851   format %{ %}
 4852   interface(REG_INTER);
 4853 %}
 4854 
 4855 // heap base register -- used for encoding immN0
 4856 
 4857 operand iRegIHeapbase()
 4858 %{
 4859   constraint(ALLOC_IN_RC(heapbase_reg));
 4860   match(RegI);
 4861   op_cost(0);
 4862   format %{ %}
 4863   interface(REG_INTER);
 4864 %}
 4865 
 4866 // Float Register
 4867 // Float register operands
 4868 operand vRegF()
 4869 %{
 4870   constraint(ALLOC_IN_RC(float_reg));
 4871   match(RegF);
 4872 
 4873   op_cost(0);
 4874   format %{ %}
 4875   interface(REG_INTER);
 4876 %}
 4877 
 4878 // Double Register
 4879 // Double register operands
 4880 operand vRegD()
 4881 %{
 4882   constraint(ALLOC_IN_RC(double_reg));
 4883   match(RegD);
 4884 
 4885   op_cost(0);
 4886   format %{ %}
 4887   interface(REG_INTER);
 4888 %}
 4889 
 4890 operand vecD()
 4891 %{
 4892   constraint(ALLOC_IN_RC(vectord_reg));
 4893   match(VecD);
 4894 
 4895   op_cost(0);
 4896   format %{ %}
 4897   interface(REG_INTER);
 4898 %}
 4899 
 4900 operand vecX()
 4901 %{
 4902   constraint(ALLOC_IN_RC(vectorx_reg));
 4903   match(VecX);
 4904 
 4905   op_cost(0);
 4906   format %{ %}
 4907   interface(REG_INTER);
 4908 %}
 4909 
 4910 operand vRegD_V0()
 4911 %{
 4912   constraint(ALLOC_IN_RC(v0_reg));
 4913   match(RegD);
 4914   op_cost(0);
 4915   format %{ %}
 4916   interface(REG_INTER);
 4917 %}
 4918 
 4919 operand vRegD_V1()
 4920 %{
 4921   constraint(ALLOC_IN_RC(v1_reg));
 4922   match(RegD);
 4923   op_cost(0);
 4924   format %{ %}
 4925   interface(REG_INTER);
 4926 %}
 4927 
 4928 operand vRegD_V2()
 4929 %{
 4930   constraint(ALLOC_IN_RC(v2_reg));
 4931   match(RegD);
 4932   op_cost(0);
 4933   format %{ %}
 4934   interface(REG_INTER);
 4935 %}
 4936 
 4937 operand vRegD_V3()
 4938 %{
 4939   constraint(ALLOC_IN_RC(v3_reg));
 4940   match(RegD);
 4941   op_cost(0);
 4942   format %{ %}
 4943   interface(REG_INTER);
 4944 %}
 4945 
 4946 operand vRegD_V4()
 4947 %{
 4948   constraint(ALLOC_IN_RC(v4_reg));
 4949   match(RegD);
 4950   op_cost(0);
 4951   format %{ %}
 4952   interface(REG_INTER);
 4953 %}
 4954 
 4955 operand vRegD_V5()
 4956 %{
 4957   constraint(ALLOC_IN_RC(v5_reg));
 4958   match(RegD);
 4959   op_cost(0);
 4960   format %{ %}
 4961   interface(REG_INTER);
 4962 %}
 4963 
 4964 operand vRegD_V6()
 4965 %{
 4966   constraint(ALLOC_IN_RC(v6_reg));
 4967   match(RegD);
 4968   op_cost(0);
 4969   format %{ %}
 4970   interface(REG_INTER);
 4971 %}
 4972 
 4973 operand vRegD_V7()
 4974 %{
 4975   constraint(ALLOC_IN_RC(v7_reg));
 4976   match(RegD);
 4977   op_cost(0);
 4978   format %{ %}
 4979   interface(REG_INTER);
 4980 %}
 4981 
 4982 operand vRegD_V8()
 4983 %{
 4984   constraint(ALLOC_IN_RC(v8_reg));
 4985   match(RegD);
 4986   op_cost(0);
 4987   format %{ %}
 4988   interface(REG_INTER);
 4989 %}
 4990 
 4991 operand vRegD_V9()
 4992 %{
 4993   constraint(ALLOC_IN_RC(v9_reg));
 4994   match(RegD);
 4995   op_cost(0);
 4996   format %{ %}
 4997   interface(REG_INTER);
 4998 %}
 4999 
 5000 operand vRegD_V10()
 5001 %{
 5002   constraint(ALLOC_IN_RC(v10_reg));
 5003   match(RegD);
 5004   op_cost(0);
 5005   format %{ %}
 5006   interface(REG_INTER);
 5007 %}
 5008 
 5009 operand vRegD_V11()
 5010 %{
 5011   constraint(ALLOC_IN_RC(v11_reg));
 5012   match(RegD);
 5013   op_cost(0);
 5014   format %{ %}
 5015   interface(REG_INTER);
 5016 %}
 5017 
 5018 operand vRegD_V12()
 5019 %{
 5020   constraint(ALLOC_IN_RC(v12_reg));
 5021   match(RegD);
 5022   op_cost(0);
 5023   format %{ %}
 5024   interface(REG_INTER);
 5025 %}
 5026 
 5027 operand vRegD_V13()
 5028 %{
 5029   constraint(ALLOC_IN_RC(v13_reg));
 5030   match(RegD);
 5031   op_cost(0);
 5032   format %{ %}
 5033   interface(REG_INTER);
 5034 %}
 5035 
 5036 operand vRegD_V14()
 5037 %{
 5038   constraint(ALLOC_IN_RC(v14_reg));
 5039   match(RegD);
 5040   op_cost(0);
 5041   format %{ %}
 5042   interface(REG_INTER);
 5043 %}
 5044 
 5045 operand vRegD_V15()
 5046 %{
 5047   constraint(ALLOC_IN_RC(v15_reg));
 5048   match(RegD);
 5049   op_cost(0);
 5050   format %{ %}
 5051   interface(REG_INTER);
 5052 %}
 5053 
 5054 operand vRegD_V16()
 5055 %{
 5056   constraint(ALLOC_IN_RC(v16_reg));
 5057   match(RegD);
 5058   op_cost(0);
 5059   format %{ %}
 5060   interface(REG_INTER);
 5061 %}
 5062 
 5063 operand vRegD_V17()
 5064 %{
 5065   constraint(ALLOC_IN_RC(v17_reg));
 5066   match(RegD);
 5067   op_cost(0);
 5068   format %{ %}
 5069   interface(REG_INTER);
 5070 %}
 5071 
 5072 operand vRegD_V18()
 5073 %{
 5074   constraint(ALLOC_IN_RC(v18_reg));
 5075   match(RegD);
 5076   op_cost(0);
 5077   format %{ %}
 5078   interface(REG_INTER);
 5079 %}
 5080 
 5081 operand vRegD_V19()
 5082 %{
 5083   constraint(ALLOC_IN_RC(v19_reg));
 5084   match(RegD);
 5085   op_cost(0);
 5086   format %{ %}
 5087   interface(REG_INTER);
 5088 %}
 5089 
 5090 operand vRegD_V20()
 5091 %{
 5092   constraint(ALLOC_IN_RC(v20_reg));
 5093   match(RegD);
 5094   op_cost(0);
 5095   format %{ %}
 5096   interface(REG_INTER);
 5097 %}
 5098 
 5099 operand vRegD_V21()
 5100 %{
 5101   constraint(ALLOC_IN_RC(v21_reg));
 5102   match(RegD);
 5103   op_cost(0);
 5104   format %{ %}
 5105   interface(REG_INTER);
 5106 %}
 5107 
 5108 operand vRegD_V22()
 5109 %{
 5110   constraint(ALLOC_IN_RC(v22_reg));
 5111   match(RegD);
 5112   op_cost(0);
 5113   format %{ %}
 5114   interface(REG_INTER);
 5115 %}
 5116 
 5117 operand vRegD_V23()
 5118 %{
 5119   constraint(ALLOC_IN_RC(v23_reg));
 5120   match(RegD);
 5121   op_cost(0);
 5122   format %{ %}
 5123   interface(REG_INTER);
 5124 %}
 5125 
 5126 operand vRegD_V24()
 5127 %{
 5128   constraint(ALLOC_IN_RC(v24_reg));
 5129   match(RegD);
 5130   op_cost(0);
 5131   format %{ %}
 5132   interface(REG_INTER);
 5133 %}
 5134 
 5135 operand vRegD_V25()
 5136 %{
 5137   constraint(ALLOC_IN_RC(v25_reg));
 5138   match(RegD);
 5139   op_cost(0);
 5140   format %{ %}
 5141   interface(REG_INTER);
 5142 %}
 5143 
 5144 operand vRegD_V26()
 5145 %{
 5146   constraint(ALLOC_IN_RC(v26_reg));
 5147   match(RegD);
 5148   op_cost(0);
 5149   format %{ %}
 5150   interface(REG_INTER);
 5151 %}
 5152 
 5153 operand vRegD_V27()
 5154 %{
 5155   constraint(ALLOC_IN_RC(v27_reg));
 5156   match(RegD);
 5157   op_cost(0);
 5158   format %{ %}
 5159   interface(REG_INTER);
 5160 %}
 5161 
 5162 operand vRegD_V28()
 5163 %{
 5164   constraint(ALLOC_IN_RC(v28_reg));
 5165   match(RegD);
 5166   op_cost(0);
 5167   format %{ %}
 5168   interface(REG_INTER);
 5169 %}
 5170 
 5171 operand vRegD_V29()
 5172 %{
 5173   constraint(ALLOC_IN_RC(v29_reg));
 5174   match(RegD);
 5175   op_cost(0);
 5176   format %{ %}
 5177   interface(REG_INTER);
 5178 %}
 5179 
 5180 operand vRegD_V30()
 5181 %{
 5182   constraint(ALLOC_IN_RC(v30_reg));
 5183   match(RegD);
 5184   op_cost(0);
 5185   format %{ %}
 5186   interface(REG_INTER);
 5187 %}
 5188 
 5189 operand vRegD_V31()
 5190 %{
 5191   constraint(ALLOC_IN_RC(v31_reg));
 5192   match(RegD);
 5193   op_cost(0);
 5194   format %{ %}
 5195   interface(REG_INTER);
 5196 %}
 5197 
 5198 // Flags register, used as output of signed compare instructions
 5199 
 5200 // note that on AArch64 we also use this register as the output for
 5201 // for floating point compare instructions (CmpF CmpD). this ensures
 5202 // that ordered inequality tests use GT, GE, LT or LE none of which
 5203 // pass through cases where the result is unordered i.e. one or both
 5204 // inputs to the compare is a NaN. this means that the ideal code can
 5205 // replace e.g. a GT with an LE and not end up capturing the NaN case
 5206 // (where the comparison should always fail). EQ and NE tests are
 5207 // always generated in ideal code so that unordered folds into the NE
 5208 // case, matching the behaviour of AArch64 NE.
 5209 //
 5210 // This differs from x86 where the outputs of FP compares use a
 5211 // special FP flags registers and where compares based on this
 5212 // register are distinguished into ordered inequalities (cmpOpUCF) and
 5213 // EQ/NEQ tests (cmpOpUCF2). x86 has to special case the latter tests
 5214 // to explicitly handle the unordered case in branches. x86 also has
 5215 // to include extra CMoveX rules to accept a cmpOpUCF input.
 5216 
 5217 operand rFlagsReg()
 5218 %{
 5219   constraint(ALLOC_IN_RC(int_flags));
 5220   match(RegFlags);
 5221 
 5222   op_cost(0);
 5223   format %{ &quot;RFLAGS&quot; %}
 5224   interface(REG_INTER);
 5225 %}
 5226 
 5227 // Flags register, used as output of unsigned compare instructions
 5228 operand rFlagsRegU()
 5229 %{
 5230   constraint(ALLOC_IN_RC(int_flags));
 5231   match(RegFlags);
 5232 
 5233   op_cost(0);
 5234   format %{ &quot;RFLAGSU&quot; %}
 5235   interface(REG_INTER);
 5236 %}
 5237 
 5238 // Special Registers
 5239 
 5240 // Method Register
 5241 operand inline_cache_RegP(iRegP reg)
 5242 %{
 5243   constraint(ALLOC_IN_RC(method_reg)); // inline_cache_reg
 5244   match(reg);
 5245   match(iRegPNoSp);
 5246   op_cost(0);
 5247   format %{ %}
 5248   interface(REG_INTER);
 5249 %}
 5250 
 5251 operand interpreter_method_oop_RegP(iRegP reg)
 5252 %{
 5253   constraint(ALLOC_IN_RC(method_reg)); // interpreter_method_oop_reg
 5254   match(reg);
 5255   match(iRegPNoSp);
 5256   op_cost(0);
 5257   format %{ %}
 5258   interface(REG_INTER);
 5259 %}
 5260 
 5261 // Thread Register
 5262 operand thread_RegP(iRegP reg)
 5263 %{
 5264   constraint(ALLOC_IN_RC(thread_reg)); // link_reg
 5265   match(reg);
 5266   op_cost(0);
 5267   format %{ %}
 5268   interface(REG_INTER);
 5269 %}
 5270 
 5271 operand lr_RegP(iRegP reg)
 5272 %{
 5273   constraint(ALLOC_IN_RC(lr_reg)); // link_reg
 5274   match(reg);
 5275   op_cost(0);
 5276   format %{ %}
 5277   interface(REG_INTER);
 5278 %}
 5279 
 5280 //----------Memory Operands----------------------------------------------------
 5281 
 5282 operand indirect(iRegP reg)
 5283 %{
 5284   constraint(ALLOC_IN_RC(ptr_reg));
 5285   match(reg);
 5286   op_cost(0);
 5287   format %{ &quot;[$reg]&quot; %}
 5288   interface(MEMORY_INTER) %{
 5289     base($reg);
 5290     index(0xffffffff);
 5291     scale(0x0);
 5292     disp(0x0);
 5293   %}
 5294 %}
 5295 
 5296 operand indIndexScaledI2L(iRegP reg, iRegI ireg, immIScale scale)
 5297 %{
 5298   constraint(ALLOC_IN_RC(ptr_reg));
 5299   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5300   match(AddP reg (LShiftL (ConvI2L ireg) scale));
 5301   op_cost(0);
 5302   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L&quot; %}
 5303   interface(MEMORY_INTER) %{
 5304     base($reg);
 5305     index($ireg);
 5306     scale($scale);
 5307     disp(0x0);
 5308   %}
 5309 %}
 5310 
 5311 operand indIndexScaled(iRegP reg, iRegL lreg, immIScale scale)
 5312 %{
 5313   constraint(ALLOC_IN_RC(ptr_reg));
 5314   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5315   match(AddP reg (LShiftL lreg scale));
 5316   op_cost(0);
 5317   format %{ &quot;$reg, $lreg lsl($scale)&quot; %}
 5318   interface(MEMORY_INTER) %{
 5319     base($reg);
 5320     index($lreg);
 5321     scale($scale);
 5322     disp(0x0);
 5323   %}
 5324 %}
 5325 
 5326 operand indIndexI2L(iRegP reg, iRegI ireg)
 5327 %{
 5328   constraint(ALLOC_IN_RC(ptr_reg));
 5329   match(AddP reg (ConvI2L ireg));
 5330   op_cost(0);
 5331   format %{ &quot;$reg, $ireg, 0, I2L&quot; %}
 5332   interface(MEMORY_INTER) %{
 5333     base($reg);
 5334     index($ireg);
 5335     scale(0x0);
 5336     disp(0x0);
 5337   %}
 5338 %}
 5339 
 5340 operand indIndex(iRegP reg, iRegL lreg)
 5341 %{
 5342   constraint(ALLOC_IN_RC(ptr_reg));
 5343   match(AddP reg lreg);
 5344   op_cost(0);
 5345   format %{ &quot;$reg, $lreg&quot; %}
 5346   interface(MEMORY_INTER) %{
 5347     base($reg);
 5348     index($lreg);
 5349     scale(0x0);
 5350     disp(0x0);
 5351   %}
 5352 %}
 5353 
 5354 operand indOffI(iRegP reg, immIOffset off)
 5355 %{
 5356   constraint(ALLOC_IN_RC(ptr_reg));
 5357   match(AddP reg off);
 5358   op_cost(0);
 5359   format %{ &quot;[$reg, $off]&quot; %}
 5360   interface(MEMORY_INTER) %{
 5361     base($reg);
 5362     index(0xffffffff);
 5363     scale(0x0);
 5364     disp($off);
 5365   %}
 5366 %}
 5367 
 5368 operand indOffI1(iRegP reg, immIOffset1 off)
 5369 %{
 5370   constraint(ALLOC_IN_RC(ptr_reg));
 5371   match(AddP reg off);
 5372   op_cost(0);
 5373   format %{ &quot;[$reg, $off]&quot; %}
 5374   interface(MEMORY_INTER) %{
 5375     base($reg);
 5376     index(0xffffffff);
 5377     scale(0x0);
 5378     disp($off);
 5379   %}
 5380 %}
 5381 
 5382 operand indOffI2(iRegP reg, immIOffset2 off)
 5383 %{
 5384   constraint(ALLOC_IN_RC(ptr_reg));
 5385   match(AddP reg off);
 5386   op_cost(0);
 5387   format %{ &quot;[$reg, $off]&quot; %}
 5388   interface(MEMORY_INTER) %{
 5389     base($reg);
 5390     index(0xffffffff);
 5391     scale(0x0);
 5392     disp($off);
 5393   %}
 5394 %}
 5395 
 5396 operand indOffI4(iRegP reg, immIOffset4 off)
 5397 %{
 5398   constraint(ALLOC_IN_RC(ptr_reg));
 5399   match(AddP reg off);
 5400   op_cost(0);
 5401   format %{ &quot;[$reg, $off]&quot; %}
 5402   interface(MEMORY_INTER) %{
 5403     base($reg);
 5404     index(0xffffffff);
 5405     scale(0x0);
 5406     disp($off);
 5407   %}
 5408 %}
 5409 
 5410 operand indOffI8(iRegP reg, immIOffset8 off)
 5411 %{
 5412   constraint(ALLOC_IN_RC(ptr_reg));
 5413   match(AddP reg off);
 5414   op_cost(0);
 5415   format %{ &quot;[$reg, $off]&quot; %}
 5416   interface(MEMORY_INTER) %{
 5417     base($reg);
 5418     index(0xffffffff);
 5419     scale(0x0);
 5420     disp($off);
 5421   %}
 5422 %}
 5423 
 5424 operand indOffI16(iRegP reg, immIOffset16 off)
 5425 %{
 5426   constraint(ALLOC_IN_RC(ptr_reg));
 5427   match(AddP reg off);
 5428   op_cost(0);
 5429   format %{ &quot;[$reg, $off]&quot; %}
 5430   interface(MEMORY_INTER) %{
 5431     base($reg);
 5432     index(0xffffffff);
 5433     scale(0x0);
 5434     disp($off);
 5435   %}
 5436 %}
 5437 
 5438 operand indOffL(iRegP reg, immLoffset off)
 5439 %{
 5440   constraint(ALLOC_IN_RC(ptr_reg));
 5441   match(AddP reg off);
 5442   op_cost(0);
 5443   format %{ &quot;[$reg, $off]&quot; %}
 5444   interface(MEMORY_INTER) %{
 5445     base($reg);
 5446     index(0xffffffff);
 5447     scale(0x0);
 5448     disp($off);
 5449   %}
 5450 %}
 5451 
 5452 operand indOffL1(iRegP reg, immLoffset1 off)
 5453 %{
 5454   constraint(ALLOC_IN_RC(ptr_reg));
 5455   match(AddP reg off);
 5456   op_cost(0);
 5457   format %{ &quot;[$reg, $off]&quot; %}
 5458   interface(MEMORY_INTER) %{
 5459     base($reg);
 5460     index(0xffffffff);
 5461     scale(0x0);
 5462     disp($off);
 5463   %}
 5464 %}
 5465 
 5466 operand indOffL2(iRegP reg, immLoffset2 off)
 5467 %{
 5468   constraint(ALLOC_IN_RC(ptr_reg));
 5469   match(AddP reg off);
 5470   op_cost(0);
 5471   format %{ &quot;[$reg, $off]&quot; %}
 5472   interface(MEMORY_INTER) %{
 5473     base($reg);
 5474     index(0xffffffff);
 5475     scale(0x0);
 5476     disp($off);
 5477   %}
 5478 %}
 5479 
 5480 operand indOffL4(iRegP reg, immLoffset4 off)
 5481 %{
 5482   constraint(ALLOC_IN_RC(ptr_reg));
 5483   match(AddP reg off);
 5484   op_cost(0);
 5485   format %{ &quot;[$reg, $off]&quot; %}
 5486   interface(MEMORY_INTER) %{
 5487     base($reg);
 5488     index(0xffffffff);
 5489     scale(0x0);
 5490     disp($off);
 5491   %}
 5492 %}
 5493 
 5494 operand indOffL8(iRegP reg, immLoffset8 off)
 5495 %{
 5496   constraint(ALLOC_IN_RC(ptr_reg));
 5497   match(AddP reg off);
 5498   op_cost(0);
 5499   format %{ &quot;[$reg, $off]&quot; %}
 5500   interface(MEMORY_INTER) %{
 5501     base($reg);
 5502     index(0xffffffff);
 5503     scale(0x0);
 5504     disp($off);
 5505   %}
 5506 %}
 5507 
 5508 operand indOffL16(iRegP reg, immLoffset16 off)
 5509 %{
 5510   constraint(ALLOC_IN_RC(ptr_reg));
 5511   match(AddP reg off);
 5512   op_cost(0);
 5513   format %{ &quot;[$reg, $off]&quot; %}
 5514   interface(MEMORY_INTER) %{
 5515     base($reg);
 5516     index(0xffffffff);
 5517     scale(0x0);
 5518     disp($off);
 5519   %}
 5520 %}
 5521 
 5522 operand indirectN(iRegN reg)
 5523 %{
 5524   predicate(CompressedOops::shift() == 0);
 5525   constraint(ALLOC_IN_RC(ptr_reg));
 5526   match(DecodeN reg);
 5527   op_cost(0);
 5528   format %{ &quot;[$reg]\t# narrow&quot; %}
 5529   interface(MEMORY_INTER) %{
 5530     base($reg);
 5531     index(0xffffffff);
 5532     scale(0x0);
 5533     disp(0x0);
 5534   %}
 5535 %}
 5536 
 5537 operand indIndexScaledI2LN(iRegN reg, iRegI ireg, immIScale scale)
 5538 %{
 5539   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5540   constraint(ALLOC_IN_RC(ptr_reg));
 5541   match(AddP (DecodeN reg) (LShiftL (ConvI2L ireg) scale));
 5542   op_cost(0);
 5543   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L\t# narrow&quot; %}
 5544   interface(MEMORY_INTER) %{
 5545     base($reg);
 5546     index($ireg);
 5547     scale($scale);
 5548     disp(0x0);
 5549   %}
 5550 %}
 5551 
 5552 operand indIndexScaledN(iRegN reg, iRegL lreg, immIScale scale)
 5553 %{
 5554   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5555   constraint(ALLOC_IN_RC(ptr_reg));
 5556   match(AddP (DecodeN reg) (LShiftL lreg scale));
 5557   op_cost(0);
 5558   format %{ &quot;$reg, $lreg lsl($scale)\t# narrow&quot; %}
 5559   interface(MEMORY_INTER) %{
 5560     base($reg);
 5561     index($lreg);
 5562     scale($scale);
 5563     disp(0x0);
 5564   %}
 5565 %}
 5566 
 5567 operand indIndexI2LN(iRegN reg, iRegI ireg)
 5568 %{
 5569   predicate(CompressedOops::shift() == 0);
 5570   constraint(ALLOC_IN_RC(ptr_reg));
 5571   match(AddP (DecodeN reg) (ConvI2L ireg));
 5572   op_cost(0);
 5573   format %{ &quot;$reg, $ireg, 0, I2L\t# narrow&quot; %}
 5574   interface(MEMORY_INTER) %{
 5575     base($reg);
 5576     index($ireg);
 5577     scale(0x0);
 5578     disp(0x0);
 5579   %}
 5580 %}
 5581 
 5582 operand indIndexN(iRegN reg, iRegL lreg)
 5583 %{
 5584   predicate(CompressedOops::shift() == 0);
 5585   constraint(ALLOC_IN_RC(ptr_reg));
 5586   match(AddP (DecodeN reg) lreg);
 5587   op_cost(0);
 5588   format %{ &quot;$reg, $lreg\t# narrow&quot; %}
 5589   interface(MEMORY_INTER) %{
 5590     base($reg);
 5591     index($lreg);
 5592     scale(0x0);
 5593     disp(0x0);
 5594   %}
 5595 %}
 5596 
 5597 operand indOffIN(iRegN reg, immIOffset off)
 5598 %{
 5599   predicate(CompressedOops::shift() == 0);
 5600   constraint(ALLOC_IN_RC(ptr_reg));
 5601   match(AddP (DecodeN reg) off);
 5602   op_cost(0);
 5603   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5604   interface(MEMORY_INTER) %{
 5605     base($reg);
 5606     index(0xffffffff);
 5607     scale(0x0);
 5608     disp($off);
 5609   %}
 5610 %}
 5611 
 5612 operand indOffLN(iRegN reg, immLoffset off)
 5613 %{
 5614   predicate(CompressedOops::shift() == 0);
 5615   constraint(ALLOC_IN_RC(ptr_reg));
 5616   match(AddP (DecodeN reg) off);
 5617   op_cost(0);
 5618   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5619   interface(MEMORY_INTER) %{
 5620     base($reg);
 5621     index(0xffffffff);
 5622     scale(0x0);
 5623     disp($off);
 5624   %}
 5625 %}
 5626 
 5627 
 5628 
 5629 // AArch64 opto stubs need to write to the pc slot in the thread anchor
 5630 operand thread_anchor_pc(thread_RegP reg, immL_pc_off off)
 5631 %{
 5632   constraint(ALLOC_IN_RC(ptr_reg));
 5633   match(AddP reg off);
 5634   op_cost(0);
 5635   format %{ &quot;[$reg, $off]&quot; %}
 5636   interface(MEMORY_INTER) %{
 5637     base($reg);
 5638     index(0xffffffff);
 5639     scale(0x0);
 5640     disp($off);
 5641   %}
 5642 %}
 5643 
 5644 //----------Special Memory Operands--------------------------------------------
 5645 // Stack Slot Operand - This operand is used for loading and storing temporary
 5646 //                      values on the stack where a match requires a value to
 5647 //                      flow through memory.
 5648 operand stackSlotP(sRegP reg)
 5649 %{
 5650   constraint(ALLOC_IN_RC(stack_slots));
 5651   op_cost(100);
 5652   // No match rule because this operand is only generated in matching
 5653   // match(RegP);
 5654   format %{ &quot;[$reg]&quot; %}
 5655   interface(MEMORY_INTER) %{
 5656     base(0x1e);  // RSP
 5657     index(0x0);  // No Index
 5658     scale(0x0);  // No Scale
 5659     disp($reg);  // Stack Offset
 5660   %}
 5661 %}
 5662 
 5663 operand stackSlotI(sRegI reg)
 5664 %{
 5665   constraint(ALLOC_IN_RC(stack_slots));
 5666   // No match rule because this operand is only generated in matching
 5667   // match(RegI);
 5668   format %{ &quot;[$reg]&quot; %}
 5669   interface(MEMORY_INTER) %{
 5670     base(0x1e);  // RSP
 5671     index(0x0);  // No Index
 5672     scale(0x0);  // No Scale
 5673     disp($reg);  // Stack Offset
 5674   %}
 5675 %}
 5676 
 5677 operand stackSlotF(sRegF reg)
 5678 %{
 5679   constraint(ALLOC_IN_RC(stack_slots));
 5680   // No match rule because this operand is only generated in matching
 5681   // match(RegF);
 5682   format %{ &quot;[$reg]&quot; %}
 5683   interface(MEMORY_INTER) %{
 5684     base(0x1e);  // RSP
 5685     index(0x0);  // No Index
 5686     scale(0x0);  // No Scale
 5687     disp($reg);  // Stack Offset
 5688   %}
 5689 %}
 5690 
 5691 operand stackSlotD(sRegD reg)
 5692 %{
 5693   constraint(ALLOC_IN_RC(stack_slots));
 5694   // No match rule because this operand is only generated in matching
 5695   // match(RegD);
 5696   format %{ &quot;[$reg]&quot; %}
 5697   interface(MEMORY_INTER) %{
 5698     base(0x1e);  // RSP
 5699     index(0x0);  // No Index
 5700     scale(0x0);  // No Scale
 5701     disp($reg);  // Stack Offset
 5702   %}
 5703 %}
 5704 
 5705 operand stackSlotL(sRegL reg)
 5706 %{
 5707   constraint(ALLOC_IN_RC(stack_slots));
 5708   // No match rule because this operand is only generated in matching
 5709   // match(RegL);
 5710   format %{ &quot;[$reg]&quot; %}
 5711   interface(MEMORY_INTER) %{
 5712     base(0x1e);  // RSP
 5713     index(0x0);  // No Index
 5714     scale(0x0);  // No Scale
 5715     disp($reg);  // Stack Offset
 5716   %}
 5717 %}
 5718 
 5719 // Operands for expressing Control Flow
 5720 // NOTE: Label is a predefined operand which should not be redefined in
 5721 //       the AD file. It is generically handled within the ADLC.
 5722 
 5723 //----------Conditional Branch Operands----------------------------------------
 5724 // Comparison Op  - This is the operation of the comparison, and is limited to
 5725 //                  the following set of codes:
 5726 //                  L (&lt;), LE (&lt;=), G (&gt;), GE (&gt;=), E (==), NE (!=)
 5727 //
 5728 // Other attributes of the comparison, such as unsignedness, are specified
 5729 // by the comparison instruction that sets a condition code flags register.
 5730 // That result is represented by a flags operand whose subtype is appropriate
 5731 // to the unsignedness (etc.) of the comparison.
 5732 //
 5733 // Later, the instruction which matches both the Comparison Op (a Bool) and
 5734 // the flags (produced by the Cmp) specifies the coding of the comparison op
 5735 // by matching a specific subtype of Bool operand below, such as cmpOpU.
 5736 
 5737 // used for signed integral comparisons and fp comparisons
 5738 
 5739 operand cmpOp()
 5740 %{
 5741   match(Bool);
 5742 
 5743   format %{ &quot;&quot; %}
 5744   interface(COND_INTER) %{
 5745     equal(0x0, &quot;eq&quot;);
 5746     not_equal(0x1, &quot;ne&quot;);
 5747     less(0xb, &quot;lt&quot;);
 5748     greater_equal(0xa, &quot;ge&quot;);
 5749     less_equal(0xd, &quot;le&quot;);
 5750     greater(0xc, &quot;gt&quot;);
 5751     overflow(0x6, &quot;vs&quot;);
 5752     no_overflow(0x7, &quot;vc&quot;);
 5753   %}
 5754 %}
 5755 
 5756 // used for unsigned integral comparisons
 5757 
 5758 operand cmpOpU()
 5759 %{
 5760   match(Bool);
 5761 
 5762   format %{ &quot;&quot; %}
 5763   interface(COND_INTER) %{
 5764     equal(0x0, &quot;eq&quot;);
 5765     not_equal(0x1, &quot;ne&quot;);
 5766     less(0x3, &quot;lo&quot;);
 5767     greater_equal(0x2, &quot;hs&quot;);
 5768     less_equal(0x9, &quot;ls&quot;);
 5769     greater(0x8, &quot;hi&quot;);
 5770     overflow(0x6, &quot;vs&quot;);
 5771     no_overflow(0x7, &quot;vc&quot;);
 5772   %}
 5773 %}
 5774 
 5775 // used for certain integral comparisons which can be
 5776 // converted to cbxx or tbxx instructions
 5777 
 5778 operand cmpOpEqNe()
 5779 %{
 5780   match(Bool);
 5781   op_cost(0);
 5782   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5783             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq);
 5784 
 5785   format %{ &quot;&quot; %}
 5786   interface(COND_INTER) %{
 5787     equal(0x0, &quot;eq&quot;);
 5788     not_equal(0x1, &quot;ne&quot;);
 5789     less(0xb, &quot;lt&quot;);
 5790     greater_equal(0xa, &quot;ge&quot;);
 5791     less_equal(0xd, &quot;le&quot;);
 5792     greater(0xc, &quot;gt&quot;);
 5793     overflow(0x6, &quot;vs&quot;);
 5794     no_overflow(0x7, &quot;vc&quot;);
 5795   %}
 5796 %}
 5797 
 5798 // used for certain integral comparisons which can be
 5799 // converted to cbxx or tbxx instructions
 5800 
 5801 operand cmpOpLtGe()
 5802 %{
 5803   match(Bool);
 5804   op_cost(0);
 5805 
 5806   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5807             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5808 
 5809   format %{ &quot;&quot; %}
 5810   interface(COND_INTER) %{
 5811     equal(0x0, &quot;eq&quot;);
 5812     not_equal(0x1, &quot;ne&quot;);
 5813     less(0xb, &quot;lt&quot;);
 5814     greater_equal(0xa, &quot;ge&quot;);
 5815     less_equal(0xd, &quot;le&quot;);
 5816     greater(0xc, &quot;gt&quot;);
 5817     overflow(0x6, &quot;vs&quot;);
 5818     no_overflow(0x7, &quot;vc&quot;);
 5819   %}
 5820 %}
 5821 
 5822 // used for certain unsigned integral comparisons which can be
 5823 // converted to cbxx or tbxx instructions
 5824 
 5825 operand cmpOpUEqNeLtGe()
 5826 %{
 5827   match(Bool);
 5828   op_cost(0);
 5829 
 5830   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq
 5831             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5832             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5833             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5834 
 5835   format %{ &quot;&quot; %}
 5836   interface(COND_INTER) %{
 5837     equal(0x0, &quot;eq&quot;);
 5838     not_equal(0x1, &quot;ne&quot;);
 5839     less(0xb, &quot;lt&quot;);
 5840     greater_equal(0xa, &quot;ge&quot;);
 5841     less_equal(0xd, &quot;le&quot;);
 5842     greater(0xc, &quot;gt&quot;);
 5843     overflow(0x6, &quot;vs&quot;);
 5844     no_overflow(0x7, &quot;vc&quot;);
 5845   %}
 5846 %}
 5847 
 5848 // Special operand allowing long args to int ops to be truncated for free
 5849 
 5850 operand iRegL2I(iRegL reg) %{
 5851 
 5852   op_cost(0);
 5853 
 5854   match(ConvL2I reg);
 5855 
 5856   format %{ &quot;l2i($reg)&quot; %}
 5857 
 5858   interface(REG_INTER)
 5859 %}
 5860 
 5861 opclass vmem4(indirect, indIndex, indOffI4, indOffL4);
 5862 opclass vmem8(indirect, indIndex, indOffI8, indOffL8);
 5863 opclass vmem16(indirect, indIndex, indOffI16, indOffL16);
 5864 
 5865 //----------OPERAND CLASSES----------------------------------------------------
 5866 // Operand Classes are groups of operands that are used as to simplify
 5867 // instruction definitions by not requiring the AD writer to specify
 5868 // separate instructions for every form of operand when the
 5869 // instruction accepts multiple operand types with the same basic
 5870 // encoding and format. The classic case of this is memory operands.
 5871 
 5872 // memory is used to define read/write location for load/store
 5873 // instruction defs. we can turn a memory op into an Address
 5874 
 5875 opclass memory1(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI1, indOffL1,
 5876                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5877 
 5878 opclass memory2(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI2, indOffL2,
 5879                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5880 
 5881 opclass memory4(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI4, indOffL4,
 5882                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5883 
 5884 opclass memory8(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI8, indOffL8,
 5885                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5886 
 5887 // All of the memory operands. For the pipeline description.
 5888 opclass memory(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex,
 5889                indOffI1, indOffL1, indOffI2, indOffL2, indOffI4, indOffL4, indOffI8, indOffL8,
 5890                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5891 
 5892 
 5893 // iRegIorL2I is used for src inputs in rules for 32 bit int (I)
 5894 // operations. it allows the src to be either an iRegI or a (ConvL2I
 5895 // iRegL). in the latter case the l2i normally planted for a ConvL2I
 5896 // can be elided because the 32-bit instruction will just employ the
 5897 // lower 32 bits anyway.
 5898 //
 5899 // n.b. this does not elide all L2I conversions. if the truncated
 5900 // value is consumed by more than one operation then the ConvL2I
 5901 // cannot be bundled into the consuming nodes so an l2i gets planted
 5902 // (actually a movw $dst $src) and the downstream instructions consume
 5903 // the result of the l2i as an iRegI input. That&#39;s a shame since the
 5904 // movw is actually redundant but its not too costly.
 5905 
 5906 opclass iRegIorL2I(iRegI, iRegL2I);
 5907 
 5908 //----------PIPELINE-----------------------------------------------------------
 5909 // Rules which define the behavior of the target architectures pipeline.
 5910 
 5911 // For specific pipelines, eg A53, define the stages of that pipeline
 5912 //pipe_desc(ISS, EX1, EX2, WR);
 5913 #define ISS S0
 5914 #define EX1 S1
 5915 #define EX2 S2
 5916 #define WR  S3
 5917 
 5918 // Integer ALU reg operation
 5919 pipeline %{
 5920 
 5921 attributes %{
 5922   // ARM instructions are of fixed length
 5923   fixed_size_instructions;        // Fixed size instructions TODO does
 5924   max_instructions_per_bundle = 2;   // A53 = 2, A57 = 4
 5925   // ARM instructions come in 32-bit word units
 5926   instruction_unit_size = 4;         // An instruction is 4 bytes long
 5927   instruction_fetch_unit_size = 64;  // The processor fetches one line
 5928   instruction_fetch_units = 1;       // of 64 bytes
 5929 
 5930   // List of nop instructions
 5931   nops( MachNop );
 5932 %}
 5933 
 5934 // We don&#39;t use an actual pipeline model so don&#39;t care about resources
 5935 // or description. we do use pipeline classes to introduce fixed
 5936 // latencies
 5937 
 5938 //----------RESOURCES----------------------------------------------------------
 5939 // Resources are the functional units available to the machine
 5940 
 5941 resources( INS0, INS1, INS01 = INS0 | INS1,
 5942            ALU0, ALU1, ALU = ALU0 | ALU1,
 5943            MAC,
 5944            DIV,
 5945            BRANCH,
 5946            LDST,
 5947            NEON_FP);
 5948 
 5949 //----------PIPELINE DESCRIPTION-----------------------------------------------
 5950 // Pipeline Description specifies the stages in the machine&#39;s pipeline
 5951 
 5952 // Define the pipeline as a generic 6 stage pipeline
 5953 pipe_desc(S0, S1, S2, S3, S4, S5);
 5954 
 5955 //----------PIPELINE CLASSES---------------------------------------------------
 5956 // Pipeline Classes describe the stages in which input and output are
 5957 // referenced by the hardware pipeline.
 5958 
 5959 pipe_class fp_dop_reg_reg_s(vRegF dst, vRegF src1, vRegF src2)
 5960 %{
 5961   single_instruction;
 5962   src1   : S1(read);
 5963   src2   : S2(read);
 5964   dst    : S5(write);
 5965   INS01  : ISS;
 5966   NEON_FP : S5;
 5967 %}
 5968 
 5969 pipe_class fp_dop_reg_reg_d(vRegD dst, vRegD src1, vRegD src2)
 5970 %{
 5971   single_instruction;
 5972   src1   : S1(read);
 5973   src2   : S2(read);
 5974   dst    : S5(write);
 5975   INS01  : ISS;
 5976   NEON_FP : S5;
 5977 %}
 5978 
 5979 pipe_class fp_uop_s(vRegF dst, vRegF src)
 5980 %{
 5981   single_instruction;
 5982   src    : S1(read);
 5983   dst    : S5(write);
 5984   INS01  : ISS;
 5985   NEON_FP : S5;
 5986 %}
 5987 
 5988 pipe_class fp_uop_d(vRegD dst, vRegD src)
 5989 %{
 5990   single_instruction;
 5991   src    : S1(read);
 5992   dst    : S5(write);
 5993   INS01  : ISS;
 5994   NEON_FP : S5;
 5995 %}
 5996 
 5997 pipe_class fp_d2f(vRegF dst, vRegD src)
 5998 %{
 5999   single_instruction;
 6000   src    : S1(read);
 6001   dst    : S5(write);
 6002   INS01  : ISS;
 6003   NEON_FP : S5;
 6004 %}
 6005 
 6006 pipe_class fp_f2d(vRegD dst, vRegF src)
 6007 %{
 6008   single_instruction;
 6009   src    : S1(read);
 6010   dst    : S5(write);
 6011   INS01  : ISS;
 6012   NEON_FP : S5;
 6013 %}
 6014 
 6015 pipe_class fp_f2i(iRegINoSp dst, vRegF src)
 6016 %{
 6017   single_instruction;
 6018   src    : S1(read);
 6019   dst    : S5(write);
 6020   INS01  : ISS;
 6021   NEON_FP : S5;
 6022 %}
 6023 
 6024 pipe_class fp_f2l(iRegLNoSp dst, vRegF src)
 6025 %{
 6026   single_instruction;
 6027   src    : S1(read);
 6028   dst    : S5(write);
 6029   INS01  : ISS;
 6030   NEON_FP : S5;
 6031 %}
 6032 
 6033 pipe_class fp_i2f(vRegF dst, iRegIorL2I src)
 6034 %{
 6035   single_instruction;
 6036   src    : S1(read);
 6037   dst    : S5(write);
 6038   INS01  : ISS;
 6039   NEON_FP : S5;
 6040 %}
 6041 
 6042 pipe_class fp_l2f(vRegF dst, iRegL src)
 6043 %{
 6044   single_instruction;
 6045   src    : S1(read);
 6046   dst    : S5(write);
 6047   INS01  : ISS;
 6048   NEON_FP : S5;
 6049 %}
 6050 
 6051 pipe_class fp_d2i(iRegINoSp dst, vRegD src)
 6052 %{
 6053   single_instruction;
 6054   src    : S1(read);
 6055   dst    : S5(write);
 6056   INS01  : ISS;
 6057   NEON_FP : S5;
 6058 %}
 6059 
 6060 pipe_class fp_d2l(iRegLNoSp dst, vRegD src)
 6061 %{
 6062   single_instruction;
 6063   src    : S1(read);
 6064   dst    : S5(write);
 6065   INS01  : ISS;
 6066   NEON_FP : S5;
 6067 %}
 6068 
 6069 pipe_class fp_i2d(vRegD dst, iRegIorL2I src)
 6070 %{
 6071   single_instruction;
 6072   src    : S1(read);
 6073   dst    : S5(write);
 6074   INS01  : ISS;
 6075   NEON_FP : S5;
 6076 %}
 6077 
 6078 pipe_class fp_l2d(vRegD dst, iRegIorL2I src)
 6079 %{
 6080   single_instruction;
 6081   src    : S1(read);
 6082   dst    : S5(write);
 6083   INS01  : ISS;
 6084   NEON_FP : S5;
 6085 %}
 6086 
 6087 pipe_class fp_div_s(vRegF dst, vRegF src1, vRegF src2)
 6088 %{
 6089   single_instruction;
 6090   src1   : S1(read);
 6091   src2   : S2(read);
 6092   dst    : S5(write);
 6093   INS0   : ISS;
 6094   NEON_FP : S5;
 6095 %}
 6096 
 6097 pipe_class fp_div_d(vRegD dst, vRegD src1, vRegD src2)
 6098 %{
 6099   single_instruction;
 6100   src1   : S1(read);
 6101   src2   : S2(read);
 6102   dst    : S5(write);
 6103   INS0   : ISS;
 6104   NEON_FP : S5;
 6105 %}
 6106 
 6107 pipe_class fp_cond_reg_reg_s(vRegF dst, vRegF src1, vRegF src2, rFlagsReg cr)
 6108 %{
 6109   single_instruction;
 6110   cr     : S1(read);
 6111   src1   : S1(read);
 6112   src2   : S1(read);
 6113   dst    : S3(write);
 6114   INS01  : ISS;
 6115   NEON_FP : S3;
 6116 %}
 6117 
 6118 pipe_class fp_cond_reg_reg_d(vRegD dst, vRegD src1, vRegD src2, rFlagsReg cr)
 6119 %{
 6120   single_instruction;
 6121   cr     : S1(read);
 6122   src1   : S1(read);
 6123   src2   : S1(read);
 6124   dst    : S3(write);
 6125   INS01  : ISS;
 6126   NEON_FP : S3;
 6127 %}
 6128 
 6129 pipe_class fp_imm_s(vRegF dst)
 6130 %{
 6131   single_instruction;
 6132   dst    : S3(write);
 6133   INS01  : ISS;
 6134   NEON_FP : S3;
 6135 %}
 6136 
 6137 pipe_class fp_imm_d(vRegD dst)
 6138 %{
 6139   single_instruction;
 6140   dst    : S3(write);
 6141   INS01  : ISS;
 6142   NEON_FP : S3;
 6143 %}
 6144 
 6145 pipe_class fp_load_constant_s(vRegF dst)
 6146 %{
 6147   single_instruction;
 6148   dst    : S4(write);
 6149   INS01  : ISS;
 6150   NEON_FP : S4;
 6151 %}
 6152 
 6153 pipe_class fp_load_constant_d(vRegD dst)
 6154 %{
 6155   single_instruction;
 6156   dst    : S4(write);
 6157   INS01  : ISS;
 6158   NEON_FP : S4;
 6159 %}
 6160 
 6161 pipe_class vmul64(vecD dst, vecD src1, vecD src2)
 6162 %{
 6163   single_instruction;
 6164   dst    : S5(write);
 6165   src1   : S1(read);
 6166   src2   : S1(read);
 6167   INS01  : ISS;
 6168   NEON_FP : S5;
 6169 %}
 6170 
 6171 pipe_class vmul128(vecX dst, vecX src1, vecX src2)
 6172 %{
 6173   single_instruction;
 6174   dst    : S5(write);
 6175   src1   : S1(read);
 6176   src2   : S1(read);
 6177   INS0   : ISS;
 6178   NEON_FP : S5;
 6179 %}
 6180 
 6181 pipe_class vmla64(vecD dst, vecD src1, vecD src2)
 6182 %{
 6183   single_instruction;
 6184   dst    : S5(write);
 6185   src1   : S1(read);
 6186   src2   : S1(read);
 6187   dst    : S1(read);
 6188   INS01  : ISS;
 6189   NEON_FP : S5;
 6190 %}
 6191 
 6192 pipe_class vmla128(vecX dst, vecX src1, vecX src2)
 6193 %{
 6194   single_instruction;
 6195   dst    : S5(write);
 6196   src1   : S1(read);
 6197   src2   : S1(read);
 6198   dst    : S1(read);
 6199   INS0   : ISS;
 6200   NEON_FP : S5;
 6201 %}
 6202 
 6203 pipe_class vdop64(vecD dst, vecD src1, vecD src2)
 6204 %{
 6205   single_instruction;
 6206   dst    : S4(write);
 6207   src1   : S2(read);
 6208   src2   : S2(read);
 6209   INS01  : ISS;
 6210   NEON_FP : S4;
 6211 %}
 6212 
 6213 pipe_class vdop128(vecX dst, vecX src1, vecX src2)
 6214 %{
 6215   single_instruction;
 6216   dst    : S4(write);
 6217   src1   : S2(read);
 6218   src2   : S2(read);
 6219   INS0   : ISS;
 6220   NEON_FP : S4;
 6221 %}
 6222 
 6223 pipe_class vlogical64(vecD dst, vecD src1, vecD src2)
 6224 %{
 6225   single_instruction;
 6226   dst    : S3(write);
 6227   src1   : S2(read);
 6228   src2   : S2(read);
 6229   INS01  : ISS;
 6230   NEON_FP : S3;
 6231 %}
 6232 
 6233 pipe_class vlogical128(vecX dst, vecX src1, vecX src2)
 6234 %{
 6235   single_instruction;
 6236   dst    : S3(write);
 6237   src1   : S2(read);
 6238   src2   : S2(read);
 6239   INS0   : ISS;
 6240   NEON_FP : S3;
 6241 %}
 6242 
 6243 pipe_class vshift64(vecD dst, vecD src, vecX shift)
 6244 %{
 6245   single_instruction;
 6246   dst    : S3(write);
 6247   src    : S1(read);
 6248   shift  : S1(read);
 6249   INS01  : ISS;
 6250   NEON_FP : S3;
 6251 %}
 6252 
 6253 pipe_class vshift128(vecX dst, vecX src, vecX shift)
 6254 %{
 6255   single_instruction;
 6256   dst    : S3(write);
 6257   src    : S1(read);
 6258   shift  : S1(read);
 6259   INS0   : ISS;
 6260   NEON_FP : S3;
 6261 %}
 6262 
 6263 pipe_class vshift64_imm(vecD dst, vecD src, immI shift)
 6264 %{
 6265   single_instruction;
 6266   dst    : S3(write);
 6267   src    : S1(read);
 6268   INS01  : ISS;
 6269   NEON_FP : S3;
 6270 %}
 6271 
 6272 pipe_class vshift128_imm(vecX dst, vecX src, immI shift)
 6273 %{
 6274   single_instruction;
 6275   dst    : S3(write);
 6276   src    : S1(read);
 6277   INS0   : ISS;
 6278   NEON_FP : S3;
 6279 %}
 6280 
 6281 pipe_class vdop_fp64(vecD dst, vecD src1, vecD src2)
 6282 %{
 6283   single_instruction;
 6284   dst    : S5(write);
 6285   src1   : S1(read);
 6286   src2   : S1(read);
 6287   INS01  : ISS;
 6288   NEON_FP : S5;
 6289 %}
 6290 
 6291 pipe_class vdop_fp128(vecX dst, vecX src1, vecX src2)
 6292 %{
 6293   single_instruction;
 6294   dst    : S5(write);
 6295   src1   : S1(read);
 6296   src2   : S1(read);
 6297   INS0   : ISS;
 6298   NEON_FP : S5;
 6299 %}
 6300 
 6301 pipe_class vmuldiv_fp64(vecD dst, vecD src1, vecD src2)
 6302 %{
 6303   single_instruction;
 6304   dst    : S5(write);
 6305   src1   : S1(read);
 6306   src2   : S1(read);
 6307   INS0   : ISS;
 6308   NEON_FP : S5;
 6309 %}
 6310 
 6311 pipe_class vmuldiv_fp128(vecX dst, vecX src1, vecX src2)
 6312 %{
 6313   single_instruction;
 6314   dst    : S5(write);
 6315   src1   : S1(read);
 6316   src2   : S1(read);
 6317   INS0   : ISS;
 6318   NEON_FP : S5;
 6319 %}
 6320 
 6321 pipe_class vsqrt_fp128(vecX dst, vecX src)
 6322 %{
 6323   single_instruction;
 6324   dst    : S5(write);
 6325   src    : S1(read);
 6326   INS0   : ISS;
 6327   NEON_FP : S5;
 6328 %}
 6329 
 6330 pipe_class vunop_fp64(vecD dst, vecD src)
 6331 %{
 6332   single_instruction;
 6333   dst    : S5(write);
 6334   src    : S1(read);
 6335   INS01  : ISS;
 6336   NEON_FP : S5;
 6337 %}
 6338 
 6339 pipe_class vunop_fp128(vecX dst, vecX src)
 6340 %{
 6341   single_instruction;
 6342   dst    : S5(write);
 6343   src    : S1(read);
 6344   INS0   : ISS;
 6345   NEON_FP : S5;
 6346 %}
 6347 
 6348 pipe_class vdup_reg_reg64(vecD dst, iRegI src)
 6349 %{
 6350   single_instruction;
 6351   dst    : S3(write);
 6352   src    : S1(read);
 6353   INS01  : ISS;
 6354   NEON_FP : S3;
 6355 %}
 6356 
 6357 pipe_class vdup_reg_reg128(vecX dst, iRegI src)
 6358 %{
 6359   single_instruction;
 6360   dst    : S3(write);
 6361   src    : S1(read);
 6362   INS01  : ISS;
 6363   NEON_FP : S3;
 6364 %}
 6365 
 6366 pipe_class vdup_reg_freg64(vecD dst, vRegF src)
 6367 %{
 6368   single_instruction;
 6369   dst    : S3(write);
 6370   src    : S1(read);
 6371   INS01  : ISS;
 6372   NEON_FP : S3;
 6373 %}
 6374 
 6375 pipe_class vdup_reg_freg128(vecX dst, vRegF src)
 6376 %{
 6377   single_instruction;
 6378   dst    : S3(write);
 6379   src    : S1(read);
 6380   INS01  : ISS;
 6381   NEON_FP : S3;
 6382 %}
 6383 
 6384 pipe_class vdup_reg_dreg128(vecX dst, vRegD src)
 6385 %{
 6386   single_instruction;
 6387   dst    : S3(write);
 6388   src    : S1(read);
 6389   INS01  : ISS;
 6390   NEON_FP : S3;
 6391 %}
 6392 
 6393 pipe_class vmovi_reg_imm64(vecD dst)
 6394 %{
 6395   single_instruction;
 6396   dst    : S3(write);
 6397   INS01  : ISS;
 6398   NEON_FP : S3;
 6399 %}
 6400 
 6401 pipe_class vmovi_reg_imm128(vecX dst)
 6402 %{
 6403   single_instruction;
 6404   dst    : S3(write);
 6405   INS0   : ISS;
 6406   NEON_FP : S3;
 6407 %}
 6408 
 6409 pipe_class vload_reg_mem64(vecD dst, vmem8 mem)
 6410 %{
 6411   single_instruction;
 6412   dst    : S5(write);
 6413   mem    : ISS(read);
 6414   INS01  : ISS;
 6415   NEON_FP : S3;
 6416 %}
 6417 
 6418 pipe_class vload_reg_mem128(vecX dst, vmem16 mem)
 6419 %{
 6420   single_instruction;
 6421   dst    : S5(write);
 6422   mem    : ISS(read);
 6423   INS01  : ISS;
 6424   NEON_FP : S3;
 6425 %}
 6426 
 6427 pipe_class vstore_reg_mem64(vecD src, vmem8 mem)
 6428 %{
 6429   single_instruction;
 6430   mem    : ISS(read);
 6431   src    : S2(read);
 6432   INS01  : ISS;
 6433   NEON_FP : S3;
 6434 %}
 6435 
 6436 pipe_class vstore_reg_mem128(vecD src, vmem16 mem)
 6437 %{
 6438   single_instruction;
 6439   mem    : ISS(read);
 6440   src    : S2(read);
 6441   INS01  : ISS;
 6442   NEON_FP : S3;
 6443 %}
 6444 
 6445 //------- Integer ALU operations --------------------------
 6446 
 6447 // Integer ALU reg-reg operation
 6448 // Operands needed in EX1, result generated in EX2
 6449 // Eg.  ADD     x0, x1, x2
 6450 pipe_class ialu_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6451 %{
 6452   single_instruction;
 6453   dst    : EX2(write);
 6454   src1   : EX1(read);
 6455   src2   : EX1(read);
 6456   INS01  : ISS; // Dual issue as instruction 0 or 1
 6457   ALU    : EX2;
 6458 %}
 6459 
 6460 // Integer ALU reg-reg operation with constant shift
 6461 // Shifted register must be available in LATE_ISS instead of EX1
 6462 // Eg.  ADD     x0, x1, x2, LSL #2
 6463 pipe_class ialu_reg_reg_shift(iRegI dst, iRegI src1, iRegI src2, immI shift)
 6464 %{
 6465   single_instruction;
 6466   dst    : EX2(write);
 6467   src1   : EX1(read);
 6468   src2   : ISS(read);
 6469   INS01  : ISS;
 6470   ALU    : EX2;
 6471 %}
 6472 
 6473 // Integer ALU reg operation with constant shift
 6474 // Eg.  LSL     x0, x1, #shift
 6475 pipe_class ialu_reg_shift(iRegI dst, iRegI src1)
 6476 %{
 6477   single_instruction;
 6478   dst    : EX2(write);
 6479   src1   : ISS(read);
 6480   INS01  : ISS;
 6481   ALU    : EX2;
 6482 %}
 6483 
 6484 // Integer ALU reg-reg operation with variable shift
 6485 // Both operands must be available in LATE_ISS instead of EX1
 6486 // Result is available in EX1 instead of EX2
 6487 // Eg.  LSLV    x0, x1, x2
 6488 pipe_class ialu_reg_reg_vshift(iRegI dst, iRegI src1, iRegI src2)
 6489 %{
 6490   single_instruction;
 6491   dst    : EX1(write);
 6492   src1   : ISS(read);
 6493   src2   : ISS(read);
 6494   INS01  : ISS;
 6495   ALU    : EX1;
 6496 %}
 6497 
 6498 // Integer ALU reg-reg operation with extract
 6499 // As for _vshift above, but result generated in EX2
 6500 // Eg.  EXTR    x0, x1, x2, #N
 6501 pipe_class ialu_reg_reg_extr(iRegI dst, iRegI src1, iRegI src2)
 6502 %{
 6503   single_instruction;
 6504   dst    : EX2(write);
 6505   src1   : ISS(read);
 6506   src2   : ISS(read);
 6507   INS1   : ISS; // Can only dual issue as Instruction 1
 6508   ALU    : EX1;
 6509 %}
 6510 
 6511 // Integer ALU reg operation
 6512 // Eg.  NEG     x0, x1
 6513 pipe_class ialu_reg(iRegI dst, iRegI src)
 6514 %{
 6515   single_instruction;
 6516   dst    : EX2(write);
 6517   src    : EX1(read);
 6518   INS01  : ISS;
 6519   ALU    : EX2;
 6520 %}
 6521 
 6522 // Integer ALU reg mmediate operation
 6523 // Eg.  ADD     x0, x1, #N
 6524 pipe_class ialu_reg_imm(iRegI dst, iRegI src1)
 6525 %{
 6526   single_instruction;
 6527   dst    : EX2(write);
 6528   src1   : EX1(read);
 6529   INS01  : ISS;
 6530   ALU    : EX2;
 6531 %}
 6532 
 6533 // Integer ALU immediate operation (no source operands)
 6534 // Eg.  MOV     x0, #N
 6535 pipe_class ialu_imm(iRegI dst)
 6536 %{
 6537   single_instruction;
 6538   dst    : EX1(write);
 6539   INS01  : ISS;
 6540   ALU    : EX1;
 6541 %}
 6542 
 6543 //------- Compare operation -------------------------------
 6544 
 6545 // Compare reg-reg
 6546 // Eg.  CMP     x0, x1
 6547 pipe_class icmp_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
 6548 %{
 6549   single_instruction;
 6550 //  fixed_latency(16);
 6551   cr     : EX2(write);
 6552   op1    : EX1(read);
 6553   op2    : EX1(read);
 6554   INS01  : ISS;
 6555   ALU    : EX2;
 6556 %}
 6557 
 6558 // Compare reg-reg
 6559 // Eg.  CMP     x0, #N
 6560 pipe_class icmp_reg_imm(rFlagsReg cr, iRegI op1)
 6561 %{
 6562   single_instruction;
 6563 //  fixed_latency(16);
 6564   cr     : EX2(write);
 6565   op1    : EX1(read);
 6566   INS01  : ISS;
 6567   ALU    : EX2;
 6568 %}
 6569 
 6570 //------- Conditional instructions ------------------------
 6571 
 6572 // Conditional no operands
 6573 // Eg.  CSINC   x0, zr, zr, &lt;cond&gt;
 6574 pipe_class icond_none(iRegI dst, rFlagsReg cr)
 6575 %{
 6576   single_instruction;
 6577   cr     : EX1(read);
 6578   dst    : EX2(write);
 6579   INS01  : ISS;
 6580   ALU    : EX2;
 6581 %}
 6582 
 6583 // Conditional 2 operand
 6584 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6585 pipe_class icond_reg_reg(iRegI dst, iRegI src1, iRegI src2, rFlagsReg cr)
 6586 %{
 6587   single_instruction;
 6588   cr     : EX1(read);
 6589   src1   : EX1(read);
 6590   src2   : EX1(read);
 6591   dst    : EX2(write);
 6592   INS01  : ISS;
 6593   ALU    : EX2;
 6594 %}
 6595 
 6596 // Conditional 2 operand
 6597 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6598 pipe_class icond_reg(iRegI dst, iRegI src, rFlagsReg cr)
 6599 %{
 6600   single_instruction;
 6601   cr     : EX1(read);
 6602   src    : EX1(read);
 6603   dst    : EX2(write);
 6604   INS01  : ISS;
 6605   ALU    : EX2;
 6606 %}
 6607 
 6608 //------- Multiply pipeline operations --------------------
 6609 
 6610 // Multiply reg-reg
 6611 // Eg.  MUL     w0, w1, w2
 6612 pipe_class imul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6613 %{
 6614   single_instruction;
 6615   dst    : WR(write);
 6616   src1   : ISS(read);
 6617   src2   : ISS(read);
 6618   INS01  : ISS;
 6619   MAC    : WR;
 6620 %}
 6621 
 6622 // Multiply accumulate
 6623 // Eg.  MADD    w0, w1, w2, w3
 6624 pipe_class imac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6625 %{
 6626   single_instruction;
 6627   dst    : WR(write);
 6628   src1   : ISS(read);
 6629   src2   : ISS(read);
 6630   src3   : ISS(read);
 6631   INS01  : ISS;
 6632   MAC    : WR;
 6633 %}
 6634 
 6635 // Eg.  MUL     w0, w1, w2
 6636 pipe_class lmul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6637 %{
 6638   single_instruction;
 6639   fixed_latency(3); // Maximum latency for 64 bit mul
 6640   dst    : WR(write);
 6641   src1   : ISS(read);
 6642   src2   : ISS(read);
 6643   INS01  : ISS;
 6644   MAC    : WR;
 6645 %}
 6646 
 6647 // Multiply accumulate
 6648 // Eg.  MADD    w0, w1, w2, w3
 6649 pipe_class lmac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6650 %{
 6651   single_instruction;
 6652   fixed_latency(3); // Maximum latency for 64 bit mul
 6653   dst    : WR(write);
 6654   src1   : ISS(read);
 6655   src2   : ISS(read);
 6656   src3   : ISS(read);
 6657   INS01  : ISS;
 6658   MAC    : WR;
 6659 %}
 6660 
 6661 //------- Divide pipeline operations --------------------
 6662 
 6663 // Eg.  SDIV    w0, w1, w2
 6664 pipe_class idiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6665 %{
 6666   single_instruction;
 6667   fixed_latency(8); // Maximum latency for 32 bit divide
 6668   dst    : WR(write);
 6669   src1   : ISS(read);
 6670   src2   : ISS(read);
 6671   INS0   : ISS; // Can only dual issue as instruction 0
 6672   DIV    : WR;
 6673 %}
 6674 
 6675 // Eg.  SDIV    x0, x1, x2
 6676 pipe_class ldiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6677 %{
 6678   single_instruction;
 6679   fixed_latency(16); // Maximum latency for 64 bit divide
 6680   dst    : WR(write);
 6681   src1   : ISS(read);
 6682   src2   : ISS(read);
 6683   INS0   : ISS; // Can only dual issue as instruction 0
 6684   DIV    : WR;
 6685 %}
 6686 
 6687 //------- Load pipeline operations ------------------------
 6688 
 6689 // Load - prefetch
 6690 // Eg.  PFRM    &lt;mem&gt;
 6691 pipe_class iload_prefetch(memory mem)
 6692 %{
 6693   single_instruction;
 6694   mem    : ISS(read);
 6695   INS01  : ISS;
 6696   LDST   : WR;
 6697 %}
 6698 
 6699 // Load - reg, mem
 6700 // Eg.  LDR     x0, &lt;mem&gt;
 6701 pipe_class iload_reg_mem(iRegI dst, memory mem)
 6702 %{
 6703   single_instruction;
 6704   dst    : WR(write);
 6705   mem    : ISS(read);
 6706   INS01  : ISS;
 6707   LDST   : WR;
 6708 %}
 6709 
 6710 // Load - reg, reg
 6711 // Eg.  LDR     x0, [sp, x1]
 6712 pipe_class iload_reg_reg(iRegI dst, iRegI src)
 6713 %{
 6714   single_instruction;
 6715   dst    : WR(write);
 6716   src    : ISS(read);
 6717   INS01  : ISS;
 6718   LDST   : WR;
 6719 %}
 6720 
 6721 //------- Store pipeline operations -----------------------
 6722 
 6723 // Store - zr, mem
 6724 // Eg.  STR     zr, &lt;mem&gt;
 6725 pipe_class istore_mem(memory mem)
 6726 %{
 6727   single_instruction;
 6728   mem    : ISS(read);
 6729   INS01  : ISS;
 6730   LDST   : WR;
 6731 %}
 6732 
 6733 // Store - reg, mem
 6734 // Eg.  STR     x0, &lt;mem&gt;
 6735 pipe_class istore_reg_mem(iRegI src, memory mem)
 6736 %{
 6737   single_instruction;
 6738   mem    : ISS(read);
 6739   src    : EX2(read);
 6740   INS01  : ISS;
 6741   LDST   : WR;
 6742 %}
 6743 
 6744 // Store - reg, reg
 6745 // Eg. STR      x0, [sp, x1]
 6746 pipe_class istore_reg_reg(iRegI dst, iRegI src)
 6747 %{
 6748   single_instruction;
 6749   dst    : ISS(read);
 6750   src    : EX2(read);
 6751   INS01  : ISS;
 6752   LDST   : WR;
 6753 %}
 6754 
 6755 //------- Store pipeline operations -----------------------
 6756 
 6757 // Branch
 6758 pipe_class pipe_branch()
 6759 %{
 6760   single_instruction;
 6761   INS01  : ISS;
 6762   BRANCH : EX1;
 6763 %}
 6764 
 6765 // Conditional branch
 6766 pipe_class pipe_branch_cond(rFlagsReg cr)
 6767 %{
 6768   single_instruction;
 6769   cr     : EX1(read);
 6770   INS01  : ISS;
 6771   BRANCH : EX1;
 6772 %}
 6773 
 6774 // Compare &amp; Branch
 6775 // EG.  CBZ/CBNZ
 6776 pipe_class pipe_cmp_branch(iRegI op1)
 6777 %{
 6778   single_instruction;
 6779   op1    : EX1(read);
 6780   INS01  : ISS;
 6781   BRANCH : EX1;
 6782 %}
 6783 
 6784 //------- Synchronisation operations ----------------------
 6785 
 6786 // Any operation requiring serialization.
 6787 // EG.  DMB/Atomic Ops/Load Acquire/Str Release
 6788 pipe_class pipe_serial()
 6789 %{
 6790   single_instruction;
 6791   force_serialization;
 6792   fixed_latency(16);
 6793   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6794   LDST   : WR;
 6795 %}
 6796 
 6797 // Generic big/slow expanded idiom - also serialized
 6798 pipe_class pipe_slow()
 6799 %{
 6800   instruction_count(10);
 6801   multiple_bundles;
 6802   force_serialization;
 6803   fixed_latency(16);
 6804   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6805   LDST   : WR;
 6806 %}
 6807 
 6808 // Empty pipeline class
 6809 pipe_class pipe_class_empty()
 6810 %{
 6811   single_instruction;
 6812   fixed_latency(0);
 6813 %}
 6814 
 6815 // Default pipeline class.
 6816 pipe_class pipe_class_default()
 6817 %{
 6818   single_instruction;
 6819   fixed_latency(2);
 6820 %}
 6821 
 6822 // Pipeline class for compares.
 6823 pipe_class pipe_class_compare()
 6824 %{
 6825   single_instruction;
 6826   fixed_latency(16);
 6827 %}
 6828 
 6829 // Pipeline class for memory operations.
 6830 pipe_class pipe_class_memory()
 6831 %{
 6832   single_instruction;
 6833   fixed_latency(16);
 6834 %}
 6835 
 6836 // Pipeline class for call.
 6837 pipe_class pipe_class_call()
 6838 %{
 6839   single_instruction;
 6840   fixed_latency(100);
 6841 %}
 6842 
 6843 // Define the class for the Nop node.
 6844 define %{
 6845    MachNop = pipe_class_empty;
 6846 %}
 6847 
 6848 %}
 6849 //----------INSTRUCTIONS-------------------------------------------------------
 6850 //
 6851 // match      -- States which machine-independent subtree may be replaced
 6852 //               by this instruction.
 6853 // ins_cost   -- The estimated cost of this instruction is used by instruction
 6854 //               selection to identify a minimum cost tree of machine
 6855 //               instructions that matches a tree of machine-independent
 6856 //               instructions.
 6857 // format     -- A string providing the disassembly for this instruction.
 6858 //               The value of an instruction&#39;s operand may be inserted
 6859 //               by referring to it with a &#39;$&#39; prefix.
 6860 // opcode     -- Three instruction opcodes may be provided.  These are referred
 6861 //               to within an encode class as $primary, $secondary, and $tertiary
 6862 //               rrspectively.  The primary opcode is commonly used to
 6863 //               indicate the type of machine instruction, while secondary
 6864 //               and tertiary are often used for prefix options or addressing
 6865 //               modes.
 6866 // ins_encode -- A list of encode classes with parameters. The encode class
 6867 //               name must have been defined in an &#39;enc_class&#39; specification
 6868 //               in the encode section of the architecture description.
 6869 
 6870 // ============================================================================
 6871 // Memory (Load/Store) Instructions
 6872 
 6873 // Load Instructions
 6874 
 6875 // Load Byte (8 bit signed)
 6876 instruct loadB(iRegINoSp dst, memory1 mem)
 6877 %{
 6878   match(Set dst (LoadB mem));
 6879   predicate(!needs_acquiring_load(n));
 6880 
 6881   ins_cost(4 * INSN_COST);
 6882   format %{ &quot;ldrsbw  $dst, $mem\t# byte&quot; %}
 6883 
 6884   ins_encode(aarch64_enc_ldrsbw(dst, mem));
 6885 
 6886   ins_pipe(iload_reg_mem);
 6887 %}
 6888 
 6889 // Load Byte (8 bit signed) into long
 6890 instruct loadB2L(iRegLNoSp dst, memory1 mem)
 6891 %{
 6892   match(Set dst (ConvI2L (LoadB mem)));
 6893   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6894 
 6895   ins_cost(4 * INSN_COST);
 6896   format %{ &quot;ldrsb  $dst, $mem\t# byte&quot; %}
 6897 
 6898   ins_encode(aarch64_enc_ldrsb(dst, mem));
 6899 
 6900   ins_pipe(iload_reg_mem);
 6901 %}
 6902 
 6903 // Load Byte (8 bit unsigned)
 6904 instruct loadUB(iRegINoSp dst, memory1 mem)
 6905 %{
 6906   match(Set dst (LoadUB mem));
 6907   predicate(!needs_acquiring_load(n));
 6908 
 6909   ins_cost(4 * INSN_COST);
 6910   format %{ &quot;ldrbw  $dst, $mem\t# byte&quot; %}
 6911 
 6912   ins_encode(aarch64_enc_ldrb(dst, mem));
 6913 
 6914   ins_pipe(iload_reg_mem);
 6915 %}
 6916 
 6917 // Load Byte (8 bit unsigned) into long
 6918 instruct loadUB2L(iRegLNoSp dst, memory1 mem)
 6919 %{
 6920   match(Set dst (ConvI2L (LoadUB mem)));
 6921   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6922 
 6923   ins_cost(4 * INSN_COST);
 6924   format %{ &quot;ldrb  $dst, $mem\t# byte&quot; %}
 6925 
 6926   ins_encode(aarch64_enc_ldrb(dst, mem));
 6927 
 6928   ins_pipe(iload_reg_mem);
 6929 %}
 6930 
 6931 // Load Short (16 bit signed)
 6932 instruct loadS(iRegINoSp dst, memory2 mem)
 6933 %{
 6934   match(Set dst (LoadS mem));
 6935   predicate(!needs_acquiring_load(n));
 6936 
 6937   ins_cost(4 * INSN_COST);
 6938   format %{ &quot;ldrshw  $dst, $mem\t# short&quot; %}
 6939 
 6940   ins_encode(aarch64_enc_ldrshw(dst, mem));
 6941 
 6942   ins_pipe(iload_reg_mem);
 6943 %}
 6944 
 6945 // Load Short (16 bit signed) into long
 6946 instruct loadS2L(iRegLNoSp dst, memory2 mem)
 6947 %{
 6948   match(Set dst (ConvI2L (LoadS mem)));
 6949   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6950 
 6951   ins_cost(4 * INSN_COST);
 6952   format %{ &quot;ldrsh  $dst, $mem\t# short&quot; %}
 6953 
 6954   ins_encode(aarch64_enc_ldrsh(dst, mem));
 6955 
 6956   ins_pipe(iload_reg_mem);
 6957 %}
 6958 
 6959 // Load Char (16 bit unsigned)
 6960 instruct loadUS(iRegINoSp dst, memory2 mem)
 6961 %{
 6962   match(Set dst (LoadUS mem));
 6963   predicate(!needs_acquiring_load(n));
 6964 
 6965   ins_cost(4 * INSN_COST);
 6966   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6967 
 6968   ins_encode(aarch64_enc_ldrh(dst, mem));
 6969 
 6970   ins_pipe(iload_reg_mem);
 6971 %}
 6972 
 6973 // Load Short/Char (16 bit unsigned) into long
 6974 instruct loadUS2L(iRegLNoSp dst, memory2 mem)
 6975 %{
 6976   match(Set dst (ConvI2L (LoadUS mem)));
 6977   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6978 
 6979   ins_cost(4 * INSN_COST);
 6980   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6981 
 6982   ins_encode(aarch64_enc_ldrh(dst, mem));
 6983 
 6984   ins_pipe(iload_reg_mem);
 6985 %}
 6986 
 6987 // Load Integer (32 bit signed)
 6988 instruct loadI(iRegINoSp dst, memory4 mem)
 6989 %{
 6990   match(Set dst (LoadI mem));
 6991   predicate(!needs_acquiring_load(n));
 6992 
 6993   ins_cost(4 * INSN_COST);
 6994   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6995 
 6996   ins_encode(aarch64_enc_ldrw(dst, mem));
 6997 
 6998   ins_pipe(iload_reg_mem);
 6999 %}
 7000 
 7001 // Load Integer (32 bit signed) into long
 7002 instruct loadI2L(iRegLNoSp dst, memory4 mem)
 7003 %{
 7004   match(Set dst (ConvI2L (LoadI mem)));
 7005   predicate(!needs_acquiring_load(n-&gt;in(1)));
 7006 
 7007   ins_cost(4 * INSN_COST);
 7008   format %{ &quot;ldrsw  $dst, $mem\t# int&quot; %}
 7009 
 7010   ins_encode(aarch64_enc_ldrsw(dst, mem));
 7011 
 7012   ins_pipe(iload_reg_mem);
 7013 %}
 7014 
 7015 // Load Integer (32 bit unsigned) into long
 7016 instruct loadUI2L(iRegLNoSp dst, memory4 mem, immL_32bits mask)
 7017 %{
 7018   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 7019   predicate(!needs_acquiring_load(n-&gt;in(1)-&gt;in(1)-&gt;as_Load()));
 7020 
 7021   ins_cost(4 * INSN_COST);
 7022   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 7023 
 7024   ins_encode(aarch64_enc_ldrw(dst, mem));
 7025 
 7026   ins_pipe(iload_reg_mem);
 7027 %}
 7028 
 7029 // Load Long (64 bit signed)
 7030 instruct loadL(iRegLNoSp dst, memory8 mem)
 7031 %{
 7032   match(Set dst (LoadL mem));
 7033   predicate(!needs_acquiring_load(n));
 7034 
 7035   ins_cost(4 * INSN_COST);
 7036   format %{ &quot;ldr  $dst, $mem\t# int&quot; %}
 7037 
 7038   ins_encode(aarch64_enc_ldr(dst, mem));
 7039 
 7040   ins_pipe(iload_reg_mem);
 7041 %}
 7042 
 7043 // Load Range
 7044 instruct loadRange(iRegINoSp dst, memory4 mem)
 7045 %{
 7046   match(Set dst (LoadRange mem));
 7047 
 7048   ins_cost(4 * INSN_COST);
 7049   format %{ &quot;ldrw  $dst, $mem\t# range&quot; %}
 7050 
 7051   ins_encode(aarch64_enc_ldrw(dst, mem));
 7052 
 7053   ins_pipe(iload_reg_mem);
 7054 %}
 7055 
 7056 // Load Pointer
 7057 instruct loadP(iRegPNoSp dst, memory8 mem)
 7058 %{
 7059   match(Set dst (LoadP mem));
 7060   predicate(!needs_acquiring_load(n) &amp;&amp; (n-&gt;as_Load()-&gt;barrier_data() == 0));
 7061 
 7062   ins_cost(4 * INSN_COST);
 7063   format %{ &quot;ldr  $dst, $mem\t# ptr&quot; %}
 7064 
 7065   ins_encode(aarch64_enc_ldr(dst, mem));
 7066 
 7067   ins_pipe(iload_reg_mem);
 7068 %}
 7069 
 7070 // Load Compressed Pointer
 7071 instruct loadN(iRegNNoSp dst, memory4 mem)
 7072 %{
 7073   match(Set dst (LoadN mem));
 7074   predicate(!needs_acquiring_load(n));
 7075 
 7076   ins_cost(4 * INSN_COST);
 7077   format %{ &quot;ldrw  $dst, $mem\t# compressed ptr&quot; %}
 7078 
 7079   ins_encode(aarch64_enc_ldrw(dst, mem));
 7080 
 7081   ins_pipe(iload_reg_mem);
 7082 %}
 7083 
 7084 // Load Klass Pointer
 7085 instruct loadKlass(iRegPNoSp dst, memory8 mem)
 7086 %{
 7087   match(Set dst (LoadKlass mem));
 7088   predicate(!needs_acquiring_load(n));
 7089 
 7090   ins_cost(4 * INSN_COST);
 7091   format %{ &quot;ldr  $dst, $mem\t# class&quot; %}
 7092 
 7093   ins_encode(aarch64_enc_ldr(dst, mem));
 7094 
 7095   ins_pipe(iload_reg_mem);
 7096 %}
 7097 
 7098 // Load Narrow Klass Pointer
 7099 instruct loadNKlass(iRegNNoSp dst, memory4 mem)
 7100 %{
 7101   match(Set dst (LoadNKlass mem));
 7102   predicate(!needs_acquiring_load(n));
 7103 
 7104   ins_cost(4 * INSN_COST);
 7105   format %{ &quot;ldrw  $dst, $mem\t# compressed class ptr&quot; %}
 7106 
 7107   ins_encode(aarch64_enc_ldrw(dst, mem));
 7108 
 7109   ins_pipe(iload_reg_mem);
 7110 %}
 7111 
 7112 // Load Float
 7113 instruct loadF(vRegF dst, memory4 mem)
 7114 %{
 7115   match(Set dst (LoadF mem));
 7116   predicate(!needs_acquiring_load(n));
 7117 
 7118   ins_cost(4 * INSN_COST);
 7119   format %{ &quot;ldrs  $dst, $mem\t# float&quot; %}
 7120 
 7121   ins_encode( aarch64_enc_ldrs(dst, mem) );
 7122 
 7123   ins_pipe(pipe_class_memory);
 7124 %}
 7125 
 7126 // Load Double
 7127 instruct loadD(vRegD dst, memory8 mem)
 7128 %{
 7129   match(Set dst (LoadD mem));
 7130   predicate(!needs_acquiring_load(n));
 7131 
 7132   ins_cost(4 * INSN_COST);
 7133   format %{ &quot;ldrd  $dst, $mem\t# double&quot; %}
 7134 
 7135   ins_encode( aarch64_enc_ldrd(dst, mem) );
 7136 
 7137   ins_pipe(pipe_class_memory);
 7138 %}
 7139 
 7140 
 7141 // Load Int Constant
 7142 instruct loadConI(iRegINoSp dst, immI src)
 7143 %{
 7144   match(Set dst src);
 7145 
 7146   ins_cost(INSN_COST);
 7147   format %{ &quot;mov $dst, $src\t# int&quot; %}
 7148 
 7149   ins_encode( aarch64_enc_movw_imm(dst, src) );
 7150 
 7151   ins_pipe(ialu_imm);
 7152 %}
 7153 
 7154 // Load Long Constant
 7155 instruct loadConL(iRegLNoSp dst, immL src)
 7156 %{
 7157   match(Set dst src);
 7158 
 7159   ins_cost(INSN_COST);
 7160   format %{ &quot;mov $dst, $src\t# long&quot; %}
 7161 
 7162   ins_encode( aarch64_enc_mov_imm(dst, src) );
 7163 
 7164   ins_pipe(ialu_imm);
 7165 %}
 7166 
 7167 // Load Pointer Constant
 7168 
 7169 instruct loadConP(iRegPNoSp dst, immP con)
 7170 %{
 7171   match(Set dst con);
 7172 
 7173   ins_cost(INSN_COST * 4);
 7174   format %{
 7175     &quot;mov  $dst, $con\t# ptr\n\t&quot;
 7176   %}
 7177 
 7178   ins_encode(aarch64_enc_mov_p(dst, con));
 7179 
 7180   ins_pipe(ialu_imm);
 7181 %}
 7182 
 7183 // Load Null Pointer Constant
 7184 
 7185 instruct loadConP0(iRegPNoSp dst, immP0 con)
 7186 %{
 7187   match(Set dst con);
 7188 
 7189   ins_cost(INSN_COST);
 7190   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7191 
 7192   ins_encode(aarch64_enc_mov_p0(dst, con));
 7193 
 7194   ins_pipe(ialu_imm);
 7195 %}
 7196 
 7197 // Load Pointer Constant One
 7198 
 7199 instruct loadConP1(iRegPNoSp dst, immP_1 con)
 7200 %{
 7201   match(Set dst con);
 7202 
 7203   ins_cost(INSN_COST);
 7204   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7205 
 7206   ins_encode(aarch64_enc_mov_p1(dst, con));
 7207 
 7208   ins_pipe(ialu_imm);
 7209 %}
 7210 
 7211 // Load Byte Map Base Constant
 7212 
 7213 instruct loadByteMapBase(iRegPNoSp dst, immByteMapBase con)
 7214 %{
 7215   match(Set dst con);
 7216 
 7217   ins_cost(INSN_COST);
 7218   format %{ &quot;adr  $dst, $con\t# Byte Map Base&quot; %}
 7219 
 7220   ins_encode(aarch64_enc_mov_byte_map_base(dst, con));
 7221 
 7222   ins_pipe(ialu_imm);
 7223 %}
 7224 
 7225 // Load Narrow Pointer Constant
 7226 
 7227 instruct loadConN(iRegNNoSp dst, immN con)
 7228 %{
 7229   match(Set dst con);
 7230 
 7231   ins_cost(INSN_COST * 4);
 7232   format %{ &quot;mov  $dst, $con\t# compressed ptr&quot; %}
 7233 
 7234   ins_encode(aarch64_enc_mov_n(dst, con));
 7235 
 7236   ins_pipe(ialu_imm);
 7237 %}
 7238 
 7239 // Load Narrow Null Pointer Constant
 7240 
 7241 instruct loadConN0(iRegNNoSp dst, immN0 con)
 7242 %{
 7243   match(Set dst con);
 7244 
 7245   ins_cost(INSN_COST);
 7246   format %{ &quot;mov  $dst, $con\t# compressed NULL ptr&quot; %}
 7247 
 7248   ins_encode(aarch64_enc_mov_n0(dst, con));
 7249 
 7250   ins_pipe(ialu_imm);
 7251 %}
 7252 
 7253 // Load Narrow Klass Constant
 7254 
 7255 instruct loadConNKlass(iRegNNoSp dst, immNKlass con)
 7256 %{
 7257   match(Set dst con);
 7258 
 7259   ins_cost(INSN_COST);
 7260   format %{ &quot;mov  $dst, $con\t# compressed klass ptr&quot; %}
 7261 
 7262   ins_encode(aarch64_enc_mov_nk(dst, con));
 7263 
 7264   ins_pipe(ialu_imm);
 7265 %}
 7266 
 7267 // Load Packed Float Constant
 7268 
 7269 instruct loadConF_packed(vRegF dst, immFPacked con) %{
 7270   match(Set dst con);
 7271   ins_cost(INSN_COST * 4);
 7272   format %{ &quot;fmovs  $dst, $con&quot;%}
 7273   ins_encode %{
 7274     __ fmovs(as_FloatRegister($dst$$reg), (double)$con$$constant);
 7275   %}
 7276 
 7277   ins_pipe(fp_imm_s);
 7278 %}
 7279 
 7280 // Load Float Constant
 7281 
 7282 instruct loadConF(vRegF dst, immF con) %{
 7283   match(Set dst con);
 7284 
 7285   ins_cost(INSN_COST * 4);
 7286 
 7287   format %{
 7288     &quot;ldrs $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7289   %}
 7290 
 7291   ins_encode %{
 7292     __ ldrs(as_FloatRegister($dst$$reg), $constantaddress($con));
 7293   %}
 7294 
 7295   ins_pipe(fp_load_constant_s);
 7296 %}
 7297 
 7298 // Load Packed Double Constant
 7299 
 7300 instruct loadConD_packed(vRegD dst, immDPacked con) %{
 7301   match(Set dst con);
 7302   ins_cost(INSN_COST);
 7303   format %{ &quot;fmovd  $dst, $con&quot;%}
 7304   ins_encode %{
 7305     __ fmovd(as_FloatRegister($dst$$reg), $con$$constant);
 7306   %}
 7307 
 7308   ins_pipe(fp_imm_d);
 7309 %}
 7310 
 7311 // Load Double Constant
 7312 
 7313 instruct loadConD(vRegD dst, immD con) %{
 7314   match(Set dst con);
 7315 
 7316   ins_cost(INSN_COST * 5);
 7317   format %{
 7318     &quot;ldrd $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7319   %}
 7320 
 7321   ins_encode %{
 7322     __ ldrd(as_FloatRegister($dst$$reg), $constantaddress($con));
 7323   %}
 7324 
 7325   ins_pipe(fp_load_constant_d);
 7326 %}
 7327 
 7328 // Store Instructions
 7329 
 7330 // Store CMS card-mark Immediate
 7331 instruct storeimmCM0(immI0 zero, memory1 mem)
 7332 %{
 7333   match(Set mem (StoreCM mem zero));
 7334 
 7335   ins_cost(INSN_COST);
 7336   format %{ &quot;storestore (elided)\n\t&quot;
 7337             &quot;strb zr, $mem\t# byte&quot; %}
 7338 
 7339   ins_encode(aarch64_enc_strb0(mem));
 7340 
 7341   ins_pipe(istore_mem);
 7342 %}
 7343 
 7344 // Store CMS card-mark Immediate with intervening StoreStore
 7345 // needed when using CMS with no conditional card marking
 7346 instruct storeimmCM0_ordered(immI0 zero, memory1 mem)
 7347 %{
 7348   match(Set mem (StoreCM mem zero));
 7349 
 7350   ins_cost(INSN_COST * 2);
 7351   format %{ &quot;storestore\n\t&quot;
 7352             &quot;dmb ishst&quot;
 7353             &quot;\n\tstrb zr, $mem\t# byte&quot; %}
 7354 
 7355   ins_encode(aarch64_enc_strb0_ordered(mem));
 7356 
 7357   ins_pipe(istore_mem);
 7358 %}
 7359 
 7360 // Store Byte
 7361 instruct storeB(iRegIorL2I src, memory1 mem)
 7362 %{
 7363   match(Set mem (StoreB mem src));
 7364   predicate(!needs_releasing_store(n));
 7365 
 7366   ins_cost(INSN_COST);
 7367   format %{ &quot;strb  $src, $mem\t# byte&quot; %}
 7368 
 7369   ins_encode(aarch64_enc_strb(src, mem));
 7370 
 7371   ins_pipe(istore_reg_mem);
 7372 %}
 7373 
 7374 
 7375 instruct storeimmB0(immI0 zero, memory1 mem)
 7376 %{
 7377   match(Set mem (StoreB mem zero));
 7378   predicate(!needs_releasing_store(n));
 7379 
 7380   ins_cost(INSN_COST);
 7381   format %{ &quot;strb rscractch2, $mem\t# byte&quot; %}
 7382 
 7383   ins_encode(aarch64_enc_strb0(mem));
 7384 
 7385   ins_pipe(istore_mem);
 7386 %}
 7387 
 7388 // Store Char/Short
 7389 instruct storeC(iRegIorL2I src, memory2 mem)
 7390 %{
 7391   match(Set mem (StoreC mem src));
 7392   predicate(!needs_releasing_store(n));
 7393 
 7394   ins_cost(INSN_COST);
 7395   format %{ &quot;strh  $src, $mem\t# short&quot; %}
 7396 
 7397   ins_encode(aarch64_enc_strh(src, mem));
 7398 
 7399   ins_pipe(istore_reg_mem);
 7400 %}
 7401 
 7402 instruct storeimmC0(immI0 zero, memory2 mem)
 7403 %{
 7404   match(Set mem (StoreC mem zero));
 7405   predicate(!needs_releasing_store(n));
 7406 
 7407   ins_cost(INSN_COST);
 7408   format %{ &quot;strh  zr, $mem\t# short&quot; %}
 7409 
 7410   ins_encode(aarch64_enc_strh0(mem));
 7411 
 7412   ins_pipe(istore_mem);
 7413 %}
 7414 
 7415 // Store Integer
 7416 
 7417 instruct storeI(iRegIorL2I src, memory4 mem)
 7418 %{
 7419   match(Set mem(StoreI mem src));
 7420   predicate(!needs_releasing_store(n));
 7421 
 7422   ins_cost(INSN_COST);
 7423   format %{ &quot;strw  $src, $mem\t# int&quot; %}
 7424 
 7425   ins_encode(aarch64_enc_strw(src, mem));
 7426 
 7427   ins_pipe(istore_reg_mem);
 7428 %}
 7429 
 7430 instruct storeimmI0(immI0 zero, memory4 mem)
 7431 %{
 7432   match(Set mem(StoreI mem zero));
 7433   predicate(!needs_releasing_store(n));
 7434 
 7435   ins_cost(INSN_COST);
 7436   format %{ &quot;strw  zr, $mem\t# int&quot; %}
 7437 
 7438   ins_encode(aarch64_enc_strw0(mem));
 7439 
 7440   ins_pipe(istore_mem);
 7441 %}
 7442 
 7443 // Store Long (64 bit signed)
 7444 instruct storeL(iRegL src, memory8 mem)
 7445 %{
 7446   match(Set mem (StoreL mem src));
 7447   predicate(!needs_releasing_store(n));
 7448 
 7449   ins_cost(INSN_COST);
 7450   format %{ &quot;str  $src, $mem\t# int&quot; %}
 7451 
 7452   ins_encode(aarch64_enc_str(src, mem));
 7453 
 7454   ins_pipe(istore_reg_mem);
 7455 %}
 7456 
 7457 // Store Long (64 bit signed)
 7458 instruct storeimmL0(immL0 zero, memory8 mem)
 7459 %{
 7460   match(Set mem (StoreL mem zero));
 7461   predicate(!needs_releasing_store(n));
 7462 
 7463   ins_cost(INSN_COST);
 7464   format %{ &quot;str  zr, $mem\t# int&quot; %}
 7465 
 7466   ins_encode(aarch64_enc_str0(mem));
 7467 
 7468   ins_pipe(istore_mem);
 7469 %}
 7470 
 7471 // Store Pointer
 7472 instruct storeP(iRegP src, memory8 mem)
 7473 %{
 7474   match(Set mem (StoreP mem src));
 7475   predicate(!needs_releasing_store(n));
 7476 
 7477   ins_cost(INSN_COST);
 7478   format %{ &quot;str  $src, $mem\t# ptr&quot; %}
 7479 
 7480   ins_encode(aarch64_enc_str(src, mem));
 7481 
 7482   ins_pipe(istore_reg_mem);
 7483 %}
 7484 
 7485 // Store Pointer
 7486 instruct storeimmP0(immP0 zero, memory8 mem)
 7487 %{
 7488   match(Set mem (StoreP mem zero));
 7489   predicate(!needs_releasing_store(n));
 7490 
 7491   ins_cost(INSN_COST);
 7492   format %{ &quot;str zr, $mem\t# ptr&quot; %}
 7493 
 7494   ins_encode(aarch64_enc_str0(mem));
 7495 
 7496   ins_pipe(istore_mem);
 7497 %}
 7498 
 7499 // Store Compressed Pointer
 7500 instruct storeN(iRegN src, memory4 mem)
 7501 %{
 7502   match(Set mem (StoreN mem src));
 7503   predicate(!needs_releasing_store(n));
 7504 
 7505   ins_cost(INSN_COST);
 7506   format %{ &quot;strw  $src, $mem\t# compressed ptr&quot; %}
 7507 
 7508   ins_encode(aarch64_enc_strw(src, mem));
 7509 
 7510   ins_pipe(istore_reg_mem);
 7511 %}
 7512 
 7513 instruct storeImmN0(immN0 zero, memory4 mem)
 7514 %{
 7515   match(Set mem (StoreN mem zero));
 7516   predicate(!needs_releasing_store(n));
 7517 
 7518   ins_cost(INSN_COST);
 7519   format %{ &quot;strw  zr, $mem\t# compressed ptr&quot; %}
 7520 
 7521   ins_encode(aarch64_enc_strw0(mem));
 7522 
 7523   ins_pipe(istore_mem);
 7524 %}
 7525 
 7526 // Store Float
 7527 instruct storeF(vRegF src, memory4 mem)
 7528 %{
 7529   match(Set mem (StoreF mem src));
 7530   predicate(!needs_releasing_store(n));
 7531 
 7532   ins_cost(INSN_COST);
 7533   format %{ &quot;strs  $src, $mem\t# float&quot; %}
 7534 
 7535   ins_encode( aarch64_enc_strs(src, mem) );
 7536 
 7537   ins_pipe(pipe_class_memory);
 7538 %}
 7539 
 7540 // TODO
 7541 // implement storeImmF0 and storeFImmPacked
 7542 
 7543 // Store Double
 7544 instruct storeD(vRegD src, memory8 mem)
 7545 %{
 7546   match(Set mem (StoreD mem src));
 7547   predicate(!needs_releasing_store(n));
 7548 
 7549   ins_cost(INSN_COST);
 7550   format %{ &quot;strd  $src, $mem\t# double&quot; %}
 7551 
 7552   ins_encode( aarch64_enc_strd(src, mem) );
 7553 
 7554   ins_pipe(pipe_class_memory);
 7555 %}
 7556 
 7557 // Store Compressed Klass Pointer
 7558 instruct storeNKlass(iRegN src, memory4 mem)
 7559 %{
 7560   predicate(!needs_releasing_store(n));
 7561   match(Set mem (StoreNKlass mem src));
 7562 
 7563   ins_cost(INSN_COST);
 7564   format %{ &quot;strw  $src, $mem\t# compressed klass ptr&quot; %}
 7565 
 7566   ins_encode(aarch64_enc_strw(src, mem));
 7567 
 7568   ins_pipe(istore_reg_mem);
 7569 %}
 7570 
 7571 // TODO
 7572 // implement storeImmD0 and storeDImmPacked
 7573 
 7574 // prefetch instructions
 7575 // Must be safe to execute with invalid address (cannot fault).
 7576 
 7577 instruct prefetchalloc( memory8 mem ) %{
 7578   match(PrefetchAllocation mem);
 7579 
 7580   ins_cost(INSN_COST);
 7581   format %{ &quot;prfm $mem, PSTL1KEEP\t# Prefetch into level 1 cache write keep&quot; %}
 7582 
 7583   ins_encode( aarch64_enc_prefetchw(mem) );
 7584 
 7585   ins_pipe(iload_prefetch);
 7586 %}
 7587 
 7588 //  ---------------- volatile loads and stores ----------------
 7589 
 7590 // Load Byte (8 bit signed)
 7591 instruct loadB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7592 %{
 7593   match(Set dst (LoadB mem));
 7594 
 7595   ins_cost(VOLATILE_REF_COST);
 7596   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7597 
 7598   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7599 
 7600   ins_pipe(pipe_serial);
 7601 %}
 7602 
 7603 // Load Byte (8 bit signed) into long
 7604 instruct loadB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7605 %{
 7606   match(Set dst (ConvI2L (LoadB mem)));
 7607 
 7608   ins_cost(VOLATILE_REF_COST);
 7609   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7610 
 7611   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7612 
 7613   ins_pipe(pipe_serial);
 7614 %}
 7615 
 7616 // Load Byte (8 bit unsigned)
 7617 instruct loadUB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7618 %{
 7619   match(Set dst (LoadUB mem));
 7620 
 7621   ins_cost(VOLATILE_REF_COST);
 7622   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7623 
 7624   ins_encode(aarch64_enc_ldarb(dst, mem));
 7625 
 7626   ins_pipe(pipe_serial);
 7627 %}
 7628 
 7629 // Load Byte (8 bit unsigned) into long
 7630 instruct loadUB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7631 %{
 7632   match(Set dst (ConvI2L (LoadUB mem)));
 7633 
 7634   ins_cost(VOLATILE_REF_COST);
 7635   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7636 
 7637   ins_encode(aarch64_enc_ldarb(dst, mem));
 7638 
 7639   ins_pipe(pipe_serial);
 7640 %}
 7641 
 7642 // Load Short (16 bit signed)
 7643 instruct loadS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7644 %{
 7645   match(Set dst (LoadS mem));
 7646 
 7647   ins_cost(VOLATILE_REF_COST);
 7648   format %{ &quot;ldarshw  $dst, $mem\t# short&quot; %}
 7649 
 7650   ins_encode(aarch64_enc_ldarshw(dst, mem));
 7651 
 7652   ins_pipe(pipe_serial);
 7653 %}
 7654 
 7655 instruct loadUS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7656 %{
 7657   match(Set dst (LoadUS mem));
 7658 
 7659   ins_cost(VOLATILE_REF_COST);
 7660   format %{ &quot;ldarhw  $dst, $mem\t# short&quot; %}
 7661 
 7662   ins_encode(aarch64_enc_ldarhw(dst, mem));
 7663 
 7664   ins_pipe(pipe_serial);
 7665 %}
 7666 
 7667 // Load Short/Char (16 bit unsigned) into long
 7668 instruct loadUS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7669 %{
 7670   match(Set dst (ConvI2L (LoadUS mem)));
 7671 
 7672   ins_cost(VOLATILE_REF_COST);
 7673   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7674 
 7675   ins_encode(aarch64_enc_ldarh(dst, mem));
 7676 
 7677   ins_pipe(pipe_serial);
 7678 %}
 7679 
 7680 // Load Short/Char (16 bit signed) into long
 7681 instruct loadS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7682 %{
 7683   match(Set dst (ConvI2L (LoadS mem)));
 7684 
 7685   ins_cost(VOLATILE_REF_COST);
 7686   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7687 
 7688   ins_encode(aarch64_enc_ldarsh(dst, mem));
 7689 
 7690   ins_pipe(pipe_serial);
 7691 %}
 7692 
 7693 // Load Integer (32 bit signed)
 7694 instruct loadI_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7695 %{
 7696   match(Set dst (LoadI mem));
 7697 
 7698   ins_cost(VOLATILE_REF_COST);
 7699   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7700 
 7701   ins_encode(aarch64_enc_ldarw(dst, mem));
 7702 
 7703   ins_pipe(pipe_serial);
 7704 %}
 7705 
 7706 // Load Integer (32 bit unsigned) into long
 7707 instruct loadUI2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem, immL_32bits mask)
 7708 %{
 7709   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 7710 
 7711   ins_cost(VOLATILE_REF_COST);
 7712   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7713 
 7714   ins_encode(aarch64_enc_ldarw(dst, mem));
 7715 
 7716   ins_pipe(pipe_serial);
 7717 %}
 7718 
 7719 // Load Long (64 bit signed)
 7720 instruct loadL_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7721 %{
 7722   match(Set dst (LoadL mem));
 7723 
 7724   ins_cost(VOLATILE_REF_COST);
 7725   format %{ &quot;ldar  $dst, $mem\t# int&quot; %}
 7726 
 7727   ins_encode(aarch64_enc_ldar(dst, mem));
 7728 
 7729   ins_pipe(pipe_serial);
 7730 %}
 7731 
 7732 // Load Pointer
 7733 instruct loadP_volatile(iRegPNoSp dst, /* sync_memory*/indirect mem)
 7734 %{
 7735   match(Set dst (LoadP mem));
 7736   predicate(n-&gt;as_Load()-&gt;barrier_data() == 0);
 7737 
 7738   ins_cost(VOLATILE_REF_COST);
 7739   format %{ &quot;ldar  $dst, $mem\t# ptr&quot; %}
 7740 
 7741   ins_encode(aarch64_enc_ldar(dst, mem));
 7742 
 7743   ins_pipe(pipe_serial);
 7744 %}
 7745 
 7746 // Load Compressed Pointer
 7747 instruct loadN_volatile(iRegNNoSp dst, /* sync_memory*/indirect mem)
 7748 %{
 7749   match(Set dst (LoadN mem));
 7750 
 7751   ins_cost(VOLATILE_REF_COST);
 7752   format %{ &quot;ldarw  $dst, $mem\t# compressed ptr&quot; %}
 7753 
 7754   ins_encode(aarch64_enc_ldarw(dst, mem));
 7755 
 7756   ins_pipe(pipe_serial);
 7757 %}
 7758 
 7759 // Load Float
 7760 instruct loadF_volatile(vRegF dst, /* sync_memory*/indirect mem)
 7761 %{
 7762   match(Set dst (LoadF mem));
 7763 
 7764   ins_cost(VOLATILE_REF_COST);
 7765   format %{ &quot;ldars  $dst, $mem\t# float&quot; %}
 7766 
 7767   ins_encode( aarch64_enc_fldars(dst, mem) );
 7768 
 7769   ins_pipe(pipe_serial);
 7770 %}
 7771 
 7772 // Load Double
 7773 instruct loadD_volatile(vRegD dst, /* sync_memory*/indirect mem)
 7774 %{
 7775   match(Set dst (LoadD mem));
 7776 
 7777   ins_cost(VOLATILE_REF_COST);
 7778   format %{ &quot;ldard  $dst, $mem\t# double&quot; %}
 7779 
 7780   ins_encode( aarch64_enc_fldard(dst, mem) );
 7781 
 7782   ins_pipe(pipe_serial);
 7783 %}
 7784 
 7785 // Store Byte
 7786 instruct storeB_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7787 %{
 7788   match(Set mem (StoreB mem src));
 7789 
 7790   ins_cost(VOLATILE_REF_COST);
 7791   format %{ &quot;stlrb  $src, $mem\t# byte&quot; %}
 7792 
 7793   ins_encode(aarch64_enc_stlrb(src, mem));
 7794 
 7795   ins_pipe(pipe_class_memory);
 7796 %}
 7797 
 7798 // Store Char/Short
 7799 instruct storeC_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7800 %{
 7801   match(Set mem (StoreC mem src));
 7802 
 7803   ins_cost(VOLATILE_REF_COST);
 7804   format %{ &quot;stlrh  $src, $mem\t# short&quot; %}
 7805 
 7806   ins_encode(aarch64_enc_stlrh(src, mem));
 7807 
 7808   ins_pipe(pipe_class_memory);
 7809 %}
 7810 
 7811 // Store Integer
 7812 
 7813 instruct storeI_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7814 %{
 7815   match(Set mem(StoreI mem src));
 7816 
 7817   ins_cost(VOLATILE_REF_COST);
 7818   format %{ &quot;stlrw  $src, $mem\t# int&quot; %}
 7819 
 7820   ins_encode(aarch64_enc_stlrw(src, mem));
 7821 
 7822   ins_pipe(pipe_class_memory);
 7823 %}
 7824 
 7825 // Store Long (64 bit signed)
 7826 instruct storeL_volatile(iRegL src, /* sync_memory*/indirect mem)
 7827 %{
 7828   match(Set mem (StoreL mem src));
 7829 
 7830   ins_cost(VOLATILE_REF_COST);
 7831   format %{ &quot;stlr  $src, $mem\t# int&quot; %}
 7832 
 7833   ins_encode(aarch64_enc_stlr(src, mem));
 7834 
 7835   ins_pipe(pipe_class_memory);
 7836 %}
 7837 
 7838 // Store Pointer
 7839 instruct storeP_volatile(iRegP src, /* sync_memory*/indirect mem)
 7840 %{
 7841   match(Set mem (StoreP mem src));
 7842 
 7843   ins_cost(VOLATILE_REF_COST);
 7844   format %{ &quot;stlr  $src, $mem\t# ptr&quot; %}
 7845 
 7846   ins_encode(aarch64_enc_stlr(src, mem));
 7847 
 7848   ins_pipe(pipe_class_memory);
 7849 %}
 7850 
 7851 // Store Compressed Pointer
 7852 instruct storeN_volatile(iRegN src, /* sync_memory*/indirect mem)
 7853 %{
 7854   match(Set mem (StoreN mem src));
 7855 
 7856   ins_cost(VOLATILE_REF_COST);
 7857   format %{ &quot;stlrw  $src, $mem\t# compressed ptr&quot; %}
 7858 
 7859   ins_encode(aarch64_enc_stlrw(src, mem));
 7860 
 7861   ins_pipe(pipe_class_memory);
 7862 %}
 7863 
 7864 // Store Float
 7865 instruct storeF_volatile(vRegF src, /* sync_memory*/indirect mem)
 7866 %{
 7867   match(Set mem (StoreF mem src));
 7868 
 7869   ins_cost(VOLATILE_REF_COST);
 7870   format %{ &quot;stlrs  $src, $mem\t# float&quot; %}
 7871 
 7872   ins_encode( aarch64_enc_fstlrs(src, mem) );
 7873 
 7874   ins_pipe(pipe_class_memory);
 7875 %}
 7876 
 7877 // TODO
 7878 // implement storeImmF0 and storeFImmPacked
 7879 
 7880 // Store Double
 7881 instruct storeD_volatile(vRegD src, /* sync_memory*/indirect mem)
 7882 %{
 7883   match(Set mem (StoreD mem src));
 7884 
 7885   ins_cost(VOLATILE_REF_COST);
 7886   format %{ &quot;stlrd  $src, $mem\t# double&quot; %}
 7887 
 7888   ins_encode( aarch64_enc_fstlrd(src, mem) );
 7889 
 7890   ins_pipe(pipe_class_memory);
 7891 %}
 7892 
 7893 //  ---------------- end of volatile loads and stores ----------------
 7894 
 7895 instruct cacheWB(indirect addr)
 7896 %{
 7897   predicate(VM_Version::supports_data_cache_line_flush());
 7898   match(CacheWB addr);
 7899 
 7900   ins_cost(100);
 7901   format %{&quot;cache wb $addr&quot; %}
 7902   ins_encode %{
 7903     assert($addr-&gt;index_position() &lt; 0, &quot;should be&quot;);
 7904     assert($addr$$disp == 0, &quot;should be&quot;);
 7905     __ cache_wb(Address($addr$$base$$Register, 0));
 7906   %}
 7907   ins_pipe(pipe_slow); // XXX
 7908 %}
 7909 
 7910 instruct cacheWBPreSync()
 7911 %{
 7912   predicate(VM_Version::supports_data_cache_line_flush());
 7913   match(CacheWBPreSync);
 7914 
 7915   ins_cost(100);
 7916   format %{&quot;cache wb presync&quot; %}
 7917   ins_encode %{
 7918     __ cache_wbsync(true);
 7919   %}
 7920   ins_pipe(pipe_slow); // XXX
 7921 %}
 7922 
 7923 instruct cacheWBPostSync()
 7924 %{
 7925   predicate(VM_Version::supports_data_cache_line_flush());
 7926   match(CacheWBPostSync);
 7927 
 7928   ins_cost(100);
 7929   format %{&quot;cache wb postsync&quot; %}
 7930   ins_encode %{
 7931     __ cache_wbsync(false);
 7932   %}
 7933   ins_pipe(pipe_slow); // XXX
 7934 %}
 7935 
 7936 // ============================================================================
 7937 // BSWAP Instructions
 7938 
 7939 instruct bytes_reverse_int(iRegINoSp dst, iRegIorL2I src) %{
 7940   match(Set dst (ReverseBytesI src));
 7941 
 7942   ins_cost(INSN_COST);
 7943   format %{ &quot;revw  $dst, $src&quot; %}
 7944 
 7945   ins_encode %{
 7946     __ revw(as_Register($dst$$reg), as_Register($src$$reg));
 7947   %}
 7948 
 7949   ins_pipe(ialu_reg);
 7950 %}
 7951 
 7952 instruct bytes_reverse_long(iRegLNoSp dst, iRegL src) %{
 7953   match(Set dst (ReverseBytesL src));
 7954 
 7955   ins_cost(INSN_COST);
 7956   format %{ &quot;rev  $dst, $src&quot; %}
 7957 
 7958   ins_encode %{
 7959     __ rev(as_Register($dst$$reg), as_Register($src$$reg));
 7960   %}
 7961 
 7962   ins_pipe(ialu_reg);
 7963 %}
 7964 
 7965 instruct bytes_reverse_unsigned_short(iRegINoSp dst, iRegIorL2I src) %{
 7966   match(Set dst (ReverseBytesUS src));
 7967 
 7968   ins_cost(INSN_COST);
 7969   format %{ &quot;rev16w  $dst, $src&quot; %}
 7970 
 7971   ins_encode %{
 7972     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7973   %}
 7974 
 7975   ins_pipe(ialu_reg);
 7976 %}
 7977 
 7978 instruct bytes_reverse_short(iRegINoSp dst, iRegIorL2I src) %{
 7979   match(Set dst (ReverseBytesS src));
 7980 
 7981   ins_cost(INSN_COST);
 7982   format %{ &quot;rev16w  $dst, $src\n\t&quot;
 7983             &quot;sbfmw $dst, $dst, #0, #15&quot; %}
 7984 
 7985   ins_encode %{
 7986     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7987     __ sbfmw(as_Register($dst$$reg), as_Register($dst$$reg), 0U, 15U);
 7988   %}
 7989 
 7990   ins_pipe(ialu_reg);
 7991 %}
 7992 
 7993 // ============================================================================
 7994 // Zero Count Instructions
 7995 
 7996 instruct countLeadingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 7997   match(Set dst (CountLeadingZerosI src));
 7998 
 7999   ins_cost(INSN_COST);
 8000   format %{ &quot;clzw  $dst, $src&quot; %}
 8001   ins_encode %{
 8002     __ clzw(as_Register($dst$$reg), as_Register($src$$reg));
 8003   %}
 8004 
 8005   ins_pipe(ialu_reg);
 8006 %}
 8007 
 8008 instruct countLeadingZerosL(iRegINoSp dst, iRegL src) %{
 8009   match(Set dst (CountLeadingZerosL src));
 8010 
 8011   ins_cost(INSN_COST);
 8012   format %{ &quot;clz   $dst, $src&quot; %}
 8013   ins_encode %{
 8014     __ clz(as_Register($dst$$reg), as_Register($src$$reg));
 8015   %}
 8016 
 8017   ins_pipe(ialu_reg);
 8018 %}
 8019 
 8020 instruct countTrailingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 8021   match(Set dst (CountTrailingZerosI src));
 8022 
 8023   ins_cost(INSN_COST * 2);
 8024   format %{ &quot;rbitw  $dst, $src\n\t&quot;
 8025             &quot;clzw   $dst, $dst&quot; %}
 8026   ins_encode %{
 8027     __ rbitw(as_Register($dst$$reg), as_Register($src$$reg));
 8028     __ clzw(as_Register($dst$$reg), as_Register($dst$$reg));
 8029   %}
 8030 
 8031   ins_pipe(ialu_reg);
 8032 %}
 8033 
 8034 instruct countTrailingZerosL(iRegINoSp dst, iRegL src) %{
 8035   match(Set dst (CountTrailingZerosL src));
 8036 
 8037   ins_cost(INSN_COST * 2);
 8038   format %{ &quot;rbit   $dst, $src\n\t&quot;
 8039             &quot;clz    $dst, $dst&quot; %}
 8040   ins_encode %{
 8041     __ rbit(as_Register($dst$$reg), as_Register($src$$reg));
 8042     __ clz(as_Register($dst$$reg), as_Register($dst$$reg));
 8043   %}
 8044 
 8045   ins_pipe(ialu_reg);
 8046 %}
 8047 
 8048 //---------- Population Count Instructions -------------------------------------
 8049 //
 8050 
 8051 instruct popCountI(iRegINoSp dst, iRegIorL2I src, vRegF tmp) %{
 8052   predicate(UsePopCountInstruction);
 8053   match(Set dst (PopCountI src));
 8054   effect(TEMP tmp);
 8055   ins_cost(INSN_COST * 13);
 8056 
 8057   format %{ &quot;movw   $src, $src\n\t&quot;
 8058             &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8059             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8060             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8061             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8062   ins_encode %{
 8063     __ movw($src$$Register, $src$$Register); // ensure top 32 bits 0
 8064     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8065     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8066     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8067     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8068   %}
 8069 
 8070   ins_pipe(pipe_class_default);
 8071 %}
 8072 
 8073 instruct popCountI_mem(iRegINoSp dst, memory4 mem, vRegF tmp) %{
 8074   predicate(UsePopCountInstruction);
 8075   match(Set dst (PopCountI (LoadI mem)));
 8076   effect(TEMP tmp);
 8077   ins_cost(INSN_COST * 13);
 8078 
 8079   format %{ &quot;ldrs   $tmp, $mem\n\t&quot;
 8080             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8081             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8082             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8083   ins_encode %{
 8084     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8085     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, tmp_reg, $mem-&gt;opcode(),
 8086               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 8087     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8088     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8089     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8090   %}
 8091 
 8092   ins_pipe(pipe_class_default);
 8093 %}
 8094 
 8095 // Note: Long.bitCount(long) returns an int.
 8096 instruct popCountL(iRegINoSp dst, iRegL src, vRegD tmp) %{
 8097   predicate(UsePopCountInstruction);
 8098   match(Set dst (PopCountL src));
 8099   effect(TEMP tmp);
 8100   ins_cost(INSN_COST * 13);
 8101 
 8102   format %{ &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8103             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8104             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8105             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8106   ins_encode %{
 8107     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8108     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8109     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8110     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8111   %}
 8112 
 8113   ins_pipe(pipe_class_default);
 8114 %}
 8115 
 8116 instruct popCountL_mem(iRegINoSp dst, memory8 mem, vRegD tmp) %{
 8117   predicate(UsePopCountInstruction);
 8118   match(Set dst (PopCountL (LoadL mem)));
 8119   effect(TEMP tmp);
 8120   ins_cost(INSN_COST * 13);
 8121 
 8122   format %{ &quot;ldrd   $tmp, $mem\n\t&quot;
 8123             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8124             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8125             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8126   ins_encode %{
 8127     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8128     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, tmp_reg, $mem-&gt;opcode(),
 8129               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 8130     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8131     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8132     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8133   %}
 8134 
 8135   ins_pipe(pipe_class_default);
 8136 %}
 8137 
 8138 // ============================================================================
 8139 // MemBar Instruction
 8140 
 8141 instruct load_fence() %{
 8142   match(LoadFence);
 8143   ins_cost(VOLATILE_REF_COST);
 8144 
 8145   format %{ &quot;load_fence&quot; %}
 8146 
 8147   ins_encode %{
 8148     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8149   %}
 8150   ins_pipe(pipe_serial);
 8151 %}
 8152 
 8153 instruct unnecessary_membar_acquire() %{
 8154   predicate(unnecessary_acquire(n));
 8155   match(MemBarAcquire);
 8156   ins_cost(0);
 8157 
 8158   format %{ &quot;membar_acquire (elided)&quot; %}
 8159 
 8160   ins_encode %{
 8161     __ block_comment(&quot;membar_acquire (elided)&quot;);
 8162   %}
 8163 
 8164   ins_pipe(pipe_class_empty);
 8165 %}
 8166 
 8167 instruct membar_acquire() %{
 8168   match(MemBarAcquire);
 8169   ins_cost(VOLATILE_REF_COST);
 8170 
 8171   format %{ &quot;membar_acquire\n\t&quot;
 8172             &quot;dmb ish&quot; %}
 8173 
 8174   ins_encode %{
 8175     __ block_comment(&quot;membar_acquire&quot;);
 8176     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8177   %}
 8178 
 8179   ins_pipe(pipe_serial);
 8180 %}
 8181 
 8182 
 8183 instruct membar_acquire_lock() %{
 8184   match(MemBarAcquireLock);
 8185   ins_cost(VOLATILE_REF_COST);
 8186 
 8187   format %{ &quot;membar_acquire_lock (elided)&quot; %}
 8188 
 8189   ins_encode %{
 8190     __ block_comment(&quot;membar_acquire_lock (elided)&quot;);
 8191   %}
 8192 
 8193   ins_pipe(pipe_serial);
 8194 %}
 8195 
 8196 instruct store_fence() %{
 8197   match(StoreFence);
 8198   ins_cost(VOLATILE_REF_COST);
 8199 
 8200   format %{ &quot;store_fence&quot; %}
 8201 
 8202   ins_encode %{
 8203     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8204   %}
 8205   ins_pipe(pipe_serial);
 8206 %}
 8207 
 8208 instruct unnecessary_membar_release() %{
 8209   predicate(unnecessary_release(n));
 8210   match(MemBarRelease);
 8211   ins_cost(0);
 8212 
 8213   format %{ &quot;membar_release (elided)&quot; %}
 8214 
 8215   ins_encode %{
 8216     __ block_comment(&quot;membar_release (elided)&quot;);
 8217   %}
 8218   ins_pipe(pipe_serial);
 8219 %}
 8220 
 8221 instruct membar_release() %{
 8222   match(MemBarRelease);
 8223   ins_cost(VOLATILE_REF_COST);
 8224 
 8225   format %{ &quot;membar_release\n\t&quot;
 8226             &quot;dmb ish&quot; %}
 8227 
 8228   ins_encode %{
 8229     __ block_comment(&quot;membar_release&quot;);
 8230     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8231   %}
 8232   ins_pipe(pipe_serial);
 8233 %}
 8234 
 8235 instruct membar_storestore() %{
 8236   match(MemBarStoreStore);
 8237   ins_cost(VOLATILE_REF_COST);
 8238 
 8239   format %{ &quot;MEMBAR-store-store&quot; %}
 8240 
 8241   ins_encode %{
 8242     __ membar(Assembler::StoreStore);
 8243   %}
 8244   ins_pipe(pipe_serial);
 8245 %}
 8246 
 8247 instruct membar_release_lock() %{
 8248   match(MemBarReleaseLock);
 8249   ins_cost(VOLATILE_REF_COST);
 8250 
 8251   format %{ &quot;membar_release_lock (elided)&quot; %}
 8252 
 8253   ins_encode %{
 8254     __ block_comment(&quot;membar_release_lock (elided)&quot;);
 8255   %}
 8256 
 8257   ins_pipe(pipe_serial);
 8258 %}
 8259 
 8260 instruct unnecessary_membar_volatile() %{
 8261   predicate(unnecessary_volatile(n));
 8262   match(MemBarVolatile);
 8263   ins_cost(0);
 8264 
 8265   format %{ &quot;membar_volatile (elided)&quot; %}
 8266 
 8267   ins_encode %{
 8268     __ block_comment(&quot;membar_volatile (elided)&quot;);
 8269   %}
 8270 
 8271   ins_pipe(pipe_serial);
 8272 %}
 8273 
 8274 instruct membar_volatile() %{
 8275   match(MemBarVolatile);
 8276   ins_cost(VOLATILE_REF_COST*100);
 8277 
 8278   format %{ &quot;membar_volatile\n\t&quot;
 8279              &quot;dmb ish&quot;%}
 8280 
 8281   ins_encode %{
 8282     __ block_comment(&quot;membar_volatile&quot;);
 8283     __ membar(Assembler::StoreLoad);
 8284   %}
 8285 
 8286   ins_pipe(pipe_serial);
 8287 %}
 8288 
 8289 // ============================================================================
 8290 // Cast/Convert Instructions
 8291 
 8292 instruct castX2P(iRegPNoSp dst, iRegL src) %{
 8293   match(Set dst (CastX2P src));
 8294 
 8295   ins_cost(INSN_COST);
 8296   format %{ &quot;mov $dst, $src\t# long -&gt; ptr&quot; %}
 8297 
 8298   ins_encode %{
 8299     if ($dst$$reg != $src$$reg) {
 8300       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8301     }
 8302   %}
 8303 
 8304   ins_pipe(ialu_reg);
 8305 %}
 8306 
<a name="8" id="anc8"></a><span class="line-added"> 8307 instruct castN2X(iRegLNoSp dst, iRegN src) %{</span>
<span class="line-added"> 8308   match(Set dst (CastP2X src));</span>
<span class="line-added"> 8309 </span>
<span class="line-added"> 8310   ins_cost(INSN_COST);</span>
<span class="line-added"> 8311   format %{ &quot;mov $dst, $src\t# ptr -&gt; long&quot; %}</span>
<span class="line-added"> 8312 </span>
<span class="line-added"> 8313   ins_encode %{</span>
<span class="line-added"> 8314     if ($dst$$reg != $src$$reg) {</span>
<span class="line-added"> 8315       __ mov(as_Register($dst$$reg), as_Register($src$$reg));</span>
<span class="line-added"> 8316     }</span>
<span class="line-added"> 8317   %}</span>
<span class="line-added"> 8318 </span>
<span class="line-added"> 8319   ins_pipe(ialu_reg);</span>
<span class="line-added"> 8320 %}</span>
<span class="line-added"> 8321 </span>
 8322 instruct castP2X(iRegLNoSp dst, iRegP src) %{
 8323   match(Set dst (CastP2X src));
 8324 
 8325   ins_cost(INSN_COST);
 8326   format %{ &quot;mov $dst, $src\t# ptr -&gt; long&quot; %}
 8327 
 8328   ins_encode %{
 8329     if ($dst$$reg != $src$$reg) {
 8330       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8331     }
 8332   %}
 8333 
 8334   ins_pipe(ialu_reg);
 8335 %}
 8336 
<a name="9" id="anc9"></a><span class="line-added"> 8337 instruct castN2I(iRegINoSp dst, iRegN src) %{</span>
<span class="line-added"> 8338   match(Set dst (CastN2I src));</span>
<span class="line-added"> 8339 </span>
<span class="line-added"> 8340   ins_cost(INSN_COST);</span>
<span class="line-added"> 8341   format %{ &quot;movw $dst, $src\t# compressed ptr -&gt; int&quot; %}</span>
<span class="line-added"> 8342 </span>
<span class="line-added"> 8343   ins_encode %{</span>
<span class="line-added"> 8344     if ($dst$$reg != $src$$reg) {</span>
<span class="line-added"> 8345       __ movw(as_Register($dst$$reg), as_Register($src$$reg));</span>
<span class="line-added"> 8346     }</span>
<span class="line-added"> 8347   %}</span>
<span class="line-added"> 8348 </span>
<span class="line-added"> 8349   ins_pipe(ialu_reg);</span>
<span class="line-added"> 8350 %}</span>
<span class="line-added"> 8351 </span>
<span class="line-added"> 8352 instruct castI2N(iRegNNoSp dst, iRegI src) %{</span>
<span class="line-added"> 8353   match(Set dst (CastI2N src));</span>
<span class="line-added"> 8354 </span>
<span class="line-added"> 8355   ins_cost(INSN_COST);</span>
<span class="line-added"> 8356   format %{ &quot;movw $dst, $src\t# int -&gt; compressed ptr&quot; %}</span>
<span class="line-added"> 8357 </span>
<span class="line-added"> 8358   ins_encode %{</span>
<span class="line-added"> 8359     if ($dst$$reg != $src$$reg) {</span>
<span class="line-added"> 8360       __ movw(as_Register($dst$$reg), as_Register($src$$reg));</span>
<span class="line-added"> 8361     }</span>
<span class="line-added"> 8362   %}</span>
<span class="line-added"> 8363 </span>
<span class="line-added"> 8364   ins_pipe(ialu_reg);</span>
<span class="line-added"> 8365 %}</span>
<span class="line-added"> 8366 </span>
<span class="line-added"> 8367 </span>
 8368 // Convert oop into int for vectors alignment masking
 8369 instruct convP2I(iRegINoSp dst, iRegP src) %{
 8370   match(Set dst (ConvL2I (CastP2X src)));
 8371 
 8372   ins_cost(INSN_COST);
 8373   format %{ &quot;movw $dst, $src\t# ptr -&gt; int&quot; %}
 8374   ins_encode %{
 8375     __ movw($dst$$Register, $src$$Register);
 8376   %}
 8377 
 8378   ins_pipe(ialu_reg);
 8379 %}
 8380 
 8381 // Convert compressed oop into int for vectors alignment masking
 8382 // in case of 32bit oops (heap &lt; 4Gb).
 8383 instruct convN2I(iRegINoSp dst, iRegN src)
 8384 %{
 8385   predicate(CompressedOops::shift() == 0);
 8386   match(Set dst (ConvL2I (CastP2X (DecodeN src))));
 8387 
 8388   ins_cost(INSN_COST);
 8389   format %{ &quot;mov dst, $src\t# compressed ptr -&gt; int&quot; %}
 8390   ins_encode %{
 8391     __ movw($dst$$Register, $src$$Register);
 8392   %}
 8393 
 8394   ins_pipe(ialu_reg);
 8395 %}
 8396 
 8397 
 8398 // Convert oop pointer into compressed form
 8399 instruct encodeHeapOop(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8400   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() != TypePtr::NotNull);
 8401   match(Set dst (EncodeP src));
 8402   effect(KILL cr);
 8403   ins_cost(INSN_COST * 3);
 8404   format %{ &quot;encode_heap_oop $dst, $src&quot; %}
 8405   ins_encode %{
 8406     Register s = $src$$Register;
 8407     Register d = $dst$$Register;
 8408     __ encode_heap_oop(d, s);
 8409   %}
 8410   ins_pipe(ialu_reg);
 8411 %}
 8412 
 8413 instruct encodeHeapOop_not_null(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8414   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() == TypePtr::NotNull);
 8415   match(Set dst (EncodeP src));
 8416   ins_cost(INSN_COST * 3);
 8417   format %{ &quot;encode_heap_oop_not_null $dst, $src&quot; %}
 8418   ins_encode %{
 8419     __ encode_heap_oop_not_null($dst$$Register, $src$$Register);
 8420   %}
 8421   ins_pipe(ialu_reg);
 8422 %}
 8423 
 8424 instruct decodeHeapOop(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8425   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::NotNull &amp;&amp;
 8426             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::Constant);
 8427   match(Set dst (DecodeN src));
 8428   ins_cost(INSN_COST * 3);
 8429   format %{ &quot;decode_heap_oop $dst, $src&quot; %}
 8430   ins_encode %{
 8431     Register s = $src$$Register;
 8432     Register d = $dst$$Register;
 8433     __ decode_heap_oop(d, s);
 8434   %}
 8435   ins_pipe(ialu_reg);
 8436 %}
 8437 
 8438 instruct decodeHeapOop_not_null(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8439   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::NotNull ||
 8440             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::Constant);
 8441   match(Set dst (DecodeN src));
 8442   ins_cost(INSN_COST * 3);
 8443   format %{ &quot;decode_heap_oop_not_null $dst, $src&quot; %}
 8444   ins_encode %{
 8445     Register s = $src$$Register;
 8446     Register d = $dst$$Register;
 8447     __ decode_heap_oop_not_null(d, s);
 8448   %}
 8449   ins_pipe(ialu_reg);
 8450 %}
 8451 
 8452 // n.b. AArch64 implementations of encode_klass_not_null and
 8453 // decode_klass_not_null do not modify the flags register so, unlike
 8454 // Intel, we don&#39;t kill CR as a side effect here
 8455 
 8456 instruct encodeKlass_not_null(iRegNNoSp dst, iRegP src) %{
 8457   match(Set dst (EncodePKlass src));
 8458 
 8459   ins_cost(INSN_COST * 3);
 8460   format %{ &quot;encode_klass_not_null $dst,$src&quot; %}
 8461 
 8462   ins_encode %{
 8463     Register src_reg = as_Register($src$$reg);
 8464     Register dst_reg = as_Register($dst$$reg);
 8465     __ encode_klass_not_null(dst_reg, src_reg);
 8466   %}
 8467 
 8468    ins_pipe(ialu_reg);
 8469 %}
 8470 
 8471 instruct decodeKlass_not_null(iRegPNoSp dst, iRegN src) %{
 8472   match(Set dst (DecodeNKlass src));
 8473 
 8474   ins_cost(INSN_COST * 3);
 8475   format %{ &quot;decode_klass_not_null $dst,$src&quot; %}
 8476 
 8477   ins_encode %{
 8478     Register src_reg = as_Register($src$$reg);
 8479     Register dst_reg = as_Register($dst$$reg);
 8480     if (dst_reg != src_reg) {
 8481       __ decode_klass_not_null(dst_reg, src_reg);
 8482     } else {
 8483       __ decode_klass_not_null(dst_reg);
 8484     }
 8485   %}
 8486 
 8487    ins_pipe(ialu_reg);
 8488 %}
 8489 
 8490 instruct checkCastPP(iRegPNoSp dst)
 8491 %{
 8492   match(Set dst (CheckCastPP dst));
 8493 
 8494   size(0);
 8495   format %{ &quot;# checkcastPP of $dst&quot; %}
 8496   ins_encode(/* empty encoding */);
 8497   ins_pipe(pipe_class_empty);
 8498 %}
 8499 
 8500 instruct castPP(iRegPNoSp dst)
 8501 %{
 8502   match(Set dst (CastPP dst));
 8503 
 8504   size(0);
 8505   format %{ &quot;# castPP of $dst&quot; %}
 8506   ins_encode(/* empty encoding */);
 8507   ins_pipe(pipe_class_empty);
 8508 %}
 8509 
 8510 instruct castII(iRegI dst)
 8511 %{
 8512   match(Set dst (CastII dst));
 8513 
 8514   size(0);
 8515   format %{ &quot;# castII of $dst&quot; %}
 8516   ins_encode(/* empty encoding */);
 8517   ins_cost(0);
 8518   ins_pipe(pipe_class_empty);
 8519 %}
 8520 
 8521 // ============================================================================
 8522 // Atomic operation instructions
 8523 //
 8524 // Intel and SPARC both implement Ideal Node LoadPLocked and
 8525 // Store{PIL}Conditional instructions using a normal load for the
 8526 // LoadPLocked and a CAS for the Store{PIL}Conditional.
 8527 //
 8528 // The ideal code appears only to use LoadPLocked/StorePLocked as a
 8529 // pair to lock object allocations from Eden space when not using
 8530 // TLABs.
 8531 //
 8532 // There does not appear to be a Load{IL}Locked Ideal Node and the
 8533 // Ideal code appears to use Store{IL}Conditional as an alias for CAS
 8534 // and to use StoreIConditional only for 32-bit and StoreLConditional
 8535 // only for 64-bit.
 8536 //
 8537 // We implement LoadPLocked and StorePLocked instructions using,
 8538 // respectively the AArch64 hw load-exclusive and store-conditional
 8539 // instructions. Whereas we must implement each of
 8540 // Store{IL}Conditional using a CAS which employs a pair of
 8541 // instructions comprising a load-exclusive followed by a
 8542 // store-conditional.
 8543 
 8544 
 8545 // Locked-load (linked load) of the current heap-top
 8546 // used when updating the eden heap top
 8547 // implemented using ldaxr on AArch64
 8548 
 8549 instruct loadPLocked(iRegPNoSp dst, indirect mem)
 8550 %{
 8551   match(Set dst (LoadPLocked mem));
 8552 
 8553   ins_cost(VOLATILE_REF_COST);
 8554 
 8555   format %{ &quot;ldaxr $dst, $mem\t# ptr linked acquire&quot; %}
 8556 
 8557   ins_encode(aarch64_enc_ldaxr(dst, mem));
 8558 
 8559   ins_pipe(pipe_serial);
 8560 %}
 8561 
 8562 // Conditional-store of the updated heap-top.
 8563 // Used during allocation of the shared heap.
 8564 // Sets flag (EQ) on success.
 8565 // implemented using stlxr on AArch64.
 8566 
 8567 instruct storePConditional(memory8 heap_top_ptr, iRegP oldval, iRegP newval, rFlagsReg cr)
 8568 %{
 8569   match(Set cr (StorePConditional heap_top_ptr (Binary oldval newval)));
 8570 
 8571   ins_cost(VOLATILE_REF_COST);
 8572 
 8573  // TODO
 8574  // do we need to do a store-conditional release or can we just use a
 8575  // plain store-conditional?
 8576 
 8577   format %{
 8578     &quot;stlxr rscratch1, $newval, $heap_top_ptr\t# ptr cond release&quot;
 8579     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8580   %}
 8581 
 8582   ins_encode(aarch64_enc_stlxr(newval, heap_top_ptr));
 8583 
 8584   ins_pipe(pipe_serial);
 8585 %}
 8586 
 8587 
 8588 // storeLConditional is used by PhaseMacroExpand::expand_lock_node
 8589 // when attempting to rebias a lock towards the current thread.  We
 8590 // must use the acquire form of cmpxchg in order to guarantee acquire
 8591 // semantics in this case.
 8592 instruct storeLConditional(indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr)
 8593 %{
 8594   match(Set cr (StoreLConditional mem (Binary oldval newval)));
 8595 
 8596   ins_cost(VOLATILE_REF_COST);
 8597 
 8598   format %{
 8599     &quot;cmpxchg rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8600     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8601   %}
 8602 
 8603   ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval));
 8604 
 8605   ins_pipe(pipe_slow);
 8606 %}
 8607 
 8608 // storeIConditional also has acquire semantics, for no better reason
 8609 // than matching storeLConditional.  At the time of writing this
 8610 // comment storeIConditional was not used anywhere by AArch64.
 8611 instruct storeIConditional(indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr)
 8612 %{
 8613   match(Set cr (StoreIConditional mem (Binary oldval newval)));
 8614 
 8615   ins_cost(VOLATILE_REF_COST);
 8616 
 8617   format %{
 8618     &quot;cmpxchgw rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8619     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8620   %}
 8621 
 8622   ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval));
 8623 
 8624   ins_pipe(pipe_slow);
 8625 %}
 8626 
 8627 // standard CompareAndSwapX when we are using barriers
 8628 // these have higher priority than the rules selected by a predicate
 8629 
 8630 // XXX No flag versions for CompareAndSwap{I,L,P,N} because matcher
 8631 // can&#39;t match them
 8632 
 8633 instruct compareAndSwapB(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8634 
 8635   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8636   ins_cost(2 * VOLATILE_REF_COST);
 8637 
 8638   effect(KILL cr);
 8639 
 8640   format %{
 8641     &quot;cmpxchgb $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8642     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8643   %}
 8644 
 8645   ins_encode(aarch64_enc_cmpxchgb(mem, oldval, newval),
 8646             aarch64_enc_cset_eq(res));
 8647 
 8648   ins_pipe(pipe_slow);
 8649 %}
 8650 
 8651 instruct compareAndSwapS(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8652 
 8653   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8654   ins_cost(2 * VOLATILE_REF_COST);
 8655 
 8656   effect(KILL cr);
 8657 
 8658   format %{
 8659     &quot;cmpxchgs $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8660     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8661   %}
 8662 
 8663   ins_encode(aarch64_enc_cmpxchgs(mem, oldval, newval),
 8664             aarch64_enc_cset_eq(res));
 8665 
 8666   ins_pipe(pipe_slow);
 8667 %}
 8668 
 8669 instruct compareAndSwapI(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8670 
 8671   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8672   ins_cost(2 * VOLATILE_REF_COST);
 8673 
 8674   effect(KILL cr);
 8675 
 8676  format %{
 8677     &quot;cmpxchgw $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8678     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8679  %}
 8680 
 8681  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8682             aarch64_enc_cset_eq(res));
 8683 
 8684   ins_pipe(pipe_slow);
 8685 %}
 8686 
 8687 instruct compareAndSwapL(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8688 
 8689   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8690   ins_cost(2 * VOLATILE_REF_COST);
 8691 
 8692   effect(KILL cr);
 8693 
 8694  format %{
 8695     &quot;cmpxchg $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8696     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8697  %}
 8698 
 8699  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8700             aarch64_enc_cset_eq(res));
 8701 
 8702   ins_pipe(pipe_slow);
 8703 %}
 8704 
 8705 instruct compareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8706 
 8707   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8708   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8709   ins_cost(2 * VOLATILE_REF_COST);
 8710 
 8711   effect(KILL cr);
 8712 
 8713  format %{
 8714     &quot;cmpxchg $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8715     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8716  %}
 8717 
 8718  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8719             aarch64_enc_cset_eq(res));
 8720 
 8721   ins_pipe(pipe_slow);
 8722 %}
 8723 
 8724 instruct compareAndSwapN(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8725 
 8726   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8727   ins_cost(2 * VOLATILE_REF_COST);
 8728 
 8729   effect(KILL cr);
 8730 
 8731  format %{
 8732     &quot;cmpxchgw $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8733     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8734  %}
 8735 
 8736  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8737             aarch64_enc_cset_eq(res));
 8738 
 8739   ins_pipe(pipe_slow);
 8740 %}
 8741 
 8742 // alternative CompareAndSwapX when we are eliding barriers
 8743 
 8744 instruct compareAndSwapBAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8745 
 8746   predicate(needs_acquiring_load_exclusive(n));
 8747   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8748   ins_cost(VOLATILE_REF_COST);
 8749 
 8750   effect(KILL cr);
 8751 
 8752   format %{
 8753     &quot;cmpxchgb_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8754     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8755   %}
 8756 
 8757   ins_encode(aarch64_enc_cmpxchgb_acq(mem, oldval, newval),
 8758             aarch64_enc_cset_eq(res));
 8759 
 8760   ins_pipe(pipe_slow);
 8761 %}
 8762 
 8763 instruct compareAndSwapSAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8764 
 8765   predicate(needs_acquiring_load_exclusive(n));
 8766   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8767   ins_cost(VOLATILE_REF_COST);
 8768 
 8769   effect(KILL cr);
 8770 
 8771   format %{
 8772     &quot;cmpxchgs_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8773     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8774   %}
 8775 
 8776   ins_encode(aarch64_enc_cmpxchgs_acq(mem, oldval, newval),
 8777             aarch64_enc_cset_eq(res));
 8778 
 8779   ins_pipe(pipe_slow);
 8780 %}
 8781 
 8782 instruct compareAndSwapIAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8783 
 8784   predicate(needs_acquiring_load_exclusive(n));
 8785   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8786   ins_cost(VOLATILE_REF_COST);
 8787 
 8788   effect(KILL cr);
 8789 
 8790  format %{
 8791     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8792     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8793  %}
 8794 
 8795  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8796             aarch64_enc_cset_eq(res));
 8797 
 8798   ins_pipe(pipe_slow);
 8799 %}
 8800 
 8801 instruct compareAndSwapLAcq(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8802 
 8803   predicate(needs_acquiring_load_exclusive(n));
 8804   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8805   ins_cost(VOLATILE_REF_COST);
 8806 
 8807   effect(KILL cr);
 8808 
 8809  format %{
 8810     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8811     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8812  %}
 8813 
 8814  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8815             aarch64_enc_cset_eq(res));
 8816 
 8817   ins_pipe(pipe_slow);
 8818 %}
 8819 
 8820 instruct compareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8821 
 8822   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 8823   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8824   ins_cost(VOLATILE_REF_COST);
 8825 
 8826   effect(KILL cr);
 8827 
 8828  format %{
 8829     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8830     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8831  %}
 8832 
 8833  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8834             aarch64_enc_cset_eq(res));
 8835 
 8836   ins_pipe(pipe_slow);
 8837 %}
 8838 
 8839 instruct compareAndSwapNAcq(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8840 
 8841   predicate(needs_acquiring_load_exclusive(n));
 8842   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8843   ins_cost(VOLATILE_REF_COST);
 8844 
 8845   effect(KILL cr);
 8846 
 8847  format %{
 8848     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8849     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8850  %}
 8851 
 8852  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8853             aarch64_enc_cset_eq(res));
 8854 
 8855   ins_pipe(pipe_slow);
 8856 %}
 8857 
 8858 
 8859 // ---------------------------------------------------------------------
 8860 
 8861 
 8862 // BEGIN This section of the file is automatically generated. Do not edit --------------
 8863 
 8864 // Sundry CAS operations.  Note that release is always true,
 8865 // regardless of the memory ordering of the CAS.  This is because we
 8866 // need the volatile case to be sequentially consistent but there is
 8867 // no trailing StoreLoad barrier emitted by C2.  Unfortunately we
 8868 // can&#39;t check the type of memory ordering here, so we always emit a
 8869 // STLXR.
 8870 
 8871 // This section is generated from aarch64_ad_cas.m4
 8872 
 8873 
 8874 
 8875 instruct compareAndExchangeB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8876   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8877   ins_cost(2 * VOLATILE_REF_COST);
 8878   effect(TEMP_DEF res, KILL cr);
 8879   format %{
 8880     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8881   %}
 8882   ins_encode %{
 8883     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8884                Assembler::byte, /*acquire*/ false, /*release*/ true,
 8885                /*weak*/ false, $res$$Register);
 8886     __ sxtbw($res$$Register, $res$$Register);
 8887   %}
 8888   ins_pipe(pipe_slow);
 8889 %}
 8890 
 8891 instruct compareAndExchangeS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8892   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8893   ins_cost(2 * VOLATILE_REF_COST);
 8894   effect(TEMP_DEF res, KILL cr);
 8895   format %{
 8896     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8897   %}
 8898   ins_encode %{
 8899     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8900                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 8901                /*weak*/ false, $res$$Register);
 8902     __ sxthw($res$$Register, $res$$Register);
 8903   %}
 8904   ins_pipe(pipe_slow);
 8905 %}
 8906 
 8907 instruct compareAndExchangeI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8908   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8909   ins_cost(2 * VOLATILE_REF_COST);
 8910   effect(TEMP_DEF res, KILL cr);
 8911   format %{
 8912     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8913   %}
 8914   ins_encode %{
 8915     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8916                Assembler::word, /*acquire*/ false, /*release*/ true,
 8917                /*weak*/ false, $res$$Register);
 8918   %}
 8919   ins_pipe(pipe_slow);
 8920 %}
 8921 
 8922 instruct compareAndExchangeL(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8923   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8924   ins_cost(2 * VOLATILE_REF_COST);
 8925   effect(TEMP_DEF res, KILL cr);
 8926   format %{
 8927     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8928   %}
 8929   ins_encode %{
 8930     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8931                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8932                /*weak*/ false, $res$$Register);
 8933   %}
 8934   ins_pipe(pipe_slow);
 8935 %}
 8936 
 8937 instruct compareAndExchangeN(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8938   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8939   ins_cost(2 * VOLATILE_REF_COST);
 8940   effect(TEMP_DEF res, KILL cr);
 8941   format %{
 8942     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8943   %}
 8944   ins_encode %{
 8945     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8946                Assembler::word, /*acquire*/ false, /*release*/ true,
 8947                /*weak*/ false, $res$$Register);
 8948   %}
 8949   ins_pipe(pipe_slow);
 8950 %}
 8951 
 8952 instruct compareAndExchangeP(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8953   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8954   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 8955   ins_cost(2 * VOLATILE_REF_COST);
 8956   effect(TEMP_DEF res, KILL cr);
 8957   format %{
 8958     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8959   %}
 8960   ins_encode %{
 8961     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8962                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8963                /*weak*/ false, $res$$Register);
 8964   %}
 8965   ins_pipe(pipe_slow);
 8966 %}
 8967 
 8968 instruct compareAndExchangeBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8969   predicate(needs_acquiring_load_exclusive(n));
 8970   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8971   ins_cost(VOLATILE_REF_COST);
 8972   effect(TEMP_DEF res, KILL cr);
 8973   format %{
 8974     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8975   %}
 8976   ins_encode %{
 8977     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8978                Assembler::byte, /*acquire*/ true, /*release*/ true,
 8979                /*weak*/ false, $res$$Register);
 8980     __ sxtbw($res$$Register, $res$$Register);
 8981   %}
 8982   ins_pipe(pipe_slow);
 8983 %}
 8984 
 8985 instruct compareAndExchangeSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8986   predicate(needs_acquiring_load_exclusive(n));
 8987   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8988   ins_cost(VOLATILE_REF_COST);
 8989   effect(TEMP_DEF res, KILL cr);
 8990   format %{
 8991     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8992   %}
 8993   ins_encode %{
 8994     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8995                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 8996                /*weak*/ false, $res$$Register);
 8997     __ sxthw($res$$Register, $res$$Register);
 8998   %}
 8999   ins_pipe(pipe_slow);
 9000 %}
 9001 
 9002 
 9003 instruct compareAndExchangeIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9004   predicate(needs_acquiring_load_exclusive(n));
 9005   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 9006   ins_cost(VOLATILE_REF_COST);
 9007   effect(TEMP_DEF res, KILL cr);
 9008   format %{
 9009     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9010   %}
 9011   ins_encode %{
 9012     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9013                Assembler::word, /*acquire*/ true, /*release*/ true,
 9014                /*weak*/ false, $res$$Register);
 9015   %}
 9016   ins_pipe(pipe_slow);
 9017 %}
 9018 
 9019 instruct compareAndExchangeLAcq(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9020   predicate(needs_acquiring_load_exclusive(n));
 9021   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 9022   ins_cost(VOLATILE_REF_COST);
 9023   effect(TEMP_DEF res, KILL cr);
 9024   format %{
 9025     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9026   %}
 9027   ins_encode %{
 9028     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9029                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9030                /*weak*/ false, $res$$Register);
 9031   %}
 9032   ins_pipe(pipe_slow);
 9033 %}
 9034 
 9035 
 9036 instruct compareAndExchangeNAcq(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9037   predicate(needs_acquiring_load_exclusive(n));
 9038   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 9039   ins_cost(VOLATILE_REF_COST);
 9040   effect(TEMP_DEF res, KILL cr);
 9041   format %{
 9042     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9043   %}
 9044   ins_encode %{
 9045     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9046                Assembler::word, /*acquire*/ true, /*release*/ true,
 9047                /*weak*/ false, $res$$Register);
 9048   %}
 9049   ins_pipe(pipe_slow);
 9050 %}
 9051 
 9052 instruct compareAndExchangePAcq(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9053   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9054   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 9055   ins_cost(VOLATILE_REF_COST);
 9056   effect(TEMP_DEF res, KILL cr);
 9057   format %{
 9058     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9059   %}
 9060   ins_encode %{
 9061     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9062                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9063                /*weak*/ false, $res$$Register);
 9064   %}
 9065   ins_pipe(pipe_slow);
 9066 %}
 9067 
 9068 instruct weakCompareAndSwapB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9069   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9070   ins_cost(2 * VOLATILE_REF_COST);
 9071   effect(KILL cr);
 9072   format %{
 9073     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9074     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9075   %}
 9076   ins_encode %{
 9077     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9078                Assembler::byte, /*acquire*/ false, /*release*/ true,
 9079                /*weak*/ true, noreg);
 9080     __ csetw($res$$Register, Assembler::EQ);
 9081   %}
 9082   ins_pipe(pipe_slow);
 9083 %}
 9084 
 9085 instruct weakCompareAndSwapS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9086   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9087   ins_cost(2 * VOLATILE_REF_COST);
 9088   effect(KILL cr);
 9089   format %{
 9090     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9091     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9092   %}
 9093   ins_encode %{
 9094     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9095                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 9096                /*weak*/ true, noreg);
 9097     __ csetw($res$$Register, Assembler::EQ);
 9098   %}
 9099   ins_pipe(pipe_slow);
 9100 %}
 9101 
 9102 instruct weakCompareAndSwapI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9103   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9104   ins_cost(2 * VOLATILE_REF_COST);
 9105   effect(KILL cr);
 9106   format %{
 9107     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9108     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9109   %}
 9110   ins_encode %{
 9111     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9112                Assembler::word, /*acquire*/ false, /*release*/ true,
 9113                /*weak*/ true, noreg);
 9114     __ csetw($res$$Register, Assembler::EQ);
 9115   %}
 9116   ins_pipe(pipe_slow);
 9117 %}
 9118 
 9119 instruct weakCompareAndSwapL(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9120   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9121   ins_cost(2 * VOLATILE_REF_COST);
 9122   effect(KILL cr);
 9123   format %{
 9124     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9125     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9126   %}
 9127   ins_encode %{
 9128     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9129                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9130                /*weak*/ true, noreg);
 9131     __ csetw($res$$Register, Assembler::EQ);
 9132   %}
 9133   ins_pipe(pipe_slow);
 9134 %}
 9135 
 9136 instruct weakCompareAndSwapN(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9137   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9138   ins_cost(2 * VOLATILE_REF_COST);
 9139   effect(KILL cr);
 9140   format %{
 9141     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9142     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9143   %}
 9144   ins_encode %{
 9145     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9146                Assembler::word, /*acquire*/ false, /*release*/ true,
 9147                /*weak*/ true, noreg);
 9148     __ csetw($res$$Register, Assembler::EQ);
 9149   %}
 9150   ins_pipe(pipe_slow);
 9151 %}
 9152 
 9153 instruct weakCompareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9154   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9155   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9156   ins_cost(2 * VOLATILE_REF_COST);
 9157   effect(KILL cr);
 9158   format %{
 9159     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9160     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9161   %}
 9162   ins_encode %{
 9163     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9164                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9165                /*weak*/ true, noreg);
 9166     __ csetw($res$$Register, Assembler::EQ);
 9167   %}
 9168   ins_pipe(pipe_slow);
 9169 %}
 9170 
 9171 instruct weakCompareAndSwapBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9172   predicate(needs_acquiring_load_exclusive(n));
 9173   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9174   ins_cost(VOLATILE_REF_COST);
 9175   effect(KILL cr);
 9176   format %{
 9177     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9178     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9179   %}
 9180   ins_encode %{
 9181     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9182                Assembler::byte, /*acquire*/ true, /*release*/ true,
 9183                /*weak*/ true, noreg);
 9184     __ csetw($res$$Register, Assembler::EQ);
 9185   %}
 9186   ins_pipe(pipe_slow);
 9187 %}
 9188 
 9189 instruct weakCompareAndSwapSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9190   predicate(needs_acquiring_load_exclusive(n));
 9191   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9192   ins_cost(VOLATILE_REF_COST);
 9193   effect(KILL cr);
 9194   format %{
 9195     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9196     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9197   %}
 9198   ins_encode %{
 9199     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9200                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 9201                /*weak*/ true, noreg);
 9202     __ csetw($res$$Register, Assembler::EQ);
 9203   %}
 9204   ins_pipe(pipe_slow);
 9205 %}
 9206 
 9207 instruct weakCompareAndSwapIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9208   predicate(needs_acquiring_load_exclusive(n));
 9209   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9210   ins_cost(VOLATILE_REF_COST);
 9211   effect(KILL cr);
 9212   format %{
 9213     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9214     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9215   %}
 9216   ins_encode %{
 9217     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9218                Assembler::word, /*acquire*/ true, /*release*/ true,
 9219                /*weak*/ true, noreg);
 9220     __ csetw($res$$Register, Assembler::EQ);
 9221   %}
 9222   ins_pipe(pipe_slow);
 9223 %}
 9224 
 9225 instruct weakCompareAndSwapLAcq(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9226   predicate(needs_acquiring_load_exclusive(n));
 9227   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9228   ins_cost(VOLATILE_REF_COST);
 9229   effect(KILL cr);
 9230   format %{
 9231     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9232     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9233   %}
 9234   ins_encode %{
 9235     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9236                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9237                /*weak*/ true, noreg);
 9238     __ csetw($res$$Register, Assembler::EQ);
 9239   %}
 9240   ins_pipe(pipe_slow);
 9241 %}
 9242 
 9243 instruct weakCompareAndSwapNAcq(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9244   predicate(needs_acquiring_load_exclusive(n));
 9245   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9246   ins_cost(VOLATILE_REF_COST);
 9247   effect(KILL cr);
 9248   format %{
 9249     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9250     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9251   %}
 9252   ins_encode %{
 9253     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9254                Assembler::word, /*acquire*/ true, /*release*/ true,
 9255                /*weak*/ true, noreg);
 9256     __ csetw($res$$Register, Assembler::EQ);
 9257   %}
 9258   ins_pipe(pipe_slow);
 9259 %}
 9260 
 9261 instruct weakCompareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9262   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9263   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9264   ins_cost(VOLATILE_REF_COST);
 9265   effect(KILL cr);
 9266   format %{
 9267     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9268     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9269   %}
 9270   ins_encode %{
 9271     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9272                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9273                /*weak*/ true, noreg);
 9274     __ csetw($res$$Register, Assembler::EQ);
 9275   %}
 9276   ins_pipe(pipe_slow);
 9277 %}
 9278 
 9279 // END This section of the file is automatically generated. Do not edit --------------
 9280 // ---------------------------------------------------------------------
 9281 
 9282 instruct get_and_setI(indirect mem, iRegI newv, iRegINoSp prev) %{
 9283   match(Set prev (GetAndSetI mem newv));
 9284   ins_cost(2 * VOLATILE_REF_COST);
 9285   format %{ &quot;atomic_xchgw  $prev, $newv, [$mem]&quot; %}
 9286   ins_encode %{
 9287     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9288   %}
 9289   ins_pipe(pipe_serial);
 9290 %}
 9291 
 9292 instruct get_and_setL(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9293   match(Set prev (GetAndSetL mem newv));
 9294   ins_cost(2 * VOLATILE_REF_COST);
 9295   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9296   ins_encode %{
 9297     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9298   %}
 9299   ins_pipe(pipe_serial);
 9300 %}
 9301 
 9302 instruct get_and_setN(indirect mem, iRegN newv, iRegINoSp prev) %{
 9303   match(Set prev (GetAndSetN mem newv));
 9304   ins_cost(2 * VOLATILE_REF_COST);
 9305   format %{ &quot;atomic_xchgw $prev, $newv, [$mem]&quot; %}
 9306   ins_encode %{
 9307     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9308   %}
 9309   ins_pipe(pipe_serial);
 9310 %}
 9311 
 9312 instruct get_and_setP(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9313   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9314   match(Set prev (GetAndSetP mem newv));
 9315   ins_cost(2 * VOLATILE_REF_COST);
 9316   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9317   ins_encode %{
 9318     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9319   %}
 9320   ins_pipe(pipe_serial);
 9321 %}
 9322 
 9323 instruct get_and_setIAcq(indirect mem, iRegI newv, iRegINoSp prev) %{
 9324   predicate(needs_acquiring_load_exclusive(n));
 9325   match(Set prev (GetAndSetI mem newv));
 9326   ins_cost(VOLATILE_REF_COST);
 9327   format %{ &quot;atomic_xchgw_acq  $prev, $newv, [$mem]&quot; %}
 9328   ins_encode %{
 9329     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9330   %}
 9331   ins_pipe(pipe_serial);
 9332 %}
 9333 
 9334 instruct get_and_setLAcq(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9335   predicate(needs_acquiring_load_exclusive(n));
 9336   match(Set prev (GetAndSetL mem newv));
 9337   ins_cost(VOLATILE_REF_COST);
 9338   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9339   ins_encode %{
 9340     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9341   %}
 9342   ins_pipe(pipe_serial);
 9343 %}
 9344 
 9345 instruct get_and_setNAcq(indirect mem, iRegN newv, iRegINoSp prev) %{
 9346   predicate(needs_acquiring_load_exclusive(n));
 9347   match(Set prev (GetAndSetN mem newv));
 9348   ins_cost(VOLATILE_REF_COST);
 9349   format %{ &quot;atomic_xchgw_acq $prev, $newv, [$mem]&quot; %}
 9350   ins_encode %{
 9351     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9352   %}
 9353   ins_pipe(pipe_serial);
 9354 %}
 9355 
 9356 instruct get_and_setPAcq(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9357   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9358   match(Set prev (GetAndSetP mem newv));
 9359   ins_cost(VOLATILE_REF_COST);
 9360   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9361   ins_encode %{
 9362     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9363   %}
 9364   ins_pipe(pipe_serial);
 9365 %}
 9366 
 9367 
 9368 instruct get_and_addL(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9369   match(Set newval (GetAndAddL mem incr));
 9370   ins_cost(2 * VOLATILE_REF_COST + 1);
 9371   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9372   ins_encode %{
 9373     __ atomic_add($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9374   %}
 9375   ins_pipe(pipe_serial);
 9376 %}
 9377 
 9378 instruct get_and_addL_no_res(indirect mem, Universe dummy, iRegL incr) %{
 9379   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9380   match(Set dummy (GetAndAddL mem incr));
 9381   ins_cost(2 * VOLATILE_REF_COST);
 9382   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9383   ins_encode %{
 9384     __ atomic_add(noreg, $incr$$Register, as_Register($mem$$base));
 9385   %}
 9386   ins_pipe(pipe_serial);
 9387 %}
 9388 
 9389 instruct get_and_addLi(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9390   match(Set newval (GetAndAddL mem incr));
 9391   ins_cost(2 * VOLATILE_REF_COST + 1);
 9392   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9393   ins_encode %{
 9394     __ atomic_add($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9395   %}
 9396   ins_pipe(pipe_serial);
 9397 %}
 9398 
 9399 instruct get_and_addLi_no_res(indirect mem, Universe dummy, immLAddSub incr) %{
 9400   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9401   match(Set dummy (GetAndAddL mem incr));
 9402   ins_cost(2 * VOLATILE_REF_COST);
 9403   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9404   ins_encode %{
 9405     __ atomic_add(noreg, $incr$$constant, as_Register($mem$$base));
 9406   %}
 9407   ins_pipe(pipe_serial);
 9408 %}
 9409 
 9410 instruct get_and_addI(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9411   match(Set newval (GetAndAddI mem incr));
 9412   ins_cost(2 * VOLATILE_REF_COST + 1);
 9413   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9414   ins_encode %{
 9415     __ atomic_addw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9416   %}
 9417   ins_pipe(pipe_serial);
 9418 %}
 9419 
 9420 instruct get_and_addI_no_res(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9421   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9422   match(Set dummy (GetAndAddI mem incr));
 9423   ins_cost(2 * VOLATILE_REF_COST);
 9424   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9425   ins_encode %{
 9426     __ atomic_addw(noreg, $incr$$Register, as_Register($mem$$base));
 9427   %}
 9428   ins_pipe(pipe_serial);
 9429 %}
 9430 
 9431 instruct get_and_addIi(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9432   match(Set newval (GetAndAddI mem incr));
 9433   ins_cost(2 * VOLATILE_REF_COST + 1);
 9434   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9435   ins_encode %{
 9436     __ atomic_addw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9437   %}
 9438   ins_pipe(pipe_serial);
 9439 %}
 9440 
 9441 instruct get_and_addIi_no_res(indirect mem, Universe dummy, immIAddSub incr) %{
 9442   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9443   match(Set dummy (GetAndAddI mem incr));
 9444   ins_cost(2 * VOLATILE_REF_COST);
 9445   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9446   ins_encode %{
 9447     __ atomic_addw(noreg, $incr$$constant, as_Register($mem$$base));
 9448   %}
 9449   ins_pipe(pipe_serial);
 9450 %}
 9451 
 9452 instruct get_and_addLAcq(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9453   predicate(needs_acquiring_load_exclusive(n));
 9454   match(Set newval (GetAndAddL mem incr));
 9455   ins_cost(VOLATILE_REF_COST + 1);
 9456   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9457   ins_encode %{
 9458     __ atomic_addal($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9459   %}
 9460   ins_pipe(pipe_serial);
 9461 %}
 9462 
 9463 instruct get_and_addL_no_resAcq(indirect mem, Universe dummy, iRegL incr) %{
 9464   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9465   match(Set dummy (GetAndAddL mem incr));
 9466   ins_cost(VOLATILE_REF_COST);
 9467   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9468   ins_encode %{
 9469     __ atomic_addal(noreg, $incr$$Register, as_Register($mem$$base));
 9470   %}
 9471   ins_pipe(pipe_serial);
 9472 %}
 9473 
 9474 instruct get_and_addLiAcq(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9475   predicate(needs_acquiring_load_exclusive(n));
 9476   match(Set newval (GetAndAddL mem incr));
 9477   ins_cost(VOLATILE_REF_COST + 1);
 9478   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9479   ins_encode %{
 9480     __ atomic_addal($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9481   %}
 9482   ins_pipe(pipe_serial);
 9483 %}
 9484 
 9485 instruct get_and_addLi_no_resAcq(indirect mem, Universe dummy, immLAddSub incr) %{
 9486   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9487   match(Set dummy (GetAndAddL mem incr));
 9488   ins_cost(VOLATILE_REF_COST);
 9489   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9490   ins_encode %{
 9491     __ atomic_addal(noreg, $incr$$constant, as_Register($mem$$base));
 9492   %}
 9493   ins_pipe(pipe_serial);
 9494 %}
 9495 
 9496 instruct get_and_addIAcq(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9497   predicate(needs_acquiring_load_exclusive(n));
 9498   match(Set newval (GetAndAddI mem incr));
 9499   ins_cost(VOLATILE_REF_COST + 1);
 9500   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9501   ins_encode %{
 9502     __ atomic_addalw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9503   %}
 9504   ins_pipe(pipe_serial);
 9505 %}
 9506 
 9507 instruct get_and_addI_no_resAcq(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9508   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9509   match(Set dummy (GetAndAddI mem incr));
 9510   ins_cost(VOLATILE_REF_COST);
 9511   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9512   ins_encode %{
 9513     __ atomic_addalw(noreg, $incr$$Register, as_Register($mem$$base));
 9514   %}
 9515   ins_pipe(pipe_serial);
 9516 %}
 9517 
 9518 instruct get_and_addIiAcq(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9519   predicate(needs_acquiring_load_exclusive(n));
 9520   match(Set newval (GetAndAddI mem incr));
 9521   ins_cost(VOLATILE_REF_COST + 1);
 9522   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9523   ins_encode %{
 9524     __ atomic_addalw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9525   %}
 9526   ins_pipe(pipe_serial);
 9527 %}
 9528 
 9529 instruct get_and_addIi_no_resAcq(indirect mem, Universe dummy, immIAddSub incr) %{
 9530   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9531   match(Set dummy (GetAndAddI mem incr));
 9532   ins_cost(VOLATILE_REF_COST);
 9533   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9534   ins_encode %{
 9535     __ atomic_addalw(noreg, $incr$$constant, as_Register($mem$$base));
 9536   %}
 9537   ins_pipe(pipe_serial);
 9538 %}
 9539 
 9540 // Manifest a CmpL result in an integer register.
 9541 // (src1 &lt; src2) ? -1 : ((src1 &gt; src2) ? 1 : 0)
 9542 instruct cmpL3_reg_reg(iRegINoSp dst, iRegL src1, iRegL src2, rFlagsReg flags)
 9543 %{
 9544   match(Set dst (CmpL3 src1 src2));
 9545   effect(KILL flags);
 9546 
 9547   ins_cost(INSN_COST * 6);
 9548   format %{
 9549       &quot;cmp $src1, $src2&quot;
 9550       &quot;csetw $dst, ne&quot;
 9551       &quot;cnegw $dst, lt&quot;
 9552   %}
 9553   // format %{ &quot;CmpL3 $dst, $src1, $src2&quot; %}
 9554   ins_encode %{
 9555     __ cmp($src1$$Register, $src2$$Register);
 9556     __ csetw($dst$$Register, Assembler::NE);
 9557     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9558   %}
 9559 
 9560   ins_pipe(pipe_class_default);
 9561 %}
 9562 
 9563 instruct cmpL3_reg_imm(iRegINoSp dst, iRegL src1, immLAddSub src2, rFlagsReg flags)
 9564 %{
 9565   match(Set dst (CmpL3 src1 src2));
 9566   effect(KILL flags);
 9567 
 9568   ins_cost(INSN_COST * 6);
 9569   format %{
 9570       &quot;cmp $src1, $src2&quot;
 9571       &quot;csetw $dst, ne&quot;
 9572       &quot;cnegw $dst, lt&quot;
 9573   %}
 9574   ins_encode %{
 9575     int32_t con = (int32_t)$src2$$constant;
 9576      if (con &lt; 0) {
 9577       __ adds(zr, $src1$$Register, -con);
 9578     } else {
 9579       __ subs(zr, $src1$$Register, con);
 9580     }
 9581     __ csetw($dst$$Register, Assembler::NE);
 9582     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9583   %}
 9584 
 9585   ins_pipe(pipe_class_default);
 9586 %}
 9587 
 9588 // ============================================================================
 9589 // Conditional Move Instructions
 9590 
 9591 // n.b. we have identical rules for both a signed compare op (cmpOp)
 9592 // and an unsigned compare op (cmpOpU). it would be nice if we could
 9593 // define an op class which merged both inputs and use it to type the
 9594 // argument to a single rule. unfortunatelyt his fails because the
 9595 // opclass does not live up to the COND_INTER interface of its
 9596 // component operands. When the generic code tries to negate the
 9597 // operand it ends up running the generci Machoper::negate method
 9598 // which throws a ShouldNotHappen. So, we have to provide two flavours
 9599 // of each rule, one for a cmpOp and a second for a cmpOpU (sigh).
 9600 
 9601 instruct cmovI_reg_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9602   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9603 
 9604   ins_cost(INSN_COST * 2);
 9605   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, int&quot;  %}
 9606 
 9607   ins_encode %{
 9608     __ cselw(as_Register($dst$$reg),
 9609              as_Register($src2$$reg),
 9610              as_Register($src1$$reg),
 9611              (Assembler::Condition)$cmp$$cmpcode);
 9612   %}
 9613 
 9614   ins_pipe(icond_reg_reg);
 9615 %}
 9616 
 9617 instruct cmovUI_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9618   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9619 
 9620   ins_cost(INSN_COST * 2);
 9621   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# unsigned, int&quot;  %}
 9622 
 9623   ins_encode %{
 9624     __ cselw(as_Register($dst$$reg),
 9625              as_Register($src2$$reg),
 9626              as_Register($src1$$reg),
 9627              (Assembler::Condition)$cmp$$cmpcode);
 9628   %}
 9629 
 9630   ins_pipe(icond_reg_reg);
 9631 %}
 9632 
 9633 // special cases where one arg is zero
 9634 
 9635 // n.b. this is selected in preference to the rule above because it
 9636 // avoids loading constant 0 into a source register
 9637 
 9638 // TODO
 9639 // we ought only to be able to cull one of these variants as the ideal
 9640 // transforms ought always to order the zero consistently (to left/right?)
 9641 
 9642 instruct cmovI_zero_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9643   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9644 
 9645   ins_cost(INSN_COST * 2);
 9646   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, int&quot;  %}
 9647 
 9648   ins_encode %{
 9649     __ cselw(as_Register($dst$$reg),
 9650              as_Register($src$$reg),
 9651              zr,
 9652              (Assembler::Condition)$cmp$$cmpcode);
 9653   %}
 9654 
 9655   ins_pipe(icond_reg);
 9656 %}
 9657 
 9658 instruct cmovUI_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9659   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9660 
 9661   ins_cost(INSN_COST * 2);
 9662   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, int&quot;  %}
 9663 
 9664   ins_encode %{
 9665     __ cselw(as_Register($dst$$reg),
 9666              as_Register($src$$reg),
 9667              zr,
 9668              (Assembler::Condition)$cmp$$cmpcode);
 9669   %}
 9670 
 9671   ins_pipe(icond_reg);
 9672 %}
 9673 
 9674 instruct cmovI_reg_zero(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9675   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9676 
 9677   ins_cost(INSN_COST * 2);
 9678   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, int&quot;  %}
 9679 
 9680   ins_encode %{
 9681     __ cselw(as_Register($dst$$reg),
 9682              zr,
 9683              as_Register($src$$reg),
 9684              (Assembler::Condition)$cmp$$cmpcode);
 9685   %}
 9686 
 9687   ins_pipe(icond_reg);
 9688 %}
 9689 
 9690 instruct cmovUI_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9691   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9692 
 9693   ins_cost(INSN_COST * 2);
 9694   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, int&quot;  %}
 9695 
 9696   ins_encode %{
 9697     __ cselw(as_Register($dst$$reg),
 9698              zr,
 9699              as_Register($src$$reg),
 9700              (Assembler::Condition)$cmp$$cmpcode);
 9701   %}
 9702 
 9703   ins_pipe(icond_reg);
 9704 %}
 9705 
 9706 // special case for creating a boolean 0 or 1
 9707 
 9708 // n.b. this is selected in preference to the rule above because it
 9709 // avoids loading constants 0 and 1 into a source register
 9710 
 9711 instruct cmovI_reg_zero_one(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9712   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9713 
 9714   ins_cost(INSN_COST * 2);
 9715   format %{ &quot;csincw $dst, zr, zr $cmp\t# signed, int&quot;  %}
 9716 
 9717   ins_encode %{
 9718     // equivalently
 9719     // cset(as_Register($dst$$reg),
 9720     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9721     __ csincw(as_Register($dst$$reg),
 9722              zr,
 9723              zr,
 9724              (Assembler::Condition)$cmp$$cmpcode);
 9725   %}
 9726 
 9727   ins_pipe(icond_none);
 9728 %}
 9729 
 9730 instruct cmovUI_reg_zero_one(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9731   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9732 
 9733   ins_cost(INSN_COST * 2);
 9734   format %{ &quot;csincw $dst, zr, zr $cmp\t# unsigned, int&quot;  %}
 9735 
 9736   ins_encode %{
 9737     // equivalently
 9738     // cset(as_Register($dst$$reg),
 9739     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9740     __ csincw(as_Register($dst$$reg),
 9741              zr,
 9742              zr,
 9743              (Assembler::Condition)$cmp$$cmpcode);
 9744   %}
 9745 
 9746   ins_pipe(icond_none);
 9747 %}
 9748 
 9749 instruct cmovL_reg_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9750   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9751 
 9752   ins_cost(INSN_COST * 2);
 9753   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, long&quot;  %}
 9754 
 9755   ins_encode %{
 9756     __ csel(as_Register($dst$$reg),
 9757             as_Register($src2$$reg),
 9758             as_Register($src1$$reg),
 9759             (Assembler::Condition)$cmp$$cmpcode);
 9760   %}
 9761 
 9762   ins_pipe(icond_reg_reg);
 9763 %}
 9764 
 9765 instruct cmovUL_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9766   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9767 
 9768   ins_cost(INSN_COST * 2);
 9769   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, long&quot;  %}
 9770 
 9771   ins_encode %{
 9772     __ csel(as_Register($dst$$reg),
 9773             as_Register($src2$$reg),
 9774             as_Register($src1$$reg),
 9775             (Assembler::Condition)$cmp$$cmpcode);
 9776   %}
 9777 
 9778   ins_pipe(icond_reg_reg);
 9779 %}
 9780 
 9781 // special cases where one arg is zero
 9782 
 9783 instruct cmovL_reg_zero(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9784   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9785 
 9786   ins_cost(INSN_COST * 2);
 9787   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, long&quot;  %}
 9788 
 9789   ins_encode %{
 9790     __ csel(as_Register($dst$$reg),
 9791             zr,
 9792             as_Register($src$$reg),
 9793             (Assembler::Condition)$cmp$$cmpcode);
 9794   %}
 9795 
 9796   ins_pipe(icond_reg);
 9797 %}
 9798 
 9799 instruct cmovUL_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9800   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9801 
 9802   ins_cost(INSN_COST * 2);
 9803   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, long&quot;  %}
 9804 
 9805   ins_encode %{
 9806     __ csel(as_Register($dst$$reg),
 9807             zr,
 9808             as_Register($src$$reg),
 9809             (Assembler::Condition)$cmp$$cmpcode);
 9810   %}
 9811 
 9812   ins_pipe(icond_reg);
 9813 %}
 9814 
 9815 instruct cmovL_zero_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9816   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9817 
 9818   ins_cost(INSN_COST * 2);
 9819   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, long&quot;  %}
 9820 
 9821   ins_encode %{
 9822     __ csel(as_Register($dst$$reg),
 9823             as_Register($src$$reg),
 9824             zr,
 9825             (Assembler::Condition)$cmp$$cmpcode);
 9826   %}
 9827 
 9828   ins_pipe(icond_reg);
 9829 %}
 9830 
 9831 instruct cmovUL_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9832   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9833 
 9834   ins_cost(INSN_COST * 2);
 9835   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, long&quot;  %}
 9836 
 9837   ins_encode %{
 9838     __ csel(as_Register($dst$$reg),
 9839             as_Register($src$$reg),
 9840             zr,
 9841             (Assembler::Condition)$cmp$$cmpcode);
 9842   %}
 9843 
 9844   ins_pipe(icond_reg);
 9845 %}
 9846 
 9847 instruct cmovP_reg_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9848   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9849 
 9850   ins_cost(INSN_COST * 2);
 9851   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, ptr&quot;  %}
 9852 
 9853   ins_encode %{
 9854     __ csel(as_Register($dst$$reg),
 9855             as_Register($src2$$reg),
 9856             as_Register($src1$$reg),
 9857             (Assembler::Condition)$cmp$$cmpcode);
 9858   %}
 9859 
 9860   ins_pipe(icond_reg_reg);
 9861 %}
 9862 
 9863 instruct cmovUP_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9864   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9865 
 9866   ins_cost(INSN_COST * 2);
 9867   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, ptr&quot;  %}
 9868 
 9869   ins_encode %{
 9870     __ csel(as_Register($dst$$reg),
 9871             as_Register($src2$$reg),
 9872             as_Register($src1$$reg),
 9873             (Assembler::Condition)$cmp$$cmpcode);
 9874   %}
 9875 
 9876   ins_pipe(icond_reg_reg);
 9877 %}
 9878 
 9879 // special cases where one arg is zero
 9880 
 9881 instruct cmovP_reg_zero(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9882   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9883 
 9884   ins_cost(INSN_COST * 2);
 9885   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, ptr&quot;  %}
 9886 
 9887   ins_encode %{
 9888     __ csel(as_Register($dst$$reg),
 9889             zr,
 9890             as_Register($src$$reg),
 9891             (Assembler::Condition)$cmp$$cmpcode);
 9892   %}
 9893 
 9894   ins_pipe(icond_reg);
 9895 %}
 9896 
 9897 instruct cmovUP_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9898   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9899 
 9900   ins_cost(INSN_COST * 2);
 9901   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, ptr&quot;  %}
 9902 
 9903   ins_encode %{
 9904     __ csel(as_Register($dst$$reg),
 9905             zr,
 9906             as_Register($src$$reg),
 9907             (Assembler::Condition)$cmp$$cmpcode);
 9908   %}
 9909 
 9910   ins_pipe(icond_reg);
 9911 %}
 9912 
 9913 instruct cmovP_zero_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9914   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9915 
 9916   ins_cost(INSN_COST * 2);
 9917   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, ptr&quot;  %}
 9918 
 9919   ins_encode %{
 9920     __ csel(as_Register($dst$$reg),
 9921             as_Register($src$$reg),
 9922             zr,
 9923             (Assembler::Condition)$cmp$$cmpcode);
 9924   %}
 9925 
 9926   ins_pipe(icond_reg);
 9927 %}
 9928 
 9929 instruct cmovUP_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9930   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9931 
 9932   ins_cost(INSN_COST * 2);
 9933   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, ptr&quot;  %}
 9934 
 9935   ins_encode %{
 9936     __ csel(as_Register($dst$$reg),
 9937             as_Register($src$$reg),
 9938             zr,
 9939             (Assembler::Condition)$cmp$$cmpcode);
 9940   %}
 9941 
 9942   ins_pipe(icond_reg);
 9943 %}
 9944 
 9945 instruct cmovN_reg_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9946   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9947 
 9948   ins_cost(INSN_COST * 2);
 9949   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9950 
 9951   ins_encode %{
 9952     __ cselw(as_Register($dst$$reg),
 9953              as_Register($src2$$reg),
 9954              as_Register($src1$$reg),
 9955              (Assembler::Condition)$cmp$$cmpcode);
 9956   %}
 9957 
 9958   ins_pipe(icond_reg_reg);
 9959 %}
 9960 
 9961 instruct cmovUN_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9962   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9963 
 9964   ins_cost(INSN_COST * 2);
 9965   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9966 
 9967   ins_encode %{
 9968     __ cselw(as_Register($dst$$reg),
 9969              as_Register($src2$$reg),
 9970              as_Register($src1$$reg),
 9971              (Assembler::Condition)$cmp$$cmpcode);
 9972   %}
 9973 
 9974   ins_pipe(icond_reg_reg);
 9975 %}
 9976 
 9977 // special cases where one arg is zero
 9978 
 9979 instruct cmovN_reg_zero(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9980   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9981 
 9982   ins_cost(INSN_COST * 2);
 9983   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, compressed ptr&quot;  %}
 9984 
 9985   ins_encode %{
 9986     __ cselw(as_Register($dst$$reg),
 9987              zr,
 9988              as_Register($src$$reg),
 9989              (Assembler::Condition)$cmp$$cmpcode);
 9990   %}
 9991 
 9992   ins_pipe(icond_reg);
 9993 %}
 9994 
 9995 instruct cmovUN_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9996   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9997 
 9998   ins_cost(INSN_COST * 2);
 9999   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, compressed ptr&quot;  %}
10000 
10001   ins_encode %{
10002     __ cselw(as_Register($dst$$reg),
10003              zr,
10004              as_Register($src$$reg),
10005              (Assembler::Condition)$cmp$$cmpcode);
10006   %}
10007 
10008   ins_pipe(icond_reg);
10009 %}
10010 
10011 instruct cmovN_zero_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
10012   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
10013 
10014   ins_cost(INSN_COST * 2);
10015   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, compressed ptr&quot;  %}
10016 
10017   ins_encode %{
10018     __ cselw(as_Register($dst$$reg),
10019              as_Register($src$$reg),
10020              zr,
10021              (Assembler::Condition)$cmp$$cmpcode);
10022   %}
10023 
10024   ins_pipe(icond_reg);
10025 %}
10026 
10027 instruct cmovUN_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
10028   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
10029 
10030   ins_cost(INSN_COST * 2);
10031   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, compressed ptr&quot;  %}
10032 
10033   ins_encode %{
10034     __ cselw(as_Register($dst$$reg),
10035              as_Register($src$$reg),
10036              zr,
10037              (Assembler::Condition)$cmp$$cmpcode);
10038   %}
10039 
10040   ins_pipe(icond_reg);
10041 %}
10042 
10043 instruct cmovF_reg(cmpOp cmp, rFlagsReg cr, vRegF dst, vRegF src1,  vRegF src2)
10044 %{
10045   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
10046 
10047   ins_cost(INSN_COST * 3);
10048 
10049   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10050   ins_encode %{
10051     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10052     __ fcsels(as_FloatRegister($dst$$reg),
10053               as_FloatRegister($src2$$reg),
10054               as_FloatRegister($src1$$reg),
10055               cond);
10056   %}
10057 
10058   ins_pipe(fp_cond_reg_reg_s);
10059 %}
10060 
10061 instruct cmovUF_reg(cmpOpU cmp, rFlagsRegU cr, vRegF dst, vRegF src1,  vRegF src2)
10062 %{
10063   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
10064 
10065   ins_cost(INSN_COST * 3);
10066 
10067   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10068   ins_encode %{
10069     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10070     __ fcsels(as_FloatRegister($dst$$reg),
10071               as_FloatRegister($src2$$reg),
10072               as_FloatRegister($src1$$reg),
10073               cond);
10074   %}
10075 
10076   ins_pipe(fp_cond_reg_reg_s);
10077 %}
10078 
10079 instruct cmovD_reg(cmpOp cmp, rFlagsReg cr, vRegD dst, vRegD src1,  vRegD src2)
10080 %{
10081   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10082 
10083   ins_cost(INSN_COST * 3);
10084 
10085   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10086   ins_encode %{
10087     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10088     __ fcseld(as_FloatRegister($dst$$reg),
10089               as_FloatRegister($src2$$reg),
10090               as_FloatRegister($src1$$reg),
10091               cond);
10092   %}
10093 
10094   ins_pipe(fp_cond_reg_reg_d);
10095 %}
10096 
10097 instruct cmovUD_reg(cmpOpU cmp, rFlagsRegU cr, vRegD dst, vRegD src1,  vRegD src2)
10098 %{
10099   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10100 
10101   ins_cost(INSN_COST * 3);
10102 
10103   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10104   ins_encode %{
10105     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10106     __ fcseld(as_FloatRegister($dst$$reg),
10107               as_FloatRegister($src2$$reg),
10108               as_FloatRegister($src1$$reg),
10109               cond);
10110   %}
10111 
10112   ins_pipe(fp_cond_reg_reg_d);
10113 %}
10114 
10115 // ============================================================================
10116 // Arithmetic Instructions
10117 //
10118 
10119 // Integer Addition
10120 
10121 // TODO
10122 // these currently employ operations which do not set CR and hence are
10123 // not flagged as killing CR but we would like to isolate the cases
10124 // where we want to set flags from those where we don&#39;t. need to work
10125 // out how to do that.
10126 
10127 instruct addI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10128   match(Set dst (AddI src1 src2));
10129 
10130   ins_cost(INSN_COST);
10131   format %{ &quot;addw  $dst, $src1, $src2&quot; %}
10132 
10133   ins_encode %{
10134     __ addw(as_Register($dst$$reg),
10135             as_Register($src1$$reg),
10136             as_Register($src2$$reg));
10137   %}
10138 
10139   ins_pipe(ialu_reg_reg);
10140 %}
10141 
10142 instruct addI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10143   match(Set dst (AddI src1 src2));
10144 
10145   ins_cost(INSN_COST);
10146   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10147 
10148   // use opcode to indicate that this is an add not a sub
10149   opcode(0x0);
10150 
10151   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10152 
10153   ins_pipe(ialu_reg_imm);
10154 %}
10155 
10156 instruct addI_reg_imm_i2l(iRegINoSp dst, iRegL src1, immIAddSub src2) %{
10157   match(Set dst (AddI (ConvL2I src1) src2));
10158 
10159   ins_cost(INSN_COST);
10160   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10161 
10162   // use opcode to indicate that this is an add not a sub
10163   opcode(0x0);
10164 
10165   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10166 
10167   ins_pipe(ialu_reg_imm);
10168 %}
10169 
10170 // Pointer Addition
10171 instruct addP_reg_reg(iRegPNoSp dst, iRegP src1, iRegL src2) %{
10172   match(Set dst (AddP src1 src2));
10173 
10174   ins_cost(INSN_COST);
10175   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10176 
10177   ins_encode %{
10178     __ add(as_Register($dst$$reg),
10179            as_Register($src1$$reg),
10180            as_Register($src2$$reg));
10181   %}
10182 
10183   ins_pipe(ialu_reg_reg);
10184 %}
10185 
10186 instruct addP_reg_reg_ext(iRegPNoSp dst, iRegP src1, iRegIorL2I src2) %{
10187   match(Set dst (AddP src1 (ConvI2L src2)));
10188 
10189   ins_cost(1.9 * INSN_COST);
10190   format %{ &quot;add $dst, $src1, $src2, sxtw\t# ptr&quot; %}
10191 
10192   ins_encode %{
10193     __ add(as_Register($dst$$reg),
10194            as_Register($src1$$reg),
10195            as_Register($src2$$reg), ext::sxtw);
10196   %}
10197 
10198   ins_pipe(ialu_reg_reg);
10199 %}
10200 
10201 instruct addP_reg_reg_lsl(iRegPNoSp dst, iRegP src1, iRegL src2, immIScale scale) %{
10202   match(Set dst (AddP src1 (LShiftL src2 scale)));
10203 
10204   ins_cost(1.9 * INSN_COST);
10205   format %{ &quot;add $dst, $src1, $src2, LShiftL $scale\t# ptr&quot; %}
10206 
10207   ins_encode %{
10208     __ lea(as_Register($dst$$reg),
10209            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10210                    Address::lsl($scale$$constant)));
10211   %}
10212 
10213   ins_pipe(ialu_reg_reg_shift);
10214 %}
10215 
10216 instruct addP_reg_reg_ext_shift(iRegPNoSp dst, iRegP src1, iRegIorL2I src2, immIScale scale) %{
10217   match(Set dst (AddP src1 (LShiftL (ConvI2L src2) scale)));
10218 
10219   ins_cost(1.9 * INSN_COST);
10220   format %{ &quot;add $dst, $src1, $src2, I2L $scale\t# ptr&quot; %}
10221 
10222   ins_encode %{
10223     __ lea(as_Register($dst$$reg),
10224            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10225                    Address::sxtw($scale$$constant)));
10226   %}
10227 
10228   ins_pipe(ialu_reg_reg_shift);
10229 %}
10230 
10231 instruct lshift_ext(iRegLNoSp dst, iRegIorL2I src, immI scale, rFlagsReg cr) %{
10232   match(Set dst (LShiftL (ConvI2L src) scale));
10233 
10234   ins_cost(INSN_COST);
10235   format %{ &quot;sbfiz $dst, $src, $scale &amp; 63, -$scale &amp; 63\t&quot; %}
10236 
10237   ins_encode %{
10238     __ sbfiz(as_Register($dst$$reg),
10239           as_Register($src$$reg),
10240           $scale$$constant &amp; 63, MIN(32, (-$scale$$constant) &amp; 63));
10241   %}
10242 
10243   ins_pipe(ialu_reg_shift);
10244 %}
10245 
10246 // Pointer Immediate Addition
10247 // n.b. this needs to be more expensive than using an indirect memory
10248 // operand
10249 instruct addP_reg_imm(iRegPNoSp dst, iRegP src1, immLAddSub src2) %{
10250   match(Set dst (AddP src1 src2));
10251 
10252   ins_cost(INSN_COST);
10253   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10254 
10255   // use opcode to indicate that this is an add not a sub
10256   opcode(0x0);
10257 
10258   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10259 
10260   ins_pipe(ialu_reg_imm);
10261 %}
10262 
10263 // Long Addition
10264 instruct addL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10265 
10266   match(Set dst (AddL src1 src2));
10267 
10268   ins_cost(INSN_COST);
10269   format %{ &quot;add  $dst, $src1, $src2&quot; %}
10270 
10271   ins_encode %{
10272     __ add(as_Register($dst$$reg),
10273            as_Register($src1$$reg),
10274            as_Register($src2$$reg));
10275   %}
10276 
10277   ins_pipe(ialu_reg_reg);
10278 %}
10279 
10280 // No constant pool entries requiredLong Immediate Addition.
10281 instruct addL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10282   match(Set dst (AddL src1 src2));
10283 
10284   ins_cost(INSN_COST);
10285   format %{ &quot;add $dst, $src1, $src2&quot; %}
10286 
10287   // use opcode to indicate that this is an add not a sub
10288   opcode(0x0);
10289 
10290   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10291 
10292   ins_pipe(ialu_reg_imm);
10293 %}
10294 
10295 // Integer Subtraction
10296 instruct subI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10297   match(Set dst (SubI src1 src2));
10298 
10299   ins_cost(INSN_COST);
10300   format %{ &quot;subw  $dst, $src1, $src2&quot; %}
10301 
10302   ins_encode %{
10303     __ subw(as_Register($dst$$reg),
10304             as_Register($src1$$reg),
10305             as_Register($src2$$reg));
10306   %}
10307 
10308   ins_pipe(ialu_reg_reg);
10309 %}
10310 
10311 // Immediate Subtraction
10312 instruct subI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10313   match(Set dst (SubI src1 src2));
10314 
10315   ins_cost(INSN_COST);
10316   format %{ &quot;subw $dst, $src1, $src2&quot; %}
10317 
10318   // use opcode to indicate that this is a sub not an add
10319   opcode(0x1);
10320 
10321   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10322 
10323   ins_pipe(ialu_reg_imm);
10324 %}
10325 
10326 // Long Subtraction
10327 instruct subL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10328 
10329   match(Set dst (SubL src1 src2));
10330 
10331   ins_cost(INSN_COST);
10332   format %{ &quot;sub  $dst, $src1, $src2&quot; %}
10333 
10334   ins_encode %{
10335     __ sub(as_Register($dst$$reg),
10336            as_Register($src1$$reg),
10337            as_Register($src2$$reg));
10338   %}
10339 
10340   ins_pipe(ialu_reg_reg);
10341 %}
10342 
10343 // No constant pool entries requiredLong Immediate Subtraction.
10344 instruct subL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10345   match(Set dst (SubL src1 src2));
10346 
10347   ins_cost(INSN_COST);
10348   format %{ &quot;sub$dst, $src1, $src2&quot; %}
10349 
10350   // use opcode to indicate that this is a sub not an add
10351   opcode(0x1);
10352 
10353   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10354 
10355   ins_pipe(ialu_reg_imm);
10356 %}
10357 
10358 // Integer Negation (special case for sub)
10359 
10360 instruct negI_reg(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr) %{
10361   match(Set dst (SubI zero src));
10362 
10363   ins_cost(INSN_COST);
10364   format %{ &quot;negw $dst, $src\t# int&quot; %}
10365 
10366   ins_encode %{
10367     __ negw(as_Register($dst$$reg),
10368             as_Register($src$$reg));
10369   %}
10370 
10371   ins_pipe(ialu_reg);
10372 %}
10373 
10374 // Long Negation
10375 
10376 instruct negL_reg(iRegLNoSp dst, iRegL src, immL0 zero, rFlagsReg cr) %{
10377   match(Set dst (SubL zero src));
10378 
10379   ins_cost(INSN_COST);
10380   format %{ &quot;neg $dst, $src\t# long&quot; %}
10381 
10382   ins_encode %{
10383     __ neg(as_Register($dst$$reg),
10384            as_Register($src$$reg));
10385   %}
10386 
10387   ins_pipe(ialu_reg);
10388 %}
10389 
10390 // Integer Multiply
10391 
10392 instruct mulI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10393   match(Set dst (MulI src1 src2));
10394 
10395   ins_cost(INSN_COST * 3);
10396   format %{ &quot;mulw  $dst, $src1, $src2&quot; %}
10397 
10398   ins_encode %{
10399     __ mulw(as_Register($dst$$reg),
10400             as_Register($src1$$reg),
10401             as_Register($src2$$reg));
10402   %}
10403 
10404   ins_pipe(imul_reg_reg);
10405 %}
10406 
10407 instruct smulI(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10408   match(Set dst (MulL (ConvI2L src1) (ConvI2L src2)));
10409 
10410   ins_cost(INSN_COST * 3);
10411   format %{ &quot;smull  $dst, $src1, $src2&quot; %}
10412 
10413   ins_encode %{
10414     __ smull(as_Register($dst$$reg),
10415              as_Register($src1$$reg),
10416              as_Register($src2$$reg));
10417   %}
10418 
10419   ins_pipe(imul_reg_reg);
10420 %}
10421 
10422 // Long Multiply
10423 
10424 instruct mulL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10425   match(Set dst (MulL src1 src2));
10426 
10427   ins_cost(INSN_COST * 5);
10428   format %{ &quot;mul  $dst, $src1, $src2&quot; %}
10429 
10430   ins_encode %{
10431     __ mul(as_Register($dst$$reg),
10432            as_Register($src1$$reg),
10433            as_Register($src2$$reg));
10434   %}
10435 
10436   ins_pipe(lmul_reg_reg);
10437 %}
10438 
10439 instruct mulHiL_rReg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr)
10440 %{
10441   match(Set dst (MulHiL src1 src2));
10442 
10443   ins_cost(INSN_COST * 7);
10444   format %{ &quot;smulh   $dst, $src1, $src2, \t# mulhi&quot; %}
10445 
10446   ins_encode %{
10447     __ smulh(as_Register($dst$$reg),
10448              as_Register($src1$$reg),
10449              as_Register($src2$$reg));
10450   %}
10451 
10452   ins_pipe(lmul_reg_reg);
10453 %}
10454 
10455 // Combined Integer Multiply &amp; Add/Sub
10456 
10457 instruct maddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10458   match(Set dst (AddI src3 (MulI src1 src2)));
10459 
10460   ins_cost(INSN_COST * 3);
10461   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10462 
10463   ins_encode %{
10464     __ maddw(as_Register($dst$$reg),
10465              as_Register($src1$$reg),
10466              as_Register($src2$$reg),
10467              as_Register($src3$$reg));
10468   %}
10469 
10470   ins_pipe(imac_reg_reg);
10471 %}
10472 
10473 instruct msubI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10474   match(Set dst (SubI src3 (MulI src1 src2)));
10475 
10476   ins_cost(INSN_COST * 3);
10477   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10478 
10479   ins_encode %{
10480     __ msubw(as_Register($dst$$reg),
10481              as_Register($src1$$reg),
10482              as_Register($src2$$reg),
10483              as_Register($src3$$reg));
10484   %}
10485 
10486   ins_pipe(imac_reg_reg);
10487 %}
10488 
10489 // Combined Integer Multiply &amp; Neg
10490 
10491 instruct mnegI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI0 zero) %{
10492   match(Set dst (MulI (SubI zero src1) src2));
10493   match(Set dst (MulI src1 (SubI zero src2)));
10494 
10495   ins_cost(INSN_COST * 3);
10496   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10497 
10498   ins_encode %{
10499     __ mnegw(as_Register($dst$$reg),
10500              as_Register($src1$$reg),
10501              as_Register($src2$$reg));
10502   %}
10503 
10504   ins_pipe(imac_reg_reg);
10505 %}
10506 
10507 // Combined Long Multiply &amp; Add/Sub
10508 
10509 instruct maddL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10510   match(Set dst (AddL src3 (MulL src1 src2)));
10511 
10512   ins_cost(INSN_COST * 5);
10513   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10514 
10515   ins_encode %{
10516     __ madd(as_Register($dst$$reg),
10517             as_Register($src1$$reg),
10518             as_Register($src2$$reg),
10519             as_Register($src3$$reg));
10520   %}
10521 
10522   ins_pipe(lmac_reg_reg);
10523 %}
10524 
10525 instruct msubL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10526   match(Set dst (SubL src3 (MulL src1 src2)));
10527 
10528   ins_cost(INSN_COST * 5);
10529   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10530 
10531   ins_encode %{
10532     __ msub(as_Register($dst$$reg),
10533             as_Register($src1$$reg),
10534             as_Register($src2$$reg),
10535             as_Register($src3$$reg));
10536   %}
10537 
10538   ins_pipe(lmac_reg_reg);
10539 %}
10540 
10541 // Combined Long Multiply &amp; Neg
10542 
10543 instruct mnegL(iRegLNoSp dst, iRegL src1, iRegL src2, immL0 zero) %{
10544   match(Set dst (MulL (SubL zero src1) src2));
10545   match(Set dst (MulL src1 (SubL zero src2)));
10546 
10547   ins_cost(INSN_COST * 5);
10548   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10549 
10550   ins_encode %{
10551     __ mneg(as_Register($dst$$reg),
10552             as_Register($src1$$reg),
10553             as_Register($src2$$reg));
10554   %}
10555 
10556   ins_pipe(lmac_reg_reg);
10557 %}
10558 
10559 // Combine Integer Signed Multiply &amp; Add/Sub/Neg Long
10560 
10561 instruct smaddL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10562   match(Set dst (AddL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10563 
10564   ins_cost(INSN_COST * 3);
10565   format %{ &quot;smaddl  $dst, $src1, $src2, $src3&quot; %}
10566 
10567   ins_encode %{
10568     __ smaddl(as_Register($dst$$reg),
10569               as_Register($src1$$reg),
10570               as_Register($src2$$reg),
10571               as_Register($src3$$reg));
10572   %}
10573 
10574   ins_pipe(imac_reg_reg);
10575 %}
10576 
10577 instruct smsubL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10578   match(Set dst (SubL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10579 
10580   ins_cost(INSN_COST * 3);
10581   format %{ &quot;smsubl  $dst, $src1, $src2, $src3&quot; %}
10582 
10583   ins_encode %{
10584     __ smsubl(as_Register($dst$$reg),
10585               as_Register($src1$$reg),
10586               as_Register($src2$$reg),
10587               as_Register($src3$$reg));
10588   %}
10589 
10590   ins_pipe(imac_reg_reg);
10591 %}
10592 
10593 instruct smnegL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, immL0 zero) %{
10594   match(Set dst (MulL (SubL zero (ConvI2L src1)) (ConvI2L src2)));
10595   match(Set dst (MulL (ConvI2L src1) (SubL zero (ConvI2L src2))));
10596 
10597   ins_cost(INSN_COST * 3);
10598   format %{ &quot;smnegl  $dst, $src1, $src2&quot; %}
10599 
10600   ins_encode %{
10601     __ smnegl(as_Register($dst$$reg),
10602               as_Register($src1$$reg),
10603               as_Register($src2$$reg));
10604   %}
10605 
10606   ins_pipe(imac_reg_reg);
10607 %}
10608 
10609 // Combined Multiply-Add Shorts into Integer (dst = src1 * src2 + src3 * src4)
10610 
10611 instruct muladdS2I(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3, iRegIorL2I src4) %{
10612   match(Set dst (MulAddS2I (Binary src1 src2) (Binary src3 src4)));
10613 
10614   ins_cost(INSN_COST * 5);
10615   format %{ &quot;mulw  rscratch1, $src1, $src2\n\t&quot;
10616             &quot;maddw $dst, $src3, $src4, rscratch1&quot; %}
10617 
10618   ins_encode %{
10619     __ mulw(rscratch1, as_Register($src1$$reg), as_Register($src2$$reg));
10620     __ maddw(as_Register($dst$$reg), as_Register($src3$$reg), as_Register($src4$$reg), rscratch1); %}
10621 
10622   ins_pipe(imac_reg_reg);
10623 %}
10624 
10625 // Integer Divide
10626 
10627 instruct divI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10628   match(Set dst (DivI src1 src2));
10629 
10630   ins_cost(INSN_COST * 19);
10631   format %{ &quot;sdivw  $dst, $src1, $src2&quot; %}
10632 
10633   ins_encode(aarch64_enc_divw(dst, src1, src2));
10634   ins_pipe(idiv_reg_reg);
10635 %}
10636 
10637 // Long Divide
10638 
10639 instruct divL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10640   match(Set dst (DivL src1 src2));
10641 
10642   ins_cost(INSN_COST * 35);
10643   format %{ &quot;sdiv   $dst, $src1, $src2&quot; %}
10644 
10645   ins_encode(aarch64_enc_div(dst, src1, src2));
10646   ins_pipe(ldiv_reg_reg);
10647 %}
10648 
10649 // Integer Remainder
10650 
10651 instruct modI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10652   match(Set dst (ModI src1 src2));
10653 
10654   ins_cost(INSN_COST * 22);
10655   format %{ &quot;sdivw  rscratch1, $src1, $src2\n\t&quot;
10656             &quot;msubw($dst, rscratch1, $src2, $src1&quot; %}
10657 
10658   ins_encode(aarch64_enc_modw(dst, src1, src2));
10659   ins_pipe(idiv_reg_reg);
10660 %}
10661 
10662 // Long Remainder
10663 
10664 instruct modL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10665   match(Set dst (ModL src1 src2));
10666 
10667   ins_cost(INSN_COST * 38);
10668   format %{ &quot;sdiv   rscratch1, $src1, $src2\n&quot;
10669             &quot;msub($dst, rscratch1, $src2, $src1&quot; %}
10670 
10671   ins_encode(aarch64_enc_mod(dst, src1, src2));
10672   ins_pipe(ldiv_reg_reg);
10673 %}
10674 
10675 // Integer Shifts
10676 
10677 // Shift Left Register
10678 instruct lShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10679   match(Set dst (LShiftI src1 src2));
10680 
10681   ins_cost(INSN_COST * 2);
10682   format %{ &quot;lslvw  $dst, $src1, $src2&quot; %}
10683 
10684   ins_encode %{
10685     __ lslvw(as_Register($dst$$reg),
10686              as_Register($src1$$reg),
10687              as_Register($src2$$reg));
10688   %}
10689 
10690   ins_pipe(ialu_reg_reg_vshift);
10691 %}
10692 
10693 // Shift Left Immediate
10694 instruct lShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10695   match(Set dst (LShiftI src1 src2));
10696 
10697   ins_cost(INSN_COST);
10698   format %{ &quot;lslw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10699 
10700   ins_encode %{
10701     __ lslw(as_Register($dst$$reg),
10702             as_Register($src1$$reg),
10703             $src2$$constant &amp; 0x1f);
10704   %}
10705 
10706   ins_pipe(ialu_reg_shift);
10707 %}
10708 
10709 // Shift Right Logical Register
10710 instruct urShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10711   match(Set dst (URShiftI src1 src2));
10712 
10713   ins_cost(INSN_COST * 2);
10714   format %{ &quot;lsrvw  $dst, $src1, $src2&quot; %}
10715 
10716   ins_encode %{
10717     __ lsrvw(as_Register($dst$$reg),
10718              as_Register($src1$$reg),
10719              as_Register($src2$$reg));
10720   %}
10721 
10722   ins_pipe(ialu_reg_reg_vshift);
10723 %}
10724 
10725 // Shift Right Logical Immediate
10726 instruct urShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10727   match(Set dst (URShiftI src1 src2));
10728 
10729   ins_cost(INSN_COST);
10730   format %{ &quot;lsrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10731 
10732   ins_encode %{
10733     __ lsrw(as_Register($dst$$reg),
10734             as_Register($src1$$reg),
10735             $src2$$constant &amp; 0x1f);
10736   %}
10737 
10738   ins_pipe(ialu_reg_shift);
10739 %}
10740 
10741 // Shift Right Arithmetic Register
10742 instruct rShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10743   match(Set dst (RShiftI src1 src2));
10744 
10745   ins_cost(INSN_COST * 2);
10746   format %{ &quot;asrvw  $dst, $src1, $src2&quot; %}
10747 
10748   ins_encode %{
10749     __ asrvw(as_Register($dst$$reg),
10750              as_Register($src1$$reg),
10751              as_Register($src2$$reg));
10752   %}
10753 
10754   ins_pipe(ialu_reg_reg_vshift);
10755 %}
10756 
10757 // Shift Right Arithmetic Immediate
10758 instruct rShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10759   match(Set dst (RShiftI src1 src2));
10760 
10761   ins_cost(INSN_COST);
10762   format %{ &quot;asrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10763 
10764   ins_encode %{
10765     __ asrw(as_Register($dst$$reg),
10766             as_Register($src1$$reg),
10767             $src2$$constant &amp; 0x1f);
10768   %}
10769 
10770   ins_pipe(ialu_reg_shift);
10771 %}
10772 
10773 // Combined Int Mask and Right Shift (using UBFM)
10774 // TODO
10775 
10776 // Long Shifts
10777 
10778 // Shift Left Register
10779 instruct lShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10780   match(Set dst (LShiftL src1 src2));
10781 
10782   ins_cost(INSN_COST * 2);
10783   format %{ &quot;lslv  $dst, $src1, $src2&quot; %}
10784 
10785   ins_encode %{
10786     __ lslv(as_Register($dst$$reg),
10787             as_Register($src1$$reg),
10788             as_Register($src2$$reg));
10789   %}
10790 
10791   ins_pipe(ialu_reg_reg_vshift);
10792 %}
10793 
10794 // Shift Left Immediate
10795 instruct lShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10796   match(Set dst (LShiftL src1 src2));
10797 
10798   ins_cost(INSN_COST);
10799   format %{ &quot;lsl $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10800 
10801   ins_encode %{
10802     __ lsl(as_Register($dst$$reg),
10803             as_Register($src1$$reg),
10804             $src2$$constant &amp; 0x3f);
10805   %}
10806 
10807   ins_pipe(ialu_reg_shift);
10808 %}
10809 
10810 // Shift Right Logical Register
10811 instruct urShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10812   match(Set dst (URShiftL src1 src2));
10813 
10814   ins_cost(INSN_COST * 2);
10815   format %{ &quot;lsrv  $dst, $src1, $src2&quot; %}
10816 
10817   ins_encode %{
10818     __ lsrv(as_Register($dst$$reg),
10819             as_Register($src1$$reg),
10820             as_Register($src2$$reg));
10821   %}
10822 
10823   ins_pipe(ialu_reg_reg_vshift);
10824 %}
10825 
10826 // Shift Right Logical Immediate
10827 instruct urShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10828   match(Set dst (URShiftL src1 src2));
10829 
10830   ins_cost(INSN_COST);
10831   format %{ &quot;lsr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10832 
10833   ins_encode %{
10834     __ lsr(as_Register($dst$$reg),
10835            as_Register($src1$$reg),
10836            $src2$$constant &amp; 0x3f);
10837   %}
10838 
10839   ins_pipe(ialu_reg_shift);
10840 %}
10841 
10842 // A special-case pattern for card table stores.
10843 instruct urShiftP_reg_imm(iRegLNoSp dst, iRegP src1, immI src2) %{
10844   match(Set dst (URShiftL (CastP2X src1) src2));
10845 
10846   ins_cost(INSN_COST);
10847   format %{ &quot;lsr $dst, p2x($src1), ($src2 &amp; 0x3f)&quot; %}
10848 
10849   ins_encode %{
10850     __ lsr(as_Register($dst$$reg),
10851            as_Register($src1$$reg),
10852            $src2$$constant &amp; 0x3f);
10853   %}
10854 
10855   ins_pipe(ialu_reg_shift);
10856 %}
10857 
10858 // Shift Right Arithmetic Register
10859 instruct rShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10860   match(Set dst (RShiftL src1 src2));
10861 
10862   ins_cost(INSN_COST * 2);
10863   format %{ &quot;asrv  $dst, $src1, $src2&quot; %}
10864 
10865   ins_encode %{
10866     __ asrv(as_Register($dst$$reg),
10867             as_Register($src1$$reg),
10868             as_Register($src2$$reg));
10869   %}
10870 
10871   ins_pipe(ialu_reg_reg_vshift);
10872 %}
10873 
10874 // Shift Right Arithmetic Immediate
10875 instruct rShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10876   match(Set dst (RShiftL src1 src2));
10877 
10878   ins_cost(INSN_COST);
10879   format %{ &quot;asr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10880 
10881   ins_encode %{
10882     __ asr(as_Register($dst$$reg),
10883            as_Register($src1$$reg),
10884            $src2$$constant &amp; 0x3f);
10885   %}
10886 
10887   ins_pipe(ialu_reg_shift);
10888 %}
10889 
10890 // BEGIN This section of the file is automatically generated. Do not edit --------------
10891 
10892 instruct regL_not_reg(iRegLNoSp dst,
10893                          iRegL src1, immL_M1 m1,
10894                          rFlagsReg cr) %{
10895   match(Set dst (XorL src1 m1));
10896   ins_cost(INSN_COST);
10897   format %{ &quot;eon  $dst, $src1, zr&quot; %}
10898 
10899   ins_encode %{
10900     __ eon(as_Register($dst$$reg),
10901               as_Register($src1$$reg),
10902               zr,
10903               Assembler::LSL, 0);
10904   %}
10905 
10906   ins_pipe(ialu_reg);
10907 %}
10908 instruct regI_not_reg(iRegINoSp dst,
10909                          iRegIorL2I src1, immI_M1 m1,
10910                          rFlagsReg cr) %{
10911   match(Set dst (XorI src1 m1));
10912   ins_cost(INSN_COST);
10913   format %{ &quot;eonw  $dst, $src1, zr&quot; %}
10914 
10915   ins_encode %{
10916     __ eonw(as_Register($dst$$reg),
10917               as_Register($src1$$reg),
10918               zr,
10919               Assembler::LSL, 0);
10920   %}
10921 
10922   ins_pipe(ialu_reg);
10923 %}
10924 
10925 instruct AndI_reg_not_reg(iRegINoSp dst,
10926                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10927                          rFlagsReg cr) %{
10928   match(Set dst (AndI src1 (XorI src2 m1)));
10929   ins_cost(INSN_COST);
10930   format %{ &quot;bicw  $dst, $src1, $src2&quot; %}
10931 
10932   ins_encode %{
10933     __ bicw(as_Register($dst$$reg),
10934               as_Register($src1$$reg),
10935               as_Register($src2$$reg),
10936               Assembler::LSL, 0);
10937   %}
10938 
10939   ins_pipe(ialu_reg_reg);
10940 %}
10941 
10942 instruct AndL_reg_not_reg(iRegLNoSp dst,
10943                          iRegL src1, iRegL src2, immL_M1 m1,
10944                          rFlagsReg cr) %{
10945   match(Set dst (AndL src1 (XorL src2 m1)));
10946   ins_cost(INSN_COST);
10947   format %{ &quot;bic  $dst, $src1, $src2&quot; %}
10948 
10949   ins_encode %{
10950     __ bic(as_Register($dst$$reg),
10951               as_Register($src1$$reg),
10952               as_Register($src2$$reg),
10953               Assembler::LSL, 0);
10954   %}
10955 
10956   ins_pipe(ialu_reg_reg);
10957 %}
10958 
10959 instruct OrI_reg_not_reg(iRegINoSp dst,
10960                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10961                          rFlagsReg cr) %{
10962   match(Set dst (OrI src1 (XorI src2 m1)));
10963   ins_cost(INSN_COST);
10964   format %{ &quot;ornw  $dst, $src1, $src2&quot; %}
10965 
10966   ins_encode %{
10967     __ ornw(as_Register($dst$$reg),
10968               as_Register($src1$$reg),
10969               as_Register($src2$$reg),
10970               Assembler::LSL, 0);
10971   %}
10972 
10973   ins_pipe(ialu_reg_reg);
10974 %}
10975 
10976 instruct OrL_reg_not_reg(iRegLNoSp dst,
10977                          iRegL src1, iRegL src2, immL_M1 m1,
10978                          rFlagsReg cr) %{
10979   match(Set dst (OrL src1 (XorL src2 m1)));
10980   ins_cost(INSN_COST);
10981   format %{ &quot;orn  $dst, $src1, $src2&quot; %}
10982 
10983   ins_encode %{
10984     __ orn(as_Register($dst$$reg),
10985               as_Register($src1$$reg),
10986               as_Register($src2$$reg),
10987               Assembler::LSL, 0);
10988   %}
10989 
10990   ins_pipe(ialu_reg_reg);
10991 %}
10992 
10993 instruct XorI_reg_not_reg(iRegINoSp dst,
10994                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10995                          rFlagsReg cr) %{
10996   match(Set dst (XorI m1 (XorI src2 src1)));
10997   ins_cost(INSN_COST);
10998   format %{ &quot;eonw  $dst, $src1, $src2&quot; %}
10999 
11000   ins_encode %{
11001     __ eonw(as_Register($dst$$reg),
11002               as_Register($src1$$reg),
11003               as_Register($src2$$reg),
11004               Assembler::LSL, 0);
11005   %}
11006 
11007   ins_pipe(ialu_reg_reg);
11008 %}
11009 
11010 instruct XorL_reg_not_reg(iRegLNoSp dst,
11011                          iRegL src1, iRegL src2, immL_M1 m1,
11012                          rFlagsReg cr) %{
11013   match(Set dst (XorL m1 (XorL src2 src1)));
11014   ins_cost(INSN_COST);
11015   format %{ &quot;eon  $dst, $src1, $src2&quot; %}
11016 
11017   ins_encode %{
11018     __ eon(as_Register($dst$$reg),
11019               as_Register($src1$$reg),
11020               as_Register($src2$$reg),
11021               Assembler::LSL, 0);
11022   %}
11023 
11024   ins_pipe(ialu_reg_reg);
11025 %}
11026 
11027 instruct AndI_reg_URShift_not_reg(iRegINoSp dst,
11028                          iRegIorL2I src1, iRegIorL2I src2,
11029                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11030   match(Set dst (AndI src1 (XorI(URShiftI src2 src3) src4)));
11031   ins_cost(1.9 * INSN_COST);
11032   format %{ &quot;bicw  $dst, $src1, $src2, LSR $src3&quot; %}
11033 
11034   ins_encode %{
11035     __ bicw(as_Register($dst$$reg),
11036               as_Register($src1$$reg),
11037               as_Register($src2$$reg),
11038               Assembler::LSR,
11039               $src3$$constant &amp; 0x1f);
11040   %}
11041 
11042   ins_pipe(ialu_reg_reg_shift);
11043 %}
11044 
11045 instruct AndL_reg_URShift_not_reg(iRegLNoSp dst,
11046                          iRegL src1, iRegL src2,
11047                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11048   match(Set dst (AndL src1 (XorL(URShiftL src2 src3) src4)));
11049   ins_cost(1.9 * INSN_COST);
11050   format %{ &quot;bic  $dst, $src1, $src2, LSR $src3&quot; %}
11051 
11052   ins_encode %{
11053     __ bic(as_Register($dst$$reg),
11054               as_Register($src1$$reg),
11055               as_Register($src2$$reg),
11056               Assembler::LSR,
11057               $src3$$constant &amp; 0x3f);
11058   %}
11059 
11060   ins_pipe(ialu_reg_reg_shift);
11061 %}
11062 
11063 instruct AndI_reg_RShift_not_reg(iRegINoSp dst,
11064                          iRegIorL2I src1, iRegIorL2I src2,
11065                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11066   match(Set dst (AndI src1 (XorI(RShiftI src2 src3) src4)));
11067   ins_cost(1.9 * INSN_COST);
11068   format %{ &quot;bicw  $dst, $src1, $src2, ASR $src3&quot; %}
11069 
11070   ins_encode %{
11071     __ bicw(as_Register($dst$$reg),
11072               as_Register($src1$$reg),
11073               as_Register($src2$$reg),
11074               Assembler::ASR,
11075               $src3$$constant &amp; 0x1f);
11076   %}
11077 
11078   ins_pipe(ialu_reg_reg_shift);
11079 %}
11080 
11081 instruct AndL_reg_RShift_not_reg(iRegLNoSp dst,
11082                          iRegL src1, iRegL src2,
11083                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11084   match(Set dst (AndL src1 (XorL(RShiftL src2 src3) src4)));
11085   ins_cost(1.9 * INSN_COST);
11086   format %{ &quot;bic  $dst, $src1, $src2, ASR $src3&quot; %}
11087 
11088   ins_encode %{
11089     __ bic(as_Register($dst$$reg),
11090               as_Register($src1$$reg),
11091               as_Register($src2$$reg),
11092               Assembler::ASR,
11093               $src3$$constant &amp; 0x3f);
11094   %}
11095 
11096   ins_pipe(ialu_reg_reg_shift);
11097 %}
11098 
11099 instruct AndI_reg_LShift_not_reg(iRegINoSp dst,
11100                          iRegIorL2I src1, iRegIorL2I src2,
11101                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11102   match(Set dst (AndI src1 (XorI(LShiftI src2 src3) src4)));
11103   ins_cost(1.9 * INSN_COST);
11104   format %{ &quot;bicw  $dst, $src1, $src2, LSL $src3&quot; %}
11105 
11106   ins_encode %{
11107     __ bicw(as_Register($dst$$reg),
11108               as_Register($src1$$reg),
11109               as_Register($src2$$reg),
11110               Assembler::LSL,
11111               $src3$$constant &amp; 0x1f);
11112   %}
11113 
11114   ins_pipe(ialu_reg_reg_shift);
11115 %}
11116 
11117 instruct AndL_reg_LShift_not_reg(iRegLNoSp dst,
11118                          iRegL src1, iRegL src2,
11119                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11120   match(Set dst (AndL src1 (XorL(LShiftL src2 src3) src4)));
11121   ins_cost(1.9 * INSN_COST);
11122   format %{ &quot;bic  $dst, $src1, $src2, LSL $src3&quot; %}
11123 
11124   ins_encode %{
11125     __ bic(as_Register($dst$$reg),
11126               as_Register($src1$$reg),
11127               as_Register($src2$$reg),
11128               Assembler::LSL,
11129               $src3$$constant &amp; 0x3f);
11130   %}
11131 
11132   ins_pipe(ialu_reg_reg_shift);
11133 %}
11134 
11135 instruct XorI_reg_URShift_not_reg(iRegINoSp dst,
11136                          iRegIorL2I src1, iRegIorL2I src2,
11137                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11138   match(Set dst (XorI src4 (XorI(URShiftI src2 src3) src1)));
11139   ins_cost(1.9 * INSN_COST);
11140   format %{ &quot;eonw  $dst, $src1, $src2, LSR $src3&quot; %}
11141 
11142   ins_encode %{
11143     __ eonw(as_Register($dst$$reg),
11144               as_Register($src1$$reg),
11145               as_Register($src2$$reg),
11146               Assembler::LSR,
11147               $src3$$constant &amp; 0x1f);
11148   %}
11149 
11150   ins_pipe(ialu_reg_reg_shift);
11151 %}
11152 
11153 instruct XorL_reg_URShift_not_reg(iRegLNoSp dst,
11154                          iRegL src1, iRegL src2,
11155                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11156   match(Set dst (XorL src4 (XorL(URShiftL src2 src3) src1)));
11157   ins_cost(1.9 * INSN_COST);
11158   format %{ &quot;eon  $dst, $src1, $src2, LSR $src3&quot; %}
11159 
11160   ins_encode %{
11161     __ eon(as_Register($dst$$reg),
11162               as_Register($src1$$reg),
11163               as_Register($src2$$reg),
11164               Assembler::LSR,
11165               $src3$$constant &amp; 0x3f);
11166   %}
11167 
11168   ins_pipe(ialu_reg_reg_shift);
11169 %}
11170 
11171 instruct XorI_reg_RShift_not_reg(iRegINoSp dst,
11172                          iRegIorL2I src1, iRegIorL2I src2,
11173                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11174   match(Set dst (XorI src4 (XorI(RShiftI src2 src3) src1)));
11175   ins_cost(1.9 * INSN_COST);
11176   format %{ &quot;eonw  $dst, $src1, $src2, ASR $src3&quot; %}
11177 
11178   ins_encode %{
11179     __ eonw(as_Register($dst$$reg),
11180               as_Register($src1$$reg),
11181               as_Register($src2$$reg),
11182               Assembler::ASR,
11183               $src3$$constant &amp; 0x1f);
11184   %}
11185 
11186   ins_pipe(ialu_reg_reg_shift);
11187 %}
11188 
11189 instruct XorL_reg_RShift_not_reg(iRegLNoSp dst,
11190                          iRegL src1, iRegL src2,
11191                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11192   match(Set dst (XorL src4 (XorL(RShiftL src2 src3) src1)));
11193   ins_cost(1.9 * INSN_COST);
11194   format %{ &quot;eon  $dst, $src1, $src2, ASR $src3&quot; %}
11195 
11196   ins_encode %{
11197     __ eon(as_Register($dst$$reg),
11198               as_Register($src1$$reg),
11199               as_Register($src2$$reg),
11200               Assembler::ASR,
11201               $src3$$constant &amp; 0x3f);
11202   %}
11203 
11204   ins_pipe(ialu_reg_reg_shift);
11205 %}
11206 
11207 instruct XorI_reg_LShift_not_reg(iRegINoSp dst,
11208                          iRegIorL2I src1, iRegIorL2I src2,
11209                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11210   match(Set dst (XorI src4 (XorI(LShiftI src2 src3) src1)));
11211   ins_cost(1.9 * INSN_COST);
11212   format %{ &quot;eonw  $dst, $src1, $src2, LSL $src3&quot; %}
11213 
11214   ins_encode %{
11215     __ eonw(as_Register($dst$$reg),
11216               as_Register($src1$$reg),
11217               as_Register($src2$$reg),
11218               Assembler::LSL,
11219               $src3$$constant &amp; 0x1f);
11220   %}
11221 
11222   ins_pipe(ialu_reg_reg_shift);
11223 %}
11224 
11225 instruct XorL_reg_LShift_not_reg(iRegLNoSp dst,
11226                          iRegL src1, iRegL src2,
11227                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11228   match(Set dst (XorL src4 (XorL(LShiftL src2 src3) src1)));
11229   ins_cost(1.9 * INSN_COST);
11230   format %{ &quot;eon  $dst, $src1, $src2, LSL $src3&quot; %}
11231 
11232   ins_encode %{
11233     __ eon(as_Register($dst$$reg),
11234               as_Register($src1$$reg),
11235               as_Register($src2$$reg),
11236               Assembler::LSL,
11237               $src3$$constant &amp; 0x3f);
11238   %}
11239 
11240   ins_pipe(ialu_reg_reg_shift);
11241 %}
11242 
11243 instruct OrI_reg_URShift_not_reg(iRegINoSp dst,
11244                          iRegIorL2I src1, iRegIorL2I src2,
11245                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11246   match(Set dst (OrI src1 (XorI(URShiftI src2 src3) src4)));
11247   ins_cost(1.9 * INSN_COST);
11248   format %{ &quot;ornw  $dst, $src1, $src2, LSR $src3&quot; %}
11249 
11250   ins_encode %{
11251     __ ornw(as_Register($dst$$reg),
11252               as_Register($src1$$reg),
11253               as_Register($src2$$reg),
11254               Assembler::LSR,
11255               $src3$$constant &amp; 0x1f);
11256   %}
11257 
11258   ins_pipe(ialu_reg_reg_shift);
11259 %}
11260 
11261 instruct OrL_reg_URShift_not_reg(iRegLNoSp dst,
11262                          iRegL src1, iRegL src2,
11263                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11264   match(Set dst (OrL src1 (XorL(URShiftL src2 src3) src4)));
11265   ins_cost(1.9 * INSN_COST);
11266   format %{ &quot;orn  $dst, $src1, $src2, LSR $src3&quot; %}
11267 
11268   ins_encode %{
11269     __ orn(as_Register($dst$$reg),
11270               as_Register($src1$$reg),
11271               as_Register($src2$$reg),
11272               Assembler::LSR,
11273               $src3$$constant &amp; 0x3f);
11274   %}
11275 
11276   ins_pipe(ialu_reg_reg_shift);
11277 %}
11278 
11279 instruct OrI_reg_RShift_not_reg(iRegINoSp dst,
11280                          iRegIorL2I src1, iRegIorL2I src2,
11281                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11282   match(Set dst (OrI src1 (XorI(RShiftI src2 src3) src4)));
11283   ins_cost(1.9 * INSN_COST);
11284   format %{ &quot;ornw  $dst, $src1, $src2, ASR $src3&quot; %}
11285 
11286   ins_encode %{
11287     __ ornw(as_Register($dst$$reg),
11288               as_Register($src1$$reg),
11289               as_Register($src2$$reg),
11290               Assembler::ASR,
11291               $src3$$constant &amp; 0x1f);
11292   %}
11293 
11294   ins_pipe(ialu_reg_reg_shift);
11295 %}
11296 
11297 instruct OrL_reg_RShift_not_reg(iRegLNoSp dst,
11298                          iRegL src1, iRegL src2,
11299                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11300   match(Set dst (OrL src1 (XorL(RShiftL src2 src3) src4)));
11301   ins_cost(1.9 * INSN_COST);
11302   format %{ &quot;orn  $dst, $src1, $src2, ASR $src3&quot; %}
11303 
11304   ins_encode %{
11305     __ orn(as_Register($dst$$reg),
11306               as_Register($src1$$reg),
11307               as_Register($src2$$reg),
11308               Assembler::ASR,
11309               $src3$$constant &amp; 0x3f);
11310   %}
11311 
11312   ins_pipe(ialu_reg_reg_shift);
11313 %}
11314 
11315 instruct OrI_reg_LShift_not_reg(iRegINoSp dst,
11316                          iRegIorL2I src1, iRegIorL2I src2,
11317                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11318   match(Set dst (OrI src1 (XorI(LShiftI src2 src3) src4)));
11319   ins_cost(1.9 * INSN_COST);
11320   format %{ &quot;ornw  $dst, $src1, $src2, LSL $src3&quot; %}
11321 
11322   ins_encode %{
11323     __ ornw(as_Register($dst$$reg),
11324               as_Register($src1$$reg),
11325               as_Register($src2$$reg),
11326               Assembler::LSL,
11327               $src3$$constant &amp; 0x1f);
11328   %}
11329 
11330   ins_pipe(ialu_reg_reg_shift);
11331 %}
11332 
11333 instruct OrL_reg_LShift_not_reg(iRegLNoSp dst,
11334                          iRegL src1, iRegL src2,
11335                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11336   match(Set dst (OrL src1 (XorL(LShiftL src2 src3) src4)));
11337   ins_cost(1.9 * INSN_COST);
11338   format %{ &quot;orn  $dst, $src1, $src2, LSL $src3&quot; %}
11339 
11340   ins_encode %{
11341     __ orn(as_Register($dst$$reg),
11342               as_Register($src1$$reg),
11343               as_Register($src2$$reg),
11344               Assembler::LSL,
11345               $src3$$constant &amp; 0x3f);
11346   %}
11347 
11348   ins_pipe(ialu_reg_reg_shift);
11349 %}
11350 
11351 instruct AndI_reg_URShift_reg(iRegINoSp dst,
11352                          iRegIorL2I src1, iRegIorL2I src2,
11353                          immI src3, rFlagsReg cr) %{
11354   match(Set dst (AndI src1 (URShiftI src2 src3)));
11355 
11356   ins_cost(1.9 * INSN_COST);
11357   format %{ &quot;andw  $dst, $src1, $src2, LSR $src3&quot; %}
11358 
11359   ins_encode %{
11360     __ andw(as_Register($dst$$reg),
11361               as_Register($src1$$reg),
11362               as_Register($src2$$reg),
11363               Assembler::LSR,
11364               $src3$$constant &amp; 0x1f);
11365   %}
11366 
11367   ins_pipe(ialu_reg_reg_shift);
11368 %}
11369 
11370 instruct AndL_reg_URShift_reg(iRegLNoSp dst,
11371                          iRegL src1, iRegL src2,
11372                          immI src3, rFlagsReg cr) %{
11373   match(Set dst (AndL src1 (URShiftL src2 src3)));
11374 
11375   ins_cost(1.9 * INSN_COST);
11376   format %{ &quot;andr  $dst, $src1, $src2, LSR $src3&quot; %}
11377 
11378   ins_encode %{
11379     __ andr(as_Register($dst$$reg),
11380               as_Register($src1$$reg),
11381               as_Register($src2$$reg),
11382               Assembler::LSR,
11383               $src3$$constant &amp; 0x3f);
11384   %}
11385 
11386   ins_pipe(ialu_reg_reg_shift);
11387 %}
11388 
11389 instruct AndI_reg_RShift_reg(iRegINoSp dst,
11390                          iRegIorL2I src1, iRegIorL2I src2,
11391                          immI src3, rFlagsReg cr) %{
11392   match(Set dst (AndI src1 (RShiftI src2 src3)));
11393 
11394   ins_cost(1.9 * INSN_COST);
11395   format %{ &quot;andw  $dst, $src1, $src2, ASR $src3&quot; %}
11396 
11397   ins_encode %{
11398     __ andw(as_Register($dst$$reg),
11399               as_Register($src1$$reg),
11400               as_Register($src2$$reg),
11401               Assembler::ASR,
11402               $src3$$constant &amp; 0x1f);
11403   %}
11404 
11405   ins_pipe(ialu_reg_reg_shift);
11406 %}
11407 
11408 instruct AndL_reg_RShift_reg(iRegLNoSp dst,
11409                          iRegL src1, iRegL src2,
11410                          immI src3, rFlagsReg cr) %{
11411   match(Set dst (AndL src1 (RShiftL src2 src3)));
11412 
11413   ins_cost(1.9 * INSN_COST);
11414   format %{ &quot;andr  $dst, $src1, $src2, ASR $src3&quot; %}
11415 
11416   ins_encode %{
11417     __ andr(as_Register($dst$$reg),
11418               as_Register($src1$$reg),
11419               as_Register($src2$$reg),
11420               Assembler::ASR,
11421               $src3$$constant &amp; 0x3f);
11422   %}
11423 
11424   ins_pipe(ialu_reg_reg_shift);
11425 %}
11426 
11427 instruct AndI_reg_LShift_reg(iRegINoSp dst,
11428                          iRegIorL2I src1, iRegIorL2I src2,
11429                          immI src3, rFlagsReg cr) %{
11430   match(Set dst (AndI src1 (LShiftI src2 src3)));
11431 
11432   ins_cost(1.9 * INSN_COST);
11433   format %{ &quot;andw  $dst, $src1, $src2, LSL $src3&quot; %}
11434 
11435   ins_encode %{
11436     __ andw(as_Register($dst$$reg),
11437               as_Register($src1$$reg),
11438               as_Register($src2$$reg),
11439               Assembler::LSL,
11440               $src3$$constant &amp; 0x1f);
11441   %}
11442 
11443   ins_pipe(ialu_reg_reg_shift);
11444 %}
11445 
11446 instruct AndL_reg_LShift_reg(iRegLNoSp dst,
11447                          iRegL src1, iRegL src2,
11448                          immI src3, rFlagsReg cr) %{
11449   match(Set dst (AndL src1 (LShiftL src2 src3)));
11450 
11451   ins_cost(1.9 * INSN_COST);
11452   format %{ &quot;andr  $dst, $src1, $src2, LSL $src3&quot; %}
11453 
11454   ins_encode %{
11455     __ andr(as_Register($dst$$reg),
11456               as_Register($src1$$reg),
11457               as_Register($src2$$reg),
11458               Assembler::LSL,
11459               $src3$$constant &amp; 0x3f);
11460   %}
11461 
11462   ins_pipe(ialu_reg_reg_shift);
11463 %}
11464 
11465 instruct XorI_reg_URShift_reg(iRegINoSp dst,
11466                          iRegIorL2I src1, iRegIorL2I src2,
11467                          immI src3, rFlagsReg cr) %{
11468   match(Set dst (XorI src1 (URShiftI src2 src3)));
11469 
11470   ins_cost(1.9 * INSN_COST);
11471   format %{ &quot;eorw  $dst, $src1, $src2, LSR $src3&quot; %}
11472 
11473   ins_encode %{
11474     __ eorw(as_Register($dst$$reg),
11475               as_Register($src1$$reg),
11476               as_Register($src2$$reg),
11477               Assembler::LSR,
11478               $src3$$constant &amp; 0x1f);
11479   %}
11480 
11481   ins_pipe(ialu_reg_reg_shift);
11482 %}
11483 
11484 instruct XorL_reg_URShift_reg(iRegLNoSp dst,
11485                          iRegL src1, iRegL src2,
11486                          immI src3, rFlagsReg cr) %{
11487   match(Set dst (XorL src1 (URShiftL src2 src3)));
11488 
11489   ins_cost(1.9 * INSN_COST);
11490   format %{ &quot;eor  $dst, $src1, $src2, LSR $src3&quot; %}
11491 
11492   ins_encode %{
11493     __ eor(as_Register($dst$$reg),
11494               as_Register($src1$$reg),
11495               as_Register($src2$$reg),
11496               Assembler::LSR,
11497               $src3$$constant &amp; 0x3f);
11498   %}
11499 
11500   ins_pipe(ialu_reg_reg_shift);
11501 %}
11502 
11503 instruct XorI_reg_RShift_reg(iRegINoSp dst,
11504                          iRegIorL2I src1, iRegIorL2I src2,
11505                          immI src3, rFlagsReg cr) %{
11506   match(Set dst (XorI src1 (RShiftI src2 src3)));
11507 
11508   ins_cost(1.9 * INSN_COST);
11509   format %{ &quot;eorw  $dst, $src1, $src2, ASR $src3&quot; %}
11510 
11511   ins_encode %{
11512     __ eorw(as_Register($dst$$reg),
11513               as_Register($src1$$reg),
11514               as_Register($src2$$reg),
11515               Assembler::ASR,
11516               $src3$$constant &amp; 0x1f);
11517   %}
11518 
11519   ins_pipe(ialu_reg_reg_shift);
11520 %}
11521 
11522 instruct XorL_reg_RShift_reg(iRegLNoSp dst,
11523                          iRegL src1, iRegL src2,
11524                          immI src3, rFlagsReg cr) %{
11525   match(Set dst (XorL src1 (RShiftL src2 src3)));
11526 
11527   ins_cost(1.9 * INSN_COST);
11528   format %{ &quot;eor  $dst, $src1, $src2, ASR $src3&quot; %}
11529 
11530   ins_encode %{
11531     __ eor(as_Register($dst$$reg),
11532               as_Register($src1$$reg),
11533               as_Register($src2$$reg),
11534               Assembler::ASR,
11535               $src3$$constant &amp; 0x3f);
11536   %}
11537 
11538   ins_pipe(ialu_reg_reg_shift);
11539 %}
11540 
11541 instruct XorI_reg_LShift_reg(iRegINoSp dst,
11542                          iRegIorL2I src1, iRegIorL2I src2,
11543                          immI src3, rFlagsReg cr) %{
11544   match(Set dst (XorI src1 (LShiftI src2 src3)));
11545 
11546   ins_cost(1.9 * INSN_COST);
11547   format %{ &quot;eorw  $dst, $src1, $src2, LSL $src3&quot; %}
11548 
11549   ins_encode %{
11550     __ eorw(as_Register($dst$$reg),
11551               as_Register($src1$$reg),
11552               as_Register($src2$$reg),
11553               Assembler::LSL,
11554               $src3$$constant &amp; 0x1f);
11555   %}
11556 
11557   ins_pipe(ialu_reg_reg_shift);
11558 %}
11559 
11560 instruct XorL_reg_LShift_reg(iRegLNoSp dst,
11561                          iRegL src1, iRegL src2,
11562                          immI src3, rFlagsReg cr) %{
11563   match(Set dst (XorL src1 (LShiftL src2 src3)));
11564 
11565   ins_cost(1.9 * INSN_COST);
11566   format %{ &quot;eor  $dst, $src1, $src2, LSL $src3&quot; %}
11567 
11568   ins_encode %{
11569     __ eor(as_Register($dst$$reg),
11570               as_Register($src1$$reg),
11571               as_Register($src2$$reg),
11572               Assembler::LSL,
11573               $src3$$constant &amp; 0x3f);
11574   %}
11575 
11576   ins_pipe(ialu_reg_reg_shift);
11577 %}
11578 
11579 instruct OrI_reg_URShift_reg(iRegINoSp dst,
11580                          iRegIorL2I src1, iRegIorL2I src2,
11581                          immI src3, rFlagsReg cr) %{
11582   match(Set dst (OrI src1 (URShiftI src2 src3)));
11583 
11584   ins_cost(1.9 * INSN_COST);
11585   format %{ &quot;orrw  $dst, $src1, $src2, LSR $src3&quot; %}
11586 
11587   ins_encode %{
11588     __ orrw(as_Register($dst$$reg),
11589               as_Register($src1$$reg),
11590               as_Register($src2$$reg),
11591               Assembler::LSR,
11592               $src3$$constant &amp; 0x1f);
11593   %}
11594 
11595   ins_pipe(ialu_reg_reg_shift);
11596 %}
11597 
11598 instruct OrL_reg_URShift_reg(iRegLNoSp dst,
11599                          iRegL src1, iRegL src2,
11600                          immI src3, rFlagsReg cr) %{
11601   match(Set dst (OrL src1 (URShiftL src2 src3)));
11602 
11603   ins_cost(1.9 * INSN_COST);
11604   format %{ &quot;orr  $dst, $src1, $src2, LSR $src3&quot; %}
11605 
11606   ins_encode %{
11607     __ orr(as_Register($dst$$reg),
11608               as_Register($src1$$reg),
11609               as_Register($src2$$reg),
11610               Assembler::LSR,
11611               $src3$$constant &amp; 0x3f);
11612   %}
11613 
11614   ins_pipe(ialu_reg_reg_shift);
11615 %}
11616 
11617 instruct OrI_reg_RShift_reg(iRegINoSp dst,
11618                          iRegIorL2I src1, iRegIorL2I src2,
11619                          immI src3, rFlagsReg cr) %{
11620   match(Set dst (OrI src1 (RShiftI src2 src3)));
11621 
11622   ins_cost(1.9 * INSN_COST);
11623   format %{ &quot;orrw  $dst, $src1, $src2, ASR $src3&quot; %}
11624 
11625   ins_encode %{
11626     __ orrw(as_Register($dst$$reg),
11627               as_Register($src1$$reg),
11628               as_Register($src2$$reg),
11629               Assembler::ASR,
11630               $src3$$constant &amp; 0x1f);
11631   %}
11632 
11633   ins_pipe(ialu_reg_reg_shift);
11634 %}
11635 
11636 instruct OrL_reg_RShift_reg(iRegLNoSp dst,
11637                          iRegL src1, iRegL src2,
11638                          immI src3, rFlagsReg cr) %{
11639   match(Set dst (OrL src1 (RShiftL src2 src3)));
11640 
11641   ins_cost(1.9 * INSN_COST);
11642   format %{ &quot;orr  $dst, $src1, $src2, ASR $src3&quot; %}
11643 
11644   ins_encode %{
11645     __ orr(as_Register($dst$$reg),
11646               as_Register($src1$$reg),
11647               as_Register($src2$$reg),
11648               Assembler::ASR,
11649               $src3$$constant &amp; 0x3f);
11650   %}
11651 
11652   ins_pipe(ialu_reg_reg_shift);
11653 %}
11654 
11655 instruct OrI_reg_LShift_reg(iRegINoSp dst,
11656                          iRegIorL2I src1, iRegIorL2I src2,
11657                          immI src3, rFlagsReg cr) %{
11658   match(Set dst (OrI src1 (LShiftI src2 src3)));
11659 
11660   ins_cost(1.9 * INSN_COST);
11661   format %{ &quot;orrw  $dst, $src1, $src2, LSL $src3&quot; %}
11662 
11663   ins_encode %{
11664     __ orrw(as_Register($dst$$reg),
11665               as_Register($src1$$reg),
11666               as_Register($src2$$reg),
11667               Assembler::LSL,
11668               $src3$$constant &amp; 0x1f);
11669   %}
11670 
11671   ins_pipe(ialu_reg_reg_shift);
11672 %}
11673 
11674 instruct OrL_reg_LShift_reg(iRegLNoSp dst,
11675                          iRegL src1, iRegL src2,
11676                          immI src3, rFlagsReg cr) %{
11677   match(Set dst (OrL src1 (LShiftL src2 src3)));
11678 
11679   ins_cost(1.9 * INSN_COST);
11680   format %{ &quot;orr  $dst, $src1, $src2, LSL $src3&quot; %}
11681 
11682   ins_encode %{
11683     __ orr(as_Register($dst$$reg),
11684               as_Register($src1$$reg),
11685               as_Register($src2$$reg),
11686               Assembler::LSL,
11687               $src3$$constant &amp; 0x3f);
11688   %}
11689 
11690   ins_pipe(ialu_reg_reg_shift);
11691 %}
11692 
11693 instruct AddI_reg_URShift_reg(iRegINoSp dst,
11694                          iRegIorL2I src1, iRegIorL2I src2,
11695                          immI src3, rFlagsReg cr) %{
11696   match(Set dst (AddI src1 (URShiftI src2 src3)));
11697 
11698   ins_cost(1.9 * INSN_COST);
11699   format %{ &quot;addw  $dst, $src1, $src2, LSR $src3&quot; %}
11700 
11701   ins_encode %{
11702     __ addw(as_Register($dst$$reg),
11703               as_Register($src1$$reg),
11704               as_Register($src2$$reg),
11705               Assembler::LSR,
11706               $src3$$constant &amp; 0x1f);
11707   %}
11708 
11709   ins_pipe(ialu_reg_reg_shift);
11710 %}
11711 
11712 instruct AddL_reg_URShift_reg(iRegLNoSp dst,
11713                          iRegL src1, iRegL src2,
11714                          immI src3, rFlagsReg cr) %{
11715   match(Set dst (AddL src1 (URShiftL src2 src3)));
11716 
11717   ins_cost(1.9 * INSN_COST);
11718   format %{ &quot;add  $dst, $src1, $src2, LSR $src3&quot; %}
11719 
11720   ins_encode %{
11721     __ add(as_Register($dst$$reg),
11722               as_Register($src1$$reg),
11723               as_Register($src2$$reg),
11724               Assembler::LSR,
11725               $src3$$constant &amp; 0x3f);
11726   %}
11727 
11728   ins_pipe(ialu_reg_reg_shift);
11729 %}
11730 
11731 instruct AddI_reg_RShift_reg(iRegINoSp dst,
11732                          iRegIorL2I src1, iRegIorL2I src2,
11733                          immI src3, rFlagsReg cr) %{
11734   match(Set dst (AddI src1 (RShiftI src2 src3)));
11735 
11736   ins_cost(1.9 * INSN_COST);
11737   format %{ &quot;addw  $dst, $src1, $src2, ASR $src3&quot; %}
11738 
11739   ins_encode %{
11740     __ addw(as_Register($dst$$reg),
11741               as_Register($src1$$reg),
11742               as_Register($src2$$reg),
11743               Assembler::ASR,
11744               $src3$$constant &amp; 0x1f);
11745   %}
11746 
11747   ins_pipe(ialu_reg_reg_shift);
11748 %}
11749 
11750 instruct AddL_reg_RShift_reg(iRegLNoSp dst,
11751                          iRegL src1, iRegL src2,
11752                          immI src3, rFlagsReg cr) %{
11753   match(Set dst (AddL src1 (RShiftL src2 src3)));
11754 
11755   ins_cost(1.9 * INSN_COST);
11756   format %{ &quot;add  $dst, $src1, $src2, ASR $src3&quot; %}
11757 
11758   ins_encode %{
11759     __ add(as_Register($dst$$reg),
11760               as_Register($src1$$reg),
11761               as_Register($src2$$reg),
11762               Assembler::ASR,
11763               $src3$$constant &amp; 0x3f);
11764   %}
11765 
11766   ins_pipe(ialu_reg_reg_shift);
11767 %}
11768 
11769 instruct AddI_reg_LShift_reg(iRegINoSp dst,
11770                          iRegIorL2I src1, iRegIorL2I src2,
11771                          immI src3, rFlagsReg cr) %{
11772   match(Set dst (AddI src1 (LShiftI src2 src3)));
11773 
11774   ins_cost(1.9 * INSN_COST);
11775   format %{ &quot;addw  $dst, $src1, $src2, LSL $src3&quot; %}
11776 
11777   ins_encode %{
11778     __ addw(as_Register($dst$$reg),
11779               as_Register($src1$$reg),
11780               as_Register($src2$$reg),
11781               Assembler::LSL,
11782               $src3$$constant &amp; 0x1f);
11783   %}
11784 
11785   ins_pipe(ialu_reg_reg_shift);
11786 %}
11787 
11788 instruct AddL_reg_LShift_reg(iRegLNoSp dst,
11789                          iRegL src1, iRegL src2,
11790                          immI src3, rFlagsReg cr) %{
11791   match(Set dst (AddL src1 (LShiftL src2 src3)));
11792 
11793   ins_cost(1.9 * INSN_COST);
11794   format %{ &quot;add  $dst, $src1, $src2, LSL $src3&quot; %}
11795 
11796   ins_encode %{
11797     __ add(as_Register($dst$$reg),
11798               as_Register($src1$$reg),
11799               as_Register($src2$$reg),
11800               Assembler::LSL,
11801               $src3$$constant &amp; 0x3f);
11802   %}
11803 
11804   ins_pipe(ialu_reg_reg_shift);
11805 %}
11806 
11807 instruct SubI_reg_URShift_reg(iRegINoSp dst,
11808                          iRegIorL2I src1, iRegIorL2I src2,
11809                          immI src3, rFlagsReg cr) %{
11810   match(Set dst (SubI src1 (URShiftI src2 src3)));
11811 
11812   ins_cost(1.9 * INSN_COST);
11813   format %{ &quot;subw  $dst, $src1, $src2, LSR $src3&quot; %}
11814 
11815   ins_encode %{
11816     __ subw(as_Register($dst$$reg),
11817               as_Register($src1$$reg),
11818               as_Register($src2$$reg),
11819               Assembler::LSR,
11820               $src3$$constant &amp; 0x1f);
11821   %}
11822 
11823   ins_pipe(ialu_reg_reg_shift);
11824 %}
11825 
11826 instruct SubL_reg_URShift_reg(iRegLNoSp dst,
11827                          iRegL src1, iRegL src2,
11828                          immI src3, rFlagsReg cr) %{
11829   match(Set dst (SubL src1 (URShiftL src2 src3)));
11830 
11831   ins_cost(1.9 * INSN_COST);
11832   format %{ &quot;sub  $dst, $src1, $src2, LSR $src3&quot; %}
11833 
11834   ins_encode %{
11835     __ sub(as_Register($dst$$reg),
11836               as_Register($src1$$reg),
11837               as_Register($src2$$reg),
11838               Assembler::LSR,
11839               $src3$$constant &amp; 0x3f);
11840   %}
11841 
11842   ins_pipe(ialu_reg_reg_shift);
11843 %}
11844 
11845 instruct SubI_reg_RShift_reg(iRegINoSp dst,
11846                          iRegIorL2I src1, iRegIorL2I src2,
11847                          immI src3, rFlagsReg cr) %{
11848   match(Set dst (SubI src1 (RShiftI src2 src3)));
11849 
11850   ins_cost(1.9 * INSN_COST);
11851   format %{ &quot;subw  $dst, $src1, $src2, ASR $src3&quot; %}
11852 
11853   ins_encode %{
11854     __ subw(as_Register($dst$$reg),
11855               as_Register($src1$$reg),
11856               as_Register($src2$$reg),
11857               Assembler::ASR,
11858               $src3$$constant &amp; 0x1f);
11859   %}
11860 
11861   ins_pipe(ialu_reg_reg_shift);
11862 %}
11863 
11864 instruct SubL_reg_RShift_reg(iRegLNoSp dst,
11865                          iRegL src1, iRegL src2,
11866                          immI src3, rFlagsReg cr) %{
11867   match(Set dst (SubL src1 (RShiftL src2 src3)));
11868 
11869   ins_cost(1.9 * INSN_COST);
11870   format %{ &quot;sub  $dst, $src1, $src2, ASR $src3&quot; %}
11871 
11872   ins_encode %{
11873     __ sub(as_Register($dst$$reg),
11874               as_Register($src1$$reg),
11875               as_Register($src2$$reg),
11876               Assembler::ASR,
11877               $src3$$constant &amp; 0x3f);
11878   %}
11879 
11880   ins_pipe(ialu_reg_reg_shift);
11881 %}
11882 
11883 instruct SubI_reg_LShift_reg(iRegINoSp dst,
11884                          iRegIorL2I src1, iRegIorL2I src2,
11885                          immI src3, rFlagsReg cr) %{
11886   match(Set dst (SubI src1 (LShiftI src2 src3)));
11887 
11888   ins_cost(1.9 * INSN_COST);
11889   format %{ &quot;subw  $dst, $src1, $src2, LSL $src3&quot; %}
11890 
11891   ins_encode %{
11892     __ subw(as_Register($dst$$reg),
11893               as_Register($src1$$reg),
11894               as_Register($src2$$reg),
11895               Assembler::LSL,
11896               $src3$$constant &amp; 0x1f);
11897   %}
11898 
11899   ins_pipe(ialu_reg_reg_shift);
11900 %}
11901 
11902 instruct SubL_reg_LShift_reg(iRegLNoSp dst,
11903                          iRegL src1, iRegL src2,
11904                          immI src3, rFlagsReg cr) %{
11905   match(Set dst (SubL src1 (LShiftL src2 src3)));
11906 
11907   ins_cost(1.9 * INSN_COST);
11908   format %{ &quot;sub  $dst, $src1, $src2, LSL $src3&quot; %}
11909 
11910   ins_encode %{
11911     __ sub(as_Register($dst$$reg),
11912               as_Register($src1$$reg),
11913               as_Register($src2$$reg),
11914               Assembler::LSL,
11915               $src3$$constant &amp; 0x3f);
11916   %}
11917 
11918   ins_pipe(ialu_reg_reg_shift);
11919 %}
11920 
11921 
11922 
11923 // Shift Left followed by Shift Right.
11924 // This idiom is used by the compiler for the i2b bytecode etc.
11925 instruct sbfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11926 %{
11927   match(Set dst (RShiftL (LShiftL src lshift_count) rshift_count));
11928   ins_cost(INSN_COST * 2);
11929   format %{ &quot;sbfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11930   ins_encode %{
11931     int lshift = $lshift_count$$constant &amp; 63;
11932     int rshift = $rshift_count$$constant &amp; 63;
11933     int s = 63 - lshift;
11934     int r = (rshift - lshift) &amp; 63;
11935     __ sbfm(as_Register($dst$$reg),
11936             as_Register($src$$reg),
11937             r, s);
11938   %}
11939 
11940   ins_pipe(ialu_reg_shift);
11941 %}
11942 
11943 // Shift Left followed by Shift Right.
11944 // This idiom is used by the compiler for the i2b bytecode etc.
11945 instruct sbfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11946 %{
11947   match(Set dst (RShiftI (LShiftI src lshift_count) rshift_count));
11948   ins_cost(INSN_COST * 2);
11949   format %{ &quot;sbfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
11950   ins_encode %{
11951     int lshift = $lshift_count$$constant &amp; 31;
11952     int rshift = $rshift_count$$constant &amp; 31;
11953     int s = 31 - lshift;
11954     int r = (rshift - lshift) &amp; 31;
11955     __ sbfmw(as_Register($dst$$reg),
11956             as_Register($src$$reg),
11957             r, s);
11958   %}
11959 
11960   ins_pipe(ialu_reg_shift);
11961 %}
11962 
11963 // Shift Left followed by Shift Right.
11964 // This idiom is used by the compiler for the i2b bytecode etc.
11965 instruct ubfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11966 %{
11967   match(Set dst (URShiftL (LShiftL src lshift_count) rshift_count));
11968   ins_cost(INSN_COST * 2);
11969   format %{ &quot;ubfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11970   ins_encode %{
11971     int lshift = $lshift_count$$constant &amp; 63;
11972     int rshift = $rshift_count$$constant &amp; 63;
11973     int s = 63 - lshift;
11974     int r = (rshift - lshift) &amp; 63;
11975     __ ubfm(as_Register($dst$$reg),
11976             as_Register($src$$reg),
11977             r, s);
11978   %}
11979 
11980   ins_pipe(ialu_reg_shift);
11981 %}
11982 
11983 // Shift Left followed by Shift Right.
11984 // This idiom is used by the compiler for the i2b bytecode etc.
11985 instruct ubfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11986 %{
11987   match(Set dst (URShiftI (LShiftI src lshift_count) rshift_count));
11988   ins_cost(INSN_COST * 2);
11989   format %{ &quot;ubfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
11990   ins_encode %{
11991     int lshift = $lshift_count$$constant &amp; 31;
11992     int rshift = $rshift_count$$constant &amp; 31;
11993     int s = 31 - lshift;
11994     int r = (rshift - lshift) &amp; 31;
11995     __ ubfmw(as_Register($dst$$reg),
11996             as_Register($src$$reg),
11997             r, s);
11998   %}
11999 
12000   ins_pipe(ialu_reg_shift);
12001 %}
12002 // Bitfield extract with shift &amp; mask
12003 
12004 instruct ubfxwI(iRegINoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
12005 %{
12006   match(Set dst (AndI (URShiftI src rshift) mask));
12007   // Make sure we are not going to exceed what ubfxw can do.
12008   predicate((exact_log2(n-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12009 
12010   ins_cost(INSN_COST);
12011   format %{ &quot;ubfxw $dst, $src, $rshift, $mask&quot; %}
12012   ins_encode %{
12013     int rshift = $rshift$$constant &amp; 31;
12014     long mask = $mask$$constant;
12015     int width = exact_log2(mask+1);
12016     __ ubfxw(as_Register($dst$$reg),
12017             as_Register($src$$reg), rshift, width);
12018   %}
12019   ins_pipe(ialu_reg_shift);
12020 %}
12021 instruct ubfxL(iRegLNoSp dst, iRegL src, immI rshift, immL_bitmask mask)
12022 %{
12023   match(Set dst (AndL (URShiftL src rshift) mask));
12024   // Make sure we are not going to exceed what ubfx can do.
12025   predicate((exact_log2_long(n-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12026 
12027   ins_cost(INSN_COST);
12028   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12029   ins_encode %{
12030     int rshift = $rshift$$constant &amp; 63;
12031     long mask = $mask$$constant;
12032     int width = exact_log2_long(mask+1);
12033     __ ubfx(as_Register($dst$$reg),
12034             as_Register($src$$reg), rshift, width);
12035   %}
12036   ins_pipe(ialu_reg_shift);
12037 %}
12038 
12039 // We can use ubfx when extending an And with a mask when we know mask
12040 // is positive.  We know that because immI_bitmask guarantees it.
12041 instruct ubfxIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
12042 %{
12043   match(Set dst (ConvI2L (AndI (URShiftI src rshift) mask)));
12044   // Make sure we are not going to exceed what ubfxw can do.
12045   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12046 
12047   ins_cost(INSN_COST * 2);
12048   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12049   ins_encode %{
12050     int rshift = $rshift$$constant &amp; 31;
12051     long mask = $mask$$constant;
12052     int width = exact_log2(mask+1);
12053     __ ubfx(as_Register($dst$$reg),
12054             as_Register($src$$reg), rshift, width);
12055   %}
12056   ins_pipe(ialu_reg_shift);
12057 %}
12058 
12059 // We can use ubfiz when masking by a positive number and then left shifting the result.
12060 // We know that the mask is positive because immI_bitmask guarantees it.
12061 instruct ubfizwI(iRegINoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12062 %{
12063   match(Set dst (LShiftI (AndI src mask) lshift));
12064   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12065 
12066   ins_cost(INSN_COST);
12067   format %{ &quot;ubfizw $dst, $src, $lshift, $mask&quot; %}
12068   ins_encode %{
12069     int lshift = $lshift$$constant &amp; 31;
12070     long mask = $mask$$constant;
12071     int width = exact_log2(mask+1);
12072     __ ubfizw(as_Register($dst$$reg),
12073           as_Register($src$$reg), lshift, width);
12074   %}
12075   ins_pipe(ialu_reg_shift);
12076 %}
12077 // We can use ubfiz when masking by a positive number and then left shifting the result.
12078 // We know that the mask is positive because immL_bitmask guarantees it.
12079 instruct ubfizL(iRegLNoSp dst, iRegL src, immI lshift, immL_bitmask mask)
12080 %{
12081   match(Set dst (LShiftL (AndL src mask) lshift));
12082   predicate((exact_log2_long(n-&gt;in(1)-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12083 
12084   ins_cost(INSN_COST);
12085   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12086   ins_encode %{
12087     int lshift = $lshift$$constant &amp; 63;
12088     long mask = $mask$$constant;
12089     int width = exact_log2_long(mask+1);
12090     __ ubfiz(as_Register($dst$$reg),
12091           as_Register($src$$reg), lshift, width);
12092   %}
12093   ins_pipe(ialu_reg_shift);
12094 %}
12095 
12096 // If there is a convert I to L block between and AndI and a LShiftL, we can also match ubfiz
12097 instruct ubfizIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12098 %{
12099   match(Set dst (LShiftL (ConvI2L (AndI src mask)) lshift));
12100   predicate((exact_log2(n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12101 
12102   ins_cost(INSN_COST);
12103   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12104   ins_encode %{
12105     int lshift = $lshift$$constant &amp; 63;
12106     long mask = $mask$$constant;
12107     int width = exact_log2(mask+1);
12108     __ ubfiz(as_Register($dst$$reg),
12109              as_Register($src$$reg), lshift, width);
12110   %}
12111   ins_pipe(ialu_reg_shift);
12112 %}
12113 
12114 // Rotations
12115 
12116 instruct extrOrL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12117 %{
12118   match(Set dst (OrL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12119   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12120 
12121   ins_cost(INSN_COST);
12122   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12123 
12124   ins_encode %{
12125     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12126             $rshift$$constant &amp; 63);
12127   %}
12128   ins_pipe(ialu_reg_reg_extr);
12129 %}
12130 
12131 instruct extrOrI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12132 %{
12133   match(Set dst (OrI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12134   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12135 
12136   ins_cost(INSN_COST);
12137   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12138 
12139   ins_encode %{
12140     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12141             $rshift$$constant &amp; 31);
12142   %}
12143   ins_pipe(ialu_reg_reg_extr);
12144 %}
12145 
12146 instruct extrAddL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12147 %{
12148   match(Set dst (AddL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12149   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12150 
12151   ins_cost(INSN_COST);
12152   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12153 
12154   ins_encode %{
12155     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12156             $rshift$$constant &amp; 63);
12157   %}
12158   ins_pipe(ialu_reg_reg_extr);
12159 %}
12160 
12161 instruct extrAddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12162 %{
12163   match(Set dst (AddI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12164   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12165 
12166   ins_cost(INSN_COST);
12167   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12168 
12169   ins_encode %{
12170     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12171             $rshift$$constant &amp; 31);
12172   %}
12173   ins_pipe(ialu_reg_reg_extr);
12174 %}
12175 
12176 
12177 // rol expander
12178 
12179 instruct rolL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12180 %{
12181   effect(DEF dst, USE src, USE shift);
12182 
12183   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12184   ins_cost(INSN_COST * 3);
12185   ins_encode %{
12186     __ subw(rscratch1, zr, as_Register($shift$$reg));
12187     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12188             rscratch1);
12189     %}
12190   ins_pipe(ialu_reg_reg_vshift);
12191 %}
12192 
12193 // rol expander
12194 
12195 instruct rolI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12196 %{
12197   effect(DEF dst, USE src, USE shift);
12198 
12199   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12200   ins_cost(INSN_COST * 3);
12201   ins_encode %{
12202     __ subw(rscratch1, zr, as_Register($shift$$reg));
12203     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12204             rscratch1);
12205     %}
12206   ins_pipe(ialu_reg_reg_vshift);
12207 %}
12208 
12209 instruct rolL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12210 %{
12211   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c_64 shift))));
12212 
12213   expand %{
12214     rolL_rReg(dst, src, shift, cr);
12215   %}
12216 %}
12217 
12218 instruct rolL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12219 %{
12220   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c0 shift))));
12221 
12222   expand %{
12223     rolL_rReg(dst, src, shift, cr);
12224   %}
12225 %}
12226 
12227 instruct rolI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12228 %{
12229   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c_32 shift))));
12230 
12231   expand %{
12232     rolI_rReg(dst, src, shift, cr);
12233   %}
12234 %}
12235 
12236 instruct rolI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12237 %{
12238   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c0 shift))));
12239 
12240   expand %{
12241     rolI_rReg(dst, src, shift, cr);
12242   %}
12243 %}
12244 
12245 // ror expander
12246 
12247 instruct rorL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12248 %{
12249   effect(DEF dst, USE src, USE shift);
12250 
12251   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12252   ins_cost(INSN_COST);
12253   ins_encode %{
12254     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12255             as_Register($shift$$reg));
12256     %}
12257   ins_pipe(ialu_reg_reg_vshift);
12258 %}
12259 
12260 // ror expander
12261 
12262 instruct rorI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12263 %{
12264   effect(DEF dst, USE src, USE shift);
12265 
12266   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12267   ins_cost(INSN_COST);
12268   ins_encode %{
12269     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12270             as_Register($shift$$reg));
12271     %}
12272   ins_pipe(ialu_reg_reg_vshift);
12273 %}
12274 
12275 instruct rorL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12276 %{
12277   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c_64 shift))));
12278 
12279   expand %{
12280     rorL_rReg(dst, src, shift, cr);
12281   %}
12282 %}
12283 
12284 instruct rorL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12285 %{
12286   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c0 shift))));
12287 
12288   expand %{
12289     rorL_rReg(dst, src, shift, cr);
12290   %}
12291 %}
12292 
12293 instruct rorI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12294 %{
12295   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c_32 shift))));
12296 
12297   expand %{
12298     rorI_rReg(dst, src, shift, cr);
12299   %}
12300 %}
12301 
12302 instruct rorI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12303 %{
12304   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c0 shift))));
12305 
12306   expand %{
12307     rorI_rReg(dst, src, shift, cr);
12308   %}
12309 %}
12310 
12311 // Add/subtract (extended)
12312 
12313 instruct AddExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12314 %{
12315   match(Set dst (AddL src1 (ConvI2L src2)));
12316   ins_cost(INSN_COST);
12317   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12318 
12319    ins_encode %{
12320      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12321             as_Register($src2$$reg), ext::sxtw);
12322    %}
12323   ins_pipe(ialu_reg_reg);
12324 %};
12325 
12326 instruct SubExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12327 %{
12328   match(Set dst (SubL src1 (ConvI2L src2)));
12329   ins_cost(INSN_COST);
12330   format %{ &quot;sub  $dst, $src1, $src2, sxtw&quot; %}
12331 
12332    ins_encode %{
12333      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12334             as_Register($src2$$reg), ext::sxtw);
12335    %}
12336   ins_pipe(ialu_reg_reg);
12337 %};
12338 
12339 
12340 instruct AddExtI_sxth(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_16 lshift, immI_16 rshift, rFlagsReg cr)
12341 %{
12342   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12343   ins_cost(INSN_COST);
12344   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12345 
12346    ins_encode %{
12347      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12348             as_Register($src2$$reg), ext::sxth);
12349    %}
12350   ins_pipe(ialu_reg_reg);
12351 %}
12352 
12353 instruct AddExtI_sxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12354 %{
12355   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12356   ins_cost(INSN_COST);
12357   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12358 
12359    ins_encode %{
12360      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12361             as_Register($src2$$reg), ext::sxtb);
12362    %}
12363   ins_pipe(ialu_reg_reg);
12364 %}
12365 
12366 instruct AddExtI_uxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12367 %{
12368   match(Set dst (AddI src1 (URShiftI (LShiftI src2 lshift) rshift)));
12369   ins_cost(INSN_COST);
12370   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12371 
12372    ins_encode %{
12373      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12374             as_Register($src2$$reg), ext::uxtb);
12375    %}
12376   ins_pipe(ialu_reg_reg);
12377 %}
12378 
12379 instruct AddExtL_sxth(iRegLNoSp dst, iRegL src1, iRegL src2, immI_48 lshift, immI_48 rshift, rFlagsReg cr)
12380 %{
12381   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12382   ins_cost(INSN_COST);
12383   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12384 
12385    ins_encode %{
12386      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12387             as_Register($src2$$reg), ext::sxth);
12388    %}
12389   ins_pipe(ialu_reg_reg);
12390 %}
12391 
12392 instruct AddExtL_sxtw(iRegLNoSp dst, iRegL src1, iRegL src2, immI_32 lshift, immI_32 rshift, rFlagsReg cr)
12393 %{
12394   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12395   ins_cost(INSN_COST);
12396   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12397 
12398    ins_encode %{
12399      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12400             as_Register($src2$$reg), ext::sxtw);
12401    %}
12402   ins_pipe(ialu_reg_reg);
12403 %}
12404 
12405 instruct AddExtL_sxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12406 %{
12407   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12408   ins_cost(INSN_COST);
12409   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12410 
12411    ins_encode %{
12412      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12413             as_Register($src2$$reg), ext::sxtb);
12414    %}
12415   ins_pipe(ialu_reg_reg);
12416 %}
12417 
12418 instruct AddExtL_uxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12419 %{
12420   match(Set dst (AddL src1 (URShiftL (LShiftL src2 lshift) rshift)));
12421   ins_cost(INSN_COST);
12422   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12423 
12424    ins_encode %{
12425      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12426             as_Register($src2$$reg), ext::uxtb);
12427    %}
12428   ins_pipe(ialu_reg_reg);
12429 %}
12430 
12431 
12432 instruct AddExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12433 %{
12434   match(Set dst (AddI src1 (AndI src2 mask)));
12435   ins_cost(INSN_COST);
12436   format %{ &quot;addw  $dst, $src1, $src2, uxtb&quot; %}
12437 
12438    ins_encode %{
12439      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12440             as_Register($src2$$reg), ext::uxtb);
12441    %}
12442   ins_pipe(ialu_reg_reg);
12443 %}
12444 
12445 instruct AddExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12446 %{
12447   match(Set dst (AddI src1 (AndI src2 mask)));
12448   ins_cost(INSN_COST);
12449   format %{ &quot;addw  $dst, $src1, $src2, uxth&quot; %}
12450 
12451    ins_encode %{
12452      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12453             as_Register($src2$$reg), ext::uxth);
12454    %}
12455   ins_pipe(ialu_reg_reg);
12456 %}
12457 
12458 instruct AddExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12459 %{
12460   match(Set dst (AddL src1 (AndL src2 mask)));
12461   ins_cost(INSN_COST);
12462   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12463 
12464    ins_encode %{
12465      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12466             as_Register($src2$$reg), ext::uxtb);
12467    %}
12468   ins_pipe(ialu_reg_reg);
12469 %}
12470 
12471 instruct AddExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12472 %{
12473   match(Set dst (AddL src1 (AndL src2 mask)));
12474   ins_cost(INSN_COST);
12475   format %{ &quot;add  $dst, $src1, $src2, uxth&quot; %}
12476 
12477    ins_encode %{
12478      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12479             as_Register($src2$$reg), ext::uxth);
12480    %}
12481   ins_pipe(ialu_reg_reg);
12482 %}
12483 
12484 instruct AddExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12485 %{
12486   match(Set dst (AddL src1 (AndL src2 mask)));
12487   ins_cost(INSN_COST);
12488   format %{ &quot;add  $dst, $src1, $src2, uxtw&quot; %}
12489 
12490    ins_encode %{
12491      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12492             as_Register($src2$$reg), ext::uxtw);
12493    %}
12494   ins_pipe(ialu_reg_reg);
12495 %}
12496 
12497 instruct SubExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12498 %{
12499   match(Set dst (SubI src1 (AndI src2 mask)));
12500   ins_cost(INSN_COST);
12501   format %{ &quot;subw  $dst, $src1, $src2, uxtb&quot; %}
12502 
12503    ins_encode %{
12504      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12505             as_Register($src2$$reg), ext::uxtb);
12506    %}
12507   ins_pipe(ialu_reg_reg);
12508 %}
12509 
12510 instruct SubExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12511 %{
12512   match(Set dst (SubI src1 (AndI src2 mask)));
12513   ins_cost(INSN_COST);
12514   format %{ &quot;subw  $dst, $src1, $src2, uxth&quot; %}
12515 
12516    ins_encode %{
12517      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12518             as_Register($src2$$reg), ext::uxth);
12519    %}
12520   ins_pipe(ialu_reg_reg);
12521 %}
12522 
12523 instruct SubExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12524 %{
12525   match(Set dst (SubL src1 (AndL src2 mask)));
12526   ins_cost(INSN_COST);
12527   format %{ &quot;sub  $dst, $src1, $src2, uxtb&quot; %}
12528 
12529    ins_encode %{
12530      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12531             as_Register($src2$$reg), ext::uxtb);
12532    %}
12533   ins_pipe(ialu_reg_reg);
12534 %}
12535 
12536 instruct SubExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12537 %{
12538   match(Set dst (SubL src1 (AndL src2 mask)));
12539   ins_cost(INSN_COST);
12540   format %{ &quot;sub  $dst, $src1, $src2, uxth&quot; %}
12541 
12542    ins_encode %{
12543      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12544             as_Register($src2$$reg), ext::uxth);
12545    %}
12546   ins_pipe(ialu_reg_reg);
12547 %}
12548 
12549 instruct SubExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12550 %{
12551   match(Set dst (SubL src1 (AndL src2 mask)));
12552   ins_cost(INSN_COST);
12553   format %{ &quot;sub  $dst, $src1, $src2, uxtw&quot; %}
12554 
12555    ins_encode %{
12556      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12557             as_Register($src2$$reg), ext::uxtw);
12558    %}
12559   ins_pipe(ialu_reg_reg);
12560 %}
12561 
12562 
12563 instruct AddExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12564 %{
12565   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12566   ins_cost(1.9 * INSN_COST);
12567   format %{ &quot;add  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12568 
12569    ins_encode %{
12570      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12571             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12572    %}
12573   ins_pipe(ialu_reg_reg_shift);
12574 %}
12575 
12576 instruct AddExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12577 %{
12578   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12579   ins_cost(1.9 * INSN_COST);
12580   format %{ &quot;add  $dst, $src1, $src2, sxth #lshift2&quot; %}
12581 
12582    ins_encode %{
12583      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12584             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12585    %}
12586   ins_pipe(ialu_reg_reg_shift);
12587 %}
12588 
12589 instruct AddExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12590 %{
12591   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12592   ins_cost(1.9 * INSN_COST);
12593   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12594 
12595    ins_encode %{
12596      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12597             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12598    %}
12599   ins_pipe(ialu_reg_reg_shift);
12600 %}
12601 
12602 instruct SubExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12603 %{
12604   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12605   ins_cost(1.9 * INSN_COST);
12606   format %{ &quot;sub  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12607 
12608    ins_encode %{
12609      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12610             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12611    %}
12612   ins_pipe(ialu_reg_reg_shift);
12613 %}
12614 
12615 instruct SubExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12616 %{
12617   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12618   ins_cost(1.9 * INSN_COST);
12619   format %{ &quot;sub  $dst, $src1, $src2, sxth #lshift2&quot; %}
12620 
12621    ins_encode %{
12622      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12623             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12624    %}
12625   ins_pipe(ialu_reg_reg_shift);
12626 %}
12627 
12628 instruct SubExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12629 %{
12630   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12631   ins_cost(1.9 * INSN_COST);
12632   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12633 
12634    ins_encode %{
12635      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12636             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12637    %}
12638   ins_pipe(ialu_reg_reg_shift);
12639 %}
12640 
12641 instruct AddExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12642 %{
12643   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12644   ins_cost(1.9 * INSN_COST);
12645   format %{ &quot;addw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12646 
12647    ins_encode %{
12648      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12649             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12650    %}
12651   ins_pipe(ialu_reg_reg_shift);
12652 %}
12653 
12654 instruct AddExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12655 %{
12656   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12657   ins_cost(1.9 * INSN_COST);
12658   format %{ &quot;addw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12659 
12660    ins_encode %{
12661      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12662             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12663    %}
12664   ins_pipe(ialu_reg_reg_shift);
12665 %}
12666 
12667 instruct SubExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12668 %{
12669   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12670   ins_cost(1.9 * INSN_COST);
12671   format %{ &quot;subw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12672 
12673    ins_encode %{
12674      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12675             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12676    %}
12677   ins_pipe(ialu_reg_reg_shift);
12678 %}
12679 
12680 instruct SubExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12681 %{
12682   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12683   ins_cost(1.9 * INSN_COST);
12684   format %{ &quot;subw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12685 
12686    ins_encode %{
12687      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12688             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12689    %}
12690   ins_pipe(ialu_reg_reg_shift);
12691 %}
12692 
12693 
12694 instruct AddExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12695 %{
12696   match(Set dst (AddL src1 (LShiftL (ConvI2L src2) lshift)));
12697   ins_cost(1.9 * INSN_COST);
12698   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift&quot; %}
12699 
12700    ins_encode %{
12701      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12702             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12703    %}
12704   ins_pipe(ialu_reg_reg_shift);
12705 %};
12706 
12707 instruct SubExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12708 %{
12709   match(Set dst (SubL src1 (LShiftL (ConvI2L src2) lshift)));
12710   ins_cost(1.9 * INSN_COST);
12711   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift&quot; %}
12712 
12713    ins_encode %{
12714      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12715             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12716    %}
12717   ins_pipe(ialu_reg_reg_shift);
12718 %};
12719 
12720 
12721 instruct AddExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12722 %{
12723   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12724   ins_cost(1.9 * INSN_COST);
12725   format %{ &quot;add  $dst, $src1, $src2, uxtb #lshift&quot; %}
12726 
12727    ins_encode %{
12728      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12729             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12730    %}
12731   ins_pipe(ialu_reg_reg_shift);
12732 %}
12733 
12734 instruct AddExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12735 %{
12736   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12737   ins_cost(1.9 * INSN_COST);
12738   format %{ &quot;add  $dst, $src1, $src2, uxth #lshift&quot; %}
12739 
12740    ins_encode %{
12741      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12742             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12743    %}
12744   ins_pipe(ialu_reg_reg_shift);
12745 %}
12746 
12747 instruct AddExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12748 %{
12749   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12750   ins_cost(1.9 * INSN_COST);
12751   format %{ &quot;add  $dst, $src1, $src2, uxtw #lshift&quot; %}
12752 
12753    ins_encode %{
12754      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12755             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12756    %}
12757   ins_pipe(ialu_reg_reg_shift);
12758 %}
12759 
12760 instruct SubExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12761 %{
12762   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12763   ins_cost(1.9 * INSN_COST);
12764   format %{ &quot;sub  $dst, $src1, $src2, uxtb #lshift&quot; %}
12765 
12766    ins_encode %{
12767      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12768             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12769    %}
12770   ins_pipe(ialu_reg_reg_shift);
12771 %}
12772 
12773 instruct SubExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12774 %{
12775   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12776   ins_cost(1.9 * INSN_COST);
12777   format %{ &quot;sub  $dst, $src1, $src2, uxth #lshift&quot; %}
12778 
12779    ins_encode %{
12780      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12781             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12782    %}
12783   ins_pipe(ialu_reg_reg_shift);
12784 %}
12785 
12786 instruct SubExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12787 %{
12788   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12789   ins_cost(1.9 * INSN_COST);
12790   format %{ &quot;sub  $dst, $src1, $src2, uxtw #lshift&quot; %}
12791 
12792    ins_encode %{
12793      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12794             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12795    %}
12796   ins_pipe(ialu_reg_reg_shift);
12797 %}
12798 
12799 instruct AddExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12800 %{
12801   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12802   ins_cost(1.9 * INSN_COST);
12803   format %{ &quot;addw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12804 
12805    ins_encode %{
12806      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12807             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12808    %}
12809   ins_pipe(ialu_reg_reg_shift);
12810 %}
12811 
12812 instruct AddExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12813 %{
12814   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12815   ins_cost(1.9 * INSN_COST);
12816   format %{ &quot;addw  $dst, $src1, $src2, uxth #lshift&quot; %}
12817 
12818    ins_encode %{
12819      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12820             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12821    %}
12822   ins_pipe(ialu_reg_reg_shift);
12823 %}
12824 
12825 instruct SubExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12826 %{
12827   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12828   ins_cost(1.9 * INSN_COST);
12829   format %{ &quot;subw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12830 
12831    ins_encode %{
12832      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12833             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12834    %}
12835   ins_pipe(ialu_reg_reg_shift);
12836 %}
12837 
12838 instruct SubExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12839 %{
12840   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12841   ins_cost(1.9 * INSN_COST);
12842   format %{ &quot;subw  $dst, $src1, $src2, uxth #lshift&quot; %}
12843 
12844    ins_encode %{
12845      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12846             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12847    %}
12848   ins_pipe(ialu_reg_reg_shift);
12849 %}
12850 // END This section of the file is automatically generated. Do not edit --------------
12851 
12852 // ============================================================================
12853 // Floating Point Arithmetic Instructions
12854 
12855 instruct addF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12856   match(Set dst (AddF src1 src2));
12857 
12858   ins_cost(INSN_COST * 5);
12859   format %{ &quot;fadds   $dst, $src1, $src2&quot; %}
12860 
12861   ins_encode %{
12862     __ fadds(as_FloatRegister($dst$$reg),
12863              as_FloatRegister($src1$$reg),
12864              as_FloatRegister($src2$$reg));
12865   %}
12866 
12867   ins_pipe(fp_dop_reg_reg_s);
12868 %}
12869 
12870 instruct addD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12871   match(Set dst (AddD src1 src2));
12872 
12873   ins_cost(INSN_COST * 5);
12874   format %{ &quot;faddd   $dst, $src1, $src2&quot; %}
12875 
12876   ins_encode %{
12877     __ faddd(as_FloatRegister($dst$$reg),
12878              as_FloatRegister($src1$$reg),
12879              as_FloatRegister($src2$$reg));
12880   %}
12881 
12882   ins_pipe(fp_dop_reg_reg_d);
12883 %}
12884 
12885 instruct subF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12886   match(Set dst (SubF src1 src2));
12887 
12888   ins_cost(INSN_COST * 5);
12889   format %{ &quot;fsubs   $dst, $src1, $src2&quot; %}
12890 
12891   ins_encode %{
12892     __ fsubs(as_FloatRegister($dst$$reg),
12893              as_FloatRegister($src1$$reg),
12894              as_FloatRegister($src2$$reg));
12895   %}
12896 
12897   ins_pipe(fp_dop_reg_reg_s);
12898 %}
12899 
12900 instruct subD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12901   match(Set dst (SubD src1 src2));
12902 
12903   ins_cost(INSN_COST * 5);
12904   format %{ &quot;fsubd   $dst, $src1, $src2&quot; %}
12905 
12906   ins_encode %{
12907     __ fsubd(as_FloatRegister($dst$$reg),
12908              as_FloatRegister($src1$$reg),
12909              as_FloatRegister($src2$$reg));
12910   %}
12911 
12912   ins_pipe(fp_dop_reg_reg_d);
12913 %}
12914 
12915 instruct mulF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12916   match(Set dst (MulF src1 src2));
12917 
12918   ins_cost(INSN_COST * 6);
12919   format %{ &quot;fmuls   $dst, $src1, $src2&quot; %}
12920 
12921   ins_encode %{
12922     __ fmuls(as_FloatRegister($dst$$reg),
12923              as_FloatRegister($src1$$reg),
12924              as_FloatRegister($src2$$reg));
12925   %}
12926 
12927   ins_pipe(fp_dop_reg_reg_s);
12928 %}
12929 
12930 instruct mulD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12931   match(Set dst (MulD src1 src2));
12932 
12933   ins_cost(INSN_COST * 6);
12934   format %{ &quot;fmuld   $dst, $src1, $src2&quot; %}
12935 
12936   ins_encode %{
12937     __ fmuld(as_FloatRegister($dst$$reg),
12938              as_FloatRegister($src1$$reg),
12939              as_FloatRegister($src2$$reg));
12940   %}
12941 
12942   ins_pipe(fp_dop_reg_reg_d);
12943 %}
12944 
12945 // src1 * src2 + src3
12946 instruct maddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12947   predicate(UseFMA);
12948   match(Set dst (FmaF src3 (Binary src1 src2)));
12949 
12950   format %{ &quot;fmadds   $dst, $src1, $src2, $src3&quot; %}
12951 
12952   ins_encode %{
12953     __ fmadds(as_FloatRegister($dst$$reg),
12954              as_FloatRegister($src1$$reg),
12955              as_FloatRegister($src2$$reg),
12956              as_FloatRegister($src3$$reg));
12957   %}
12958 
12959   ins_pipe(pipe_class_default);
12960 %}
12961 
12962 // src1 * src2 + src3
12963 instruct maddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
12964   predicate(UseFMA);
12965   match(Set dst (FmaD src3 (Binary src1 src2)));
12966 
12967   format %{ &quot;fmaddd   $dst, $src1, $src2, $src3&quot; %}
12968 
12969   ins_encode %{
12970     __ fmaddd(as_FloatRegister($dst$$reg),
12971              as_FloatRegister($src1$$reg),
12972              as_FloatRegister($src2$$reg),
12973              as_FloatRegister($src3$$reg));
12974   %}
12975 
12976   ins_pipe(pipe_class_default);
12977 %}
12978 
12979 // -src1 * src2 + src3
12980 instruct msubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12981   predicate(UseFMA);
12982   match(Set dst (FmaF src3 (Binary (NegF src1) src2)));
12983   match(Set dst (FmaF src3 (Binary src1 (NegF src2))));
12984 
12985   format %{ &quot;fmsubs   $dst, $src1, $src2, $src3&quot; %}
12986 
12987   ins_encode %{
12988     __ fmsubs(as_FloatRegister($dst$$reg),
12989               as_FloatRegister($src1$$reg),
12990               as_FloatRegister($src2$$reg),
12991               as_FloatRegister($src3$$reg));
12992   %}
12993 
12994   ins_pipe(pipe_class_default);
12995 %}
12996 
12997 // -src1 * src2 + src3
12998 instruct msubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
12999   predicate(UseFMA);
13000   match(Set dst (FmaD src3 (Binary (NegD src1) src2)));
13001   match(Set dst (FmaD src3 (Binary src1 (NegD src2))));
13002 
13003   format %{ &quot;fmsubd   $dst, $src1, $src2, $src3&quot; %}
13004 
13005   ins_encode %{
13006     __ fmsubd(as_FloatRegister($dst$$reg),
13007               as_FloatRegister($src1$$reg),
13008               as_FloatRegister($src2$$reg),
13009               as_FloatRegister($src3$$reg));
13010   %}
13011 
13012   ins_pipe(pipe_class_default);
13013 %}
13014 
13015 // -src1 * src2 - src3
13016 instruct mnaddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
13017   predicate(UseFMA);
13018   match(Set dst (FmaF (NegF src3) (Binary (NegF src1) src2)));
13019   match(Set dst (FmaF (NegF src3) (Binary src1 (NegF src2))));
13020 
13021   format %{ &quot;fnmadds  $dst, $src1, $src2, $src3&quot; %}
13022 
13023   ins_encode %{
13024     __ fnmadds(as_FloatRegister($dst$$reg),
13025                as_FloatRegister($src1$$reg),
13026                as_FloatRegister($src2$$reg),
13027                as_FloatRegister($src3$$reg));
13028   %}
13029 
13030   ins_pipe(pipe_class_default);
13031 %}
13032 
13033 // -src1 * src2 - src3
13034 instruct mnaddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13035   predicate(UseFMA);
13036   match(Set dst (FmaD (NegD src3) (Binary (NegD src1) src2)));
13037   match(Set dst (FmaD (NegD src3) (Binary src1 (NegD src2))));
13038 
13039   format %{ &quot;fnmaddd   $dst, $src1, $src2, $src3&quot; %}
13040 
13041   ins_encode %{
13042     __ fnmaddd(as_FloatRegister($dst$$reg),
13043                as_FloatRegister($src1$$reg),
13044                as_FloatRegister($src2$$reg),
13045                as_FloatRegister($src3$$reg));
13046   %}
13047 
13048   ins_pipe(pipe_class_default);
13049 %}
13050 
13051 // src1 * src2 - src3
13052 instruct mnsubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3, immF0 zero) %{
13053   predicate(UseFMA);
13054   match(Set dst (FmaF (NegF src3) (Binary src1 src2)));
13055 
13056   format %{ &quot;fnmsubs  $dst, $src1, $src2, $src3&quot; %}
13057 
13058   ins_encode %{
13059     __ fnmsubs(as_FloatRegister($dst$$reg),
13060                as_FloatRegister($src1$$reg),
13061                as_FloatRegister($src2$$reg),
13062                as_FloatRegister($src3$$reg));
13063   %}
13064 
13065   ins_pipe(pipe_class_default);
13066 %}
13067 
13068 // src1 * src2 - src3
13069 instruct mnsubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3, immD0 zero) %{
13070   predicate(UseFMA);
13071   match(Set dst (FmaD (NegD src3) (Binary src1 src2)));
13072 
13073   format %{ &quot;fnmsubd   $dst, $src1, $src2, $src3&quot; %}
13074 
13075   ins_encode %{
13076   // n.b. insn name should be fnmsubd
13077     __ fnmsub(as_FloatRegister($dst$$reg),
13078               as_FloatRegister($src1$$reg),
13079               as_FloatRegister($src2$$reg),
13080               as_FloatRegister($src3$$reg));
13081   %}
13082 
13083   ins_pipe(pipe_class_default);
13084 %}
13085 
13086 
13087 // Math.max(FF)F
13088 instruct maxF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13089   match(Set dst (MaxF src1 src2));
13090 
13091   format %{ &quot;fmaxs   $dst, $src1, $src2&quot; %}
13092   ins_encode %{
13093     __ fmaxs(as_FloatRegister($dst$$reg),
13094              as_FloatRegister($src1$$reg),
13095              as_FloatRegister($src2$$reg));
13096   %}
13097 
13098   ins_pipe(fp_dop_reg_reg_s);
13099 %}
13100 
13101 // Math.min(FF)F
13102 instruct minF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13103   match(Set dst (MinF src1 src2));
13104 
13105   format %{ &quot;fmins   $dst, $src1, $src2&quot; %}
13106   ins_encode %{
13107     __ fmins(as_FloatRegister($dst$$reg),
13108              as_FloatRegister($src1$$reg),
13109              as_FloatRegister($src2$$reg));
13110   %}
13111 
13112   ins_pipe(fp_dop_reg_reg_s);
13113 %}
13114 
13115 // Math.max(DD)D
13116 instruct maxD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13117   match(Set dst (MaxD src1 src2));
13118 
13119   format %{ &quot;fmaxd   $dst, $src1, $src2&quot; %}
13120   ins_encode %{
13121     __ fmaxd(as_FloatRegister($dst$$reg),
13122              as_FloatRegister($src1$$reg),
13123              as_FloatRegister($src2$$reg));
13124   %}
13125 
13126   ins_pipe(fp_dop_reg_reg_d);
13127 %}
13128 
13129 // Math.min(DD)D
13130 instruct minD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13131   match(Set dst (MinD src1 src2));
13132 
13133   format %{ &quot;fmind   $dst, $src1, $src2&quot; %}
13134   ins_encode %{
13135     __ fmind(as_FloatRegister($dst$$reg),
13136              as_FloatRegister($src1$$reg),
13137              as_FloatRegister($src2$$reg));
13138   %}
13139 
13140   ins_pipe(fp_dop_reg_reg_d);
13141 %}
13142 
13143 
13144 instruct divF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13145   match(Set dst (DivF src1  src2));
13146 
13147   ins_cost(INSN_COST * 18);
13148   format %{ &quot;fdivs   $dst, $src1, $src2&quot; %}
13149 
13150   ins_encode %{
13151     __ fdivs(as_FloatRegister($dst$$reg),
13152              as_FloatRegister($src1$$reg),
13153              as_FloatRegister($src2$$reg));
13154   %}
13155 
13156   ins_pipe(fp_div_s);
13157 %}
13158 
13159 instruct divD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13160   match(Set dst (DivD src1  src2));
13161 
13162   ins_cost(INSN_COST * 32);
13163   format %{ &quot;fdivd   $dst, $src1, $src2&quot; %}
13164 
13165   ins_encode %{
13166     __ fdivd(as_FloatRegister($dst$$reg),
13167              as_FloatRegister($src1$$reg),
13168              as_FloatRegister($src2$$reg));
13169   %}
13170 
13171   ins_pipe(fp_div_d);
13172 %}
13173 
13174 instruct negF_reg_reg(vRegF dst, vRegF src) %{
13175   match(Set dst (NegF src));
13176 
13177   ins_cost(INSN_COST * 3);
13178   format %{ &quot;fneg   $dst, $src&quot; %}
13179 
13180   ins_encode %{
13181     __ fnegs(as_FloatRegister($dst$$reg),
13182              as_FloatRegister($src$$reg));
13183   %}
13184 
13185   ins_pipe(fp_uop_s);
13186 %}
13187 
13188 instruct negD_reg_reg(vRegD dst, vRegD src) %{
13189   match(Set dst (NegD src));
13190 
13191   ins_cost(INSN_COST * 3);
13192   format %{ &quot;fnegd   $dst, $src&quot; %}
13193 
13194   ins_encode %{
13195     __ fnegd(as_FloatRegister($dst$$reg),
13196              as_FloatRegister($src$$reg));
13197   %}
13198 
13199   ins_pipe(fp_uop_d);
13200 %}
13201 
13202 instruct absI_reg(iRegINoSp dst, iRegIorL2I src, rFlagsReg cr)
13203 %{
13204   match(Set dst (AbsI src));
13205 
13206   effect(KILL cr);
13207   ins_cost(INSN_COST * 2);
13208   format %{ &quot;cmpw  $src, zr\n\t&quot;
13209             &quot;cnegw $dst, $src, Assembler::LT\t# int abs&quot;
13210   %}
13211 
13212   ins_encode %{
13213     __ cmpw(as_Register($src$$reg), zr);
13214     __ cnegw(as_Register($dst$$reg), as_Register($src$$reg), Assembler::LT);
13215   %}
13216   ins_pipe(pipe_class_default);
13217 %}
13218 
13219 instruct absL_reg(iRegLNoSp dst, iRegL src, rFlagsReg cr)
13220 %{
13221   match(Set dst (AbsL src));
13222 
13223   effect(KILL cr);
13224   ins_cost(INSN_COST * 2);
13225   format %{ &quot;cmp  $src, zr\n\t&quot;
13226             &quot;cneg $dst, $src, Assembler::LT\t# long abs&quot;
13227   %}
13228 
13229   ins_encode %{
13230     __ cmp(as_Register($src$$reg), zr);
13231     __ cneg(as_Register($dst$$reg), as_Register($src$$reg), Assembler::LT);
13232   %}
13233   ins_pipe(pipe_class_default);
13234 %}
13235 
13236 instruct absF_reg(vRegF dst, vRegF src) %{
13237   match(Set dst (AbsF src));
13238 
13239   ins_cost(INSN_COST * 3);
13240   format %{ &quot;fabss   $dst, $src&quot; %}
13241   ins_encode %{
13242     __ fabss(as_FloatRegister($dst$$reg),
13243              as_FloatRegister($src$$reg));
13244   %}
13245 
13246   ins_pipe(fp_uop_s);
13247 %}
13248 
13249 instruct absD_reg(vRegD dst, vRegD src) %{
13250   match(Set dst (AbsD src));
13251 
13252   ins_cost(INSN_COST * 3);
13253   format %{ &quot;fabsd   $dst, $src&quot; %}
13254   ins_encode %{
13255     __ fabsd(as_FloatRegister($dst$$reg),
13256              as_FloatRegister($src$$reg));
13257   %}
13258 
13259   ins_pipe(fp_uop_d);
13260 %}
13261 
13262 instruct sqrtD_reg(vRegD dst, vRegD src) %{
13263   match(Set dst (SqrtD src));
13264 
13265   ins_cost(INSN_COST * 50);
13266   format %{ &quot;fsqrtd  $dst, $src&quot; %}
13267   ins_encode %{
13268     __ fsqrtd(as_FloatRegister($dst$$reg),
13269              as_FloatRegister($src$$reg));
13270   %}
13271 
13272   ins_pipe(fp_div_s);
13273 %}
13274 
13275 instruct sqrtF_reg(vRegF dst, vRegF src) %{
13276   match(Set dst (SqrtF src));
13277 
13278   ins_cost(INSN_COST * 50);
13279   format %{ &quot;fsqrts  $dst, $src&quot; %}
13280   ins_encode %{
13281     __ fsqrts(as_FloatRegister($dst$$reg),
13282              as_FloatRegister($src$$reg));
13283   %}
13284 
13285   ins_pipe(fp_div_d);
13286 %}
13287 
13288 // Math.rint, floor, ceil
13289 instruct roundD_reg(vRegD dst, vRegD src, immI rmode) %{
13290   match(Set dst (RoundDoubleMode src rmode));
13291   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
13292   ins_encode %{
13293     switch ($rmode$$constant) {
13294       case RoundDoubleModeNode::rmode_rint:
13295         __ frintnd(as_FloatRegister($dst$$reg),
13296                    as_FloatRegister($src$$reg));
13297         break;
13298       case RoundDoubleModeNode::rmode_floor:
13299         __ frintmd(as_FloatRegister($dst$$reg),
13300                    as_FloatRegister($src$$reg));
13301         break;
13302       case RoundDoubleModeNode::rmode_ceil:
13303         __ frintpd(as_FloatRegister($dst$$reg),
13304                    as_FloatRegister($src$$reg));
13305         break;
13306     }
13307   %}
13308   ins_pipe(fp_uop_d);
13309 %}
13310 
13311 // ============================================================================
13312 // Logical Instructions
13313 
13314 // Integer Logical Instructions
13315 
13316 // And Instructions
13317 
13318 
13319 instruct andI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, rFlagsReg cr) %{
13320   match(Set dst (AndI src1 src2));
13321 
13322   format %{ &quot;andw  $dst, $src1, $src2\t# int&quot; %}
13323 
13324   ins_cost(INSN_COST);
13325   ins_encode %{
13326     __ andw(as_Register($dst$$reg),
13327             as_Register($src1$$reg),
13328             as_Register($src2$$reg));
13329   %}
13330 
13331   ins_pipe(ialu_reg_reg);
13332 %}
13333 
13334 instruct andI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2, rFlagsReg cr) %{
13335   match(Set dst (AndI src1 src2));
13336 
13337   format %{ &quot;andsw  $dst, $src1, $src2\t# int&quot; %}
13338 
13339   ins_cost(INSN_COST);
13340   ins_encode %{
13341     __ andw(as_Register($dst$$reg),
13342             as_Register($src1$$reg),
13343             (unsigned long)($src2$$constant));
13344   %}
13345 
13346   ins_pipe(ialu_reg_imm);
13347 %}
13348 
13349 // Or Instructions
13350 
13351 instruct orI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13352   match(Set dst (OrI src1 src2));
13353 
13354   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13355 
13356   ins_cost(INSN_COST);
13357   ins_encode %{
13358     __ orrw(as_Register($dst$$reg),
13359             as_Register($src1$$reg),
13360             as_Register($src2$$reg));
13361   %}
13362 
13363   ins_pipe(ialu_reg_reg);
13364 %}
13365 
13366 instruct orI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13367   match(Set dst (OrI src1 src2));
13368 
13369   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13370 
13371   ins_cost(INSN_COST);
13372   ins_encode %{
13373     __ orrw(as_Register($dst$$reg),
13374             as_Register($src1$$reg),
13375             (unsigned long)($src2$$constant));
13376   %}
13377 
13378   ins_pipe(ialu_reg_imm);
13379 %}
13380 
13381 // Xor Instructions
13382 
13383 instruct xorI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13384   match(Set dst (XorI src1 src2));
13385 
13386   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13387 
13388   ins_cost(INSN_COST);
13389   ins_encode %{
13390     __ eorw(as_Register($dst$$reg),
13391             as_Register($src1$$reg),
13392             as_Register($src2$$reg));
13393   %}
13394 
13395   ins_pipe(ialu_reg_reg);
13396 %}
13397 
13398 instruct xorI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13399   match(Set dst (XorI src1 src2));
13400 
13401   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13402 
13403   ins_cost(INSN_COST);
13404   ins_encode %{
13405     __ eorw(as_Register($dst$$reg),
13406             as_Register($src1$$reg),
13407             (unsigned long)($src2$$constant));
13408   %}
13409 
13410   ins_pipe(ialu_reg_imm);
13411 %}
13412 
13413 // Long Logical Instructions
13414 // TODO
13415 
13416 instruct andL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr) %{
13417   match(Set dst (AndL src1 src2));
13418 
13419   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13420 
13421   ins_cost(INSN_COST);
13422   ins_encode %{
13423     __ andr(as_Register($dst$$reg),
13424             as_Register($src1$$reg),
13425             as_Register($src2$$reg));
13426   %}
13427 
13428   ins_pipe(ialu_reg_reg);
13429 %}
13430 
13431 instruct andL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2, rFlagsReg cr) %{
13432   match(Set dst (AndL src1 src2));
13433 
13434   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13435 
13436   ins_cost(INSN_COST);
13437   ins_encode %{
13438     __ andr(as_Register($dst$$reg),
13439             as_Register($src1$$reg),
13440             (unsigned long)($src2$$constant));
13441   %}
13442 
13443   ins_pipe(ialu_reg_imm);
13444 %}
13445 
13446 // Or Instructions
13447 
13448 instruct orL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13449   match(Set dst (OrL src1 src2));
13450 
13451   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13452 
13453   ins_cost(INSN_COST);
13454   ins_encode %{
13455     __ orr(as_Register($dst$$reg),
13456            as_Register($src1$$reg),
13457            as_Register($src2$$reg));
13458   %}
13459 
13460   ins_pipe(ialu_reg_reg);
13461 %}
13462 
13463 instruct orL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13464   match(Set dst (OrL src1 src2));
13465 
13466   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13467 
13468   ins_cost(INSN_COST);
13469   ins_encode %{
13470     __ orr(as_Register($dst$$reg),
13471            as_Register($src1$$reg),
13472            (unsigned long)($src2$$constant));
13473   %}
13474 
13475   ins_pipe(ialu_reg_imm);
13476 %}
13477 
13478 // Xor Instructions
13479 
13480 instruct xorL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13481   match(Set dst (XorL src1 src2));
13482 
13483   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13484 
13485   ins_cost(INSN_COST);
13486   ins_encode %{
13487     __ eor(as_Register($dst$$reg),
13488            as_Register($src1$$reg),
13489            as_Register($src2$$reg));
13490   %}
13491 
13492   ins_pipe(ialu_reg_reg);
13493 %}
13494 
13495 instruct xorL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13496   match(Set dst (XorL src1 src2));
13497 
13498   ins_cost(INSN_COST);
13499   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13500 
13501   ins_encode %{
13502     __ eor(as_Register($dst$$reg),
13503            as_Register($src1$$reg),
13504            (unsigned long)($src2$$constant));
13505   %}
13506 
13507   ins_pipe(ialu_reg_imm);
13508 %}
13509 
13510 instruct convI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src)
13511 %{
13512   match(Set dst (ConvI2L src));
13513 
13514   ins_cost(INSN_COST);
13515   format %{ &quot;sxtw  $dst, $src\t# i2l&quot; %}
13516   ins_encode %{
13517     __ sbfm($dst$$Register, $src$$Register, 0, 31);
13518   %}
13519   ins_pipe(ialu_reg_shift);
13520 %}
13521 
13522 // this pattern occurs in bigmath arithmetic
13523 instruct convUI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src, immL_32bits mask)
13524 %{
13525   match(Set dst (AndL (ConvI2L src) mask));
13526 
13527   ins_cost(INSN_COST);
13528   format %{ &quot;ubfm  $dst, $src, 0, 31\t# ui2l&quot; %}
13529   ins_encode %{
13530     __ ubfm($dst$$Register, $src$$Register, 0, 31);
13531   %}
13532 
13533   ins_pipe(ialu_reg_shift);
13534 %}
13535 
13536 instruct convL2I_reg(iRegINoSp dst, iRegL src) %{
13537   match(Set dst (ConvL2I src));
13538 
13539   ins_cost(INSN_COST);
13540   format %{ &quot;movw  $dst, $src \t// l2i&quot; %}
13541 
13542   ins_encode %{
13543     __ movw(as_Register($dst$$reg), as_Register($src$$reg));
13544   %}
13545 
13546   ins_pipe(ialu_reg);
13547 %}
13548 
13549 instruct convI2B(iRegINoSp dst, iRegIorL2I src, rFlagsReg cr)
13550 %{
13551   match(Set dst (Conv2B src));
13552   effect(KILL cr);
13553 
13554   format %{
13555     &quot;cmpw $src, zr\n\t&quot;
13556     &quot;cset $dst, ne&quot;
13557   %}
13558 
13559   ins_encode %{
13560     __ cmpw(as_Register($src$$reg), zr);
13561     __ cset(as_Register($dst$$reg), Assembler::NE);
13562   %}
13563 
13564   ins_pipe(ialu_reg);
13565 %}
13566 
13567 instruct convP2B(iRegINoSp dst, iRegP src, rFlagsReg cr)
13568 %{
13569   match(Set dst (Conv2B src));
13570   effect(KILL cr);
13571 
13572   format %{
13573     &quot;cmp  $src, zr\n\t&quot;
13574     &quot;cset $dst, ne&quot;
13575   %}
13576 
13577   ins_encode %{
13578     __ cmp(as_Register($src$$reg), zr);
13579     __ cset(as_Register($dst$$reg), Assembler::NE);
13580   %}
13581 
13582   ins_pipe(ialu_reg);
13583 %}
13584 
13585 instruct convD2F_reg(vRegF dst, vRegD src) %{
13586   match(Set dst (ConvD2F src));
13587 
13588   ins_cost(INSN_COST * 5);
13589   format %{ &quot;fcvtd  $dst, $src \t// d2f&quot; %}
13590 
13591   ins_encode %{
13592     __ fcvtd(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13593   %}
13594 
13595   ins_pipe(fp_d2f);
13596 %}
13597 
13598 instruct convF2D_reg(vRegD dst, vRegF src) %{
13599   match(Set dst (ConvF2D src));
13600 
13601   ins_cost(INSN_COST * 5);
13602   format %{ &quot;fcvts  $dst, $src \t// f2d&quot; %}
13603 
13604   ins_encode %{
13605     __ fcvts(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13606   %}
13607 
13608   ins_pipe(fp_f2d);
13609 %}
13610 
13611 instruct convF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13612   match(Set dst (ConvF2I src));
13613 
13614   ins_cost(INSN_COST * 5);
13615   format %{ &quot;fcvtzsw  $dst, $src \t// f2i&quot; %}
13616 
13617   ins_encode %{
13618     __ fcvtzsw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13619   %}
13620 
13621   ins_pipe(fp_f2i);
13622 %}
13623 
13624 instruct convF2L_reg_reg(iRegLNoSp dst, vRegF src) %{
13625   match(Set dst (ConvF2L src));
13626 
13627   ins_cost(INSN_COST * 5);
13628   format %{ &quot;fcvtzs  $dst, $src \t// f2l&quot; %}
13629 
13630   ins_encode %{
13631     __ fcvtzs(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13632   %}
13633 
13634   ins_pipe(fp_f2l);
13635 %}
13636 
13637 instruct convI2F_reg_reg(vRegF dst, iRegIorL2I src) %{
13638   match(Set dst (ConvI2F src));
13639 
13640   ins_cost(INSN_COST * 5);
13641   format %{ &quot;scvtfws  $dst, $src \t// i2f&quot; %}
13642 
13643   ins_encode %{
13644     __ scvtfws(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13645   %}
13646 
13647   ins_pipe(fp_i2f);
13648 %}
13649 
13650 instruct convL2F_reg_reg(vRegF dst, iRegL src) %{
13651   match(Set dst (ConvL2F src));
13652 
13653   ins_cost(INSN_COST * 5);
13654   format %{ &quot;scvtfs  $dst, $src \t// l2f&quot; %}
13655 
13656   ins_encode %{
13657     __ scvtfs(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13658   %}
13659 
13660   ins_pipe(fp_l2f);
13661 %}
13662 
13663 instruct convD2I_reg_reg(iRegINoSp dst, vRegD src) %{
13664   match(Set dst (ConvD2I src));
13665 
13666   ins_cost(INSN_COST * 5);
13667   format %{ &quot;fcvtzdw  $dst, $src \t// d2i&quot; %}
13668 
13669   ins_encode %{
13670     __ fcvtzdw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13671   %}
13672 
13673   ins_pipe(fp_d2i);
13674 %}
13675 
13676 instruct convD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13677   match(Set dst (ConvD2L src));
13678 
13679   ins_cost(INSN_COST * 5);
13680   format %{ &quot;fcvtzd  $dst, $src \t// d2l&quot; %}
13681 
13682   ins_encode %{
13683     __ fcvtzd(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13684   %}
13685 
13686   ins_pipe(fp_d2l);
13687 %}
13688 
13689 instruct convI2D_reg_reg(vRegD dst, iRegIorL2I src) %{
13690   match(Set dst (ConvI2D src));
13691 
13692   ins_cost(INSN_COST * 5);
13693   format %{ &quot;scvtfwd  $dst, $src \t// i2d&quot; %}
13694 
13695   ins_encode %{
13696     __ scvtfwd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13697   %}
13698 
13699   ins_pipe(fp_i2d);
13700 %}
13701 
13702 instruct convL2D_reg_reg(vRegD dst, iRegL src) %{
13703   match(Set dst (ConvL2D src));
13704 
13705   ins_cost(INSN_COST * 5);
13706   format %{ &quot;scvtfd  $dst, $src \t// l2d&quot; %}
13707 
13708   ins_encode %{
13709     __ scvtfd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13710   %}
13711 
13712   ins_pipe(fp_l2d);
13713 %}
13714 
13715 // stack &lt;-&gt; reg and reg &lt;-&gt; reg shuffles with no conversion
13716 
13717 instruct MoveF2I_stack_reg(iRegINoSp dst, stackSlotF src) %{
13718 
13719   match(Set dst (MoveF2I src));
13720 
13721   effect(DEF dst, USE src);
13722 
13723   ins_cost(4 * INSN_COST);
13724 
13725   format %{ &quot;ldrw $dst, $src\t# MoveF2I_stack_reg&quot; %}
13726 
13727   ins_encode %{
13728     __ ldrw($dst$$Register, Address(sp, $src$$disp));
13729   %}
13730 
13731   ins_pipe(iload_reg_reg);
13732 
13733 %}
13734 
13735 instruct MoveI2F_stack_reg(vRegF dst, stackSlotI src) %{
13736 
13737   match(Set dst (MoveI2F src));
13738 
13739   effect(DEF dst, USE src);
13740 
13741   ins_cost(4 * INSN_COST);
13742 
13743   format %{ &quot;ldrs $dst, $src\t# MoveI2F_stack_reg&quot; %}
13744 
13745   ins_encode %{
13746     __ ldrs(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13747   %}
13748 
13749   ins_pipe(pipe_class_memory);
13750 
13751 %}
13752 
13753 instruct MoveD2L_stack_reg(iRegLNoSp dst, stackSlotD src) %{
13754 
13755   match(Set dst (MoveD2L src));
13756 
13757   effect(DEF dst, USE src);
13758 
13759   ins_cost(4 * INSN_COST);
13760 
13761   format %{ &quot;ldr $dst, $src\t# MoveD2L_stack_reg&quot; %}
13762 
13763   ins_encode %{
13764     __ ldr($dst$$Register, Address(sp, $src$$disp));
13765   %}
13766 
13767   ins_pipe(iload_reg_reg);
13768 
13769 %}
13770 
13771 instruct MoveL2D_stack_reg(vRegD dst, stackSlotL src) %{
13772 
13773   match(Set dst (MoveL2D src));
13774 
13775   effect(DEF dst, USE src);
13776 
13777   ins_cost(4 * INSN_COST);
13778 
13779   format %{ &quot;ldrd $dst, $src\t# MoveL2D_stack_reg&quot; %}
13780 
13781   ins_encode %{
13782     __ ldrd(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13783   %}
13784 
13785   ins_pipe(pipe_class_memory);
13786 
13787 %}
13788 
13789 instruct MoveF2I_reg_stack(stackSlotI dst, vRegF src) %{
13790 
13791   match(Set dst (MoveF2I src));
13792 
13793   effect(DEF dst, USE src);
13794 
13795   ins_cost(INSN_COST);
13796 
13797   format %{ &quot;strs $src, $dst\t# MoveF2I_reg_stack&quot; %}
13798 
13799   ins_encode %{
13800     __ strs(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13801   %}
13802 
13803   ins_pipe(pipe_class_memory);
13804 
13805 %}
13806 
13807 instruct MoveI2F_reg_stack(stackSlotF dst, iRegI src) %{
13808 
13809   match(Set dst (MoveI2F src));
13810 
13811   effect(DEF dst, USE src);
13812 
13813   ins_cost(INSN_COST);
13814 
13815   format %{ &quot;strw $src, $dst\t# MoveI2F_reg_stack&quot; %}
13816 
13817   ins_encode %{
13818     __ strw($src$$Register, Address(sp, $dst$$disp));
13819   %}
13820 
13821   ins_pipe(istore_reg_reg);
13822 
13823 %}
13824 
13825 instruct MoveD2L_reg_stack(stackSlotL dst, vRegD src) %{
13826 
13827   match(Set dst (MoveD2L src));
13828 
13829   effect(DEF dst, USE src);
13830 
13831   ins_cost(INSN_COST);
13832 
13833   format %{ &quot;strd $dst, $src\t# MoveD2L_reg_stack&quot; %}
13834 
13835   ins_encode %{
13836     __ strd(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13837   %}
13838 
13839   ins_pipe(pipe_class_memory);
13840 
13841 %}
13842 
13843 instruct MoveL2D_reg_stack(stackSlotD dst, iRegL src) %{
13844 
13845   match(Set dst (MoveL2D src));
13846 
13847   effect(DEF dst, USE src);
13848 
13849   ins_cost(INSN_COST);
13850 
13851   format %{ &quot;str $src, $dst\t# MoveL2D_reg_stack&quot; %}
13852 
13853   ins_encode %{
13854     __ str($src$$Register, Address(sp, $dst$$disp));
13855   %}
13856 
13857   ins_pipe(istore_reg_reg);
13858 
13859 %}
13860 
13861 instruct MoveF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13862 
13863   match(Set dst (MoveF2I src));
13864 
13865   effect(DEF dst, USE src);
13866 
13867   ins_cost(INSN_COST);
13868 
13869   format %{ &quot;fmovs $dst, $src\t# MoveF2I_reg_reg&quot; %}
13870 
13871   ins_encode %{
13872     __ fmovs($dst$$Register, as_FloatRegister($src$$reg));
13873   %}
13874 
13875   ins_pipe(fp_f2i);
13876 
13877 %}
13878 
13879 instruct MoveI2F_reg_reg(vRegF dst, iRegI src) %{
13880 
13881   match(Set dst (MoveI2F src));
13882 
13883   effect(DEF dst, USE src);
13884 
13885   ins_cost(INSN_COST);
13886 
13887   format %{ &quot;fmovs $dst, $src\t# MoveI2F_reg_reg&quot; %}
13888 
13889   ins_encode %{
13890     __ fmovs(as_FloatRegister($dst$$reg), $src$$Register);
13891   %}
13892 
13893   ins_pipe(fp_i2f);
13894 
13895 %}
13896 
13897 instruct MoveD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13898 
13899   match(Set dst (MoveD2L src));
13900 
13901   effect(DEF dst, USE src);
13902 
13903   ins_cost(INSN_COST);
13904 
13905   format %{ &quot;fmovd $dst, $src\t# MoveD2L_reg_reg&quot; %}
13906 
13907   ins_encode %{
13908     __ fmovd($dst$$Register, as_FloatRegister($src$$reg));
13909   %}
13910 
13911   ins_pipe(fp_d2l);
13912 
13913 %}
13914 
13915 instruct MoveL2D_reg_reg(vRegD dst, iRegL src) %{
13916 
13917   match(Set dst (MoveL2D src));
13918 
13919   effect(DEF dst, USE src);
13920 
13921   ins_cost(INSN_COST);
13922 
13923   format %{ &quot;fmovd $dst, $src\t# MoveL2D_reg_reg&quot; %}
13924 
13925   ins_encode %{
13926     __ fmovd(as_FloatRegister($dst$$reg), $src$$Register);
13927   %}
13928 
13929   ins_pipe(fp_l2d);
13930 
13931 %}
13932 
13933 // ============================================================================
13934 // clearing of an array
13935 
<a name="10" id="anc10"></a><span class="line-modified">13936 instruct clearArray_reg_reg(iRegL_R11 cnt, iRegP_R10 base, iRegL val, Universe dummy, rFlagsReg cr)</span>
13937 %{
<a name="11" id="anc11"></a><span class="line-modified">13938   match(Set dummy (ClearArray (Binary cnt base) val));</span>
13939   effect(USE_KILL cnt, USE_KILL base, KILL cr);
13940 
13941   ins_cost(4 * INSN_COST);
13942   format %{ &quot;ClearArray $cnt, $base&quot; %}
13943 
13944   ins_encode %{
13945     __ zero_words($base$$Register, $cnt$$Register);
13946   %}
13947 
13948   ins_pipe(pipe_class_memory);
13949 %}
13950 
13951 instruct clearArray_imm_reg(immL cnt, iRegP_R10 base, Universe dummy, rFlagsReg cr)
13952 %{
13953   predicate((uint64_t)n-&gt;in(2)-&gt;get_long()
13954             &lt; (uint64_t)(BlockZeroingLowLimit &gt;&gt; LogBytesPerWord));
13955   match(Set dummy (ClearArray cnt base));
13956   effect(USE_KILL base);
13957 
13958   ins_cost(4 * INSN_COST);
13959   format %{ &quot;ClearArray $cnt, $base&quot; %}
13960 
13961   ins_encode %{
13962     __ zero_words($base$$Register, (uint64_t)$cnt$$constant);
13963   %}
13964 
13965   ins_pipe(pipe_class_memory);
13966 %}
13967 
13968 // ============================================================================
13969 // Overflow Math Instructions
13970 
13971 instruct overflowAddI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
13972 %{
13973   match(Set cr (OverflowAddI op1 op2));
13974 
13975   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13976   ins_cost(INSN_COST);
13977   ins_encode %{
13978     __ cmnw($op1$$Register, $op2$$Register);
13979   %}
13980 
13981   ins_pipe(icmp_reg_reg);
13982 %}
13983 
13984 instruct overflowAddI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
13985 %{
13986   match(Set cr (OverflowAddI op1 op2));
13987 
13988   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13989   ins_cost(INSN_COST);
13990   ins_encode %{
13991     __ cmnw($op1$$Register, $op2$$constant);
13992   %}
13993 
13994   ins_pipe(icmp_reg_imm);
13995 %}
13996 
13997 instruct overflowAddL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
13998 %{
13999   match(Set cr (OverflowAddL op1 op2));
14000 
14001   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
14002   ins_cost(INSN_COST);
14003   ins_encode %{
14004     __ cmn($op1$$Register, $op2$$Register);
14005   %}
14006 
14007   ins_pipe(icmp_reg_reg);
14008 %}
14009 
14010 instruct overflowAddL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
14011 %{
14012   match(Set cr (OverflowAddL op1 op2));
14013 
14014   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
14015   ins_cost(INSN_COST);
14016   ins_encode %{
14017     __ cmn($op1$$Register, $op2$$constant);
14018   %}
14019 
14020   ins_pipe(icmp_reg_imm);
14021 %}
14022 
14023 instruct overflowSubI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14024 %{
14025   match(Set cr (OverflowSubI op1 op2));
14026 
14027   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
14028   ins_cost(INSN_COST);
14029   ins_encode %{
14030     __ cmpw($op1$$Register, $op2$$Register);
14031   %}
14032 
14033   ins_pipe(icmp_reg_reg);
14034 %}
14035 
14036 instruct overflowSubI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
14037 %{
14038   match(Set cr (OverflowSubI op1 op2));
14039 
14040   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
14041   ins_cost(INSN_COST);
14042   ins_encode %{
14043     __ cmpw($op1$$Register, $op2$$constant);
14044   %}
14045 
14046   ins_pipe(icmp_reg_imm);
14047 %}
14048 
14049 instruct overflowSubL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14050 %{
14051   match(Set cr (OverflowSubL op1 op2));
14052 
14053   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
14054   ins_cost(INSN_COST);
14055   ins_encode %{
14056     __ cmp($op1$$Register, $op2$$Register);
14057   %}
14058 
14059   ins_pipe(icmp_reg_reg);
14060 %}
14061 
14062 instruct overflowSubL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
14063 %{
14064   match(Set cr (OverflowSubL op1 op2));
14065 
14066   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
14067   ins_cost(INSN_COST);
14068   ins_encode %{
14069     __ subs(zr, $op1$$Register, $op2$$constant);
14070   %}
14071 
14072   ins_pipe(icmp_reg_imm);
14073 %}
14074 
14075 instruct overflowNegI_reg(rFlagsReg cr, immI0 zero, iRegIorL2I op1)
14076 %{
14077   match(Set cr (OverflowSubI zero op1));
14078 
14079   format %{ &quot;cmpw  zr, $op1\t# overflow check int&quot; %}
14080   ins_cost(INSN_COST);
14081   ins_encode %{
14082     __ cmpw(zr, $op1$$Register);
14083   %}
14084 
14085   ins_pipe(icmp_reg_imm);
14086 %}
14087 
14088 instruct overflowNegL_reg(rFlagsReg cr, immI0 zero, iRegL op1)
14089 %{
14090   match(Set cr (OverflowSubL zero op1));
14091 
14092   format %{ &quot;cmp   zr, $op1\t# overflow check long&quot; %}
14093   ins_cost(INSN_COST);
14094   ins_encode %{
14095     __ cmp(zr, $op1$$Register);
14096   %}
14097 
14098   ins_pipe(icmp_reg_imm);
14099 %}
14100 
14101 instruct overflowMulI_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14102 %{
14103   match(Set cr (OverflowMulI op1 op2));
14104 
14105   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14106             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14107             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14108             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14109             &quot;cmpw  rscratch1, #1&quot; %}
14110   ins_cost(5 * INSN_COST);
14111   ins_encode %{
14112     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14113     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14114     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14115     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14116     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14117   %}
14118 
14119   ins_pipe(pipe_slow);
14120 %}
14121 
14122 instruct overflowMulI_reg_branch(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, label labl, rFlagsReg cr)
14123 %{
14124   match(If cmp (OverflowMulI op1 op2));
14125   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14126             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14127   effect(USE labl, KILL cr);
14128 
14129   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14130             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14131             &quot;b$cmp   $labl&quot; %}
14132   ins_cost(3 * INSN_COST); // Branch is rare so treat as INSN_COST
14133   ins_encode %{
14134     Label* L = $labl$$label;
14135     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14136     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14137     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14138     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14139   %}
14140 
14141   ins_pipe(pipe_serial);
14142 %}
14143 
14144 instruct overflowMulL_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14145 %{
14146   match(Set cr (OverflowMulL op1 op2));
14147 
14148   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14149             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14150             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14151             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14152             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14153             &quot;cmpw  rscratch1, #1&quot; %}
14154   ins_cost(6 * INSN_COST);
14155   ins_encode %{
14156     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14157     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14158     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14159     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14160     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14161     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14162   %}
14163 
14164   ins_pipe(pipe_slow);
14165 %}
14166 
14167 instruct overflowMulL_reg_branch(cmpOp cmp, iRegL op1, iRegL op2, label labl, rFlagsReg cr)
14168 %{
14169   match(If cmp (OverflowMulL op1 op2));
14170   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14171             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14172   effect(USE labl, KILL cr);
14173 
14174   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14175             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14176             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14177             &quot;b$cmp $labl&quot; %}
14178   ins_cost(4 * INSN_COST); // Branch is rare so treat as INSN_COST
14179   ins_encode %{
14180     Label* L = $labl$$label;
14181     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14182     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14183     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14184     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14185     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14186   %}
14187 
14188   ins_pipe(pipe_serial);
14189 %}
14190 
14191 // ============================================================================
14192 // Compare Instructions
14193 
14194 instruct compI_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
14195 %{
14196   match(Set cr (CmpI op1 op2));
14197 
14198   effect(DEF cr, USE op1, USE op2);
14199 
14200   ins_cost(INSN_COST);
14201   format %{ &quot;cmpw  $op1, $op2&quot; %}
14202 
14203   ins_encode(aarch64_enc_cmpw(op1, op2));
14204 
14205   ins_pipe(icmp_reg_reg);
14206 %}
14207 
14208 instruct compI_reg_immI0(rFlagsReg cr, iRegI op1, immI0 zero)
14209 %{
14210   match(Set cr (CmpI op1 zero));
14211 
14212   effect(DEF cr, USE op1);
14213 
14214   ins_cost(INSN_COST);
14215   format %{ &quot;cmpw $op1, 0&quot; %}
14216 
14217   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14218 
14219   ins_pipe(icmp_reg_imm);
14220 %}
14221 
14222 instruct compI_reg_immIAddSub(rFlagsReg cr, iRegI op1, immIAddSub op2)
14223 %{
14224   match(Set cr (CmpI op1 op2));
14225 
14226   effect(DEF cr, USE op1);
14227 
14228   ins_cost(INSN_COST);
14229   format %{ &quot;cmpw  $op1, $op2&quot; %}
14230 
14231   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14232 
14233   ins_pipe(icmp_reg_imm);
14234 %}
14235 
14236 instruct compI_reg_immI(rFlagsReg cr, iRegI op1, immI op2)
14237 %{
14238   match(Set cr (CmpI op1 op2));
14239 
14240   effect(DEF cr, USE op1);
14241 
14242   ins_cost(INSN_COST * 2);
14243   format %{ &quot;cmpw  $op1, $op2&quot; %}
14244 
14245   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14246 
14247   ins_pipe(icmp_reg_imm);
14248 %}
14249 
14250 // Unsigned compare Instructions; really, same as signed compare
14251 // except it should only be used to feed an If or a CMovI which takes a
14252 // cmpOpU.
14253 
14254 instruct compU_reg_reg(rFlagsRegU cr, iRegI op1, iRegI op2)
14255 %{
14256   match(Set cr (CmpU op1 op2));
14257 
14258   effect(DEF cr, USE op1, USE op2);
14259 
14260   ins_cost(INSN_COST);
14261   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14262 
14263   ins_encode(aarch64_enc_cmpw(op1, op2));
14264 
14265   ins_pipe(icmp_reg_reg);
14266 %}
14267 
14268 instruct compU_reg_immI0(rFlagsRegU cr, iRegI op1, immI0 zero)
14269 %{
14270   match(Set cr (CmpU op1 zero));
14271 
14272   effect(DEF cr, USE op1);
14273 
14274   ins_cost(INSN_COST);
14275   format %{ &quot;cmpw $op1, #0\t# unsigned&quot; %}
14276 
14277   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14278 
14279   ins_pipe(icmp_reg_imm);
14280 %}
14281 
14282 instruct compU_reg_immIAddSub(rFlagsRegU cr, iRegI op1, immIAddSub op2)
14283 %{
14284   match(Set cr (CmpU op1 op2));
14285 
14286   effect(DEF cr, USE op1);
14287 
14288   ins_cost(INSN_COST);
14289   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14290 
14291   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14292 
14293   ins_pipe(icmp_reg_imm);
14294 %}
14295 
14296 instruct compU_reg_immI(rFlagsRegU cr, iRegI op1, immI op2)
14297 %{
14298   match(Set cr (CmpU op1 op2));
14299 
14300   effect(DEF cr, USE op1);
14301 
14302   ins_cost(INSN_COST * 2);
14303   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14304 
14305   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14306 
14307   ins_pipe(icmp_reg_imm);
14308 %}
14309 
14310 instruct compL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14311 %{
14312   match(Set cr (CmpL op1 op2));
14313 
14314   effect(DEF cr, USE op1, USE op2);
14315 
14316   ins_cost(INSN_COST);
14317   format %{ &quot;cmp  $op1, $op2&quot; %}
14318 
14319   ins_encode(aarch64_enc_cmp(op1, op2));
14320 
14321   ins_pipe(icmp_reg_reg);
14322 %}
14323 
14324 instruct compL_reg_immL0(rFlagsReg cr, iRegL op1, immL0 zero)
14325 %{
14326   match(Set cr (CmpL op1 zero));
14327 
14328   effect(DEF cr, USE op1);
14329 
14330   ins_cost(INSN_COST);
14331   format %{ &quot;tst  $op1&quot; %}
14332 
14333   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14334 
14335   ins_pipe(icmp_reg_imm);
14336 %}
14337 
14338 instruct compL_reg_immLAddSub(rFlagsReg cr, iRegL op1, immLAddSub op2)
14339 %{
14340   match(Set cr (CmpL op1 op2));
14341 
14342   effect(DEF cr, USE op1);
14343 
14344   ins_cost(INSN_COST);
14345   format %{ &quot;cmp  $op1, $op2&quot; %}
14346 
14347   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14348 
14349   ins_pipe(icmp_reg_imm);
14350 %}
14351 
14352 instruct compL_reg_immL(rFlagsReg cr, iRegL op1, immL op2)
14353 %{
14354   match(Set cr (CmpL op1 op2));
14355 
14356   effect(DEF cr, USE op1);
14357 
14358   ins_cost(INSN_COST * 2);
14359   format %{ &quot;cmp  $op1, $op2&quot; %}
14360 
14361   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14362 
14363   ins_pipe(icmp_reg_imm);
14364 %}
14365 
14366 instruct compUL_reg_reg(rFlagsRegU cr, iRegL op1, iRegL op2)
14367 %{
14368   match(Set cr (CmpUL op1 op2));
14369 
14370   effect(DEF cr, USE op1, USE op2);
14371 
14372   ins_cost(INSN_COST);
14373   format %{ &quot;cmp  $op1, $op2&quot; %}
14374 
14375   ins_encode(aarch64_enc_cmp(op1, op2));
14376 
14377   ins_pipe(icmp_reg_reg);
14378 %}
14379 
14380 instruct compUL_reg_immL0(rFlagsRegU cr, iRegL op1, immL0 zero)
14381 %{
14382   match(Set cr (CmpUL op1 zero));
14383 
14384   effect(DEF cr, USE op1);
14385 
14386   ins_cost(INSN_COST);
14387   format %{ &quot;tst  $op1&quot; %}
14388 
14389   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14390 
14391   ins_pipe(icmp_reg_imm);
14392 %}
14393 
14394 instruct compUL_reg_immLAddSub(rFlagsRegU cr, iRegL op1, immLAddSub op2)
14395 %{
14396   match(Set cr (CmpUL op1 op2));
14397 
14398   effect(DEF cr, USE op1);
14399 
14400   ins_cost(INSN_COST);
14401   format %{ &quot;cmp  $op1, $op2&quot; %}
14402 
14403   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14404 
14405   ins_pipe(icmp_reg_imm);
14406 %}
14407 
14408 instruct compUL_reg_immL(rFlagsRegU cr, iRegL op1, immL op2)
14409 %{
14410   match(Set cr (CmpUL op1 op2));
14411 
14412   effect(DEF cr, USE op1);
14413 
14414   ins_cost(INSN_COST * 2);
14415   format %{ &quot;cmp  $op1, $op2&quot; %}
14416 
14417   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14418 
14419   ins_pipe(icmp_reg_imm);
14420 %}
14421 
14422 instruct compP_reg_reg(rFlagsRegU cr, iRegP op1, iRegP op2)
14423 %{
14424   match(Set cr (CmpP op1 op2));
14425 
14426   effect(DEF cr, USE op1, USE op2);
14427 
14428   ins_cost(INSN_COST);
14429   format %{ &quot;cmp  $op1, $op2\t // ptr&quot; %}
14430 
14431   ins_encode(aarch64_enc_cmpp(op1, op2));
14432 
14433   ins_pipe(icmp_reg_reg);
14434 %}
14435 
14436 instruct compN_reg_reg(rFlagsRegU cr, iRegN op1, iRegN op2)
14437 %{
14438   match(Set cr (CmpN op1 op2));
14439 
14440   effect(DEF cr, USE op1, USE op2);
14441 
14442   ins_cost(INSN_COST);
14443   format %{ &quot;cmp  $op1, $op2\t // compressed ptr&quot; %}
14444 
14445   ins_encode(aarch64_enc_cmpn(op1, op2));
14446 
14447   ins_pipe(icmp_reg_reg);
14448 %}
14449 
14450 instruct testP_reg(rFlagsRegU cr, iRegP op1, immP0 zero)
14451 %{
14452   match(Set cr (CmpP op1 zero));
14453 
14454   effect(DEF cr, USE op1, USE zero);
14455 
14456   ins_cost(INSN_COST);
14457   format %{ &quot;cmp  $op1, 0\t // ptr&quot; %}
14458 
14459   ins_encode(aarch64_enc_testp(op1));
14460 
14461   ins_pipe(icmp_reg_imm);
14462 %}
14463 
14464 instruct testN_reg(rFlagsRegU cr, iRegN op1, immN0 zero)
14465 %{
14466   match(Set cr (CmpN op1 zero));
14467 
14468   effect(DEF cr, USE op1, USE zero);
14469 
14470   ins_cost(INSN_COST);
14471   format %{ &quot;cmp  $op1, 0\t // compressed ptr&quot; %}
14472 
14473   ins_encode(aarch64_enc_testn(op1));
14474 
14475   ins_pipe(icmp_reg_imm);
14476 %}
14477 
14478 // FP comparisons
14479 //
14480 // n.b. CmpF/CmpD set a normal flags reg which then gets compared
14481 // using normal cmpOp. See declaration of rFlagsReg for details.
14482 
14483 instruct compF_reg_reg(rFlagsReg cr, vRegF src1, vRegF src2)
14484 %{
14485   match(Set cr (CmpF src1 src2));
14486 
14487   ins_cost(3 * INSN_COST);
14488   format %{ &quot;fcmps $src1, $src2&quot; %}
14489 
14490   ins_encode %{
14491     __ fcmps(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14492   %}
14493 
14494   ins_pipe(pipe_class_compare);
14495 %}
14496 
14497 instruct compF_reg_zero(rFlagsReg cr, vRegF src1, immF0 src2)
14498 %{
14499   match(Set cr (CmpF src1 src2));
14500 
14501   ins_cost(3 * INSN_COST);
14502   format %{ &quot;fcmps $src1, 0.0&quot; %}
14503 
14504   ins_encode %{
14505     __ fcmps(as_FloatRegister($src1$$reg), 0.0);
14506   %}
14507 
14508   ins_pipe(pipe_class_compare);
14509 %}
14510 // FROM HERE
14511 
14512 instruct compD_reg_reg(rFlagsReg cr, vRegD src1, vRegD src2)
14513 %{
14514   match(Set cr (CmpD src1 src2));
14515 
14516   ins_cost(3 * INSN_COST);
14517   format %{ &quot;fcmpd $src1, $src2&quot; %}
14518 
14519   ins_encode %{
14520     __ fcmpd(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14521   %}
14522 
14523   ins_pipe(pipe_class_compare);
14524 %}
14525 
14526 instruct compD_reg_zero(rFlagsReg cr, vRegD src1, immD0 src2)
14527 %{
14528   match(Set cr (CmpD src1 src2));
14529 
14530   ins_cost(3 * INSN_COST);
14531   format %{ &quot;fcmpd $src1, 0.0&quot; %}
14532 
14533   ins_encode %{
14534     __ fcmpd(as_FloatRegister($src1$$reg), 0.0);
14535   %}
14536 
14537   ins_pipe(pipe_class_compare);
14538 %}
14539 
14540 instruct compF3_reg_reg(iRegINoSp dst, vRegF src1, vRegF src2, rFlagsReg cr)
14541 %{
14542   match(Set dst (CmpF3 src1 src2));
14543   effect(KILL cr);
14544 
14545   ins_cost(5 * INSN_COST);
14546   format %{ &quot;fcmps $src1, $src2\n\t&quot;
14547             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14548             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14549   %}
14550 
14551   ins_encode %{
14552     Label done;
14553     FloatRegister s1 = as_FloatRegister($src1$$reg);
14554     FloatRegister s2 = as_FloatRegister($src2$$reg);
14555     Register d = as_Register($dst$$reg);
14556     __ fcmps(s1, s2);
14557     // installs 0 if EQ else -1
14558     __ csinvw(d, zr, zr, Assembler::EQ);
14559     // keeps -1 if less or unordered else installs 1
14560     __ csnegw(d, d, d, Assembler::LT);
14561     __ bind(done);
14562   %}
14563 
14564   ins_pipe(pipe_class_default);
14565 
14566 %}
14567 
14568 instruct compD3_reg_reg(iRegINoSp dst, vRegD src1, vRegD src2, rFlagsReg cr)
14569 %{
14570   match(Set dst (CmpD3 src1 src2));
14571   effect(KILL cr);
14572 
14573   ins_cost(5 * INSN_COST);
14574   format %{ &quot;fcmpd $src1, $src2\n\t&quot;
14575             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14576             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14577   %}
14578 
14579   ins_encode %{
14580     Label done;
14581     FloatRegister s1 = as_FloatRegister($src1$$reg);
14582     FloatRegister s2 = as_FloatRegister($src2$$reg);
14583     Register d = as_Register($dst$$reg);
14584     __ fcmpd(s1, s2);
14585     // installs 0 if EQ else -1
14586     __ csinvw(d, zr, zr, Assembler::EQ);
14587     // keeps -1 if less or unordered else installs 1
14588     __ csnegw(d, d, d, Assembler::LT);
14589     __ bind(done);
14590   %}
14591   ins_pipe(pipe_class_default);
14592 
14593 %}
14594 
14595 instruct compF3_reg_immF0(iRegINoSp dst, vRegF src1, immF0 zero, rFlagsReg cr)
14596 %{
14597   match(Set dst (CmpF3 src1 zero));
14598   effect(KILL cr);
14599 
14600   ins_cost(5 * INSN_COST);
14601   format %{ &quot;fcmps $src1, 0.0\n\t&quot;
14602             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14603             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14604   %}
14605 
14606   ins_encode %{
14607     Label done;
14608     FloatRegister s1 = as_FloatRegister($src1$$reg);
14609     Register d = as_Register($dst$$reg);
14610     __ fcmps(s1, 0.0);
14611     // installs 0 if EQ else -1
14612     __ csinvw(d, zr, zr, Assembler::EQ);
14613     // keeps -1 if less or unordered else installs 1
14614     __ csnegw(d, d, d, Assembler::LT);
14615     __ bind(done);
14616   %}
14617 
14618   ins_pipe(pipe_class_default);
14619 
14620 %}
14621 
14622 instruct compD3_reg_immD0(iRegINoSp dst, vRegD src1, immD0 zero, rFlagsReg cr)
14623 %{
14624   match(Set dst (CmpD3 src1 zero));
14625   effect(KILL cr);
14626 
14627   ins_cost(5 * INSN_COST);
14628   format %{ &quot;fcmpd $src1, 0.0\n\t&quot;
14629             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14630             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14631   %}
14632 
14633   ins_encode %{
14634     Label done;
14635     FloatRegister s1 = as_FloatRegister($src1$$reg);
14636     Register d = as_Register($dst$$reg);
14637     __ fcmpd(s1, 0.0);
14638     // installs 0 if EQ else -1
14639     __ csinvw(d, zr, zr, Assembler::EQ);
14640     // keeps -1 if less or unordered else installs 1
14641     __ csnegw(d, d, d, Assembler::LT);
14642     __ bind(done);
14643   %}
14644   ins_pipe(pipe_class_default);
14645 
14646 %}
14647 
14648 instruct cmpLTMask_reg_reg(iRegINoSp dst, iRegIorL2I p, iRegIorL2I q, rFlagsReg cr)
14649 %{
14650   match(Set dst (CmpLTMask p q));
14651   effect(KILL cr);
14652 
14653   ins_cost(3 * INSN_COST);
14654 
14655   format %{ &quot;cmpw $p, $q\t# cmpLTMask\n\t&quot;
14656             &quot;csetw $dst, lt\n\t&quot;
14657             &quot;subw $dst, zr, $dst&quot;
14658   %}
14659 
14660   ins_encode %{
14661     __ cmpw(as_Register($p$$reg), as_Register($q$$reg));
14662     __ csetw(as_Register($dst$$reg), Assembler::LT);
14663     __ subw(as_Register($dst$$reg), zr, as_Register($dst$$reg));
14664   %}
14665 
14666   ins_pipe(ialu_reg_reg);
14667 %}
14668 
14669 instruct cmpLTMask_reg_zero(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr)
14670 %{
14671   match(Set dst (CmpLTMask src zero));
14672   effect(KILL cr);
14673 
14674   ins_cost(INSN_COST);
14675 
14676   format %{ &quot;asrw $dst, $src, #31\t# cmpLTMask0&quot; %}
14677 
14678   ins_encode %{
14679     __ asrw(as_Register($dst$$reg), as_Register($src$$reg), 31);
14680   %}
14681 
14682   ins_pipe(ialu_reg_shift);
14683 %}
14684 
14685 // ============================================================================
14686 // Max and Min
14687 
14688 instruct cmovI_reg_reg_lt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14689 %{
14690   effect( DEF dst, USE src1, USE src2, USE cr );
14691 
14692   ins_cost(INSN_COST * 2);
14693   format %{ &quot;cselw $dst, $src1, $src2 lt\t&quot;  %}
14694 
14695   ins_encode %{
14696     __ cselw(as_Register($dst$$reg),
14697              as_Register($src1$$reg),
14698              as_Register($src2$$reg),
14699              Assembler::LT);
14700   %}
14701 
14702   ins_pipe(icond_reg_reg);
14703 %}
14704 
14705 instruct minI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14706 %{
14707   match(Set dst (MinI src1 src2));
14708   ins_cost(INSN_COST * 3);
14709 
14710   expand %{
14711     rFlagsReg cr;
14712     compI_reg_reg(cr, src1, src2);
14713     cmovI_reg_reg_lt(dst, src1, src2, cr);
14714   %}
14715 
14716 %}
14717 // FROM HERE
14718 
14719 instruct cmovI_reg_reg_gt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14720 %{
14721   effect( DEF dst, USE src1, USE src2, USE cr );
14722 
14723   ins_cost(INSN_COST * 2);
14724   format %{ &quot;cselw $dst, $src1, $src2 gt\t&quot;  %}
14725 
14726   ins_encode %{
14727     __ cselw(as_Register($dst$$reg),
14728              as_Register($src1$$reg),
14729              as_Register($src2$$reg),
14730              Assembler::GT);
14731   %}
14732 
14733   ins_pipe(icond_reg_reg);
14734 %}
14735 
14736 instruct maxI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14737 %{
14738   match(Set dst (MaxI src1 src2));
14739   ins_cost(INSN_COST * 3);
14740   expand %{
14741     rFlagsReg cr;
14742     compI_reg_reg(cr, src1, src2);
14743     cmovI_reg_reg_gt(dst, src1, src2, cr);
14744   %}
14745 %}
14746 
14747 // ============================================================================
14748 // Branch Instructions
14749 
14750 // Direct Branch.
14751 instruct branch(label lbl)
14752 %{
14753   match(Goto);
14754 
14755   effect(USE lbl);
14756 
14757   ins_cost(BRANCH_COST);
14758   format %{ &quot;b  $lbl&quot; %}
14759 
14760   ins_encode(aarch64_enc_b(lbl));
14761 
14762   ins_pipe(pipe_branch);
14763 %}
14764 
14765 // Conditional Near Branch
14766 instruct branchCon(cmpOp cmp, rFlagsReg cr, label lbl)
14767 %{
14768   // Same match rule as `branchConFar&#39;.
14769   match(If cmp cr);
14770 
14771   effect(USE lbl);
14772 
14773   ins_cost(BRANCH_COST);
14774   // If set to 1 this indicates that the current instruction is a
14775   // short variant of a long branch. This avoids using this
14776   // instruction in first-pass matching. It will then only be used in
14777   // the `Shorten_branches&#39; pass.
14778   // ins_short_branch(1);
14779   format %{ &quot;b$cmp  $lbl&quot; %}
14780 
14781   ins_encode(aarch64_enc_br_con(cmp, lbl));
14782 
14783   ins_pipe(pipe_branch_cond);
14784 %}
14785 
14786 // Conditional Near Branch Unsigned
14787 instruct branchConU(cmpOpU cmp, rFlagsRegU cr, label lbl)
14788 %{
14789   // Same match rule as `branchConFar&#39;.
14790   match(If cmp cr);
14791 
14792   effect(USE lbl);
14793 
14794   ins_cost(BRANCH_COST);
14795   // If set to 1 this indicates that the current instruction is a
14796   // short variant of a long branch. This avoids using this
14797   // instruction in first-pass matching. It will then only be used in
14798   // the `Shorten_branches&#39; pass.
14799   // ins_short_branch(1);
14800   format %{ &quot;b$cmp  $lbl\t# unsigned&quot; %}
14801 
14802   ins_encode(aarch64_enc_br_conU(cmp, lbl));
14803 
14804   ins_pipe(pipe_branch_cond);
14805 %}
14806 
14807 // Make use of CBZ and CBNZ.  These instructions, as well as being
14808 // shorter than (cmp; branch), have the additional benefit of not
14809 // killing the flags.
14810 
14811 instruct cmpI_imm0_branch(cmpOpEqNe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsReg cr) %{
14812   match(If cmp (CmpI op1 op2));
14813   effect(USE labl);
14814 
14815   ins_cost(BRANCH_COST);
14816   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14817   ins_encode %{
14818     Label* L = $labl$$label;
14819     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14820     if (cond == Assembler::EQ)
14821       __ cbzw($op1$$Register, *L);
14822     else
14823       __ cbnzw($op1$$Register, *L);
14824   %}
14825   ins_pipe(pipe_cmp_branch);
14826 %}
14827 
14828 instruct cmpL_imm0_branch(cmpOpEqNe cmp, iRegL op1, immL0 op2, label labl, rFlagsReg cr) %{
14829   match(If cmp (CmpL op1 op2));
14830   effect(USE labl);
14831 
14832   ins_cost(BRANCH_COST);
14833   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14834   ins_encode %{
14835     Label* L = $labl$$label;
14836     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14837     if (cond == Assembler::EQ)
14838       __ cbz($op1$$Register, *L);
14839     else
14840       __ cbnz($op1$$Register, *L);
14841   %}
14842   ins_pipe(pipe_cmp_branch);
14843 %}
14844 
14845 instruct cmpP_imm0_branch(cmpOpEqNe cmp, iRegP op1, immP0 op2, label labl, rFlagsReg cr) %{
14846   match(If cmp (CmpP op1 op2));
14847   effect(USE labl);
14848 
14849   ins_cost(BRANCH_COST);
14850   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14851   ins_encode %{
14852     Label* L = $labl$$label;
14853     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14854     if (cond == Assembler::EQ)
14855       __ cbz($op1$$Register, *L);
14856     else
14857       __ cbnz($op1$$Register, *L);
14858   %}
14859   ins_pipe(pipe_cmp_branch);
14860 %}
14861 
14862 instruct cmpN_imm0_branch(cmpOpEqNe cmp, iRegN op1, immN0 op2, label labl, rFlagsReg cr) %{
14863   match(If cmp (CmpN op1 op2));
14864   effect(USE labl);
14865 
14866   ins_cost(BRANCH_COST);
14867   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14868   ins_encode %{
14869     Label* L = $labl$$label;
14870     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14871     if (cond == Assembler::EQ)
14872       __ cbzw($op1$$Register, *L);
14873     else
14874       __ cbnzw($op1$$Register, *L);
14875   %}
14876   ins_pipe(pipe_cmp_branch);
14877 %}
14878 
14879 instruct cmpP_narrowOop_imm0_branch(cmpOpEqNe cmp, iRegN oop, immP0 zero, label labl, rFlagsReg cr) %{
14880   match(If cmp (CmpP (DecodeN oop) zero));
14881   effect(USE labl);
14882 
14883   ins_cost(BRANCH_COST);
14884   format %{ &quot;cb$cmp   $oop, $labl&quot; %}
14885   ins_encode %{
14886     Label* L = $labl$$label;
14887     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14888     if (cond == Assembler::EQ)
14889       __ cbzw($oop$$Register, *L);
14890     else
14891       __ cbnzw($oop$$Register, *L);
14892   %}
14893   ins_pipe(pipe_cmp_branch);
14894 %}
14895 
14896 instruct cmpUI_imm0_branch(cmpOpUEqNeLtGe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsRegU cr) %{
14897   match(If cmp (CmpU op1 op2));
14898   effect(USE labl);
14899 
14900   ins_cost(BRANCH_COST);
14901   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14902   ins_encode %{
14903     Label* L = $labl$$label;
14904     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14905     if (cond == Assembler::EQ || cond == Assembler::LS)
14906       __ cbzw($op1$$Register, *L);
14907     else
14908       __ cbnzw($op1$$Register, *L);
14909   %}
14910   ins_pipe(pipe_cmp_branch);
14911 %}
14912 
14913 instruct cmpUL_imm0_branch(cmpOpUEqNeLtGe cmp, iRegL op1, immL0 op2, label labl, rFlagsRegU cr) %{
14914   match(If cmp (CmpUL op1 op2));
14915   effect(USE labl);
14916 
14917   ins_cost(BRANCH_COST);
14918   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14919   ins_encode %{
14920     Label* L = $labl$$label;
14921     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14922     if (cond == Assembler::EQ || cond == Assembler::LS)
14923       __ cbz($op1$$Register, *L);
14924     else
14925       __ cbnz($op1$$Register, *L);
14926   %}
14927   ins_pipe(pipe_cmp_branch);
14928 %}
14929 
14930 // Test bit and Branch
14931 
14932 // Patterns for short (&lt; 32KiB) variants
14933 instruct cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14934   match(If cmp (CmpL op1 op2));
14935   effect(USE labl);
14936 
14937   ins_cost(BRANCH_COST);
14938   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14939   ins_encode %{
14940     Label* L = $labl$$label;
14941     Assembler::Condition cond =
14942       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14943     __ tbr(cond, $op1$$Register, 63, *L);
14944   %}
14945   ins_pipe(pipe_cmp_branch);
14946   ins_short_branch(1);
14947 %}
14948 
14949 instruct cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14950   match(If cmp (CmpI op1 op2));
14951   effect(USE labl);
14952 
14953   ins_cost(BRANCH_COST);
14954   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14955   ins_encode %{
14956     Label* L = $labl$$label;
14957     Assembler::Condition cond =
14958       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14959     __ tbr(cond, $op1$$Register, 31, *L);
14960   %}
14961   ins_pipe(pipe_cmp_branch);
14962   ins_short_branch(1);
14963 %}
14964 
14965 instruct cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14966   match(If cmp (CmpL (AndL op1 op2) op3));
14967   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14968   effect(USE labl);
14969 
14970   ins_cost(BRANCH_COST);
14971   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14972   ins_encode %{
14973     Label* L = $labl$$label;
14974     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14975     int bit = exact_log2_long($op2$$constant);
14976     __ tbr(cond, $op1$$Register, bit, *L);
14977   %}
14978   ins_pipe(pipe_cmp_branch);
14979   ins_short_branch(1);
14980 %}
14981 
14982 instruct cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14983   match(If cmp (CmpI (AndI op1 op2) op3));
14984   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
14985   effect(USE labl);
14986 
14987   ins_cost(BRANCH_COST);
14988   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14989   ins_encode %{
14990     Label* L = $labl$$label;
14991     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14992     int bit = exact_log2((juint)$op2$$constant);
14993     __ tbr(cond, $op1$$Register, bit, *L);
14994   %}
14995   ins_pipe(pipe_cmp_branch);
14996   ins_short_branch(1);
14997 %}
14998 
14999 // And far variants
15000 instruct far_cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
15001   match(If cmp (CmpL op1 op2));
15002   effect(USE labl);
15003 
15004   ins_cost(BRANCH_COST);
15005   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
15006   ins_encode %{
15007     Label* L = $labl$$label;
15008     Assembler::Condition cond =
15009       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
15010     __ tbr(cond, $op1$$Register, 63, *L, /*far*/true);
15011   %}
15012   ins_pipe(pipe_cmp_branch);
15013 %}
15014 
15015 instruct far_cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
15016   match(If cmp (CmpI op1 op2));
15017   effect(USE labl);
15018 
15019   ins_cost(BRANCH_COST);
15020   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
15021   ins_encode %{
15022     Label* L = $labl$$label;
15023     Assembler::Condition cond =
15024       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
15025     __ tbr(cond, $op1$$Register, 31, *L, /*far*/true);
15026   %}
15027   ins_pipe(pipe_cmp_branch);
15028 %}
15029 
15030 instruct far_cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
15031   match(If cmp (CmpL (AndL op1 op2) op3));
15032   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15033   effect(USE labl);
15034 
15035   ins_cost(BRANCH_COST);
15036   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15037   ins_encode %{
15038     Label* L = $labl$$label;
15039     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15040     int bit = exact_log2_long($op2$$constant);
15041     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15042   %}
15043   ins_pipe(pipe_cmp_branch);
15044 %}
15045 
15046 instruct far_cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
15047   match(If cmp (CmpI (AndI op1 op2) op3));
15048   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15049   effect(USE labl);
15050 
15051   ins_cost(BRANCH_COST);
15052   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15053   ins_encode %{
15054     Label* L = $labl$$label;
15055     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15056     int bit = exact_log2((juint)$op2$$constant);
15057     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15058   %}
15059   ins_pipe(pipe_cmp_branch);
15060 %}
15061 
15062 // Test bits
15063 
15064 instruct cmpL_and(cmpOp cmp, iRegL op1, immL op2, immL0 op3, rFlagsReg cr) %{
15065   match(Set cr (CmpL (AndL op1 op2) op3));
15066   predicate(Assembler::operand_valid_for_logical_immediate
15067             (/*is_32*/false, n-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15068 
15069   ins_cost(INSN_COST);
15070   format %{ &quot;tst $op1, $op2 # long&quot; %}
15071   ins_encode %{
15072     __ tst($op1$$Register, $op2$$constant);
15073   %}
15074   ins_pipe(ialu_reg_reg);
15075 %}
15076 
15077 instruct cmpI_and(cmpOp cmp, iRegIorL2I op1, immI op2, immI0 op3, rFlagsReg cr) %{
15078   match(Set cr (CmpI (AndI op1 op2) op3));
15079   predicate(Assembler::operand_valid_for_logical_immediate
15080             (/*is_32*/true, n-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15081 
15082   ins_cost(INSN_COST);
15083   format %{ &quot;tst $op1, $op2 # int&quot; %}
15084   ins_encode %{
15085     __ tstw($op1$$Register, $op2$$constant);
15086   %}
15087   ins_pipe(ialu_reg_reg);
15088 %}
15089 
15090 instruct cmpL_and_reg(cmpOp cmp, iRegL op1, iRegL op2, immL0 op3, rFlagsReg cr) %{
15091   match(Set cr (CmpL (AndL op1 op2) op3));
15092 
15093   ins_cost(INSN_COST);
15094   format %{ &quot;tst $op1, $op2 # long&quot; %}
15095   ins_encode %{
15096     __ tst($op1$$Register, $op2$$Register);
15097   %}
15098   ins_pipe(ialu_reg_reg);
15099 %}
15100 
15101 instruct cmpI_and_reg(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, immI0 op3, rFlagsReg cr) %{
15102   match(Set cr (CmpI (AndI op1 op2) op3));
15103 
15104   ins_cost(INSN_COST);
15105   format %{ &quot;tstw $op1, $op2 # int&quot; %}
15106   ins_encode %{
15107     __ tstw($op1$$Register, $op2$$Register);
15108   %}
15109   ins_pipe(ialu_reg_reg);
15110 %}
15111 
15112 
15113 // Conditional Far Branch
15114 // Conditional Far Branch Unsigned
15115 // TODO: fixme
15116 
15117 // counted loop end branch near
15118 instruct branchLoopEnd(cmpOp cmp, rFlagsReg cr, label lbl)
15119 %{
15120   match(CountedLoopEnd cmp cr);
15121 
15122   effect(USE lbl);
15123 
15124   ins_cost(BRANCH_COST);
15125   // short variant.
15126   // ins_short_branch(1);
15127   format %{ &quot;b$cmp $lbl \t// counted loop end&quot; %}
15128 
15129   ins_encode(aarch64_enc_br_con(cmp, lbl));
15130 
15131   ins_pipe(pipe_branch);
15132 %}
15133 
15134 // counted loop end branch near Unsigned
15135 instruct branchLoopEndU(cmpOpU cmp, rFlagsRegU cr, label lbl)
15136 %{
15137   match(CountedLoopEnd cmp cr);
15138 
15139   effect(USE lbl);
15140 
15141   ins_cost(BRANCH_COST);
15142   // short variant.
15143   // ins_short_branch(1);
15144   format %{ &quot;b$cmp $lbl \t// counted loop end unsigned&quot; %}
15145 
15146   ins_encode(aarch64_enc_br_conU(cmp, lbl));
15147 
15148   ins_pipe(pipe_branch);
15149 %}
15150 
15151 // counted loop end branch far
15152 // counted loop end branch far unsigned
15153 // TODO: fixme
15154 
15155 // ============================================================================
15156 // inlined locking and unlocking
15157 
15158 instruct cmpFastLock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15159 %{
15160   match(Set cr (FastLock object box));
15161   effect(TEMP tmp, TEMP tmp2);
15162 
15163   // TODO
15164   // identify correct cost
15165   ins_cost(5 * INSN_COST);
15166   format %{ &quot;fastlock $object,$box\t! kills $tmp,$tmp2&quot; %}
15167 
15168   ins_encode(aarch64_enc_fast_lock(object, box, tmp, tmp2));
15169 
15170   ins_pipe(pipe_serial);
15171 %}
15172 
15173 instruct cmpFastUnlock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15174 %{
15175   match(Set cr (FastUnlock object box));
15176   effect(TEMP tmp, TEMP tmp2);
15177 
15178   ins_cost(5 * INSN_COST);
15179   format %{ &quot;fastunlock $object,$box\t! kills $tmp, $tmp2&quot; %}
15180 
15181   ins_encode(aarch64_enc_fast_unlock(object, box, tmp, tmp2));
15182 
15183   ins_pipe(pipe_serial);
15184 %}
15185 
15186 
15187 // ============================================================================
15188 // Safepoint Instructions
15189 
15190 // TODO
15191 // provide a near and far version of this code
15192 
15193 instruct safePoint(rFlagsReg cr, iRegP poll)
15194 %{
15195   match(SafePoint poll);
15196   effect(KILL cr);
15197 
15198   format %{
15199     &quot;ldrw zr, [$poll]\t# Safepoint: poll for GC&quot;
15200   %}
15201   ins_encode %{
15202     __ read_polling_page(as_Register($poll$$reg), relocInfo::poll_type);
15203   %}
15204   ins_pipe(pipe_serial); // ins_pipe(iload_reg_mem);
15205 %}
15206 
15207 
15208 // ============================================================================
15209 // Procedure Call/Return Instructions
15210 
15211 // Call Java Static Instruction
15212 
15213 instruct CallStaticJavaDirect(method meth)
15214 %{
15215   match(CallStaticJava);
15216 
15217   effect(USE meth);
15218 
15219   ins_cost(CALL_COST);
15220 
15221   format %{ &quot;call,static $meth \t// ==&gt; &quot; %}
15222 
15223   ins_encode( aarch64_enc_java_static_call(meth),
15224               aarch64_enc_call_epilog );
15225 
15226   ins_pipe(pipe_class_call);
15227 %}
15228 
15229 // TO HERE
15230 
15231 // Call Java Dynamic Instruction
15232 instruct CallDynamicJavaDirect(method meth)
15233 %{
15234   match(CallDynamicJava);
15235 
15236   effect(USE meth);
15237 
15238   ins_cost(CALL_COST);
15239 
15240   format %{ &quot;CALL,dynamic $meth \t// ==&gt; &quot; %}
15241 
15242   ins_encode( aarch64_enc_java_dynamic_call(meth),
15243                aarch64_enc_call_epilog );
15244 
15245   ins_pipe(pipe_class_call);
15246 %}
15247 
15248 // Call Runtime Instruction
15249 
15250 instruct CallRuntimeDirect(method meth)
15251 %{
15252   match(CallRuntime);
15253 
15254   effect(USE meth);
15255 
15256   ins_cost(CALL_COST);
15257 
15258   format %{ &quot;CALL, runtime $meth&quot; %}
15259 
15260   ins_encode( aarch64_enc_java_to_runtime(meth) );
15261 
15262   ins_pipe(pipe_class_call);
15263 %}
15264 
15265 // Call Runtime Instruction
15266 
15267 instruct CallLeafDirect(method meth)
15268 %{
15269   match(CallLeaf);
15270 
15271   effect(USE meth);
15272 
15273   ins_cost(CALL_COST);
15274 
15275   format %{ &quot;CALL, runtime leaf $meth&quot; %}
15276 
15277   ins_encode( aarch64_enc_java_to_runtime(meth) );
15278 
15279   ins_pipe(pipe_class_call);
15280 %}
15281 
15282 // Call Runtime Instruction
15283 
15284 instruct CallLeafNoFPDirect(method meth)
15285 %{
15286   match(CallLeafNoFP);
15287 
15288   effect(USE meth);
15289 
15290   ins_cost(CALL_COST);
15291 
15292   format %{ &quot;CALL, runtime leaf nofp $meth&quot; %}
15293 
15294   ins_encode( aarch64_enc_java_to_runtime(meth) );
15295 
15296   ins_pipe(pipe_class_call);
15297 %}
15298 
15299 // Tail Call; Jump from runtime stub to Java code.
15300 // Also known as an &#39;interprocedural jump&#39;.
15301 // Target of jump will eventually return to caller.
15302 // TailJump below removes the return address.
15303 instruct TailCalljmpInd(iRegPNoSp jump_target, inline_cache_RegP method_oop)
15304 %{
15305   match(TailCall jump_target method_oop);
15306 
15307   ins_cost(CALL_COST);
15308 
15309   format %{ &quot;br $jump_target\t# $method_oop holds method oop&quot; %}
15310 
15311   ins_encode(aarch64_enc_tail_call(jump_target));
15312 
15313   ins_pipe(pipe_class_call);
15314 %}
15315 
15316 instruct TailjmpInd(iRegPNoSp jump_target, iRegP_R0 ex_oop)
15317 %{
15318   match(TailJump jump_target ex_oop);
15319 
15320   ins_cost(CALL_COST);
15321 
15322   format %{ &quot;br $jump_target\t# $ex_oop holds exception oop&quot; %}
15323 
15324   ins_encode(aarch64_enc_tail_jmp(jump_target));
15325 
15326   ins_pipe(pipe_class_call);
15327 %}
15328 
15329 // Create exception oop: created by stack-crawling runtime code.
15330 // Created exception is now available to this handler, and is setup
15331 // just prior to jumping to this handler. No code emitted.
15332 // TODO check
15333 // should ex_oop be in r0? intel uses rax, ppc cannot use r0 so uses rarg1
15334 instruct CreateException(iRegP_R0 ex_oop)
15335 %{
15336   match(Set ex_oop (CreateEx));
15337 
15338   format %{ &quot; -- \t// exception oop; no code emitted&quot; %}
15339 
15340   size(0);
15341 
15342   ins_encode( /*empty*/ );
15343 
15344   ins_pipe(pipe_class_empty);
15345 %}
15346 
15347 // Rethrow exception: The exception oop will come in the first
15348 // argument position. Then JUMP (not call) to the rethrow stub code.
15349 instruct RethrowException() %{
15350   match(Rethrow);
15351   ins_cost(CALL_COST);
15352 
15353   format %{ &quot;b rethrow_stub&quot; %}
15354 
15355   ins_encode( aarch64_enc_rethrow() );
15356 
15357   ins_pipe(pipe_class_call);
15358 %}
15359 
15360 
15361 // Return Instruction
15362 // epilog node loads ret address into lr as part of frame pop
15363 instruct Ret()
15364 %{
15365   match(Return);
15366 
15367   format %{ &quot;ret\t// return register&quot; %}
15368 
15369   ins_encode( aarch64_enc_ret() );
15370 
15371   ins_pipe(pipe_branch);
15372 %}
15373 
15374 // Die now.
15375 instruct ShouldNotReachHere() %{
15376   match(Halt);
15377 
15378   ins_cost(CALL_COST);
15379   format %{ &quot;ShouldNotReachHere&quot; %}
15380 
15381   ins_encode %{
15382     if (is_reachable()) {
15383       __ stop(_halt_reason);
15384     }
15385   %}
15386 
15387   ins_pipe(pipe_class_default);
15388 %}
15389 
15390 // ============================================================================
15391 // Partial Subtype Check
15392 //
15393 // superklass array for an instance of the superklass.  Set a hidden
15394 // internal cache on a hit (cache is checked with exposed code in
15395 // gen_subtype_check()).  Return NZ for a miss or zero for a hit.  The
15396 // encoding ALSO sets flags.
15397 
15398 instruct partialSubtypeCheck(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, rFlagsReg cr)
15399 %{
15400   match(Set result (PartialSubtypeCheck sub super));
15401   effect(KILL cr, KILL temp);
15402 
15403   ins_cost(1100);  // slightly larger than the next version
15404   format %{ &quot;partialSubtypeCheck $result, $sub, $super&quot; %}
15405 
15406   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15407 
15408   opcode(0x1); // Force zero of result reg on hit
15409 
15410   ins_pipe(pipe_class_memory);
15411 %}
15412 
15413 instruct partialSubtypeCheckVsZero(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, immP0 zero, rFlagsReg cr)
15414 %{
15415   match(Set cr (CmpP (PartialSubtypeCheck sub super) zero));
15416   effect(KILL temp, KILL result);
15417 
15418   ins_cost(1100);  // slightly larger than the next version
15419   format %{ &quot;partialSubtypeCheck $result, $sub, $super == 0&quot; %}
15420 
15421   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15422 
15423   opcode(0x0); // Don&#39;t zero result reg on hit
15424 
15425   ins_pipe(pipe_class_memory);
15426 %}
15427 
15428 instruct string_compareU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15429                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15430 %{
15431   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15432   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15433   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15434 
15435   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15436   ins_encode %{
15437     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15438     __ string_compare($str1$$Register, $str2$$Register,
15439                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15440                       $tmp1$$Register, $tmp2$$Register,
15441                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::UU);
15442   %}
15443   ins_pipe(pipe_class_memory);
15444 %}
15445 
15446 instruct string_compareL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15447                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15448 %{
15449   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15450   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15451   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15452 
15453   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15454   ins_encode %{
15455     __ string_compare($str1$$Register, $str2$$Register,
15456                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15457                       $tmp1$$Register, $tmp2$$Register,
15458                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::LL);
15459   %}
15460   ins_pipe(pipe_class_memory);
15461 %}
15462 
15463 instruct string_compareUL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15464                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15465                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15466 %{
15467   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15468   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15469   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15470          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15471 
15472   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15473   ins_encode %{
15474     __ string_compare($str1$$Register, $str2$$Register,
15475                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15476                       $tmp1$$Register, $tmp2$$Register,
15477                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15478                       $vtmp3$$FloatRegister, StrIntrinsicNode::UL);
15479   %}
15480   ins_pipe(pipe_class_memory);
15481 %}
15482 
15483 instruct string_compareLU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15484                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15485                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15486 %{
15487   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LU);
15488   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15489   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15490          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15491 
15492   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15493   ins_encode %{
15494     __ string_compare($str1$$Register, $str2$$Register,
15495                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15496                       $tmp1$$Register, $tmp2$$Register,
15497                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15498                       $vtmp3$$FloatRegister,StrIntrinsicNode::LU);
15499   %}
15500   ins_pipe(pipe_class_memory);
15501 %}
15502 
15503 instruct string_indexofUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15504        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15505        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15506 %{
15507   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15508   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15509   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15510          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15511   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UU)&quot; %}
15512 
15513   ins_encode %{
15514     __ string_indexof($str1$$Register, $str2$$Register,
15515                       $cnt1$$Register, $cnt2$$Register,
15516                       $tmp1$$Register, $tmp2$$Register,
15517                       $tmp3$$Register, $tmp4$$Register,
15518                       $tmp5$$Register, $tmp6$$Register,
15519                       -1, $result$$Register, StrIntrinsicNode::UU);
15520   %}
15521   ins_pipe(pipe_class_memory);
15522 %}
15523 
15524 instruct string_indexofLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15525        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15526        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15527 %{
15528   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15529   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15530   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15531          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15532   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (LL)&quot; %}
15533 
15534   ins_encode %{
15535     __ string_indexof($str1$$Register, $str2$$Register,
15536                       $cnt1$$Register, $cnt2$$Register,
15537                       $tmp1$$Register, $tmp2$$Register,
15538                       $tmp3$$Register, $tmp4$$Register,
15539                       $tmp5$$Register, $tmp6$$Register,
15540                       -1, $result$$Register, StrIntrinsicNode::LL);
15541   %}
15542   ins_pipe(pipe_class_memory);
15543 %}
15544 
15545 instruct string_indexofUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15546        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15547        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15548 %{
15549   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15550   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15551   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15552          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15553   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UL)&quot; %}
15554 
15555   ins_encode %{
15556     __ string_indexof($str1$$Register, $str2$$Register,
15557                       $cnt1$$Register, $cnt2$$Register,
15558                       $tmp1$$Register, $tmp2$$Register,
15559                       $tmp3$$Register, $tmp4$$Register,
15560                       $tmp5$$Register, $tmp6$$Register,
15561                       -1, $result$$Register, StrIntrinsicNode::UL);
15562   %}
15563   ins_pipe(pipe_class_memory);
15564 %}
15565 
15566 instruct string_indexof_conUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15567                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15568                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15569 %{
15570   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15571   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15572   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15573          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15574   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UU)&quot; %}
15575 
15576   ins_encode %{
15577     int icnt2 = (int)$int_cnt2$$constant;
15578     __ string_indexof($str1$$Register, $str2$$Register,
15579                       $cnt1$$Register, zr,
15580                       $tmp1$$Register, $tmp2$$Register,
15581                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15582                       icnt2, $result$$Register, StrIntrinsicNode::UU);
15583   %}
15584   ins_pipe(pipe_class_memory);
15585 %}
15586 
15587 instruct string_indexof_conLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15588                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15589                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15590 %{
15591   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15592   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15593   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15594          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15595   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (LL)&quot; %}
15596 
15597   ins_encode %{
15598     int icnt2 = (int)$int_cnt2$$constant;
15599     __ string_indexof($str1$$Register, $str2$$Register,
15600                       $cnt1$$Register, zr,
15601                       $tmp1$$Register, $tmp2$$Register,
15602                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15603                       icnt2, $result$$Register, StrIntrinsicNode::LL);
15604   %}
15605   ins_pipe(pipe_class_memory);
15606 %}
15607 
15608 instruct string_indexof_conUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15609                  immI_1 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15610                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15611 %{
15612   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15613   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15614   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15615          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15616   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UL)&quot; %}
15617 
15618   ins_encode %{
15619     int icnt2 = (int)$int_cnt2$$constant;
15620     __ string_indexof($str1$$Register, $str2$$Register,
15621                       $cnt1$$Register, zr,
15622                       $tmp1$$Register, $tmp2$$Register,
15623                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15624                       icnt2, $result$$Register, StrIntrinsicNode::UL);
15625   %}
15626   ins_pipe(pipe_class_memory);
15627 %}
15628 
15629 instruct string_indexofU_char(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,
15630                               iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15631                               iRegINoSp tmp3, rFlagsReg cr)
15632 %{
15633   match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));
15634   effect(USE_KILL str1, USE_KILL cnt1, USE_KILL ch,
15635          TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15636 
15637   format %{ &quot;String IndexOf char[] $str1,$cnt1,$ch -&gt; $result&quot; %}
15638 
15639   ins_encode %{
15640     __ string_indexof_char($str1$$Register, $cnt1$$Register, $ch$$Register,
15641                            $result$$Register, $tmp1$$Register, $tmp2$$Register,
15642                            $tmp3$$Register);
15643   %}
15644   ins_pipe(pipe_class_memory);
15645 %}
15646 
15647 instruct string_equalsL(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15648                         iRegI_R0 result, rFlagsReg cr)
15649 %{
15650   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15651   match(Set result (StrEquals (Binary str1 str2) cnt));
15652   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15653 
15654   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15655   ins_encode %{
15656     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15657     __ string_equals($str1$$Register, $str2$$Register,
15658                      $result$$Register, $cnt$$Register, 1);
15659   %}
15660   ins_pipe(pipe_class_memory);
15661 %}
15662 
15663 instruct string_equalsU(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15664                         iRegI_R0 result, rFlagsReg cr)
15665 %{
15666   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15667   match(Set result (StrEquals (Binary str1 str2) cnt));
15668   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15669 
15670   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15671   ins_encode %{
15672     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15673     __ string_equals($str1$$Register, $str2$$Register,
15674                      $result$$Register, $cnt$$Register, 2);
15675   %}
15676   ins_pipe(pipe_class_memory);
15677 %}
15678 
15679 instruct array_equalsB(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15680                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15681                        iRegP_R10 tmp, rFlagsReg cr)
15682 %{
15683   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15684   match(Set result (AryEq ary1 ary2));
15685   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15686 
15687   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15688   ins_encode %{
15689     __ arrays_equals($ary1$$Register, $ary2$$Register,
15690                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15691                      $result$$Register, $tmp$$Register, 1);
15692     %}
15693   ins_pipe(pipe_class_memory);
15694 %}
15695 
15696 instruct array_equalsC(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15697                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15698                        iRegP_R10 tmp, rFlagsReg cr)
15699 %{
15700   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15701   match(Set result (AryEq ary1 ary2));
15702   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15703 
15704   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15705   ins_encode %{
15706     __ arrays_equals($ary1$$Register, $ary2$$Register,
15707                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15708                      $result$$Register, $tmp$$Register, 2);
15709   %}
15710   ins_pipe(pipe_class_memory);
15711 %}
15712 
15713 instruct has_negatives(iRegP_R1 ary1, iRegI_R2 len, iRegI_R0 result, rFlagsReg cr)
15714 %{
15715   match(Set result (HasNegatives ary1 len));
15716   effect(USE_KILL ary1, USE_KILL len, KILL cr);
15717   format %{ &quot;has negatives byte[] $ary1,$len -&gt; $result&quot; %}
15718   ins_encode %{
15719     __ has_negatives($ary1$$Register, $len$$Register, $result$$Register);
15720   %}
15721   ins_pipe( pipe_slow );
15722 %}
15723 
15724 // fast char[] to byte[] compression
15725 instruct string_compress(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15726                          vRegD_V0 tmp1, vRegD_V1 tmp2,
15727                          vRegD_V2 tmp3, vRegD_V3 tmp4,
15728                          iRegI_R0 result, rFlagsReg cr)
15729 %{
15730   match(Set result (StrCompressedCopy src (Binary dst len)));
15731   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15732 
15733   format %{ &quot;String Compress $src,$dst -&gt; $result    // KILL R1, R2, R3, R4&quot; %}
15734   ins_encode %{
15735     __ char_array_compress($src$$Register, $dst$$Register, $len$$Register,
15736                            $tmp1$$FloatRegister, $tmp2$$FloatRegister,
15737                            $tmp3$$FloatRegister, $tmp4$$FloatRegister,
15738                            $result$$Register);
15739   %}
15740   ins_pipe( pipe_slow );
15741 %}
15742 
15743 // fast byte[] to char[] inflation
15744 instruct string_inflate(Universe dummy, iRegP_R0 src, iRegP_R1 dst, iRegI_R2 len,
15745                         vRegD_V0 tmp1, vRegD_V1 tmp2, vRegD_V2 tmp3, iRegP_R3 tmp4, rFlagsReg cr)
15746 %{
15747   match(Set dummy (StrInflatedCopy src (Binary dst len)));
15748   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15749 
15750   format %{ &quot;String Inflate $src,$dst    // KILL $tmp1, $tmp2&quot; %}
15751   ins_encode %{
15752     __ byte_array_inflate($src$$Register, $dst$$Register, $len$$Register,
15753                           $tmp1$$FloatRegister, $tmp2$$FloatRegister, $tmp3$$FloatRegister, $tmp4$$Register);
15754   %}
15755   ins_pipe(pipe_class_memory);
15756 %}
15757 
15758 // encode char[] to byte[] in ISO_8859_1
15759 instruct encode_iso_array(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15760                           vRegD_V0 Vtmp1, vRegD_V1 Vtmp2,
15761                           vRegD_V2 Vtmp3, vRegD_V3 Vtmp4,
15762                           iRegI_R0 result, rFlagsReg cr)
15763 %{
15764   match(Set result (EncodeISOArray src (Binary dst len)));
15765   effect(USE_KILL src, USE_KILL dst, USE_KILL len,
15766          KILL Vtmp1, KILL Vtmp2, KILL Vtmp3, KILL Vtmp4, KILL cr);
15767 
15768   format %{ &quot;Encode array $src,$dst,$len -&gt; $result&quot; %}
15769   ins_encode %{
15770     __ encode_iso_array($src$$Register, $dst$$Register, $len$$Register,
15771          $result$$Register, $Vtmp1$$FloatRegister,  $Vtmp2$$FloatRegister,
15772          $Vtmp3$$FloatRegister,  $Vtmp4$$FloatRegister);
15773   %}
15774   ins_pipe( pipe_class_memory );
15775 %}
15776 
15777 // ============================================================================
15778 // This name is KNOWN by the ADLC and cannot be changed.
15779 // The ADLC forces a &#39;TypeRawPtr::BOTTOM&#39; output type
15780 // for this guy.
15781 instruct tlsLoadP(thread_RegP dst)
15782 %{
15783   match(Set dst (ThreadLocal));
15784 
15785   ins_cost(0);
15786 
15787   format %{ &quot; -- \t// $dst=Thread::current(), empty&quot; %}
15788 
15789   size(0);
15790 
15791   ins_encode( /*empty*/ );
15792 
15793   ins_pipe(pipe_class_empty);
15794 %}
15795 
15796 // ====================VECTOR INSTRUCTIONS=====================================
15797 
15798 // Load vector (32 bits)
15799 instruct loadV4(vecD dst, vmem4 mem)
15800 %{
15801   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 4);
15802   match(Set dst (LoadVector mem));
15803   ins_cost(4 * INSN_COST);
15804   format %{ &quot;ldrs   $dst,$mem\t# vector (32 bits)&quot; %}
15805   ins_encode( aarch64_enc_ldrvS(dst, mem) );
15806   ins_pipe(vload_reg_mem64);
15807 %}
15808 
15809 // Load vector (64 bits)
15810 instruct loadV8(vecD dst, vmem8 mem)
15811 %{
15812   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 8);
15813   match(Set dst (LoadVector mem));
15814   ins_cost(4 * INSN_COST);
15815   format %{ &quot;ldrd   $dst,$mem\t# vector (64 bits)&quot; %}
15816   ins_encode( aarch64_enc_ldrvD(dst, mem) );
15817   ins_pipe(vload_reg_mem64);
15818 %}
15819 
15820 // Load Vector (128 bits)
15821 instruct loadV16(vecX dst, vmem16 mem)
15822 %{
15823   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 16);
15824   match(Set dst (LoadVector mem));
15825   ins_cost(4 * INSN_COST);
15826   format %{ &quot;ldrq   $dst,$mem\t# vector (128 bits)&quot; %}
15827   ins_encode( aarch64_enc_ldrvQ(dst, mem) );
15828   ins_pipe(vload_reg_mem128);
15829 %}
15830 
15831 // Store Vector (32 bits)
15832 instruct storeV4(vecD src, vmem4 mem)
15833 %{
15834   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 4);
15835   match(Set mem (StoreVector mem src));
15836   ins_cost(4 * INSN_COST);
15837   format %{ &quot;strs   $mem,$src\t# vector (32 bits)&quot; %}
15838   ins_encode( aarch64_enc_strvS(src, mem) );
15839   ins_pipe(vstore_reg_mem64);
15840 %}
15841 
15842 // Store Vector (64 bits)
15843 instruct storeV8(vecD src, vmem8 mem)
15844 %{
15845   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 8);
15846   match(Set mem (StoreVector mem src));
15847   ins_cost(4 * INSN_COST);
15848   format %{ &quot;strd   $mem,$src\t# vector (64 bits)&quot; %}
15849   ins_encode( aarch64_enc_strvD(src, mem) );
15850   ins_pipe(vstore_reg_mem64);
15851 %}
15852 
15853 // Store Vector (128 bits)
15854 instruct storeV16(vecX src, vmem16 mem)
15855 %{
15856   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 16);
15857   match(Set mem (StoreVector mem src));
15858   ins_cost(4 * INSN_COST);
15859   format %{ &quot;strq   $mem,$src\t# vector (128 bits)&quot; %}
15860   ins_encode( aarch64_enc_strvQ(src, mem) );
15861   ins_pipe(vstore_reg_mem128);
15862 %}
15863 
15864 instruct replicate8B(vecD dst, iRegIorL2I src)
15865 %{
15866   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15867             n-&gt;as_Vector()-&gt;length() == 8);
15868   match(Set dst (ReplicateB src));
15869   ins_cost(INSN_COST);
15870   format %{ &quot;dup  $dst, $src\t# vector (8B)&quot; %}
15871   ins_encode %{
15872     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($src$$reg));
15873   %}
15874   ins_pipe(vdup_reg_reg64);
15875 %}
15876 
15877 instruct replicate16B(vecX dst, iRegIorL2I src)
15878 %{
15879   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15880   match(Set dst (ReplicateB src));
15881   ins_cost(INSN_COST);
15882   format %{ &quot;dup  $dst, $src\t# vector (16B)&quot; %}
15883   ins_encode %{
15884     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($src$$reg));
15885   %}
15886   ins_pipe(vdup_reg_reg128);
15887 %}
15888 
15889 instruct replicate8B_imm(vecD dst, immI con)
15890 %{
15891   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15892             n-&gt;as_Vector()-&gt;length() == 8);
15893   match(Set dst (ReplicateB con));
15894   ins_cost(INSN_COST);
15895   format %{ &quot;movi  $dst, $con\t# vector(8B)&quot; %}
15896   ins_encode %{
15897     __ mov(as_FloatRegister($dst$$reg), __ T8B, $con$$constant &amp; 0xff);
15898   %}
15899   ins_pipe(vmovi_reg_imm64);
15900 %}
15901 
15902 instruct replicate16B_imm(vecX dst, immI con)
15903 %{
15904   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15905   match(Set dst (ReplicateB con));
15906   ins_cost(INSN_COST);
15907   format %{ &quot;movi  $dst, $con\t# vector(16B)&quot; %}
15908   ins_encode %{
15909     __ mov(as_FloatRegister($dst$$reg), __ T16B, $con$$constant &amp; 0xff);
15910   %}
15911   ins_pipe(vmovi_reg_imm128);
15912 %}
15913 
15914 instruct replicate4S(vecD dst, iRegIorL2I src)
15915 %{
15916   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15917             n-&gt;as_Vector()-&gt;length() == 4);
15918   match(Set dst (ReplicateS src));
15919   ins_cost(INSN_COST);
15920   format %{ &quot;dup  $dst, $src\t# vector (4S)&quot; %}
15921   ins_encode %{
15922     __ dup(as_FloatRegister($dst$$reg), __ T4H, as_Register($src$$reg));
15923   %}
15924   ins_pipe(vdup_reg_reg64);
15925 %}
15926 
15927 instruct replicate8S(vecX dst, iRegIorL2I src)
15928 %{
15929   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15930   match(Set dst (ReplicateS src));
15931   ins_cost(INSN_COST);
15932   format %{ &quot;dup  $dst, $src\t# vector (8S)&quot; %}
15933   ins_encode %{
15934     __ dup(as_FloatRegister($dst$$reg), __ T8H, as_Register($src$$reg));
15935   %}
15936   ins_pipe(vdup_reg_reg128);
15937 %}
15938 
15939 instruct replicate4S_imm(vecD dst, immI con)
15940 %{
15941   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15942             n-&gt;as_Vector()-&gt;length() == 4);
15943   match(Set dst (ReplicateS con));
15944   ins_cost(INSN_COST);
15945   format %{ &quot;movi  $dst, $con\t# vector(4H)&quot; %}
15946   ins_encode %{
15947     __ mov(as_FloatRegister($dst$$reg), __ T4H, $con$$constant &amp; 0xffff);
15948   %}
15949   ins_pipe(vmovi_reg_imm64);
15950 %}
15951 
15952 instruct replicate8S_imm(vecX dst, immI con)
15953 %{
15954   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15955   match(Set dst (ReplicateS con));
15956   ins_cost(INSN_COST);
15957   format %{ &quot;movi  $dst, $con\t# vector(8H)&quot; %}
15958   ins_encode %{
15959     __ mov(as_FloatRegister($dst$$reg), __ T8H, $con$$constant &amp; 0xffff);
15960   %}
15961   ins_pipe(vmovi_reg_imm128);
15962 %}
15963 
15964 instruct replicate2I(vecD dst, iRegIorL2I src)
15965 %{
15966   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15967   match(Set dst (ReplicateI src));
15968   ins_cost(INSN_COST);
15969   format %{ &quot;dup  $dst, $src\t# vector (2I)&quot; %}
15970   ins_encode %{
15971     __ dup(as_FloatRegister($dst$$reg), __ T2S, as_Register($src$$reg));
15972   %}
15973   ins_pipe(vdup_reg_reg64);
15974 %}
15975 
15976 instruct replicate4I(vecX dst, iRegIorL2I src)
15977 %{
15978   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15979   match(Set dst (ReplicateI src));
15980   ins_cost(INSN_COST);
15981   format %{ &quot;dup  $dst, $src\t# vector (4I)&quot; %}
15982   ins_encode %{
15983     __ dup(as_FloatRegister($dst$$reg), __ T4S, as_Register($src$$reg));
15984   %}
15985   ins_pipe(vdup_reg_reg128);
15986 %}
15987 
15988 instruct replicate2I_imm(vecD dst, immI con)
15989 %{
15990   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15991   match(Set dst (ReplicateI con));
15992   ins_cost(INSN_COST);
15993   format %{ &quot;movi  $dst, $con\t# vector(2I)&quot; %}
15994   ins_encode %{
15995     __ mov(as_FloatRegister($dst$$reg), __ T2S, $con$$constant);
15996   %}
15997   ins_pipe(vmovi_reg_imm64);
15998 %}
15999 
16000 instruct replicate4I_imm(vecX dst, immI con)
16001 %{
16002   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16003   match(Set dst (ReplicateI con));
16004   ins_cost(INSN_COST);
16005   format %{ &quot;movi  $dst, $con\t# vector(4I)&quot; %}
16006   ins_encode %{
16007     __ mov(as_FloatRegister($dst$$reg), __ T4S, $con$$constant);
16008   %}
16009   ins_pipe(vmovi_reg_imm128);
16010 %}
16011 
16012 instruct replicate2L(vecX dst, iRegL src)
16013 %{
16014   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16015   match(Set dst (ReplicateL src));
16016   ins_cost(INSN_COST);
16017   format %{ &quot;dup  $dst, $src\t# vector (2L)&quot; %}
16018   ins_encode %{
16019     __ dup(as_FloatRegister($dst$$reg), __ T2D, as_Register($src$$reg));
16020   %}
16021   ins_pipe(vdup_reg_reg128);
16022 %}
16023 
16024 instruct replicate2L_zero(vecX dst, immI0 zero)
16025 %{
16026   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16027   match(Set dst (ReplicateI zero));
16028   ins_cost(INSN_COST);
16029   format %{ &quot;movi  $dst, $zero\t# vector(4I)&quot; %}
16030   ins_encode %{
16031     __ eor(as_FloatRegister($dst$$reg), __ T16B,
16032            as_FloatRegister($dst$$reg),
16033            as_FloatRegister($dst$$reg));
16034   %}
16035   ins_pipe(vmovi_reg_imm128);
16036 %}
16037 
16038 instruct replicate2F(vecD dst, vRegF src)
16039 %{
16040   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16041   match(Set dst (ReplicateF src));
16042   ins_cost(INSN_COST);
16043   format %{ &quot;dup  $dst, $src\t# vector (2F)&quot; %}
16044   ins_encode %{
16045     __ dup(as_FloatRegister($dst$$reg), __ T2S,
16046            as_FloatRegister($src$$reg));
16047   %}
16048   ins_pipe(vdup_reg_freg64);
16049 %}
16050 
16051 instruct replicate4F(vecX dst, vRegF src)
16052 %{
16053   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16054   match(Set dst (ReplicateF src));
16055   ins_cost(INSN_COST);
16056   format %{ &quot;dup  $dst, $src\t# vector (4F)&quot; %}
16057   ins_encode %{
16058     __ dup(as_FloatRegister($dst$$reg), __ T4S,
16059            as_FloatRegister($src$$reg));
16060   %}
16061   ins_pipe(vdup_reg_freg128);
16062 %}
16063 
16064 instruct replicate2D(vecX dst, vRegD src)
16065 %{
16066   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16067   match(Set dst (ReplicateD src));
16068   ins_cost(INSN_COST);
16069   format %{ &quot;dup  $dst, $src\t# vector (2D)&quot; %}
16070   ins_encode %{
16071     __ dup(as_FloatRegister($dst$$reg), __ T2D,
16072            as_FloatRegister($src$$reg));
16073   %}
16074   ins_pipe(vdup_reg_dreg128);
16075 %}
16076 
16077 // ====================REDUCTION ARITHMETIC====================================
16078 
16079 instruct reduce_add2I(iRegINoSp dst, iRegIorL2I isrc, vecD vsrc, iRegINoSp tmp, iRegINoSp tmp2)
16080 %{
16081   match(Set dst (AddReductionVI isrc vsrc));
16082   ins_cost(INSN_COST);
16083   effect(TEMP tmp, TEMP tmp2);
16084   format %{ &quot;umov  $tmp, $vsrc, S, 0\n\t&quot;
16085             &quot;umov  $tmp2, $vsrc, S, 1\n\t&quot;
16086             &quot;addw  $tmp, $isrc, $tmp\n\t&quot;
16087             &quot;addw  $dst, $tmp, $tmp2\t# add reduction2I&quot;
16088   %}
16089   ins_encode %{
16090     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 0);
16091     __ umov($tmp2$$Register, as_FloatRegister($vsrc$$reg), __ S, 1);
16092     __ addw($tmp$$Register, $isrc$$Register, $tmp$$Register);
16093     __ addw($dst$$Register, $tmp$$Register, $tmp2$$Register);
16094   %}
16095   ins_pipe(pipe_class_default);
16096 %}
16097 
16098 instruct reduce_add4I(iRegINoSp dst, iRegIorL2I isrc, vecX vsrc, vecX vtmp, iRegINoSp itmp)
16099 %{
16100   match(Set dst (AddReductionVI isrc vsrc));
16101   ins_cost(INSN_COST);
16102   effect(TEMP vtmp, TEMP itmp);
16103   format %{ &quot;addv  $vtmp, T4S, $vsrc\n\t&quot;
16104             &quot;umov  $itmp, $vtmp, S, 0\n\t&quot;
16105             &quot;addw  $dst, $itmp, $isrc\t# add reduction4I&quot;
16106   %}
16107   ins_encode %{
16108     __ addv(as_FloatRegister($vtmp$$reg), __ T4S,
16109             as_FloatRegister($vsrc$$reg));
16110     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 0);
16111     __ addw($dst$$Register, $itmp$$Register, $isrc$$Register);
16112   %}
16113   ins_pipe(pipe_class_default);
16114 %}
16115 
16116 instruct reduce_mul2I(iRegINoSp dst, iRegIorL2I isrc, vecD vsrc, iRegINoSp tmp)
16117 %{
16118   match(Set dst (MulReductionVI isrc vsrc));
16119   ins_cost(INSN_COST);
16120   effect(TEMP tmp, TEMP dst);
16121   format %{ &quot;umov  $tmp, $vsrc, S, 0\n\t&quot;
16122             &quot;mul   $dst, $tmp, $isrc\n\t&quot;
16123             &quot;umov  $tmp, $vsrc, S, 1\n\t&quot;
16124             &quot;mul   $dst, $tmp, $dst\t# mul reduction2I&quot;
16125   %}
16126   ins_encode %{
16127     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 0);
16128     __ mul($dst$$Register, $tmp$$Register, $isrc$$Register);
16129     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 1);
16130     __ mul($dst$$Register, $tmp$$Register, $dst$$Register);
16131   %}
16132   ins_pipe(pipe_class_default);
16133 %}
16134 
16135 instruct reduce_mul4I(iRegINoSp dst, iRegIorL2I isrc, vecX vsrc, vecX vtmp, iRegINoSp itmp)
16136 %{
16137   match(Set dst (MulReductionVI isrc vsrc));
16138   ins_cost(INSN_COST);
16139   effect(TEMP vtmp, TEMP itmp, TEMP dst);
16140   format %{ &quot;ins   $vtmp, D, $vsrc, 0, 1\n\t&quot;
16141             &quot;mulv  $vtmp, T2S, $vtmp, $vsrc\n\t&quot;
16142             &quot;umov  $itmp, $vtmp, S, 0\n\t&quot;
16143             &quot;mul   $dst, $itmp, $isrc\n\t&quot;
16144             &quot;umov  $itmp, $vtmp, S, 1\n\t&quot;
16145             &quot;mul   $dst, $itmp, $dst\t# mul reduction4I&quot;
16146   %}
16147   ins_encode %{
16148     __ ins(as_FloatRegister($vtmp$$reg), __ D,
16149            as_FloatRegister($vsrc$$reg), 0, 1);
16150     __ mulv(as_FloatRegister($vtmp$$reg), __ T2S,
16151             as_FloatRegister($vtmp$$reg), as_FloatRegister($vsrc$$reg));
16152     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 0);
16153     __ mul($dst$$Register, $itmp$$Register, $isrc$$Register);
16154     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 1);
16155     __ mul($dst$$Register, $itmp$$Register, $dst$$Register);
16156   %}
16157   ins_pipe(pipe_class_default);
16158 %}
16159 
16160 instruct reduce_add2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp)
16161 %{
16162   match(Set dst (AddReductionVF fsrc vsrc));
16163   ins_cost(INSN_COST);
16164   effect(TEMP tmp, TEMP dst);
16165   format %{ &quot;fadds $dst, $fsrc, $vsrc\n\t&quot;
16166             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16167             &quot;fadds $dst, $dst, $tmp\t# add reduction2F&quot;
16168   %}
16169   ins_encode %{
16170     __ fadds(as_FloatRegister($dst$$reg),
16171              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16172     __ ins(as_FloatRegister($tmp$$reg), __ S,
16173            as_FloatRegister($vsrc$$reg), 0, 1);
16174     __ fadds(as_FloatRegister($dst$$reg),
16175              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16176   %}
16177   ins_pipe(pipe_class_default);
16178 %}
16179 
16180 instruct reduce_add4F(vRegF dst, vRegF fsrc, vecX vsrc, vecX tmp)
16181 %{
16182   match(Set dst (AddReductionVF fsrc vsrc));
16183   ins_cost(INSN_COST);
16184   effect(TEMP tmp, TEMP dst);
16185   format %{ &quot;fadds $dst, $fsrc, $vsrc\n\t&quot;
16186             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16187             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16188             &quot;ins   $tmp, S, $vsrc, 0, 2\n\t&quot;
16189             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16190             &quot;ins   $tmp, S, $vsrc, 0, 3\n\t&quot;
16191             &quot;fadds $dst, $dst, $tmp\t# add reduction4F&quot;
16192   %}
16193   ins_encode %{
16194     __ fadds(as_FloatRegister($dst$$reg),
16195              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16196     __ ins(as_FloatRegister($tmp$$reg), __ S,
16197            as_FloatRegister($vsrc$$reg), 0, 1);
16198     __ fadds(as_FloatRegister($dst$$reg),
16199              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16200     __ ins(as_FloatRegister($tmp$$reg), __ S,
16201            as_FloatRegister($vsrc$$reg), 0, 2);
16202     __ fadds(as_FloatRegister($dst$$reg),
16203              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16204     __ ins(as_FloatRegister($tmp$$reg), __ S,
16205            as_FloatRegister($vsrc$$reg), 0, 3);
16206     __ fadds(as_FloatRegister($dst$$reg),
16207              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16208   %}
16209   ins_pipe(pipe_class_default);
16210 %}
16211 
16212 instruct reduce_mul2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp)
16213 %{
16214   match(Set dst (MulReductionVF fsrc vsrc));
16215   ins_cost(INSN_COST);
16216   effect(TEMP tmp, TEMP dst);
16217   format %{ &quot;fmuls $dst, $fsrc, $vsrc\n\t&quot;
16218             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16219             &quot;fmuls $dst, $dst, $tmp\t# mul reduction2F&quot;
16220   %}
16221   ins_encode %{
16222     __ fmuls(as_FloatRegister($dst$$reg),
16223              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16224     __ ins(as_FloatRegister($tmp$$reg), __ S,
16225            as_FloatRegister($vsrc$$reg), 0, 1);
16226     __ fmuls(as_FloatRegister($dst$$reg),
16227              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16228   %}
16229   ins_pipe(pipe_class_default);
16230 %}
16231 
16232 instruct reduce_mul4F(vRegF dst, vRegF fsrc, vecX vsrc, vecX tmp)
16233 %{
16234   match(Set dst (MulReductionVF fsrc vsrc));
16235   ins_cost(INSN_COST);
16236   effect(TEMP tmp, TEMP dst);
16237   format %{ &quot;fmuls $dst, $fsrc, $vsrc\n\t&quot;
16238             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16239             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16240             &quot;ins   $tmp, S, $vsrc, 0, 2\n\t&quot;
16241             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16242             &quot;ins   $tmp, S, $vsrc, 0, 3\n\t&quot;
16243             &quot;fmuls $dst, $dst, $tmp\t# mul reduction4F&quot;
16244   %}
16245   ins_encode %{
16246     __ fmuls(as_FloatRegister($dst$$reg),
16247              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16248     __ ins(as_FloatRegister($tmp$$reg), __ S,
16249            as_FloatRegister($vsrc$$reg), 0, 1);
16250     __ fmuls(as_FloatRegister($dst$$reg),
16251              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16252     __ ins(as_FloatRegister($tmp$$reg), __ S,
16253            as_FloatRegister($vsrc$$reg), 0, 2);
16254     __ fmuls(as_FloatRegister($dst$$reg),
16255              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16256     __ ins(as_FloatRegister($tmp$$reg), __ S,
16257            as_FloatRegister($vsrc$$reg), 0, 3);
16258     __ fmuls(as_FloatRegister($dst$$reg),
16259              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16260   %}
16261   ins_pipe(pipe_class_default);
16262 %}
16263 
16264 instruct reduce_add2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp)
16265 %{
16266   match(Set dst (AddReductionVD dsrc vsrc));
16267   ins_cost(INSN_COST);
16268   effect(TEMP tmp, TEMP dst);
16269   format %{ &quot;faddd $dst, $dsrc, $vsrc\n\t&quot;
16270             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16271             &quot;faddd $dst, $dst, $tmp\t# add reduction2D&quot;
16272   %}
16273   ins_encode %{
16274     __ faddd(as_FloatRegister($dst$$reg),
16275              as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16276     __ ins(as_FloatRegister($tmp$$reg), __ D,
16277            as_FloatRegister($vsrc$$reg), 0, 1);
16278     __ faddd(as_FloatRegister($dst$$reg),
16279              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16280   %}
16281   ins_pipe(pipe_class_default);
16282 %}
16283 
16284 instruct reduce_mul2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp)
16285 %{
16286   match(Set dst (MulReductionVD dsrc vsrc));
16287   ins_cost(INSN_COST);
16288   effect(TEMP tmp, TEMP dst);
16289   format %{ &quot;fmuld $dst, $dsrc, $vsrc\n\t&quot;
16290             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16291             &quot;fmuld $dst, $dst, $tmp\t# mul reduction2D&quot;
16292   %}
16293   ins_encode %{
16294     __ fmuld(as_FloatRegister($dst$$reg),
16295              as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16296     __ ins(as_FloatRegister($tmp$$reg), __ D,
16297            as_FloatRegister($vsrc$$reg), 0, 1);
16298     __ fmuld(as_FloatRegister($dst$$reg),
16299              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16300   %}
16301   ins_pipe(pipe_class_default);
16302 %}
16303 
16304 instruct reduce_max2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp) %{
16305   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16306   match(Set dst (MaxReductionV fsrc vsrc));
16307   ins_cost(INSN_COST);
16308   effect(TEMP_DEF dst, TEMP tmp);
16309   format %{ &quot;fmaxs $dst, $fsrc, $vsrc\n\t&quot;
16310             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16311             &quot;fmaxs $dst, $dst, $tmp\t# max reduction2F&quot; %}
16312   ins_encode %{
16313     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16314     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($vsrc$$reg), 0, 1);
16315     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16316   %}
16317   ins_pipe(pipe_class_default);
16318 %}
16319 
16320 instruct reduce_max4F(vRegF dst, vRegF fsrc, vecX vsrc) %{
16321   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16322   match(Set dst (MaxReductionV fsrc vsrc));
16323   ins_cost(INSN_COST);
16324   effect(TEMP_DEF dst);
16325   format %{ &quot;fmaxv $dst, T4S, $vsrc\n\t&quot;
16326             &quot;fmaxs $dst, $dst, $fsrc\t# max reduction4F&quot; %}
16327   ins_encode %{
16328     __ fmaxv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($vsrc$$reg));
16329     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));
16330   %}
16331   ins_pipe(pipe_class_default);
16332 %}
16333 
16334 instruct reduce_max2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp) %{
16335   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16336   match(Set dst (MaxReductionV dsrc vsrc));
16337   ins_cost(INSN_COST);
16338   effect(TEMP_DEF dst, TEMP tmp);
16339   format %{ &quot;fmaxd $dst, $dsrc, $vsrc\n\t&quot;
16340             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16341             &quot;fmaxd $dst, $dst, $tmp\t# max reduction2D&quot; %}
16342   ins_encode %{
16343     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16344     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($vsrc$$reg), 0, 1);
16345     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16346   %}
16347   ins_pipe(pipe_class_default);
16348 %}
16349 
16350 instruct reduce_min2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp) %{
16351   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16352   match(Set dst (MinReductionV fsrc vsrc));
16353   ins_cost(INSN_COST);
16354   effect(TEMP_DEF dst, TEMP tmp);
16355   format %{ &quot;fmins $dst, $fsrc, $vsrc\n\t&quot;
16356             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16357             &quot;fmins $dst, $dst, $tmp\t# min reduction2F&quot; %}
16358   ins_encode %{
16359     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16360     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($vsrc$$reg), 0, 1);
16361     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16362   %}
16363   ins_pipe(pipe_class_default);
16364 %}
16365 
16366 instruct reduce_min4F(vRegF dst, vRegF fsrc, vecX vsrc) %{
16367   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16368   match(Set dst (MinReductionV fsrc vsrc));
16369   ins_cost(INSN_COST);
16370   effect(TEMP_DEF dst);
16371   format %{ &quot;fminv $dst, T4S, $vsrc\n\t&quot;
16372             &quot;fmins $dst, $dst, $fsrc\t# min reduction4F&quot; %}
16373   ins_encode %{
16374     __ fminv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($vsrc$$reg));
16375     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));
16376   %}
16377   ins_pipe(pipe_class_default);
16378 %}
16379 
16380 instruct reduce_min2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp) %{
16381   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16382   match(Set dst (MinReductionV dsrc vsrc));
16383   ins_cost(INSN_COST);
16384   effect(TEMP_DEF dst, TEMP tmp);
16385   format %{ &quot;fmind $dst, $dsrc, $vsrc\n\t&quot;
16386             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16387             &quot;fmind $dst, $dst, $tmp\t# min reduction2D&quot; %}
16388   ins_encode %{
16389     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16390     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($vsrc$$reg), 0, 1);
16391     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16392   %}
16393   ins_pipe(pipe_class_default);
16394 %}
16395 
16396 // ====================VECTOR ARITHMETIC=======================================
16397 
16398 // --------------------------------- ADD --------------------------------------
16399 
16400 instruct vadd8B(vecD dst, vecD src1, vecD src2)
16401 %{
16402   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16403             n-&gt;as_Vector()-&gt;length() == 8);
16404   match(Set dst (AddVB src1 src2));
16405   ins_cost(INSN_COST);
16406   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16407   ins_encode %{
16408     __ addv(as_FloatRegister($dst$$reg), __ T8B,
16409             as_FloatRegister($src1$$reg),
16410             as_FloatRegister($src2$$reg));
16411   %}
16412   ins_pipe(vdop64);
16413 %}
16414 
16415 instruct vadd16B(vecX dst, vecX src1, vecX src2)
16416 %{
16417   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16418   match(Set dst (AddVB src1 src2));
16419   ins_cost(INSN_COST);
16420   format %{ &quot;addv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16421   ins_encode %{
16422     __ addv(as_FloatRegister($dst$$reg), __ T16B,
16423             as_FloatRegister($src1$$reg),
16424             as_FloatRegister($src2$$reg));
16425   %}
16426   ins_pipe(vdop128);
16427 %}
16428 
16429 instruct vadd4S(vecD dst, vecD src1, vecD src2)
16430 %{
16431   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16432             n-&gt;as_Vector()-&gt;length() == 4);
16433   match(Set dst (AddVS src1 src2));
16434   ins_cost(INSN_COST);
16435   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16436   ins_encode %{
16437     __ addv(as_FloatRegister($dst$$reg), __ T4H,
16438             as_FloatRegister($src1$$reg),
16439             as_FloatRegister($src2$$reg));
16440   %}
16441   ins_pipe(vdop64);
16442 %}
16443 
16444 instruct vadd8S(vecX dst, vecX src1, vecX src2)
16445 %{
16446   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16447   match(Set dst (AddVS src1 src2));
16448   ins_cost(INSN_COST);
16449   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16450   ins_encode %{
16451     __ addv(as_FloatRegister($dst$$reg), __ T8H,
16452             as_FloatRegister($src1$$reg),
16453             as_FloatRegister($src2$$reg));
16454   %}
16455   ins_pipe(vdop128);
16456 %}
16457 
16458 instruct vadd2I(vecD dst, vecD src1, vecD src2)
16459 %{
16460   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16461   match(Set dst (AddVI src1 src2));
16462   ins_cost(INSN_COST);
16463   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16464   ins_encode %{
16465     __ addv(as_FloatRegister($dst$$reg), __ T2S,
16466             as_FloatRegister($src1$$reg),
16467             as_FloatRegister($src2$$reg));
16468   %}
16469   ins_pipe(vdop64);
16470 %}
16471 
16472 instruct vadd4I(vecX dst, vecX src1, vecX src2)
16473 %{
16474   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16475   match(Set dst (AddVI src1 src2));
16476   ins_cost(INSN_COST);
16477   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16478   ins_encode %{
16479     __ addv(as_FloatRegister($dst$$reg), __ T4S,
16480             as_FloatRegister($src1$$reg),
16481             as_FloatRegister($src2$$reg));
16482   %}
16483   ins_pipe(vdop128);
16484 %}
16485 
16486 instruct vadd2L(vecX dst, vecX src1, vecX src2)
16487 %{
16488   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16489   match(Set dst (AddVL src1 src2));
16490   ins_cost(INSN_COST);
16491   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16492   ins_encode %{
16493     __ addv(as_FloatRegister($dst$$reg), __ T2D,
16494             as_FloatRegister($src1$$reg),
16495             as_FloatRegister($src2$$reg));
16496   %}
16497   ins_pipe(vdop128);
16498 %}
16499 
16500 instruct vadd2F(vecD dst, vecD src1, vecD src2)
16501 %{
16502   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16503   match(Set dst (AddVF src1 src2));
16504   ins_cost(INSN_COST);
16505   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2S)&quot; %}
16506   ins_encode %{
16507     __ fadd(as_FloatRegister($dst$$reg), __ T2S,
16508             as_FloatRegister($src1$$reg),
16509             as_FloatRegister($src2$$reg));
16510   %}
16511   ins_pipe(vdop_fp64);
16512 %}
16513 
16514 instruct vadd4F(vecX dst, vecX src1, vecX src2)
16515 %{
16516   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16517   match(Set dst (AddVF src1 src2));
16518   ins_cost(INSN_COST);
16519   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (4S)&quot; %}
16520   ins_encode %{
16521     __ fadd(as_FloatRegister($dst$$reg), __ T4S,
16522             as_FloatRegister($src1$$reg),
16523             as_FloatRegister($src2$$reg));
16524   %}
16525   ins_pipe(vdop_fp128);
16526 %}
16527 
16528 instruct vadd2D(vecX dst, vecX src1, vecX src2)
16529 %{
16530   match(Set dst (AddVD src1 src2));
16531   ins_cost(INSN_COST);
16532   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2D)&quot; %}
16533   ins_encode %{
16534     __ fadd(as_FloatRegister($dst$$reg), __ T2D,
16535             as_FloatRegister($src1$$reg),
16536             as_FloatRegister($src2$$reg));
16537   %}
16538   ins_pipe(vdop_fp128);
16539 %}
16540 
16541 // --------------------------------- SUB --------------------------------------
16542 
16543 instruct vsub8B(vecD dst, vecD src1, vecD src2)
16544 %{
16545   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16546             n-&gt;as_Vector()-&gt;length() == 8);
16547   match(Set dst (SubVB src1 src2));
16548   ins_cost(INSN_COST);
16549   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16550   ins_encode %{
16551     __ subv(as_FloatRegister($dst$$reg), __ T8B,
16552             as_FloatRegister($src1$$reg),
16553             as_FloatRegister($src2$$reg));
16554   %}
16555   ins_pipe(vdop64);
16556 %}
16557 
16558 instruct vsub16B(vecX dst, vecX src1, vecX src2)
16559 %{
16560   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16561   match(Set dst (SubVB src1 src2));
16562   ins_cost(INSN_COST);
16563   format %{ &quot;subv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16564   ins_encode %{
16565     __ subv(as_FloatRegister($dst$$reg), __ T16B,
16566             as_FloatRegister($src1$$reg),
16567             as_FloatRegister($src2$$reg));
16568   %}
16569   ins_pipe(vdop128);
16570 %}
16571 
16572 instruct vsub4S(vecD dst, vecD src1, vecD src2)
16573 %{
16574   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16575             n-&gt;as_Vector()-&gt;length() == 4);
16576   match(Set dst (SubVS src1 src2));
16577   ins_cost(INSN_COST);
16578   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16579   ins_encode %{
16580     __ subv(as_FloatRegister($dst$$reg), __ T4H,
16581             as_FloatRegister($src1$$reg),
16582             as_FloatRegister($src2$$reg));
16583   %}
16584   ins_pipe(vdop64);
16585 %}
16586 
16587 instruct vsub8S(vecX dst, vecX src1, vecX src2)
16588 %{
16589   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16590   match(Set dst (SubVS src1 src2));
16591   ins_cost(INSN_COST);
16592   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16593   ins_encode %{
16594     __ subv(as_FloatRegister($dst$$reg), __ T8H,
16595             as_FloatRegister($src1$$reg),
16596             as_FloatRegister($src2$$reg));
16597   %}
16598   ins_pipe(vdop128);
16599 %}
16600 
16601 instruct vsub2I(vecD dst, vecD src1, vecD src2)
16602 %{
16603   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16604   match(Set dst (SubVI src1 src2));
16605   ins_cost(INSN_COST);
16606   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16607   ins_encode %{
16608     __ subv(as_FloatRegister($dst$$reg), __ T2S,
16609             as_FloatRegister($src1$$reg),
16610             as_FloatRegister($src2$$reg));
16611   %}
16612   ins_pipe(vdop64);
16613 %}
16614 
16615 instruct vsub4I(vecX dst, vecX src1, vecX src2)
16616 %{
16617   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16618   match(Set dst (SubVI src1 src2));
16619   ins_cost(INSN_COST);
16620   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16621   ins_encode %{
16622     __ subv(as_FloatRegister($dst$$reg), __ T4S,
16623             as_FloatRegister($src1$$reg),
16624             as_FloatRegister($src2$$reg));
16625   %}
16626   ins_pipe(vdop128);
16627 %}
16628 
16629 instruct vsub2L(vecX dst, vecX src1, vecX src2)
16630 %{
16631   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16632   match(Set dst (SubVL src1 src2));
16633   ins_cost(INSN_COST);
16634   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16635   ins_encode %{
16636     __ subv(as_FloatRegister($dst$$reg), __ T2D,
16637             as_FloatRegister($src1$$reg),
16638             as_FloatRegister($src2$$reg));
16639   %}
16640   ins_pipe(vdop128);
16641 %}
16642 
16643 instruct vsub2F(vecD dst, vecD src1, vecD src2)
16644 %{
16645   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16646   match(Set dst (SubVF src1 src2));
16647   ins_cost(INSN_COST);
16648   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2S)&quot; %}
16649   ins_encode %{
16650     __ fsub(as_FloatRegister($dst$$reg), __ T2S,
16651             as_FloatRegister($src1$$reg),
16652             as_FloatRegister($src2$$reg));
16653   %}
16654   ins_pipe(vdop_fp64);
16655 %}
16656 
16657 instruct vsub4F(vecX dst, vecX src1, vecX src2)
16658 %{
16659   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16660   match(Set dst (SubVF src1 src2));
16661   ins_cost(INSN_COST);
16662   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (4S)&quot; %}
16663   ins_encode %{
16664     __ fsub(as_FloatRegister($dst$$reg), __ T4S,
16665             as_FloatRegister($src1$$reg),
16666             as_FloatRegister($src2$$reg));
16667   %}
16668   ins_pipe(vdop_fp128);
16669 %}
16670 
16671 instruct vsub2D(vecX dst, vecX src1, vecX src2)
16672 %{
16673   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16674   match(Set dst (SubVD src1 src2));
16675   ins_cost(INSN_COST);
16676   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2D)&quot; %}
16677   ins_encode %{
16678     __ fsub(as_FloatRegister($dst$$reg), __ T2D,
16679             as_FloatRegister($src1$$reg),
16680             as_FloatRegister($src2$$reg));
16681   %}
16682   ins_pipe(vdop_fp128);
16683 %}
16684 
16685 // --------------------------------- MUL --------------------------------------
16686 
16687 instruct vmul8B(vecD dst, vecD src1, vecD src2)
16688 %{
16689   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16690             n-&gt;as_Vector()-&gt;length() == 8);
16691   match(Set dst (MulVB src1 src2));
16692   ins_cost(INSN_COST);
16693   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16694   ins_encode %{
16695     __ mulv(as_FloatRegister($dst$$reg), __ T8B,
16696             as_FloatRegister($src1$$reg),
16697             as_FloatRegister($src2$$reg));
16698   %}
16699   ins_pipe(vmul64);
16700 %}
16701 
16702 instruct vmul16B(vecX dst, vecX src1, vecX src2)
16703 %{
16704   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16705   match(Set dst (MulVB src1 src2));
16706   ins_cost(INSN_COST);
16707   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16708   ins_encode %{
16709     __ mulv(as_FloatRegister($dst$$reg), __ T16B,
16710             as_FloatRegister($src1$$reg),
16711             as_FloatRegister($src2$$reg));
16712   %}
16713   ins_pipe(vmul128);
16714 %}
16715 
16716 instruct vmul4S(vecD dst, vecD src1, vecD src2)
16717 %{
16718   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16719             n-&gt;as_Vector()-&gt;length() == 4);
16720   match(Set dst (MulVS src1 src2));
16721   ins_cost(INSN_COST);
16722   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16723   ins_encode %{
16724     __ mulv(as_FloatRegister($dst$$reg), __ T4H,
16725             as_FloatRegister($src1$$reg),
16726             as_FloatRegister($src2$$reg));
16727   %}
16728   ins_pipe(vmul64);
16729 %}
16730 
16731 instruct vmul8S(vecX dst, vecX src1, vecX src2)
16732 %{
16733   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16734   match(Set dst (MulVS src1 src2));
16735   ins_cost(INSN_COST);
16736   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16737   ins_encode %{
16738     __ mulv(as_FloatRegister($dst$$reg), __ T8H,
16739             as_FloatRegister($src1$$reg),
16740             as_FloatRegister($src2$$reg));
16741   %}
16742   ins_pipe(vmul128);
16743 %}
16744 
16745 instruct vmul2I(vecD dst, vecD src1, vecD src2)
16746 %{
16747   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16748   match(Set dst (MulVI src1 src2));
16749   ins_cost(INSN_COST);
16750   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16751   ins_encode %{
16752     __ mulv(as_FloatRegister($dst$$reg), __ T2S,
16753             as_FloatRegister($src1$$reg),
16754             as_FloatRegister($src2$$reg));
16755   %}
16756   ins_pipe(vmul64);
16757 %}
16758 
16759 instruct vmul4I(vecX dst, vecX src1, vecX src2)
16760 %{
16761   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16762   match(Set dst (MulVI src1 src2));
16763   ins_cost(INSN_COST);
16764   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16765   ins_encode %{
16766     __ mulv(as_FloatRegister($dst$$reg), __ T4S,
16767             as_FloatRegister($src1$$reg),
16768             as_FloatRegister($src2$$reg));
16769   %}
16770   ins_pipe(vmul128);
16771 %}
16772 
16773 instruct vmul2F(vecD dst, vecD src1, vecD src2)
16774 %{
16775   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16776   match(Set dst (MulVF src1 src2));
16777   ins_cost(INSN_COST);
16778   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2S)&quot; %}
16779   ins_encode %{
16780     __ fmul(as_FloatRegister($dst$$reg), __ T2S,
16781             as_FloatRegister($src1$$reg),
16782             as_FloatRegister($src2$$reg));
16783   %}
16784   ins_pipe(vmuldiv_fp64);
16785 %}
16786 
16787 instruct vmul4F(vecX dst, vecX src1, vecX src2)
16788 %{
16789   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16790   match(Set dst (MulVF src1 src2));
16791   ins_cost(INSN_COST);
16792   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (4S)&quot; %}
16793   ins_encode %{
16794     __ fmul(as_FloatRegister($dst$$reg), __ T4S,
16795             as_FloatRegister($src1$$reg),
16796             as_FloatRegister($src2$$reg));
16797   %}
16798   ins_pipe(vmuldiv_fp128);
16799 %}
16800 
16801 instruct vmul2D(vecX dst, vecX src1, vecX src2)
16802 %{
16803   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16804   match(Set dst (MulVD src1 src2));
16805   ins_cost(INSN_COST);
16806   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2D)&quot; %}
16807   ins_encode %{
16808     __ fmul(as_FloatRegister($dst$$reg), __ T2D,
16809             as_FloatRegister($src1$$reg),
16810             as_FloatRegister($src2$$reg));
16811   %}
16812   ins_pipe(vmuldiv_fp128);
16813 %}
16814 
16815 // --------------------------------- MLA --------------------------------------
16816 
16817 instruct vmla4S(vecD dst, vecD src1, vecD src2)
16818 %{
16819   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16820             n-&gt;as_Vector()-&gt;length() == 4);
16821   match(Set dst (AddVS dst (MulVS src1 src2)));
16822   ins_cost(INSN_COST);
16823   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4H)&quot; %}
16824   ins_encode %{
16825     __ mlav(as_FloatRegister($dst$$reg), __ T4H,
16826             as_FloatRegister($src1$$reg),
16827             as_FloatRegister($src2$$reg));
16828   %}
16829   ins_pipe(vmla64);
16830 %}
16831 
16832 instruct vmla8S(vecX dst, vecX src1, vecX src2)
16833 %{
16834   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16835   match(Set dst (AddVS dst (MulVS src1 src2)));
16836   ins_cost(INSN_COST);
16837   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (8H)&quot; %}
16838   ins_encode %{
16839     __ mlav(as_FloatRegister($dst$$reg), __ T8H,
16840             as_FloatRegister($src1$$reg),
16841             as_FloatRegister($src2$$reg));
16842   %}
16843   ins_pipe(vmla128);
16844 %}
16845 
16846 instruct vmla2I(vecD dst, vecD src1, vecD src2)
16847 %{
16848   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16849   match(Set dst (AddVI dst (MulVI src1 src2)));
16850   ins_cost(INSN_COST);
16851   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (2S)&quot; %}
16852   ins_encode %{
16853     __ mlav(as_FloatRegister($dst$$reg), __ T2S,
16854             as_FloatRegister($src1$$reg),
16855             as_FloatRegister($src2$$reg));
16856   %}
16857   ins_pipe(vmla64);
16858 %}
16859 
16860 instruct vmla4I(vecX dst, vecX src1, vecX src2)
16861 %{
16862   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16863   match(Set dst (AddVI dst (MulVI src1 src2)));
16864   ins_cost(INSN_COST);
16865   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4S)&quot; %}
16866   ins_encode %{
16867     __ mlav(as_FloatRegister($dst$$reg), __ T4S,
16868             as_FloatRegister($src1$$reg),
16869             as_FloatRegister($src2$$reg));
16870   %}
16871   ins_pipe(vmla128);
16872 %}
16873 
16874 // dst + src1 * src2
16875 instruct vmla2F(vecD dst, vecD src1, vecD src2) %{
16876   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16877   match(Set dst (FmaVF  dst (Binary src1 src2)));
16878   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2S)&quot; %}
16879   ins_cost(INSN_COST);
16880   ins_encode %{
16881     __ fmla(as_FloatRegister($dst$$reg), __ T2S,
16882             as_FloatRegister($src1$$reg),
16883             as_FloatRegister($src2$$reg));
16884   %}
16885   ins_pipe(vmuldiv_fp64);
16886 %}
16887 
16888 // dst + src1 * src2
16889 instruct vmla4F(vecX dst, vecX src1, vecX src2) %{
16890   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16891   match(Set dst (FmaVF  dst (Binary src1 src2)));
16892   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (4S)&quot; %}
16893   ins_cost(INSN_COST);
16894   ins_encode %{
16895     __ fmla(as_FloatRegister($dst$$reg), __ T4S,
16896             as_FloatRegister($src1$$reg),
16897             as_FloatRegister($src2$$reg));
16898   %}
16899   ins_pipe(vmuldiv_fp128);
16900 %}
16901 
16902 // dst + src1 * src2
16903 instruct vmla2D(vecX dst, vecX src1, vecX src2) %{
16904   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16905   match(Set dst (FmaVD  dst (Binary src1 src2)));
16906   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2D)&quot; %}
16907   ins_cost(INSN_COST);
16908   ins_encode %{
16909     __ fmla(as_FloatRegister($dst$$reg), __ T2D,
16910             as_FloatRegister($src1$$reg),
16911             as_FloatRegister($src2$$reg));
16912   %}
16913   ins_pipe(vmuldiv_fp128);
16914 %}
16915 
16916 // --------------------------------- MLS --------------------------------------
16917 
16918 instruct vmls4S(vecD dst, vecD src1, vecD src2)
16919 %{
16920   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16921             n-&gt;as_Vector()-&gt;length() == 4);
16922   match(Set dst (SubVS dst (MulVS src1 src2)));
16923   ins_cost(INSN_COST);
16924   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16925   ins_encode %{
16926     __ mlsv(as_FloatRegister($dst$$reg), __ T4H,
16927             as_FloatRegister($src1$$reg),
16928             as_FloatRegister($src2$$reg));
16929   %}
16930   ins_pipe(vmla64);
16931 %}
16932 
16933 instruct vmls8S(vecX dst, vecX src1, vecX src2)
16934 %{
16935   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16936   match(Set dst (SubVS dst (MulVS src1 src2)));
16937   ins_cost(INSN_COST);
16938   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16939   ins_encode %{
16940     __ mlsv(as_FloatRegister($dst$$reg), __ T8H,
16941             as_FloatRegister($src1$$reg),
16942             as_FloatRegister($src2$$reg));
16943   %}
16944   ins_pipe(vmla128);
16945 %}
16946 
16947 instruct vmls2I(vecD dst, vecD src1, vecD src2)
16948 %{
16949   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16950   match(Set dst (SubVI dst (MulVI src1 src2)));
16951   ins_cost(INSN_COST);
16952   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16953   ins_encode %{
16954     __ mlsv(as_FloatRegister($dst$$reg), __ T2S,
16955             as_FloatRegister($src1$$reg),
16956             as_FloatRegister($src2$$reg));
16957   %}
16958   ins_pipe(vmla64);
16959 %}
16960 
16961 instruct vmls4I(vecX dst, vecX src1, vecX src2)
16962 %{
16963   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16964   match(Set dst (SubVI dst (MulVI src1 src2)));
16965   ins_cost(INSN_COST);
16966   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16967   ins_encode %{
16968     __ mlsv(as_FloatRegister($dst$$reg), __ T4S,
16969             as_FloatRegister($src1$$reg),
16970             as_FloatRegister($src2$$reg));
16971   %}
16972   ins_pipe(vmla128);
16973 %}
16974 
16975 // dst - src1 * src2
16976 instruct vmls2F(vecD dst, vecD src1, vecD src2) %{
16977   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16978   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16979   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16980   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2S)&quot; %}
16981   ins_cost(INSN_COST);
16982   ins_encode %{
16983     __ fmls(as_FloatRegister($dst$$reg), __ T2S,
16984             as_FloatRegister($src1$$reg),
16985             as_FloatRegister($src2$$reg));
16986   %}
16987   ins_pipe(vmuldiv_fp64);
16988 %}
16989 
16990 // dst - src1 * src2
16991 instruct vmls4F(vecX dst, vecX src1, vecX src2) %{
16992   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16993   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16994   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16995   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (4S)&quot; %}
16996   ins_cost(INSN_COST);
16997   ins_encode %{
16998     __ fmls(as_FloatRegister($dst$$reg), __ T4S,
16999             as_FloatRegister($src1$$reg),
17000             as_FloatRegister($src2$$reg));
17001   %}
17002   ins_pipe(vmuldiv_fp128);
17003 %}
17004 
17005 // dst - src1 * src2
17006 instruct vmls2D(vecX dst, vecX src1, vecX src2) %{
17007   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
17008   match(Set dst (FmaVD  dst (Binary (NegVD src1) src2)));
17009   match(Set dst (FmaVD  dst (Binary src1 (NegVD src2))));
17010   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2D)&quot; %}
17011   ins_cost(INSN_COST);
17012   ins_encode %{
17013     __ fmls(as_FloatRegister($dst$$reg), __ T2D,
17014             as_FloatRegister($src1$$reg),
17015             as_FloatRegister($src2$$reg));
17016   %}
17017   ins_pipe(vmuldiv_fp128);
17018 %}
17019 
17020 // --------------- Vector Multiply-Add Shorts into Integer --------------------
17021 
17022 instruct vmuladdS2I(vecX dst, vecX src1, vecX src2, vecX tmp) %{
17023   predicate(n-&gt;in(1)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_SHORT);
17024   match(Set dst (MulAddVS2VI src1 src2));
17025   ins_cost(INSN_COST);
17026   effect(TEMP_DEF dst, TEMP tmp);
17027   format %{ &quot;smullv  $tmp, $src1, $src2\t# vector (4H)\n\t&quot;
17028             &quot;smullv  $dst, $src1, $src2\t# vector (8H)\n\t&quot;
17029             &quot;addpv   $dst, $tmp, $dst\t# vector (4S)\n\t&quot; %}
17030   ins_encode %{
17031     __ smullv(as_FloatRegister($tmp$$reg), __ T4H,
17032               as_FloatRegister($src1$$reg),
17033               as_FloatRegister($src2$$reg));
17034     __ smullv(as_FloatRegister($dst$$reg), __ T8H,
17035               as_FloatRegister($src1$$reg),
17036               as_FloatRegister($src2$$reg));
17037     __ addpv(as_FloatRegister($dst$$reg), __ T4S,
17038              as_FloatRegister($tmp$$reg),
17039              as_FloatRegister($dst$$reg));
17040   %}
17041   ins_pipe(vmuldiv_fp128);
17042 %}
17043 
17044 // --------------------------------- DIV --------------------------------------
17045 
17046 instruct vdiv2F(vecD dst, vecD src1, vecD src2)
17047 %{
17048   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17049   match(Set dst (DivVF src1 src2));
17050   ins_cost(INSN_COST);
17051   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2S)&quot; %}
17052   ins_encode %{
17053     __ fdiv(as_FloatRegister($dst$$reg), __ T2S,
17054             as_FloatRegister($src1$$reg),
17055             as_FloatRegister($src2$$reg));
17056   %}
17057   ins_pipe(vmuldiv_fp64);
17058 %}
17059 
17060 instruct vdiv4F(vecX dst, vecX src1, vecX src2)
17061 %{
17062   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17063   match(Set dst (DivVF src1 src2));
17064   ins_cost(INSN_COST);
17065   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (4S)&quot; %}
17066   ins_encode %{
17067     __ fdiv(as_FloatRegister($dst$$reg), __ T4S,
17068             as_FloatRegister($src1$$reg),
17069             as_FloatRegister($src2$$reg));
17070   %}
17071   ins_pipe(vmuldiv_fp128);
17072 %}
17073 
17074 instruct vdiv2D(vecX dst, vecX src1, vecX src2)
17075 %{
17076   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17077   match(Set dst (DivVD src1 src2));
17078   ins_cost(INSN_COST);
17079   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2D)&quot; %}
17080   ins_encode %{
17081     __ fdiv(as_FloatRegister($dst$$reg), __ T2D,
17082             as_FloatRegister($src1$$reg),
17083             as_FloatRegister($src2$$reg));
17084   %}
17085   ins_pipe(vmuldiv_fp128);
17086 %}
17087 
17088 // --------------------------------- SQRT -------------------------------------
17089 
17090 instruct vsqrt2F(vecD dst, vecD src)
17091 %{
17092   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17093   match(Set dst (SqrtVF src));
17094   format %{ &quot;fsqrt  $dst, $src\t# vector (2F)&quot; %}
17095   ins_encode %{
17096     __ fsqrt(as_FloatRegister($dst$$reg), __ T2S, as_FloatRegister($src$$reg));
17097   %}
17098   ins_pipe(vunop_fp64);
17099 %}
17100 
17101 instruct vsqrt4F(vecX dst, vecX src)
17102 %{
17103   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17104   match(Set dst (SqrtVF src));
17105   format %{ &quot;fsqrt  $dst, $src\t# vector (4F)&quot; %}
17106   ins_encode %{
17107     __ fsqrt(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src$$reg));
17108   %}
17109   ins_pipe(vsqrt_fp128);
17110 %}
17111 
17112 instruct vsqrt2D(vecX dst, vecX src)
17113 %{
17114   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17115   match(Set dst (SqrtVD src));
17116   format %{ &quot;fsqrt  $dst, $src\t# vector (2D)&quot; %}
17117   ins_encode %{
17118     __ fsqrt(as_FloatRegister($dst$$reg), __ T2D,
17119              as_FloatRegister($src$$reg));
17120   %}
17121   ins_pipe(vsqrt_fp128);
17122 %}
17123 
17124 // --------------------------------- ABS --------------------------------------
17125 
17126 instruct vabs8B(vecD dst, vecD src)
17127 %{
17128   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17129             n-&gt;as_Vector()-&gt;length() == 8);
17130   match(Set dst (AbsVB src));
17131   ins_cost(INSN_COST);
17132   format %{ &quot;abs  $dst, $src\t# vector (8B)&quot; %}
17133   ins_encode %{
17134     __ absr(as_FloatRegister($dst$$reg), __ T8B, as_FloatRegister($src$$reg));
17135   %}
17136   ins_pipe(vlogical64);
17137 %}
17138 
17139 instruct vabs16B(vecX dst, vecX src)
17140 %{
17141   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17142   match(Set dst (AbsVB src));
17143   ins_cost(INSN_COST);
17144   format %{ &quot;abs  $dst, $src\t# vector (16B)&quot; %}
17145   ins_encode %{
17146     __ absr(as_FloatRegister($dst$$reg), __ T16B, as_FloatRegister($src$$reg));
17147   %}
17148   ins_pipe(vlogical128);
17149 %}
17150 
17151 instruct vabs4S(vecD dst, vecD src)
17152 %{
17153   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17154   match(Set dst (AbsVS src));
17155   ins_cost(INSN_COST);
17156   format %{ &quot;abs  $dst, $src\t# vector (4H)&quot; %}
17157   ins_encode %{
17158     __ absr(as_FloatRegister($dst$$reg), __ T4H, as_FloatRegister($src$$reg));
17159   %}
17160   ins_pipe(vlogical64);
17161 %}
17162 
17163 instruct vabs8S(vecX dst, vecX src)
17164 %{
17165   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17166   match(Set dst (AbsVS src));
17167   ins_cost(INSN_COST);
17168   format %{ &quot;abs  $dst, $src\t# vector (8H)&quot; %}
17169   ins_encode %{
17170     __ absr(as_FloatRegister($dst$$reg), __ T8H, as_FloatRegister($src$$reg));
17171   %}
17172   ins_pipe(vlogical128);
17173 %}
17174 
17175 instruct vabs2I(vecD dst, vecD src)
17176 %{
17177   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17178   match(Set dst (AbsVI src));
17179   ins_cost(INSN_COST);
17180   format %{ &quot;abs  $dst, $src\t# vector (2S)&quot; %}
17181   ins_encode %{
17182     __ absr(as_FloatRegister($dst$$reg), __ T2S, as_FloatRegister($src$$reg));
17183   %}
17184   ins_pipe(vlogical64);
17185 %}
17186 
17187 instruct vabs4I(vecX dst, vecX src)
17188 %{
17189   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17190   match(Set dst (AbsVI src));
17191   ins_cost(INSN_COST);
17192   format %{ &quot;abs  $dst, $src\t# vector (4S)&quot; %}
17193   ins_encode %{
17194     __ absr(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src$$reg));
17195   %}
17196   ins_pipe(vlogical128);
17197 %}
17198 
17199 instruct vabs2L(vecX dst, vecX src)
17200 %{
17201   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17202   match(Set dst (AbsVL src));
17203   ins_cost(INSN_COST);
17204   format %{ &quot;abs  $dst, $src\t# vector (2D)&quot; %}
17205   ins_encode %{
17206     __ absr(as_FloatRegister($dst$$reg), __ T2D, as_FloatRegister($src$$reg));
17207   %}
17208   ins_pipe(vlogical128);
17209 %}
17210 
17211 instruct vabs2F(vecD dst, vecD src)
17212 %{
17213   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17214   match(Set dst (AbsVF src));
17215   ins_cost(INSN_COST * 3);
17216   format %{ &quot;fabs  $dst,$src\t# vector (2S)&quot; %}
17217   ins_encode %{
17218     __ fabs(as_FloatRegister($dst$$reg), __ T2S,
17219             as_FloatRegister($src$$reg));
17220   %}
17221   ins_pipe(vunop_fp64);
17222 %}
17223 
17224 instruct vabs4F(vecX dst, vecX src)
17225 %{
17226   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17227   match(Set dst (AbsVF src));
17228   ins_cost(INSN_COST * 3);
17229   format %{ &quot;fabs  $dst,$src\t# vector (4S)&quot; %}
17230   ins_encode %{
17231     __ fabs(as_FloatRegister($dst$$reg), __ T4S,
17232             as_FloatRegister($src$$reg));
17233   %}
17234   ins_pipe(vunop_fp128);
17235 %}
17236 
17237 instruct vabs2D(vecX dst, vecX src)
17238 %{
17239   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17240   match(Set dst (AbsVD src));
17241   ins_cost(INSN_COST * 3);
17242   format %{ &quot;fabs  $dst,$src\t# vector (2D)&quot; %}
17243   ins_encode %{
17244     __ fabs(as_FloatRegister($dst$$reg), __ T2D,
17245             as_FloatRegister($src$$reg));
17246   %}
17247   ins_pipe(vunop_fp128);
17248 %}
17249 
17250 // --------------------------------- NEG --------------------------------------
17251 
17252 instruct vneg2F(vecD dst, vecD src)
17253 %{
17254   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17255   match(Set dst (NegVF src));
17256   ins_cost(INSN_COST * 3);
17257   format %{ &quot;fneg  $dst,$src\t# vector (2S)&quot; %}
17258   ins_encode %{
17259     __ fneg(as_FloatRegister($dst$$reg), __ T2S,
17260             as_FloatRegister($src$$reg));
17261   %}
17262   ins_pipe(vunop_fp64);
17263 %}
17264 
17265 instruct vneg4F(vecX dst, vecX src)
17266 %{
17267   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17268   match(Set dst (NegVF src));
17269   ins_cost(INSN_COST * 3);
17270   format %{ &quot;fneg  $dst,$src\t# vector (4S)&quot; %}
17271   ins_encode %{
17272     __ fneg(as_FloatRegister($dst$$reg), __ T4S,
17273             as_FloatRegister($src$$reg));
17274   %}
17275   ins_pipe(vunop_fp128);
17276 %}
17277 
17278 instruct vneg2D(vecX dst, vecX src)
17279 %{
17280   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17281   match(Set dst (NegVD src));
17282   ins_cost(INSN_COST * 3);
17283   format %{ &quot;fneg  $dst,$src\t# vector (2D)&quot; %}
17284   ins_encode %{
17285     __ fneg(as_FloatRegister($dst$$reg), __ T2D,
17286             as_FloatRegister($src$$reg));
17287   %}
17288   ins_pipe(vunop_fp128);
17289 %}
17290 
17291 // --------------------------------- AND --------------------------------------
17292 
17293 instruct vand8B(vecD dst, vecD src1, vecD src2)
17294 %{
17295   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17296             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17297   match(Set dst (AndV src1 src2));
17298   ins_cost(INSN_COST);
17299   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17300   ins_encode %{
17301     __ andr(as_FloatRegister($dst$$reg), __ T8B,
17302             as_FloatRegister($src1$$reg),
17303             as_FloatRegister($src2$$reg));
17304   %}
17305   ins_pipe(vlogical64);
17306 %}
17307 
17308 instruct vand16B(vecX dst, vecX src1, vecX src2)
17309 %{
17310   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17311   match(Set dst (AndV src1 src2));
17312   ins_cost(INSN_COST);
17313   format %{ &quot;and  $dst,$src1,$src2\t# vector (16B)&quot; %}
17314   ins_encode %{
17315     __ andr(as_FloatRegister($dst$$reg), __ T16B,
17316             as_FloatRegister($src1$$reg),
17317             as_FloatRegister($src2$$reg));
17318   %}
17319   ins_pipe(vlogical128);
17320 %}
17321 
17322 // --------------------------------- OR ---------------------------------------
17323 
17324 instruct vor8B(vecD dst, vecD src1, vecD src2)
17325 %{
17326   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17327             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17328   match(Set dst (OrV src1 src2));
17329   ins_cost(INSN_COST);
17330   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17331   ins_encode %{
17332     __ orr(as_FloatRegister($dst$$reg), __ T8B,
17333             as_FloatRegister($src1$$reg),
17334             as_FloatRegister($src2$$reg));
17335   %}
17336   ins_pipe(vlogical64);
17337 %}
17338 
17339 instruct vor16B(vecX dst, vecX src1, vecX src2)
17340 %{
17341   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17342   match(Set dst (OrV src1 src2));
17343   ins_cost(INSN_COST);
17344   format %{ &quot;orr  $dst,$src1,$src2\t# vector (16B)&quot; %}
17345   ins_encode %{
17346     __ orr(as_FloatRegister($dst$$reg), __ T16B,
17347             as_FloatRegister($src1$$reg),
17348             as_FloatRegister($src2$$reg));
17349   %}
17350   ins_pipe(vlogical128);
17351 %}
17352 
17353 // --------------------------------- XOR --------------------------------------
17354 
17355 instruct vxor8B(vecD dst, vecD src1, vecD src2)
17356 %{
17357   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17358             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17359   match(Set dst (XorV src1 src2));
17360   ins_cost(INSN_COST);
17361   format %{ &quot;xor  $dst,$src1,$src2\t# vector (8B)&quot; %}
17362   ins_encode %{
17363     __ eor(as_FloatRegister($dst$$reg), __ T8B,
17364             as_FloatRegister($src1$$reg),
17365             as_FloatRegister($src2$$reg));
17366   %}
17367   ins_pipe(vlogical64);
17368 %}
17369 
17370 instruct vxor16B(vecX dst, vecX src1, vecX src2)
17371 %{
17372   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17373   match(Set dst (XorV src1 src2));
17374   ins_cost(INSN_COST);
17375   format %{ &quot;xor  $dst,$src1,$src2\t# vector (16B)&quot; %}
17376   ins_encode %{
17377     __ eor(as_FloatRegister($dst$$reg), __ T16B,
17378             as_FloatRegister($src1$$reg),
17379             as_FloatRegister($src2$$reg));
17380   %}
17381   ins_pipe(vlogical128);
17382 %}
17383 
17384 // ------------------------------ Shift ---------------------------------------
17385 instruct vshiftcnt8B(vecD dst, iRegIorL2I cnt) %{
17386   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17387   match(Set dst (LShiftCntV cnt));
17388   match(Set dst (RShiftCntV cnt));
17389   format %{ &quot;dup  $dst, $cnt\t# shift count vector (8B)&quot; %}
17390   ins_encode %{
17391     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($cnt$$reg));
17392   %}
17393   ins_pipe(vdup_reg_reg64);
17394 %}
17395 
17396 instruct vshiftcnt16B(vecX dst, iRegIorL2I cnt) %{
17397   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17398   match(Set dst (LShiftCntV cnt));
17399   match(Set dst (RShiftCntV cnt));
17400   format %{ &quot;dup  $dst, $cnt\t# shift count vector (16B)&quot; %}
17401   ins_encode %{
17402     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($cnt$$reg));
17403   %}
17404   ins_pipe(vdup_reg_reg128);
17405 %}
17406 
17407 instruct vsll8B(vecD dst, vecD src, vecD shift) %{
17408   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17409             n-&gt;as_Vector()-&gt;length() == 8);
17410   match(Set dst (LShiftVB src shift));
17411   ins_cost(INSN_COST);
17412   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8B)&quot; %}
17413   ins_encode %{
17414     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17415             as_FloatRegister($src$$reg),
17416             as_FloatRegister($shift$$reg));
17417   %}
17418   ins_pipe(vshift64);
17419 %}
17420 
17421 instruct vsll16B(vecX dst, vecX src, vecX shift) %{
17422   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17423   match(Set dst (LShiftVB src shift));
17424   ins_cost(INSN_COST);
17425   format %{ &quot;sshl  $dst,$src,$shift\t# vector (16B)&quot; %}
17426   ins_encode %{
17427     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17428             as_FloatRegister($src$$reg),
17429             as_FloatRegister($shift$$reg));
17430   %}
17431   ins_pipe(vshift128);
17432 %}
17433 
17434 // Right shifts with vector shift count on aarch64 SIMD are implemented
17435 // as left shift by negative shift count.
17436 // There are two cases for vector shift count.
17437 //
17438 // Case 1: The vector shift count is from replication.
17439 //        |            |
17440 //    LoadVector  RShiftCntV
17441 //        |       /
17442 //     RShiftVI
17443 // Note: In inner loop, multiple neg instructions are used, which can be
17444 // moved to outer loop and merge into one neg instruction.
17445 //
17446 // Case 2: The vector shift count is from loading.
17447 // This case isn&#39;t supported by middle-end now. But it&#39;s supported by
17448 // panama/vectorIntrinsics(JEP 338: Vector API).
17449 //        |            |
17450 //    LoadVector  LoadVector
17451 //        |       /
17452 //     RShiftVI
17453 //
17454 
17455 instruct vsra8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17456   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17457             n-&gt;as_Vector()-&gt;length() == 8);
17458   match(Set dst (RShiftVB src shift));
17459   ins_cost(INSN_COST);
17460   effect(TEMP tmp);
17461   format %{ &quot;negr  $tmp,$shift\t&quot;
17462             &quot;sshl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17463   ins_encode %{
17464     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17465             as_FloatRegister($shift$$reg));
17466     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17467             as_FloatRegister($src$$reg),
17468             as_FloatRegister($tmp$$reg));
17469   %}
17470   ins_pipe(vshift64);
17471 %}
17472 
17473 instruct vsra16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17474   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17475   match(Set dst (RShiftVB src shift));
17476   ins_cost(INSN_COST);
17477   effect(TEMP tmp);
17478   format %{ &quot;negr  $tmp,$shift\t&quot;
17479             &quot;sshl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17480   ins_encode %{
17481     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17482             as_FloatRegister($shift$$reg));
17483     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17484             as_FloatRegister($src$$reg),
17485             as_FloatRegister($tmp$$reg));
17486   %}
17487   ins_pipe(vshift128);
17488 %}
17489 
17490 instruct vsrl8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17491   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17492             n-&gt;as_Vector()-&gt;length() == 8);
17493   match(Set dst (URShiftVB src shift));
17494   ins_cost(INSN_COST);
17495   effect(TEMP tmp);
17496   format %{ &quot;negr  $tmp,$shift\t&quot;
17497             &quot;ushl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17498   ins_encode %{
17499     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17500             as_FloatRegister($shift$$reg));
17501     __ ushl(as_FloatRegister($dst$$reg), __ T8B,
17502             as_FloatRegister($src$$reg),
17503             as_FloatRegister($tmp$$reg));
17504   %}
17505   ins_pipe(vshift64);
17506 %}
17507 
17508 instruct vsrl16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17509   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17510   match(Set dst (URShiftVB src shift));
17511   ins_cost(INSN_COST);
17512   effect(TEMP tmp);
17513   format %{ &quot;negr  $tmp,$shift\t&quot;
17514             &quot;ushl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17515   ins_encode %{
17516     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17517             as_FloatRegister($shift$$reg));
17518     __ ushl(as_FloatRegister($dst$$reg), __ T16B,
17519             as_FloatRegister($src$$reg),
17520             as_FloatRegister($tmp$$reg));
17521   %}
17522   ins_pipe(vshift128);
17523 %}
17524 
17525 instruct vsll8B_imm(vecD dst, vecD src, immI shift) %{
17526   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17527             n-&gt;as_Vector()-&gt;length() == 8);
17528   match(Set dst (LShiftVB src (LShiftCntV shift)));
17529   ins_cost(INSN_COST);
17530   format %{ &quot;shl    $dst, $src, $shift\t# vector (8B)&quot; %}
17531   ins_encode %{
17532     int sh = (int)$shift$$constant;
17533     if (sh &gt;= 8) {
17534       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17535              as_FloatRegister($src$$reg),
17536              as_FloatRegister($src$$reg));
17537     } else {
17538       __ shl(as_FloatRegister($dst$$reg), __ T8B,
17539              as_FloatRegister($src$$reg), sh);
17540     }
17541   %}
17542   ins_pipe(vshift64_imm);
17543 %}
17544 
17545 instruct vsll16B_imm(vecX dst, vecX src, immI shift) %{
17546   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17547   match(Set dst (LShiftVB src (LShiftCntV shift)));
17548   ins_cost(INSN_COST);
17549   format %{ &quot;shl    $dst, $src, $shift\t# vector (16B)&quot; %}
17550   ins_encode %{
17551     int sh = (int)$shift$$constant;
17552     if (sh &gt;= 8) {
17553       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17554              as_FloatRegister($src$$reg),
17555              as_FloatRegister($src$$reg));
17556     } else {
17557       __ shl(as_FloatRegister($dst$$reg), __ T16B,
17558              as_FloatRegister($src$$reg), sh);
17559     }
17560   %}
17561   ins_pipe(vshift128_imm);
17562 %}
17563 
17564 instruct vsra8B_imm(vecD dst, vecD src, immI shift) %{
17565   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17566             n-&gt;as_Vector()-&gt;length() == 8);
17567   match(Set dst (RShiftVB src (RShiftCntV shift)));
17568   ins_cost(INSN_COST);
17569   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8B)&quot; %}
17570   ins_encode %{
17571     int sh = (int)$shift$$constant;
17572     if (sh &gt;= 8) sh = 7;
17573     __ sshr(as_FloatRegister($dst$$reg), __ T8B,
17574            as_FloatRegister($src$$reg), sh);
17575   %}
17576   ins_pipe(vshift64_imm);
17577 %}
17578 
17579 instruct vsra16B_imm(vecX dst, vecX src, immI shift) %{
17580   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17581   match(Set dst (RShiftVB src (RShiftCntV shift)));
17582   ins_cost(INSN_COST);
17583   format %{ &quot;sshr    $dst, $src, $shift\t# vector (16B)&quot; %}
17584   ins_encode %{
17585     int sh = (int)$shift$$constant;
17586     if (sh &gt;= 8) sh = 7;
17587     __ sshr(as_FloatRegister($dst$$reg), __ T16B,
17588            as_FloatRegister($src$$reg), sh);
17589   %}
17590   ins_pipe(vshift128_imm);
17591 %}
17592 
17593 instruct vsrl8B_imm(vecD dst, vecD src, immI shift) %{
17594   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17595             n-&gt;as_Vector()-&gt;length() == 8);
17596   match(Set dst (URShiftVB src (RShiftCntV shift)));
17597   ins_cost(INSN_COST);
17598   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8B)&quot; %}
17599   ins_encode %{
17600     int sh = (int)$shift$$constant;
17601     if (sh &gt;= 8) {
17602       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17603              as_FloatRegister($src$$reg),
17604              as_FloatRegister($src$$reg));
17605     } else {
17606       __ ushr(as_FloatRegister($dst$$reg), __ T8B,
17607              as_FloatRegister($src$$reg), sh);
17608     }
17609   %}
17610   ins_pipe(vshift64_imm);
17611 %}
17612 
17613 instruct vsrl16B_imm(vecX dst, vecX src, immI shift) %{
17614   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17615   match(Set dst (URShiftVB src (RShiftCntV shift)));
17616   ins_cost(INSN_COST);
17617   format %{ &quot;ushr    $dst, $src, $shift\t# vector (16B)&quot; %}
17618   ins_encode %{
17619     int sh = (int)$shift$$constant;
17620     if (sh &gt;= 8) {
17621       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17622              as_FloatRegister($src$$reg),
17623              as_FloatRegister($src$$reg));
17624     } else {
17625       __ ushr(as_FloatRegister($dst$$reg), __ T16B,
17626              as_FloatRegister($src$$reg), sh);
17627     }
17628   %}
17629   ins_pipe(vshift128_imm);
17630 %}
17631 
17632 instruct vsll4S(vecD dst, vecD src, vecD shift) %{
17633   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17634             n-&gt;as_Vector()-&gt;length() == 4);
17635   match(Set dst (LShiftVS src shift));
17636   ins_cost(INSN_COST);
17637   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4H)&quot; %}
17638   ins_encode %{
17639     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17640             as_FloatRegister($src$$reg),
17641             as_FloatRegister($shift$$reg));
17642   %}
17643   ins_pipe(vshift64);
17644 %}
17645 
17646 instruct vsll8S(vecX dst, vecX src, vecX shift) %{
17647   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17648   match(Set dst (LShiftVS src shift));
17649   ins_cost(INSN_COST);
17650   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8H)&quot; %}
17651   ins_encode %{
17652     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17653             as_FloatRegister($src$$reg),
17654             as_FloatRegister($shift$$reg));
17655   %}
17656   ins_pipe(vshift128);
17657 %}
17658 
17659 instruct vsra4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17660   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17661             n-&gt;as_Vector()-&gt;length() == 4);
17662   match(Set dst (RShiftVS src shift));
17663   ins_cost(INSN_COST);
17664   effect(TEMP tmp);
17665   format %{ &quot;negr  $tmp,$shift\t&quot;
17666             &quot;sshl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17667   ins_encode %{
17668     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17669             as_FloatRegister($shift$$reg));
17670     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17671             as_FloatRegister($src$$reg),
17672             as_FloatRegister($tmp$$reg));
17673   %}
17674   ins_pipe(vshift64);
17675 %}
17676 
17677 instruct vsra8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17678   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17679   match(Set dst (RShiftVS src shift));
17680   ins_cost(INSN_COST);
17681   effect(TEMP tmp);
17682   format %{ &quot;negr  $tmp,$shift\t&quot;
17683             &quot;sshl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17684   ins_encode %{
17685     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17686             as_FloatRegister($shift$$reg));
17687     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17688             as_FloatRegister($src$$reg),
17689             as_FloatRegister($tmp$$reg));
17690   %}
17691   ins_pipe(vshift128);
17692 %}
17693 
17694 instruct vsrl4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17695   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17696             n-&gt;as_Vector()-&gt;length() == 4);
17697   match(Set dst (URShiftVS src shift));
17698   ins_cost(INSN_COST);
17699   effect(TEMP tmp);
17700   format %{ &quot;negr  $tmp,$shift\t&quot;
17701             &quot;ushl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17702   ins_encode %{
17703     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17704             as_FloatRegister($shift$$reg));
17705     __ ushl(as_FloatRegister($dst$$reg), __ T4H,
17706             as_FloatRegister($src$$reg),
17707             as_FloatRegister($tmp$$reg));
17708   %}
17709   ins_pipe(vshift64);
17710 %}
17711 
17712 instruct vsrl8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17713   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17714   match(Set dst (URShiftVS src shift));
17715   ins_cost(INSN_COST);
17716   effect(TEMP tmp);
17717   format %{ &quot;negr  $tmp,$shift\t&quot;
17718             &quot;ushl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17719   ins_encode %{
17720     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17721             as_FloatRegister($shift$$reg));
17722     __ ushl(as_FloatRegister($dst$$reg), __ T8H,
17723             as_FloatRegister($src$$reg),
17724             as_FloatRegister($tmp$$reg));
17725   %}
17726   ins_pipe(vshift128);
17727 %}
17728 
17729 instruct vsll4S_imm(vecD dst, vecD src, immI shift) %{
17730   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17731             n-&gt;as_Vector()-&gt;length() == 4);
17732   match(Set dst (LShiftVS src (LShiftCntV shift)));
17733   ins_cost(INSN_COST);
17734   format %{ &quot;shl    $dst, $src, $shift\t# vector (4H)&quot; %}
17735   ins_encode %{
17736     int sh = (int)$shift$$constant;
17737     if (sh &gt;= 16) {
17738       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17739              as_FloatRegister($src$$reg),
17740              as_FloatRegister($src$$reg));
17741     } else {
17742       __ shl(as_FloatRegister($dst$$reg), __ T4H,
17743              as_FloatRegister($src$$reg), sh);
17744     }
17745   %}
17746   ins_pipe(vshift64_imm);
17747 %}
17748 
17749 instruct vsll8S_imm(vecX dst, vecX src, immI shift) %{
17750   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17751   match(Set dst (LShiftVS src (LShiftCntV shift)));
17752   ins_cost(INSN_COST);
17753   format %{ &quot;shl    $dst, $src, $shift\t# vector (8H)&quot; %}
17754   ins_encode %{
17755     int sh = (int)$shift$$constant;
17756     if (sh &gt;= 16) {
17757       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17758              as_FloatRegister($src$$reg),
17759              as_FloatRegister($src$$reg));
17760     } else {
17761       __ shl(as_FloatRegister($dst$$reg), __ T8H,
17762              as_FloatRegister($src$$reg), sh);
17763     }
17764   %}
17765   ins_pipe(vshift128_imm);
17766 %}
17767 
17768 instruct vsra4S_imm(vecD dst, vecD src, immI shift) %{
17769   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17770             n-&gt;as_Vector()-&gt;length() == 4);
17771   match(Set dst (RShiftVS src (RShiftCntV shift)));
17772   ins_cost(INSN_COST);
17773   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4H)&quot; %}
17774   ins_encode %{
17775     int sh = (int)$shift$$constant;
17776     if (sh &gt;= 16) sh = 15;
17777     __ sshr(as_FloatRegister($dst$$reg), __ T4H,
17778            as_FloatRegister($src$$reg), sh);
17779   %}
17780   ins_pipe(vshift64_imm);
17781 %}
17782 
17783 instruct vsra8S_imm(vecX dst, vecX src, immI shift) %{
17784   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17785   match(Set dst (RShiftVS src (RShiftCntV shift)));
17786   ins_cost(INSN_COST);
17787   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8H)&quot; %}
17788   ins_encode %{
17789     int sh = (int)$shift$$constant;
17790     if (sh &gt;= 16) sh = 15;
17791     __ sshr(as_FloatRegister($dst$$reg), __ T8H,
17792            as_FloatRegister($src$$reg), sh);
17793   %}
17794   ins_pipe(vshift128_imm);
17795 %}
17796 
17797 instruct vsrl4S_imm(vecD dst, vecD src, immI shift) %{
17798   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17799             n-&gt;as_Vector()-&gt;length() == 4);
17800   match(Set dst (URShiftVS src (RShiftCntV shift)));
17801   ins_cost(INSN_COST);
17802   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4H)&quot; %}
17803   ins_encode %{
17804     int sh = (int)$shift$$constant;
17805     if (sh &gt;= 16) {
17806       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17807              as_FloatRegister($src$$reg),
17808              as_FloatRegister($src$$reg));
17809     } else {
17810       __ ushr(as_FloatRegister($dst$$reg), __ T4H,
17811              as_FloatRegister($src$$reg), sh);
17812     }
17813   %}
17814   ins_pipe(vshift64_imm);
17815 %}
17816 
17817 instruct vsrl8S_imm(vecX dst, vecX src, immI shift) %{
17818   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17819   match(Set dst (URShiftVS src (RShiftCntV shift)));
17820   ins_cost(INSN_COST);
17821   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8H)&quot; %}
17822   ins_encode %{
17823     int sh = (int)$shift$$constant;
17824     if (sh &gt;= 16) {
17825       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17826              as_FloatRegister($src$$reg),
17827              as_FloatRegister($src$$reg));
17828     } else {
17829       __ ushr(as_FloatRegister($dst$$reg), __ T8H,
17830              as_FloatRegister($src$$reg), sh);
17831     }
17832   %}
17833   ins_pipe(vshift128_imm);
17834 %}
17835 
17836 instruct vsll2I(vecD dst, vecD src, vecD shift) %{
17837   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17838   match(Set dst (LShiftVI src shift));
17839   ins_cost(INSN_COST);
17840   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2S)&quot; %}
17841   ins_encode %{
17842     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17843             as_FloatRegister($src$$reg),
17844             as_FloatRegister($shift$$reg));
17845   %}
17846   ins_pipe(vshift64);
17847 %}
17848 
17849 instruct vsll4I(vecX dst, vecX src, vecX shift) %{
17850   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17851   match(Set dst (LShiftVI src shift));
17852   ins_cost(INSN_COST);
17853   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4S)&quot; %}
17854   ins_encode %{
17855     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17856             as_FloatRegister($src$$reg),
17857             as_FloatRegister($shift$$reg));
17858   %}
17859   ins_pipe(vshift128);
17860 %}
17861 
17862 instruct vsra2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17863   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17864   match(Set dst (RShiftVI src shift));
17865   ins_cost(INSN_COST);
17866   effect(TEMP tmp);
17867   format %{ &quot;negr  $tmp,$shift\t&quot;
17868             &quot;sshl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17869   ins_encode %{
17870     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17871             as_FloatRegister($shift$$reg));
17872     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17873             as_FloatRegister($src$$reg),
17874             as_FloatRegister($tmp$$reg));
17875   %}
17876   ins_pipe(vshift64);
17877 %}
17878 
17879 instruct vsra4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17880   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17881   match(Set dst (RShiftVI src shift));
17882   ins_cost(INSN_COST);
17883   effect(TEMP tmp);
17884   format %{ &quot;negr  $tmp,$shift\t&quot;
17885             &quot;sshl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17886   ins_encode %{
17887     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17888             as_FloatRegister($shift$$reg));
17889     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17890             as_FloatRegister($src$$reg),
17891             as_FloatRegister($tmp$$reg));
17892   %}
17893   ins_pipe(vshift128);
17894 %}
17895 
17896 instruct vsrl2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17897   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17898   match(Set dst (URShiftVI src shift));
17899   ins_cost(INSN_COST);
17900   effect(TEMP tmp);
17901   format %{ &quot;negr  $tmp,$shift\t&quot;
17902             &quot;ushl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17903   ins_encode %{
17904     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17905             as_FloatRegister($shift$$reg));
17906     __ ushl(as_FloatRegister($dst$$reg), __ T2S,
17907             as_FloatRegister($src$$reg),
17908             as_FloatRegister($tmp$$reg));
17909   %}
17910   ins_pipe(vshift64);
17911 %}
17912 
17913 instruct vsrl4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17914   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17915   match(Set dst (URShiftVI src shift));
17916   ins_cost(INSN_COST);
17917   effect(TEMP tmp);
17918   format %{ &quot;negr  $tmp,$shift\t&quot;
17919             &quot;ushl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17920   ins_encode %{
17921     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17922             as_FloatRegister($shift$$reg));
17923     __ ushl(as_FloatRegister($dst$$reg), __ T4S,
17924             as_FloatRegister($src$$reg),
17925             as_FloatRegister($tmp$$reg));
17926   %}
17927   ins_pipe(vshift128);
17928 %}
17929 
17930 instruct vsll2I_imm(vecD dst, vecD src, immI shift) %{
17931   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17932   match(Set dst (LShiftVI src (LShiftCntV shift)));
17933   ins_cost(INSN_COST);
17934   format %{ &quot;shl    $dst, $src, $shift\t# vector (2S)&quot; %}
17935   ins_encode %{
17936     __ shl(as_FloatRegister($dst$$reg), __ T2S,
17937            as_FloatRegister($src$$reg),
17938            (int)$shift$$constant);
17939   %}
17940   ins_pipe(vshift64_imm);
17941 %}
17942 
17943 instruct vsll4I_imm(vecX dst, vecX src, immI shift) %{
17944   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17945   match(Set dst (LShiftVI src (LShiftCntV shift)));
17946   ins_cost(INSN_COST);
17947   format %{ &quot;shl    $dst, $src, $shift\t# vector (4S)&quot; %}
17948   ins_encode %{
17949     __ shl(as_FloatRegister($dst$$reg), __ T4S,
17950            as_FloatRegister($src$$reg),
17951            (int)$shift$$constant);
17952   %}
17953   ins_pipe(vshift128_imm);
17954 %}
17955 
17956 instruct vsra2I_imm(vecD dst, vecD src, immI shift) %{
17957   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17958   match(Set dst (RShiftVI src (RShiftCntV shift)));
17959   ins_cost(INSN_COST);
17960   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2S)&quot; %}
17961   ins_encode %{
17962     __ sshr(as_FloatRegister($dst$$reg), __ T2S,
17963             as_FloatRegister($src$$reg),
17964             (int)$shift$$constant);
17965   %}
17966   ins_pipe(vshift64_imm);
17967 %}
17968 
17969 instruct vsra4I_imm(vecX dst, vecX src, immI shift) %{
17970   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17971   match(Set dst (RShiftVI src (RShiftCntV shift)));
17972   ins_cost(INSN_COST);
17973   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4S)&quot; %}
17974   ins_encode %{
17975     __ sshr(as_FloatRegister($dst$$reg), __ T4S,
17976             as_FloatRegister($src$$reg),
17977             (int)$shift$$constant);
17978   %}
17979   ins_pipe(vshift128_imm);
17980 %}
17981 
17982 instruct vsrl2I_imm(vecD dst, vecD src, immI shift) %{
17983   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17984   match(Set dst (URShiftVI src (RShiftCntV shift)));
17985   ins_cost(INSN_COST);
17986   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2S)&quot; %}
17987   ins_encode %{
17988     __ ushr(as_FloatRegister($dst$$reg), __ T2S,
17989             as_FloatRegister($src$$reg),
17990             (int)$shift$$constant);
17991   %}
17992   ins_pipe(vshift64_imm);
17993 %}
17994 
17995 instruct vsrl4I_imm(vecX dst, vecX src, immI shift) %{
17996   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17997   match(Set dst (URShiftVI src (RShiftCntV shift)));
17998   ins_cost(INSN_COST);
17999   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4S)&quot; %}
18000   ins_encode %{
18001     __ ushr(as_FloatRegister($dst$$reg), __ T4S,
18002             as_FloatRegister($src$$reg),
18003             (int)$shift$$constant);
18004   %}
18005   ins_pipe(vshift128_imm);
18006 %}
18007 
18008 instruct vsll2L(vecX dst, vecX src, vecX shift) %{
18009   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18010   match(Set dst (LShiftVL src shift));
18011   ins_cost(INSN_COST);
18012   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2D)&quot; %}
18013   ins_encode %{
18014     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
18015             as_FloatRegister($src$$reg),
18016             as_FloatRegister($shift$$reg));
18017   %}
18018   ins_pipe(vshift128);
18019 %}
18020 
18021 instruct vsra2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
18022   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18023   match(Set dst (RShiftVL src shift));
18024   ins_cost(INSN_COST);
18025   effect(TEMP tmp);
18026   format %{ &quot;negr  $tmp,$shift\t&quot;
18027             &quot;sshl  $dst,$src,$tmp\t# vector (2D)&quot; %}
18028   ins_encode %{
18029     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
18030             as_FloatRegister($shift$$reg));
18031     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
18032             as_FloatRegister($src$$reg),
18033             as_FloatRegister($tmp$$reg));
18034   %}
18035   ins_pipe(vshift128);
18036 %}
18037 
18038 instruct vsrl2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
18039   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18040   match(Set dst (URShiftVL src shift));
18041   ins_cost(INSN_COST);
18042   effect(TEMP tmp);
18043   format %{ &quot;negr  $tmp,$shift\t&quot;
18044             &quot;ushl  $dst,$src,$tmp\t# vector (2D)&quot; %}
18045   ins_encode %{
18046     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
18047             as_FloatRegister($shift$$reg));
18048     __ ushl(as_FloatRegister($dst$$reg), __ T2D,
18049             as_FloatRegister($src$$reg),
18050             as_FloatRegister($tmp$$reg));
18051   %}
18052   ins_pipe(vshift128);
18053 %}
18054 
18055 instruct vsll2L_imm(vecX dst, vecX src, immI shift) %{
18056   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18057   match(Set dst (LShiftVL src (LShiftCntV shift)));
18058   ins_cost(INSN_COST);
18059   format %{ &quot;shl    $dst, $src, $shift\t# vector (2D)&quot; %}
18060   ins_encode %{
18061     __ shl(as_FloatRegister($dst$$reg), __ T2D,
18062            as_FloatRegister($src$$reg),
18063            (int)$shift$$constant);
18064   %}
18065   ins_pipe(vshift128_imm);
18066 %}
18067 
18068 instruct vsra2L_imm(vecX dst, vecX src, immI shift) %{
18069   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18070   match(Set dst (RShiftVL src (RShiftCntV shift)));
18071   ins_cost(INSN_COST);
18072   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2D)&quot; %}
18073   ins_encode %{
18074     __ sshr(as_FloatRegister($dst$$reg), __ T2D,
18075             as_FloatRegister($src$$reg),
18076             (int)$shift$$constant);
18077   %}
18078   ins_pipe(vshift128_imm);
18079 %}
18080 
18081 instruct vsrl2L_imm(vecX dst, vecX src, immI shift) %{
18082   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18083   match(Set dst (URShiftVL src (RShiftCntV shift)));
18084   ins_cost(INSN_COST);
18085   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2D)&quot; %}
18086   ins_encode %{
18087     __ ushr(as_FloatRegister($dst$$reg), __ T2D,
18088             as_FloatRegister($src$$reg),
18089             (int)$shift$$constant);
18090   %}
18091   ins_pipe(vshift128_imm);
18092 %}
18093 
18094 instruct vmax2F(vecD dst, vecD src1, vecD src2)
18095 %{
18096   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18097   match(Set dst (MaxV src1 src2));
18098   ins_cost(INSN_COST);
18099   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2F)&quot; %}
18100   ins_encode %{
18101     __ fmax(as_FloatRegister($dst$$reg), __ T2S,
18102             as_FloatRegister($src1$$reg),
18103             as_FloatRegister($src2$$reg));
18104   %}
18105   ins_pipe(vdop_fp64);
18106 %}
18107 
18108 instruct vmax4F(vecX dst, vecX src1, vecX src2)
18109 %{
18110   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18111   match(Set dst (MaxV src1 src2));
18112   ins_cost(INSN_COST);
18113   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (4S)&quot; %}
18114   ins_encode %{
18115     __ fmax(as_FloatRegister($dst$$reg), __ T4S,
18116             as_FloatRegister($src1$$reg),
18117             as_FloatRegister($src2$$reg));
18118   %}
18119   ins_pipe(vdop_fp128);
18120 %}
18121 
18122 instruct vmax2D(vecX dst, vecX src1, vecX src2)
18123 %{
18124   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18125   match(Set dst (MaxV src1 src2));
18126   ins_cost(INSN_COST);
18127   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2D)&quot; %}
18128   ins_encode %{
18129     __ fmax(as_FloatRegister($dst$$reg), __ T2D,
18130             as_FloatRegister($src1$$reg),
18131             as_FloatRegister($src2$$reg));
18132   %}
18133   ins_pipe(vdop_fp128);
18134 %}
18135 
18136 instruct vmin2F(vecD dst, vecD src1, vecD src2)
18137 %{
18138   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18139   match(Set dst (MinV src1 src2));
18140   ins_cost(INSN_COST);
18141   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2F)&quot; %}
18142   ins_encode %{
18143     __ fmin(as_FloatRegister($dst$$reg), __ T2S,
18144             as_FloatRegister($src1$$reg),
18145             as_FloatRegister($src2$$reg));
18146   %}
18147   ins_pipe(vdop_fp64);
18148 %}
18149 
18150 instruct vmin4F(vecX dst, vecX src1, vecX src2)
18151 %{
18152   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18153   match(Set dst (MinV src1 src2));
18154   ins_cost(INSN_COST);
18155   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (4S)&quot; %}
18156   ins_encode %{
18157     __ fmin(as_FloatRegister($dst$$reg), __ T4S,
18158             as_FloatRegister($src1$$reg),
18159             as_FloatRegister($src2$$reg));
18160   %}
18161   ins_pipe(vdop_fp128);
18162 %}
18163 
18164 instruct vmin2D(vecX dst, vecX src1, vecX src2)
18165 %{
18166   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18167   match(Set dst (MinV src1 src2));
18168   ins_cost(INSN_COST);
18169   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2D)&quot; %}
18170   ins_encode %{
18171     __ fmin(as_FloatRegister($dst$$reg), __ T2D,
18172             as_FloatRegister($src1$$reg),
18173             as_FloatRegister($src2$$reg));
18174   %}
18175   ins_pipe(vdop_fp128);
18176 %}
18177 
18178 instruct vround2D_reg(vecX dst, vecX src, immI rmode) %{
18179   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18180   match(Set dst (RoundDoubleModeV src rmode));
18181   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
18182   ins_encode %{
18183     switch ($rmode$$constant) {
18184       case RoundDoubleModeNode::rmode_rint:
18185         __ frintn(as_FloatRegister($dst$$reg), __ T2D,
18186                   as_FloatRegister($src$$reg));
18187         break;
18188       case RoundDoubleModeNode::rmode_floor:
18189         __ frintm(as_FloatRegister($dst$$reg), __ T2D,
18190                   as_FloatRegister($src$$reg));
18191         break;
18192       case RoundDoubleModeNode::rmode_ceil:
18193         __ frintp(as_FloatRegister($dst$$reg), __ T2D,
18194                   as_FloatRegister($src$$reg));
18195         break;
18196     }
18197   %}
18198   ins_pipe(vdop_fp128);
18199 %}
18200 
18201 instruct vpopcount4I(vecX dst, vecX src) %{
18202   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
18203   match(Set dst (PopCountVI src));
18204   format %{
18205     &quot;cnt     $dst, $src\t# vector (16B)\n\t&quot;
18206     &quot;uaddlp  $dst, $dst\t# vector (16B)\n\t&quot;
18207     &quot;uaddlp  $dst, $dst\t# vector (8H)&quot;
18208   %}
18209   ins_encode %{
18210      __ cnt(as_FloatRegister($dst$$reg), __ T16B,
18211             as_FloatRegister($src$$reg));
18212      __ uaddlp(as_FloatRegister($dst$$reg), __ T16B,
18213                as_FloatRegister($dst$$reg));
18214      __ uaddlp(as_FloatRegister($dst$$reg), __ T8H,
18215                as_FloatRegister($dst$$reg));
18216   %}
18217   ins_pipe(pipe_class_default);
18218 %}
18219 
18220 instruct vpopcount2I(vecD dst, vecD src) %{
18221   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
18222   match(Set dst (PopCountVI src));
18223   format %{
18224     &quot;cnt     $dst, $src\t# vector (8B)\n\t&quot;
18225     &quot;uaddlp  $dst, $dst\t# vector (8B)\n\t&quot;
18226     &quot;uaddlp  $dst, $dst\t# vector (4H)&quot;
18227   %}
18228   ins_encode %{
18229      __ cnt(as_FloatRegister($dst$$reg), __ T8B,
18230             as_FloatRegister($src$$reg));
18231      __ uaddlp(as_FloatRegister($dst$$reg), __ T8B,
18232                as_FloatRegister($dst$$reg));
18233      __ uaddlp(as_FloatRegister($dst$$reg), __ T4H,
18234                as_FloatRegister($dst$$reg));
18235   %}
18236   ins_pipe(pipe_class_default);
18237 %}
18238 
18239 //----------PEEPHOLE RULES-----------------------------------------------------
18240 // These must follow all instruction definitions as they use the names
18241 // defined in the instructions definitions.
18242 //
18243 // peepmatch ( root_instr_name [preceding_instruction]* );
18244 //
18245 // peepconstraint %{
18246 // (instruction_number.operand_name relational_op instruction_number.operand_name
18247 //  [, ...] );
18248 // // instruction numbers are zero-based using left to right order in peepmatch
18249 //
18250 // peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
18251 // // provide an instruction_number.operand_name for each operand that appears
18252 // // in the replacement instruction&#39;s match rule
18253 //
18254 // ---------VM FLAGS---------------------------------------------------------
18255 //
18256 // All peephole optimizations can be turned off using -XX:-OptoPeephole
18257 //
18258 // Each peephole rule is given an identifying number starting with zero and
18259 // increasing by one in the order seen by the parser.  An individual peephole
18260 // can be enabled, and all others disabled, by using -XX:OptoPeepholeAt=#
18261 // on the command-line.
18262 //
18263 // ---------CURRENT LIMITATIONS----------------------------------------------
18264 //
18265 // Only match adjacent instructions in same basic block
18266 // Only equality constraints
18267 // Only constraints between operands, not (0.dest_reg == RAX_enc)
18268 // Only one replacement instruction
18269 //
18270 // ---------EXAMPLE----------------------------------------------------------
18271 //
18272 // // pertinent parts of existing instructions in architecture description
18273 // instruct movI(iRegINoSp dst, iRegI src)
18274 // %{
18275 //   match(Set dst (CopyI src));
18276 // %}
18277 //
18278 // instruct incI_iReg(iRegINoSp dst, immI1 src, rFlagsReg cr)
18279 // %{
18280 //   match(Set dst (AddI dst src));
18281 //   effect(KILL cr);
18282 // %}
18283 //
18284 // // Change (inc mov) to lea
18285 // peephole %{
18286 //   // increment preceeded by register-register move
18287 //   peepmatch ( incI_iReg movI );
18288 //   // require that the destination register of the increment
18289 //   // match the destination register of the move
18290 //   peepconstraint ( 0.dst == 1.dst );
18291 //   // construct a replacement instruction that sets
18292 //   // the destination to ( move&#39;s source register + one )
18293 //   peepreplace ( leaI_iReg_immI( 0.dst 1.src 0.src ) );
18294 // %}
18295 //
18296 
18297 // Implementation no longer uses movX instructions since
18298 // machine-independent system no longer uses CopyX nodes.
18299 //
18300 // peephole
18301 // %{
18302 //   peepmatch (incI_iReg movI);
18303 //   peepconstraint (0.dst == 1.dst);
18304 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18305 // %}
18306 
18307 // peephole
18308 // %{
18309 //   peepmatch (decI_iReg movI);
18310 //   peepconstraint (0.dst == 1.dst);
18311 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18312 // %}
18313 
18314 // peephole
18315 // %{
18316 //   peepmatch (addI_iReg_imm movI);
18317 //   peepconstraint (0.dst == 1.dst);
18318 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18319 // %}
18320 
18321 // peephole
18322 // %{
18323 //   peepmatch (incL_iReg movL);
18324 //   peepconstraint (0.dst == 1.dst);
18325 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18326 // %}
18327 
18328 // peephole
18329 // %{
18330 //   peepmatch (decL_iReg movL);
18331 //   peepconstraint (0.dst == 1.dst);
18332 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18333 // %}
18334 
18335 // peephole
18336 // %{
18337 //   peepmatch (addL_iReg_imm movL);
18338 //   peepconstraint (0.dst == 1.dst);
18339 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18340 // %}
18341 
18342 // peephole
18343 // %{
18344 //   peepmatch (addP_iReg_imm movP);
18345 //   peepconstraint (0.dst == 1.dst);
18346 //   peepreplace (leaP_iReg_imm(0.dst 1.src 0.src));
18347 // %}
18348 
18349 // // Change load of spilled value to only a spill
18350 // instruct storeI(memory mem, iRegI src)
18351 // %{
18352 //   match(Set mem (StoreI mem src));
18353 // %}
18354 //
18355 // instruct loadI(iRegINoSp dst, memory mem)
18356 // %{
18357 //   match(Set dst (LoadI mem));
18358 // %}
18359 //
18360 
18361 //----------SMARTSPILL RULES---------------------------------------------------
18362 // These must follow all instruction definitions as they use the names
18363 // defined in the instructions definitions.
18364 
18365 // Local Variables:
18366 // mode: c++
18367 // End:
<a name="12" id="anc12"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="12" type="hidden" />
</body>
</html>