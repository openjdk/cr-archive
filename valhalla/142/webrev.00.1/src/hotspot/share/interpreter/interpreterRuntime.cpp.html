<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/share/interpreter/interpreterRuntime.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /*
   2  * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;classfile/javaClasses.inline.hpp&quot;
  27 #include &quot;classfile/symbolTable.hpp&quot;
  28 #include &quot;classfile/systemDictionary.hpp&quot;
  29 #include &quot;classfile/vmSymbols.hpp&quot;
  30 #include &quot;code/codeCache.hpp&quot;
  31 #include &quot;compiler/compilationPolicy.hpp&quot;
  32 #include &quot;compiler/compileBroker.hpp&quot;
  33 #include &quot;compiler/disassembler.hpp&quot;
  34 #include &quot;gc/shared/barrierSetNMethod.hpp&quot;
  35 #include &quot;gc/shared/collectedHeap.hpp&quot;
  36 #include &quot;interpreter/interpreter.hpp&quot;
  37 #include &quot;interpreter/interpreterRuntime.hpp&quot;
  38 #include &quot;interpreter/linkResolver.hpp&quot;
  39 #include &quot;interpreter/templateTable.hpp&quot;
  40 #include &quot;logging/log.hpp&quot;
  41 #include &quot;memory/oopFactory.hpp&quot;
  42 #include &quot;memory/resourceArea.hpp&quot;
  43 #include &quot;memory/universe.hpp&quot;
  44 #include &quot;oops/constantPool.hpp&quot;
  45 #include &quot;oops/cpCache.inline.hpp&quot;
  46 #include &quot;oops/flatArrayKlass.hpp&quot;
  47 #include &quot;oops/flatArrayOop.inline.hpp&quot;
  48 #include &quot;oops/inlineKlass.inline.hpp&quot;
  49 #include &quot;oops/instanceKlass.hpp&quot;
  50 #include &quot;oops/methodData.hpp&quot;
  51 #include &quot;oops/objArrayKlass.hpp&quot;
  52 #include &quot;oops/objArrayOop.inline.hpp&quot;
  53 #include &quot;oops/oop.inline.hpp&quot;
  54 #include &quot;oops/symbol.hpp&quot;
  55 #include &quot;prims/jvmtiExport.hpp&quot;
  56 #include &quot;prims/nativeLookup.hpp&quot;
  57 #include &quot;runtime/atomic.hpp&quot;
  58 #include &quot;runtime/biasedLocking.hpp&quot;
  59 #include &quot;runtime/deoptimization.hpp&quot;
  60 #include &quot;runtime/fieldDescriptor.inline.hpp&quot;
  61 #include &quot;runtime/frame.inline.hpp&quot;
  62 #include &quot;runtime/handles.inline.hpp&quot;
  63 #include &quot;runtime/icache.hpp&quot;
  64 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  65 #include &quot;runtime/java.hpp&quot;
  66 #include &quot;runtime/javaCalls.hpp&quot;
  67 #include &quot;runtime/jfieldIDWorkaround.hpp&quot;
  68 #include &quot;runtime/osThread.hpp&quot;
  69 #include &quot;runtime/sharedRuntime.hpp&quot;
  70 #include &quot;runtime/stubRoutines.hpp&quot;
  71 #include &quot;runtime/synchronizer.hpp&quot;
  72 #include &quot;runtime/threadCritical.hpp&quot;
  73 #include &quot;utilities/align.hpp&quot;
  74 #include &quot;utilities/copy.hpp&quot;
  75 #include &quot;utilities/events.hpp&quot;
  76 #include &quot;utilities/globalDefinitions.hpp&quot;
  77 #ifdef COMPILER2
  78 #include &quot;opto/runtime.hpp&quot;
  79 #endif
  80 
  81 class UnlockFlagSaver {
  82   private:
  83     JavaThread* _thread;
  84     bool _do_not_unlock;
  85   public:
  86     UnlockFlagSaver(JavaThread* t) {
  87       _thread = t;
  88       _do_not_unlock = t-&gt;do_not_unlock_if_synchronized();
  89       t-&gt;set_do_not_unlock_if_synchronized(false);
  90     }
  91     ~UnlockFlagSaver() {
  92       _thread-&gt;set_do_not_unlock_if_synchronized(_do_not_unlock);
  93     }
  94 };
  95 
  96 // Helper class to access current interpreter state
  97 class LastFrameAccessor : public StackObj {
  98   frame _last_frame;
  99 public:
 100   LastFrameAccessor(JavaThread* thread) {
 101     assert(thread == Thread::current(), &quot;sanity&quot;);
 102     _last_frame = thread-&gt;last_frame();
 103   }
 104   bool is_interpreted_frame() const              { return _last_frame.is_interpreted_frame(); }
 105   Method*   method() const                       { return _last_frame.interpreter_frame_method(); }
 106   address   bcp() const                          { return _last_frame.interpreter_frame_bcp(); }
 107   int       bci() const                          { return _last_frame.interpreter_frame_bci(); }
 108   address   mdp() const                          { return _last_frame.interpreter_frame_mdp(); }
 109 
 110   void      set_bcp(address bcp)                 { _last_frame.interpreter_frame_set_bcp(bcp); }
 111   void      set_mdp(address dp)                  { _last_frame.interpreter_frame_set_mdp(dp); }
 112 
 113   // pass method to avoid calling unsafe bcp_to_method (partial fix 4926272)
 114   Bytecodes::Code code() const                   { return Bytecodes::code_at(method(), bcp()); }
 115 
 116   Bytecode  bytecode() const                     { return Bytecode(method(), bcp()); }
 117   int get_index_u1(Bytecodes::Code bc) const     { return bytecode().get_index_u1(bc); }
 118   int get_index_u2(Bytecodes::Code bc) const     { return bytecode().get_index_u2(bc); }
 119   int get_index_u2_cpcache(Bytecodes::Code bc) const
 120                                                  { return bytecode().get_index_u2_cpcache(bc); }
 121   int get_index_u4(Bytecodes::Code bc) const     { return bytecode().get_index_u4(bc); }
 122   int number_of_dimensions() const               { return bcp()[3]; }
 123   ConstantPoolCacheEntry* cache_entry_at(int i) const
 124                                                  { return method()-&gt;constants()-&gt;cache()-&gt;entry_at(i); }
 125   ConstantPoolCacheEntry* cache_entry() const    { return cache_entry_at(Bytes::get_native_u2(bcp() + 1)); }
 126 
 127   oop callee_receiver(Symbol* signature) {
 128     return _last_frame.interpreter_callee_receiver(signature);
 129   }
 130   BasicObjectLock* monitor_begin() const {
 131     return _last_frame.interpreter_frame_monitor_begin();
 132   }
 133   BasicObjectLock* monitor_end() const {
 134     return _last_frame.interpreter_frame_monitor_end();
 135   }
 136   BasicObjectLock* next_monitor(BasicObjectLock* current) const {
 137     return _last_frame.next_monitor_in_interpreter_frame(current);
 138   }
 139 
 140   frame&amp; get_frame()                             { return _last_frame; }
 141 };
 142 
 143 //------------------------------------------------------------------------------------------------------------------------
 144 // State accessors
 145 
 146 void InterpreterRuntime::set_bcp_and_mdp(address bcp, JavaThread *thread) {
 147   LastFrameAccessor last_frame(thread);
 148   last_frame.set_bcp(bcp);
 149   if (ProfileInterpreter) {
 150     // ProfileTraps uses MDOs independently of ProfileInterpreter.
 151     // That is why we must check both ProfileInterpreter and mdo != NULL.
 152     MethodData* mdo = last_frame.method()-&gt;method_data();
 153     if (mdo != NULL) {
 154       NEEDS_CLEANUP;
 155       last_frame.set_mdp(mdo-&gt;bci_to_dp(last_frame.bci()));
 156     }
 157   }
 158 }
 159 
 160 //------------------------------------------------------------------------------------------------------------------------
 161 // Constants
 162 
 163 
 164 JRT_ENTRY(void, InterpreterRuntime::ldc(JavaThread* thread, bool wide))
 165   // access constant pool
 166   LastFrameAccessor last_frame(thread);
 167   ConstantPool* pool = last_frame.method()-&gt;constants();
 168   int index = wide ? last_frame.get_index_u2(Bytecodes::_ldc_w) : last_frame.get_index_u1(Bytecodes::_ldc);
 169   constantTag tag = pool-&gt;tag_at(index);
 170 
 171   assert (tag.is_unresolved_klass() || tag.is_klass(), &quot;wrong ldc call&quot;);
 172   Klass* klass = pool-&gt;klass_at(index, CHECK);
 173     oop java_class = klass-&gt;java_mirror();
 174     thread-&gt;set_vm_result(java_class);
 175 JRT_END
 176 
 177 JRT_ENTRY(void, InterpreterRuntime::resolve_ldc(JavaThread* thread, Bytecodes::Code bytecode)) {
 178   assert(bytecode == Bytecodes::_ldc ||
 179          bytecode == Bytecodes::_ldc_w ||
 180          bytecode == Bytecodes::_ldc2_w ||
 181          bytecode == Bytecodes::_fast_aldc ||
 182          bytecode == Bytecodes::_fast_aldc_w, &quot;wrong bc&quot;);
 183   ResourceMark rm(thread);
 184   const bool is_fast_aldc = (bytecode == Bytecodes::_fast_aldc ||
 185                              bytecode == Bytecodes::_fast_aldc_w);
 186   LastFrameAccessor last_frame(thread);
 187   methodHandle m (thread, last_frame.method());
 188   Bytecode_loadconstant ldc(m, last_frame.bci());
 189 
 190   // Double-check the size.  (Condy can have any type.)
 191   BasicType type = ldc.result_type();
 192   switch (type2size[type]) {
 193   case 2: guarantee(bytecode == Bytecodes::_ldc2_w, &quot;&quot;); break;
 194   case 1: guarantee(bytecode != Bytecodes::_ldc2_w, &quot;&quot;); break;
 195   default: ShouldNotReachHere();
 196   }
 197 
 198   // Resolve the constant.  This does not do unboxing.
 199   // But it does replace Universe::the_null_sentinel by null.
 200   oop result = ldc.resolve_constant(CHECK);
 201   assert(result != NULL || is_fast_aldc, &quot;null result only valid for fast_aldc&quot;);
 202 
 203 #ifdef ASSERT
 204   {
 205     // The bytecode wrappers aren&#39;t GC-safe so construct a new one
 206     Bytecode_loadconstant ldc2(m, last_frame.bci());
 207     int rindex = ldc2.cache_index();
 208     if (rindex &lt; 0)
 209       rindex = m-&gt;constants()-&gt;cp_to_object_index(ldc2.pool_index());
 210     if (rindex &gt;= 0) {
 211       oop coop = m-&gt;constants()-&gt;resolved_references()-&gt;obj_at(rindex);
 212       oop roop = (result == NULL ? Universe::the_null_sentinel() : result);
 213       assert(roop == coop, &quot;expected result for assembly code&quot;);
 214     }
 215   }
 216 #endif
 217   thread-&gt;set_vm_result(result);
 218   if (!is_fast_aldc) {
 219     // Tell the interpreter how to unbox the primitive.
 220     guarantee(java_lang_boxing_object::is_instance(result, type), &quot;&quot;);
 221     int offset = java_lang_boxing_object::value_offset(type);
 222     intptr_t flags = ((as_TosState(type) &lt;&lt; ConstantPoolCacheEntry::tos_state_shift)
 223                       | (offset &amp; ConstantPoolCacheEntry::field_index_mask));
 224     thread-&gt;set_vm_result_2((Metadata*)flags);
 225   }
 226 }
 227 JRT_END
 228 
 229 
 230 //------------------------------------------------------------------------------------------------------------------------
 231 // Allocation
 232 
 233 JRT_ENTRY(void, InterpreterRuntime::_new(JavaThread* thread, ConstantPool* pool, int index))
 234   Klass* k = pool-&gt;klass_at(index, CHECK);
 235   InstanceKlass* klass = InstanceKlass::cast(k);
 236 
 237   if (klass-&gt;is_inline_klass()) {
 238     THROW(vmSymbols::java_lang_InstantiationError());
 239   }
 240 
 241   // Make sure we are not instantiating an abstract klass
 242   klass-&gt;check_valid_for_instantiation(true, CHECK);
 243 
 244   // Make sure klass is initialized
 245   klass-&gt;initialize(CHECK);
 246 
 247   // At this point the class may not be fully initialized
 248   // because of recursive initialization. If it is fully
 249   // initialized &amp; has_finalized is not set, we rewrite
 250   // it into its fast version (Note: no locking is needed
 251   // here since this is an atomic byte write and can be
 252   // done more than once).
 253   //
 254   // Note: In case of classes with has_finalized we don&#39;t
 255   //       rewrite since that saves us an extra check in
 256   //       the fast version which then would call the
 257   //       slow version anyway (and do a call back into
 258   //       Java).
 259   //       If we have a breakpoint, then we don&#39;t rewrite
 260   //       because the _breakpoint bytecode would be lost.
 261   oop obj = klass-&gt;allocate_instance(CHECK);
 262   thread-&gt;set_vm_result(obj);
 263 JRT_END
 264 
 265 void copy_primitive_argument(intptr_t* addr, Handle instance, int offset, BasicType type) {
 266   switch (type) {
 267   case T_BOOLEAN:
 268     instance()-&gt;bool_field_put(offset, (jboolean)*((int*)addr));
 269     break;
 270   case T_CHAR:
 271     instance()-&gt;char_field_put(offset, (jchar) *((int*)addr));
 272     break;
 273   case T_FLOAT:
 274     instance()-&gt;float_field_put(offset, (jfloat)*((float*)addr));
 275     break;
 276   case T_DOUBLE:
 277     instance()-&gt;double_field_put(offset, (jdouble)*((double*)addr));
 278     break;
 279   case T_BYTE:
 280     instance()-&gt;byte_field_put(offset, (jbyte)*((int*)addr));
 281     break;
 282   case T_SHORT:
 283     instance()-&gt;short_field_put(offset, (jshort)*((int*)addr));
 284     break;
 285   case T_INT:
 286     instance()-&gt;int_field_put(offset, (jint)*((int*)addr));
 287     break;
 288   case T_LONG:
 289     instance()-&gt;long_field_put(offset, (jlong)*((long long*)addr));
 290     break;
 291   case T_OBJECT:
 292   case T_ARRAY:
 293   case T_INLINE_TYPE:
 294     fatal(&quot;Should not be handled with this method&quot;);
 295     break;
 296   default:
 297     fatal(&quot;Unsupported BasicType&quot;);
 298   }
 299 }
 300 
 301 JRT_ENTRY(void, InterpreterRuntime::defaultvalue(JavaThread* thread, ConstantPool* pool, int index))
 302   // Getting the InlineKlass
 303   Klass* k = pool-&gt;klass_at(index, CHECK);
 304   if (!k-&gt;is_inline_klass()) {
 305     // inconsistency with &#39;new&#39; which throws an InstantiationError
 306     // in the future, defaultvalue will just return null instead of throwing an exception
 307     THROW(vmSymbols::java_lang_IncompatibleClassChangeError());
 308   }
 309   assert(k-&gt;is_inline_klass(), &quot;defaultvalue argument must be the inline type class&quot;);
 310   InlineKlass* vklass = InlineKlass::cast(k);
 311 
 312   vklass-&gt;initialize(THREAD);
 313   oop res = vklass-&gt;default_value();
 314   thread-&gt;set_vm_result(res);
 315 JRT_END
 316 
 317 JRT_ENTRY(int, InterpreterRuntime::withfield(JavaThread* thread, ConstantPoolCache* cp_cache))
 318   LastFrameAccessor last_frame(thread);
 319   // Getting the InlineKlass
 320   int index = ConstantPool::decode_cpcache_index(last_frame.get_index_u2_cpcache(Bytecodes::_withfield));
 321   ConstantPoolCacheEntry* cp_entry = cp_cache-&gt;entry_at(index);
 322   assert(cp_entry-&gt;is_resolved(Bytecodes::_withfield), &quot;Should have been resolved&quot;);
 323   Klass* klass = cp_entry-&gt;f1_as_klass();
 324   assert(klass-&gt;is_inline_klass(), &quot;withfield only applies to inline types&quot;);
 325   InlineKlass* vklass = InlineKlass::cast(klass);
 326 
 327   // Getting Field information
 328   int offset = cp_entry-&gt;f2_as_index();
 329   int field_index = cp_entry-&gt;field_index();
 330   int field_offset = cp_entry-&gt;f2_as_offset();
 331   Symbol* field_signature = vklass-&gt;field_signature(field_index);
 332   BasicType field_type = Signature::basic_type(field_signature);
 333   int return_offset = (type2size[field_type] + type2size[T_OBJECT]) * AbstractInterpreter::stackElementSize;
 334 
 335   // Getting old value
 336   frame&amp; f = last_frame.get_frame();
 337   jint tos_idx = f.interpreter_frame_expression_stack_size() - 1;
 338   int vt_offset = type2size[field_type];
 339   oop old_value = *(oop*)f.interpreter_frame_expression_stack_at(tos_idx - vt_offset);
 340   assert(old_value != NULL &amp;&amp; oopDesc::is_oop(old_value) &amp;&amp; old_value-&gt;is_inline_type(),&quot;Verifying receiver&quot;);
 341   Handle old_value_h(THREAD, old_value);
 342 
 343   // Creating new value by copying the one passed in argument
 344   instanceOop new_value = vklass-&gt;allocate_instance_buffer(
 345       CHECK_((type2size[field_type]) * AbstractInterpreter::stackElementSize));
 346   Handle new_value_h = Handle(THREAD, new_value);
 347   vklass-&gt;inline_copy_oop_to_new_oop(old_value_h(), new_value_h());
 348 
 349   // Updating the field specified in arguments
 350   if (field_type == T_ARRAY || field_type == T_OBJECT) {
 351     oop aoop = *(oop*)f.interpreter_frame_expression_stack_at(tos_idx);
 352     assert(aoop == NULL || oopDesc::is_oop(aoop),&quot;argument must be a reference type&quot;);
 353     new_value_h()-&gt;obj_field_put(field_offset, aoop);
 354   } else if (field_type == T_INLINE_TYPE) {
 355     if (cp_entry-&gt;is_inlined()) {
 356       oop vt_oop = *(oop*)f.interpreter_frame_expression_stack_at(tos_idx);
 357       assert(vt_oop != NULL &amp;&amp; oopDesc::is_oop(vt_oop) &amp;&amp; vt_oop-&gt;is_inline_type(),&quot;argument must be an inline type&quot;);
 358       InlineKlass* field_vk = InlineKlass::cast(vklass-&gt;get_inline_type_field_klass(field_index));
 359       assert(vt_oop != NULL &amp;&amp; field_vk == vt_oop-&gt;klass(), &quot;Must match&quot;);
 360       field_vk-&gt;write_inlined_field(new_value_h(), offset, vt_oop, CHECK_(return_offset));
 361     } else { // not inlined
 362       oop voop = *(oop*)f.interpreter_frame_expression_stack_at(tos_idx);
 363       if (voop == NULL &amp;&amp; cp_entry-&gt;is_inline_type()) {
 364         THROW_(vmSymbols::java_lang_NullPointerException(), return_offset);
 365       }
 366       assert(voop == NULL || oopDesc::is_oop(voop),&quot;checking argument&quot;);
 367       new_value_h()-&gt;obj_field_put(field_offset, voop);
 368     }
 369   } else { // not T_OBJECT nor T_ARRAY nor T_INLINE_TYPE
 370     intptr_t* addr = f.interpreter_frame_expression_stack_at(tos_idx);
 371     copy_primitive_argument(addr, new_value_h, field_offset, field_type);
 372   }
 373 
 374   // returning result
 375   thread-&gt;set_vm_result(new_value_h());
 376   return return_offset;
 377 JRT_END
 378 
 379 JRT_ENTRY(void, InterpreterRuntime::uninitialized_static_inline_type_field(JavaThread* thread, oopDesc* mirror, int index))
 380   // The interpreter tries to access an inline static field that has not been initialized.
 381   // This situation can happen in different scenarios:
 382   //   1 - if the load or initialization of the field failed during step 8 of
 383   //       the initialization of the holder of the field, in this case the access to the field
 384   //       must fail
 385   //   2 - it can also happen when the initialization of the holder class triggered the initialization of
 386   //       another class which accesses this field in its static initializer, in this case the
 387   //       access must succeed to allow circularity
 388   // The code below tries to load and initialize the field&#39;s class again before returning the default value.
 389   // If the field was not initialized because of an error, a exception should be thrown.
 390   // If the class is being initialized, the default value is returned.
 391   instanceHandle mirror_h(THREAD, (instanceOop)mirror);
 392   InstanceKlass* klass = InstanceKlass::cast(java_lang_Class::as_Klass(mirror));
 393   if (klass-&gt;is_being_initialized() &amp;&amp; klass-&gt;is_reentrant_initialization(THREAD)) {
 394     int offset = klass-&gt;field_offset(index);
 395     Klass* field_k = klass-&gt;get_inline_type_field_klass_or_null(index);
 396     if (field_k == NULL) {
 397       field_k = SystemDictionary::resolve_or_fail(klass-&gt;field_signature(index)-&gt;fundamental_name(THREAD),
 398           Handle(THREAD, klass-&gt;class_loader()),
 399           Handle(THREAD, klass-&gt;protection_domain()),
 400           true, CHECK);
 401       assert(field_k != NULL, &quot;Should have been loaded or an exception thrown above&quot;);
 402       klass-&gt;set_inline_type_field_klass(index, field_k);
 403     }
 404     field_k-&gt;initialize(CHECK);
 405     oop defaultvalue = InlineKlass::cast(field_k)-&gt;default_value();
 406     // It is safe to initialized the static field because 1) the current thread is the initializing thread
 407     // and is the only one that can access it, and 2) the field is actually not initialized (i.e. null)
 408     // otherwise the JVM should not be executing this code.
 409     mirror-&gt;obj_field_put(offset, defaultvalue);
 410     thread-&gt;set_vm_result(defaultvalue);
 411   } else {
 412     assert(klass-&gt;is_in_error_state(), &quot;If not initializing, initialization must have failed to get there&quot;);
 413     ResourceMark rm(THREAD);
 414     const char* desc = &quot;Could not initialize class &quot;;
 415     const char* className = klass-&gt;external_name();
 416     size_t msglen = strlen(desc) + strlen(className) + 1;
 417     char* message = NEW_RESOURCE_ARRAY(char, msglen);
 418     if (NULL == message) {
 419       // Out of memory: can&#39;t create detailed error message
 420       THROW_MSG(vmSymbols::java_lang_NoClassDefFoundError(), className);
 421     } else {
 422       jio_snprintf(message, msglen, &quot;%s%s&quot;, desc, className);
 423       THROW_MSG(vmSymbols::java_lang_NoClassDefFoundError(), message);
 424     }
 425   }
 426 JRT_END
 427 
 428 JRT_ENTRY(void, InterpreterRuntime::read_inlined_field(JavaThread* thread, oopDesc* obj, int index, Klass* field_holder))
 429   Handle obj_h(THREAD, obj);
 430 
 431   assert(oopDesc::is_oop(obj), &quot;Sanity check&quot;);
 432 
 433   assert(field_holder-&gt;is_instance_klass(), &quot;Sanity check&quot;);
 434   InstanceKlass* klass = InstanceKlass::cast(field_holder);
 435 
 436   assert(klass-&gt;field_is_inlined(index), &quot;Sanity check&quot;);
 437 
 438   InlineKlass* field_vklass = InlineKlass::cast(klass-&gt;get_inline_type_field_klass(index));
 439   assert(field_vklass-&gt;is_initialized(), &quot;Must be initialized at this point&quot;);
 440 
 441   oop res = field_vklass-&gt;read_inlined_field(obj_h(), klass-&gt;field_offset(index), CHECK);
 442   thread-&gt;set_vm_result(res);
 443 JRT_END
 444 
 445 JRT_ENTRY(void, InterpreterRuntime::newarray(JavaThread* thread, BasicType type, jint size))
 446   oop obj = oopFactory::new_typeArray(type, size, CHECK);
 447   thread-&gt;set_vm_result(obj);
 448 JRT_END
 449 
 450 
 451 JRT_ENTRY(void, InterpreterRuntime::anewarray(JavaThread* thread, ConstantPool* pool, int index, jint size))
 452   Klass*    klass = pool-&gt;klass_at(index, CHECK);
 453   bool      is_qtype_desc = pool-&gt;tag_at(index).is_Qdescriptor_klass();
 454   arrayOop obj;
 455   if ((!klass-&gt;is_array_klass()) &amp;&amp; is_qtype_desc) { // Logically creates elements, ensure klass init
 456     klass-&gt;initialize(CHECK);
 457     obj = oopFactory::new_flatArray(klass, size, CHECK);
 458   } else {
 459     obj = oopFactory::new_objArray(klass, size, CHECK);
 460   }
 461   thread-&gt;set_vm_result(obj);
 462 JRT_END
 463 
 464 JRT_ENTRY(void, InterpreterRuntime::value_array_load(JavaThread* thread, arrayOopDesc* array, int index))
 465   flatArrayHandle vah(thread, (flatArrayOop)array);
 466   oop value_holder = flatArrayOopDesc::value_alloc_copy_from_index(vah, index, CHECK);
 467   thread-&gt;set_vm_result(value_holder);
 468 JRT_END
 469 
 470 JRT_ENTRY(void, InterpreterRuntime::value_array_store(JavaThread* thread, void* val, arrayOopDesc* array, int index))
 471   assert(val != NULL, &quot;can&#39;t store null into flat array&quot;);
 472   ((flatArrayOop)array)-&gt;value_copy_to_index((oop)val, index);
 473 JRT_END
 474 
 475 JRT_ENTRY(void, InterpreterRuntime::multianewarray(JavaThread* thread, jint* first_size_address))
 476   // We may want to pass in more arguments - could make this slightly faster
 477   LastFrameAccessor last_frame(thread);
 478   ConstantPool* constants = last_frame.method()-&gt;constants();
 479   int i = last_frame.get_index_u2(Bytecodes::_multianewarray);
 480   Klass* klass = constants-&gt;klass_at(i, CHECK);
 481   bool is_qtype = klass-&gt;name()-&gt;is_Q_array_signature();
 482   int   nof_dims = last_frame.number_of_dimensions();
 483   assert(klass-&gt;is_klass(), &quot;not a class&quot;);
 484   assert(nof_dims &gt;= 1, &quot;multianewarray rank must be nonzero&quot;);
 485 
 486   if (is_qtype) { // Logically creates elements, ensure klass init
 487     klass-&gt;initialize(CHECK);
 488   }
 489 
 490   // We must create an array of jints to pass to multi_allocate.
 491   ResourceMark rm(thread);
 492   const int small_dims = 10;
 493   jint dim_array[small_dims];
 494   jint *dims = &amp;dim_array[0];
 495   if (nof_dims &gt; small_dims) {
 496     dims = (jint*) NEW_RESOURCE_ARRAY(jint, nof_dims);
 497   }
 498   for (int index = 0; index &lt; nof_dims; index++) {
 499     // offset from first_size_address is addressed as local[index]
 500     int n = Interpreter::local_offset_in_bytes(index)/jintSize;
 501     dims[index] = first_size_address[n];
 502   }
 503   oop obj = ArrayKlass::cast(klass)-&gt;multi_allocate(nof_dims, dims, CHECK);
 504   thread-&gt;set_vm_result(obj);
 505 JRT_END
 506 
 507 
 508 JRT_ENTRY(void, InterpreterRuntime::register_finalizer(JavaThread* thread, oopDesc* obj))
 509   assert(oopDesc::is_oop(obj), &quot;must be a valid oop&quot;);
 510   assert(obj-&gt;klass()-&gt;has_finalizer(), &quot;shouldn&#39;t be here otherwise&quot;);
 511   InstanceKlass::register_finalizer(instanceOop(obj), CHECK);
 512 JRT_END
 513 
 514 JRT_ENTRY(jboolean, InterpreterRuntime::is_substitutable(JavaThread* thread, oopDesc* aobj, oopDesc* bobj))
 515   assert(oopDesc::is_oop(aobj) &amp;&amp; oopDesc::is_oop(bobj), &quot;must be valid oops&quot;);
 516 
 517   Handle ha(THREAD, aobj);
 518   Handle hb(THREAD, bobj);
 519   JavaValue result(T_BOOLEAN);
 520   JavaCallArguments args;
 521   args.push_oop(ha);
 522   args.push_oop(hb);
 523   methodHandle method(thread, Universe::is_substitutable_method());
 524   JavaCalls::call(&amp;result, method, &amp;args, THREAD);
 525   if (HAS_PENDING_EXCEPTION) {
 526     // Something really bad happened because isSubstitutable() should not throw exceptions
 527     // If it is an error, just let it propagate
 528     // If it is an exception, wrap it into an InternalError
 529     if (!PENDING_EXCEPTION-&gt;is_a(SystemDictionary::Error_klass())) {
 530       Handle e(THREAD, PENDING_EXCEPTION);
 531       CLEAR_PENDING_EXCEPTION;
 532       THROW_MSG_CAUSE_(vmSymbols::java_lang_InternalError(), &quot;Internal error in substitutability test&quot;, e, false);
 533     }
 534   }
 535   return result.get_jboolean();
 536 JRT_END
 537 
 538 // Quicken instance-of and check-cast bytecodes
 539 JRT_ENTRY(void, InterpreterRuntime::quicken_io_cc(JavaThread* thread))
 540   // Force resolving; quicken the bytecode
 541   LastFrameAccessor last_frame(thread);
 542   int which = last_frame.get_index_u2(Bytecodes::_checkcast);
 543   ConstantPool* cpool = last_frame.method()-&gt;constants();
 544   // We&#39;d expect to assert that we&#39;re only here to quicken bytecodes, but in a multithreaded
 545   // program we might have seen an unquick&#39;d bytecode in the interpreter but have another
 546   // thread quicken the bytecode before we get here.
 547   // assert( cpool-&gt;tag_at(which).is_unresolved_klass(), &quot;should only come here to quicken bytecodes&quot; );
 548   Klass* klass = cpool-&gt;klass_at(which, CHECK);
 549   thread-&gt;set_vm_result_2(klass);
 550 JRT_END
 551 
 552 
 553 //------------------------------------------------------------------------------------------------------------------------
 554 // Exceptions
 555 
 556 void InterpreterRuntime::note_trap_inner(JavaThread* thread, int reason,
 557                                          const methodHandle&amp; trap_method, int trap_bci, TRAPS) {
 558   if (trap_method.not_null()) {
 559     MethodData* trap_mdo = trap_method-&gt;method_data();
 560     if (trap_mdo == NULL) {
 561       Method::build_interpreter_method_data(trap_method, THREAD);
 562       if (HAS_PENDING_EXCEPTION) {
 563         assert((PENDING_EXCEPTION-&gt;is_a(SystemDictionary::OutOfMemoryError_klass())),
 564                &quot;we expect only an OOM error here&quot;);
 565         CLEAR_PENDING_EXCEPTION;
 566       }
 567       trap_mdo = trap_method-&gt;method_data();
 568       // and fall through...
 569     }
 570     if (trap_mdo != NULL) {
 571       // Update per-method count of trap events.  The interpreter
 572       // is updating the MDO to simulate the effect of compiler traps.
 573       Deoptimization::update_method_data_from_interpreter(trap_mdo, trap_bci, reason);
 574     }
 575   }
 576 }
 577 
 578 // Assume the compiler is (or will be) interested in this event.
 579 // If necessary, create an MDO to hold the information, and record it.
 580 void InterpreterRuntime::note_trap(JavaThread* thread, int reason, TRAPS) {
 581   assert(ProfileTraps, &quot;call me only if profiling&quot;);
 582   LastFrameAccessor last_frame(thread);
 583   methodHandle trap_method(thread, last_frame.method());
 584   int trap_bci = trap_method-&gt;bci_from(last_frame.bcp());
 585   note_trap_inner(thread, reason, trap_method, trap_bci, THREAD);
 586 }
 587 
 588 static Handle get_preinitialized_exception(Klass* k, TRAPS) {
 589   // get klass
 590   InstanceKlass* klass = InstanceKlass::cast(k);
 591   assert(klass-&gt;is_initialized(),
 592          &quot;this klass should have been initialized during VM initialization&quot;);
 593   // create instance - do not call constructor since we may have no
 594   // (java) stack space left (should assert constructor is empty)
 595   Handle exception;
 596   oop exception_oop = klass-&gt;allocate_instance(CHECK_(exception));
 597   exception = Handle(THREAD, exception_oop);
 598   if (StackTraceInThrowable) {
 599     java_lang_Throwable::fill_in_stack_trace(exception);
 600   }
 601   return exception;
 602 }
 603 
 604 // Special handling for stack overflow: since we don&#39;t have any (java) stack
 605 // space left we use the pre-allocated &amp; pre-initialized StackOverflowError
 606 // klass to create an stack overflow error instance.  We do not call its
 607 // constructor for the same reason (it is empty, anyway).
 608 JRT_ENTRY(void, InterpreterRuntime::throw_StackOverflowError(JavaThread* thread))
 609   Handle exception = get_preinitialized_exception(
 610                                  SystemDictionary::StackOverflowError_klass(),
 611                                  CHECK);
 612   // Increment counter for hs_err file reporting
 613   Atomic::inc(&amp;Exceptions::_stack_overflow_errors);
 614   THROW_HANDLE(exception);
 615 JRT_END
 616 
 617 JRT_ENTRY(void, InterpreterRuntime::throw_delayed_StackOverflowError(JavaThread* thread))
 618   Handle exception = get_preinitialized_exception(
 619                                  SystemDictionary::StackOverflowError_klass(),
 620                                  CHECK);
 621   java_lang_Throwable::set_message(exception(),
 622           Universe::delayed_stack_overflow_error_message());
 623   // Increment counter for hs_err file reporting
 624   Atomic::inc(&amp;Exceptions::_stack_overflow_errors);
 625   THROW_HANDLE(exception);
 626 JRT_END
 627 
 628 JRT_ENTRY(void, InterpreterRuntime::create_exception(JavaThread* thread, char* name, char* message))
 629   // lookup exception klass
 630   TempNewSymbol s = SymbolTable::new_symbol(name);
 631   if (ProfileTraps) {
 632     if (s == vmSymbols::java_lang_ArithmeticException()) {
 633       note_trap(thread, Deoptimization::Reason_div0_check, CHECK);
 634     } else if (s == vmSymbols::java_lang_NullPointerException()) {
 635       note_trap(thread, Deoptimization::Reason_null_check, CHECK);
 636     }
 637   }
 638   // create exception
 639   Handle exception = Exceptions::new_exception(thread, s, message);
 640   thread-&gt;set_vm_result(exception());
 641 JRT_END
 642 
 643 
 644 JRT_ENTRY(void, InterpreterRuntime::create_klass_exception(JavaThread* thread, char* name, oopDesc* obj))
 645   // Produce the error message first because note_trap can safepoint
 646   ResourceMark rm(thread);
 647   const char* klass_name = obj-&gt;klass()-&gt;external_name();
 648   // lookup exception klass
 649   TempNewSymbol s = SymbolTable::new_symbol(name);
 650   if (ProfileTraps) {
 651     note_trap(thread, Deoptimization::Reason_class_check, CHECK);
 652   }
 653   // create exception, with klass name as detail message
 654   Handle exception = Exceptions::new_exception(thread, s, klass_name);
 655   thread-&gt;set_vm_result(exception());
 656 JRT_END
 657 
 658 JRT_ENTRY(void, InterpreterRuntime::throw_ArrayIndexOutOfBoundsException(JavaThread* thread, arrayOopDesc* a, jint index))
 659   // Produce the error message first because note_trap can safepoint
 660   ResourceMark rm(thread);
 661   stringStream ss;
 662   ss.print(&quot;Index %d out of bounds for length %d&quot;, index, a-&gt;length());
 663 
 664   if (ProfileTraps) {
 665     note_trap(thread, Deoptimization::Reason_range_check, CHECK);
 666   }
 667 
 668   THROW_MSG(vmSymbols::java_lang_ArrayIndexOutOfBoundsException(), ss.as_string());
 669 JRT_END
 670 
 671 JRT_ENTRY(void, InterpreterRuntime::throw_ClassCastException(
 672   JavaThread* thread, oopDesc* obj))
 673 
 674   // Produce the error message first because note_trap can safepoint
 675   ResourceMark rm(thread);
 676   char* message = SharedRuntime::generate_class_cast_message(
 677     thread, obj-&gt;klass());
 678 
 679   if (ProfileTraps) {
 680     note_trap(thread, Deoptimization::Reason_class_check, CHECK);
 681   }
 682 
 683   // create exception
 684   THROW_MSG(vmSymbols::java_lang_ClassCastException(), message);
 685 JRT_END
 686 
 687 // exception_handler_for_exception(...) returns the continuation address,
 688 // the exception oop (via TLS) and sets the bci/bcp for the continuation.
 689 // The exception oop is returned to make sure it is preserved over GC (it
 690 // is only on the stack if the exception was thrown explicitly via athrow).
 691 // During this operation, the expression stack contains the values for the
 692 // bci where the exception happened. If the exception was propagated back
 693 // from a call, the expression stack contains the values for the bci at the
 694 // invoke w/o arguments (i.e., as if one were inside the call).
 695 JRT_ENTRY(address, InterpreterRuntime::exception_handler_for_exception(JavaThread* thread, oopDesc* exception))
 696 
 697   LastFrameAccessor last_frame(thread);
 698   Handle             h_exception(thread, exception);
 699   methodHandle       h_method   (thread, last_frame.method());
 700   constantPoolHandle h_constants(thread, h_method-&gt;constants());
 701   bool               should_repeat;
 702   int                handler_bci;
 703   int                current_bci = last_frame.bci();
 704 
 705   if (thread-&gt;frames_to_pop_failed_realloc() &gt; 0) {
 706     // Allocation of scalar replaced object used in this frame
 707     // failed. Unconditionally pop the frame.
 708     thread-&gt;dec_frames_to_pop_failed_realloc();
 709     thread-&gt;set_vm_result(h_exception());
 710     // If the method is synchronized we already unlocked the monitor
 711     // during deoptimization so the interpreter needs to skip it when
 712     // the frame is popped.
 713     thread-&gt;set_do_not_unlock_if_synchronized(true);
 714     return Interpreter::remove_activation_entry();
 715   }
 716 
 717   // Need to do this check first since when _do_not_unlock_if_synchronized
 718   // is set, we don&#39;t want to trigger any classloading which may make calls
 719   // into java, or surprisingly find a matching exception handler for bci 0
 720   // since at this moment the method hasn&#39;t been &quot;officially&quot; entered yet.
 721   if (thread-&gt;do_not_unlock_if_synchronized()) {
 722     ResourceMark rm;
 723     assert(current_bci == 0,  &quot;bci isn&#39;t zero for do_not_unlock_if_synchronized&quot;);
 724     thread-&gt;set_vm_result(exception);
 725     return Interpreter::remove_activation_entry();
 726   }
 727 
 728   do {
 729     should_repeat = false;
 730 
 731     // assertions
 732 #ifdef ASSERT
 733     assert(h_exception.not_null(), &quot;NULL exceptions should be handled by athrow&quot;);
 734     // Check that exception is a subclass of Throwable, otherwise we have a VerifyError
 735     if (!(h_exception-&gt;is_a(SystemDictionary::Throwable_klass()))) {
 736       if (ExitVMOnVerifyError) vm_exit(-1);
 737       ShouldNotReachHere();
 738     }
 739 #endif
 740 
 741     // tracing
 742     if (log_is_enabled(Info, exceptions)) {
 743       ResourceMark rm(thread);
 744       stringStream tempst;
 745       tempst.print(&quot;interpreter method &lt;%s&gt;\n&quot;
 746                    &quot; at bci %d for thread &quot; INTPTR_FORMAT &quot; (%s)&quot;,
 747                    h_method-&gt;print_value_string(), current_bci, p2i(thread), thread-&gt;name());
 748       Exceptions::log_exception(h_exception, tempst.as_string());
 749     }
 750 // Don&#39;t go paging in something which won&#39;t be used.
 751 //     else if (extable-&gt;length() == 0) {
 752 //       // disabled for now - interpreter is not using shortcut yet
 753 //       // (shortcut is not to call runtime if we have no exception handlers)
 754 //       // warning(&quot;performance bug: should not call runtime if method has no exception handlers&quot;);
 755 //     }
 756     // for AbortVMOnException flag
 757     Exceptions::debug_check_abort(h_exception);
 758 
 759     // exception handler lookup
 760     Klass* klass = h_exception-&gt;klass();
 761     handler_bci = Method::fast_exception_handler_bci_for(h_method, klass, current_bci, THREAD);
 762     if (HAS_PENDING_EXCEPTION) {
 763       // We threw an exception while trying to find the exception handler.
 764       // Transfer the new exception to the exception handle which will
 765       // be set into thread local storage, and do another lookup for an
 766       // exception handler for this exception, this time starting at the
 767       // BCI of the exception handler which caused the exception to be
 768       // thrown (bug 4307310).
 769       h_exception = Handle(THREAD, PENDING_EXCEPTION);
 770       CLEAR_PENDING_EXCEPTION;
 771       if (handler_bci &gt;= 0) {
 772         current_bci = handler_bci;
 773         should_repeat = true;
 774       }
 775     }
 776   } while (should_repeat == true);
 777 
 778 #if INCLUDE_JVMCI
 779   if (EnableJVMCI &amp;&amp; h_method-&gt;method_data() != NULL) {
 780     ResourceMark rm(thread);
 781     ProfileData* pdata = h_method-&gt;method_data()-&gt;allocate_bci_to_data(current_bci, NULL);
 782     if (pdata != NULL &amp;&amp; pdata-&gt;is_BitData()) {
 783       BitData* bit_data = (BitData*) pdata;
 784       bit_data-&gt;set_exception_seen();
 785     }
 786   }
 787 #endif
 788 
 789   // notify JVMTI of an exception throw; JVMTI will detect if this is a first
 790   // time throw or a stack unwinding throw and accordingly notify the debugger
 791   if (JvmtiExport::can_post_on_exceptions()) {
 792     JvmtiExport::post_exception_throw(thread, h_method(), last_frame.bcp(), h_exception());
 793   }
 794 
 795   address continuation = NULL;
 796   address handler_pc = NULL;
 797   if (handler_bci &lt; 0 || !thread-&gt;reguard_stack((address) &amp;continuation)) {
 798     // Forward exception to callee (leaving bci/bcp untouched) because (a) no
 799     // handler in this method, or (b) after a stack overflow there is not yet
 800     // enough stack space available to reprotect the stack.
 801     continuation = Interpreter::remove_activation_entry();
 802 #if COMPILER2_OR_JVMCI
 803     // Count this for compilation purposes
 804     h_method-&gt;interpreter_throwout_increment(THREAD);
 805 #endif
 806   } else {
 807     // handler in this method =&gt; change bci/bcp to handler bci/bcp and continue there
 808     handler_pc = h_method-&gt;code_base() + handler_bci;
 809 #ifndef ZERO
 810     set_bcp_and_mdp(handler_pc, thread);
 811     continuation = Interpreter::dispatch_table(vtos)[*handler_pc];
 812 #else
 813     continuation = (address)(intptr_t) handler_bci;
 814 #endif
 815   }
 816 
 817   // notify debugger of an exception catch
 818   // (this is good for exceptions caught in native methods as well)
 819   if (JvmtiExport::can_post_on_exceptions()) {
 820     JvmtiExport::notice_unwind_due_to_exception(thread, h_method(), handler_pc, h_exception(), (handler_pc != NULL));
 821   }
 822 
 823   thread-&gt;set_vm_result(h_exception());
 824   return continuation;
 825 JRT_END
 826 
 827 
 828 JRT_ENTRY(void, InterpreterRuntime::throw_pending_exception(JavaThread* thread))
 829   assert(thread-&gt;has_pending_exception(), &quot;must only ne called if there&#39;s an exception pending&quot;);
 830   // nothing to do - eventually we should remove this code entirely (see comments @ call sites)
 831 JRT_END
 832 
 833 
 834 JRT_ENTRY(void, InterpreterRuntime::throw_AbstractMethodError(JavaThread* thread))
 835   THROW(vmSymbols::java_lang_AbstractMethodError());
 836 JRT_END
 837 
 838 // This method is called from the &quot;abstract_entry&quot; of the interpreter.
 839 // At that point, the arguments have already been removed from the stack
 840 // and therefore we don&#39;t have the receiver object at our fingertips. (Though,
 841 // on some platforms the receiver still resides in a register...). Thus,
 842 // we have no choice but print an error message not containing the receiver
 843 // type.
 844 JRT_ENTRY(void, InterpreterRuntime::throw_AbstractMethodErrorWithMethod(JavaThread* thread,
 845                                                                         Method* missingMethod))
 846   ResourceMark rm(thread);
 847   assert(missingMethod != NULL, &quot;sanity&quot;);
 848   methodHandle m(thread, missingMethod);
 849   LinkResolver::throw_abstract_method_error(m, THREAD);
 850 JRT_END
 851 
 852 JRT_ENTRY(void, InterpreterRuntime::throw_AbstractMethodErrorVerbose(JavaThread* thread,
 853                                                                      Klass* recvKlass,
 854                                                                      Method* missingMethod))
 855   ResourceMark rm(thread);
 856   methodHandle mh = methodHandle(thread, missingMethod);
 857   LinkResolver::throw_abstract_method_error(mh, recvKlass, THREAD);
 858 JRT_END
 859 
 860 JRT_ENTRY(void, InterpreterRuntime::throw_InstantiationError(JavaThread* thread))
 861   THROW(vmSymbols::java_lang_InstantiationError());
 862 JRT_END
 863 
 864 
 865 JRT_ENTRY(void, InterpreterRuntime::throw_IncompatibleClassChangeError(JavaThread* thread))
 866   THROW(vmSymbols::java_lang_IncompatibleClassChangeError());
 867 JRT_END
 868 
 869 JRT_ENTRY(void, InterpreterRuntime::throw_IncompatibleClassChangeErrorVerbose(JavaThread* thread,
 870                                                                               Klass* recvKlass,
 871                                                                               Klass* interfaceKlass))
 872   ResourceMark rm(thread);
 873   char buf[1000];
 874   buf[0] = &#39;\0&#39;;
 875   jio_snprintf(buf, sizeof(buf),
 876                &quot;Class %s does not implement the requested interface %s&quot;,
 877                recvKlass ? recvKlass-&gt;external_name() : &quot;NULL&quot;,
 878                interfaceKlass ? interfaceKlass-&gt;external_name() : &quot;NULL&quot;);
 879   THROW_MSG(vmSymbols::java_lang_IncompatibleClassChangeError(), buf);
 880 JRT_END
 881 
 882 //------------------------------------------------------------------------------------------------------------------------
 883 // Fields
 884 //
 885 
 886 void InterpreterRuntime::resolve_get_put(JavaThread* thread, Bytecodes::Code bytecode) {
 887   Thread* THREAD = thread;
 888   // resolve field
 889   fieldDescriptor info;
 890   LastFrameAccessor last_frame(thread);
 891   constantPoolHandle pool(thread, last_frame.method()-&gt;constants());
 892   methodHandle m(thread, last_frame.method());
 893   bool is_put    = (bytecode == Bytecodes::_putfield  || bytecode == Bytecodes::_nofast_putfield ||
 894                     bytecode == Bytecodes::_putstatic || bytecode == Bytecodes::_withfield);
 895   bool is_static = (bytecode == Bytecodes::_getstatic || bytecode == Bytecodes::_putstatic);
 896   bool is_inline_type  = bytecode == Bytecodes::_withfield;
 897 
 898   {
 899     JvmtiHideSingleStepping jhss(thread);
 900     LinkResolver::resolve_field_access(info, pool, last_frame.get_index_u2_cpcache(bytecode),
 901                                        m, bytecode, CHECK);
 902   } // end JvmtiHideSingleStepping
 903 
 904   // check if link resolution caused cpCache to be updated
 905   ConstantPoolCacheEntry* cp_cache_entry = last_frame.cache_entry();
 906   if (cp_cache_entry-&gt;is_resolved(bytecode)) return;
 907 
 908   // compute auxiliary field attributes
 909   TosState state  = as_TosState(info.field_type());
 910 
 911   // Resolution of put instructions on final fields is delayed. That is required so that
 912   // exceptions are thrown at the correct place (when the instruction is actually invoked).
 913   // If we do not resolve an instruction in the current pass, leaving the put_code
 914   // set to zero will cause the next put instruction to the same field to reresolve.
 915 
 916   // Resolution of put instructions to final instance fields with invalid updates (i.e.,
 917   // to final instance fields with updates originating from a method different than &lt;init&gt;)
 918   // is inhibited. A putfield instruction targeting an instance final field must throw
 919   // an IllegalAccessError if the instruction is not in an instance
 920   // initializer method &lt;init&gt;. If resolution were not inhibited, a putfield
 921   // in an initializer method could be resolved in the initializer. Subsequent
 922   // putfield instructions to the same field would then use cached information.
 923   // As a result, those instructions would not pass through the VM. That is,
 924   // checks in resolve_field_access() would not be executed for those instructions
 925   // and the required IllegalAccessError would not be thrown.
 926   //
 927   // Also, we need to delay resolving getstatic and putstatic instructions until the
 928   // class is initialized.  This is required so that access to the static
 929   // field will call the initialization function every time until the class
 930   // is completely initialized ala. in 2.17.5 in JVM Specification.
 931   InstanceKlass* klass = info.field_holder();
 932   bool uninitialized_static = is_static &amp;&amp; !klass-&gt;is_initialized();
 933   bool has_initialized_final_update = info.field_holder()-&gt;major_version() &gt;= 53 &amp;&amp;
 934                                       info.has_initialized_final_update();
 935   assert(!(has_initialized_final_update &amp;&amp; !info.access_flags().is_final()), &quot;Fields with initialized final updates must be final&quot;);
 936 
 937   Bytecodes::Code get_code = (Bytecodes::Code)0;
 938   Bytecodes::Code put_code = (Bytecodes::Code)0;
 939   if (!uninitialized_static) {
 940     if (is_static) {
 941       get_code = Bytecodes::_getstatic;
 942     } else {
 943       get_code = Bytecodes::_getfield;
 944     }
 945     if (is_put &amp;&amp; is_inline_type) {
 946         put_code = ((is_static) ? Bytecodes::_putstatic : Bytecodes::_withfield);
 947     } else if ((is_put &amp;&amp; !has_initialized_final_update) || !info.access_flags().is_final()) {
 948         put_code = ((is_static) ? Bytecodes::_putstatic : Bytecodes::_putfield);
 949     }
 950   }
 951 
 952   cp_cache_entry-&gt;set_field(
 953     get_code,
 954     put_code,
 955     info.field_holder(),
 956     info.index(),
 957     info.offset(),
 958     state,
 959     info.access_flags().is_final(),
 960     info.access_flags().is_volatile(),
 961     info.is_inlined(),
 962     info.is_inline_type(),
 963     pool-&gt;pool_holder()
 964   );
 965 }
 966 
 967 
 968 //------------------------------------------------------------------------------------------------------------------------
 969 // Synchronization
 970 //
 971 // The interpreter&#39;s synchronization code is factored out so that it can
 972 // be shared by method invocation and synchronized blocks.
 973 //%note synchronization_3
 974 
 975 //%note monitor_1
 976 JRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorenter(JavaThread* thread, BasicObjectLock* elem))
 977 #ifdef ASSERT
 978   thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);
 979 #endif
 980   if (PrintBiasedLockingStatistics) {
 981     Atomic::inc(BiasedLocking::slow_path_entry_count_addr());
 982   }
 983   Handle h_obj(thread, elem-&gt;obj());
 984   assert(Universe::heap()-&gt;is_in_or_null(h_obj()),
 985          &quot;must be NULL or an object&quot;);
 986   ObjectSynchronizer::enter(h_obj, elem-&gt;lock(), CHECK);
 987   assert(Universe::heap()-&gt;is_in_or_null(elem-&gt;obj()),
 988          &quot;must be NULL or an object&quot;);
 989 #ifdef ASSERT
 990   thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);
 991 #endif
 992 JRT_END
 993 
 994 
 995 //%note monitor_1
 996 JRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorexit(JavaThread* thread, BasicObjectLock* elem))
 997 #ifdef ASSERT
 998   thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);
 999 #endif
1000   Handle h_obj(thread, elem-&gt;obj());
1001   assert(Universe::heap()-&gt;is_in_or_null(h_obj()),
1002          &quot;must be NULL or an object&quot;);
1003   if (elem == NULL || h_obj()-&gt;is_unlocked()) {
1004     THROW(vmSymbols::java_lang_IllegalMonitorStateException());
1005   }
1006   ObjectSynchronizer::exit(h_obj(), elem-&gt;lock(), thread);
1007   // Free entry. This must be done here, since a pending exception might be installed on
1008   // exit. If it is not cleared, the exception handling code will try to unlock the monitor again.
1009   elem-&gt;set_obj(NULL);
1010 #ifdef ASSERT
1011   thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);
1012 #endif
1013 JRT_END
1014 
1015 
1016 JRT_ENTRY(void, InterpreterRuntime::throw_illegal_monitor_state_exception(JavaThread* thread))
1017   THROW(vmSymbols::java_lang_IllegalMonitorStateException());
1018 JRT_END
1019 
1020 
1021 JRT_ENTRY(void, InterpreterRuntime::new_illegal_monitor_state_exception(JavaThread* thread))
1022   // Returns an illegal exception to install into the current thread. The
1023   // pending_exception flag is cleared so normal exception handling does not
1024   // trigger. Any current installed exception will be overwritten. This
1025   // method will be called during an exception unwind.
1026 
1027   assert(!HAS_PENDING_EXCEPTION, &quot;no pending exception&quot;);
1028   Handle exception(thread, thread-&gt;vm_result());
1029   assert(exception() != NULL, &quot;vm result should be set&quot;);
1030   thread-&gt;set_vm_result(NULL); // clear vm result before continuing (may cause memory leaks and assert failures)
1031   if (!exception-&gt;is_a(SystemDictionary::ThreadDeath_klass())) {
1032     exception = get_preinitialized_exception(
1033                        SystemDictionary::IllegalMonitorStateException_klass(),
1034                        CATCH);
1035   }
1036   thread-&gt;set_vm_result(exception());
1037 JRT_END
1038 
1039 
1040 //------------------------------------------------------------------------------------------------------------------------
1041 // Invokes
1042 
1043 JRT_ENTRY(Bytecodes::Code, InterpreterRuntime::get_original_bytecode_at(JavaThread* thread, Method* method, address bcp))
1044   return method-&gt;orig_bytecode_at(method-&gt;bci_from(bcp));
1045 JRT_END
1046 
1047 JRT_ENTRY(void, InterpreterRuntime::set_original_bytecode_at(JavaThread* thread, Method* method, address bcp, Bytecodes::Code new_code))
1048   method-&gt;set_orig_bytecode_at(method-&gt;bci_from(bcp), new_code);
1049 JRT_END
1050 
1051 JRT_ENTRY(void, InterpreterRuntime::_breakpoint(JavaThread* thread, Method* method, address bcp))
1052   JvmtiExport::post_raw_breakpoint(thread, method, bcp);
1053 JRT_END
1054 
1055 void InterpreterRuntime::resolve_invoke(JavaThread* thread, Bytecodes::Code bytecode) {
1056   Thread* THREAD = thread;
1057   LastFrameAccessor last_frame(thread);
1058   // extract receiver from the outgoing argument list if necessary
1059   Handle receiver(thread, NULL);
1060   if (bytecode == Bytecodes::_invokevirtual || bytecode == Bytecodes::_invokeinterface ||
1061       bytecode == Bytecodes::_invokespecial) {
1062     ResourceMark rm(thread);
1063     methodHandle m (thread, last_frame.method());
1064     Bytecode_invoke call(m, last_frame.bci());
1065     Symbol* signature = call.signature();
1066     receiver = Handle(thread, last_frame.callee_receiver(signature));
1067 
1068     assert(Universe::heap()-&gt;is_in_or_null(receiver()),
1069            &quot;sanity check&quot;);
1070     assert(receiver.is_null() ||
1071            !Universe::heap()-&gt;is_in(receiver-&gt;klass()),
1072            &quot;sanity check&quot;);
1073   }
1074 
1075   // resolve method
1076   CallInfo info;
1077   constantPoolHandle pool(thread, last_frame.method()-&gt;constants());
1078 
1079   {
1080     JvmtiHideSingleStepping jhss(thread);
1081     LinkResolver::resolve_invoke(info, receiver, pool,
1082                                  last_frame.get_index_u2_cpcache(bytecode), bytecode,
1083                                  CHECK);
1084     if (JvmtiExport::can_hotswap_or_post_breakpoint()) {
1085       int retry_count = 0;
1086       while (info.resolved_method()-&gt;is_old()) {
1087         // It is very unlikely that method is redefined more than 100 times
1088         // in the middle of resolve. If it is looping here more than 100 times
1089         // means then there could be a bug here.
1090         guarantee((retry_count++ &lt; 100),
1091                   &quot;Could not resolve to latest version of redefined method&quot;);
1092         // method is redefined in the middle of resolve so re-try.
1093         LinkResolver::resolve_invoke(info, receiver, pool,
1094                                      last_frame.get_index_u2_cpcache(bytecode), bytecode,
1095                                      CHECK);
1096       }
1097     }
1098   } // end JvmtiHideSingleStepping
1099 
1100   // check if link resolution caused cpCache to be updated
1101   ConstantPoolCacheEntry* cp_cache_entry = last_frame.cache_entry();
1102   if (cp_cache_entry-&gt;is_resolved(bytecode)) return;
1103 
1104 #ifdef ASSERT
1105   if (bytecode == Bytecodes::_invokeinterface) {
1106     if (info.resolved_method()-&gt;method_holder() ==
1107                                             SystemDictionary::Object_klass()) {
1108       // NOTE: THIS IS A FIX FOR A CORNER CASE in the JVM spec
1109       // (see also CallInfo::set_interface for details)
1110       assert(info.call_kind() == CallInfo::vtable_call ||
1111              info.call_kind() == CallInfo::direct_call, &quot;&quot;);
1112       Method* rm = info.resolved_method();
1113       assert(rm-&gt;is_final() || info.has_vtable_index(),
1114              &quot;should have been set already&quot;);
1115     } else if (!info.resolved_method()-&gt;has_itable_index()) {
1116       // Resolved something like CharSequence.toString.  Use vtable not itable.
1117       assert(info.call_kind() != CallInfo::itable_call, &quot;&quot;);
1118     } else {
1119       // Setup itable entry
1120       assert(info.call_kind() == CallInfo::itable_call, &quot;&quot;);
1121       int index = info.resolved_method()-&gt;itable_index();
1122       assert(info.itable_index() == index, &quot;&quot;);
1123     }
1124   } else if (bytecode == Bytecodes::_invokespecial) {
1125     assert(info.call_kind() == CallInfo::direct_call, &quot;must be direct call&quot;);
1126   } else {
1127     assert(info.call_kind() == CallInfo::direct_call ||
1128            info.call_kind() == CallInfo::vtable_call, &quot;&quot;);
1129   }
1130 #endif
1131   // Get sender or sender&#39;s unsafe_anonymous_host, and only set cpCache entry to resolved if
1132   // it is not an interface.  The receiver for invokespecial calls within interface
1133   // methods must be checked for every call.
1134   InstanceKlass* sender = pool-&gt;pool_holder();
1135   sender = sender-&gt;is_unsafe_anonymous() ? sender-&gt;unsafe_anonymous_host() : sender;
1136   methodHandle resolved_method(THREAD, info.resolved_method());
1137 
1138   switch (info.call_kind()) {
1139   case CallInfo::direct_call:
1140     cp_cache_entry-&gt;set_direct_call(
1141       bytecode,
1142       resolved_method,
1143       sender-&gt;is_interface());
1144     break;
1145   case CallInfo::vtable_call:
1146     cp_cache_entry-&gt;set_vtable_call(
1147       bytecode,
1148       resolved_method,
1149       info.vtable_index());
1150     break;
1151   case CallInfo::itable_call:
1152     cp_cache_entry-&gt;set_itable_call(
1153       bytecode,
1154       info.resolved_klass(),
1155       resolved_method,
1156       info.itable_index());
1157     break;
1158   default:  ShouldNotReachHere();
1159   }
1160 }
1161 
1162 
1163 // First time execution:  Resolve symbols, create a permanent MethodType object.
1164 void InterpreterRuntime::resolve_invokehandle(JavaThread* thread) {
1165   Thread* THREAD = thread;
1166   const Bytecodes::Code bytecode = Bytecodes::_invokehandle;
1167   LastFrameAccessor last_frame(thread);
1168 
1169   // resolve method
1170   CallInfo info;
1171   constantPoolHandle pool(thread, last_frame.method()-&gt;constants());
1172   {
1173     JvmtiHideSingleStepping jhss(thread);
1174     LinkResolver::resolve_invoke(info, Handle(), pool,
1175                                  last_frame.get_index_u2_cpcache(bytecode), bytecode,
1176                                  CHECK);
1177   } // end JvmtiHideSingleStepping
1178 
1179   ConstantPoolCacheEntry* cp_cache_entry = last_frame.cache_entry();
1180   cp_cache_entry-&gt;set_method_handle(pool, info);
1181 }
1182 
1183 // First time execution:  Resolve symbols, create a permanent CallSite object.
1184 void InterpreterRuntime::resolve_invokedynamic(JavaThread* thread) {
1185   Thread* THREAD = thread;
1186   LastFrameAccessor last_frame(thread);
1187   const Bytecodes::Code bytecode = Bytecodes::_invokedynamic;
1188 
1189   // resolve method
1190   CallInfo info;
1191   constantPoolHandle pool(thread, last_frame.method()-&gt;constants());
1192   int index = last_frame.get_index_u4(bytecode);
1193   {
1194     JvmtiHideSingleStepping jhss(thread);
1195     LinkResolver::resolve_invoke(info, Handle(), pool,
1196                                  index, bytecode, CHECK);
1197   } // end JvmtiHideSingleStepping
1198 
1199   ConstantPoolCacheEntry* cp_cache_entry = pool-&gt;invokedynamic_cp_cache_entry_at(index);
1200   cp_cache_entry-&gt;set_dynamic_call(pool, info);
1201 }
1202 
1203 // This function is the interface to the assembly code. It returns the resolved
1204 // cpCache entry.  This doesn&#39;t safepoint, but the helper routines safepoint.
1205 // This function will check for redefinition!
1206 JRT_ENTRY(void, InterpreterRuntime::resolve_from_cache(JavaThread* thread, Bytecodes::Code bytecode)) {
1207   switch (bytecode) {
1208   case Bytecodes::_getstatic:
1209   case Bytecodes::_putstatic:
1210   case Bytecodes::_getfield:
1211   case Bytecodes::_putfield:
1212   case Bytecodes::_withfield:
1213     resolve_get_put(thread, bytecode);
1214     break;
1215   case Bytecodes::_invokevirtual:
1216   case Bytecodes::_invokespecial:
1217   case Bytecodes::_invokestatic:
1218   case Bytecodes::_invokeinterface:
1219     resolve_invoke(thread, bytecode);
1220     break;
1221   case Bytecodes::_invokehandle:
1222     resolve_invokehandle(thread);
1223     break;
1224   case Bytecodes::_invokedynamic:
1225     resolve_invokedynamic(thread);
1226     break;
1227   default:
1228     fatal(&quot;unexpected bytecode: %s&quot;, Bytecodes::name(bytecode));
1229     break;
1230   }
1231 }
1232 JRT_END
1233 
1234 //------------------------------------------------------------------------------------------------------------------------
1235 // Miscellaneous
1236 
1237 
1238 nmethod* InterpreterRuntime::frequency_counter_overflow(JavaThread* thread, address branch_bcp) {
1239   nmethod* nm = frequency_counter_overflow_inner(thread, branch_bcp);
1240   assert(branch_bcp != NULL || nm == NULL, &quot;always returns null for non OSR requests&quot;);
1241   if (branch_bcp != NULL &amp;&amp; nm != NULL) {
1242     // This was a successful request for an OSR nmethod.  Because
1243     // frequency_counter_overflow_inner ends with a safepoint check,
1244     // nm could have been unloaded so look it up again.  It&#39;s unsafe
1245     // to examine nm directly since it might have been freed and used
1246     // for something else.
1247     LastFrameAccessor last_frame(thread);
1248     Method* method =  last_frame.method();
1249     int bci = method-&gt;bci_from(last_frame.bcp());
1250     nm = method-&gt;lookup_osr_nmethod_for(bci, CompLevel_none, false);
1251     BarrierSetNMethod* bs_nm = BarrierSet::barrier_set()-&gt;barrier_set_nmethod();
1252     if (nm != NULL &amp;&amp; bs_nm != NULL) {
1253       // in case the transition passed a safepoint we need to barrier this again
1254       if (!bs_nm-&gt;nmethod_osr_entry_barrier(nm)) {
1255         nm = NULL;
1256       }
1257     }
1258   }
1259   if (nm != NULL &amp;&amp; thread-&gt;is_interp_only_mode()) {
1260     // Normally we never get an nm if is_interp_only_mode() is true, because
1261     // policy()-&gt;event has a check for this and won&#39;t compile the method when
1262     // true. However, it&#39;s possible for is_interp_only_mode() to become true
1263     // during the compilation. We don&#39;t want to return the nm in that case
1264     // because we want to continue to execute interpreted.
1265     nm = NULL;
1266   }
1267 #ifndef PRODUCT
1268   if (TraceOnStackReplacement) {
1269     if (nm != NULL) {
1270       tty-&gt;print(&quot;OSR entry @ pc: &quot; INTPTR_FORMAT &quot;: &quot;, p2i(nm-&gt;osr_entry()));
1271       nm-&gt;print();
1272     }
1273   }
1274 #endif
1275   return nm;
1276 }
1277 
1278 JRT_ENTRY(nmethod*,
1279           InterpreterRuntime::frequency_counter_overflow_inner(JavaThread* thread, address branch_bcp))
1280   // use UnlockFlagSaver to clear and restore the _do_not_unlock_if_synchronized
1281   // flag, in case this method triggers classloading which will call into Java.
1282   UnlockFlagSaver fs(thread);
1283 
1284   LastFrameAccessor last_frame(thread);
1285   assert(last_frame.is_interpreted_frame(), &quot;must come from interpreter&quot;);
1286   methodHandle method(thread, last_frame.method());
1287   const int branch_bci = branch_bcp != NULL ? method-&gt;bci_from(branch_bcp) : InvocationEntryBci;
1288   const int bci = branch_bcp != NULL ? method-&gt;bci_from(last_frame.bcp()) : InvocationEntryBci;
1289 
1290   assert(!HAS_PENDING_EXCEPTION, &quot;Should not have any exceptions pending&quot;);
1291   nmethod* osr_nm = CompilationPolicy::policy()-&gt;event(method, method, branch_bci, bci, CompLevel_none, NULL, thread);
1292   assert(!HAS_PENDING_EXCEPTION, &quot;Event handler should not throw any exceptions&quot;);
1293 
1294   BarrierSetNMethod* bs_nm = BarrierSet::barrier_set()-&gt;barrier_set_nmethod();
1295   if (osr_nm != NULL &amp;&amp; bs_nm != NULL) {
1296     if (!bs_nm-&gt;nmethod_osr_entry_barrier(osr_nm)) {
1297       osr_nm = NULL;
1298     }
1299   }
1300 
1301   if (osr_nm != NULL) {
1302     // We may need to do on-stack replacement which requires that no
1303     // monitors in the activation are biased because their
1304     // BasicObjectLocks will need to migrate during OSR. Force
1305     // unbiasing of all monitors in the activation now (even though
1306     // the OSR nmethod might be invalidated) because we don&#39;t have a
1307     // safepoint opportunity later once the migration begins.
1308     if (UseBiasedLocking) {
1309       ResourceMark rm;
1310       GrowableArray&lt;Handle&gt;* objects_to_revoke = new GrowableArray&lt;Handle&gt;();
1311       for( BasicObjectLock *kptr = last_frame.monitor_end();
1312            kptr &lt; last_frame.monitor_begin();
1313            kptr = last_frame.next_monitor(kptr) ) {
1314         if( kptr-&gt;obj() != NULL ) {
1315           objects_to_revoke-&gt;append(Handle(THREAD, kptr-&gt;obj()));
1316         }
1317       }
1318       BiasedLocking::revoke(objects_to_revoke, thread);
1319     }
1320   }
1321   return osr_nm;
1322 JRT_END
1323 
1324 JRT_LEAF(jint, InterpreterRuntime::bcp_to_di(Method* method, address cur_bcp))
1325   assert(ProfileInterpreter, &quot;must be profiling interpreter&quot;);
1326   int bci = method-&gt;bci_from(cur_bcp);
1327   MethodData* mdo = method-&gt;method_data();
1328   if (mdo == NULL)  return 0;
1329   return mdo-&gt;bci_to_di(bci);
1330 JRT_END
1331 
1332 JRT_ENTRY(void, InterpreterRuntime::profile_method(JavaThread* thread))
1333   // use UnlockFlagSaver to clear and restore the _do_not_unlock_if_synchronized
1334   // flag, in case this method triggers classloading which will call into Java.
1335   UnlockFlagSaver fs(thread);
1336 
1337   assert(ProfileInterpreter, &quot;must be profiling interpreter&quot;);
1338   LastFrameAccessor last_frame(thread);
1339   assert(last_frame.is_interpreted_frame(), &quot;must come from interpreter&quot;);
1340   methodHandle method(thread, last_frame.method());
1341   Method::build_interpreter_method_data(method, THREAD);
1342   if (HAS_PENDING_EXCEPTION) {
1343     assert((PENDING_EXCEPTION-&gt;is_a(SystemDictionary::OutOfMemoryError_klass())), &quot;we expect only an OOM error here&quot;);
1344     CLEAR_PENDING_EXCEPTION;
1345     // and fall through...
1346   }
1347 JRT_END
1348 
1349 
1350 #ifdef ASSERT
1351 JRT_LEAF(void, InterpreterRuntime::verify_mdp(Method* method, address bcp, address mdp))
1352   assert(ProfileInterpreter, &quot;must be profiling interpreter&quot;);
1353 
1354   MethodData* mdo = method-&gt;method_data();
1355   assert(mdo != NULL, &quot;must not be null&quot;);
1356 
1357   int bci = method-&gt;bci_from(bcp);
1358 
1359   address mdp2 = mdo-&gt;bci_to_dp(bci);
1360   if (mdp != mdp2) {
1361     ResourceMark rm;
1362     ResetNoHandleMark rnm; // In a LEAF entry.
1363     HandleMark hm;
1364     tty-&gt;print_cr(&quot;FAILED verify : actual mdp %p   expected mdp %p @ bci %d&quot;, mdp, mdp2, bci);
1365     int current_di = mdo-&gt;dp_to_di(mdp);
1366     int expected_di  = mdo-&gt;dp_to_di(mdp2);
1367     tty-&gt;print_cr(&quot;  actual di %d   expected di %d&quot;, current_di, expected_di);
1368     int expected_approx_bci = mdo-&gt;data_at(expected_di)-&gt;bci();
1369     int approx_bci = -1;
1370     if (current_di &gt;= 0) {
1371       approx_bci = mdo-&gt;data_at(current_di)-&gt;bci();
1372     }
1373     tty-&gt;print_cr(&quot;  actual bci is %d  expected bci %d&quot;, approx_bci, expected_approx_bci);
1374     mdo-&gt;print_on(tty);
1375     method-&gt;print_codes();
1376   }
1377   assert(mdp == mdp2, &quot;wrong mdp&quot;);
1378 JRT_END
1379 #endif // ASSERT
1380 
1381 JRT_ENTRY(void, InterpreterRuntime::update_mdp_for_ret(JavaThread* thread, int return_bci))
1382   assert(ProfileInterpreter, &quot;must be profiling interpreter&quot;);
1383   ResourceMark rm(thread);
1384   HandleMark hm(thread);
1385   LastFrameAccessor last_frame(thread);
1386   assert(last_frame.is_interpreted_frame(), &quot;must come from interpreter&quot;);
1387   MethodData* h_mdo = last_frame.method()-&gt;method_data();
1388 
1389   // Grab a lock to ensure atomic access to setting the return bci and
1390   // the displacement.  This can block and GC, invalidating all naked oops.
1391   MutexLocker ml(RetData_lock);
1392 
1393   // ProfileData is essentially a wrapper around a derived oop, so we
1394   // need to take the lock before making any ProfileData structures.
1395   ProfileData* data = h_mdo-&gt;data_at(h_mdo-&gt;dp_to_di(last_frame.mdp()));
1396   guarantee(data != NULL, &quot;profile data must be valid&quot;);
1397   RetData* rdata = data-&gt;as_RetData();
1398   address new_mdp = rdata-&gt;fixup_ret(return_bci, h_mdo);
1399   last_frame.set_mdp(new_mdp);
1400 JRT_END
1401 
1402 JRT_ENTRY(MethodCounters*, InterpreterRuntime::build_method_counters(JavaThread* thread, Method* m))
1403   MethodCounters* mcs = Method::build_method_counters(m, thread);
1404   if (HAS_PENDING_EXCEPTION) {
1405     assert((PENDING_EXCEPTION-&gt;is_a(SystemDictionary::OutOfMemoryError_klass())), &quot;we expect only an OOM error here&quot;);
1406     CLEAR_PENDING_EXCEPTION;
1407   }
1408   return mcs;
1409 JRT_END
1410 
1411 
1412 JRT_ENTRY(void, InterpreterRuntime::at_safepoint(JavaThread* thread))
1413   // We used to need an explict preserve_arguments here for invoke bytecodes. However,
1414   // stack traversal automatically takes care of preserving arguments for invoke, so
1415   // this is no longer needed.
1416 
1417   // JRT_END does an implicit safepoint check, hence we are guaranteed to block
1418   // if this is called during a safepoint
1419 
1420   if (JvmtiExport::should_post_single_step()) {
1421     // We are called during regular safepoints and when the VM is
1422     // single stepping. If any thread is marked for single stepping,
1423     // then we may have JVMTI work to do.
1424     LastFrameAccessor last_frame(thread);
1425     JvmtiExport::at_single_stepping_point(thread, last_frame.method(), last_frame.bcp());
1426   }
1427 JRT_END
1428 
1429 JRT_ENTRY(void, InterpreterRuntime::post_field_access(JavaThread *thread, oopDesc* obj,
1430 ConstantPoolCacheEntry *cp_entry))
1431 
1432   // check the access_flags for the field in the klass
1433 
1434   InstanceKlass* ik = InstanceKlass::cast(cp_entry-&gt;f1_as_klass());
1435   int index = cp_entry-&gt;field_index();
1436   if ((ik-&gt;field_access_flags(index) &amp; JVM_ACC_FIELD_ACCESS_WATCHED) == 0) return;
1437 
1438   bool is_static = (obj == NULL);
1439   bool is_inlined = cp_entry-&gt;is_inlined();
1440   HandleMark hm(thread);
1441 
1442   Handle h_obj;
1443   if (!is_static) {
1444     // non-static field accessors have an object, but we need a handle
1445     h_obj = Handle(thread, obj);
1446   }
1447   InstanceKlass* cp_entry_f1 = InstanceKlass::cast(cp_entry-&gt;f1_as_klass());
1448   jfieldID fid = jfieldIDWorkaround::to_jfieldID(cp_entry_f1, cp_entry-&gt;f2_as_index(), is_static, is_inlined);
1449   LastFrameAccessor last_frame(thread);
1450   JvmtiExport::post_field_access(thread, last_frame.method(), last_frame.bcp(), cp_entry_f1, h_obj, fid);
1451 JRT_END
1452 
1453 JRT_ENTRY(void, InterpreterRuntime::post_field_modification(JavaThread *thread,
1454   oopDesc* obj, ConstantPoolCacheEntry *cp_entry, jvalue *value))
1455 
1456   Klass* k = cp_entry-&gt;f1_as_klass();
1457 
1458   // check the access_flags for the field in the klass
1459   InstanceKlass* ik = InstanceKlass::cast(k);
1460   int index = cp_entry-&gt;field_index();
1461   // bail out if field modifications are not watched
1462   if ((ik-&gt;field_access_flags(index) &amp; JVM_ACC_FIELD_MODIFICATION_WATCHED) == 0) return;
1463 
1464   char sig_type = &#39;\0&#39;;
1465 
1466   switch(cp_entry-&gt;flag_state()) {
1467     case btos: sig_type = JVM_SIGNATURE_BYTE;    break;
1468     case ztos: sig_type = JVM_SIGNATURE_BOOLEAN; break;
1469     case ctos: sig_type = JVM_SIGNATURE_CHAR;    break;
1470     case stos: sig_type = JVM_SIGNATURE_SHORT;   break;
1471     case itos: sig_type = JVM_SIGNATURE_INT;     break;
1472     case ftos: sig_type = JVM_SIGNATURE_FLOAT;   break;
1473     case atos: sig_type = JVM_SIGNATURE_CLASS;   break;
1474     case ltos: sig_type = JVM_SIGNATURE_LONG;    break;
1475     case dtos: sig_type = JVM_SIGNATURE_DOUBLE;  break;
1476     default:  ShouldNotReachHere(); return;
1477   }
1478 
1479   // Both Q-signatures and L-signatures are mapped to atos
1480   if (cp_entry-&gt;flag_state() == atos &amp;&amp; ik-&gt;field_signature(index)-&gt;is_Q_signature()) {
1481     sig_type = JVM_SIGNATURE_INLINE_TYPE;
1482   }
1483 
1484   bool is_static = (obj == NULL);
1485   bool is_inlined = cp_entry-&gt;is_inlined();
1486 
1487   HandleMark hm(thread);
1488   jfieldID fid = jfieldIDWorkaround::to_jfieldID(ik, cp_entry-&gt;f2_as_index(), is_static, is_inlined);
1489   jvalue fvalue;
1490 #ifdef _LP64
1491   fvalue = *value;
1492 #else
1493   // Long/double values are stored unaligned and also noncontiguously with
1494   // tagged stacks.  We can&#39;t just do a simple assignment even in the non-
1495   // J/D cases because a C++ compiler is allowed to assume that a jvalue is
1496   // 8-byte aligned, and interpreter stack slots are only 4-byte aligned.
1497   // We assume that the two halves of longs/doubles are stored in interpreter
1498   // stack slots in platform-endian order.
1499   jlong_accessor u;
1500   jint* newval = (jint*)value;
1501   u.words[0] = newval[0];
1502   u.words[1] = newval[Interpreter::stackElementWords]; // skip if tag
1503   fvalue.j = u.long_value;
1504 #endif // _LP64
1505 
1506   Handle h_obj;
1507   if (!is_static) {
1508     // non-static field accessors have an object, but we need a handle
1509     h_obj = Handle(thread, obj);
1510   }
1511 
1512   LastFrameAccessor last_frame(thread);
1513   JvmtiExport::post_raw_field_modification(thread, last_frame.method(), last_frame.bcp(), ik, h_obj,
1514                                            fid, sig_type, &amp;fvalue);
1515 JRT_END
1516 
1517 JRT_ENTRY(void, InterpreterRuntime::post_method_entry(JavaThread *thread))
1518   LastFrameAccessor last_frame(thread);
1519   JvmtiExport::post_method_entry(thread, last_frame.method(), last_frame.get_frame());
1520 JRT_END
1521 
1522 
1523 JRT_ENTRY(void, InterpreterRuntime::post_method_exit(JavaThread *thread))
1524   LastFrameAccessor last_frame(thread);
1525   JvmtiExport::post_method_exit(thread, last_frame.method(), last_frame.get_frame());
1526 JRT_END
1527 
1528 JRT_LEAF(int, InterpreterRuntime::interpreter_contains(address pc))
1529 {
1530   return (Interpreter::contains(pc) ? 1 : 0);
1531 }
1532 JRT_END
1533 
1534 
1535 // Implementation of SignatureHandlerLibrary
1536 
1537 #ifndef SHARING_FAST_NATIVE_FINGERPRINTS
1538 // Dummy definition (else normalization method is defined in CPU
1539 // dependant code)
1540 uint64_t InterpreterRuntime::normalize_fast_native_fingerprint(uint64_t fingerprint) {
1541   return fingerprint;
1542 }
1543 #endif
1544 
1545 address SignatureHandlerLibrary::set_handler_blob() {
1546   BufferBlob* handler_blob = BufferBlob::create(&quot;native signature handlers&quot;, blob_size);
1547   if (handler_blob == NULL) {
1548     return NULL;
1549   }
1550   address handler = handler_blob-&gt;code_begin();
1551   _handler_blob = handler_blob;
1552   _handler = handler;
1553   return handler;
1554 }
1555 
1556 void SignatureHandlerLibrary::initialize() {
1557   if (_fingerprints != NULL) {
1558     return;
1559   }
1560   if (set_handler_blob() == NULL) {
1561     vm_exit_out_of_memory(blob_size, OOM_MALLOC_ERROR, &quot;native signature handlers&quot;);
1562   }
1563 
1564   BufferBlob* bb = BufferBlob::create(&quot;Signature Handler Temp Buffer&quot;,
1565                                       SignatureHandlerLibrary::buffer_size);
1566   _buffer = bb-&gt;code_begin();
1567 
1568   _fingerprints = new(ResourceObj::C_HEAP, mtCode)GrowableArray&lt;uint64_t&gt;(32, mtCode);
1569   _handlers     = new(ResourceObj::C_HEAP, mtCode)GrowableArray&lt;address&gt;(32, mtCode);
1570 }
1571 
1572 address SignatureHandlerLibrary::set_handler(CodeBuffer* buffer) {
1573   address handler   = _handler;
1574   int     insts_size = buffer-&gt;pure_insts_size();
1575   if (handler + insts_size &gt; _handler_blob-&gt;code_end()) {
1576     // get a new handler blob
1577     handler = set_handler_blob();
1578   }
1579   if (handler != NULL) {
1580     memcpy(handler, buffer-&gt;insts_begin(), insts_size);
1581     pd_set_handler(handler);
1582     ICache::invalidate_range(handler, insts_size);
1583     _handler = handler + insts_size;
1584   }
1585   return handler;
1586 }
1587 
1588 void SignatureHandlerLibrary::add(const methodHandle&amp; method) {
1589   if (method-&gt;signature_handler() == NULL) {
1590     // use slow signature handler if we can&#39;t do better
1591     int handler_index = -1;
1592     // check if we can use customized (fast) signature handler
1593     if (UseFastSignatureHandlers &amp;&amp; method-&gt;size_of_parameters() &lt;= Fingerprinter::fp_max_size_of_parameters) {
1594       // use customized signature handler
1595       MutexLocker mu(SignatureHandlerLibrary_lock);
1596       // make sure data structure is initialized
1597       initialize();
1598       // lookup method signature&#39;s fingerprint
1599       uint64_t fingerprint = Fingerprinter(method).fingerprint();
1600       // allow CPU dependant code to optimize the fingerprints for the fast handler
1601       fingerprint = InterpreterRuntime::normalize_fast_native_fingerprint(fingerprint);
1602       handler_index = _fingerprints-&gt;find(fingerprint);
1603       // create handler if necessary
1604       if (handler_index &lt; 0) {
1605         ResourceMark rm;
1606         ptrdiff_t align_offset = align_up(_buffer, CodeEntryAlignment) - (address)_buffer;
1607         CodeBuffer buffer((address)(_buffer + align_offset),
1608                           SignatureHandlerLibrary::buffer_size - align_offset);
1609         InterpreterRuntime::SignatureHandlerGenerator(method, &amp;buffer).generate(fingerprint);
1610         // copy into code heap
1611         address handler = set_handler(&amp;buffer);
1612         if (handler == NULL) {
1613           // use slow signature handler (without memorizing it in the fingerprints)
1614         } else {
1615           // debugging suppport
1616           if (PrintSignatureHandlers &amp;&amp; (handler != Interpreter::slow_signature_handler())) {
1617             ttyLocker ttyl;
1618             tty-&gt;cr();
1619             tty-&gt;print_cr(&quot;argument handler #%d for: %s %s (fingerprint = &quot; UINT64_FORMAT &quot;, %d bytes generated)&quot;,
1620                           _handlers-&gt;length(),
1621                           (method-&gt;is_static() ? &quot;static&quot; : &quot;receiver&quot;),
1622                           method-&gt;name_and_sig_as_C_string(),
1623                           fingerprint,
1624                           buffer.insts_size());
1625             if (buffer.insts_size() &gt; 0) {
1626               Disassembler::decode(handler, handler + buffer.insts_size());
1627             }
1628 #ifndef PRODUCT
1629             address rh_begin = Interpreter::result_handler(method()-&gt;result_type());
1630             if (CodeCache::contains(rh_begin)) {
1631               // else it might be special platform dependent values
1632               tty-&gt;print_cr(&quot; --- associated result handler ---&quot;);
1633               address rh_end = rh_begin;
1634               while (*(int*)rh_end != 0) {
1635                 rh_end += sizeof(int);
1636               }
1637               Disassembler::decode(rh_begin, rh_end);
1638             } else {
1639               tty-&gt;print_cr(&quot; associated result handler: &quot; PTR_FORMAT, p2i(rh_begin));
1640             }
1641 #endif
1642           }
1643           // add handler to library
1644           _fingerprints-&gt;append(fingerprint);
1645           _handlers-&gt;append(handler);
1646           // set handler index
1647           assert(_fingerprints-&gt;length() == _handlers-&gt;length(), &quot;sanity check&quot;);
1648           handler_index = _fingerprints-&gt;length() - 1;
1649         }
1650       }
1651       // Set handler under SignatureHandlerLibrary_lock
1652       if (handler_index &lt; 0) {
1653         // use generic signature handler
1654         method-&gt;set_signature_handler(Interpreter::slow_signature_handler());
1655       } else {
1656         // set handler
1657         method-&gt;set_signature_handler(_handlers-&gt;at(handler_index));
1658       }
1659     } else {
1660       DEBUG_ONLY(Thread::current()-&gt;check_possible_safepoint());
1661       // use generic signature handler
1662       method-&gt;set_signature_handler(Interpreter::slow_signature_handler());
1663     }
1664   }
1665 #ifdef ASSERT
1666   int handler_index = -1;
1667   int fingerprint_index = -2;
1668   {
1669     // &#39;_handlers&#39; and &#39;_fingerprints&#39; are &#39;GrowableArray&#39;s and are NOT synchronized
1670     // in any way if accessed from multiple threads. To avoid races with another
1671     // thread which may change the arrays in the above, mutex protected block, we
1672     // have to protect this read access here with the same mutex as well!
1673     MutexLocker mu(SignatureHandlerLibrary_lock);
1674     if (_handlers != NULL) {
1675       handler_index = _handlers-&gt;find(method-&gt;signature_handler());
1676       uint64_t fingerprint = Fingerprinter(method).fingerprint();
1677       fingerprint = InterpreterRuntime::normalize_fast_native_fingerprint(fingerprint);
1678       fingerprint_index = _fingerprints-&gt;find(fingerprint);
1679     }
1680   }
1681   assert(method-&gt;signature_handler() == Interpreter::slow_signature_handler() ||
1682          handler_index == fingerprint_index, &quot;sanity check&quot;);
1683 #endif // ASSERT
1684 }
1685 
1686 void SignatureHandlerLibrary::add(uint64_t fingerprint, address handler) {
1687   int handler_index = -1;
1688   // use customized signature handler
1689   MutexLocker mu(SignatureHandlerLibrary_lock);
1690   // make sure data structure is initialized
1691   initialize();
1692   fingerprint = InterpreterRuntime::normalize_fast_native_fingerprint(fingerprint);
1693   handler_index = _fingerprints-&gt;find(fingerprint);
1694   // create handler if necessary
1695   if (handler_index &lt; 0) {
1696     if (PrintSignatureHandlers &amp;&amp; (handler != Interpreter::slow_signature_handler())) {
1697       tty-&gt;cr();
1698       tty-&gt;print_cr(&quot;argument handler #%d at &quot; PTR_FORMAT &quot; for fingerprint &quot; UINT64_FORMAT,
1699                     _handlers-&gt;length(),
1700                     p2i(handler),
1701                     fingerprint);
1702     }
1703     _fingerprints-&gt;append(fingerprint);
1704     _handlers-&gt;append(handler);
1705   } else {
1706     if (PrintSignatureHandlers) {
1707       tty-&gt;cr();
1708       tty-&gt;print_cr(&quot;duplicate argument handler #%d for fingerprint &quot; UINT64_FORMAT &quot;(old: &quot; PTR_FORMAT &quot;, new : &quot; PTR_FORMAT &quot;)&quot;,
1709                     _handlers-&gt;length(),
1710                     fingerprint,
1711                     p2i(_handlers-&gt;at(handler_index)),
1712                     p2i(handler));
1713     }
1714   }
1715 }
1716 
1717 
1718 BufferBlob*              SignatureHandlerLibrary::_handler_blob = NULL;
1719 address                  SignatureHandlerLibrary::_handler      = NULL;
1720 GrowableArray&lt;uint64_t&gt;* SignatureHandlerLibrary::_fingerprints = NULL;
1721 GrowableArray&lt;address&gt;*  SignatureHandlerLibrary::_handlers     = NULL;
1722 address                  SignatureHandlerLibrary::_buffer       = NULL;
1723 
1724 
1725 JRT_ENTRY(void, InterpreterRuntime::prepare_native_call(JavaThread* thread, Method* method))
1726   methodHandle m(thread, method);
1727   assert(m-&gt;is_native(), &quot;sanity check&quot;);
1728   // lookup native function entry point if it doesn&#39;t exist
1729   bool in_base_library;
1730   if (!m-&gt;has_native_function()) {
1731     NativeLookup::lookup(m, in_base_library, CHECK);
1732   }
1733   // make sure signature handler is installed
1734   SignatureHandlerLibrary::add(m);
1735   // The interpreter entry point checks the signature handler first,
1736   // before trying to fetch the native entry point and klass mirror.
1737   // We must set the signature handler last, so that multiple processors
1738   // preparing the same method will be sure to see non-null entry &amp; mirror.
1739 JRT_END
1740 
1741 #if defined(IA32) || defined(AMD64) || defined(ARM)
1742 JRT_LEAF(void, InterpreterRuntime::popframe_move_outgoing_args(JavaThread* thread, void* src_address, void* dest_address))
1743   if (src_address == dest_address) {
1744     return;
1745   }
1746   ResetNoHandleMark rnm; // In a LEAF entry.
1747   HandleMark hm;
1748   ResourceMark rm;
1749   LastFrameAccessor last_frame(thread);
1750   assert(last_frame.is_interpreted_frame(), &quot;&quot;);
1751   jint bci = last_frame.bci();
1752   methodHandle mh(thread, last_frame.method());
1753   Bytecode_invoke invoke(mh, bci);
1754   ArgumentSizeComputer asc(invoke.signature());
1755   int size_of_arguments = (asc.size() + (invoke.has_receiver() ? 1 : 0)); // receiver
1756   Copy::conjoint_jbytes(src_address, dest_address,
1757                        size_of_arguments * Interpreter::stackElementSize);
1758 JRT_END
1759 #endif
1760 
1761 #if INCLUDE_JVMTI
1762 // This is a support of the JVMTI PopFrame interface.
1763 // Make sure it is an invokestatic of a polymorphic intrinsic that has a member_name argument
1764 // and return it as a vm_result so that it can be reloaded in the list of invokestatic parameters.
1765 // The member_name argument is a saved reference (in local#0) to the member_name.
1766 // For backward compatibility with some JDK versions (7, 8) it can also be a direct method handle.
1767 // FIXME: remove DMH case after j.l.i.InvokerBytecodeGenerator code shape is updated.
1768 JRT_ENTRY(void, InterpreterRuntime::member_name_arg_or_null(JavaThread* thread, address member_name,
1769                                                             Method* method, address bcp))
1770   Bytecodes::Code code = Bytecodes::code_at(method, bcp);
1771   if (code != Bytecodes::_invokestatic) {
1772     return;
1773   }
1774   ConstantPool* cpool = method-&gt;constants();
1775   int cp_index = Bytes::get_native_u2(bcp + 1) + ConstantPool::CPCACHE_INDEX_TAG;
1776   Symbol* cname = cpool-&gt;klass_name_at(cpool-&gt;klass_ref_index_at(cp_index));
1777   Symbol* mname = cpool-&gt;name_ref_at(cp_index);
1778 
1779   if (MethodHandles::has_member_arg(cname, mname)) {
1780     oop member_name_oop = (oop) member_name;
1781     if (java_lang_invoke_DirectMethodHandle::is_instance(member_name_oop)) {
1782       // FIXME: remove after j.l.i.InvokerBytecodeGenerator code shape is updated.
1783       member_name_oop = java_lang_invoke_DirectMethodHandle::member(member_name_oop);
1784     }
1785     thread-&gt;set_vm_result(member_name_oop);
1786   } else {
1787     thread-&gt;set_vm_result(NULL);
1788   }
1789 JRT_END
1790 #endif // INCLUDE_JVMTI
1791 
1792 #ifndef PRODUCT
1793 // This must be a JRT_LEAF function because the interpreter must save registers on x86 to
1794 // call this, which changes rsp and makes the interpreter&#39;s expression stack not walkable.
1795 // The generated code still uses call_VM because that will set up the frame pointer for
1796 // bcp and method.
1797 JRT_LEAF(intptr_t, InterpreterRuntime::trace_bytecode(JavaThread* thread, intptr_t preserve_this_value, intptr_t tos, intptr_t tos2))
1798   LastFrameAccessor last_frame(thread);
1799   assert(last_frame.is_interpreted_frame(), &quot;must be an interpreted frame&quot;);
1800   methodHandle mh(thread, last_frame.method());
1801   BytecodeTracer::trace(mh, last_frame.bcp(), tos, tos2);
1802   return preserve_this_value;
1803 JRT_END
1804 #endif // !PRODUCT
    </pre>
  </body>
</html>