<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff src/hotspot/share/opto/library_call.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="../memory/metaspaceShared.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="loopopts.cpp.cdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/library_call.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 40,10 ***</span>
<span class="line-new-header">--- 40,11 ---</span>
  #include &quot;opto/callGenerator.hpp&quot;
  #include &quot;opto/castnode.hpp&quot;
  #include &quot;opto/cfgnode.hpp&quot;
  #include &quot;opto/convertnode.hpp&quot;
  #include &quot;opto/countbitsnode.hpp&quot;
<span class="line-added">+ #include &quot;opto/inlinetypenode.hpp&quot;</span>
  #include &quot;opto/intrinsicnode.hpp&quot;
  #include &quot;opto/idealKit.hpp&quot;
  #include &quot;opto/mathexactnode.hpp&quot;
  #include &quot;opto/movenode.hpp&quot;
  #include &quot;opto/mulnode.hpp&quot;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 132,13 ***</span>
    bool  try_to_inline(int predicate);
    Node* try_to_predicate(int predicate);
  
    void push_result() {
      // Push the result onto the stack.
<span class="line-modified">!     if (!stopped() &amp;&amp; result() != NULL) {</span>
<span class="line-modified">!       BasicType bt = result()-&gt;bottom_type()-&gt;basic_type();</span>
<span class="line-modified">!       push_node(bt, result());</span>
      }
    }
  
   private:
    void fatal_unexpected_iid(vmIntrinsics::ID iid) {
<span class="line-new-header">--- 133,21 ---</span>
    bool  try_to_inline(int predicate);
    Node* try_to_predicate(int predicate);
  
    void push_result() {
      // Push the result onto the stack.
<span class="line-modified">!     Node* res = result();</span>
<span class="line-modified">!     if (!stopped() &amp;&amp; res != NULL) {</span>
<span class="line-modified">!       BasicType bt = res-&gt;bottom_type()-&gt;basic_type();</span>
<span class="line-added">+       if (C-&gt;inlining_incrementally() &amp;&amp; res-&gt;is_InlineType()) {</span>
<span class="line-added">+         // The caller expects an oop when incrementally inlining an intrinsic that returns an</span>
<span class="line-added">+         // inline type. Make sure the call is re-executed if the allocation triggers a deoptimization.</span>
<span class="line-added">+         PreserveReexecuteState preexecs(this);</span>
<span class="line-added">+         jvms()-&gt;set_should_reexecute(true);</span>
<span class="line-added">+         res = res-&gt;as_InlineType()-&gt;buffer(this);</span>
<span class="line-added">+       }</span>
<span class="line-added">+       push_node(bt, res);</span>
      }
    }
  
   private:
    void fatal_unexpected_iid(vmIntrinsics::ID iid) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 162,11 ***</span>
                               Node* array_length,
                               RegionNode* region);
    void  generate_string_range_check(Node* array, Node* offset,
                                      Node* length, bool char_count);
    Node* generate_current_thread(Node* &amp;tls_output);
<span class="line-removed">-   Node* load_mirror_from_klass(Node* klass);</span>
    Node* load_klass_from_mirror_common(Node* mirror, bool never_see_null,
                                        RegionNode* region, int null_path,
                                        int offset);
    Node* load_klass_from_mirror(Node* mirror, bool never_see_null,
                                 RegionNode* region, int null_path) {
<span class="line-new-header">--- 171,10 ---</span>
</pre>
<hr />
<pre>
<span class="line-old-header">*** 184,25 ***</span>
    }
    Node* generate_access_flags_guard(Node* kls,
                                      int modifier_mask, int modifier_bits,
                                      RegionNode* region);
    Node* generate_interface_guard(Node* kls, RegionNode* region);
    Node* generate_hidden_class_guard(Node* kls, RegionNode* region);
    Node* generate_array_guard(Node* kls, RegionNode* region) {
<span class="line-modified">!     return generate_array_guard_common(kls, region, false, false);</span>
    }
    Node* generate_non_array_guard(Node* kls, RegionNode* region) {
<span class="line-modified">!     return generate_array_guard_common(kls, region, false, true);</span>
    }
    Node* generate_objArray_guard(Node* kls, RegionNode* region) {
<span class="line-modified">!     return generate_array_guard_common(kls, region, true, false);</span>
    }
    Node* generate_non_objArray_guard(Node* kls, RegionNode* region) {
<span class="line-modified">!     return generate_array_guard_common(kls, region, true, true);</span>
    }
<span class="line-modified">!   Node* generate_array_guard_common(Node* kls, RegionNode* region,</span>
<span class="line-removed">-                                     bool obj_array, bool not_array);</span>
    Node* generate_virtual_guard(Node* obj_klass, RegionNode* slow_region);
    CallJavaNode* generate_method_call(vmIntrinsics::ID method_id,
                                       bool is_virtual = false, bool is_static = false);
    CallJavaNode* generate_method_call_static(vmIntrinsics::ID method_id) {
      return generate_method_call(method_id, false, true);
<span class="line-new-header">--- 192,43 ---</span>
    }
    Node* generate_access_flags_guard(Node* kls,
                                      int modifier_mask, int modifier_bits,
                                      RegionNode* region);
    Node* generate_interface_guard(Node* kls, RegionNode* region);
<span class="line-added">+   Node* generate_value_guard(Node* kls, RegionNode* region);</span>
<span class="line-added">+ </span>
<span class="line-added">+   enum ArrayKind {</span>
<span class="line-added">+     AnyArray,</span>
<span class="line-added">+     NonArray,</span>
<span class="line-added">+     ObjectArray,</span>
<span class="line-added">+     NonObjectArray,</span>
<span class="line-added">+     TypeArray,</span>
<span class="line-added">+     FlatArray</span>
<span class="line-added">+   };</span>
<span class="line-added">+ </span>
    Node* generate_hidden_class_guard(Node* kls, RegionNode* region);
<span class="line-added">+ </span>
    Node* generate_array_guard(Node* kls, RegionNode* region) {
<span class="line-modified">!     return generate_array_guard_common(kls, region, AnyArray);</span>
    }
    Node* generate_non_array_guard(Node* kls, RegionNode* region) {
<span class="line-modified">!     return generate_array_guard_common(kls, region, NonArray);</span>
    }
    Node* generate_objArray_guard(Node* kls, RegionNode* region) {
<span class="line-modified">!     return generate_array_guard_common(kls, region, ObjectArray);</span>
    }
    Node* generate_non_objArray_guard(Node* kls, RegionNode* region) {
<span class="line-modified">!     return generate_array_guard_common(kls, region, NonObjectArray);</span>
<span class="line-added">+   }</span>
<span class="line-added">+   Node* generate_typeArray_guard(Node* kls, RegionNode* region) {</span>
<span class="line-added">+     return generate_array_guard_common(kls, region, TypeArray);</span>
<span class="line-added">+   }</span>
<span class="line-added">+   Node* generate_flatArray_guard(Node* kls, RegionNode* region) {</span>
<span class="line-added">+     assert(UseFlatArray, &quot;can never be flattened&quot;);</span>
<span class="line-added">+     return generate_array_guard_common(kls, region, FlatArray);</span>
    }
<span class="line-modified">!   Node* generate_array_guard_common(Node* kls, RegionNode* region, ArrayKind kind);</span>
    Node* generate_virtual_guard(Node* obj_klass, RegionNode* slow_region);
    CallJavaNode* generate_method_call(vmIntrinsics::ID method_id,
                                       bool is_virtual = false, bool is_static = false);
    CallJavaNode* generate_method_call_static(vmIntrinsics::ID method_id) {
      return generate_method_call(method_id, false, true);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 256,10 ***</span>
<span class="line-new-header">--- 282,12 ---</span>
    bool inline_unsafe_allocate();
    bool inline_unsafe_newArray(bool uninitialized);
    bool inline_unsafe_writeback0();
    bool inline_unsafe_writebackSync0(bool is_pre);
    bool inline_unsafe_copyMemory();
<span class="line-added">+   bool inline_unsafe_make_private_buffer();</span>
<span class="line-added">+   bool inline_unsafe_finish_private_buffer();</span>
    bool inline_native_currentThread();
  
    bool inline_native_time_funcs(address method, const char* funcName);
  #ifdef JFR_HAVE_INTRINSICS
    bool inline_native_classID();
</pre>
<hr />
<pre>
<span class="line-old-header">*** 600,29 ***</span>
<span class="line-new-header">--- 628,33 ---</span>
    case vmIntrinsics::_compressStringC:
    case vmIntrinsics::_compressStringB:          return inline_string_copy( is_compress);
    case vmIntrinsics::_inflateStringC:
    case vmIntrinsics::_inflateStringB:           return inline_string_copy(!is_compress);
  
<span class="line-added">+   case vmIntrinsics::_makePrivateBuffer:        return inline_unsafe_make_private_buffer();</span>
<span class="line-added">+   case vmIntrinsics::_finishPrivateBuffer:      return inline_unsafe_finish_private_buffer();</span>
    case vmIntrinsics::_getReference:             return inline_unsafe_access(!is_store, T_OBJECT,   Relaxed, false);
    case vmIntrinsics::_getBoolean:               return inline_unsafe_access(!is_store, T_BOOLEAN,  Relaxed, false);
    case vmIntrinsics::_getByte:                  return inline_unsafe_access(!is_store, T_BYTE,     Relaxed, false);
    case vmIntrinsics::_getShort:                 return inline_unsafe_access(!is_store, T_SHORT,    Relaxed, false);
    case vmIntrinsics::_getChar:                  return inline_unsafe_access(!is_store, T_CHAR,     Relaxed, false);
    case vmIntrinsics::_getInt:                   return inline_unsafe_access(!is_store, T_INT,      Relaxed, false);
    case vmIntrinsics::_getLong:                  return inline_unsafe_access(!is_store, T_LONG,     Relaxed, false);
    case vmIntrinsics::_getFloat:                 return inline_unsafe_access(!is_store, T_FLOAT,    Relaxed, false);
    case vmIntrinsics::_getDouble:                return inline_unsafe_access(!is_store, T_DOUBLE,   Relaxed, false);
<span class="line-added">+   case vmIntrinsics::_getValue:                 return inline_unsafe_access(!is_store, T_INLINE_TYPE,Relaxed, false);</span>
  
    case vmIntrinsics::_putReference:             return inline_unsafe_access( is_store, T_OBJECT,   Relaxed, false);
    case vmIntrinsics::_putBoolean:               return inline_unsafe_access( is_store, T_BOOLEAN,  Relaxed, false);
    case vmIntrinsics::_putByte:                  return inline_unsafe_access( is_store, T_BYTE,     Relaxed, false);
    case vmIntrinsics::_putShort:                 return inline_unsafe_access( is_store, T_SHORT,    Relaxed, false);
    case vmIntrinsics::_putChar:                  return inline_unsafe_access( is_store, T_CHAR,     Relaxed, false);
    case vmIntrinsics::_putInt:                   return inline_unsafe_access( is_store, T_INT,      Relaxed, false);
    case vmIntrinsics::_putLong:                  return inline_unsafe_access( is_store, T_LONG,     Relaxed, false);
    case vmIntrinsics::_putFloat:                 return inline_unsafe_access( is_store, T_FLOAT,    Relaxed, false);
    case vmIntrinsics::_putDouble:                return inline_unsafe_access( is_store, T_DOUBLE,   Relaxed, false);
<span class="line-added">+   case vmIntrinsics::_putValue:                 return inline_unsafe_access( is_store, T_INLINE_TYPE,Relaxed, false);</span>
  
    case vmIntrinsics::_getReferenceVolatile:     return inline_unsafe_access(!is_store, T_OBJECT,   Volatile, false);
    case vmIntrinsics::_getBooleanVolatile:       return inline_unsafe_access(!is_store, T_BOOLEAN,  Volatile, false);
    case vmIntrinsics::_getByteVolatile:          return inline_unsafe_access(!is_store, T_BYTE,     Volatile, false);
    case vmIntrinsics::_getShortVolatile:         return inline_unsafe_access(!is_store, T_SHORT,    Volatile, false);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2394,22 ***</span>
      ciSignature* sig = callee()-&gt;signature();
  #ifdef ASSERT
      if (!is_store) {
        // Object getReference(Object base, int/long offset), etc.
        BasicType rtype = sig-&gt;return_type()-&gt;basic_type();
<span class="line-modified">!       assert(rtype == type, &quot;getter must return the expected value&quot;);</span>
<span class="line-modified">!       assert(sig-&gt;count() == 2, &quot;oop getter has 2 arguments&quot;);</span>
        assert(sig-&gt;type_at(0)-&gt;basic_type() == T_OBJECT, &quot;getter base is object&quot;);
        assert(sig-&gt;type_at(1)-&gt;basic_type() == T_LONG, &quot;getter offset is correct&quot;);
      } else {
        // void putReference(Object base, int/long offset, Object x), etc.
        assert(sig-&gt;return_type()-&gt;basic_type() == T_VOID, &quot;putter must not return a value&quot;);
<span class="line-modified">!       assert(sig-&gt;count() == 3, &quot;oop putter has 3 arguments&quot;);</span>
        assert(sig-&gt;type_at(0)-&gt;basic_type() == T_OBJECT, &quot;putter base is object&quot;);
        assert(sig-&gt;type_at(1)-&gt;basic_type() == T_LONG, &quot;putter offset is correct&quot;);
        BasicType vtype = sig-&gt;type_at(sig-&gt;count()-1)-&gt;basic_type();
<span class="line-modified">!       assert(vtype == type, &quot;putter must accept the expected value&quot;);</span>
      }
  #endif // ASSERT
   }
  #endif //PRODUCT
  
<span class="line-new-header">--- 2426,22 ---</span>
      ciSignature* sig = callee()-&gt;signature();
  #ifdef ASSERT
      if (!is_store) {
        // Object getReference(Object base, int/long offset), etc.
        BasicType rtype = sig-&gt;return_type()-&gt;basic_type();
<span class="line-modified">!       assert(rtype == type || (rtype == T_OBJECT &amp;&amp; type == T_INLINE_TYPE), &quot;getter must return the expected value&quot;);</span>
<span class="line-modified">!       assert(sig-&gt;count() == 2 || (type == T_INLINE_TYPE &amp;&amp; sig-&gt;count() == 3), &quot;oop getter has 2 or 3 arguments&quot;);</span>
        assert(sig-&gt;type_at(0)-&gt;basic_type() == T_OBJECT, &quot;getter base is object&quot;);
        assert(sig-&gt;type_at(1)-&gt;basic_type() == T_LONG, &quot;getter offset is correct&quot;);
      } else {
        // void putReference(Object base, int/long offset, Object x), etc.
        assert(sig-&gt;return_type()-&gt;basic_type() == T_VOID, &quot;putter must not return a value&quot;);
<span class="line-modified">!       assert(sig-&gt;count() == 3 || (type == T_INLINE_TYPE &amp;&amp; sig-&gt;count() == 4), &quot;oop putter has 3 arguments&quot;);</span>
        assert(sig-&gt;type_at(0)-&gt;basic_type() == T_OBJECT, &quot;putter base is object&quot;);
        assert(sig-&gt;type_at(1)-&gt;basic_type() == T_LONG, &quot;putter offset is correct&quot;);
        BasicType vtype = sig-&gt;type_at(sig-&gt;count()-1)-&gt;basic_type();
<span class="line-modified">!       assert(vtype == type || (type == T_INLINE_TYPE &amp;&amp; vtype == T_OBJECT), &quot;putter must accept the expected value&quot;);</span>
      }
  #endif // ASSERT
   }
  #endif //PRODUCT
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2430,16 ***</span>
    // We currently rely on the cookies produced by Unsafe.xxxFieldOffset
    // to be plain byte offsets, which are also the same as those accepted
    // by oopDesc::field_addr.
    assert(Unsafe_field_offset_to_byte_offset(11) == 11,
           &quot;fieldOffset must be byte-scaled&quot;);
    // 32-bit machines ignore the high half!
    offset = ConvL2X(offset);
    adr = make_unsafe_address(base, offset, is_store ? ACCESS_WRITE : ACCESS_READ, type, kind == Relaxed);
  
    if (_gvn.type(base)-&gt;isa_ptr() == TypePtr::NULL_PTR) {
<span class="line-modified">!     if (type != T_OBJECT) {</span>
        decorators |= IN_NATIVE; // off-heap primitive access
      } else {
        return false; // off-heap oop accesses are not supported
      }
    } else {
<span class="line-new-header">--- 2462,78 ---</span>
    // We currently rely on the cookies produced by Unsafe.xxxFieldOffset
    // to be plain byte offsets, which are also the same as those accepted
    // by oopDesc::field_addr.
    assert(Unsafe_field_offset_to_byte_offset(11) == 11,
           &quot;fieldOffset must be byte-scaled&quot;);
<span class="line-added">+ </span>
<span class="line-added">+   ciInlineKlass* inline_klass = NULL;</span>
<span class="line-added">+   if (type == T_INLINE_TYPE) {</span>
<span class="line-added">+     Node* cls = null_check(argument(4));</span>
<span class="line-added">+     if (stopped()) {</span>
<span class="line-added">+       return true;</span>
<span class="line-added">+     }</span>
<span class="line-added">+     Node* kls = load_klass_from_mirror(cls, false, NULL, 0);</span>
<span class="line-added">+     const TypeKlassPtr* kls_t = _gvn.type(kls)-&gt;isa_klassptr();</span>
<span class="line-added">+     if (!kls_t-&gt;klass_is_exact()) {</span>
<span class="line-added">+       return false;</span>
<span class="line-added">+     }</span>
<span class="line-added">+     ciKlass* klass = kls_t-&gt;klass();</span>
<span class="line-added">+     if (!klass-&gt;is_inlinetype()) {</span>
<span class="line-added">+       return false;</span>
<span class="line-added">+     }</span>
<span class="line-added">+     inline_klass = klass-&gt;as_inline_klass();</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   receiver = null_check(receiver);</span>
<span class="line-added">+   if (stopped()) {</span>
<span class="line-added">+     return true;</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   if (base-&gt;is_InlineType()) {</span>
<span class="line-added">+     InlineTypeNode* vt = base-&gt;as_InlineType();</span>
<span class="line-added">+ </span>
<span class="line-added">+     if (is_store) {</span>
<span class="line-added">+       if (!vt-&gt;is_allocated(&amp;_gvn) || !_gvn.type(vt)-&gt;is_inlinetype()-&gt;larval()) {</span>
<span class="line-added">+         return false;</span>
<span class="line-added">+       }</span>
<span class="line-added">+       base = vt-&gt;get_oop();</span>
<span class="line-added">+     } else {</span>
<span class="line-added">+       if (offset-&gt;is_Con()) {</span>
<span class="line-added">+         long off = find_long_con(offset, 0);</span>
<span class="line-added">+         ciInlineKlass* vk = vt-&gt;type()-&gt;inline_klass();</span>
<span class="line-added">+         if ((long)(int)off != off || !vk-&gt;contains_field_offset(off)) {</span>
<span class="line-added">+           return false;</span>
<span class="line-added">+         }</span>
<span class="line-added">+ </span>
<span class="line-added">+         ciField* f = vk-&gt;get_non_flattened_field_by_offset((int)off);</span>
<span class="line-added">+ </span>
<span class="line-added">+         if (f != NULL) {</span>
<span class="line-added">+           BasicType bt = f-&gt;layout_type();</span>
<span class="line-added">+           if (bt == T_ARRAY || bt == T_NARROWOOP) {</span>
<span class="line-added">+             bt = T_OBJECT;</span>
<span class="line-added">+           }</span>
<span class="line-added">+           if (bt == type) {</span>
<span class="line-added">+             if (bt != T_INLINE_TYPE || f-&gt;type() == inline_klass) {</span>
<span class="line-added">+               set_result(vt-&gt;field_value_by_offset((int)off, false));</span>
<span class="line-added">+               return true;</span>
<span class="line-added">+             }</span>
<span class="line-added">+           }</span>
<span class="line-added">+         }</span>
<span class="line-added">+       }</span>
<span class="line-added">+       // Re-execute the unsafe access if allocation triggers deoptimization.</span>
<span class="line-added">+       PreserveReexecuteState preexecs(this);</span>
<span class="line-added">+       jvms()-&gt;set_should_reexecute(true);</span>
<span class="line-added">+       base = vt-&gt;buffer(this)-&gt;get_oop();</span>
<span class="line-added">+     }</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
    // 32-bit machines ignore the high half!
    offset = ConvL2X(offset);
    adr = make_unsafe_address(base, offset, is_store ? ACCESS_WRITE : ACCESS_READ, type, kind == Relaxed);
  
    if (_gvn.type(base)-&gt;isa_ptr() == TypePtr::NULL_PTR) {
<span class="line-modified">!     if (type != T_OBJECT &amp;&amp; (inline_klass == NULL || !inline_klass-&gt;has_object_fields())) {</span>
        decorators |= IN_NATIVE; // off-heap primitive access
      } else {
        return false; // off-heap oop accesses are not supported
      }
    } else {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2451,11 ***</span>
  
    if (!can_access_non_heap) {
      decorators |= IN_HEAP;
    }
  
<span class="line-modified">!   val = is_store ? argument(4) : NULL;</span>
  
    const TypePtr* adr_type = _gvn.type(adr)-&gt;isa_ptr();
    if (adr_type == TypePtr::NULL_PTR) {
      return false; // off-heap access with zero address
    }
<span class="line-new-header">--- 2545,11 ---</span>
  
    if (!can_access_non_heap) {
      decorators |= IN_HEAP;
    }
  
<span class="line-modified">!   val = is_store ? argument(4 + (type == T_INLINE_TYPE ? 1 : 0)) : NULL;</span>
  
    const TypePtr* adr_type = _gvn.type(adr)-&gt;isa_ptr();
    if (adr_type == TypePtr::NULL_PTR) {
      return false; // off-heap access with zero address
    }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2468,11 ***</span>
        alias_type-&gt;adr_type() == TypeAryPtr::RANGE) {
      return false; // not supported
    }
  
    bool mismatched = false;
<span class="line-modified">!   BasicType bt = alias_type-&gt;basic_type();</span>
    if (bt != T_ILLEGAL) {
      assert(alias_type-&gt;adr_type()-&gt;is_oopptr(), &quot;should be on-heap access&quot;);
      if (bt == T_BYTE &amp;&amp; adr_type-&gt;isa_aryptr()) {
        // Alias type doesn&#39;t differentiate between byte[] and boolean[]).
        // Use address type to get the element type.
<span class="line-new-header">--- 2562,35 ---</span>
        alias_type-&gt;adr_type() == TypeAryPtr::RANGE) {
      return false; // not supported
    }
  
    bool mismatched = false;
<span class="line-modified">!   BasicType bt = T_ILLEGAL;</span>
<span class="line-added">+   ciField* field = NULL;</span>
<span class="line-added">+   if (adr_type-&gt;isa_instptr()) {</span>
<span class="line-added">+     const TypeInstPtr* instptr = adr_type-&gt;is_instptr();</span>
<span class="line-added">+     ciInstanceKlass* k = instptr-&gt;klass()-&gt;as_instance_klass();</span>
<span class="line-added">+     int off = instptr-&gt;offset();</span>
<span class="line-added">+     if (instptr-&gt;const_oop() != NULL &amp;&amp;</span>
<span class="line-added">+         instptr-&gt;klass() == ciEnv::current()-&gt;Class_klass() &amp;&amp;</span>
<span class="line-added">+         instptr-&gt;offset() &gt;= (instptr-&gt;klass()-&gt;as_instance_klass()-&gt;size_helper() * wordSize)) {</span>
<span class="line-added">+       k = instptr-&gt;const_oop()-&gt;as_instance()-&gt;java_lang_Class_klass()-&gt;as_instance_klass();</span>
<span class="line-added">+       field = k-&gt;get_field_by_offset(off, true);</span>
<span class="line-added">+     } else {</span>
<span class="line-added">+       field = k-&gt;get_non_flattened_field_by_offset(off);</span>
<span class="line-added">+     }</span>
<span class="line-added">+     if (field != NULL) {</span>
<span class="line-added">+       bt = field-&gt;layout_type();</span>
<span class="line-added">+     }</span>
<span class="line-added">+     assert(bt == alias_type-&gt;basic_type() || bt == T_INLINE_TYPE, &quot;should match&quot;);</span>
<span class="line-added">+     if (field != NULL &amp;&amp; bt == T_INLINE_TYPE &amp;&amp; !field-&gt;is_flattened()) {</span>
<span class="line-added">+       bt = T_OBJECT;</span>
<span class="line-added">+     }</span>
<span class="line-added">+   } else {</span>
<span class="line-added">+     bt = alias_type-&gt;basic_type();</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
    if (bt != T_ILLEGAL) {
      assert(alias_type-&gt;adr_type()-&gt;is_oopptr(), &quot;should be on-heap access&quot;);
      if (bt == T_BYTE &amp;&amp; adr_type-&gt;isa_aryptr()) {
        // Alias type doesn&#39;t differentiate between byte[] and boolean[]).
        // Use address type to get the element type.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2489,10 ***</span>
<span class="line-new-header">--- 2607,31 ---</span>
      mismatched = (bt != type);
    } else if (alias_type-&gt;adr_type()-&gt;isa_oopptr()) {
      mismatched = true; // conservatively mark all &quot;wide&quot; on-heap accesses as mismatched
    }
  
<span class="line-added">+   if (type == T_INLINE_TYPE) {</span>
<span class="line-added">+     if (adr_type-&gt;isa_instptr()) {</span>
<span class="line-added">+       if (field == NULL || field-&gt;type() != inline_klass) {</span>
<span class="line-added">+         mismatched = true;</span>
<span class="line-added">+       }</span>
<span class="line-added">+     } else if (adr_type-&gt;isa_aryptr()) {</span>
<span class="line-added">+       const Type* elem = adr_type-&gt;is_aryptr()-&gt;elem();</span>
<span class="line-added">+       if (!elem-&gt;isa_inlinetype()) {</span>
<span class="line-added">+         mismatched = true;</span>
<span class="line-added">+       } else if (elem-&gt;inline_klass() != inline_klass) {</span>
<span class="line-added">+         mismatched = true;</span>
<span class="line-added">+       }</span>
<span class="line-added">+     }</span>
<span class="line-added">+     if (is_store) {</span>
<span class="line-added">+       const Type* val_t = _gvn.type(val);</span>
<span class="line-added">+       if (!val_t-&gt;isa_inlinetype() || val_t-&gt;inline_klass() != inline_klass) {</span>
<span class="line-added">+         return false;</span>
<span class="line-added">+       }</span>
<span class="line-added">+     }</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
    assert(!mismatched || alias_type-&gt;adr_type()-&gt;is_oopptr(), &quot;off-heap access can&#39;t be mismatched&quot;);
  
    if (mismatched) {
      decorators |= C2_MISMATCHED;
    }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2501,37 ***</span>
    const Type *value_type = Type::get_const_basic_type(type);
  
    // Figure out the memory ordering.
    decorators |= mo_decorator_for_access_kind(kind);
  
<span class="line-modified">!   if (!is_store &amp;&amp; type == T_OBJECT) {</span>
<span class="line-modified">!     const TypeOopPtr* tjp = sharpen_unsafe_type(alias_type, adr_type);</span>
<span class="line-modified">!     if (tjp != NULL) {</span>
<span class="line-modified">!       value_type = tjp;</span>
      }
    }
  
<span class="line-removed">-   receiver = null_check(receiver);</span>
<span class="line-removed">-   if (stopped()) {</span>
<span class="line-removed">-     return true;</span>
<span class="line-removed">-   }</span>
    // Heap pointers get a null-check from the interpreter,
    // as a courtesy.  However, this is not guaranteed by Unsafe,
    // and it is not possible to fully distinguish unintended nulls
    // from intended ones in this API.
  
    if (!is_store) {
      Node* p = NULL;
      // Try to constant fold a load from a constant field
<span class="line-modified">!     ciField* field = alias_type-&gt;field();</span>
      if (heap_base_oop != top() &amp;&amp; field != NULL &amp;&amp; field-&gt;is_constant() &amp;&amp; !mismatched) {
        // final or stable field
        p = make_constant_from_field(field, heap_base_oop);
      }
  
      if (p == NULL) { // Could not constant fold the load
<span class="line-modified">!       p = access_load_at(heap_base_oop, adr, adr_type, value_type, type, decorators);</span>
        // Normalize the value returned by getBoolean in the following cases
        if (type == T_BOOLEAN &amp;&amp;
            (mismatched ||
             heap_base_oop == top() ||                  // - heap_base_oop is NULL or
             (can_access_non_heap &amp;&amp; field == NULL))    // - heap_base_oop is potentially NULL
<span class="line-new-header">--- 2640,47 ---</span>
    const Type *value_type = Type::get_const_basic_type(type);
  
    // Figure out the memory ordering.
    decorators |= mo_decorator_for_access_kind(kind);
  
<span class="line-modified">!   if (!is_store) {</span>
<span class="line-modified">!     if (type == T_OBJECT) {</span>
<span class="line-modified">!       const TypeOopPtr* tjp = sharpen_unsafe_type(alias_type, adr_type);</span>
<span class="line-modified">!       if (tjp != NULL) {</span>
<span class="line-added">+         value_type = tjp;</span>
<span class="line-added">+       }</span>
<span class="line-added">+     } else if (type == T_INLINE_TYPE) {</span>
<span class="line-added">+       value_type = NULL;</span>
      }
    }
  
    // Heap pointers get a null-check from the interpreter,
    // as a courtesy.  However, this is not guaranteed by Unsafe,
    // and it is not possible to fully distinguish unintended nulls
    // from intended ones in this API.
  
    if (!is_store) {
      Node* p = NULL;
      // Try to constant fold a load from a constant field
<span class="line-modified">! </span>
      if (heap_base_oop != top() &amp;&amp; field != NULL &amp;&amp; field-&gt;is_constant() &amp;&amp; !mismatched) {
        // final or stable field
        p = make_constant_from_field(field, heap_base_oop);
      }
  
      if (p == NULL) { // Could not constant fold the load
<span class="line-modified">!       if (type == T_INLINE_TYPE) {</span>
<span class="line-added">+         if (adr_type-&gt;isa_instptr() &amp;&amp; !mismatched) {</span>
<span class="line-added">+           ciInstanceKlass* holder = adr_type-&gt;is_instptr()-&gt;klass()-&gt;as_instance_klass();</span>
<span class="line-added">+           int offset = adr_type-&gt;is_instptr()-&gt;offset();</span>
<span class="line-added">+           p = InlineTypeNode::make_from_flattened(this, inline_klass, base, base, holder, offset, decorators);</span>
<span class="line-added">+         } else {</span>
<span class="line-added">+           p = InlineTypeNode::make_from_flattened(this, inline_klass, base, adr, NULL, 0, decorators);</span>
<span class="line-added">+         }</span>
<span class="line-added">+       } else {</span>
<span class="line-added">+         p = access_load_at(heap_base_oop, adr, adr_type, value_type, type, decorators);</span>
<span class="line-added">+       }</span>
        // Normalize the value returned by getBoolean in the following cases
        if (type == T_BOOLEAN &amp;&amp;
            (mismatched ||
             heap_base_oop == top() ||                  // - heap_base_oop is NULL or
             (can_access_non_heap &amp;&amp; field == NULL))    // - heap_base_oop is potentially NULL
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2554,10 ***</span>
<span class="line-new-header">--- 2703,18 ---</span>
      }
      if (type == T_ADDRESS) {
        p = gvn().transform(new CastP2XNode(NULL, p));
        p = ConvX2UL(p);
      }
<span class="line-added">+     if (field != NULL &amp;&amp; field-&gt;type()-&gt;is_inlinetype() &amp;&amp; !field-&gt;is_flattened()) {</span>
<span class="line-added">+       // Load a non-flattened inline type from memory</span>
<span class="line-added">+       if (value_type-&gt;inline_klass()-&gt;is_scalarizable()) {</span>
<span class="line-added">+         p = InlineTypeNode::make_from_oop(this, p, value_type-&gt;inline_klass());</span>
<span class="line-added">+       } else {</span>
<span class="line-added">+         p = null2default(p, value_type-&gt;inline_klass());</span>
<span class="line-added">+       }</span>
<span class="line-added">+     }</span>
      // The load node has the control of the preceding MemBarCPUOrder.  All
      // following nodes will have the control of the MemBarCPUOrder inserted at
      // the end of this method.  So, pushing the load onto the stack at a later
      // point is fine.
      set_result(p);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2565,13 ***</span>
      if (bt == T_ADDRESS) {
        // Repackage the long as a pointer.
        val = ConvL2X(val);
        val = gvn().transform(new CastX2PNode(val));
      }
<span class="line-modified">!     access_store_at(heap_base_oop, adr, adr_type, val, value_type, type, decorators);</span>
    }
  
    return true;
  }
  
  //----------------------------inline_unsafe_load_store----------------------------
  // This method serves a couple of different customers (depending on LoadStoreKind):
<span class="line-new-header">--- 2722,70 ---</span>
      if (bt == T_ADDRESS) {
        // Repackage the long as a pointer.
        val = ConvL2X(val);
        val = gvn().transform(new CastX2PNode(val));
      }
<span class="line-modified">!     if (type == T_INLINE_TYPE) {</span>
<span class="line-added">+       if (adr_type-&gt;isa_instptr() &amp;&amp; !mismatched) {</span>
<span class="line-added">+         ciInstanceKlass* holder = adr_type-&gt;is_instptr()-&gt;klass()-&gt;as_instance_klass();</span>
<span class="line-added">+         int offset = adr_type-&gt;is_instptr()-&gt;offset();</span>
<span class="line-added">+         val-&gt;as_InlineType()-&gt;store_flattened(this, base, base, holder, offset, decorators);</span>
<span class="line-added">+       } else {</span>
<span class="line-added">+         val-&gt;as_InlineType()-&gt;store_flattened(this, base, adr, NULL, 0, decorators);</span>
<span class="line-added">+       }</span>
<span class="line-added">+     } else {</span>
<span class="line-added">+       access_store_at(heap_base_oop, adr, adr_type, val, value_type, type, decorators);</span>
<span class="line-added">+     }</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   if (argument(1)-&gt;is_InlineType() &amp;&amp; is_store) {</span>
<span class="line-added">+     Node* value = InlineTypeNode::make_from_oop(this, base, _gvn.type(base)-&gt;inline_klass());</span>
<span class="line-added">+     value = value-&gt;as_InlineType()-&gt;make_larval(this, false);</span>
<span class="line-added">+     replace_in_map(argument(1), value);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   return true;</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ bool LibraryCallKit::inline_unsafe_make_private_buffer() {</span>
<span class="line-added">+   Node* receiver = argument(0);</span>
<span class="line-added">+   Node* value = argument(1);</span>
<span class="line-added">+ </span>
<span class="line-added">+   receiver = null_check(receiver);</span>
<span class="line-added">+   if (stopped()) {</span>
<span class="line-added">+     return true;</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   if (!value-&gt;is_InlineType()) {</span>
<span class="line-added">+     return false;</span>
    }
  
<span class="line-added">+   set_result(value-&gt;as_InlineType()-&gt;make_larval(this, true));</span>
<span class="line-added">+ </span>
<span class="line-added">+   return true;</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ bool LibraryCallKit::inline_unsafe_finish_private_buffer() {</span>
<span class="line-added">+   Node* receiver = argument(0);</span>
<span class="line-added">+   Node* buffer = argument(1);</span>
<span class="line-added">+ </span>
<span class="line-added">+   receiver = null_check(receiver);</span>
<span class="line-added">+   if (stopped()) {</span>
<span class="line-added">+     return true;</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   if (!buffer-&gt;is_InlineType()) {</span>
<span class="line-added">+     return false;</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   InlineTypeNode* vt = buffer-&gt;as_InlineType();</span>
<span class="line-added">+   if (!vt-&gt;is_allocated(&amp;_gvn) || !_gvn.type(vt)-&gt;is_inlinetype()-&gt;larval()) {</span>
<span class="line-added">+     return false;</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   set_result(vt-&gt;finish_larval(this));</span>
<span class="line-added">+ </span>
    return true;
  }
  
  //----------------------------inline_unsafe_load_store----------------------------
  // This method serves a couple of different customers (depending on LoadStoreKind):
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3030,19 ***</span>
    Node* junk = NULL;
    set_result(generate_current_thread(junk));
    return true;
  }
  
<span class="line-removed">- //---------------------------load_mirror_from_klass----------------------------</span>
<span class="line-removed">- // Given a klass oop, load its java mirror (a java.lang.Class oop).</span>
<span class="line-removed">- Node* LibraryCallKit::load_mirror_from_klass(Node* klass) {</span>
<span class="line-removed">-   Node* p = basic_plus_adr(klass, in_bytes(Klass::java_mirror_offset()));</span>
<span class="line-removed">-   Node* load = make_load(NULL, p, TypeRawPtr::NOTNULL, T_ADDRESS, MemNode::unordered);</span>
<span class="line-removed">-   // mirror = ((OopHandle)mirror)-&gt;resolve();</span>
<span class="line-removed">-   return access_load(load, TypeInstPtr::MIRROR, T_OBJECT, IN_NATIVE);</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
  //-----------------------load_klass_from_mirror_common-------------------------
  // Given a java mirror (a java.lang.Class oop), load its corresponding klass oop.
  // Test the klass oop for null (signifying a primitive Class like Integer.TYPE),
  // and branch to the given path on the region.
  // If never_see_null, take an uncommon trap on null, so we can optimistically
<span class="line-new-header">--- 3244,10 ---</span>
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3081,17 ***</span>
<span class="line-new-header">--- 3286,22 ---</span>
    Node* mbit = _gvn.transform(new AndINode(mods, mask));
    Node* cmp  = _gvn.transform(new CmpINode(mbit, bits));
    Node* bol  = _gvn.transform(new BoolNode(cmp, BoolTest::ne));
    return generate_fair_guard(bol, region);
  }
<span class="line-added">+ </span>
  Node* LibraryCallKit::generate_interface_guard(Node* kls, RegionNode* region) {
    return generate_access_flags_guard(kls, JVM_ACC_INTERFACE, 0, region);
  }
  Node* LibraryCallKit::generate_hidden_class_guard(Node* kls, RegionNode* region) {
    return generate_access_flags_guard(kls, JVM_ACC_IS_HIDDEN_CLASS, 0, region);
  }
  
<span class="line-added">+ Node* LibraryCallKit::generate_value_guard(Node* kls, RegionNode* region) {</span>
<span class="line-added">+   return generate_access_flags_guard(kls, JVM_ACC_VALUE, 0, region);</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
  //-------------------------inline_native_Class_query-------------------
  bool LibraryCallKit::inline_native_Class_query(vmIntrinsics::ID id) {
    const Type* return_type = TypeInt::BOOL;
    Node* prim_return_value = top();  // what happens if it&#39;s a primitive class?
    bool never_see_null = !too_many_traps(Deoptimization::Reason_null_check);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3285,22 ***</span>
      return false;  // dead path (mirror-&gt;is_top()).
    }
    if (obj == NULL || obj-&gt;is_top()) {
      return false;  // dead path
    }
<span class="line-modified">!   const TypeOopPtr* tp = _gvn.type(obj)-&gt;isa_oopptr();</span>
  
    // First, see if Class.cast() can be folded statically.
    // java_mirror_type() returns non-null for compile-time Class constants.
    ciType* tm = mirror_con-&gt;java_mirror_type();
<span class="line-modified">!   if (tm != NULL &amp;&amp; tm-&gt;is_klass() &amp;&amp;</span>
<span class="line-modified">!       tp != NULL &amp;&amp; tp-&gt;klass() != NULL) {</span>
<span class="line-removed">-     if (!tp-&gt;klass()-&gt;is_loaded()) {</span>
        // Don&#39;t use intrinsic when class is not loaded.
        return false;
      } else {
<span class="line-modified">!       int static_res = C-&gt;static_subtype_check(tm-&gt;as_klass(), tp-&gt;klass());</span>
        if (static_res == Compile::SSC_always_true) {
          // isInstance() is true - fold the code.
          set_result(obj);
          return true;
        } else if (static_res == Compile::SSC_always_false) {
<span class="line-new-header">--- 3495,34 ---</span>
      return false;  // dead path (mirror-&gt;is_top()).
    }
    if (obj == NULL || obj-&gt;is_top()) {
      return false;  // dead path
    }
<span class="line-modified">!   ciKlass* obj_klass = NULL;</span>
<span class="line-added">+   const Type* obj_t = _gvn.type(obj);</span>
<span class="line-added">+   if (obj-&gt;is_InlineType()) {</span>
<span class="line-added">+     obj_klass = obj_t-&gt;inline_klass();</span>
<span class="line-added">+   } else if (obj_t-&gt;isa_oopptr()) {</span>
<span class="line-added">+     obj_klass = obj_t-&gt;is_oopptr()-&gt;klass();</span>
<span class="line-added">+   }</span>
  
    // First, see if Class.cast() can be folded statically.
    // java_mirror_type() returns non-null for compile-time Class constants.
    ciType* tm = mirror_con-&gt;java_mirror_type();
<span class="line-modified">!   if (tm != NULL &amp;&amp; tm-&gt;is_klass() &amp;&amp; obj_klass != NULL) {</span>
<span class="line-modified">!     if (!obj_klass-&gt;is_loaded()) {</span>
        // Don&#39;t use intrinsic when class is not loaded.
        return false;
      } else {
<span class="line-modified">!       if (!obj-&gt;is_InlineType() &amp;&amp; tm-&gt;as_klass()-&gt;is_inlinetype()) {</span>
<span class="line-added">+         // Casting to .val, check for null</span>
<span class="line-added">+         obj = null_check(obj);</span>
<span class="line-added">+         if (stopped()) {</span>
<span class="line-added">+           return true;</span>
<span class="line-added">+         }</span>
<span class="line-added">+       }</span>
<span class="line-added">+       int static_res = C-&gt;static_subtype_check(tm-&gt;as_klass(), obj_klass);</span>
        if (static_res == Compile::SSC_always_true) {
          // isInstance() is true - fold the code.
          set_result(obj);
          return true;
        } else if (static_res == Compile::SSC_always_false) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3326,28 ***</span>
    if (stopped()) {
      return true;
    }
  
    // Not-subtype or the mirror&#39;s klass ptr is NULL (in case it is a primitive).
<span class="line-modified">!   enum { _bad_type_path = 1, _prim_path = 2, PATH_LIMIT };</span>
    RegionNode* region = new RegionNode(PATH_LIMIT);
    record_for_igvn(region);
  
    // Now load the mirror&#39;s klass metaobject, and null-check it.
    // If kls is null, we have a primitive mirror and
    // nothing is an instance of a primitive type.
    Node* kls = load_klass_from_mirror(mirror, false, region, _prim_path);
  
    Node* res = top();
    if (!stopped()) {
      Node* bad_type_ctrl = top();
      // Do checkcast optimizations.
      res = gen_checkcast(obj, kls, &amp;bad_type_ctrl);
      region-&gt;init_req(_bad_type_path, bad_type_ctrl);
    }
    if (region-&gt;in(_prim_path) != top() ||
<span class="line-modified">!       region-&gt;in(_bad_type_path) != top()) {</span>
      // Let Interpreter throw ClassCastException.
      PreserveJVMState pjvms(this);
      set_control(_gvn.transform(region));
      uncommon_trap(Deoptimization::Reason_intrinsic,
                    Deoptimization::Action_maybe_recompile);
<span class="line-new-header">--- 3548,48 ---</span>
    if (stopped()) {
      return true;
    }
  
    // Not-subtype or the mirror&#39;s klass ptr is NULL (in case it is a primitive).
<span class="line-modified">!   enum { _bad_type_path = 1, _prim_path = 2, _npe_path = 3, PATH_LIMIT };</span>
    RegionNode* region = new RegionNode(PATH_LIMIT);
    record_for_igvn(region);
  
    // Now load the mirror&#39;s klass metaobject, and null-check it.
    // If kls is null, we have a primitive mirror and
    // nothing is an instance of a primitive type.
    Node* kls = load_klass_from_mirror(mirror, false, region, _prim_path);
  
    Node* res = top();
    if (!stopped()) {
<span class="line-added">+     if (EnableValhalla &amp;&amp; !obj-&gt;is_InlineType()) {</span>
<span class="line-added">+       // Check if we are casting to .val</span>
<span class="line-added">+       Node* is_val_kls = generate_value_guard(kls, NULL);</span>
<span class="line-added">+       if (is_val_kls != NULL) {</span>
<span class="line-added">+         RegionNode* r = new RegionNode(3);</span>
<span class="line-added">+         record_for_igvn(r);</span>
<span class="line-added">+         r-&gt;init_req(1, control());</span>
<span class="line-added">+ </span>
<span class="line-added">+         // Casting to .val, check for null</span>
<span class="line-added">+         set_control(is_val_kls);</span>
<span class="line-added">+         Node* null_ctr = top();</span>
<span class="line-added">+         null_check_oop(obj, &amp;null_ctr);</span>
<span class="line-added">+         region-&gt;init_req(_npe_path, null_ctr);</span>
<span class="line-added">+         r-&gt;init_req(2, control());</span>
<span class="line-added">+ </span>
<span class="line-added">+         set_control(_gvn.transform(r));</span>
<span class="line-added">+       }</span>
<span class="line-added">+     }</span>
<span class="line-added">+ </span>
      Node* bad_type_ctrl = top();
      // Do checkcast optimizations.
      res = gen_checkcast(obj, kls, &amp;bad_type_ctrl);
      region-&gt;init_req(_bad_type_path, bad_type_ctrl);
    }
    if (region-&gt;in(_prim_path) != top() ||
<span class="line-modified">!       region-&gt;in(_bad_type_path) != top() ||</span>
<span class="line-added">+       region-&gt;in(_npe_path) != top()) {</span>
      // Let Interpreter throw ClassCastException.
      PreserveJVMState pjvms(this);
      set_control(_gvn.transform(region));
      uncommon_trap(Deoptimization::Reason_intrinsic,
                    Deoptimization::Action_maybe_recompile);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3380,12 ***</span>
<span class="line-new-header">--- 3622,14 ---</span>
      _both_ref_path,             // {N,N} &amp; subtype check loses =&gt; false
      PATH_LIMIT
    };
  
    RegionNode* region = new RegionNode(PATH_LIMIT);
<span class="line-added">+   RegionNode* prim_region = new RegionNode(2);</span>
    Node*       phi    = new PhiNode(region, TypeInt::BOOL);
    record_for_igvn(region);
<span class="line-added">+   record_for_igvn(prim_region);</span>
  
    const TypePtr* adr_type = TypeRawPtr::BOTTOM;   // memory type of loads
    const TypeKlassPtr* kls_type = TypeKlassPtr::OBJECT_OR_NULL;
    int class_klass_offset = java_lang_Class::klass_offset();
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3406,12 ***</span>
    bool never_see_null = !too_many_traps(Deoptimization::Reason_null_check);
    for (which_arg = 0; which_arg &lt;= 1; which_arg++) {
      Node* kls = klasses[which_arg];
      Node* null_ctl = top();
      kls = null_check_oop(kls, &amp;null_ctl, never_see_null);
<span class="line-modified">!     int prim_path = (which_arg == 0 ? _prim_0_path : _prim_1_path);</span>
<span class="line-modified">!     region-&gt;init_req(prim_path, null_ctl);</span>
      if (stopped())  break;
      klasses[which_arg] = kls;
    }
  
    if (!stopped()) {
<span class="line-new-header">--- 3650,15 ---</span>
    bool never_see_null = !too_many_traps(Deoptimization::Reason_null_check);
    for (which_arg = 0; which_arg &lt;= 1; which_arg++) {
      Node* kls = klasses[which_arg];
      Node* null_ctl = top();
      kls = null_check_oop(kls, &amp;null_ctl, never_see_null);
<span class="line-modified">!     if (which_arg == 0) {</span>
<span class="line-modified">!       prim_region-&gt;init_req(1, null_ctl);</span>
<span class="line-added">+     } else {</span>
<span class="line-added">+       region-&gt;init_req(_prim_1_path, null_ctl);</span>
<span class="line-added">+     }</span>
      if (stopped())  break;
      klasses[which_arg] = kls;
    }
  
    if (!stopped()) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3424,16 ***</span>
    }
  
    // If both operands are primitive (both klasses null), then
    // we must return true when they are identical primitives.
    // It is convenient to test this after the first null klass check.
<span class="line-modified">!   set_control(region-&gt;in(_prim_0_path)); // go back to first null check</span>
    if (!stopped()) {
      // Since superc is primitive, make a guard for the superc==subc case.
      Node* cmp_eq = _gvn.transform(new CmpPNode(args[0], args[1]));
      Node* bol_eq = _gvn.transform(new BoolNode(cmp_eq, BoolTest::eq));
<span class="line-modified">!     generate_guard(bol_eq, region, PROB_FAIR);</span>
      if (region-&gt;req() == PATH_LIMIT+1) {
        // A guard was added.  If the added guard is taken, superc==subc.
        region-&gt;swap_edges(PATH_LIMIT, _prim_same_path);
        region-&gt;del_req(PATH_LIMIT);
      }
<span class="line-new-header">--- 3671,17 ---</span>
    }
  
    // If both operands are primitive (both klasses null), then
    // we must return true when they are identical primitives.
    // It is convenient to test this after the first null klass check.
<span class="line-modified">!   // This path is also used if superc is a value mirror.</span>
<span class="line-added">+   set_control(_gvn.transform(prim_region));</span>
    if (!stopped()) {
      // Since superc is primitive, make a guard for the superc==subc case.
      Node* cmp_eq = _gvn.transform(new CmpPNode(args[0], args[1]));
      Node* bol_eq = _gvn.transform(new BoolNode(cmp_eq, BoolTest::eq));
<span class="line-modified">!     generate_fair_guard(bol_eq, region);</span>
      if (region-&gt;req() == PATH_LIMIT+1) {
        // A guard was added.  If the added guard is taken, superc==subc.
        region-&gt;swap_edges(PATH_LIMIT, _prim_same_path);
        region-&gt;del_req(PATH_LIMIT);
      }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3460,59 ***</span>
    set_result(_gvn.transform(phi));
    return true;
  }
  
  //---------------------generate_array_guard_common------------------------
<span class="line-modified">! Node* LibraryCallKit::generate_array_guard_common(Node* kls, RegionNode* region,</span>
<span class="line-removed">-                                                   bool obj_array, bool not_array) {</span>
  
    if (stopped()) {
      return NULL;
    }
  
<span class="line-removed">-   // If obj_array/non_array==false/false:</span>
<span class="line-removed">-   // Branch around if the given klass is in fact an array (either obj or prim).</span>
<span class="line-removed">-   // If obj_array/non_array==false/true:</span>
<span class="line-removed">-   // Branch around if the given klass is not an array klass of any kind.</span>
<span class="line-removed">-   // If obj_array/non_array==true/true:</span>
<span class="line-removed">-   // Branch around if the kls is not an oop array (kls is int[], String, etc.)</span>
<span class="line-removed">-   // If obj_array/non_array==true/false:</span>
<span class="line-removed">-   // Branch around if the kls is an oop array (Object[] or subtype)</span>
<span class="line-removed">-   //</span>
    // Like generate_guard, adds a new path onto the region.
    jint  layout_con = 0;
    Node* layout_val = get_layout_helper(kls, layout_con);
    if (layout_val == NULL) {
<span class="line-modified">!     bool query = (obj_array</span>
<span class="line-modified">!                   ? Klass::layout_helper_is_objArray(layout_con)</span>
<span class="line-modified">!                   : Klass::layout_helper_is_array(layout_con));</span>
<span class="line-modified">!     if (query == not_array) {</span>
        return NULL;                       // never a branch
      } else {                             // always a branch
        Node* always_branch = control();
        if (region != NULL)
          region-&gt;add_req(always_branch);
        set_control(top());
        return always_branch;
      }
    }
    // Now test the correct condition.
<span class="line-modified">!   jint  nval = (obj_array</span>
<span class="line-removed">-                 ? (jint)(Klass::_lh_array_tag_type_value</span>
<span class="line-removed">-                    &lt;&lt;    Klass::_lh_array_tag_shift)</span>
<span class="line-removed">-                 : Klass::_lh_neutral_value);</span>
    Node* cmp = _gvn.transform(new CmpINode(layout_val, intcon(nval)));
<span class="line-removed">-   BoolTest::mask btest = BoolTest::lt;  // correct for testing is_[obj]array</span>
<span class="line-removed">-   // invert the test if we are looking for a non-array</span>
<span class="line-removed">-   if (not_array)  btest = BoolTest(btest).negate();</span>
    Node* bol = _gvn.transform(new BoolNode(cmp, btest));
    return generate_fair_guard(bol, region);
  }
  
  
  //-----------------------inline_native_newArray--------------------------
<span class="line-modified">! // private static native Object java.lang.reflect.newArray(Class&lt;?&gt; componentType, int length);</span>
  // private        native Object Unsafe.allocateUninitializedArray0(Class&lt;?&gt; cls, int size);
  bool LibraryCallKit::inline_unsafe_newArray(bool uninitialized) {
    Node* mirror;
    Node* count_val;
    if (uninitialized) {
<span class="line-new-header">--- 3708,78 ---</span>
    set_result(_gvn.transform(phi));
    return true;
  }
  
  //---------------------generate_array_guard_common------------------------
<span class="line-modified">! Node* LibraryCallKit::generate_array_guard_common(Node* kls, RegionNode* region, ArrayKind kind) {</span>
  
    if (stopped()) {
      return NULL;
    }
  
    // Like generate_guard, adds a new path onto the region.
    jint  layout_con = 0;
    Node* layout_val = get_layout_helper(kls, layout_con);
    if (layout_val == NULL) {
<span class="line-modified">!     bool query = 0;</span>
<span class="line-modified">!     switch(kind) {</span>
<span class="line-modified">!       case ObjectArray:    query = Klass::layout_helper_is_objArray(layout_con); break;</span>
<span class="line-modified">!       case NonObjectArray: query = !Klass::layout_helper_is_objArray(layout_con); break;</span>
<span class="line-added">+       case TypeArray:      query = Klass::layout_helper_is_typeArray(layout_con); break;</span>
<span class="line-added">+       case FlatArray:      query = Klass::layout_helper_is_flatArray(layout_con); break;</span>
<span class="line-added">+       case AnyArray:       query = Klass::layout_helper_is_array(layout_con); break;</span>
<span class="line-added">+       case NonArray:       query = !Klass::layout_helper_is_array(layout_con); break;</span>
<span class="line-added">+       default:</span>
<span class="line-added">+         ShouldNotReachHere();</span>
<span class="line-added">+     }</span>
<span class="line-added">+     if (!query) {</span>
        return NULL;                       // never a branch
      } else {                             // always a branch
        Node* always_branch = control();
        if (region != NULL)
          region-&gt;add_req(always_branch);
        set_control(top());
        return always_branch;
      }
    }
<span class="line-added">+   unsigned int value = 0;</span>
<span class="line-added">+   BoolTest::mask btest = BoolTest::illegal;</span>
<span class="line-added">+   switch(kind) {</span>
<span class="line-added">+     case ObjectArray:</span>
<span class="line-added">+     case NonObjectArray: {</span>
<span class="line-added">+       value = Klass::_lh_array_tag_obj_value;</span>
<span class="line-added">+       layout_val = _gvn.transform(new RShiftINode(layout_val, intcon(Klass::_lh_array_tag_shift)));</span>
<span class="line-added">+       btest = kind == ObjectArray ? BoolTest::eq : BoolTest::ne;</span>
<span class="line-added">+       break;</span>
<span class="line-added">+     }</span>
<span class="line-added">+     case TypeArray: {</span>
<span class="line-added">+       value = Klass::_lh_array_tag_type_value;</span>
<span class="line-added">+       layout_val = _gvn.transform(new RShiftINode(layout_val, intcon(Klass::_lh_array_tag_shift)));</span>
<span class="line-added">+       btest = BoolTest::eq;</span>
<span class="line-added">+       break;</span>
<span class="line-added">+     }</span>
<span class="line-added">+     case FlatArray: {</span>
<span class="line-added">+       value = Klass::_lh_array_tag_vt_value;</span>
<span class="line-added">+       layout_val = _gvn.transform(new RShiftINode(layout_val, intcon(Klass::_lh_array_tag_shift)));</span>
<span class="line-added">+       btest = BoolTest::eq;</span>
<span class="line-added">+       break;</span>
<span class="line-added">+     }</span>
<span class="line-added">+     case AnyArray:    value = Klass::_lh_neutral_value; btest = BoolTest::lt; break;</span>
<span class="line-added">+     case NonArray:    value = Klass::_lh_neutral_value; btest = BoolTest::gt; break;</span>
<span class="line-added">+     default:</span>
<span class="line-added">+       ShouldNotReachHere();</span>
<span class="line-added">+   }</span>
    // Now test the correct condition.
<span class="line-modified">!   jint nval = (jint)value;</span>
    Node* cmp = _gvn.transform(new CmpINode(layout_val, intcon(nval)));
    Node* bol = _gvn.transform(new BoolNode(cmp, btest));
    return generate_fair_guard(bol, region);
  }
  
  
  //-----------------------inline_native_newArray--------------------------
<span class="line-modified">! // private static native Object java.lang.reflect.Array.newArray(Class&lt;?&gt; componentType, int length);</span>
  // private        native Object Unsafe.allocateUninitializedArray0(Class&lt;?&gt; cls, int size);
  bool LibraryCallKit::inline_unsafe_newArray(bool uninitialized) {
    Node* mirror;
    Node* count_val;
    if (uninitialized) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3624,10 ***</span>
<span class="line-new-header">--- 3891,23 ---</span>
    Node* original          = argument(0);
    Node* start             = is_copyOfRange? argument(1): intcon(0);
    Node* end               = is_copyOfRange? argument(2): argument(1);
    Node* array_type_mirror = is_copyOfRange? argument(3): argument(2);
  
<span class="line-added">+   const TypeAryPtr* original_t = _gvn.type(original)-&gt;isa_aryptr();</span>
<span class="line-added">+   const TypeInstPtr* mirror_t = _gvn.type(array_type_mirror)-&gt;isa_instptr();</span>
<span class="line-added">+   if (EnableValhalla &amp;&amp; UseFlatArray &amp;&amp;</span>
<span class="line-added">+       (original_t == NULL || mirror_t == NULL ||</span>
<span class="line-added">+        (mirror_t-&gt;java_mirror_type() == NULL &amp;&amp;</span>
<span class="line-added">+         (original_t-&gt;elem()-&gt;isa_inlinetype() ||</span>
<span class="line-added">+          (original_t-&gt;elem()-&gt;make_oopptr() != NULL &amp;&amp;</span>
<span class="line-added">+           original_t-&gt;elem()-&gt;make_oopptr()-&gt;can_be_inline_type()))))) {</span>
<span class="line-added">+     // We need to know statically if the copy is to a flattened array</span>
<span class="line-added">+     // or not but can&#39;t tell.</span>
<span class="line-added">+     return false;</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
    Node* newcopy = NULL;
  
    // Set the original stack and the reexecute bit for the interpreter to reexecute
    // the bytecode that invokes Arrays.copyOf if deoptimization happens.
    { PreserveReexecuteState preexecs(this);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3647,20 ***</span>
      RegionNode* bailout = new RegionNode(1);
      record_for_igvn(bailout);
  
      // Despite the generic type of Arrays.copyOf, the mirror might be int, int[], etc.
      // Bail out if that is so.
<span class="line-modified">!     Node* not_objArray = generate_non_objArray_guard(klass_node, bailout);</span>
      if (not_objArray != NULL) {
        // Improve the klass node&#39;s type from the new optimistic assumption:
        ciKlass* ak = ciArrayKlass::make(env()-&gt;Object_klass());
<span class="line-modified">!       const Type* akls = TypeKlassPtr::make(TypePtr::NotNull, ak, 0/*offset*/);</span>
        Node* cast = new CastPPNode(klass_node, akls);
        cast-&gt;init_req(0, control());
        klass_node = _gvn.transform(cast);
      }
  
      // Bail out if either start or end is negative.
      generate_negative_guard(start, bailout, &amp;start);
      generate_negative_guard(end,   bailout, &amp;end);
  
      Node* length = end;
<span class="line-new-header">--- 3927,66 ---</span>
      RegionNode* bailout = new RegionNode(1);
      record_for_igvn(bailout);
  
      // Despite the generic type of Arrays.copyOf, the mirror might be int, int[], etc.
      // Bail out if that is so.
<span class="line-modified">!     // Inline type array may have object field that would require a</span>
<span class="line-added">+     // write barrier. Conservatively, go to slow path.</span>
<span class="line-added">+     BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();</span>
<span class="line-added">+     Node* not_objArray = !bs-&gt;array_copy_requires_gc_barriers(false, T_OBJECT, false, BarrierSetC2::Parsing) ?</span>
<span class="line-added">+         generate_typeArray_guard(klass_node, bailout) : generate_non_objArray_guard(klass_node, bailout);</span>
      if (not_objArray != NULL) {
        // Improve the klass node&#39;s type from the new optimistic assumption:
        ciKlass* ak = ciArrayKlass::make(env()-&gt;Object_klass());
<span class="line-modified">!       const Type* akls = TypeKlassPtr::make(TypePtr::NotNull, ak, Type::Offset(0), false);</span>
        Node* cast = new CastPPNode(klass_node, akls);
        cast-&gt;init_req(0, control());
        klass_node = _gvn.transform(cast);
      }
  
<span class="line-added">+     Node* original_kls = load_object_klass(original);</span>
<span class="line-added">+     // ArrayCopyNode:Ideal may transform the ArrayCopyNode to</span>
<span class="line-added">+     // loads/stores but it is legal only if we&#39;re sure the</span>
<span class="line-added">+     // Arrays.copyOf would succeed. So we need all input arguments</span>
<span class="line-added">+     // to the copyOf to be validated, including that the copy to the</span>
<span class="line-added">+     // new array won&#39;t trigger an ArrayStoreException. That subtype</span>
<span class="line-added">+     // check can be optimized if we know something on the type of</span>
<span class="line-added">+     // the input array from type speculation.</span>
<span class="line-added">+     if (_gvn.type(klass_node)-&gt;singleton() &amp;&amp; !stopped()) {</span>
<span class="line-added">+       ciKlass* subk   = _gvn.type(original_kls)-&gt;is_klassptr()-&gt;klass();</span>
<span class="line-added">+       ciKlass* superk = _gvn.type(klass_node)-&gt;is_klassptr()-&gt;klass();</span>
<span class="line-added">+ </span>
<span class="line-added">+       int test = C-&gt;static_subtype_check(superk, subk);</span>
<span class="line-added">+       if (test != Compile::SSC_always_true &amp;&amp; test != Compile::SSC_always_false) {</span>
<span class="line-added">+         const TypeOopPtr* t_original = _gvn.type(original)-&gt;is_oopptr();</span>
<span class="line-added">+         if (t_original-&gt;speculative_type() != NULL) {</span>
<span class="line-added">+           original = maybe_cast_profiled_obj(original, t_original-&gt;speculative_type(), true);</span>
<span class="line-added">+           original_kls = load_object_klass(original);</span>
<span class="line-added">+         }</span>
<span class="line-added">+       }</span>
<span class="line-added">+     }</span>
<span class="line-added">+ </span>
<span class="line-added">+     if (UseFlatArray) {</span>
<span class="line-added">+       // Either both or neither new array klass and original array</span>
<span class="line-added">+       // klass must be flattened</span>
<span class="line-added">+       Node* is_flat = generate_flatArray_guard(klass_node, NULL);</span>
<span class="line-added">+       if (!original_t-&gt;is_not_flat()) {</span>
<span class="line-added">+         generate_flatArray_guard(original_kls, bailout);</span>
<span class="line-added">+       }</span>
<span class="line-added">+       if (is_flat != NULL) {</span>
<span class="line-added">+         RegionNode* r = new RegionNode(2);</span>
<span class="line-added">+         record_for_igvn(r);</span>
<span class="line-added">+         r-&gt;init_req(1, control());</span>
<span class="line-added">+         set_control(is_flat);</span>
<span class="line-added">+         if (!original_t-&gt;is_not_flat()) {</span>
<span class="line-added">+           generate_flatArray_guard(original_kls, r);</span>
<span class="line-added">+         }</span>
<span class="line-added">+         bailout-&gt;add_req(control());</span>
<span class="line-added">+         set_control(_gvn.transform(r));</span>
<span class="line-added">+       }</span>
<span class="line-added">+     }</span>
<span class="line-added">+ </span>
      // Bail out if either start or end is negative.
      generate_negative_guard(start, bailout, &amp;start);
      generate_negative_guard(end,   bailout, &amp;end);
  
      Node* length = end;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3691,30 ***</span>
        // We know the copy is disjoint but we might not know if the
        // oop stores need checking.
        // Extreme case:  Arrays.copyOf((Integer[])x, 10, String[].class).
        // This will fail a store-check if x contains any non-nulls.
  
<span class="line-removed">-       // ArrayCopyNode:Ideal may transform the ArrayCopyNode to</span>
<span class="line-removed">-       // loads/stores but it is legal only if we&#39;re sure the</span>
<span class="line-removed">-       // Arrays.copyOf would succeed. So we need all input arguments</span>
<span class="line-removed">-       // to the copyOf to be validated, including that the copy to the</span>
<span class="line-removed">-       // new array won&#39;t trigger an ArrayStoreException. That subtype</span>
<span class="line-removed">-       // check can be optimized if we know something on the type of</span>
<span class="line-removed">-       // the input array from type speculation.</span>
<span class="line-removed">-       if (_gvn.type(klass_node)-&gt;singleton()) {</span>
<span class="line-removed">-         ciKlass* subk   = _gvn.type(load_object_klass(original))-&gt;is_klassptr()-&gt;klass();</span>
<span class="line-removed">-         ciKlass* superk = _gvn.type(klass_node)-&gt;is_klassptr()-&gt;klass();</span>
<span class="line-removed">- </span>
<span class="line-removed">-         int test = C-&gt;static_subtype_check(superk, subk);</span>
<span class="line-removed">-         if (test != Compile::SSC_always_true &amp;&amp; test != Compile::SSC_always_false) {</span>
<span class="line-removed">-           const TypeOopPtr* t_original = _gvn.type(original)-&gt;is_oopptr();</span>
<span class="line-removed">-           if (t_original-&gt;speculative_type() != NULL) {</span>
<span class="line-removed">-             original = maybe_cast_profiled_obj(original, t_original-&gt;speculative_type(), true);</span>
<span class="line-removed">-           }</span>
<span class="line-removed">-         }</span>
<span class="line-removed">-       }</span>
<span class="line-removed">- </span>
        bool validated = false;
        // Reason_class_check rather than Reason_intrinsic because we
        // want to intrinsify even if this traps.
        if (!too_many_traps(Deoptimization::Reason_class_check)) {
          Node* not_subtype_ctrl = gen_subtype_check(original, klass_node);
<span class="line-new-header">--- 4017,10 ---</span>
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3731,11 ***</span>
  
        if (!stopped()) {
          newcopy = new_array(klass_node, length, 0);  // no arguments to push
  
          ArrayCopyNode* ac = ArrayCopyNode::make(this, true, original, start, newcopy, intcon(0), moved, true, false,
<span class="line-modified">!                                                 load_object_klass(original), klass_node);</span>
          if (!is_copyOfRange) {
            ac-&gt;set_copyof(validated);
          } else {
            ac-&gt;set_copyofrange(validated);
          }
<span class="line-new-header">--- 4037,11 ---</span>
  
        if (!stopped()) {
          newcopy = new_array(klass_node, length, 0);  // no arguments to push
  
          ArrayCopyNode* ac = ArrayCopyNode::make(this, true, original, start, newcopy, intcon(0), moved, true, false,
<span class="line-modified">!                                                 original_kls, klass_node);</span>
          if (!is_copyOfRange) {
            ac-&gt;set_copyof(validated);
          } else {
            ac-&gt;set_copyofrange(validated);
          }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3855,21 ***</span>
  
    RegionNode* result_reg = new RegionNode(PATH_LIMIT);
    PhiNode*    result_val = new PhiNode(result_reg, TypeInt::INT);
    PhiNode*    result_io  = new PhiNode(result_reg, Type::ABIO);
    PhiNode*    result_mem = new PhiNode(result_reg, Type::MEMORY, TypePtr::BOTTOM);
<span class="line-modified">!   Node* obj = NULL;</span>
    if (!is_static) {
      // Check for hashing null object
      obj = null_check_receiver();
      if (stopped())  return true;        // unconditionally null
      result_reg-&gt;init_req(_null_path, top());
      result_val-&gt;init_req(_null_path, top());
    } else {
      // Do a null check, and return zero if null.
      // System.identityHashCode(null) == 0
<span class="line-removed">-     obj = argument(0);</span>
      Node* null_ctl = top();
      obj = null_check_oop(obj, &amp;null_ctl);
      result_reg-&gt;init_req(_null_path, null_ctl);
      result_val-&gt;init_req(_null_path, _gvn.intcon(0));
    }
<span class="line-new-header">--- 4161,25 ---</span>
  
    RegionNode* result_reg = new RegionNode(PATH_LIMIT);
    PhiNode*    result_val = new PhiNode(result_reg, TypeInt::INT);
    PhiNode*    result_io  = new PhiNode(result_reg, Type::ABIO);
    PhiNode*    result_mem = new PhiNode(result_reg, Type::MEMORY, TypePtr::BOTTOM);
<span class="line-modified">!   Node* obj = argument(0);</span>
<span class="line-added">+ </span>
<span class="line-added">+   if (obj-&gt;is_InlineType() || gvn().type(obj)-&gt;is_inlinetypeptr()) {</span>
<span class="line-added">+     return false;</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
    if (!is_static) {
      // Check for hashing null object
      obj = null_check_receiver();
      if (stopped())  return true;        // unconditionally null
      result_reg-&gt;init_req(_null_path, top());
      result_val-&gt;init_req(_null_path, top());
    } else {
      // Do a null check, and return zero if null.
      // System.identityHashCode(null) == 0
      Node* null_ctl = top();
      obj = null_check_oop(obj, &amp;null_ctl);
      result_reg-&gt;init_req(_null_path, null_ctl);
      result_val-&gt;init_req(_null_path, _gvn.intcon(0));
    }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3905,10 ***</span>
<span class="line-new-header">--- 4215,11 ---</span>
    // the null check after castPP removal.
    Node* no_ctrl = NULL;
    Node* header = make_load(no_ctrl, header_addr, TypeX_X, TypeX_X-&gt;basic_type(), MemNode::unordered);
  
    // Test the header to see if it is unlocked.
<span class="line-added">+   // This also serves as guard against inline types (they have the always_locked_pattern set).</span>
    Node *lock_mask      = _gvn.MakeConX(markWord::biased_lock_mask_in_place);
    Node *lmasked_header = _gvn.transform(new AndXNode(header, lock_mask));
    Node *unlocked_val   = _gvn.MakeConX(markWord::unlocked_value);
    Node *chk_unlocked   = _gvn.transform(new CmpXNode( lmasked_header, unlocked_val));
    Node *test_unlocked  = _gvn.transform(new BoolNode( chk_unlocked, BoolTest::ne));
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3971,11 ***</span>
  //---------------------------inline_native_getClass----------------------------
  // public final native Class&lt;?&gt; java.lang.Object.getClass();
  //
  // Build special case code for calls to getClass on an object.
  bool LibraryCallKit::inline_native_getClass() {
<span class="line-modified">!   Node* obj = null_check_receiver();</span>
    if (stopped())  return true;
    set_result(load_mirror_from_klass(load_object_klass(obj)));
    return true;
  }
  
<span class="line-new-header">--- 4282,17 ---</span>
  //---------------------------inline_native_getClass----------------------------
  // public final native Class&lt;?&gt; java.lang.Object.getClass();
  //
  // Build special case code for calls to getClass on an object.
  bool LibraryCallKit::inline_native_getClass() {
<span class="line-modified">!   Node* obj = argument(0);</span>
<span class="line-added">+   if (obj-&gt;is_InlineType()) {</span>
<span class="line-added">+     ciKlass* vk = _gvn.type(obj)-&gt;inline_klass();</span>
<span class="line-added">+     set_result(makecon(TypeInstPtr::make(vk-&gt;java_mirror())));</span>
<span class="line-added">+     return true;</span>
<span class="line-added">+   }</span>
<span class="line-added">+   obj = null_check_receiver();</span>
    if (stopped())  return true;
    set_result(load_mirror_from_klass(load_object_klass(obj)));
    return true;
  }
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 4233,11 ***</span>
      // copy and a StoreStore barrier exists after the array copy.
      alloc-&gt;initialization()-&gt;set_complete_with_arraycopy();
    }
  
    Node* size = _gvn.transform(obj_size);
<span class="line-modified">!   access_clone(obj, alloc_obj, size, is_array);</span>
  
    // Do not let reads from the cloned object float above the arraycopy.
    if (alloc != NULL) {
      // Do not let stores that initialize this object be reordered with
      // a subsequent store that would make this object accessible by
<span class="line-new-header">--- 4550,18 ---</span>
      // copy and a StoreStore barrier exists after the array copy.
      alloc-&gt;initialization()-&gt;set_complete_with_arraycopy();
    }
  
    Node* size = _gvn.transform(obj_size);
<span class="line-modified">!   // Exclude the header but include array length to copy by 8 bytes words.</span>
<span class="line-added">+   // Can&#39;t use base_offset_in_bytes(bt) since basic type is unknown.</span>
<span class="line-added">+   int base_off = BarrierSetC2::arraycopy_payload_base_offset(is_array);</span>
<span class="line-added">+   Node* countx = size;</span>
<span class="line-added">+   countx = _gvn.transform(new SubXNode(countx, MakeConX(base_off)));</span>
<span class="line-added">+   countx = _gvn.transform(new URShiftXNode(countx, intcon(LogBytesPerLong)));</span>
<span class="line-added">+ </span>
<span class="line-added">+   access_clone(obj, alloc_obj, countx, is_array);</span>
  
    // Do not let reads from the cloned object float above the arraycopy.
    if (alloc != NULL) {
      // Do not let stores that initialize this object be reordered with
      // a subsequent store that would make this object accessible by
</pre>
<hr />
<pre>
<span class="line-old-header">*** 4276,21 ***</span>
    // Set the reexecute bit for the interpreter to reexecute
    // the bytecode that invokes Object.clone if deoptimization happens.
    { PreserveReexecuteState preexecs(this);
      jvms()-&gt;set_should_reexecute(true);
  
<span class="line-modified">!     Node* obj = null_check_receiver();</span>
      if (stopped())  return true;
  
      const TypeOopPtr* obj_type = _gvn.type(obj)-&gt;is_oopptr();
  
      // If we are going to clone an instance, we need its exact type to
      // know the number and types of fields to convert the clone to
      // loads/stores. Maybe a speculative type can help us.
      if (!obj_type-&gt;klass_is_exact() &amp;&amp;
          obj_type-&gt;speculative_type() != NULL &amp;&amp;
<span class="line-modified">!         obj_type-&gt;speculative_type()-&gt;is_instance_klass()) {</span>
        ciInstanceKlass* spec_ik = obj_type-&gt;speculative_type()-&gt;as_instance_klass();
        if (spec_ik-&gt;nof_nonstatic_fields() &lt;= ArrayCopyLoadStoreMaxElem &amp;&amp;
            !spec_ik-&gt;has_injected_fields()) {
          ciKlass* k = obj_type-&gt;klass();
          if (!k-&gt;is_instance_klass() ||
<span class="line-new-header">--- 4600,27 ---</span>
    // Set the reexecute bit for the interpreter to reexecute
    // the bytecode that invokes Object.clone if deoptimization happens.
    { PreserveReexecuteState preexecs(this);
      jvms()-&gt;set_should_reexecute(true);
  
<span class="line-modified">!     Node* obj = argument(0);</span>
<span class="line-added">+     if (obj-&gt;is_InlineType()) {</span>
<span class="line-added">+       return false;</span>
<span class="line-added">+     }</span>
<span class="line-added">+ </span>
<span class="line-added">+     obj = null_check_receiver();</span>
      if (stopped())  return true;
  
      const TypeOopPtr* obj_type = _gvn.type(obj)-&gt;is_oopptr();
  
      // If we are going to clone an instance, we need its exact type to
      // know the number and types of fields to convert the clone to
      // loads/stores. Maybe a speculative type can help us.
      if (!obj_type-&gt;klass_is_exact() &amp;&amp;
          obj_type-&gt;speculative_type() != NULL &amp;&amp;
<span class="line-modified">!         obj_type-&gt;speculative_type()-&gt;is_instance_klass() &amp;&amp;</span>
<span class="line-added">+         !obj_type-&gt;speculative_type()-&gt;is_inlinetype()) {</span>
        ciInstanceKlass* spec_ik = obj_type-&gt;speculative_type()-&gt;as_instance_klass();
        if (spec_ik-&gt;nof_nonstatic_fields() &lt;= ArrayCopyLoadStoreMaxElem &amp;&amp;
            !spec_ik-&gt;has_injected_fields()) {
          ciKlass* k = obj_type-&gt;klass();
          if (!k-&gt;is_instance_klass() ||
</pre>
<hr />
<pre>
<span class="line-old-header">*** 4318,64 ***</span>
      PhiNode*    result_i_o = new PhiNode(result_reg, Type::ABIO);
      PhiNode*    result_mem = new PhiNode(result_reg, Type::MEMORY, TypePtr::BOTTOM);
      record_for_igvn(result_reg);
  
      Node* obj_klass = load_object_klass(obj);
      Node* array_ctl = generate_array_guard(obj_klass, (RegionNode*)NULL);
      if (array_ctl != NULL) {
        // It&#39;s an array.
        PreserveJVMState pjvms(this);
        set_control(array_ctl);
<span class="line-removed">-       Node* obj_length = load_array_length(obj);</span>
<span class="line-removed">-       Node* obj_size  = NULL;</span>
<span class="line-removed">-       Node* alloc_obj = new_array(obj_klass, obj_length, 0, &amp;obj_size, /*deoptimize_on_exception=*/true);</span>
  
        BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
<span class="line-modified">!       if (bs-&gt;array_copy_requires_gc_barriers(true, T_OBJECT, true, BarrierSetC2::Parsing)) {</span>
<span class="line-modified">!         // If it is an oop array, it requires very special treatment,</span>
<span class="line-modified">!         // because gc barriers are required when accessing the array.</span>
<span class="line-modified">!         Node* is_obja = generate_objArray_guard(obj_klass, (RegionNode*)NULL);</span>
<span class="line-modified">!         if (is_obja != NULL) {</span>
<span class="line-removed">-           PreserveJVMState pjvms2(this);</span>
<span class="line-removed">-           set_control(is_obja);</span>
<span class="line-removed">-           // Generate a direct call to the right arraycopy function(s).</span>
<span class="line-removed">-           Node* alloc = tightly_coupled_allocation(alloc_obj, NULL);</span>
<span class="line-removed">-           ArrayCopyNode* ac = ArrayCopyNode::make(this, true, obj, intcon(0), alloc_obj, intcon(0), obj_length, alloc != NULL, false);</span>
<span class="line-removed">-           ac-&gt;set_clone_oop_array();</span>
<span class="line-removed">-           Node* n = _gvn.transform(ac);</span>
<span class="line-removed">-           assert(n == ac, &quot;cannot disappear&quot;);</span>
<span class="line-removed">-           ac-&gt;connect_outputs(this, /*deoptimize_on_exception=*/true);</span>
<span class="line-removed">- </span>
<span class="line-removed">-           result_reg-&gt;init_req(_objArray_path, control());</span>
<span class="line-removed">-           result_val-&gt;init_req(_objArray_path, alloc_obj);</span>
<span class="line-removed">-           result_i_o -&gt;set_req(_objArray_path, i_o());</span>
<span class="line-removed">-           result_mem -&gt;set_req(_objArray_path, reset_memory());</span>
<span class="line-removed">-         }</span>
        }
<span class="line-removed">-       // Otherwise, there are no barriers to worry about.</span>
<span class="line-removed">-       // (We can dispense with card marks if we know the allocation</span>
<span class="line-removed">-       //  comes out of eden (TLAB)...  In fact, ReduceInitialCardMarks</span>
<span class="line-removed">-       //  causes the non-eden paths to take compensating steps to</span>
<span class="line-removed">-       //  simulate a fresh allocation, so that no further</span>
<span class="line-removed">-       //  card marks are required in compiled code to initialize</span>
<span class="line-removed">-       //  the object.)</span>
  
        if (!stopped()) {
<span class="line-modified">!         copy_to_clone(obj, alloc_obj, obj_size, true);</span>
<span class="line-modified">! </span>
<span class="line-modified">!         // Present the results of the copy.</span>
<span class="line-modified">!         result_reg-&gt;init_req(_array_path, control());</span>
<span class="line-modified">!         result_val-&gt;init_req(_array_path, alloc_obj);</span>
<span class="line-modified">!         result_i_o -&gt;set_req(_array_path, i_o());</span>
<span class="line-modified">!         result_mem -&gt;set_req(_array_path, reset_memory());</span>
        }
      }
  
<span class="line-removed">-     // We only go to the instance fast case code if we pass a number of guards.</span>
<span class="line-removed">-     // The paths which do not pass are accumulated in the slow_region.</span>
<span class="line-removed">-     RegionNode* slow_region = new RegionNode(1);</span>
<span class="line-removed">-     record_for_igvn(slow_region);</span>
      if (!stopped()) {
        // It&#39;s an instance (we did array above).  Make the slow-path tests.
        // If this is a virtual call, we generate a funny guard.  We grab
        // the vtable entry corresponding to clone() from the target object.
        // If the target method which we are calling happens to be the
<span class="line-new-header">--- 4648,76 ---</span>
      PhiNode*    result_i_o = new PhiNode(result_reg, Type::ABIO);
      PhiNode*    result_mem = new PhiNode(result_reg, Type::MEMORY, TypePtr::BOTTOM);
      record_for_igvn(result_reg);
  
      Node* obj_klass = load_object_klass(obj);
<span class="line-added">+     // We only go to the fast case code if we pass a number of guards.</span>
<span class="line-added">+     // The paths which do not pass are accumulated in the slow_region.</span>
<span class="line-added">+     RegionNode* slow_region = new RegionNode(1);</span>
<span class="line-added">+     record_for_igvn(slow_region);</span>
<span class="line-added">+ </span>
      Node* array_ctl = generate_array_guard(obj_klass, (RegionNode*)NULL);
      if (array_ctl != NULL) {
        // It&#39;s an array.
        PreserveJVMState pjvms(this);
        set_control(array_ctl);
  
        BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
<span class="line-modified">!       if (bs-&gt;array_copy_requires_gc_barriers(true, T_OBJECT, true, BarrierSetC2::Parsing) &amp;&amp;</span>
<span class="line-modified">!           (!obj_type-&gt;isa_aryptr() || !obj_type-&gt;is_aryptr()-&gt;is_not_flat())) {</span>
<span class="line-modified">!         // Flattened inline type array may have object field that would require a</span>
<span class="line-modified">!         // write barrier. Conservatively, go to slow path.</span>
<span class="line-modified">!         generate_flatArray_guard(obj_klass, slow_region);</span>
        }
  
        if (!stopped()) {
<span class="line-modified">!         Node* obj_length = load_array_length(obj);</span>
<span class="line-modified">!         Node* obj_size  = NULL;</span>
<span class="line-modified">!         Node* alloc_obj = new_array(obj_klass, obj_length, 0, &amp;obj_size, /*deoptimize_on_exception=*/true);</span>
<span class="line-modified">! </span>
<span class="line-modified">!         BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();</span>
<span class="line-modified">!         if (bs-&gt;array_copy_requires_gc_barriers(true, T_OBJECT, true, BarrierSetC2::Parsing)) {</span>
<span class="line-modified">!           // If it is an oop array, it requires very special treatment,</span>
<span class="line-added">+           // because gc barriers are required when accessing the array.</span>
<span class="line-added">+           Node* is_obja = generate_objArray_guard(obj_klass, (RegionNode*)NULL);</span>
<span class="line-added">+           if (is_obja != NULL) {</span>
<span class="line-added">+             PreserveJVMState pjvms2(this);</span>
<span class="line-added">+             set_control(is_obja);</span>
<span class="line-added">+             // Generate a direct call to the right arraycopy function(s).</span>
<span class="line-added">+             Node* alloc = tightly_coupled_allocation(alloc_obj, NULL);</span>
<span class="line-added">+             ArrayCopyNode* ac = ArrayCopyNode::make(this, true, obj, intcon(0), alloc_obj, intcon(0), obj_length, alloc != NULL, false);</span>
<span class="line-added">+             ac-&gt;set_clone_oop_array();</span>
<span class="line-added">+             Node* n = _gvn.transform(ac);</span>
<span class="line-added">+             assert(n == ac, &quot;cannot disappear&quot;);</span>
<span class="line-added">+             ac-&gt;connect_outputs(this, /*deoptimize_on_exception=*/true);</span>
<span class="line-added">+ </span>
<span class="line-added">+             result_reg-&gt;init_req(_objArray_path, control());</span>
<span class="line-added">+             result_val-&gt;init_req(_objArray_path, alloc_obj);</span>
<span class="line-added">+             result_i_o -&gt;set_req(_objArray_path, i_o());</span>
<span class="line-added">+             result_mem -&gt;set_req(_objArray_path, reset_memory());</span>
<span class="line-added">+           }</span>
<span class="line-added">+         }</span>
<span class="line-added">+         // Otherwise, there are no barriers to worry about.</span>
<span class="line-added">+         // (We can dispense with card marks if we know the allocation</span>
<span class="line-added">+         //  comes out of eden (TLAB)...  In fact, ReduceInitialCardMarks</span>
<span class="line-added">+         //  causes the non-eden paths to take compensating steps to</span>
<span class="line-added">+         //  simulate a fresh allocation, so that no further</span>
<span class="line-added">+         //  card marks are required in compiled code to initialize</span>
<span class="line-added">+         //  the object.)</span>
<span class="line-added">+ </span>
<span class="line-added">+         if (!stopped()) {</span>
<span class="line-added">+           copy_to_clone(obj, alloc_obj, obj_size, true);</span>
<span class="line-added">+ </span>
<span class="line-added">+           // Present the results of the copy.</span>
<span class="line-added">+           result_reg-&gt;init_req(_array_path, control());</span>
<span class="line-added">+           result_val-&gt;init_req(_array_path, alloc_obj);</span>
<span class="line-added">+           result_i_o -&gt;set_req(_array_path, i_o());</span>
<span class="line-added">+           result_mem -&gt;set_req(_array_path, reset_memory());</span>
<span class="line-added">+         }</span>
        }
      }
  
      if (!stopped()) {
        // It&#39;s an instance (we did array above).  Make the slow-path tests.
        // If this is a virtual call, we generate a funny guard.  We grab
        // the vtable entry corresponding to clone() from the target object.
        // If the target method which we are calling happens to be the
</pre>
<hr />
<pre>
<span class="line-old-header">*** 4532,15 ***</span>
      map()-&gt;replaced_nodes().apply(saved_jvms-&gt;map(), new_idx);
      set_jvms(saved_jvms);
      _reexecute_sp = saved_reexecute_sp;
  
      // Remove the allocation from above the guards
<span class="line-modified">!     CallProjections callprojs;</span>
<span class="line-removed">-     alloc-&gt;extract_projections(&amp;callprojs, true);</span>
      InitializeNode* init = alloc-&gt;initialization();
      Node* alloc_mem = alloc-&gt;in(TypeFunc::Memory);
<span class="line-modified">!     C-&gt;gvn_replace_by(callprojs.fallthrough_ioproj, alloc-&gt;in(TypeFunc::I_O));</span>
      C-&gt;gvn_replace_by(init-&gt;proj_out(TypeFunc::Memory), alloc_mem);
      C-&gt;gvn_replace_by(init-&gt;proj_out(TypeFunc::Control), alloc-&gt;in(0));
  
      // move the allocation here (after the guards)
      _gvn.hash_delete(alloc);
<span class="line-new-header">--- 4874,14 ---</span>
      map()-&gt;replaced_nodes().apply(saved_jvms-&gt;map(), new_idx);
      set_jvms(saved_jvms);
      _reexecute_sp = saved_reexecute_sp;
  
      // Remove the allocation from above the guards
<span class="line-modified">!     CallProjections* callprojs = alloc-&gt;extract_projections(true);</span>
      InitializeNode* init = alloc-&gt;initialization();
      Node* alloc_mem = alloc-&gt;in(TypeFunc::Memory);
<span class="line-modified">!     C-&gt;gvn_replace_by(callprojs-&gt;fallthrough_ioproj, alloc-&gt;in(TypeFunc::I_O));</span>
      C-&gt;gvn_replace_by(init-&gt;proj_out(TypeFunc::Memory), alloc_mem);
      C-&gt;gvn_replace_by(init-&gt;proj_out(TypeFunc::Control), alloc-&gt;in(0));
  
      // move the allocation here (after the guards)
      _gvn.hash_delete(alloc);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 4548,11 ***</span>
      alloc-&gt;set_req(TypeFunc::I_O, i_o());
      Node *mem = reset_memory();
      set_all_memory(mem);
      alloc-&gt;set_req(TypeFunc::Memory, mem);
      set_control(init-&gt;proj_out_or_null(TypeFunc::Control));
<span class="line-modified">!     set_i_o(callprojs.fallthrough_ioproj);</span>
  
      // Update memory as done in GraphKit::set_output_for_allocation()
      const TypeInt* length_type = _gvn.find_int_type(alloc-&gt;in(AllocateNode::ALength));
      const TypeOopPtr* ary_type = _gvn.type(alloc-&gt;in(AllocateNode::KlassNode))-&gt;is_klassptr()-&gt;as_instance_type();
      if (ary_type-&gt;isa_aryptr() &amp;&amp; length_type != NULL) {
<span class="line-new-header">--- 4889,11 ---</span>
      alloc-&gt;set_req(TypeFunc::I_O, i_o());
      Node *mem = reset_memory();
      set_all_memory(mem);
      alloc-&gt;set_req(TypeFunc::Memory, mem);
      set_control(init-&gt;proj_out_or_null(TypeFunc::Control));
<span class="line-modified">!     set_i_o(callprojs-&gt;fallthrough_ioproj);</span>
  
      // Update memory as done in GraphKit::set_output_for_allocation()
      const TypeInt* length_type = _gvn.find_int_type(alloc-&gt;in(AllocateNode::ALength));
      const TypeOopPtr* ary_type = _gvn.type(alloc-&gt;in(AllocateNode::KlassNode))-&gt;is_klassptr()-&gt;as_instance_type();
      if (ary_type-&gt;isa_aryptr() &amp;&amp; length_type != NULL) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 4793,21 ***</span>
          uncommon_trap(Deoptimization::Reason_intrinsic,
                        Deoptimization::Action_make_not_entrant);
          assert(stopped(), &quot;Should be stopped&quot;);
        }
      }
      {
        PreserveJVMState pjvms(this);
        set_control(_gvn.transform(slow_region));
        uncommon_trap(Deoptimization::Reason_intrinsic,
                      Deoptimization::Action_make_not_entrant);
        assert(stopped(), &quot;Should be stopped&quot;);
      }
<span class="line-removed">- </span>
<span class="line-removed">-     const TypeKlassPtr* dest_klass_t = _gvn.type(dest_klass)-&gt;is_klassptr();</span>
<span class="line-removed">-     const Type *toop = TypeOopPtr::make_from_klass(dest_klass_t-&gt;klass());</span>
<span class="line-removed">-     src = _gvn.transform(new CheckCastPPNode(control(), src, toop));</span>
    }
  
    arraycopy_move_allocation_here(alloc, dest, saved_jvms, saved_reexecute_sp, new_idx);
  
    if (stopped()) {
<span class="line-new-header">--- 5134,33 ---</span>
          uncommon_trap(Deoptimization::Reason_intrinsic,
                        Deoptimization::Action_make_not_entrant);
          assert(stopped(), &quot;Should be stopped&quot;);
        }
      }
<span class="line-added">+ </span>
<span class="line-added">+     const TypeKlassPtr* dest_klass_t = _gvn.type(dest_klass)-&gt;is_klassptr();</span>
<span class="line-added">+     const Type* toop = TypeOopPtr::make_from_klass(dest_klass_t-&gt;klass());</span>
<span class="line-added">+     src = _gvn.transform(new CheckCastPPNode(control(), src, toop));</span>
<span class="line-added">+     src_type = _gvn.type(src);</span>
<span class="line-added">+     top_src  = src_type-&gt;isa_aryptr();</span>
<span class="line-added">+ </span>
<span class="line-added">+     if (top_dest != NULL &amp;&amp; !top_dest-&gt;elem()-&gt;isa_inlinetype() &amp;&amp; !top_dest-&gt;is_not_flat()) {</span>
<span class="line-added">+       generate_flatArray_guard(dest_klass, slow_region);</span>
<span class="line-added">+     }</span>
<span class="line-added">+ </span>
<span class="line-added">+     if (top_src != NULL &amp;&amp; !top_src-&gt;elem()-&gt;isa_inlinetype() &amp;&amp; !top_src-&gt;is_not_flat()) {</span>
<span class="line-added">+       Node* src_klass = load_object_klass(src);</span>
<span class="line-added">+       generate_flatArray_guard(src_klass, slow_region);</span>
<span class="line-added">+     }</span>
<span class="line-added">+ </span>
      {
        PreserveJVMState pjvms(this);
        set_control(_gvn.transform(slow_region));
        uncommon_trap(Deoptimization::Reason_intrinsic,
                      Deoptimization::Action_make_not_entrant);
        assert(stopped(), &quot;Should be stopped&quot;);
      }
    }
  
    arraycopy_move_allocation_here(alloc, dest, saved_jvms, saved_reexecute_sp, new_idx);
  
    if (stopped()) {
</pre>
<center><a href="../memory/metaspaceShared.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="loopopts.cpp.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>