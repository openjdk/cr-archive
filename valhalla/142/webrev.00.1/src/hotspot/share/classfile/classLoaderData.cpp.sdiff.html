<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/classfile/classLoaderData.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="../ci/ciInstanceKlass.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="classLoaderData.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/classfile/classLoaderData.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 47 // the singleton class the_null_class_loader_data().
 48 
 49 #include &quot;precompiled.hpp&quot;
 50 #include &quot;classfile/classLoaderData.inline.hpp&quot;
 51 #include &quot;classfile/classLoaderDataGraph.inline.hpp&quot;
 52 #include &quot;classfile/dictionary.hpp&quot;
 53 #include &quot;classfile/javaClasses.hpp&quot;
 54 #include &quot;classfile/moduleEntry.hpp&quot;
 55 #include &quot;classfile/packageEntry.hpp&quot;
 56 #include &quot;classfile/symbolTable.hpp&quot;
 57 #include &quot;classfile/systemDictionary.hpp&quot;
 58 #include &quot;gc/shared/oopStorageSet.hpp&quot;
 59 #include &quot;logging/log.hpp&quot;
 60 #include &quot;logging/logStream.hpp&quot;
 61 #include &quot;memory/allocation.inline.hpp&quot;
 62 #include &quot;memory/metadataFactory.hpp&quot;
 63 #include &quot;memory/resourceArea.hpp&quot;
 64 #include &quot;oops/access.inline.hpp&quot;
 65 #include &quot;oops/oop.inline.hpp&quot;
 66 #include &quot;oops/oopHandle.inline.hpp&quot;

 67 #include &quot;oops/weakHandle.inline.hpp&quot;
 68 #include &quot;runtime/atomic.hpp&quot;
 69 #include &quot;runtime/handles.inline.hpp&quot;
 70 #include &quot;runtime/mutex.hpp&quot;
 71 #include &quot;runtime/safepoint.hpp&quot;
 72 #include &quot;utilities/growableArray.hpp&quot;
 73 #include &quot;utilities/macros.hpp&quot;
 74 #include &quot;utilities/ostream.hpp&quot;
 75 
 76 ClassLoaderData * ClassLoaderData::_the_null_class_loader_data = NULL;
 77 
 78 void ClassLoaderData::init_null_class_loader_data() {
 79   assert(_the_null_class_loader_data == NULL, &quot;cannot initialize twice&quot;);
 80   assert(ClassLoaderDataGraph::_head == NULL, &quot;cannot initialize twice&quot;);
 81 
 82   _the_null_class_loader_data = new ClassLoaderData(Handle(), false);
 83   ClassLoaderDataGraph::_head = _the_null_class_loader_data;
 84   assert(_the_null_class_loader_data-&gt;is_the_null_class_loader_data(), &quot;Must be&quot;);
 85 
 86   LogTarget(Trace, class, loader, data) lt;
</pre>
<hr />
<pre>
357 #ifdef ASSERT
358       oop m = k-&gt;java_mirror();
359       assert(m != NULL, &quot;NULL mirror&quot;);
360       assert(m-&gt;is_a(SystemDictionary::Class_klass()), &quot;invalid mirror&quot;);
361 #endif
362       klass_closure-&gt;do_klass(k);
363     }
364   }
365 }
366 
367 void ClassLoaderData::classes_do(void f(InstanceKlass*)) {
368   // Lock-free access requires load_acquire
369   for (Klass* k = Atomic::load_acquire(&amp;_klasses); k != NULL; k = k-&gt;next_link()) {
370     if (k-&gt;is_instance_klass()) {
371       f(InstanceKlass::cast(k));
372     }
373     assert(k != k-&gt;next_link(), &quot;no loops!&quot;);
374   }
375 }
376 










377 void ClassLoaderData::modules_do(void f(ModuleEntry*)) {
378   assert_locked_or_safepoint(Module_lock);
379   if (_unnamed_module != NULL) {
380     f(_unnamed_module);
381   }
382   if (_modules != NULL) {
383     for (int i = 0; i &lt; _modules-&gt;table_size(); i++) {
384       for (ModuleEntry* entry = _modules-&gt;bucket(i);
385            entry != NULL;
386            entry = entry-&gt;next()) {
387         f(entry);
388       }
389     }
390   }
391 }
392 
393 void ClassLoaderData::packages_do(void f(PackageEntry*)) {
394   assert_locked_or_safepoint(Module_lock);
395   if (_packages != NULL) {
396     for (int i = 0; i &lt; _packages-&gt;table_size(); i++) {
</pre>
<hr />
<pre>
523   }
524   ShouldNotReachHere();   // should have found this class!!
525 }
526 
527 void ClassLoaderData::unload() {
528   _unloading = true;
529 
530   LogTarget(Trace, class, loader, data) lt;
531   if (lt.is_enabled()) {
532     ResourceMark rm;
533     LogStream ls(lt);
534     ls.print(&quot;unload&quot;);
535     print_value_on(&amp;ls);
536     ls.cr();
537   }
538 
539   // Some items on the _deallocate_list need to free their C heap structures
540   // if they are not already on the _klasses list.
541   free_deallocate_list_C_heap_structures();
542 


543   // Clean up class dependencies and tell serviceability tools
544   // these classes are unloading.  Must be called
545   // after erroneous classes are released.
546   classes_do(InstanceKlass::unload_class);
547 
548   // Clean up global class iterator for compiler
549   ClassLoaderDataGraph::adjust_saved_class(this);
550 }
551 
552 ModuleEntryTable* ClassLoaderData::modules() {
553   // Lazily create the module entry table at first request.
554   // Lock-free access requires load_acquire.
555   ModuleEntryTable* modules = Atomic::load_acquire(&amp;_modules);
556   if (modules == NULL) {
557     MutexLocker m1(Module_lock);
558     // Check if _modules got allocated while we were waiting for this lock.
559     if ((modules = _modules) == NULL) {
560       modules = new ModuleEntryTable(ModuleEntryTable::_moduletable_entry_size);
561 
562       {
</pre>
<hr />
<pre>
817 void ClassLoaderData::free_deallocate_list() {
818   // This must be called at a safepoint because it depends on metadata walking at
819   // safepoint cleanup time.
820   assert(SafepointSynchronize::is_at_safepoint(), &quot;only called at safepoint&quot;);
821   assert(!is_unloading(), &quot;only called for ClassLoaderData that are not unloading&quot;);
822   if (_deallocate_list == NULL) {
823     return;
824   }
825   // Go backwards because this removes entries that are freed.
826   for (int i = _deallocate_list-&gt;length() - 1; i &gt;= 0; i--) {
827     Metadata* m = _deallocate_list-&gt;at(i);
828     if (!m-&gt;on_stack()) {
829       _deallocate_list-&gt;remove_at(i);
830       // There are only three types of metadata that we deallocate directly.
831       // Cast them so they can be used by the template function.
832       if (m-&gt;is_method()) {
833         MetadataFactory::free_metadata(this, (Method*)m);
834       } else if (m-&gt;is_constantPool()) {
835         MetadataFactory::free_metadata(this, (ConstantPool*)m);
836       } else if (m-&gt;is_klass()) {
<span class="line-modified">837         MetadataFactory::free_metadata(this, (InstanceKlass*)m);</span>




838       } else {
839         ShouldNotReachHere();
840       }
841     } else {
842       // Metadata is alive.
843       // If scratch_class is on stack then it shouldn&#39;t be on this list!
844       assert(!m-&gt;is_klass() || !((InstanceKlass*)m)-&gt;is_scratch_class(),
845              &quot;scratch classes on this list should be dead&quot;);
846       // Also should assert that other metadata on the list was found in handles.
847       // Some cleaning remains.
848       ClassLoaderDataGraph::set_should_clean_deallocate_lists();
849     }
850   }
851 }
852 
853 // This is distinct from free_deallocate_list.  For class loader data that are
854 // unloading, this frees the C heap memory for items on the list, and unlinks
855 // scratch or error classes so that unloading events aren&#39;t triggered for these
856 // classes. The metadata is removed with the unloading metaspace.
857 // There isn&#39;t C heap memory allocated for methods, so nothing is done for them.
</pre>
</td>
<td>
<hr />
<pre>
 47 // the singleton class the_null_class_loader_data().
 48 
 49 #include &quot;precompiled.hpp&quot;
 50 #include &quot;classfile/classLoaderData.inline.hpp&quot;
 51 #include &quot;classfile/classLoaderDataGraph.inline.hpp&quot;
 52 #include &quot;classfile/dictionary.hpp&quot;
 53 #include &quot;classfile/javaClasses.hpp&quot;
 54 #include &quot;classfile/moduleEntry.hpp&quot;
 55 #include &quot;classfile/packageEntry.hpp&quot;
 56 #include &quot;classfile/symbolTable.hpp&quot;
 57 #include &quot;classfile/systemDictionary.hpp&quot;
 58 #include &quot;gc/shared/oopStorageSet.hpp&quot;
 59 #include &quot;logging/log.hpp&quot;
 60 #include &quot;logging/logStream.hpp&quot;
 61 #include &quot;memory/allocation.inline.hpp&quot;
 62 #include &quot;memory/metadataFactory.hpp&quot;
 63 #include &quot;memory/resourceArea.hpp&quot;
 64 #include &quot;oops/access.inline.hpp&quot;
 65 #include &quot;oops/oop.inline.hpp&quot;
 66 #include &quot;oops/oopHandle.inline.hpp&quot;
<span class="line-added"> 67 #include &quot;oops/inlineKlass.inline.hpp&quot;</span>
 68 #include &quot;oops/weakHandle.inline.hpp&quot;
 69 #include &quot;runtime/atomic.hpp&quot;
 70 #include &quot;runtime/handles.inline.hpp&quot;
 71 #include &quot;runtime/mutex.hpp&quot;
 72 #include &quot;runtime/safepoint.hpp&quot;
 73 #include &quot;utilities/growableArray.hpp&quot;
 74 #include &quot;utilities/macros.hpp&quot;
 75 #include &quot;utilities/ostream.hpp&quot;
 76 
 77 ClassLoaderData * ClassLoaderData::_the_null_class_loader_data = NULL;
 78 
 79 void ClassLoaderData::init_null_class_loader_data() {
 80   assert(_the_null_class_loader_data == NULL, &quot;cannot initialize twice&quot;);
 81   assert(ClassLoaderDataGraph::_head == NULL, &quot;cannot initialize twice&quot;);
 82 
 83   _the_null_class_loader_data = new ClassLoaderData(Handle(), false);
 84   ClassLoaderDataGraph::_head = _the_null_class_loader_data;
 85   assert(_the_null_class_loader_data-&gt;is_the_null_class_loader_data(), &quot;Must be&quot;);
 86 
 87   LogTarget(Trace, class, loader, data) lt;
</pre>
<hr />
<pre>
358 #ifdef ASSERT
359       oop m = k-&gt;java_mirror();
360       assert(m != NULL, &quot;NULL mirror&quot;);
361       assert(m-&gt;is_a(SystemDictionary::Class_klass()), &quot;invalid mirror&quot;);
362 #endif
363       klass_closure-&gt;do_klass(k);
364     }
365   }
366 }
367 
368 void ClassLoaderData::classes_do(void f(InstanceKlass*)) {
369   // Lock-free access requires load_acquire
370   for (Klass* k = Atomic::load_acquire(&amp;_klasses); k != NULL; k = k-&gt;next_link()) {
371     if (k-&gt;is_instance_klass()) {
372       f(InstanceKlass::cast(k));
373     }
374     assert(k != k-&gt;next_link(), &quot;no loops!&quot;);
375   }
376 }
377 
<span class="line-added">378 void ClassLoaderData::inline_classes_do(void f(InlineKlass*)) {</span>
<span class="line-added">379   // Lock-free access requires load_acquire</span>
<span class="line-added">380   for (Klass* k = Atomic::load_acquire(&amp;_klasses); k != NULL; k = k-&gt;next_link()) {</span>
<span class="line-added">381     if (k-&gt;is_inline_klass()) {</span>
<span class="line-added">382       f(InlineKlass::cast(k));</span>
<span class="line-added">383     }</span>
<span class="line-added">384     assert(k != k-&gt;next_link(), &quot;no loops!&quot;);</span>
<span class="line-added">385   }</span>
<span class="line-added">386 }</span>
<span class="line-added">387 </span>
388 void ClassLoaderData::modules_do(void f(ModuleEntry*)) {
389   assert_locked_or_safepoint(Module_lock);
390   if (_unnamed_module != NULL) {
391     f(_unnamed_module);
392   }
393   if (_modules != NULL) {
394     for (int i = 0; i &lt; _modules-&gt;table_size(); i++) {
395       for (ModuleEntry* entry = _modules-&gt;bucket(i);
396            entry != NULL;
397            entry = entry-&gt;next()) {
398         f(entry);
399       }
400     }
401   }
402 }
403 
404 void ClassLoaderData::packages_do(void f(PackageEntry*)) {
405   assert_locked_or_safepoint(Module_lock);
406   if (_packages != NULL) {
407     for (int i = 0; i &lt; _packages-&gt;table_size(); i++) {
</pre>
<hr />
<pre>
534   }
535   ShouldNotReachHere();   // should have found this class!!
536 }
537 
538 void ClassLoaderData::unload() {
539   _unloading = true;
540 
541   LogTarget(Trace, class, loader, data) lt;
542   if (lt.is_enabled()) {
543     ResourceMark rm;
544     LogStream ls(lt);
545     ls.print(&quot;unload&quot;);
546     print_value_on(&amp;ls);
547     ls.cr();
548   }
549 
550   // Some items on the _deallocate_list need to free their C heap structures
551   // if they are not already on the _klasses list.
552   free_deallocate_list_C_heap_structures();
553 
<span class="line-added">554   inline_classes_do(InlineKlass::cleanup);</span>
<span class="line-added">555 </span>
556   // Clean up class dependencies and tell serviceability tools
557   // these classes are unloading.  Must be called
558   // after erroneous classes are released.
559   classes_do(InstanceKlass::unload_class);
560 
561   // Clean up global class iterator for compiler
562   ClassLoaderDataGraph::adjust_saved_class(this);
563 }
564 
565 ModuleEntryTable* ClassLoaderData::modules() {
566   // Lazily create the module entry table at first request.
567   // Lock-free access requires load_acquire.
568   ModuleEntryTable* modules = Atomic::load_acquire(&amp;_modules);
569   if (modules == NULL) {
570     MutexLocker m1(Module_lock);
571     // Check if _modules got allocated while we were waiting for this lock.
572     if ((modules = _modules) == NULL) {
573       modules = new ModuleEntryTable(ModuleEntryTable::_moduletable_entry_size);
574 
575       {
</pre>
<hr />
<pre>
830 void ClassLoaderData::free_deallocate_list() {
831   // This must be called at a safepoint because it depends on metadata walking at
832   // safepoint cleanup time.
833   assert(SafepointSynchronize::is_at_safepoint(), &quot;only called at safepoint&quot;);
834   assert(!is_unloading(), &quot;only called for ClassLoaderData that are not unloading&quot;);
835   if (_deallocate_list == NULL) {
836     return;
837   }
838   // Go backwards because this removes entries that are freed.
839   for (int i = _deallocate_list-&gt;length() - 1; i &gt;= 0; i--) {
840     Metadata* m = _deallocate_list-&gt;at(i);
841     if (!m-&gt;on_stack()) {
842       _deallocate_list-&gt;remove_at(i);
843       // There are only three types of metadata that we deallocate directly.
844       // Cast them so they can be used by the template function.
845       if (m-&gt;is_method()) {
846         MetadataFactory::free_metadata(this, (Method*)m);
847       } else if (m-&gt;is_constantPool()) {
848         MetadataFactory::free_metadata(this, (ConstantPool*)m);
849       } else if (m-&gt;is_klass()) {
<span class="line-modified">850         if (!((Klass*)m)-&gt;is_inline_klass()) {</span>
<span class="line-added">851           MetadataFactory::free_metadata(this, (InstanceKlass*)m);</span>
<span class="line-added">852         } else {</span>
<span class="line-added">853           MetadataFactory::free_metadata(this, (InlineKlass*)m);</span>
<span class="line-added">854         }</span>
855       } else {
856         ShouldNotReachHere();
857       }
858     } else {
859       // Metadata is alive.
860       // If scratch_class is on stack then it shouldn&#39;t be on this list!
861       assert(!m-&gt;is_klass() || !((InstanceKlass*)m)-&gt;is_scratch_class(),
862              &quot;scratch classes on this list should be dead&quot;);
863       // Also should assert that other metadata on the list was found in handles.
864       // Some cleaning remains.
865       ClassLoaderDataGraph::set_should_clean_deallocate_lists();
866     }
867   }
868 }
869 
870 // This is distinct from free_deallocate_list.  For class loader data that are
871 // unloading, this frees the C heap memory for items on the list, and unlinks
872 // scratch or error classes so that unloading events aren&#39;t triggered for these
873 // classes. The metadata is removed with the unloading metaspace.
874 // There isn&#39;t C heap memory allocated for methods, so nothing is done for them.
</pre>
</td>
</tr>
</table>
<center><a href="../ci/ciInstanceKlass.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="classLoaderData.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>