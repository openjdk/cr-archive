<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/cfgnode.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="c2compiler.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="compile.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/cfgnode.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;classfile/systemDictionary.hpp&quot;
  27 #include &quot;gc/shared/barrierSet.hpp&quot;
  28 #include &quot;gc/shared/c2/barrierSetC2.hpp&quot;
  29 #include &quot;memory/allocation.inline.hpp&quot;
  30 #include &quot;memory/resourceArea.hpp&quot;
  31 #include &quot;oops/objArrayKlass.hpp&quot;
  32 #include &quot;opto/addnode.hpp&quot;
  33 #include &quot;opto/castnode.hpp&quot;
  34 #include &quot;opto/cfgnode.hpp&quot;
  35 #include &quot;opto/connode.hpp&quot;
  36 #include &quot;opto/convertnode.hpp&quot;

  37 #include &quot;opto/loopnode.hpp&quot;
  38 #include &quot;opto/machnode.hpp&quot;
  39 #include &quot;opto/movenode.hpp&quot;
  40 #include &quot;opto/narrowptrnode.hpp&quot;
  41 #include &quot;opto/mulnode.hpp&quot;
  42 #include &quot;opto/phaseX.hpp&quot;
  43 #include &quot;opto/regmask.hpp&quot;
  44 #include &quot;opto/runtime.hpp&quot;
  45 #include &quot;opto/subnode.hpp&quot;
  46 #include &quot;utilities/vmError.hpp&quot;
  47 
  48 // Portions of code courtesy of Clifford Click
  49 
  50 // Optimization - Graph Style
  51 
  52 //=============================================================================
  53 //------------------------------Value------------------------------------------
  54 // Compute the type of the RegionNode.
  55 const Type* RegionNode::Value(PhaseGVN* phase) const {
  56   for( uint i=1; i&lt;req(); ++i ) {       // For all paths in
</pre>
<hr />
<pre>
 354   nstack.push(n);
 355   visited.set(n-&gt;_idx);
 356   while (nstack.size() != 0) {
 357     n = nstack.pop();
 358     uint max = n-&gt;outcnt();
 359     for (uint i = 0; i &lt; max; i++) {
 360       Node* m = n-&gt;raw_out(i);
 361       if (m != NULL &amp;&amp; m-&gt;is_CFG()) {
 362         if (phase-&gt;eqv(m, this)) {
 363           return false; // We reached the Region node - it is not dead.
 364         }
 365         if (!visited.test_set(m-&gt;_idx))
 366           nstack.push(m);
 367       }
 368     }
 369   }
 370 
 371   return true; // The Region node is unreachable - it is dead.
 372 }
 373 
<span class="line-modified"> 374 bool RegionNode::try_clean_mem_phi(PhaseGVN *phase) {</span>
 375   // Incremental inlining + PhaseStringOpts sometimes produce:
 376   //
 377   // cmpP with 1 top input
 378   //           |
 379   //          If
 380   //         /  \
 381   //   IfFalse  IfTrue  /- Some Node
 382   //         \  /      /    /
 383   //        Region    / /-MergeMem
 384   //             \---Phi
 385   //
 386   //
 387   // It&#39;s expected by PhaseStringOpts that the Region goes away and is
 388   // replaced by If&#39;s control input but because there&#39;s still a Phi,
 389   // the Region stays in the graph. The top input from the cmpP is
 390   // propagated forward and a subgraph that is useful goes away. The
 391   // code below replaces the Phi with the MergeMem so that the Region
 392   // is simplified.
 393 
<span class="line-modified"> 394   PhiNode* phi = has_unique_phi();</span>
<span class="line-removed"> 395   if (phi &amp;&amp; phi-&gt;type() == Type::MEMORY &amp;&amp; req() == 3 &amp;&amp; phi-&gt;is_diamond_phi(true)) {</span>
 396     MergeMemNode* m = NULL;
<span class="line-modified"> 397     assert(phi-&gt;req() == 3, &quot;same as region&quot;);</span>

 398     for (uint i = 1; i &lt; 3; ++i) {
<span class="line-modified"> 399       Node *mem = phi-&gt;in(i);</span>
<span class="line-modified"> 400       if (mem &amp;&amp; mem-&gt;is_MergeMem() &amp;&amp; in(i)-&gt;outcnt() == 1) {</span>
 401         // Nothing is control-dependent on path #i except the region itself.
 402         m = mem-&gt;as_MergeMem();
 403         uint j = 3 - i;
<span class="line-modified"> 404         Node* other = phi-&gt;in(j);</span>
 405         if (other &amp;&amp; other == m-&gt;base_memory()) {
 406           // m is a successor memory to other, and is not pinned inside the diamond, so push it out.
 407           // This will allow the diamond to collapse completely.
<span class="line-modified"> 408           phase-&gt;is_IterGVN()-&gt;replace_node(phi, m);</span>
<span class="line-removed"> 409           return true;</span>
 410         }
 411       }
 412     }
 413   }
<span class="line-modified"> 414   return false;</span>
 415 }
 416 
 417 //------------------------------Ideal------------------------------------------
 418 // Return a node which is more &quot;ideal&quot; than the current node.  Must preserve
 419 // the CFG, but we can still strip out dead paths.
 420 Node *RegionNode::Ideal(PhaseGVN *phase, bool can_reshape) {
 421   if( !can_reshape &amp;&amp; !in(0) ) return NULL;     // Already degraded to a Copy
 422   assert(!in(0) || !in(0)-&gt;is_Root(), &quot;not a specially hidden merge&quot;);
 423 
 424   // Check for RegionNode with no Phi users and both inputs come from either
 425   // arm of the same IF.  If found, then the control-flow split is useless.
 426   bool has_phis = false;
 427   if (can_reshape) {            // Need DU info to check for Phi users
 428     has_phis = (has_phi() != NULL);       // Cache result
<span class="line-modified"> 429     if (has_phis &amp;&amp; try_clean_mem_phi(phase)) {</span>
<span class="line-modified"> 430       has_phis = false;</span>







 431     }
 432 
 433     if (!has_phis) {            // No Phi users?  Nothing merging?
 434       for (uint i = 1; i &lt; req()-1; i++) {
 435         Node *if1 = in(i);
 436         if( !if1 ) continue;
 437         Node *iff = if1-&gt;in(0);
 438         if( !iff || !iff-&gt;is_If() ) continue;
 439         for( uint j=i+1; j&lt;req(); j++ ) {
 440           if( in(j) &amp;&amp; in(j)-&gt;in(0) == iff &amp;&amp;
 441               if1-&gt;Opcode() != in(j)-&gt;Opcode() ) {
 442             // Add the IF Projections to the worklist. They (and the IF itself)
 443             // will be eliminated if dead.
 444             phase-&gt;is_IterGVN()-&gt;add_users_to_worklist(iff);
 445             set_req(i, iff-&gt;in(0));// Skip around the useless IF diamond
 446             set_req(j, NULL);
 447             return this;      // Record progress
 448           }
 449         }
 450       }
</pre>
<hr />
<pre>
 878 
 879 //=============================================================================
 880 // note that these functions assume that the _adr_type field is flattened
 881 uint PhiNode::hash() const {
 882   const Type* at = _adr_type;
 883   return TypeNode::hash() + (at ? at-&gt;hash() : 0);
 884 }
 885 bool PhiNode::cmp( const Node &amp;n ) const {
 886   return TypeNode::cmp(n) &amp;&amp; _adr_type == ((PhiNode&amp;)n)._adr_type;
 887 }
 888 static inline
 889 const TypePtr* flatten_phi_adr_type(const TypePtr* at) {
 890   if (at == NULL || at == TypePtr::BOTTOM)  return at;
 891   return Compile::current()-&gt;alias_type(at)-&gt;adr_type();
 892 }
 893 
 894 //----------------------------make---------------------------------------------
 895 // create a new phi with edges matching r and set (initially) to x
 896 PhiNode* PhiNode::make(Node* r, Node* x, const Type *t, const TypePtr* at) {
 897   uint preds = r-&gt;req();   // Number of predecessor paths
<span class="line-modified"> 898   assert(t != Type::MEMORY || at == flatten_phi_adr_type(at), &quot;flatten at&quot;);</span>
 899   PhiNode* p = new PhiNode(r, t, at);
 900   for (uint j = 1; j &lt; preds; j++) {
 901     // Fill in all inputs, except those which the region does not yet have
 902     if (r-&gt;in(j) != NULL)
 903       p-&gt;init_req(j, x);
 904   }
 905   return p;
 906 }
 907 PhiNode* PhiNode::make(Node* r, Node* x) {
 908   const Type*    t  = x-&gt;bottom_type();
 909   const TypePtr* at = NULL;
 910   if (t == Type::MEMORY)  at = flatten_phi_adr_type(x-&gt;adr_type());
 911   return make(r, x, t, at);
 912 }
 913 PhiNode* PhiNode::make_blank(Node* r, Node* x) {
 914   const Type*    t  = x-&gt;bottom_type();
 915   const TypePtr* at = NULL;
 916   if (t == Type::MEMORY)  at = flatten_phi_adr_type(x-&gt;adr_type());
 917   return new PhiNode(r, t, at);
 918 }
</pre>
<hr />
<pre>
1088         }
1089       }
1090     } else if (l-&gt;in(LoopNode::LoopBackControl) != NULL &amp;&amp;
1091                in(LoopNode::EntryControl) != NULL &amp;&amp;
1092                phase-&gt;type(l-&gt;in(LoopNode::LoopBackControl)) == Type::TOP) {
1093       // During CCP, if we saturate the type of a counted loop&#39;s Phi
1094       // before the special code for counted loop above has a chance
1095       // to run (that is as long as the type of the backedge&#39;s control
1096       // is top), we might end up with non monotonic types
1097       return phase-&gt;type(in(LoopNode::EntryControl))-&gt;filter_speculative(_type);
1098     }
1099   }
1100 
1101   // Until we have harmony between classes and interfaces in the type
1102   // lattice, we must tread carefully around phis which implicitly
1103   // convert the one to the other.
1104   const TypePtr* ttp = _type-&gt;make_ptr();
1105   const TypeInstPtr* ttip = (ttp != NULL) ? ttp-&gt;isa_instptr() : NULL;
1106   const TypeKlassPtr* ttkp = (ttp != NULL) ? ttp-&gt;isa_klassptr() : NULL;
1107   bool is_intf = false;
<span class="line-modified">1108   if (ttip != NULL) {</span>
<span class="line-modified">1109     ciKlass* k = ttip-&gt;klass();</span>
<span class="line-modified">1110     if (k-&gt;is_loaded() &amp;&amp; k-&gt;is_interface())</span>
<span class="line-modified">1111       is_intf = true;</span>
<span class="line-removed">1112   }</span>
<span class="line-removed">1113   if (ttkp != NULL) {</span>
<span class="line-removed">1114     ciKlass* k = ttkp-&gt;klass();</span>
<span class="line-removed">1115     if (k-&gt;is_loaded() &amp;&amp; k-&gt;is_interface())</span>
<span class="line-removed">1116       is_intf = true;</span>
1117   }
1118 
1119   // Default case: merge all inputs
1120   const Type *t = Type::TOP;        // Merged type starting value
1121   for (uint i = 1; i &lt; req(); ++i) {// For all paths in
1122     // Reachable control path?
1123     if (r-&gt;in(i) &amp;&amp; phase-&gt;type(r-&gt;in(i)) == Type::CONTROL) {
1124       const Type* ti = phase-&gt;type(in(i));
1125       // We assume that each input of an interface-valued Phi is a true
1126       // subtype of that interface.  This might not be true of the meet
1127       // of all the input types.  The lattice is not distributive in
1128       // such cases.  Ward off asserts in type.cpp by refusing to do
1129       // meets between interfaces and proper classes.
1130       const TypePtr* tip = ti-&gt;make_ptr();
1131       const TypeInstPtr* tiip = (tip != NULL) ? tip-&gt;isa_instptr() : NULL;
1132       if (tiip) {
1133         bool ti_is_intf = false;
1134         ciKlass* k = tiip-&gt;klass();
1135         if (k-&gt;is_loaded() &amp;&amp; k-&gt;is_interface())
1136           ti_is_intf = true;
</pre>
<hr />
<pre>
1153   //   (Occurrences of this case suggest improvements to Value methods.)
1154   //
1155   // It is not possible to see Type::BOTTOM values as phi inputs,
1156   // because the ciTypeFlow pre-pass produces verifier-quality types.
1157   const Type* ft = t-&gt;filter_speculative(_type);  // Worst case type
1158 
1159 #ifdef ASSERT
1160   // The following logic has been moved into TypeOopPtr::filter.
1161   const Type* jt = t-&gt;join_speculative(_type);
1162   if (jt-&gt;empty()) {           // Emptied out???
1163 
1164     // Check for evil case of &#39;t&#39; being a class and &#39;_type&#39; expecting an
1165     // interface.  This can happen because the bytecodes do not contain
1166     // enough type info to distinguish a Java-level interface variable
1167     // from a Java-level object variable.  If we meet 2 classes which
1168     // both implement interface I, but their meet is at &#39;j/l/O&#39; which
1169     // doesn&#39;t implement I, we have no way to tell if the result should
1170     // be &#39;I&#39; or &#39;j/l/O&#39;.  Thus we&#39;ll pick &#39;j/l/O&#39;.  If this then flows
1171     // into a Phi which &quot;knows&quot; it&#39;s an Interface type we&#39;ll have to
1172     // uplift the type.
<span class="line-modified">1173     if (!t-&gt;empty() &amp;&amp; ttip &amp;&amp; ttip-&gt;is_loaded() &amp;&amp; ttip-&gt;klass()-&gt;is_interface()) {</span>
1174       assert(ft == _type, &quot;&quot;); // Uplift to interface
<span class="line-modified">1175     } else if (!t-&gt;empty() &amp;&amp; ttkp &amp;&amp; ttkp-&gt;is_loaded() &amp;&amp; ttkp-&gt;klass()-&gt;is_interface()) {</span>
1176       assert(ft == _type, &quot;&quot;); // Uplift to interface
1177     } else {
1178       // We also have to handle &#39;evil cases&#39; of interface- vs. class-arrays
1179       Type::get_arrays_base_elements(jt, _type, NULL, &amp;ttip);
1180       if (!t-&gt;empty() &amp;&amp; ttip != NULL &amp;&amp; ttip-&gt;is_loaded() &amp;&amp; ttip-&gt;klass()-&gt;is_interface()) {
1181           assert(ft == _type, &quot;&quot;);   // Uplift to array of interface
1182       } else {
1183         // Otherwise it&#39;s something stupid like non-overlapping int ranges
1184         // found on dying counted loops.
1185         assert(ft == Type::TOP, &quot;&quot;); // Canonical empty value
1186       }
1187     }
1188   }
1189 
1190   else {
1191 
1192     // If we have an interface-typed Phi and we narrow to a class type, the join
1193     // should report back the class.  However, if we have a J/L/Object
1194     // class-typed Phi and an interface flows in, it&#39;s possible that the meet &amp;
1195     // join report an interface back out.  This isn&#39;t possible but happens
</pre>
<hr />
<pre>
1317 
1318 //------------------------------Identity---------------------------------------
1319 // Check for Region being Identity.
1320 Node* PhiNode::Identity(PhaseGVN* phase) {
1321   // Check for no merging going on
1322   // (There used to be special-case code here when this-&gt;region-&gt;is_Loop.
1323   // It would check for a tributary phi on the backedge that the main phi
1324   // trivially, perhaps with a single cast.  The unique_input method
1325   // does all this and more, by reducing such tributaries to &#39;this&#39;.)
1326   Node* uin = unique_input(phase, false);
1327   if (uin != NULL) {
1328     return uin;
1329   }
1330 
1331   int true_path = is_diamond_phi();
1332   if (true_path != 0) {
1333     Node* id = is_cmove_id(phase, true_path);
1334     if (id != NULL)  return id;
1335   }
1336 








1337   // Looking for phis with identical inputs.  If we find one that has
1338   // type TypePtr::BOTTOM, replace the current phi with the bottom phi.
1339   if (phase-&gt;is_IterGVN() &amp;&amp; type() == Type::MEMORY &amp;&amp; adr_type() !=
1340       TypePtr::BOTTOM &amp;&amp; !adr_type()-&gt;is_known_instance()) {
1341     uint phi_len = req();
1342     Node* phi_reg = region();
1343     for (DUIterator_Fast imax, i = phi_reg-&gt;fast_outs(imax); i &lt; imax; i++) {
1344       Node* u = phi_reg-&gt;fast_out(i);
1345       if (u-&gt;is_Phi() &amp;&amp; u-&gt;as_Phi()-&gt;type() == Type::MEMORY &amp;&amp;
1346           u-&gt;adr_type() == TypePtr::BOTTOM &amp;&amp; u-&gt;in(0) == phi_reg &amp;&amp;
1347           u-&gt;req() == phi_len) {
1348         for (uint j = 1; j &lt; phi_len; j++) {
1349           if (in(j) != u-&gt;in(j)) {
1350             u = NULL;
1351             break;
1352           }
1353         }
1354         if (u != NULL) {
1355           return u;
1356         }
</pre>
<hr />
<pre>
1863   }
1864   return delay;
1865 }
1866 
1867 //------------------------------Ideal------------------------------------------
1868 // Return a node which is more &quot;ideal&quot; than the current node.  Must preserve
1869 // the CFG, but we can still strip out dead paths.
1870 Node *PhiNode::Ideal(PhaseGVN *phase, bool can_reshape) {
1871   // The next should never happen after 6297035 fix.
1872   if( is_copy() )               // Already degraded to a Copy ?
1873     return NULL;                // No change
1874 
1875   Node *r = in(0);              // RegionNode
1876   assert(r-&gt;in(0) == NULL || !r-&gt;in(0)-&gt;is_Root(), &quot;not a specially hidden merge&quot;);
1877 
1878   // Note: During parsing, phis are often transformed before their regions.
1879   // This means we have to use type_or_null to defend against untyped regions.
1880   if( phase-&gt;type_or_null(r) == Type::TOP ) // Dead code?
1881     return NULL;                // No change
1882 


















1883   Node *top = phase-&gt;C-&gt;top();
1884   bool new_phi = (outcnt() == 0); // transforming new Phi
1885   // No change for igvn if new phi is not hooked
1886   if (new_phi &amp;&amp; can_reshape)
1887     return NULL;
1888 
1889   // The are 2 situations when only one valid phi&#39;s input is left
1890   // (in addition to Region input).
1891   // One: region is not loop - replace phi with this input.
1892   // Two: region is loop - replace phi with top since this data path is dead
1893   //                       and we need to break the dead data loop.
1894   Node* progress = NULL;        // Record if any progress made
1895   for( uint j = 1; j &lt; req(); ++j ){ // For all paths in
1896     // Check unreachable control paths
1897     Node* rc = r-&gt;in(j);
1898     Node* n = in(j);            // Get the input
1899     if (rc == NULL || phase-&gt;type(rc) == Type::TOP) {
1900       if (n != top) {           // Not already top?
1901         PhaseIterGVN *igvn = phase-&gt;is_IterGVN();
1902         if (can_reshape &amp;&amp; igvn != NULL) {
</pre>
<hr />
<pre>
2161           for (uint i = 1; i &lt; req(); i++) {
2162             offset-&gt;init_req(i, in(i)-&gt;in(AddPNode::Offset));
2163           }
2164           phase-&gt;is_IterGVN()-&gt;register_new_node_with_optimizer(offset);
2165         }
2166         return new AddPNode(base, address, offset);
2167       }
2168     }
2169   }
2170 
2171   // Split phis through memory merges, so that the memory merges will go away.
2172   // Piggy-back this transformation on the search for a unique input....
2173   // It will be as if the merged memory is the unique value of the phi.
2174   // (Do not attempt this optimization unless parsing is complete.
2175   // It would make the parser&#39;s memory-merge logic sick.)
2176   // (MergeMemNode is not dead_loop_safe - need to check for dead loop.)
2177   if (progress == NULL &amp;&amp; can_reshape &amp;&amp; type() == Type::MEMORY) {
2178     // see if this phi should be sliced
2179     uint merge_width = 0;
2180     bool saw_self = false;


2181     for( uint i=1; i&lt;req(); ++i ) {// For all paths in
2182       Node *ii = in(i);
2183       // TOP inputs should not be counted as safe inputs because if the
2184       // Phi references itself through all other inputs then splitting the
2185       // Phi through memory merges would create dead loop at later stage.
2186       if (ii == top) {
2187         return NULL; // Delay optimization until graph is cleaned.
2188       }
2189       if (ii-&gt;is_MergeMem()) {
2190         MergeMemNode* n = ii-&gt;as_MergeMem();
2191         merge_width = MAX2(merge_width, n-&gt;req());
2192         saw_self = saw_self || phase-&gt;eqv(n-&gt;base_memory(), this);


2193       }
2194     }
2195 
2196     // This restriction is temporarily necessary to ensure termination:
<span class="line-modified">2197     if (!saw_self &amp;&amp; adr_type() == TypePtr::BOTTOM)  merge_width = 0;</span>
2198 
2199     if (merge_width &gt; Compile::AliasIdxRaw) {
2200       // found at least one non-empty MergeMem
2201       const TypePtr* at = adr_type();
2202       if (at != TypePtr::BOTTOM) {
2203         // Patch the existing phi to select an input from the merge:
2204         // Phi:AT1(...MergeMem(m0, m1, m2)...) into
2205         //     Phi:AT1(...m1...)
2206         int alias_idx = phase-&gt;C-&gt;get_alias_index(at);
2207         for (uint i=1; i&lt;req(); ++i) {
2208           Node *ii = in(i);
2209           if (ii-&gt;is_MergeMem()) {
2210             MergeMemNode* n = ii-&gt;as_MergeMem();
2211             // compress paths and change unreachable cycles to TOP
2212             // If not, we can update the input infinitely along a MergeMem cycle
2213             // Equivalent code is in MemNode::Ideal_common
2214             Node *m  = phase-&gt;transform(n);
2215             if (outcnt() == 0) {  // Above transform() may kill us!
2216               return top;
2217             }
</pre>
<hr />
<pre>
2606   return in(0)-&gt;in(0);
2607 }
2608 
2609 
2610 #ifndef PRODUCT
2611 void CatchProjNode::dump_spec(outputStream *st) const {
2612   ProjNode::dump_spec(st);
2613   st-&gt;print(&quot;@bci %d &quot;,_handler_bci);
2614 }
2615 #endif
2616 
2617 //=============================================================================
2618 //------------------------------Identity---------------------------------------
2619 // Check for CreateEx being Identity.
2620 Node* CreateExNode::Identity(PhaseGVN* phase) {
2621   if( phase-&gt;type(in(1)) == Type::TOP ) return in(1);
2622   if( phase-&gt;type(in(0)) == Type::TOP ) return in(0);
2623   // We only come from CatchProj, unless the CatchProj goes away.
2624   // If the CatchProj is optimized away, then we just carry the
2625   // exception oop through.






2626   CallNode *call = in(1)-&gt;in(0)-&gt;as_Call();
2627 
2628   return ( in(0)-&gt;is_CatchProj() &amp;&amp; in(0)-&gt;in(0)-&gt;in(1) == in(1) )
2629     ? this
2630     : call-&gt;in(TypeFunc::Parms);
2631 }
2632 
2633 //=============================================================================
2634 //------------------------------Value------------------------------------------
2635 // Check for being unreachable.
2636 const Type* NeverBranchNode::Value(PhaseGVN* phase) const {
2637   if (!in(0) || in(0)-&gt;is_top()) return Type::TOP;
2638   return bottom_type();
2639 }
2640 
2641 //------------------------------Ideal------------------------------------------
2642 // Check for no longer being part of a loop
2643 Node *NeverBranchNode::Ideal(PhaseGVN *phase, bool can_reshape) {
2644   if (can_reshape &amp;&amp; !in(0)-&gt;is_Loop()) {
2645     // Dead code elimination can sometimes delete this projection so
</pre>
</td>
<td>
<hr />
<pre>
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;classfile/systemDictionary.hpp&quot;
  27 #include &quot;gc/shared/barrierSet.hpp&quot;
  28 #include &quot;gc/shared/c2/barrierSetC2.hpp&quot;
  29 #include &quot;memory/allocation.inline.hpp&quot;
  30 #include &quot;memory/resourceArea.hpp&quot;
  31 #include &quot;oops/objArrayKlass.hpp&quot;
  32 #include &quot;opto/addnode.hpp&quot;
  33 #include &quot;opto/castnode.hpp&quot;
  34 #include &quot;opto/cfgnode.hpp&quot;
  35 #include &quot;opto/connode.hpp&quot;
  36 #include &quot;opto/convertnode.hpp&quot;
<span class="line-added">  37 #include &quot;opto/inlinetypenode.hpp&quot;</span>
  38 #include &quot;opto/loopnode.hpp&quot;
  39 #include &quot;opto/machnode.hpp&quot;
  40 #include &quot;opto/movenode.hpp&quot;
  41 #include &quot;opto/narrowptrnode.hpp&quot;
  42 #include &quot;opto/mulnode.hpp&quot;
  43 #include &quot;opto/phaseX.hpp&quot;
  44 #include &quot;opto/regmask.hpp&quot;
  45 #include &quot;opto/runtime.hpp&quot;
  46 #include &quot;opto/subnode.hpp&quot;
  47 #include &quot;utilities/vmError.hpp&quot;
  48 
  49 // Portions of code courtesy of Clifford Click
  50 
  51 // Optimization - Graph Style
  52 
  53 //=============================================================================
  54 //------------------------------Value------------------------------------------
  55 // Compute the type of the RegionNode.
  56 const Type* RegionNode::Value(PhaseGVN* phase) const {
  57   for( uint i=1; i&lt;req(); ++i ) {       // For all paths in
</pre>
<hr />
<pre>
 355   nstack.push(n);
 356   visited.set(n-&gt;_idx);
 357   while (nstack.size() != 0) {
 358     n = nstack.pop();
 359     uint max = n-&gt;outcnt();
 360     for (uint i = 0; i &lt; max; i++) {
 361       Node* m = n-&gt;raw_out(i);
 362       if (m != NULL &amp;&amp; m-&gt;is_CFG()) {
 363         if (phase-&gt;eqv(m, this)) {
 364           return false; // We reached the Region node - it is not dead.
 365         }
 366         if (!visited.test_set(m-&gt;_idx))
 367           nstack.push(m);
 368       }
 369     }
 370   }
 371 
 372   return true; // The Region node is unreachable - it is dead.
 373 }
 374 
<span class="line-modified"> 375 Node* PhiNode::try_clean_mem_phi(PhaseGVN *phase) {</span>
 376   // Incremental inlining + PhaseStringOpts sometimes produce:
 377   //
 378   // cmpP with 1 top input
 379   //           |
 380   //          If
 381   //         /  \
 382   //   IfFalse  IfTrue  /- Some Node
 383   //         \  /      /    /
 384   //        Region    / /-MergeMem
 385   //             \---Phi
 386   //
 387   //
 388   // It&#39;s expected by PhaseStringOpts that the Region goes away and is
 389   // replaced by If&#39;s control input but because there&#39;s still a Phi,
 390   // the Region stays in the graph. The top input from the cmpP is
 391   // propagated forward and a subgraph that is useful goes away. The
 392   // code below replaces the Phi with the MergeMem so that the Region
 393   // is simplified.
 394 
<span class="line-modified"> 395   if (type() == Type::MEMORY &amp;&amp; is_diamond_phi(true)) {</span>

 396     MergeMemNode* m = NULL;
<span class="line-modified"> 397     assert(req() == 3, &quot;same as region&quot;);</span>
<span class="line-added"> 398     Node* r = in(0);</span>
 399     for (uint i = 1; i &lt; 3; ++i) {
<span class="line-modified"> 400       Node *mem = in(i);</span>
<span class="line-modified"> 401       if (mem &amp;&amp; mem-&gt;is_MergeMem() &amp;&amp; r-&gt;in(i)-&gt;outcnt() == 1) {</span>
 402         // Nothing is control-dependent on path #i except the region itself.
 403         m = mem-&gt;as_MergeMem();
 404         uint j = 3 - i;
<span class="line-modified"> 405         Node* other = in(j);</span>
 406         if (other &amp;&amp; other == m-&gt;base_memory()) {
 407           // m is a successor memory to other, and is not pinned inside the diamond, so push it out.
 408           // This will allow the diamond to collapse completely.
<span class="line-modified"> 409           return m;</span>

 410         }
 411       }
 412     }
 413   }
<span class="line-modified"> 414   return NULL;</span>
 415 }
 416 
 417 //------------------------------Ideal------------------------------------------
 418 // Return a node which is more &quot;ideal&quot; than the current node.  Must preserve
 419 // the CFG, but we can still strip out dead paths.
 420 Node *RegionNode::Ideal(PhaseGVN *phase, bool can_reshape) {
 421   if( !can_reshape &amp;&amp; !in(0) ) return NULL;     // Already degraded to a Copy
 422   assert(!in(0) || !in(0)-&gt;is_Root(), &quot;not a specially hidden merge&quot;);
 423 
 424   // Check for RegionNode with no Phi users and both inputs come from either
 425   // arm of the same IF.  If found, then the control-flow split is useless.
 426   bool has_phis = false;
 427   if (can_reshape) {            // Need DU info to check for Phi users
 428     has_phis = (has_phi() != NULL);       // Cache result
<span class="line-modified"> 429     if (has_phis) {</span>
<span class="line-modified"> 430       PhiNode* phi = has_unique_phi();</span>
<span class="line-added"> 431       if (phi != NULL) {</span>
<span class="line-added"> 432         Node* m = phi-&gt;try_clean_mem_phi(phase);</span>
<span class="line-added"> 433         if (m != NULL) {</span>
<span class="line-added"> 434           phase-&gt;is_IterGVN()-&gt;replace_node(phi, m);</span>
<span class="line-added"> 435           has_phis = false;</span>
<span class="line-added"> 436         }</span>
<span class="line-added"> 437       }</span>
 438     }
 439 
 440     if (!has_phis) {            // No Phi users?  Nothing merging?
 441       for (uint i = 1; i &lt; req()-1; i++) {
 442         Node *if1 = in(i);
 443         if( !if1 ) continue;
 444         Node *iff = if1-&gt;in(0);
 445         if( !iff || !iff-&gt;is_If() ) continue;
 446         for( uint j=i+1; j&lt;req(); j++ ) {
 447           if( in(j) &amp;&amp; in(j)-&gt;in(0) == iff &amp;&amp;
 448               if1-&gt;Opcode() != in(j)-&gt;Opcode() ) {
 449             // Add the IF Projections to the worklist. They (and the IF itself)
 450             // will be eliminated if dead.
 451             phase-&gt;is_IterGVN()-&gt;add_users_to_worklist(iff);
 452             set_req(i, iff-&gt;in(0));// Skip around the useless IF diamond
 453             set_req(j, NULL);
 454             return this;      // Record progress
 455           }
 456         }
 457       }
</pre>
<hr />
<pre>
 885 
 886 //=============================================================================
 887 // note that these functions assume that the _adr_type field is flattened
 888 uint PhiNode::hash() const {
 889   const Type* at = _adr_type;
 890   return TypeNode::hash() + (at ? at-&gt;hash() : 0);
 891 }
 892 bool PhiNode::cmp( const Node &amp;n ) const {
 893   return TypeNode::cmp(n) &amp;&amp; _adr_type == ((PhiNode&amp;)n)._adr_type;
 894 }
 895 static inline
 896 const TypePtr* flatten_phi_adr_type(const TypePtr* at) {
 897   if (at == NULL || at == TypePtr::BOTTOM)  return at;
 898   return Compile::current()-&gt;alias_type(at)-&gt;adr_type();
 899 }
 900 
 901 //----------------------------make---------------------------------------------
 902 // create a new phi with edges matching r and set (initially) to x
 903 PhiNode* PhiNode::make(Node* r, Node* x, const Type *t, const TypePtr* at) {
 904   uint preds = r-&gt;req();   // Number of predecessor paths
<span class="line-modified"> 905   assert(t != Type::MEMORY || at == flatten_phi_adr_type(at) || (flatten_phi_adr_type(at) == TypeAryPtr::INLINES &amp;&amp; Compile::current()-&gt;flattened_accesses_share_alias()), &quot;flatten at&quot;);</span>
 906   PhiNode* p = new PhiNode(r, t, at);
 907   for (uint j = 1; j &lt; preds; j++) {
 908     // Fill in all inputs, except those which the region does not yet have
 909     if (r-&gt;in(j) != NULL)
 910       p-&gt;init_req(j, x);
 911   }
 912   return p;
 913 }
 914 PhiNode* PhiNode::make(Node* r, Node* x) {
 915   const Type*    t  = x-&gt;bottom_type();
 916   const TypePtr* at = NULL;
 917   if (t == Type::MEMORY)  at = flatten_phi_adr_type(x-&gt;adr_type());
 918   return make(r, x, t, at);
 919 }
 920 PhiNode* PhiNode::make_blank(Node* r, Node* x) {
 921   const Type*    t  = x-&gt;bottom_type();
 922   const TypePtr* at = NULL;
 923   if (t == Type::MEMORY)  at = flatten_phi_adr_type(x-&gt;adr_type());
 924   return new PhiNode(r, t, at);
 925 }
</pre>
<hr />
<pre>
1095         }
1096       }
1097     } else if (l-&gt;in(LoopNode::LoopBackControl) != NULL &amp;&amp;
1098                in(LoopNode::EntryControl) != NULL &amp;&amp;
1099                phase-&gt;type(l-&gt;in(LoopNode::LoopBackControl)) == Type::TOP) {
1100       // During CCP, if we saturate the type of a counted loop&#39;s Phi
1101       // before the special code for counted loop above has a chance
1102       // to run (that is as long as the type of the backedge&#39;s control
1103       // is top), we might end up with non monotonic types
1104       return phase-&gt;type(in(LoopNode::EntryControl))-&gt;filter_speculative(_type);
1105     }
1106   }
1107 
1108   // Until we have harmony between classes and interfaces in the type
1109   // lattice, we must tread carefully around phis which implicitly
1110   // convert the one to the other.
1111   const TypePtr* ttp = _type-&gt;make_ptr();
1112   const TypeInstPtr* ttip = (ttp != NULL) ? ttp-&gt;isa_instptr() : NULL;
1113   const TypeKlassPtr* ttkp = (ttp != NULL) ? ttp-&gt;isa_klassptr() : NULL;
1114   bool is_intf = false;
<span class="line-modified">1115   if (ttip != NULL &amp;&amp; ttip-&gt;is_loaded() &amp;&amp; ttip-&gt;klass()-&gt;is_interface()) {</span>
<span class="line-modified">1116     is_intf = true;</span>
<span class="line-modified">1117   } else if (ttkp != NULL &amp;&amp; ttkp-&gt;is_loaded() &amp;&amp; ttkp-&gt;klass()-&gt;is_interface()) {</span>
<span class="line-modified">1118     is_intf = true;</span>





1119   }
1120 
1121   // Default case: merge all inputs
1122   const Type *t = Type::TOP;        // Merged type starting value
1123   for (uint i = 1; i &lt; req(); ++i) {// For all paths in
1124     // Reachable control path?
1125     if (r-&gt;in(i) &amp;&amp; phase-&gt;type(r-&gt;in(i)) == Type::CONTROL) {
1126       const Type* ti = phase-&gt;type(in(i));
1127       // We assume that each input of an interface-valued Phi is a true
1128       // subtype of that interface.  This might not be true of the meet
1129       // of all the input types.  The lattice is not distributive in
1130       // such cases.  Ward off asserts in type.cpp by refusing to do
1131       // meets between interfaces and proper classes.
1132       const TypePtr* tip = ti-&gt;make_ptr();
1133       const TypeInstPtr* tiip = (tip != NULL) ? tip-&gt;isa_instptr() : NULL;
1134       if (tiip) {
1135         bool ti_is_intf = false;
1136         ciKlass* k = tiip-&gt;klass();
1137         if (k-&gt;is_loaded() &amp;&amp; k-&gt;is_interface())
1138           ti_is_intf = true;
</pre>
<hr />
<pre>
1155   //   (Occurrences of this case suggest improvements to Value methods.)
1156   //
1157   // It is not possible to see Type::BOTTOM values as phi inputs,
1158   // because the ciTypeFlow pre-pass produces verifier-quality types.
1159   const Type* ft = t-&gt;filter_speculative(_type);  // Worst case type
1160 
1161 #ifdef ASSERT
1162   // The following logic has been moved into TypeOopPtr::filter.
1163   const Type* jt = t-&gt;join_speculative(_type);
1164   if (jt-&gt;empty()) {           // Emptied out???
1165 
1166     // Check for evil case of &#39;t&#39; being a class and &#39;_type&#39; expecting an
1167     // interface.  This can happen because the bytecodes do not contain
1168     // enough type info to distinguish a Java-level interface variable
1169     // from a Java-level object variable.  If we meet 2 classes which
1170     // both implement interface I, but their meet is at &#39;j/l/O&#39; which
1171     // doesn&#39;t implement I, we have no way to tell if the result should
1172     // be &#39;I&#39; or &#39;j/l/O&#39;.  Thus we&#39;ll pick &#39;j/l/O&#39;.  If this then flows
1173     // into a Phi which &quot;knows&quot; it&#39;s an Interface type we&#39;ll have to
1174     // uplift the type.
<span class="line-modified">1175     if (!t-&gt;empty() &amp;&amp; ttip != NULL &amp;&amp; ttip-&gt;is_loaded() &amp;&amp; ttip-&gt;klass()-&gt;is_interface()) {</span>
1176       assert(ft == _type, &quot;&quot;); // Uplift to interface
<span class="line-modified">1177     } else if (!t-&gt;empty() &amp;&amp; ttkp != NULL &amp;&amp; ttkp-&gt;is_loaded() &amp;&amp; ttkp-&gt;klass()-&gt;is_interface()) {</span>
1178       assert(ft == _type, &quot;&quot;); // Uplift to interface
1179     } else {
1180       // We also have to handle &#39;evil cases&#39; of interface- vs. class-arrays
1181       Type::get_arrays_base_elements(jt, _type, NULL, &amp;ttip);
1182       if (!t-&gt;empty() &amp;&amp; ttip != NULL &amp;&amp; ttip-&gt;is_loaded() &amp;&amp; ttip-&gt;klass()-&gt;is_interface()) {
1183           assert(ft == _type, &quot;&quot;);   // Uplift to array of interface
1184       } else {
1185         // Otherwise it&#39;s something stupid like non-overlapping int ranges
1186         // found on dying counted loops.
1187         assert(ft == Type::TOP, &quot;&quot;); // Canonical empty value
1188       }
1189     }
1190   }
1191 
1192   else {
1193 
1194     // If we have an interface-typed Phi and we narrow to a class type, the join
1195     // should report back the class.  However, if we have a J/L/Object
1196     // class-typed Phi and an interface flows in, it&#39;s possible that the meet &amp;
1197     // join report an interface back out.  This isn&#39;t possible but happens
</pre>
<hr />
<pre>
1319 
1320 //------------------------------Identity---------------------------------------
1321 // Check for Region being Identity.
1322 Node* PhiNode::Identity(PhaseGVN* phase) {
1323   // Check for no merging going on
1324   // (There used to be special-case code here when this-&gt;region-&gt;is_Loop.
1325   // It would check for a tributary phi on the backedge that the main phi
1326   // trivially, perhaps with a single cast.  The unique_input method
1327   // does all this and more, by reducing such tributaries to &#39;this&#39;.)
1328   Node* uin = unique_input(phase, false);
1329   if (uin != NULL) {
1330     return uin;
1331   }
1332 
1333   int true_path = is_diamond_phi();
1334   if (true_path != 0) {
1335     Node* id = is_cmove_id(phase, true_path);
1336     if (id != NULL)  return id;
1337   }
1338 
<span class="line-added">1339   if (phase-&gt;is_IterGVN()) {</span>
<span class="line-added">1340     Node* m = try_clean_mem_phi(phase);</span>
<span class="line-added">1341     if (m != NULL) {</span>
<span class="line-added">1342       return m;</span>
<span class="line-added">1343     }</span>
<span class="line-added">1344   }</span>
<span class="line-added">1345 </span>
<span class="line-added">1346 </span>
1347   // Looking for phis with identical inputs.  If we find one that has
1348   // type TypePtr::BOTTOM, replace the current phi with the bottom phi.
1349   if (phase-&gt;is_IterGVN() &amp;&amp; type() == Type::MEMORY &amp;&amp; adr_type() !=
1350       TypePtr::BOTTOM &amp;&amp; !adr_type()-&gt;is_known_instance()) {
1351     uint phi_len = req();
1352     Node* phi_reg = region();
1353     for (DUIterator_Fast imax, i = phi_reg-&gt;fast_outs(imax); i &lt; imax; i++) {
1354       Node* u = phi_reg-&gt;fast_out(i);
1355       if (u-&gt;is_Phi() &amp;&amp; u-&gt;as_Phi()-&gt;type() == Type::MEMORY &amp;&amp;
1356           u-&gt;adr_type() == TypePtr::BOTTOM &amp;&amp; u-&gt;in(0) == phi_reg &amp;&amp;
1357           u-&gt;req() == phi_len) {
1358         for (uint j = 1; j &lt; phi_len; j++) {
1359           if (in(j) != u-&gt;in(j)) {
1360             u = NULL;
1361             break;
1362           }
1363         }
1364         if (u != NULL) {
1365           return u;
1366         }
</pre>
<hr />
<pre>
1873   }
1874   return delay;
1875 }
1876 
1877 //------------------------------Ideal------------------------------------------
1878 // Return a node which is more &quot;ideal&quot; than the current node.  Must preserve
1879 // the CFG, but we can still strip out dead paths.
1880 Node *PhiNode::Ideal(PhaseGVN *phase, bool can_reshape) {
1881   // The next should never happen after 6297035 fix.
1882   if( is_copy() )               // Already degraded to a Copy ?
1883     return NULL;                // No change
1884 
1885   Node *r = in(0);              // RegionNode
1886   assert(r-&gt;in(0) == NULL || !r-&gt;in(0)-&gt;is_Root(), &quot;not a specially hidden merge&quot;);
1887 
1888   // Note: During parsing, phis are often transformed before their regions.
1889   // This means we have to use type_or_null to defend against untyped regions.
1890   if( phase-&gt;type_or_null(r) == Type::TOP ) // Dead code?
1891     return NULL;                // No change
1892 
<span class="line-added">1893   // If all inputs are inline types of the same type, push the inline type node down</span>
<span class="line-added">1894   // through the phi because inline type nodes should be merged through their input values.</span>
<span class="line-added">1895   if (req() &gt; 2 &amp;&amp; in(1) != NULL &amp;&amp; in(1)-&gt;is_InlineTypeBase() &amp;&amp; (can_reshape || in(1)-&gt;is_InlineType())) {</span>
<span class="line-added">1896     int opcode = in(1)-&gt;Opcode();</span>
<span class="line-added">1897     uint i = 2;</span>
<span class="line-added">1898     // Check if inputs are values of the same type</span>
<span class="line-added">1899     for (; i &lt; req() &amp;&amp; in(i) &amp;&amp; in(i)-&gt;is_InlineTypeBase() &amp;&amp; in(i)-&gt;cmp(*in(1)); i++) {</span>
<span class="line-added">1900       assert(in(i)-&gt;Opcode() == opcode, &quot;mixing pointers and values?&quot;);</span>
<span class="line-added">1901     }</span>
<span class="line-added">1902     if (i == req()) {</span>
<span class="line-added">1903       InlineTypeBaseNode* vt = in(1)-&gt;as_InlineTypeBase()-&gt;clone_with_phis(phase, in(0));</span>
<span class="line-added">1904       for (uint i = 2; i &lt; req(); ++i) {</span>
<span class="line-added">1905         vt-&gt;merge_with(phase, in(i)-&gt;as_InlineTypeBase(), i, i == (req()-1));</span>
<span class="line-added">1906       }</span>
<span class="line-added">1907       return vt;</span>
<span class="line-added">1908     }</span>
<span class="line-added">1909   }</span>
<span class="line-added">1910 </span>
1911   Node *top = phase-&gt;C-&gt;top();
1912   bool new_phi = (outcnt() == 0); // transforming new Phi
1913   // No change for igvn if new phi is not hooked
1914   if (new_phi &amp;&amp; can_reshape)
1915     return NULL;
1916 
1917   // The are 2 situations when only one valid phi&#39;s input is left
1918   // (in addition to Region input).
1919   // One: region is not loop - replace phi with this input.
1920   // Two: region is loop - replace phi with top since this data path is dead
1921   //                       and we need to break the dead data loop.
1922   Node* progress = NULL;        // Record if any progress made
1923   for( uint j = 1; j &lt; req(); ++j ){ // For all paths in
1924     // Check unreachable control paths
1925     Node* rc = r-&gt;in(j);
1926     Node* n = in(j);            // Get the input
1927     if (rc == NULL || phase-&gt;type(rc) == Type::TOP) {
1928       if (n != top) {           // Not already top?
1929         PhaseIterGVN *igvn = phase-&gt;is_IterGVN();
1930         if (can_reshape &amp;&amp; igvn != NULL) {
</pre>
<hr />
<pre>
2189           for (uint i = 1; i &lt; req(); i++) {
2190             offset-&gt;init_req(i, in(i)-&gt;in(AddPNode::Offset));
2191           }
2192           phase-&gt;is_IterGVN()-&gt;register_new_node_with_optimizer(offset);
2193         }
2194         return new AddPNode(base, address, offset);
2195       }
2196     }
2197   }
2198 
2199   // Split phis through memory merges, so that the memory merges will go away.
2200   // Piggy-back this transformation on the search for a unique input....
2201   // It will be as if the merged memory is the unique value of the phi.
2202   // (Do not attempt this optimization unless parsing is complete.
2203   // It would make the parser&#39;s memory-merge logic sick.)
2204   // (MergeMemNode is not dead_loop_safe - need to check for dead loop.)
2205   if (progress == NULL &amp;&amp; can_reshape &amp;&amp; type() == Type::MEMORY) {
2206     // see if this phi should be sliced
2207     uint merge_width = 0;
2208     bool saw_self = false;
<span class="line-added">2209     // TODO revisit this with JDK-8247216</span>
<span class="line-added">2210     bool mergemem_only = true;</span>
2211     for( uint i=1; i&lt;req(); ++i ) {// For all paths in
2212       Node *ii = in(i);
2213       // TOP inputs should not be counted as safe inputs because if the
2214       // Phi references itself through all other inputs then splitting the
2215       // Phi through memory merges would create dead loop at later stage.
2216       if (ii == top) {
2217         return NULL; // Delay optimization until graph is cleaned.
2218       }
2219       if (ii-&gt;is_MergeMem()) {
2220         MergeMemNode* n = ii-&gt;as_MergeMem();
2221         merge_width = MAX2(merge_width, n-&gt;req());
2222         saw_self = saw_self || phase-&gt;eqv(n-&gt;base_memory(), this);
<span class="line-added">2223       } else {</span>
<span class="line-added">2224         mergemem_only = false;</span>
2225       }
2226     }
2227 
2228     // This restriction is temporarily necessary to ensure termination:
<span class="line-modified">2229     if (!mergemem_only &amp;&amp; !saw_self &amp;&amp; adr_type() == TypePtr::BOTTOM)  merge_width = 0;</span>
2230 
2231     if (merge_width &gt; Compile::AliasIdxRaw) {
2232       // found at least one non-empty MergeMem
2233       const TypePtr* at = adr_type();
2234       if (at != TypePtr::BOTTOM) {
2235         // Patch the existing phi to select an input from the merge:
2236         // Phi:AT1(...MergeMem(m0, m1, m2)...) into
2237         //     Phi:AT1(...m1...)
2238         int alias_idx = phase-&gt;C-&gt;get_alias_index(at);
2239         for (uint i=1; i&lt;req(); ++i) {
2240           Node *ii = in(i);
2241           if (ii-&gt;is_MergeMem()) {
2242             MergeMemNode* n = ii-&gt;as_MergeMem();
2243             // compress paths and change unreachable cycles to TOP
2244             // If not, we can update the input infinitely along a MergeMem cycle
2245             // Equivalent code is in MemNode::Ideal_common
2246             Node *m  = phase-&gt;transform(n);
2247             if (outcnt() == 0) {  // Above transform() may kill us!
2248               return top;
2249             }
</pre>
<hr />
<pre>
2638   return in(0)-&gt;in(0);
2639 }
2640 
2641 
2642 #ifndef PRODUCT
2643 void CatchProjNode::dump_spec(outputStream *st) const {
2644   ProjNode::dump_spec(st);
2645   st-&gt;print(&quot;@bci %d &quot;,_handler_bci);
2646 }
2647 #endif
2648 
2649 //=============================================================================
2650 //------------------------------Identity---------------------------------------
2651 // Check for CreateEx being Identity.
2652 Node* CreateExNode::Identity(PhaseGVN* phase) {
2653   if( phase-&gt;type(in(1)) == Type::TOP ) return in(1);
2654   if( phase-&gt;type(in(0)) == Type::TOP ) return in(0);
2655   // We only come from CatchProj, unless the CatchProj goes away.
2656   // If the CatchProj is optimized away, then we just carry the
2657   // exception oop through.
<span class="line-added">2658 </span>
<span class="line-added">2659   // CheckCastPPNode::Ideal() for inline types reuses the exception</span>
<span class="line-added">2660   // paths of a call to perform an allocation: we can see a Phi here.</span>
<span class="line-added">2661   if (in(1)-&gt;is_Phi()) {</span>
<span class="line-added">2662     return this;</span>
<span class="line-added">2663   }</span>
2664   CallNode *call = in(1)-&gt;in(0)-&gt;as_Call();
2665 
2666   return ( in(0)-&gt;is_CatchProj() &amp;&amp; in(0)-&gt;in(0)-&gt;in(1) == in(1) )
2667     ? this
2668     : call-&gt;in(TypeFunc::Parms);
2669 }
2670 
2671 //=============================================================================
2672 //------------------------------Value------------------------------------------
2673 // Check for being unreachable.
2674 const Type* NeverBranchNode::Value(PhaseGVN* phase) const {
2675   if (!in(0) || in(0)-&gt;is_top()) return Type::TOP;
2676   return bottom_type();
2677 }
2678 
2679 //------------------------------Ideal------------------------------------------
2680 // Check for no longer being part of a loop
2681 Node *NeverBranchNode::Ideal(PhaseGVN *phase, bool can_reshape) {
2682   if (can_reshape &amp;&amp; !in(0)-&gt;is_Loop()) {
2683     // Dead code elimination can sometimes delete this projection so
</pre>
</td>
</tr>
</table>
<center><a href="c2compiler.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="compile.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>