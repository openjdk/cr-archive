<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff src/hotspot/share/opto/macro.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="graphKit.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="memnode.cpp.cdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/macro.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 1,7 ***</span>
  /*
<span class="line-modified">!  * Copyright (c) 2005, 2019, Oracle and/or its affiliates. All rights reserved.</span>
   * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   *
   * This code is free software; you can redistribute it and/or modify it
   * under the terms of the GNU General Public License version 2 only, as
   * published by the Free Software Foundation.
<span class="line-new-header">--- 1,7 ---</span>
  /*
<span class="line-modified">!  * Copyright (c) 2005, 2020, Oracle and/or its affiliates. All rights reserved.</span>
   * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   *
   * This code is free software; you can redistribute it and/or modify it
   * under the terms of the GNU General Public License version 2 only, as
   * published by the Free Software Foundation.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 21,10 ***</span>
<span class="line-new-header">--- 21,11 ---</span>
   * questions.
   *
   */
  
  #include &quot;precompiled.hpp&quot;
<span class="line-added">+ #include &quot;ci/ciFlatArrayKlass.hpp&quot;</span>
  #include &quot;compiler/compileLog.hpp&quot;
  #include &quot;gc/shared/collectedHeap.inline.hpp&quot;
  #include &quot;libadt/vectset.hpp&quot;
  #include &quot;memory/universe.hpp&quot;
  #include &quot;opto/addnode.hpp&quot;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 33,10 ***</span>
<span class="line-new-header">--- 34,11 ---</span>
  #include &quot;opto/castnode.hpp&quot;
  #include &quot;opto/cfgnode.hpp&quot;
  #include &quot;opto/compile.hpp&quot;
  #include &quot;opto/convertnode.hpp&quot;
  #include &quot;opto/graphKit.hpp&quot;
<span class="line-added">+ #include &quot;opto/inlinetypenode.hpp&quot;</span>
  #include &quot;opto/intrinsicnode.hpp&quot;
  #include &quot;opto/locknode.hpp&quot;
  #include &quot;opto/loopnode.hpp&quot;
  #include &quot;opto/macro.hpp&quot;
  #include &quot;opto/memnode.hpp&quot;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 80,60 ***</span>
      }
    }
    return nreplacements;
  }
  
<span class="line-removed">- void PhaseMacroExpand::migrate_outs(Node *old, Node *target) {</span>
<span class="line-removed">-   assert(old != NULL, &quot;sanity&quot;);</span>
<span class="line-removed">-   for (DUIterator_Fast imax, i = old-&gt;fast_outs(imax); i &lt; imax; i++) {</span>
<span class="line-removed">-     Node* use = old-&gt;fast_out(i);</span>
<span class="line-removed">-     _igvn.rehash_node_delayed(use);</span>
<span class="line-removed">-     imax -= replace_input(use, old, target);</span>
<span class="line-removed">-     // back up iterator</span>
<span class="line-removed">-     --i;</span>
<span class="line-removed">-   }</span>
<span class="line-removed">-   assert(old-&gt;outcnt() == 0, &quot;all uses must be deleted&quot;);</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
<span class="line-removed">- void PhaseMacroExpand::copy_call_debug_info(CallNode *oldcall, CallNode * newcall) {</span>
<span class="line-removed">-   // Copy debug information and adjust JVMState information</span>
<span class="line-removed">-   uint old_dbg_start = oldcall-&gt;tf()-&gt;domain()-&gt;cnt();</span>
<span class="line-removed">-   uint new_dbg_start = newcall-&gt;tf()-&gt;domain()-&gt;cnt();</span>
<span class="line-removed">-   int jvms_adj  = new_dbg_start - old_dbg_start;</span>
<span class="line-removed">-   assert (new_dbg_start == newcall-&gt;req(), &quot;argument count mismatch&quot;);</span>
<span class="line-removed">- </span>
<span class="line-removed">-   // SafePointScalarObject node could be referenced several times in debug info.</span>
<span class="line-removed">-   // Use Dict to record cloned nodes.</span>
<span class="line-removed">-   Dict* sosn_map = new Dict(cmpkey,hashkey);</span>
<span class="line-removed">-   for (uint i = old_dbg_start; i &lt; oldcall-&gt;req(); i++) {</span>
<span class="line-removed">-     Node* old_in = oldcall-&gt;in(i);</span>
<span class="line-removed">-     // Clone old SafePointScalarObjectNodes, adjusting their field contents.</span>
<span class="line-removed">-     if (old_in != NULL &amp;&amp; old_in-&gt;is_SafePointScalarObject()) {</span>
<span class="line-removed">-       SafePointScalarObjectNode* old_sosn = old_in-&gt;as_SafePointScalarObject();</span>
<span class="line-removed">-       uint old_unique = C-&gt;unique();</span>
<span class="line-removed">-       Node* new_in = old_sosn-&gt;clone(sosn_map);</span>
<span class="line-removed">-       if (old_unique != C-&gt;unique()) { // New node?</span>
<span class="line-removed">-         new_in-&gt;set_req(0, C-&gt;root()); // reset control edge</span>
<span class="line-removed">-         new_in = transform_later(new_in); // Register new node.</span>
<span class="line-removed">-       }</span>
<span class="line-removed">-       old_in = new_in;</span>
<span class="line-removed">-     }</span>
<span class="line-removed">-     newcall-&gt;add_req(old_in);</span>
<span class="line-removed">-   }</span>
<span class="line-removed">- </span>
<span class="line-removed">-   // JVMS may be shared so clone it before we modify it</span>
<span class="line-removed">-   newcall-&gt;set_jvms(oldcall-&gt;jvms() != NULL ? oldcall-&gt;jvms()-&gt;clone_deep(C) : NULL);</span>
<span class="line-removed">-   for (JVMState *jvms = newcall-&gt;jvms(); jvms != NULL; jvms = jvms-&gt;caller()) {</span>
<span class="line-removed">-     jvms-&gt;set_map(newcall);</span>
<span class="line-removed">-     jvms-&gt;set_locoff(jvms-&gt;locoff()+jvms_adj);</span>
<span class="line-removed">-     jvms-&gt;set_stkoff(jvms-&gt;stkoff()+jvms_adj);</span>
<span class="line-removed">-     jvms-&gt;set_monoff(jvms-&gt;monoff()+jvms_adj);</span>
<span class="line-removed">-     jvms-&gt;set_scloff(jvms-&gt;scloff()+jvms_adj);</span>
<span class="line-removed">-     jvms-&gt;set_endoff(jvms-&gt;endoff()+jvms_adj);</span>
<span class="line-removed">-   }</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
  Node* PhaseMacroExpand::opt_bits_test(Node* ctrl, Node* region, int edge, Node* word, int mask, int bits, bool return_fast_path) {
    Node* cmp;
    if (mask != 0) {
      Node* and_node = transform_later(new AndXNode(word, MakeConX(mask)));
      cmp = transform_later(new CmpXNode(and_node, MakeConX(bits)));
<span class="line-new-header">--- 82,10 ---</span>
</pre>
<hr />
<pre>
<span class="line-old-header">*** 182,11 ***</span>
    // Slow path call has no side-effects, uses few values
    copy_predefined_input_for_runtime_call(slow_path, oldcall, call );
    if (parm0 != NULL)  call-&gt;init_req(TypeFunc::Parms+0, parm0);
    if (parm1 != NULL)  call-&gt;init_req(TypeFunc::Parms+1, parm1);
    if (parm2 != NULL)  call-&gt;init_req(TypeFunc::Parms+2, parm2);
<span class="line-modified">!   copy_call_debug_info(oldcall, call);</span>
    call-&gt;set_cnt(PROB_UNLIKELY_MAG(4));  // Same effect as RC_UNCOMMON.
    _igvn.replace_node(oldcall, call);
    transform_later(call);
  
    return call;
<span class="line-new-header">--- 134,11 ---</span>
    // Slow path call has no side-effects, uses few values
    copy_predefined_input_for_runtime_call(slow_path, oldcall, call );
    if (parm0 != NULL)  call-&gt;init_req(TypeFunc::Parms+0, parm0);
    if (parm1 != NULL)  call-&gt;init_req(TypeFunc::Parms+1, parm1);
    if (parm2 != NULL)  call-&gt;init_req(TypeFunc::Parms+2, parm2);
<span class="line-modified">!   call-&gt;copy_call_debug_info(&amp;_igvn, oldcall);</span>
    call-&gt;set_cnt(PROB_UNLIKELY_MAG(4));  // Same effect as RC_UNCOMMON.
    _igvn.replace_node(oldcall, call);
    transform_later(call);
  
    return call;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 290,11 ***</span>
      } else if (mem-&gt;is_Store()) {
        const TypePtr* atype = mem-&gt;as_Store()-&gt;adr_type();
        int adr_idx = phase-&gt;C-&gt;get_alias_index(atype);
        if (adr_idx == alias_idx) {
          assert(atype-&gt;isa_oopptr(), &quot;address type must be oopptr&quot;);
<span class="line-modified">!         int adr_offset = atype-&gt;offset();</span>
          uint adr_iid = atype-&gt;is_oopptr()-&gt;instance_id();
          // Array elements references have the same alias_idx
          // but different offset and different instance_id.
          if (adr_offset == offset &amp;&amp; adr_iid == alloc-&gt;_idx)
            return mem;
<span class="line-new-header">--- 242,11 ---</span>
      } else if (mem-&gt;is_Store()) {
        const TypePtr* atype = mem-&gt;as_Store()-&gt;adr_type();
        int adr_idx = phase-&gt;C-&gt;get_alias_index(atype);
        if (adr_idx == alias_idx) {
          assert(atype-&gt;isa_oopptr(), &quot;address type must be oopptr&quot;);
<span class="line-modified">!         int adr_offset = atype-&gt;flattened_offset();</span>
          uint adr_iid = atype-&gt;is_oopptr()-&gt;instance_id();
          // Array elements references have the same alias_idx
          // but different offset and different instance_id.
          if (adr_offset == offset &amp;&amp; adr_iid == alloc-&gt;_idx)
            return mem;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 333,11 ***</span>
          DEBUG_ONLY(mem-&gt;dump();)
          assert(false, &quot;Object is not scalar replaceable if a LoadStore node accesses its field&quot;);
          return NULL;
        }
        mem = mem-&gt;in(MemNode::Memory);
<span class="line-modified">!    } else if (mem-&gt;Opcode() == Op_StrInflatedCopy) {</span>
        Node* adr = mem-&gt;in(3); // Destination array
        const TypePtr* atype = adr-&gt;bottom_type()-&gt;is_ptr();
        int adr_idx = phase-&gt;C-&gt;get_alias_index(atype);
        if (adr_idx == alias_idx) {
          DEBUG_ONLY(mem-&gt;dump();)
<span class="line-new-header">--- 285,11 ---</span>
          DEBUG_ONLY(mem-&gt;dump();)
          assert(false, &quot;Object is not scalar replaceable if a LoadStore node accesses its field&quot;);
          return NULL;
        }
        mem = mem-&gt;in(MemNode::Memory);
<span class="line-modified">!     } else if (mem-&gt;Opcode() == Op_StrInflatedCopy) {</span>
        Node* adr = mem-&gt;in(3); // Destination array
        const TypePtr* atype = adr-&gt;bottom_type()-&gt;is_ptr();
        int adr_idx = phase-&gt;C-&gt;get_alias_index(atype);
        if (adr_idx == alias_idx) {
          DEBUG_ONLY(mem-&gt;dump();)
</pre>
<hr />
<pre>
<span class="line-old-header">*** 378,45 ***</span>
        Node* dest_pos = ac-&gt;in(ArrayCopyNode::DestPos);
        const TypeInt* src_pos_t = _igvn.type(src_pos)-&gt;is_int();
        const TypeInt* dest_pos_t = _igvn.type(dest_pos)-&gt;is_int();
  
        Node* adr = NULL;
<span class="line-modified">!       const TypePtr* adr_type = NULL;</span>
        if (src_pos_t-&gt;is_con() &amp;&amp; dest_pos_t-&gt;is_con()) {
          intptr_t off = ((src_pos_t-&gt;get_con() - dest_pos_t-&gt;get_con()) &lt;&lt; shift) + offset;
<span class="line-modified">!         Node* base = ac-&gt;in(ArrayCopyNode::Src);</span>
<span class="line-modified">!         adr = _igvn.transform(new AddPNode(base, base, MakeConX(off)));</span>
          assert(adr_type == _igvn.type(base)-&gt;is_aryptr()-&gt;add_field_offset_and_offset(off), &quot;incorrect address type&quot;);
          if (ac-&gt;in(ArrayCopyNode::Src) == ac-&gt;in(ArrayCopyNode::Dest)) {
            // Don&#39;t emit a new load from src if src == dst but try to get the value from memory instead
            return value_from_mem(ac-&gt;in(TypeFunc::Memory), ctl, ft, ftype, adr_type-&gt;isa_oopptr(), alloc);
          }
        } else {
          Node* diff = _igvn.transform(new SubINode(ac-&gt;in(ArrayCopyNode::SrcPos), ac-&gt;in(ArrayCopyNode::DestPos)));
  #ifdef _LP64
          diff = _igvn.transform(new ConvI2LNode(diff));
  #endif
          diff = _igvn.transform(new LShiftXNode(diff, intcon(shift)));
  
          Node* off = _igvn.transform(new AddXNode(MakeConX(offset), diff));
<span class="line-modified">!         Node* base = ac-&gt;in(ArrayCopyNode::Src);</span>
<span class="line-modified">!         adr = _igvn.transform(new AddPNode(base, base, off));</span>
<span class="line-modified">!         adr_type = _igvn.type(base)-&gt;is_ptr()-&gt;add_offset(Type::OffsetBot);</span>
<span class="line-modified">!         if (ac-&gt;in(ArrayCopyNode::Src) == ac-&gt;in(ArrayCopyNode::Dest)) {</span>
<span class="line-modified">!           // Non constant offset in the array: we can&#39;t statically</span>
<span class="line-removed">-           // determine the value</span>
<span class="line-removed">-           return NULL;</span>
          adr = _igvn.transform(new CastPPNode(adr, adr_type));
        }
        MergeMemNode* mergemen = MergeMemNode::make(mem);
        BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
        res = ArrayCopyNode::load(bs, &amp;_igvn, ctl, mergemen, adr, adr_type, type, bt);
      }
    }
    if (res != NULL) {
      if (ftype-&gt;isa_narrowoop()) {
        // PhaseMacroExpand::scalar_replacement adds DecodeN nodes
        res = _igvn.transform(new EncodePNode(res, ftype));
      }
      return res;
    }
    return NULL;
<span class="line-new-header">--- 330,51 ---</span>
        Node* dest_pos = ac-&gt;in(ArrayCopyNode::DestPos);
        const TypeInt* src_pos_t = _igvn.type(src_pos)-&gt;is_int();
        const TypeInt* dest_pos_t = _igvn.type(dest_pos)-&gt;is_int();
  
        Node* adr = NULL;
<span class="line-modified">!       Node* base = ac-&gt;in(ArrayCopyNode::Src);</span>
<span class="line-added">+       const TypePtr* adr_type = _igvn.type(base)-&gt;is_ptr();</span>
<span class="line-added">+       assert(adr_type-&gt;isa_aryptr(), &quot;only arrays here&quot;);</span>
        if (src_pos_t-&gt;is_con() &amp;&amp; dest_pos_t-&gt;is_con()) {
          intptr_t off = ((src_pos_t-&gt;get_con() - dest_pos_t-&gt;get_con()) &lt;&lt; shift) + offset;
<span class="line-modified">!         adr = _igvn.transform(new AddPNode(base, base, MakeConX(off)));</span>
<span class="line-modified">!         adr_type = _igvn.type(adr)-&gt;is_ptr();</span>
          assert(adr_type == _igvn.type(base)-&gt;is_aryptr()-&gt;add_field_offset_and_offset(off), &quot;incorrect address type&quot;);
          if (ac-&gt;in(ArrayCopyNode::Src) == ac-&gt;in(ArrayCopyNode::Dest)) {
            // Don&#39;t emit a new load from src if src == dst but try to get the value from memory instead
            return value_from_mem(ac-&gt;in(TypeFunc::Memory), ctl, ft, ftype, adr_type-&gt;isa_oopptr(), alloc);
          }
        } else {
<span class="line-added">+         if (ac-&gt;in(ArrayCopyNode::Src) == ac-&gt;in(ArrayCopyNode::Dest)) {</span>
<span class="line-added">+           // Non constant offset in the array: we can&#39;t statically</span>
<span class="line-added">+           // determine the value</span>
<span class="line-added">+           return NULL;</span>
<span class="line-added">+         }</span>
          Node* diff = _igvn.transform(new SubINode(ac-&gt;in(ArrayCopyNode::SrcPos), ac-&gt;in(ArrayCopyNode::DestPos)));
  #ifdef _LP64
          diff = _igvn.transform(new ConvI2LNode(diff));
  #endif
          diff = _igvn.transform(new LShiftXNode(diff, intcon(shift)));
  
          Node* off = _igvn.transform(new AddXNode(MakeConX(offset), diff));
<span class="line-modified">!         adr = _igvn.transform(new AddPNode(base, base, off));</span>
<span class="line-modified">!         // In the case of a flattened inline type array, each field has its</span>
<span class="line-modified">!         // own slice so we need to extract the field being accessed from</span>
<span class="line-modified">!         // the address computation</span>
<span class="line-modified">!         adr_type = adr_type-&gt;is_aryptr()-&gt;add_field_offset_and_offset(offset)-&gt;add_offset(Type::OffsetBot);</span>
          adr = _igvn.transform(new CastPPNode(adr, adr_type));
        }
        MergeMemNode* mergemen = MergeMemNode::make(mem);
        BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
        res = ArrayCopyNode::load(bs, &amp;_igvn, ctl, mergemen, adr, adr_type, type, bt);
      }
    }
    if (res != NULL) {
      if (ftype-&gt;isa_narrowoop()) {
        // PhaseMacroExpand::scalar_replacement adds DecodeN nodes
<span class="line-added">+       assert(res-&gt;isa_DecodeN(), &quot;should be narrow oop&quot;);</span>
        res = _igvn.transform(new EncodePNode(res, ftype));
      }
      return res;
    }
    return NULL;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 428,11 ***</span>
  // Note: this function is recursive, its depth is limited by the &quot;level&quot; argument
  // Returns the computed Phi, or NULL if it cannot compute it.
  Node *PhaseMacroExpand::value_from_mem_phi(Node *mem, BasicType ft, const Type *phi_type, const TypeOopPtr *adr_t, AllocateNode *alloc, Node_Stack *value_phis, int level) {
    assert(mem-&gt;is_Phi(), &quot;sanity&quot;);
    int alias_idx = C-&gt;get_alias_index(adr_t);
<span class="line-modified">!   int offset = adr_t-&gt;offset();</span>
    int instance_id = adr_t-&gt;instance_id();
  
    // Check if an appropriate value phi already exists.
    Node* region = mem-&gt;in(0);
    for (DUIterator_Fast kmax, k = region-&gt;fast_outs(kmax); k &lt; kmax; k++) {
<span class="line-new-header">--- 386,11 ---</span>
  // Note: this function is recursive, its depth is limited by the &quot;level&quot; argument
  // Returns the computed Phi, or NULL if it cannot compute it.
  Node *PhaseMacroExpand::value_from_mem_phi(Node *mem, BasicType ft, const Type *phi_type, const TypeOopPtr *adr_t, AllocateNode *alloc, Node_Stack *value_phis, int level) {
    assert(mem-&gt;is_Phi(), &quot;sanity&quot;);
    int alias_idx = C-&gt;get_alias_index(adr_t);
<span class="line-modified">!   int offset = adr_t-&gt;flattened_offset();</span>
    int instance_id = adr_t-&gt;instance_id();
  
    // Check if an appropriate value phi already exists.
    Node* region = mem-&gt;in(0);
    for (DUIterator_Fast kmax, k = region-&gt;fast_outs(kmax); k &lt; kmax; k++) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 467,11 ***</span>
        values.at_put(j, in);
      } else  {
        Node *val = scan_mem_chain(in, alias_idx, offset, start_mem, alloc, &amp;_igvn);
        if (val == start_mem || val == alloc_mem) {
          // hit a sentinel, return appropriate 0 value
<span class="line-modified">!         values.at_put(j, _igvn.zerocon(ft));</span>
          continue;
        }
        if (val-&gt;is_Initialize()) {
          val = val-&gt;as_Initialize()-&gt;find_captured_store(offset, type2aelembytes(ft), &amp;_igvn);
        }
<span class="line-new-header">--- 425,17 ---</span>
        values.at_put(j, in);
      } else  {
        Node *val = scan_mem_chain(in, alias_idx, offset, start_mem, alloc, &amp;_igvn);
        if (val == start_mem || val == alloc_mem) {
          // hit a sentinel, return appropriate 0 value
<span class="line-modified">!         Node* default_value = alloc-&gt;in(AllocateNode::DefaultValue);</span>
<span class="line-added">+         if (default_value != NULL) {</span>
<span class="line-added">+           values.at_put(j, default_value);</span>
<span class="line-added">+         } else {</span>
<span class="line-added">+           assert(alloc-&gt;in(AllocateNode::RawDefaultValue) == NULL, &quot;default value may not be null&quot;);</span>
<span class="line-added">+           values.at_put(j, _igvn.zerocon(ft));</span>
<span class="line-added">+         }</span>
          continue;
        }
        if (val-&gt;is_Initialize()) {
          val = val-&gt;as_Initialize()-&gt;find_captured_store(offset, type2aelembytes(ft), &amp;_igvn);
        }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 484,11 ***</span>
          Node* n = val-&gt;in(MemNode::ValueIn);
          BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
          n = bs-&gt;step_over_gc_barrier(n);
          values.at_put(j, n);
        } else if(val-&gt;is_Proj() &amp;&amp; val-&gt;in(0) == alloc) {
<span class="line-modified">!         values.at_put(j, _igvn.zerocon(ft));</span>
        } else if (val-&gt;is_Phi()) {
          val = value_from_mem_phi(val, ft, phi_type, adr_t, alloc, value_phis, level-1);
          if (val == NULL) {
            return NULL;
          }
<span class="line-new-header">--- 448,17 ---</span>
          Node* n = val-&gt;in(MemNode::ValueIn);
          BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
          n = bs-&gt;step_over_gc_barrier(n);
          values.at_put(j, n);
        } else if(val-&gt;is_Proj() &amp;&amp; val-&gt;in(0) == alloc) {
<span class="line-modified">!         Node* default_value = alloc-&gt;in(AllocateNode::DefaultValue);</span>
<span class="line-added">+         if (default_value != NULL) {</span>
<span class="line-added">+           values.at_put(j, default_value);</span>
<span class="line-added">+         } else {</span>
<span class="line-added">+           assert(alloc-&gt;in(AllocateNode::RawDefaultValue) == NULL, &quot;default value may not be null&quot;);</span>
<span class="line-added">+           values.at_put(j, _igvn.zerocon(ft));</span>
<span class="line-added">+         }</span>
        } else if (val-&gt;is_Phi()) {
          val = value_from_mem_phi(val, ft, phi_type, adr_t, alloc, value_phis, level-1);
          if (val == NULL) {
            return NULL;
          }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 530,13 ***</span>
    assert(adr_t-&gt;is_known_instance_field(), &quot;instance required&quot;);
    int instance_id = adr_t-&gt;instance_id();
    assert((uint)instance_id == alloc-&gt;_idx, &quot;wrong allocation&quot;);
  
    int alias_idx = C-&gt;get_alias_index(adr_t);
<span class="line-modified">!   int offset = adr_t-&gt;offset();</span>
    Node *start_mem = C-&gt;start()-&gt;proj_out_or_null(TypeFunc::Memory);
<span class="line-removed">-   Node *alloc_ctrl = alloc-&gt;in(TypeFunc::Control);</span>
    Node *alloc_mem = alloc-&gt;in(TypeFunc::Memory);
    VectorSet visited;
  
    bool done = sfpt_mem == alloc_mem;
    Node *mem = sfpt_mem;
<span class="line-new-header">--- 500,12 ---</span>
    assert(adr_t-&gt;is_known_instance_field(), &quot;instance required&quot;);
    int instance_id = adr_t-&gt;instance_id();
    assert((uint)instance_id == alloc-&gt;_idx, &quot;wrong allocation&quot;);
  
    int alias_idx = C-&gt;get_alias_index(adr_t);
<span class="line-modified">!   int offset = adr_t-&gt;flattened_offset();</span>
    Node *start_mem = C-&gt;start()-&gt;proj_out_or_null(TypeFunc::Memory);
    Node *alloc_mem = alloc-&gt;in(TypeFunc::Memory);
    VectorSet visited;
  
    bool done = sfpt_mem == alloc_mem;
    Node *mem = sfpt_mem;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 548,21 ***</span>
      if (mem == start_mem || mem == alloc_mem) {
        done = true;  // hit a sentinel, return appropriate 0 value
      } else if (mem-&gt;is_Initialize()) {
        mem = mem-&gt;as_Initialize()-&gt;find_captured_store(offset, type2aelembytes(ft), &amp;_igvn);
        if (mem == NULL) {
<span class="line-modified">!         done = true; // Something go wrong.</span>
        } else if (mem-&gt;is_Store()) {
          const TypePtr* atype = mem-&gt;as_Store()-&gt;adr_type();
          assert(C-&gt;get_alias_index(atype) == Compile::AliasIdxRaw, &quot;store is correct memory slice&quot;);
          done = true;
        }
      } else if (mem-&gt;is_Store()) {
        const TypeOopPtr* atype = mem-&gt;as_Store()-&gt;adr_type()-&gt;isa_oopptr();
        assert(atype != NULL, &quot;address type must be oopptr&quot;);
        assert(C-&gt;get_alias_index(atype) == alias_idx &amp;&amp;
<span class="line-modified">!              atype-&gt;is_known_instance_field() &amp;&amp; atype-&gt;offset() == offset &amp;&amp;</span>
               atype-&gt;instance_id() == instance_id, &quot;store is correct memory slice&quot;);
        done = true;
      } else if (mem-&gt;is_Phi()) {
        // try to find a phi&#39;s unique input
        Node *unique_input = NULL;
<span class="line-new-header">--- 517,21 ---</span>
      if (mem == start_mem || mem == alloc_mem) {
        done = true;  // hit a sentinel, return appropriate 0 value
      } else if (mem-&gt;is_Initialize()) {
        mem = mem-&gt;as_Initialize()-&gt;find_captured_store(offset, type2aelembytes(ft), &amp;_igvn);
        if (mem == NULL) {
<span class="line-modified">!         done = true; // Something went wrong.</span>
        } else if (mem-&gt;is_Store()) {
          const TypePtr* atype = mem-&gt;as_Store()-&gt;adr_type();
          assert(C-&gt;get_alias_index(atype) == Compile::AliasIdxRaw, &quot;store is correct memory slice&quot;);
          done = true;
        }
      } else if (mem-&gt;is_Store()) {
        const TypeOopPtr* atype = mem-&gt;as_Store()-&gt;adr_type()-&gt;isa_oopptr();
        assert(atype != NULL, &quot;address type must be oopptr&quot;);
        assert(C-&gt;get_alias_index(atype) == alias_idx &amp;&amp;
<span class="line-modified">!              atype-&gt;is_known_instance_field() &amp;&amp; atype-&gt;flattened_offset() == offset &amp;&amp;</span>
               atype-&gt;instance_id() == instance_id, &quot;store is correct memory slice&quot;);
        done = true;
      } else if (mem-&gt;is_Phi()) {
        // try to find a phi&#39;s unique input
        Node *unique_input = NULL;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 590,10 ***</span>
<span class="line-new-header">--- 559,15 ---</span>
      }
    }
    if (mem != NULL) {
      if (mem == start_mem || mem == alloc_mem) {
        // hit a sentinel, return appropriate 0 value
<span class="line-added">+       Node* default_value = alloc-&gt;in(AllocateNode::DefaultValue);</span>
<span class="line-added">+       if (default_value != NULL) {</span>
<span class="line-added">+         return default_value;</span>
<span class="line-added">+       }</span>
<span class="line-added">+       assert(alloc-&gt;in(AllocateNode::RawDefaultValue) == NULL, &quot;default value may not be null&quot;);</span>
        return _igvn.zerocon(ft);
      } else if (mem-&gt;is_Store()) {
        Node* n = mem-&gt;in(MemNode::ValueIn);
        BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
        n = bs-&gt;step_over_gc_barrier(n);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 621,14 ***</span>
          m = sfpt_mem;
        }
        return make_arraycopy_load(mem-&gt;as_ArrayCopy(), offset, ctl, m, ft, ftype, alloc);
      }
    }
<span class="line-modified">!   // Something go wrong.</span>
    return NULL;
  }
  
  // Check the possibility of scalar replacement.
  bool PhaseMacroExpand::can_eliminate_allocation(AllocateNode *alloc, GrowableArray &lt;SafePointNode *&gt;&amp; safepoints) {
    //  Scan the uses of the allocation to check for anything that would
    //  prevent us from eliminating it.
    NOT_PRODUCT( const char* fail_eliminate = NULL; )
<span class="line-new-header">--- 595,51 ---</span>
          m = sfpt_mem;
        }
        return make_arraycopy_load(mem-&gt;as_ArrayCopy(), offset, ctl, m, ft, ftype, alloc);
      }
    }
<span class="line-modified">!   // Something went wrong.</span>
    return NULL;
  }
  
<span class="line-added">+ // Search the last value stored into the inline type&#39;s fields.</span>
<span class="line-added">+ Node* PhaseMacroExpand::inline_type_from_mem(Node* mem, Node* ctl, ciInlineKlass* vk, const TypeAryPtr* adr_type, int offset, AllocateNode* alloc) {</span>
<span class="line-added">+   // Subtract the offset of the first field to account for the missing oop header</span>
<span class="line-added">+   offset -= vk-&gt;first_field_offset();</span>
<span class="line-added">+   // Create a new InlineTypeNode and retrieve the field values from memory</span>
<span class="line-added">+   InlineTypeNode* vt = InlineTypeNode::make_uninitialized(_igvn, vk)-&gt;as_InlineType();</span>
<span class="line-added">+   for (int i = 0; i &lt; vk-&gt;nof_declared_nonstatic_fields(); ++i) {</span>
<span class="line-added">+     ciType* field_type = vt-&gt;field_type(i);</span>
<span class="line-added">+     int field_offset = offset + vt-&gt;field_offset(i);</span>
<span class="line-added">+     // Each inline type field has its own memory slice</span>
<span class="line-added">+     adr_type = adr_type-&gt;with_field_offset(field_offset);</span>
<span class="line-added">+     Node* value = NULL;</span>
<span class="line-added">+     if (vt-&gt;field_is_flattened(i)) {</span>
<span class="line-added">+       value = inline_type_from_mem(mem, ctl, field_type-&gt;as_inline_klass(), adr_type, field_offset, alloc);</span>
<span class="line-added">+     } else {</span>
<span class="line-added">+       const Type* ft = Type::get_const_type(field_type);</span>
<span class="line-added">+       BasicType bt = field_type-&gt;basic_type();</span>
<span class="line-added">+       if (UseCompressedOops &amp;&amp; !is_java_primitive(bt)) {</span>
<span class="line-added">+         ft = ft-&gt;make_narrowoop();</span>
<span class="line-added">+         bt = T_NARROWOOP;</span>
<span class="line-added">+       }</span>
<span class="line-added">+       value = value_from_mem(mem, ctl, bt, ft, adr_type, alloc);</span>
<span class="line-added">+       if (value != NULL &amp;&amp; ft-&gt;isa_narrowoop()) {</span>
<span class="line-added">+         assert(UseCompressedOops, &quot;unexpected narrow oop&quot;);</span>
<span class="line-added">+         value = transform_later(new DecodeNNode(value, value-&gt;get_ptr_type()));</span>
<span class="line-added">+       }</span>
<span class="line-added">+     }</span>
<span class="line-added">+     if (value != NULL) {</span>
<span class="line-added">+       vt-&gt;set_field_value(i, value);</span>
<span class="line-added">+     } else {</span>
<span class="line-added">+       // We might have reached the TrackedInitializationLimit</span>
<span class="line-added">+       return NULL;</span>
<span class="line-added">+     }</span>
<span class="line-added">+   }</span>
<span class="line-added">+   return transform_later(vt);</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
  // Check the possibility of scalar replacement.
  bool PhaseMacroExpand::can_eliminate_allocation(AllocateNode *alloc, GrowableArray &lt;SafePointNode *&gt;&amp; safepoints) {
    //  Scan the uses of the allocation to check for anything that would
    //  prevent us from eliminating it.
    NOT_PRODUCT( const char* fail_eliminate = NULL; )
</pre>
<hr />
<pre>
<span class="line-old-header">*** 677,11 ***</span>
                SHENANDOAHGC_ONLY(&amp;&amp; (!UseShenandoahGC || !ShenandoahBarrierSetC2::is_shenandoah_wb_pre_call(n))) ) {
              DEBUG_ONLY(disq_node = n;)
              if (n-&gt;is_Load() || n-&gt;is_LoadStore()) {
                NOT_PRODUCT(fail_eliminate = &quot;Field load&quot;;)
              } else {
<span class="line-modified">!               NOT_PRODUCT(fail_eliminate = &quot;Not store field referrence&quot;;)</span>
              }
              can_eliminate = false;
            }
          }
        } else if (use-&gt;is_ArrayCopy() &amp;&amp;
<span class="line-new-header">--- 688,11 ---</span>
                SHENANDOAHGC_ONLY(&amp;&amp; (!UseShenandoahGC || !ShenandoahBarrierSetC2::is_shenandoah_wb_pre_call(n))) ) {
              DEBUG_ONLY(disq_node = n;)
              if (n-&gt;is_Load() || n-&gt;is_LoadStore()) {
                NOT_PRODUCT(fail_eliminate = &quot;Field load&quot;;)
              } else {
<span class="line-modified">!               NOT_PRODUCT(fail_eliminate = &quot;Not store field reference&quot;;)</span>
              }
              can_eliminate = false;
            }
          }
        } else if (use-&gt;is_ArrayCopy() &amp;&amp;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 705,10 ***</span>
<span class="line-new-header">--- 716,14 ---</span>
            NOT_PRODUCT(fail_eliminate = &quot;NULL or TOP memory&quot;;)
            can_eliminate = false;
          } else {
            safepoints.append_if_missing(sfpt);
          }
<span class="line-added">+       } else if (use-&gt;is_InlineType() &amp;&amp; use-&gt;isa_InlineType()-&gt;get_oop() == res) {</span>
<span class="line-added">+         // ok to eliminate</span>
<span class="line-added">+       } else if (use-&gt;Opcode() == Op_StoreX &amp;&amp; use-&gt;in(MemNode::Address) == res) {</span>
<span class="line-added">+         // store to mark work</span>
        } else if (use-&gt;Opcode() != Op_CastP2X) { // CastP2X is used by card mark
          if (use-&gt;is_Phi()) {
            if (use-&gt;outcnt() == 1 &amp;&amp; use-&gt;unique_out()-&gt;Opcode() == Op_Return) {
              NOT_PRODUCT(fail_eliminate = &quot;Object is return value&quot;;)
            } else {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 716,16 ***</span>
            }
            DEBUG_ONLY(disq_node = use;)
          } else {
            if (use-&gt;Opcode() == Op_Return) {
              NOT_PRODUCT(fail_eliminate = &quot;Object is return value&quot;;)
<span class="line-modified">!           }else {</span>
              NOT_PRODUCT(fail_eliminate = &quot;Object is referenced by node&quot;;)
            }
            DEBUG_ONLY(disq_node = use;)
          }
          can_eliminate = false;
        }
      }
    }
  
  #ifndef PRODUCT
<span class="line-new-header">--- 731,19 ---</span>
            }
            DEBUG_ONLY(disq_node = use;)
          } else {
            if (use-&gt;Opcode() == Op_Return) {
              NOT_PRODUCT(fail_eliminate = &quot;Object is return value&quot;;)
<span class="line-modified">!           } else {</span>
              NOT_PRODUCT(fail_eliminate = &quot;Object is referenced by node&quot;;)
            }
            DEBUG_ONLY(disq_node = use;)
          }
          can_eliminate = false;
<span class="line-added">+       } else {</span>
<span class="line-added">+         assert(use-&gt;Opcode() == Op_CastP2X, &quot;should be&quot;);</span>
<span class="line-added">+         assert(!use-&gt;has_out_with(Op_OrL), &quot;should have been removed because oop is never null&quot;);</span>
        }
      }
    }
  
  #ifndef PRODUCT
</pre>
<hr />
<pre>
<span class="line-old-header">*** 784,17 ***</span>
<span class="line-new-header">--- 802,26 ---</span>
        // find the array&#39;s elements which will be needed for safepoint debug information
        nfields = alloc-&gt;in(AllocateNode::ALength)-&gt;find_int_con(-1);
        assert(klass-&gt;is_array_klass() &amp;&amp; nfields &gt;= 0, &quot;must be an array klass.&quot;);
        elem_type = klass-&gt;as_array_klass()-&gt;element_type();
        basic_elem_type = elem_type-&gt;basic_type();
<span class="line-added">+       if (elem_type-&gt;is_inlinetype() &amp;&amp; !klass-&gt;is_flat_array_klass()) {</span>
<span class="line-added">+         assert(basic_elem_type == T_INLINE_TYPE, &quot;unexpected element basic type&quot;);</span>
<span class="line-added">+         basic_elem_type = T_OBJECT;</span>
<span class="line-added">+       }</span>
        array_base = arrayOopDesc::base_offset_in_bytes(basic_elem_type);
        element_size = type2aelembytes(basic_elem_type);
<span class="line-added">+       if (klass-&gt;is_flat_array_klass()) {</span>
<span class="line-added">+         // Flattened inline type array</span>
<span class="line-added">+         element_size = klass-&gt;as_flat_array_klass()-&gt;element_byte_size();</span>
<span class="line-added">+       }</span>
      }
    }
    //
    // Process the safepoint uses
    //
<span class="line-added">+   Unique_Node_List value_worklist;</span>
    while (safepoints.length() &gt; 0) {
      SafePointNode* sfpt = safepoints.pop();
      Node* mem = sfpt-&gt;memory();
      Node* ctl = sfpt-&gt;control();
      assert(sfpt-&gt;jvms() != NULL, &quot;missed JVMS&quot;);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 817,10 ***</span>
<span class="line-new-header">--- 844,11 ---</span>
        if (iklass != NULL) {
          field = iklass-&gt;nonstatic_field_at(j);
          offset = field-&gt;offset();
          elem_type = field-&gt;type();
          basic_elem_type = field-&gt;layout_type();
<span class="line-added">+         assert(!field-&gt;is_flattened(), &quot;flattened inline type fields should not have safepoint uses&quot;);</span>
        } else {
          offset = array_base + j * (intptr_t)element_size;
        }
  
        const Type *field_type;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 844,13 ***</span>
          }
        } else {
          field_type = Type::get_const_basic_type(basic_elem_type);
        }
  
<span class="line-modified">!       const TypeOopPtr *field_addr_type = res_type-&gt;add_offset(offset)-&gt;isa_oopptr();</span>
<span class="line-modified">! </span>
<span class="line-modified">!       Node *field_val = value_from_mem(mem, ctl, basic_elem_type, field_type, field_addr_type, alloc);</span>
        if (field_val == NULL) {
          // We weren&#39;t able to find a value for this field,
          // give up on eliminating this allocation.
  
          // Remove any extra entries we added to the safepoint.
<span class="line-new-header">--- 872,19 ---</span>
          }
        } else {
          field_type = Type::get_const_basic_type(basic_elem_type);
        }
  
<span class="line-modified">!       Node* field_val = NULL;</span>
<span class="line-modified">!       const TypeOopPtr* field_addr_type = res_type-&gt;add_offset(offset)-&gt;isa_oopptr();</span>
<span class="line-modified">!       if (klass-&gt;is_flat_array_klass()) {</span>
<span class="line-added">+         ciInlineKlass* vk = elem_type-&gt;as_inline_klass();</span>
<span class="line-added">+         assert(vk-&gt;flatten_array(), &quot;must be flattened&quot;);</span>
<span class="line-added">+         field_val = inline_type_from_mem(mem, ctl, vk, field_addr_type-&gt;isa_aryptr(), 0, alloc);</span>
<span class="line-added">+       } else {</span>
<span class="line-added">+         field_val = value_from_mem(mem, ctl, basic_elem_type, field_type, field_addr_type, alloc);</span>
<span class="line-added">+       }</span>
        if (field_val == NULL) {
          // We weren&#39;t able to find a value for this field,
          // give up on eliminating this allocation.
  
          // Remove any extra entries we added to the safepoint.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 904,11 ***</span>
              res-&gt;dump();
          }
  #endif
          return false;
        }
<span class="line-modified">!       if (UseCompressedOops &amp;&amp; field_type-&gt;isa_narrowoop()) {</span>
          // Enable &quot;DecodeN(EncodeP(Allocate)) --&gt; Allocate&quot; transformation
          // to be able scalar replace the allocation.
          if (field_val-&gt;is_EncodeP()) {
            field_val = field_val-&gt;in(1);
          } else {
<span class="line-new-header">--- 938,14 ---</span>
              res-&gt;dump();
          }
  #endif
          return false;
        }
<span class="line-modified">!       if (field_val-&gt;is_InlineType()) {</span>
<span class="line-added">+         // Keep track of inline types to scalarize them later</span>
<span class="line-added">+         value_worklist.push(field_val);</span>
<span class="line-added">+       } else if (UseCompressedOops &amp;&amp; field_type-&gt;isa_narrowoop()) {</span>
          // Enable &quot;DecodeN(EncodeP(Allocate)) --&gt; Allocate&quot; transformation
          // to be able scalar replace the allocation.
          if (field_val-&gt;is_EncodeP()) {
            field_val = field_val-&gt;in(1);
          } else {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 925,10 ***</span>
<span class="line-new-header">--- 962,15 ---</span>
      int end   = jvms-&gt;debug_end();
      sfpt-&gt;replace_edges_in_range(res, sobj, start, end);
      _igvn._worklist.push(sfpt);
      safepoints_done.append_if_missing(sfpt); // keep it for rollback
    }
<span class="line-added">+   // Scalarize inline types that were added to the safepoint</span>
<span class="line-added">+   for (uint i = 0; i &lt; value_worklist.size(); ++i) {</span>
<span class="line-added">+     Node* vt = value_worklist.at(i);</span>
<span class="line-added">+     vt-&gt;as_InlineType()-&gt;make_scalar_in_safepoints(&amp;_igvn);</span>
<span class="line-added">+   }</span>
    return true;
  }
  
  static void disconnect_projections(MultiNode* n, PhaseIterGVN&amp; igvn) {
    Node* ctl_proj = n-&gt;proj_out_or_null(TypeFunc::Control);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 940,11 ***</span>
      igvn.replace_node(mem_proj, n-&gt;in(TypeFunc::Memory));
    }
  }
  
  // Process users of eliminated allocation.
<span class="line-modified">! void PhaseMacroExpand::process_users_of_allocation(CallNode *alloc) {</span>
    Node* res = alloc-&gt;result_cast();
    if (res != NULL) {
      for (DUIterator_Last jmin, j = res-&gt;last_outs(jmin); j &gt;= jmin; ) {
        Node *use = res-&gt;last_out(j);
        uint oc1 = res-&gt;outcnt();
<span class="line-new-header">--- 982,11 ---</span>
      igvn.replace_node(mem_proj, n-&gt;in(TypeFunc::Memory));
    }
  }
  
  // Process users of eliminated allocation.
<span class="line-modified">! void PhaseMacroExpand::process_users_of_allocation(CallNode *alloc, bool inline_alloc) {</span>
    Node* res = alloc-&gt;result_cast();
    if (res != NULL) {
      for (DUIterator_Last jmin, j = res-&gt;last_outs(jmin); j &gt;= jmin; ) {
        Node *use = res-&gt;last_out(j);
        uint oc1 = res-&gt;outcnt();
</pre>
<hr />
<pre>
<span class="line-old-header">*** 952,22 ***</span>
        if (use-&gt;is_AddP()) {
          for (DUIterator_Last kmin, k = use-&gt;last_outs(kmin); k &gt;= kmin; ) {
            Node *n = use-&gt;last_out(k);
            uint oc2 = use-&gt;outcnt();
            if (n-&gt;is_Store()) {
<span class="line-modified">! #ifdef ASSERT</span>
<span class="line-modified">!             // Verify that there is no dependent MemBarVolatile nodes,</span>
<span class="line-modified">!             // they should be removed during IGVN, see MemBarNode::Ideal().</span>
<span class="line-modified">!             for (DUIterator_Fast pmax, p = n-&gt;fast_outs(pmax);</span>
<span class="line-modified">!                                        p &lt; pmax; p++) {</span>
<span class="line-modified">!               Node* mb = n-&gt;fast_out(p);</span>
<span class="line-modified">!               assert(mb-&gt;is_Initialize() || !mb-&gt;is_MemBar() ||</span>
<span class="line-removed">-                      mb-&gt;req() &lt;= MemBarNode::Precedent ||</span>
<span class="line-removed">-                      mb-&gt;in(MemBarNode::Precedent) != n,</span>
<span class="line-removed">-                      &quot;MemBarVolatile should be eliminated for non-escaping object&quot;);</span>
              }
<span class="line-removed">- #endif</span>
              _igvn.replace_node(n, n-&gt;in(MemNode::Memory));
            } else {
              eliminate_gc_barrier(n);
            }
            k -= (oc2 - use-&gt;outcnt());
<span class="line-new-header">--- 994,18 ---</span>
        if (use-&gt;is_AddP()) {
          for (DUIterator_Last kmin, k = use-&gt;last_outs(kmin); k &gt;= kmin; ) {
            Node *n = use-&gt;last_out(k);
            uint oc2 = use-&gt;outcnt();
            if (n-&gt;is_Store()) {
<span class="line-modified">!             for (DUIterator_Fast pmax, p = n-&gt;fast_outs(pmax); p &lt; pmax; p++) {</span>
<span class="line-modified">!               MemBarNode* mb = n-&gt;fast_out(p)-&gt;isa_MemBar();</span>
<span class="line-modified">!               if (mb != NULL &amp;&amp; mb-&gt;req() &lt;= MemBarNode::Precedent &amp;&amp; mb-&gt;in(MemBarNode::Precedent) == n) {</span>
<span class="line-modified">!                 // MemBarVolatiles should have been removed by MemBarNode::Ideal() for non-inline allocations</span>
<span class="line-modified">!                 assert(inline_alloc, &quot;MemBarVolatile should be eliminated for non-escaping object&quot;);</span>
<span class="line-modified">!                 mb-&gt;remove(&amp;_igvn);</span>
<span class="line-modified">!               }</span>
              }
              _igvn.replace_node(n, n-&gt;in(MemNode::Memory));
            } else {
              eliminate_gc_barrier(n);
            }
            k -= (oc2 - use-&gt;outcnt());
</pre>
<hr />
<pre>
<span class="line-old-header">*** 987,16 ***</span>
            }
          } else {
            assert(ac-&gt;is_arraycopy_validated() ||
                   ac-&gt;is_copyof_validated() ||
                   ac-&gt;is_copyofrange_validated(), &quot;unsupported&quot;);
<span class="line-modified">!           CallProjections callprojs;</span>
<span class="line-removed">-           ac-&gt;extract_projections(&amp;callprojs, true);</span>
  
<span class="line-modified">!           _igvn.replace_node(callprojs.fallthrough_ioproj, ac-&gt;in(TypeFunc::I_O));</span>
<span class="line-modified">!           _igvn.replace_node(callprojs.fallthrough_memproj, ac-&gt;in(TypeFunc::Memory));</span>
<span class="line-modified">!           _igvn.replace_node(callprojs.fallthrough_catchproj, ac-&gt;in(TypeFunc::Control));</span>
  
            // Set control to top. IGVN will remove the remaining projections
            ac-&gt;set_req(0, top());
            ac-&gt;replace_edge(res, top());
  
<span class="line-new-header">--- 1025,15 ---</span>
            }
          } else {
            assert(ac-&gt;is_arraycopy_validated() ||
                   ac-&gt;is_copyof_validated() ||
                   ac-&gt;is_copyofrange_validated(), &quot;unsupported&quot;);
<span class="line-modified">!           CallProjections* callprojs = ac-&gt;extract_projections(true);</span>
  
<span class="line-modified">!           _igvn.replace_node(callprojs-&gt;fallthrough_ioproj, ac-&gt;in(TypeFunc::I_O));</span>
<span class="line-modified">!           _igvn.replace_node(callprojs-&gt;fallthrough_memproj, ac-&gt;in(TypeFunc::Memory));</span>
<span class="line-modified">!           _igvn.replace_node(callprojs-&gt;fallthrough_catchproj, ac-&gt;in(TypeFunc::Control));</span>
  
            // Set control to top. IGVN will remove the remaining projections
            ac-&gt;set_req(0, top());
            ac-&gt;replace_edge(res, top());
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1009,10 ***</span>
<span class="line-new-header">--- 1046,16 ---</span>
            if (src-&gt;outcnt() == 0 &amp;&amp; !src-&gt;is_top()) {
              _igvn.remove_dead_node(src);
            }
          }
          _igvn._worklist.push(ac);
<span class="line-added">+       } else if (use-&gt;is_InlineType()) {</span>
<span class="line-added">+         assert(use-&gt;isa_InlineType()-&gt;get_oop() == res, &quot;unexpected inline type use&quot;);</span>
<span class="line-added">+         _igvn.rehash_node_delayed(use);</span>
<span class="line-added">+         use-&gt;isa_InlineType()-&gt;set_oop(_igvn.zerocon(T_INLINE_TYPE));</span>
<span class="line-added">+       } else if (use-&gt;is_Store()) {</span>
<span class="line-added">+         _igvn.replace_node(use, use-&gt;in(MemNode::Memory));</span>
        } else {
          eliminate_gc_barrier(use);
        }
        j -= (oc1 - res-&gt;outcnt());
      }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1042,10 ***</span>
<span class="line-new-header">--- 1085,15 ---</span>
          // Eliminate Initialize node.
          InitializeNode *init = use-&gt;as_Initialize();
          assert(init-&gt;outcnt() &lt;= 2, &quot;only a control and memory projection expected&quot;);
          Node *ctrl_proj = init-&gt;proj_out_or_null(TypeFunc::Control);
          if (ctrl_proj != NULL) {
<span class="line-added">+           // Inline type buffer allocations are followed by a membar</span>
<span class="line-added">+           Node* membar_after = ctrl_proj-&gt;unique_ctrl_out();</span>
<span class="line-added">+           if (inline_alloc &amp;&amp; membar_after-&gt;Opcode() == Op_MemBarCPUOrder) {</span>
<span class="line-added">+             membar_after-&gt;as_MemBar()-&gt;remove(&amp;_igvn);</span>
<span class="line-added">+           }</span>
            _igvn.replace_node(ctrl_proj, init-&gt;in(TypeFunc::Control));
  #ifdef ASSERT
            Node* tmp = init-&gt;in(TypeFunc::Control);
            assert(tmp == _fallthroughcatchproj, &quot;allocation control projection&quot;);
  #endif
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1060,10 ***</span>
<span class="line-new-header">--- 1108,14 ---</span>
              assert(mem == _memproj_fallthrough, &quot;allocation memory projection&quot;);
            }
  #endif
            _igvn.replace_node(mem_proj, mem);
          }
<span class="line-added">+       } else if (use-&gt;Opcode() == Op_MemBarStoreStore) {</span>
<span class="line-added">+         // Inline type buffer allocations are followed by a membar</span>
<span class="line-added">+         assert(inline_alloc, &quot;Unexpected MemBarStoreStore&quot;);</span>
<span class="line-added">+         use-&gt;as_MemBar()-&gt;remove(&amp;_igvn);</span>
        } else  {
          assert(false, &quot;only Initialize or AddP expected&quot;);
        }
        j -= (oc1 - _resproj-&gt;outcnt());
      }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1091,22 ***</span>
  bool PhaseMacroExpand::eliminate_allocate_node(AllocateNode *alloc) {
    // Don&#39;t do scalar replacement if the frame can be popped by JVMTI:
    // if reallocation fails during deoptimization we&#39;ll pop all
    // interpreter frames for this compiled frame and that won&#39;t play
    // nice with JVMTI popframe.
<span class="line-modified">!   if (!EliminateAllocations || JvmtiExport::can_pop_frame() || !alloc-&gt;_is_non_escaping) {</span>
      return false;
    }
    Node* klass = alloc-&gt;in(AllocateNode::KlassNode);
    const TypeKlassPtr* tklass = _igvn.type(klass)-&gt;is_klassptr();
<span class="line-modified">!   Node* res = alloc-&gt;result_cast();</span>
    // Eliminate boxing allocations which are not used
<span class="line-modified">!   // regardless scalar replacable status.</span>
<span class="line-modified">!   bool boxing_alloc = C-&gt;eliminate_boxing() &amp;&amp;</span>
<span class="line-modified">!                       tklass-&gt;klass()-&gt;is_instance_klass()  &amp;&amp;</span>
                        tklass-&gt;klass()-&gt;as_instance_klass()-&gt;is_box_klass();
<span class="line-modified">!   if (!alloc-&gt;_is_scalar_replaceable &amp;&amp; (!boxing_alloc || (res != NULL))) {</span>
      return false;
    }
  
    extract_call_projections(alloc);
  
<span class="line-new-header">--- 1143,29 ---</span>
  bool PhaseMacroExpand::eliminate_allocate_node(AllocateNode *alloc) {
    // Don&#39;t do scalar replacement if the frame can be popped by JVMTI:
    // if reallocation fails during deoptimization we&#39;ll pop all
    // interpreter frames for this compiled frame and that won&#39;t play
    // nice with JVMTI popframe.
<span class="line-modified">!   if (!EliminateAllocations || JvmtiExport::can_pop_frame()) {</span>
      return false;
    }
    Node* klass = alloc-&gt;in(AllocateNode::KlassNode);
    const TypeKlassPtr* tklass = _igvn.type(klass)-&gt;is_klassptr();
<span class="line-modified">! </span>
<span class="line-added">+   // Attempt to eliminate inline type buffer allocations</span>
<span class="line-added">+   // regardless of usage and escape/replaceable status.</span>
<span class="line-added">+   bool inline_alloc = tklass-&gt;klass()-&gt;is_inlinetype();</span>
<span class="line-added">+   if (!alloc-&gt;_is_non_escaping &amp;&amp; !inline_alloc) {</span>
<span class="line-added">+     return false;</span>
<span class="line-added">+   }</span>
    // Eliminate boxing allocations which are not used
<span class="line-modified">!   // regardless of scalar replaceable status.</span>
<span class="line-modified">!   Node* res = alloc-&gt;result_cast();</span>
<span class="line-modified">!   bool boxing_alloc = (res == NULL) &amp;&amp; C-&gt;eliminate_boxing() &amp;&amp;</span>
<span class="line-added">+                       tklass-&gt;klass()-&gt;is_instance_klass() &amp;&amp;</span>
                        tklass-&gt;klass()-&gt;as_instance_klass()-&gt;is_box_klass();
<span class="line-modified">!   if (!alloc-&gt;_is_scalar_replaceable &amp;&amp; !boxing_alloc &amp;&amp; !inline_alloc) {</span>
      return false;
    }
  
    extract_call_projections(alloc);
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1114,15 ***</span>
    if (!can_eliminate_allocation(alloc, safepoints)) {
      return false;
    }
  
    if (!alloc-&gt;_is_scalar_replaceable) {
<span class="line-modified">!     assert(res == NULL, &quot;sanity&quot;);</span>
      // We can only eliminate allocation if all debug info references
      // are already replaced with SafePointScalarObject because
      // we can&#39;t search for a fields value without instance_id.
      if (safepoints.length() &gt; 0) {
        return false;
      }
    }
  
    if (!scalar_replacement(alloc, safepoints)) {
<span class="line-new-header">--- 1173,16 ---</span>
    if (!can_eliminate_allocation(alloc, safepoints)) {
      return false;
    }
  
    if (!alloc-&gt;_is_scalar_replaceable) {
<span class="line-modified">!     assert(res == NULL || inline_alloc, &quot;sanity&quot;);</span>
      // We can only eliminate allocation if all debug info references
      // are already replaced with SafePointScalarObject because
      // we can&#39;t search for a fields value without instance_id.
      if (safepoints.length() &gt; 0) {
<span class="line-added">+       assert(!inline_alloc, &quot;Inline type allocations should not have safepoint uses&quot;);</span>
        return false;
      }
    }
  
    if (!scalar_replacement(alloc, safepoints)) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1139,11 ***</span>
        p = p-&gt;caller();
      }
      log-&gt;tail(&quot;eliminate_allocation&quot;);
    }
  
<span class="line-modified">!   process_users_of_allocation(alloc);</span>
  
  #ifndef PRODUCT
    if (PrintEliminateAllocations) {
      if (alloc-&gt;is_AllocateArray())
        tty-&gt;print_cr(&quot;++++ Eliminated: %d AllocateArray&quot;, alloc-&gt;_idx);
<span class="line-new-header">--- 1199,11 ---</span>
        p = p-&gt;caller();
      }
      log-&gt;tail(&quot;eliminate_allocation&quot;);
    }
  
<span class="line-modified">!   process_users_of_allocation(alloc, inline_alloc);</span>
  
  #ifndef PRODUCT
    if (PrintEliminateAllocations) {
      if (alloc-&gt;is_AllocateArray())
        tty-&gt;print_cr(&quot;++++ Eliminated: %d AllocateArray&quot;, alloc-&gt;_idx);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1163,11 ***</span>
  
    assert(boxing-&gt;result_cast() == NULL, &quot;unexpected boxing node result&quot;);
  
    extract_call_projections(boxing);
  
<span class="line-modified">!   const TypeTuple* r = boxing-&gt;tf()-&gt;range();</span>
    assert(r-&gt;cnt() &gt; TypeFunc::Parms, &quot;sanity&quot;);
    const TypeInstPtr* t = r-&gt;field_at(TypeFunc::Parms)-&gt;isa_instptr();
    assert(t != NULL, &quot;sanity&quot;);
  
    CompileLog* log = C-&gt;log();
<span class="line-new-header">--- 1223,11 ---</span>
  
    assert(boxing-&gt;result_cast() == NULL, &quot;unexpected boxing node result&quot;);
  
    extract_call_projections(boxing);
  
<span class="line-modified">!   const TypeTuple* r = boxing-&gt;tf()-&gt;range_sig();</span>
    assert(r-&gt;cnt() &gt; TypeFunc::Parms, &quot;sanity&quot;);
    const TypeInstPtr* t = r-&gt;field_at(TypeFunc::Parms)-&gt;isa_instptr();
    assert(t != NULL, &quot;sanity&quot;);
  
    CompileLog* log = C-&gt;log();
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1364,17 ***</span>
      slow_region = new RegionNode(3);
  
      // Now make the initial failure test.  Usually a too-big test but
      // might be a TRUE for finalizers or a fancy class check for
      // newInstance0.
<span class="line-modified">!     IfNode *toobig_iff = new IfNode(ctrl, initial_slow_test, PROB_MIN, COUNT_UNKNOWN);</span>
      transform_later(toobig_iff);
      // Plug the failing-too-big test into the slow-path region
<span class="line-modified">!     Node *toobig_true = new IfTrueNode( toobig_iff );</span>
      transform_later(toobig_true);
      slow_region    -&gt;init_req( too_big_or_final_path, toobig_true );
<span class="line-modified">!     toobig_false = new IfFalseNode( toobig_iff );</span>
      transform_later(toobig_false);
    } else {
      // No initial test, just fall into next case
      assert(allocation_has_use || !expand_fast_path, &quot;Should already have been handled&quot;);
      toobig_false = ctrl;
<span class="line-new-header">--- 1424,17 ---</span>
      slow_region = new RegionNode(3);
  
      // Now make the initial failure test.  Usually a too-big test but
      // might be a TRUE for finalizers or a fancy class check for
      // newInstance0.
<span class="line-modified">!     IfNode* toobig_iff = new IfNode(ctrl, initial_slow_test, PROB_MIN, COUNT_UNKNOWN);</span>
      transform_later(toobig_iff);
      // Plug the failing-too-big test into the slow-path region
<span class="line-modified">!     Node* toobig_true = new IfTrueNode(toobig_iff);</span>
      transform_later(toobig_true);
      slow_region    -&gt;init_req( too_big_or_final_path, toobig_true );
<span class="line-modified">!     toobig_false = new IfFalseNode(toobig_iff);</span>
      transform_later(toobig_false);
    } else {
      // No initial test, just fall into next case
      assert(allocation_has_use || !expand_fast_path, &quot;Should already have been handled&quot;);
      toobig_false = ctrl;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1409,10 ***</span>
<span class="line-new-header">--- 1469,11 ---</span>
      result_phi_i_o-&gt;init_req(slow_result_path, i_o);
  
      // Name successful fast-path variables
      Node* fast_oop_ctrl;
      Node* fast_oop_rawmem;
<span class="line-added">+ </span>
      if (allocation_has_use) {
        Node* needgc_ctrl = NULL;
        result_phi_rawoop = new PhiNode(result_region, TypeRawPtr::BOTTOM);
  
        intx prefetch_lines = length != NULL ? AllocatePrefetchLines : AllocateInstancePrefetchLines;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1467,15 ***</span>
    call-&gt;init_req(TypeFunc::FramePtr,  alloc-&gt;in(TypeFunc::FramePtr));
  
    call-&gt;init_req(TypeFunc::Parms+0, klass_node);
    if (length != NULL) {
      call-&gt;init_req(TypeFunc::Parms+1, length);
    }
  
    // Copy debug information and adjust JVMState information, then replace
    // allocate node with the call
<span class="line-modified">!   copy_call_debug_info((CallNode *) alloc,  call);</span>
    if (expand_fast_path) {
      call-&gt;set_cnt(PROB_UNLIKELY_MAG(4));  // Same effect as RC_UNCOMMON.
    } else {
      // Hook i_o projection to avoid its elimination during allocation
      // replacement (when only a slow call is generated).
<span class="line-new-header">--- 1528,18 ---</span>
    call-&gt;init_req(TypeFunc::FramePtr,  alloc-&gt;in(TypeFunc::FramePtr));
  
    call-&gt;init_req(TypeFunc::Parms+0, klass_node);
    if (length != NULL) {
      call-&gt;init_req(TypeFunc::Parms+1, length);
<span class="line-added">+   } else {</span>
<span class="line-added">+     // Let the runtime know if this is a larval allocation</span>
<span class="line-added">+     call-&gt;init_req(TypeFunc::Parms+1, _igvn.intcon(alloc-&gt;_larval));</span>
    }
  
    // Copy debug information and adjust JVMState information, then replace
    // allocate node with the call
<span class="line-modified">!   call-&gt;copy_call_debug_info(&amp;_igvn, alloc);</span>
    if (expand_fast_path) {
      call-&gt;set_cnt(PROB_UNLIKELY_MAG(4));  // Same effect as RC_UNCOMMON.
    } else {
      // Hook i_o projection to avoid its elimination during allocation
      // replacement (when only a slow call is generated).
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1499,39 ***</span>
    // An allocate node has separate memory projections for the uses on
    // the control and i_o paths. Replace the control memory projection with
    // result_phi_rawmem (unless we are only generating a slow call when
    // both memory projections are combined)
    if (expand_fast_path &amp;&amp; _memproj_fallthrough != NULL) {
<span class="line-modified">!     migrate_outs(_memproj_fallthrough, result_phi_rawmem);</span>
    }
    // Now change uses of _memproj_catchall to use _memproj_fallthrough and delete
    // _memproj_catchall so we end up with a call that has only 1 memory projection.
<span class="line-modified">!   if (_memproj_catchall != NULL ) {</span>
      if (_memproj_fallthrough == NULL) {
        _memproj_fallthrough = new ProjNode(call, TypeFunc::Memory);
        transform_later(_memproj_fallthrough);
      }
<span class="line-modified">!     migrate_outs(_memproj_catchall, _memproj_fallthrough);</span>
      _igvn.remove_dead_node(_memproj_catchall);
    }
  
    // An allocate node has separate i_o projections for the uses on the control
    // and i_o paths. Always replace the control i_o projection with result i_o
    // otherwise incoming i_o become dead when only a slow call is generated
    // (it is different from memory projections where both projections are
    // combined in such case).
    if (_ioproj_fallthrough != NULL) {
<span class="line-modified">!     migrate_outs(_ioproj_fallthrough, result_phi_i_o);</span>
    }
    // Now change uses of _ioproj_catchall to use _ioproj_fallthrough and delete
    // _ioproj_catchall so we end up with a call that has only 1 i_o projection.
<span class="line-modified">!   if (_ioproj_catchall != NULL ) {</span>
      if (_ioproj_fallthrough == NULL) {
        _ioproj_fallthrough = new ProjNode(call, TypeFunc::I_O);
        transform_later(_ioproj_fallthrough);
      }
<span class="line-modified">!     migrate_outs(_ioproj_catchall, _ioproj_fallthrough);</span>
      _igvn.remove_dead_node(_ioproj_catchall);
    }
  
    // if we generated only a slow call, we are done
    if (!expand_fast_path) {
<span class="line-new-header">--- 1563,39 ---</span>
    // An allocate node has separate memory projections for the uses on
    // the control and i_o paths. Replace the control memory projection with
    // result_phi_rawmem (unless we are only generating a slow call when
    // both memory projections are combined)
    if (expand_fast_path &amp;&amp; _memproj_fallthrough != NULL) {
<span class="line-modified">!     _igvn.replace_in_uses(_memproj_fallthrough, result_phi_rawmem);</span>
    }
    // Now change uses of _memproj_catchall to use _memproj_fallthrough and delete
    // _memproj_catchall so we end up with a call that has only 1 memory projection.
<span class="line-modified">!   if (_memproj_catchall != NULL) {</span>
      if (_memproj_fallthrough == NULL) {
        _memproj_fallthrough = new ProjNode(call, TypeFunc::Memory);
        transform_later(_memproj_fallthrough);
      }
<span class="line-modified">!     _igvn.replace_in_uses(_memproj_catchall, _memproj_fallthrough);</span>
      _igvn.remove_dead_node(_memproj_catchall);
    }
  
    // An allocate node has separate i_o projections for the uses on the control
    // and i_o paths. Always replace the control i_o projection with result i_o
    // otherwise incoming i_o become dead when only a slow call is generated
    // (it is different from memory projections where both projections are
    // combined in such case).
    if (_ioproj_fallthrough != NULL) {
<span class="line-modified">!     _igvn.replace_in_uses(_ioproj_fallthrough, result_phi_i_o);</span>
    }
    // Now change uses of _ioproj_catchall to use _ioproj_fallthrough and delete
    // _ioproj_catchall so we end up with a call that has only 1 i_o projection.
<span class="line-modified">!   if (_ioproj_catchall != NULL) {</span>
      if (_ioproj_fallthrough == NULL) {
        _ioproj_fallthrough = new ProjNode(call, TypeFunc::I_O);
        transform_later(_ioproj_fallthrough);
      }
<span class="line-modified">!     _igvn.replace_in_uses(_ioproj_catchall, _ioproj_fallthrough);</span>
      _igvn.remove_dead_node(_ioproj_catchall);
    }
  
    // if we generated only a slow call, we are done
    if (!expand_fast_path) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1595,11 ***</span>
      }
      assert(_resproj-&gt;outcnt() == 0, &quot;all uses must be deleted&quot;);
      _igvn.remove_dead_node(_resproj);
    }
    if (_fallthroughcatchproj != NULL) {
<span class="line-modified">!     migrate_outs(_fallthroughcatchproj, ctrl);</span>
      _igvn.remove_dead_node(_fallthroughcatchproj);
    }
    if (_catchallcatchproj != NULL) {
      _igvn.rehash_node_delayed(_catchallcatchproj);
      _catchallcatchproj-&gt;set_req(0, top());
<span class="line-new-header">--- 1659,11 ---</span>
      }
      assert(_resproj-&gt;outcnt() == 0, &quot;all uses must be deleted&quot;);
      _igvn.remove_dead_node(_resproj);
    }
    if (_fallthroughcatchproj != NULL) {
<span class="line-modified">!     _igvn.replace_in_uses(_fallthroughcatchproj, ctrl);</span>
      _igvn.remove_dead_node(_fallthroughcatchproj);
    }
    if (_catchallcatchproj != NULL) {
      _igvn.rehash_node_delayed(_catchallcatchproj);
      _catchallcatchproj-&gt;set_req(0, top());
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1608,15 ***</span>
      Node* catchnode = _fallthroughproj-&gt;unique_ctrl_out();
      _igvn.remove_dead_node(catchnode);
      _igvn.remove_dead_node(_fallthroughproj);
    }
    if (_memproj_fallthrough != NULL) {
<span class="line-modified">!     migrate_outs(_memproj_fallthrough, mem);</span>
      _igvn.remove_dead_node(_memproj_fallthrough);
    }
    if (_ioproj_fallthrough != NULL) {
<span class="line-modified">!     migrate_outs(_ioproj_fallthrough, i_o);</span>
      _igvn.remove_dead_node(_ioproj_fallthrough);
    }
    if (_memproj_catchall != NULL) {
      _igvn.rehash_node_delayed(_memproj_catchall);
      _memproj_catchall-&gt;set_req(0, top());
<span class="line-new-header">--- 1672,15 ---</span>
      Node* catchnode = _fallthroughproj-&gt;unique_ctrl_out();
      _igvn.remove_dead_node(catchnode);
      _igvn.remove_dead_node(_fallthroughproj);
    }
    if (_memproj_fallthrough != NULL) {
<span class="line-modified">!     _igvn.replace_in_uses(_memproj_fallthrough, mem);</span>
      _igvn.remove_dead_node(_memproj_fallthrough);
    }
    if (_ioproj_fallthrough != NULL) {
<span class="line-modified">!     _igvn.replace_in_uses(_ioproj_fallthrough, i_o);</span>
      _igvn.remove_dead_node(_ioproj_fallthrough);
    }
    if (_memproj_catchall != NULL) {
      _igvn.rehash_node_delayed(_memproj_catchall);
      _memproj_catchall-&gt;set_req(0, top());
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1738,18 ***</span>
    }
  }
  
  // Helper for PhaseMacroExpand::expand_allocate_common.
  // Initializes the newly-allocated storage.
<span class="line-modified">! Node*</span>
<span class="line-modified">! PhaseMacroExpand::initialize_object(AllocateNode* alloc,</span>
<span class="line-modified">!                                     Node* control, Node* rawmem, Node* object,</span>
<span class="line-modified">!                                     Node* klass_node, Node* length,</span>
<span class="line-removed">-                                     Node* size_in_bytes) {</span>
    InitializeNode* init = alloc-&gt;initialization();
    // Store the klass &amp; mark bits
<span class="line-modified">!   Node* mark_node = alloc-&gt;make_ideal_mark(&amp;_igvn, object, control, rawmem);</span>
    if (!mark_node-&gt;is_Con()) {
      transform_later(mark_node);
    }
    rawmem = make_store(control, rawmem, object, oopDesc::mark_offset_in_bytes(), mark_node, TypeX_X-&gt;basic_type());
  
<span class="line-new-header">--- 1802,17 ---</span>
    }
  }
  
  // Helper for PhaseMacroExpand::expand_allocate_common.
  // Initializes the newly-allocated storage.
<span class="line-modified">! Node* PhaseMacroExpand::initialize_object(AllocateNode* alloc,</span>
<span class="line-modified">!                                           Node* control, Node* rawmem, Node* object,</span>
<span class="line-modified">!                                           Node* klass_node, Node* length,</span>
<span class="line-modified">!                                           Node* size_in_bytes) {</span>
    InitializeNode* init = alloc-&gt;initialization();
    // Store the klass &amp; mark bits
<span class="line-modified">!   Node* mark_node = alloc-&gt;make_ideal_mark(&amp;_igvn, control, rawmem);</span>
    if (!mark_node-&gt;is_Con()) {
      transform_later(mark_node);
    }
    rawmem = make_store(control, rawmem, object, oopDesc::mark_offset_in_bytes(), mark_node, TypeX_X-&gt;basic_type());
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1777,10 ***</span>
<span class="line-new-header">--- 1840,12 ---</span>
      // there can be two Allocates to one Initialize.  The answer in all these
      // edge cases is safety first.  It is always safe to clear immediately
      // within an Allocate, and then (maybe or maybe not) clear some more later.
      if (!(UseTLAB &amp;&amp; ZeroTLAB)) {
        rawmem = ClearArrayNode::clear_memory(control, rawmem, object,
<span class="line-added">+                                             alloc-&gt;in(AllocateNode::DefaultValue),</span>
<span class="line-added">+                                             alloc-&gt;in(AllocateNode::RawDefaultValue),</span>
                                              header_size, size_in_bytes,
                                              &amp;_igvn);
      }
    } else {
      if (!init-&gt;is_complete()) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2157,10 ***</span>
<span class="line-new-header">--- 2222,12 ---</span>
  
    if (!alock-&gt;is_eliminated()) {
      return false;
    }
  #ifdef ASSERT
<span class="line-added">+   const Type* obj_type = _igvn.type(alock-&gt;obj_node());</span>
<span class="line-added">+   assert(!obj_type-&gt;isa_inlinetype() &amp;&amp; !obj_type-&gt;is_inlinetypeptr(), &quot;Eliminating lock on inline type&quot;);</span>
    if (!alock-&gt;is_coarsened()) {
      // Check that new &quot;eliminated&quot; BoxLock node is created.
      BoxLockNode* oldbox = alock-&gt;box_node()-&gt;as_BoxLock();
      assert(oldbox-&gt;is_eliminated(), &quot;should be done already&quot;);
    }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2438,10 ***</span>
<span class="line-new-header">--- 2505,52 ---</span>
      // Optimize test; set region slot 2
      slow_path = opt_bits_test(ctrl, region, 2, flock, 0, 0);
      mem_phi-&gt;init_req(2, mem);
    }
  
<span class="line-added">+   const TypeOopPtr* objptr = _igvn.type(obj)-&gt;make_oopptr();</span>
<span class="line-added">+   if (objptr-&gt;can_be_inline_type()) {</span>
<span class="line-added">+     // Deoptimize and re-execute if a value</span>
<span class="line-added">+     assert(EnableValhalla, &quot;should only be used if inline types are enabled&quot;);</span>
<span class="line-added">+     Node* mark = make_load(slow_path, mem, obj, oopDesc::mark_offset_in_bytes(), TypeX_X, TypeX_X-&gt;basic_type());</span>
<span class="line-added">+     Node* value_mask = _igvn.MakeConX(markWord::always_locked_pattern);</span>
<span class="line-added">+     Node* is_value = _igvn.transform(new AndXNode(mark, value_mask));</span>
<span class="line-added">+     Node* cmp = _igvn.transform(new CmpXNode(is_value, value_mask));</span>
<span class="line-added">+     Node* bol = _igvn.transform(new BoolNode(cmp, BoolTest::eq));</span>
<span class="line-added">+     Node* unc_ctrl = generate_slow_guard(&amp;slow_path, bol, NULL);</span>
<span class="line-added">+ </span>
<span class="line-added">+     int trap_request = Deoptimization::make_trap_request(Deoptimization::Reason_class_check, Deoptimization::Action_none);</span>
<span class="line-added">+     address call_addr = SharedRuntime::uncommon_trap_blob()-&gt;entry_point();</span>
<span class="line-added">+     const TypePtr* no_memory_effects = NULL;</span>
<span class="line-added">+     JVMState* jvms = lock-&gt;jvms();</span>
<span class="line-added">+     CallNode* unc = new CallStaticJavaNode(OptoRuntime::uncommon_trap_Type(), call_addr, &quot;uncommon_trap&quot;,</span>
<span class="line-added">+                                            jvms-&gt;bci(), no_memory_effects);</span>
<span class="line-added">+ </span>
<span class="line-added">+     unc-&gt;init_req(TypeFunc::Control, unc_ctrl);</span>
<span class="line-added">+     unc-&gt;init_req(TypeFunc::I_O, lock-&gt;i_o());</span>
<span class="line-added">+     unc-&gt;init_req(TypeFunc::Memory, mem); // may gc ptrs</span>
<span class="line-added">+     unc-&gt;init_req(TypeFunc::FramePtr,  lock-&gt;in(TypeFunc::FramePtr));</span>
<span class="line-added">+     unc-&gt;init_req(TypeFunc::ReturnAdr, lock-&gt;in(TypeFunc::ReturnAdr));</span>
<span class="line-added">+     unc-&gt;init_req(TypeFunc::Parms+0, _igvn.intcon(trap_request));</span>
<span class="line-added">+     unc-&gt;set_cnt(PROB_UNLIKELY_MAG(4));</span>
<span class="line-added">+     unc-&gt;copy_call_debug_info(&amp;_igvn, lock);</span>
<span class="line-added">+ </span>
<span class="line-added">+     assert(unc-&gt;peek_monitor_box() == box, &quot;wrong monitor&quot;);</span>
<span class="line-added">+     assert(unc-&gt;peek_monitor_obj() == obj, &quot;wrong monitor&quot;);</span>
<span class="line-added">+ </span>
<span class="line-added">+     // pop monitor and push obj back on stack: we trap before the monitorenter</span>
<span class="line-added">+     unc-&gt;pop_monitor();</span>
<span class="line-added">+     unc-&gt;grow_stack(unc-&gt;jvms(), 1);</span>
<span class="line-added">+     unc-&gt;set_stack(unc-&gt;jvms(), unc-&gt;jvms()-&gt;stk_size()-1, obj);</span>
<span class="line-added">+ </span>
<span class="line-added">+     _igvn.register_new_node_with_optimizer(unc);</span>
<span class="line-added">+ </span>
<span class="line-added">+     Node* ctrl = _igvn.transform(new ProjNode(unc, TypeFunc::Control));</span>
<span class="line-added">+     Node* halt = _igvn.transform(new HaltNode(ctrl, lock-&gt;in(TypeFunc::FramePtr), &quot;monitor enter on value-type&quot;));</span>
<span class="line-added">+     C-&gt;root()-&gt;add_req(halt);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
    // Make slow path call
    CallNode *call = make_slow_call((CallNode *) lock, OptoRuntime::complete_monitor_enter_Type(),
                                    OptoRuntime::complete_monitor_locking_Java(), NULL, slow_path,
                                    obj, box, NULL);
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2539,10 ***</span>
<span class="line-new-header">--- 2648,215 ---</span>
    mem_phi-&gt;init_req(2, mem);
    transform_later(mem_phi);
    _igvn.replace_node(_memproj_fallthrough, mem_phi);
  }
  
<span class="line-added">+ // An inline type might be returned from the call but we don&#39;t know its</span>
<span class="line-added">+ // type. Either we get a buffered inline type (and nothing needs to be done)</span>
<span class="line-added">+ // or one of the inlines being returned is the klass of the inline type</span>
<span class="line-added">+ // and we need to allocate an inline type instance of that type and</span>
<span class="line-added">+ // initialize it with other values being returned. In that case, we</span>
<span class="line-added">+ // first try a fast path allocation and initialize the value with the</span>
<span class="line-added">+ // inline klass&#39;s pack handler or we fall back to a runtime call.</span>
<span class="line-added">+ void PhaseMacroExpand::expand_mh_intrinsic_return(CallStaticJavaNode* call) {</span>
<span class="line-added">+   assert(call-&gt;method()-&gt;is_method_handle_intrinsic(), &quot;must be a method handle intrinsic call&quot;);</span>
<span class="line-added">+   Node* ret = call-&gt;proj_out_or_null(TypeFunc::Parms);</span>
<span class="line-added">+   if (ret == NULL) {</span>
<span class="line-added">+     return;</span>
<span class="line-added">+   }</span>
<span class="line-added">+   const TypeFunc* tf = call-&gt;_tf;</span>
<span class="line-added">+   const TypeTuple* domain = OptoRuntime::store_inline_type_fields_Type()-&gt;domain_cc();</span>
<span class="line-added">+   const TypeFunc* new_tf = TypeFunc::make(tf-&gt;domain_sig(), tf-&gt;domain_cc(), tf-&gt;range_sig(), domain);</span>
<span class="line-added">+   call-&gt;_tf = new_tf;</span>
<span class="line-added">+   // Make sure the change of type is applied before projections are processed by igvn</span>
<span class="line-added">+   _igvn.set_type(call, call-&gt;Value(&amp;_igvn));</span>
<span class="line-added">+   _igvn.set_type(ret, ret-&gt;Value(&amp;_igvn));</span>
<span class="line-added">+ </span>
<span class="line-added">+   // Before any new projection is added:</span>
<span class="line-added">+   CallProjections* projs = call-&gt;extract_projections(true, true);</span>
<span class="line-added">+ </span>
<span class="line-added">+   Node* ctl = new Node(1);</span>
<span class="line-added">+   Node* mem = new Node(1);</span>
<span class="line-added">+   Node* io = new Node(1);</span>
<span class="line-added">+   Node* ex_ctl = new Node(1);</span>
<span class="line-added">+   Node* ex_mem = new Node(1);</span>
<span class="line-added">+   Node* ex_io = new Node(1);</span>
<span class="line-added">+   Node* res = new Node(1);</span>
<span class="line-added">+ </span>
<span class="line-added">+   Node* cast = transform_later(new CastP2XNode(ctl, res));</span>
<span class="line-added">+   Node* mask = MakeConX(0x1);</span>
<span class="line-added">+   Node* masked = transform_later(new AndXNode(cast, mask));</span>
<span class="line-added">+   Node* cmp = transform_later(new CmpXNode(masked, mask));</span>
<span class="line-added">+   Node* bol = transform_later(new BoolNode(cmp, BoolTest::eq));</span>
<span class="line-added">+   IfNode* allocation_iff = new IfNode(ctl, bol, PROB_MAX, COUNT_UNKNOWN);</span>
<span class="line-added">+   transform_later(allocation_iff);</span>
<span class="line-added">+   Node* allocation_ctl = transform_later(new IfTrueNode(allocation_iff));</span>
<span class="line-added">+   Node* no_allocation_ctl = transform_later(new IfFalseNode(allocation_iff));</span>
<span class="line-added">+ </span>
<span class="line-added">+   Node* no_allocation_res = transform_later(new CheckCastPPNode(no_allocation_ctl, res, TypeInstPtr::BOTTOM));</span>
<span class="line-added">+ </span>
<span class="line-added">+   Node* mask2 = MakeConX(-2);</span>
<span class="line-added">+   Node* masked2 = transform_later(new AndXNode(cast, mask2));</span>
<span class="line-added">+   Node* rawklassptr = transform_later(new CastX2PNode(masked2));</span>
<span class="line-added">+   Node* klass_node = transform_later(new CheckCastPPNode(allocation_ctl, rawklassptr, TypeKlassPtr::OBJECT_OR_NULL));</span>
<span class="line-added">+ </span>
<span class="line-added">+   Node* slowpath_bol = NULL;</span>
<span class="line-added">+   Node* top_adr = NULL;</span>
<span class="line-added">+   Node* old_top = NULL;</span>
<span class="line-added">+   Node* new_top = NULL;</span>
<span class="line-added">+   if (UseTLAB) {</span>
<span class="line-added">+     Node* end_adr = NULL;</span>
<span class="line-added">+     set_eden_pointers(top_adr, end_adr);</span>
<span class="line-added">+     Node* end = make_load(ctl, mem, end_adr, 0, TypeRawPtr::BOTTOM, T_ADDRESS);</span>
<span class="line-added">+     old_top = new LoadPNode(ctl, mem, top_adr, TypeRawPtr::BOTTOM, TypeRawPtr::BOTTOM, MemNode::unordered);</span>
<span class="line-added">+     transform_later(old_top);</span>
<span class="line-added">+     Node* layout_val = make_load(NULL, mem, klass_node, in_bytes(Klass::layout_helper_offset()), TypeInt::INT, T_INT);</span>
<span class="line-added">+     Node* size_in_bytes = ConvI2X(layout_val);</span>
<span class="line-added">+     new_top = new AddPNode(top(), old_top, size_in_bytes);</span>
<span class="line-added">+     transform_later(new_top);</span>
<span class="line-added">+     Node* slowpath_cmp = new CmpPNode(new_top, end);</span>
<span class="line-added">+     transform_later(slowpath_cmp);</span>
<span class="line-added">+     slowpath_bol = new BoolNode(slowpath_cmp, BoolTest::ge);</span>
<span class="line-added">+     transform_later(slowpath_bol);</span>
<span class="line-added">+   } else {</span>
<span class="line-added">+     slowpath_bol = intcon(1);</span>
<span class="line-added">+     top_adr = top();</span>
<span class="line-added">+     old_top = top();</span>
<span class="line-added">+     new_top = top();</span>
<span class="line-added">+   }</span>
<span class="line-added">+   IfNode* slowpath_iff = new IfNode(allocation_ctl, slowpath_bol, PROB_UNLIKELY_MAG(4), COUNT_UNKNOWN);</span>
<span class="line-added">+   transform_later(slowpath_iff);</span>
<span class="line-added">+ </span>
<span class="line-added">+   Node* slowpath_true = new IfTrueNode(slowpath_iff);</span>
<span class="line-added">+   transform_later(slowpath_true);</span>
<span class="line-added">+ </span>
<span class="line-added">+   CallStaticJavaNode* slow_call = new CallStaticJavaNode(OptoRuntime::store_inline_type_fields_Type(),</span>
<span class="line-added">+                                                          StubRoutines::store_inline_type_fields_to_buf(),</span>
<span class="line-added">+                                                          &quot;store_inline_type_fields&quot;,</span>
<span class="line-added">+                                                          call-&gt;jvms()-&gt;bci(),</span>
<span class="line-added">+                                                          TypePtr::BOTTOM);</span>
<span class="line-added">+   slow_call-&gt;init_req(TypeFunc::Control, slowpath_true);</span>
<span class="line-added">+   slow_call-&gt;init_req(TypeFunc::Memory, mem);</span>
<span class="line-added">+   slow_call-&gt;init_req(TypeFunc::I_O, io);</span>
<span class="line-added">+   slow_call-&gt;init_req(TypeFunc::FramePtr, call-&gt;in(TypeFunc::FramePtr));</span>
<span class="line-added">+   slow_call-&gt;init_req(TypeFunc::ReturnAdr, call-&gt;in(TypeFunc::ReturnAdr));</span>
<span class="line-added">+   slow_call-&gt;init_req(TypeFunc::Parms, res);</span>
<span class="line-added">+ </span>
<span class="line-added">+   Node* slow_ctl = transform_later(new ProjNode(slow_call, TypeFunc::Control));</span>
<span class="line-added">+   Node* slow_mem = transform_later(new ProjNode(slow_call, TypeFunc::Memory));</span>
<span class="line-added">+   Node* slow_io = transform_later(new ProjNode(slow_call, TypeFunc::I_O));</span>
<span class="line-added">+   Node* slow_res = transform_later(new ProjNode(slow_call, TypeFunc::Parms));</span>
<span class="line-added">+   Node* slow_catc = transform_later(new CatchNode(slow_ctl, slow_io, 2));</span>
<span class="line-added">+   Node* slow_norm = transform_later(new CatchProjNode(slow_catc, CatchProjNode::fall_through_index, CatchProjNode::no_handler_bci));</span>
<span class="line-added">+   Node* slow_excp = transform_later(new CatchProjNode(slow_catc, CatchProjNode::catch_all_index,    CatchProjNode::no_handler_bci));</span>
<span class="line-added">+ </span>
<span class="line-added">+   Node* ex_r = new RegionNode(3);</span>
<span class="line-added">+   Node* ex_mem_phi = new PhiNode(ex_r, Type::MEMORY, TypePtr::BOTTOM);</span>
<span class="line-added">+   Node* ex_io_phi = new PhiNode(ex_r, Type::ABIO);</span>
<span class="line-added">+   ex_r-&gt;init_req(1, slow_excp);</span>
<span class="line-added">+   ex_mem_phi-&gt;init_req(1, slow_mem);</span>
<span class="line-added">+   ex_io_phi-&gt;init_req(1, slow_io);</span>
<span class="line-added">+   ex_r-&gt;init_req(2, ex_ctl);</span>
<span class="line-added">+   ex_mem_phi-&gt;init_req(2, ex_mem);</span>
<span class="line-added">+   ex_io_phi-&gt;init_req(2, ex_io);</span>
<span class="line-added">+ </span>
<span class="line-added">+   transform_later(ex_r);</span>
<span class="line-added">+   transform_later(ex_mem_phi);</span>
<span class="line-added">+   transform_later(ex_io_phi);</span>
<span class="line-added">+ </span>
<span class="line-added">+   Node* slowpath_false = new IfFalseNode(slowpath_iff);</span>
<span class="line-added">+   transform_later(slowpath_false);</span>
<span class="line-added">+   Node* rawmem = new StorePNode(slowpath_false, mem, top_adr, TypeRawPtr::BOTTOM, new_top, MemNode::unordered);</span>
<span class="line-added">+   transform_later(rawmem);</span>
<span class="line-added">+   Node* mark_node = makecon(TypeRawPtr::make((address)markWord::always_locked_prototype().value()));</span>
<span class="line-added">+   rawmem = make_store(slowpath_false, rawmem, old_top, oopDesc::mark_offset_in_bytes(), mark_node, T_ADDRESS);</span>
<span class="line-added">+   rawmem = make_store(slowpath_false, rawmem, old_top, oopDesc::klass_offset_in_bytes(), klass_node, T_METADATA);</span>
<span class="line-added">+   if (UseCompressedClassPointers) {</span>
<span class="line-added">+     rawmem = make_store(slowpath_false, rawmem, old_top, oopDesc::klass_gap_offset_in_bytes(), intcon(0), T_INT);</span>
<span class="line-added">+   }</span>
<span class="line-added">+   Node* fixed_block  = make_load(slowpath_false, rawmem, klass_node, in_bytes(InstanceKlass::adr_inlineklass_fixed_block_offset()), TypeRawPtr::BOTTOM, T_ADDRESS);</span>
<span class="line-added">+   Node* pack_handler = make_load(slowpath_false, rawmem, fixed_block, in_bytes(InlineKlass::pack_handler_offset()), TypeRawPtr::BOTTOM, T_ADDRESS);</span>
<span class="line-added">+ </span>
<span class="line-added">+   CallLeafNoFPNode* handler_call = new CallLeafNoFPNode(OptoRuntime::pack_inline_type_Type(),</span>
<span class="line-added">+                                                         NULL,</span>
<span class="line-added">+                                                         &quot;pack handler&quot;,</span>
<span class="line-added">+                                                         TypeRawPtr::BOTTOM);</span>
<span class="line-added">+   handler_call-&gt;init_req(TypeFunc::Control, slowpath_false);</span>
<span class="line-added">+   handler_call-&gt;init_req(TypeFunc::Memory, rawmem);</span>
<span class="line-added">+   handler_call-&gt;init_req(TypeFunc::I_O, top());</span>
<span class="line-added">+   handler_call-&gt;init_req(TypeFunc::FramePtr, call-&gt;in(TypeFunc::FramePtr));</span>
<span class="line-added">+   handler_call-&gt;init_req(TypeFunc::ReturnAdr, top());</span>
<span class="line-added">+   handler_call-&gt;init_req(TypeFunc::Parms, pack_handler);</span>
<span class="line-added">+   handler_call-&gt;init_req(TypeFunc::Parms+1, old_top);</span>
<span class="line-added">+ </span>
<span class="line-added">+   // We don&#39;t know how many values are returned. This assumes the</span>
<span class="line-added">+   // worst case, that all available registers are used.</span>
<span class="line-added">+   for (uint i = TypeFunc::Parms+1; i &lt; domain-&gt;cnt(); i++) {</span>
<span class="line-added">+     if (domain-&gt;field_at(i) == Type::HALF) {</span>
<span class="line-added">+       slow_call-&gt;init_req(i, top());</span>
<span class="line-added">+       handler_call-&gt;init_req(i+1, top());</span>
<span class="line-added">+       continue;</span>
<span class="line-added">+     }</span>
<span class="line-added">+     Node* proj = transform_later(new ProjNode(call, i));</span>
<span class="line-added">+     slow_call-&gt;init_req(i, proj);</span>
<span class="line-added">+     handler_call-&gt;init_req(i+1, proj);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   // We can safepoint at that new call</span>
<span class="line-added">+   slow_call-&gt;copy_call_debug_info(&amp;_igvn, call);</span>
<span class="line-added">+   transform_later(slow_call);</span>
<span class="line-added">+   transform_later(handler_call);</span>
<span class="line-added">+ </span>
<span class="line-added">+   Node* handler_ctl = transform_later(new ProjNode(handler_call, TypeFunc::Control));</span>
<span class="line-added">+   rawmem = transform_later(new ProjNode(handler_call, TypeFunc::Memory));</span>
<span class="line-added">+   Node* slowpath_false_res = transform_later(new ProjNode(handler_call, TypeFunc::Parms));</span>
<span class="line-added">+ </span>
<span class="line-added">+   MergeMemNode* slowpath_false_mem = MergeMemNode::make(mem);</span>
<span class="line-added">+   slowpath_false_mem-&gt;set_memory_at(Compile::AliasIdxRaw, rawmem);</span>
<span class="line-added">+   transform_later(slowpath_false_mem);</span>
<span class="line-added">+ </span>
<span class="line-added">+   Node* r = new RegionNode(4);</span>
<span class="line-added">+   Node* mem_phi = new PhiNode(r, Type::MEMORY, TypePtr::BOTTOM);</span>
<span class="line-added">+   Node* io_phi = new PhiNode(r, Type::ABIO);</span>
<span class="line-added">+   Node* res_phi = new PhiNode(r, TypeInstPtr::BOTTOM);</span>
<span class="line-added">+ </span>
<span class="line-added">+   r-&gt;init_req(1, no_allocation_ctl);</span>
<span class="line-added">+   mem_phi-&gt;init_req(1, mem);</span>
<span class="line-added">+   io_phi-&gt;init_req(1, io);</span>
<span class="line-added">+   res_phi-&gt;init_req(1, no_allocation_res);</span>
<span class="line-added">+   r-&gt;init_req(2, slow_norm);</span>
<span class="line-added">+   mem_phi-&gt;init_req(2, slow_mem);</span>
<span class="line-added">+   io_phi-&gt;init_req(2, slow_io);</span>
<span class="line-added">+   res_phi-&gt;init_req(2, slow_res);</span>
<span class="line-added">+   r-&gt;init_req(3, handler_ctl);</span>
<span class="line-added">+   mem_phi-&gt;init_req(3, slowpath_false_mem);</span>
<span class="line-added">+   io_phi-&gt;init_req(3, io);</span>
<span class="line-added">+   res_phi-&gt;init_req(3, slowpath_false_res);</span>
<span class="line-added">+ </span>
<span class="line-added">+   transform_later(r);</span>
<span class="line-added">+   transform_later(mem_phi);</span>
<span class="line-added">+   transform_later(io_phi);</span>
<span class="line-added">+   transform_later(res_phi);</span>
<span class="line-added">+ </span>
<span class="line-added">+   assert(projs-&gt;nb_resproj == 1, &quot;unexpected number of results&quot;);</span>
<span class="line-added">+   _igvn.replace_in_uses(projs-&gt;fallthrough_catchproj, r);</span>
<span class="line-added">+   _igvn.replace_in_uses(projs-&gt;fallthrough_memproj, mem_phi);</span>
<span class="line-added">+   _igvn.replace_in_uses(projs-&gt;fallthrough_ioproj, io_phi);</span>
<span class="line-added">+   _igvn.replace_in_uses(projs-&gt;resproj[0], res_phi);</span>
<span class="line-added">+   _igvn.replace_in_uses(projs-&gt;catchall_catchproj, ex_r);</span>
<span class="line-added">+   _igvn.replace_in_uses(projs-&gt;catchall_memproj, ex_mem_phi);</span>
<span class="line-added">+   _igvn.replace_in_uses(projs-&gt;catchall_ioproj, ex_io_phi);</span>
<span class="line-added">+ </span>
<span class="line-added">+   _igvn.replace_node(ctl, projs-&gt;fallthrough_catchproj);</span>
<span class="line-added">+   _igvn.replace_node(mem, projs-&gt;fallthrough_memproj);</span>
<span class="line-added">+   _igvn.replace_node(io, projs-&gt;fallthrough_ioproj);</span>
<span class="line-added">+   _igvn.replace_node(res, projs-&gt;resproj[0]);</span>
<span class="line-added">+   _igvn.replace_node(ex_ctl, projs-&gt;catchall_catchproj);</span>
<span class="line-added">+   _igvn.replace_node(ex_mem, projs-&gt;catchall_memproj);</span>
<span class="line-added">+   _igvn.replace_node(ex_io, projs-&gt;catchall_ioproj);</span>
<span class="line-added">+  }</span>
<span class="line-added">+ </span>
  void PhaseMacroExpand::expand_subtypecheck_node(SubTypeCheckNode *check) {
    assert(check-&gt;in(SubTypeCheckNode::Control) == NULL, &quot;should be pinned&quot;);
    Node* bol = check-&gt;unique_out();
    Node* obj_or_subklass = check-&gt;in(SubTypeCheckNode::ObjOrSubKlass);
    Node* superklass = check-&gt;in(SubTypeCheckNode::SuperKlass);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2564,11 ***</span>
      Node* subklass = NULL;
      if (_igvn.type(obj_or_subklass)-&gt;isa_klassptr()) {
        subklass = obj_or_subklass;
      } else {
        Node* k_adr = basic_plus_adr(obj_or_subklass, oopDesc::klass_offset_in_bytes());
<span class="line-modified">!       subklass = _igvn.transform(LoadKlassNode::make(_igvn, NULL, C-&gt;immutable_memory(), k_adr, TypeInstPtr::KLASS));</span>
      }
  
      Node* not_subtype_ctrl = Phase::gen_subtype_check(subklass, superklass, &amp;ctrl, NULL, _igvn);
  
      _igvn.replace_input_of(iff, 0, C-&gt;top());
<span class="line-new-header">--- 2878,11 ---</span>
      Node* subklass = NULL;
      if (_igvn.type(obj_or_subklass)-&gt;isa_klassptr()) {
        subklass = obj_or_subklass;
      } else {
        Node* k_adr = basic_plus_adr(obj_or_subklass, oopDesc::klass_offset_in_bytes());
<span class="line-modified">!       subklass = _igvn.transform(LoadKlassNode::make(_igvn, NULL, C-&gt;immutable_memory(), k_adr, TypeInstPtr::KLASS, TypeKlassPtr::OBJECT));</span>
      }
  
      Node* not_subtype_ctrl = Phase::gen_subtype_check(subklass, superklass, &amp;ctrl, NULL, _igvn);
  
      _igvn.replace_input_of(iff, 0, C-&gt;top());
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2620,13 ***</span>
        switch (n-&gt;class_id()) {
        case Node::Class_Allocate:
        case Node::Class_AllocateArray:
          success = eliminate_allocate_node(n-&gt;as_Allocate());
          break;
<span class="line-modified">!       case Node::Class_CallStaticJava:</span>
<span class="line-modified">!         success = eliminate_boxing_node(n-&gt;as_CallStaticJava());</span>
          break;
        case Node::Class_Lock:
        case Node::Class_Unlock:
          assert(!n-&gt;as_AbstractLock()-&gt;is_eliminated(), &quot;sanity&quot;);
          _has_locks = true;
          break;
<span class="line-new-header">--- 2934,17 ---</span>
        switch (n-&gt;class_id()) {
        case Node::Class_Allocate:
        case Node::Class_AllocateArray:
          success = eliminate_allocate_node(n-&gt;as_Allocate());
          break;
<span class="line-modified">!       case Node::Class_CallStaticJava: {</span>
<span class="line-modified">!         CallStaticJavaNode* call = n-&gt;as_CallStaticJava();</span>
<span class="line-added">+         if (!call-&gt;method()-&gt;is_method_handle_intrinsic()) {</span>
<span class="line-added">+           success = eliminate_boxing_node(n-&gt;as_CallStaticJava());</span>
<span class="line-added">+         }</span>
          break;
<span class="line-added">+       }</span>
        case Node::Class_Lock:
        case Node::Class_Unlock:
          assert(!n-&gt;as_AbstractLock()-&gt;is_eliminated(), &quot;sanity&quot;);
          _has_locks = true;
          break;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2668,14 ***</span>
          // Remove it from macro list and put on IGVN worklist to optimize.
          C-&gt;remove_macro_node(n);
          _igvn._worklist.push(n);
          success = true;
        } else if (n-&gt;Opcode() == Op_CallStaticJava) {
<span class="line-modified">!         // Remove it from macro list and put on IGVN worklist to optimize.</span>
<span class="line-modified">!         C-&gt;remove_macro_node(n);</span>
<span class="line-modified">!         _igvn._worklist.push(n);</span>
<span class="line-modified">!         success = true;</span>
        } else if (n-&gt;Opcode() == Op_Opaque1 || n-&gt;Opcode() == Op_Opaque2) {
          _igvn.replace_node(n, n-&gt;in(1));
          success = true;
  #if INCLUDE_RTM_OPT
        } else if ((n-&gt;Opcode() == Op_Opaque3) &amp;&amp; ((Opaque3Node*)n)-&gt;rtm_opt()) {
<span class="line-new-header">--- 2986,17 ---</span>
          // Remove it from macro list and put on IGVN worklist to optimize.
          C-&gt;remove_macro_node(n);
          _igvn._worklist.push(n);
          success = true;
        } else if (n-&gt;Opcode() == Op_CallStaticJava) {
<span class="line-modified">!         CallStaticJavaNode* call = n-&gt;as_CallStaticJava();</span>
<span class="line-modified">!         if (!call-&gt;method()-&gt;is_method_handle_intrinsic()) {</span>
<span class="line-modified">!           // Remove it from macro list and put on IGVN worklist to optimize.</span>
<span class="line-modified">!           C-&gt;remove_macro_node(n);</span>
<span class="line-added">+           _igvn._worklist.push(n);</span>
<span class="line-added">+           success = true;</span>
<span class="line-added">+         }</span>
        } else if (n-&gt;Opcode() == Op_Opaque1 || n-&gt;Opcode() == Op_Opaque2) {
          _igvn.replace_node(n, n-&gt;in(1));
          success = true;
  #if INCLUDE_RTM_OPT
        } else if ((n-&gt;Opcode() == Op_Opaque3) &amp;&amp; ((Opaque3Node*)n)-&gt;rtm_opt()) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2765,10 ***</span>
<span class="line-new-header">--- 3086,15 ---</span>
        break;
      case Node::Class_SubTypeCheck:
        expand_subtypecheck_node(n-&gt;as_SubTypeCheck());
        assert(C-&gt;macro_count() == (old_macro_count - 1), &quot;expansion must have deleted one node from macro list&quot;);
        break;
<span class="line-added">+     case Node::Class_CallStaticJava:</span>
<span class="line-added">+       expand_mh_intrinsic_return(n-&gt;as_CallStaticJava());</span>
<span class="line-added">+       C-&gt;remove_macro_node(n);</span>
<span class="line-added">+       assert(C-&gt;macro_count() == (old_macro_count - 1), &quot;expansion must have deleted one node from macro list&quot;);</span>
<span class="line-added">+       break;</span>
      default:
        assert(false, &quot;unknown node type in macro list&quot;);
      }
      assert(C-&gt;macro_count() &lt; macro_count, &quot;must have deleted a node from macro list&quot;);
      if (C-&gt;failing())  return true;
</pre>
<center><a href="graphKit.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="memnode.cpp.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>