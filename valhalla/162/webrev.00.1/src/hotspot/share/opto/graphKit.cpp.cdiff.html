<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff src/hotspot/share/opto/graphKit.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="compile.hpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macro.cpp.cdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/graphKit.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 21,10 ***</span>
<span class="line-new-header">--- 21,12 ---</span>
   * questions.
   *
   */
  
  #include &quot;precompiled.hpp&quot;
<span class="line-added">+ #include &quot;ci/ciFlatArrayKlass.hpp&quot;</span>
<span class="line-added">+ #include &quot;ci/ciInlineKlass.hpp&quot;</span>
  #include &quot;ci/ciUtilities.hpp&quot;
  #include &quot;classfile/javaClasses.hpp&quot;
  #include &quot;compiler/compileLog.hpp&quot;
  #include &quot;gc/shared/barrierSet.hpp&quot;
  #include &quot;gc/shared/c2/barrierSetC2.hpp&quot;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 33,13 ***</span>
<span class="line-new-header">--- 35,15 ---</span>
  #include &quot;opto/addnode.hpp&quot;
  #include &quot;opto/castnode.hpp&quot;
  #include &quot;opto/convertnode.hpp&quot;
  #include &quot;opto/graphKit.hpp&quot;
  #include &quot;opto/idealKit.hpp&quot;
<span class="line-added">+ #include &quot;opto/inlinetypenode.hpp&quot;</span>
  #include &quot;opto/intrinsicnode.hpp&quot;
  #include &quot;opto/locknode.hpp&quot;
  #include &quot;opto/machnode.hpp&quot;
<span class="line-added">+ #include &quot;opto/narrowptrnode.hpp&quot;</span>
  #include &quot;opto/opaquenode.hpp&quot;
  #include &quot;opto/parse.hpp&quot;
  #include &quot;opto/rootnode.hpp&quot;
  #include &quot;opto/runtime.hpp&quot;
  #include &quot;opto/subtypenode.hpp&quot;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 48,19 ***</span>
  #include &quot;utilities/bitMap.inline.hpp&quot;
  #include &quot;utilities/powerOfTwo.hpp&quot;
  
  //----------------------------GraphKit-----------------------------------------
  // Main utility constructor.
<span class="line-modified">! GraphKit::GraphKit(JVMState* jvms)</span>
    : Phase(Phase::Parser),
      _env(C-&gt;env()),
<span class="line-modified">!     _gvn(*C-&gt;initial_gvn()),</span>
      _barrier_set(BarrierSet::barrier_set()-&gt;barrier_set_c2())
  {
    _exceptions = jvms-&gt;map()-&gt;next_exception();
    if (_exceptions != NULL)  jvms-&gt;map()-&gt;set_next_exception(NULL);
    set_jvms(jvms);
  }
  
  // Private constructor for parser.
  GraphKit::GraphKit()
    : Phase(Phase::Parser),
<span class="line-new-header">--- 52,27 ---</span>
  #include &quot;utilities/bitMap.inline.hpp&quot;
  #include &quot;utilities/powerOfTwo.hpp&quot;
  
  //----------------------------GraphKit-----------------------------------------
  // Main utility constructor.
<span class="line-modified">! GraphKit::GraphKit(JVMState* jvms, PhaseGVN* gvn)</span>
    : Phase(Phase::Parser),
      _env(C-&gt;env()),
<span class="line-modified">!     _gvn((gvn != NULL) ? *gvn : *C-&gt;initial_gvn()),</span>
      _barrier_set(BarrierSet::barrier_set()-&gt;barrier_set_c2())
  {
<span class="line-added">+   assert(gvn == NULL || !gvn-&gt;is_IterGVN() || gvn-&gt;is_IterGVN()-&gt;delay_transform(), &quot;delay transform should be enabled&quot;);</span>
    _exceptions = jvms-&gt;map()-&gt;next_exception();
    if (_exceptions != NULL)  jvms-&gt;map()-&gt;set_next_exception(NULL);
    set_jvms(jvms);
<span class="line-added">+ #ifdef ASSERT</span>
<span class="line-added">+   if (_gvn.is_IterGVN() != NULL) {</span>
<span class="line-added">+     assert(_gvn.is_IterGVN()-&gt;delay_transform(), &quot;Transformation must be delayed if IterGVN is used&quot;);</span>
<span class="line-added">+     // Save the initial size of _for_igvn worklist for verification (see ~GraphKit)</span>
<span class="line-added">+     _worklist_size = _gvn.C-&gt;for_igvn()-&gt;size();</span>
<span class="line-added">+   }</span>
<span class="line-added">+ #endif</span>
  }
  
  // Private constructor for parser.
  GraphKit::GraphKit()
    : Phase(Phase::Parser),
</pre>
<hr />
<pre>
<span class="line-old-header">*** 825,20 ***</span>
    ciMethod* cur_method = jvms-&gt;method();
    int       cur_bci   = jvms-&gt;bci();
    if (cur_method != NULL &amp;&amp; cur_bci != InvocationEntryBci) {
      Bytecodes::Code code = cur_method-&gt;java_code_at_bci(cur_bci);
      return Interpreter::bytecode_should_reexecute(code) ||
<span class="line-modified">!            (is_anewarray &amp;&amp; code == Bytecodes::_multianewarray);</span>
      // Reexecute _multianewarray bytecode which was replaced with
      // sequence of [a]newarray. See Parse::do_multianewarray().
      //
      // Note: interpreter should not have it set since this optimization
      // is limited by dimensions and guarded by flag so in some cases
      // multianewarray() runtime calls will be generated and
      // the bytecode should not be reexecutes (stack will not be reset).
<span class="line-modified">!   } else</span>
      return false;
  }
  
  // Helper function for adding JVMState and debug information to node
  void GraphKit::add_safepoint_edges(SafePointNode* call, bool must_throw) {
    // Add the safepoint edges to the call (or other safepoint).
<span class="line-new-header">--- 837,21 ---</span>
    ciMethod* cur_method = jvms-&gt;method();
    int       cur_bci   = jvms-&gt;bci();
    if (cur_method != NULL &amp;&amp; cur_bci != InvocationEntryBci) {
      Bytecodes::Code code = cur_method-&gt;java_code_at_bci(cur_bci);
      return Interpreter::bytecode_should_reexecute(code) ||
<span class="line-modified">!            (is_anewarray &amp;&amp; (code == Bytecodes::_multianewarray));</span>
      // Reexecute _multianewarray bytecode which was replaced with
      // sequence of [a]newarray. See Parse::do_multianewarray().
      //
      // Note: interpreter should not have it set since this optimization
      // is limited by dimensions and guarded by flag so in some cases
      // multianewarray() runtime calls will be generated and
      // the bytecode should not be reexecutes (stack will not be reset).
<span class="line-modified">!   } else {</span>
      return false;
<span class="line-added">+   }</span>
  }
  
  // Helper function for adding JVMState and debug information to node
  void GraphKit::add_safepoint_edges(SafePointNode* call, bool must_throw) {
    // Add the safepoint edges to the call (or other safepoint).
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1078,10 ***</span>
<span class="line-new-header">--- 1091,19 ---</span>
        assert(rsize == 1, &quot;&quot;);
        depth = rsize - inputs;
      }
      break;
  
<span class="line-added">+   case Bytecodes::_withfield: {</span>
<span class="line-added">+     bool ignored_will_link;</span>
<span class="line-added">+     ciField* field = method()-&gt;get_field_at_bci(bci(), ignored_will_link);</span>
<span class="line-added">+     int      size  = field-&gt;type()-&gt;size();</span>
<span class="line-added">+     inputs = size+1;</span>
<span class="line-added">+     depth = rsize - inputs;</span>
<span class="line-added">+     break;</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
    case Bytecodes::_ireturn:
    case Bytecodes::_lreturn:
    case Bytecodes::_freturn:
    case Bytecodes::_dreturn:
    case Bytecodes::_areturn:
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1160,11 ***</span>
  Node* GraphKit::load_object_klass(Node* obj) {
    // Special-case a fresh allocation to avoid building nodes:
    Node* akls = AllocateNode::Ideal_klass(obj, &amp;_gvn);
    if (akls != NULL)  return akls;
    Node* k_adr = basic_plus_adr(obj, oopDesc::klass_offset_in_bytes());
<span class="line-modified">!   return _gvn.transform(LoadKlassNode::make(_gvn, NULL, immutable_memory(), k_adr, TypeInstPtr::KLASS));</span>
  }
  
  //-------------------------load_array_length-----------------------------------
  Node* GraphKit::load_array_length(Node* array) {
    // Special-case a fresh allocation to avoid building nodes:
<span class="line-new-header">--- 1182,11 ---</span>
  Node* GraphKit::load_object_klass(Node* obj) {
    // Special-case a fresh allocation to avoid building nodes:
    Node* akls = AllocateNode::Ideal_klass(obj, &amp;_gvn);
    if (akls != NULL)  return akls;
    Node* k_adr = basic_plus_adr(obj, oopDesc::klass_offset_in_bytes());
<span class="line-modified">!   return _gvn.transform(LoadKlassNode::make(_gvn, NULL, immutable_memory(), k_adr, TypeInstPtr::KLASS, TypeKlassPtr::OBJECT));</span>
  }
  
  //-------------------------load_array_length-----------------------------------
  Node* GraphKit::load_array_length(Node* array) {
    // Special-case a fresh allocation to avoid building nodes:
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1203,10 ***</span>
<span class="line-new-header">--- 1225,11 ---</span>
    // Construct NULL check
    Node *chk = NULL;
    switch(type) {
      case T_LONG   : chk = new CmpLNode(value, _gvn.zerocon(T_LONG)); break;
      case T_INT    : chk = new CmpINode(value, _gvn.intcon(0)); break;
<span class="line-added">+     case T_INLINE_TYPE : // fall through</span>
      case T_ARRAY  : // fall through
        type = T_OBJECT;  // simplify further tests
      case T_OBJECT : {
        const Type *t = _gvn.type( value );
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1374,23 ***</span>
<span class="line-new-header">--- 1397,47 ---</span>
    }
  
    return value;
  }
  
<span class="line-added">+ Node* GraphKit::null2default(Node* value, ciInlineKlass* vk) {</span>
<span class="line-added">+   assert(!vk-&gt;is_scalarizable(), &quot;Should only be used for non scalarizable inline klasses&quot;);</span>
<span class="line-added">+   Node* null_ctl = top();</span>
<span class="line-added">+   value = null_check_oop(value, &amp;null_ctl);</span>
<span class="line-added">+   if (!null_ctl-&gt;is_top()) {</span>
<span class="line-added">+     // Return default value if oop is null</span>
<span class="line-added">+     Node* region = new RegionNode(3);</span>
<span class="line-added">+     region-&gt;init_req(1, control());</span>
<span class="line-added">+     region-&gt;init_req(2, null_ctl);</span>
<span class="line-added">+     value = PhiNode::make(region, value, TypeInstPtr::make(TypePtr::BotPTR, vk));</span>
<span class="line-added">+     value-&gt;set_req(2, InlineTypeNode::default_oop(gvn(), vk));</span>
<span class="line-added">+     set_control(gvn().transform(region));</span>
<span class="line-added">+     value = gvn().transform(value);</span>
<span class="line-added">+   }</span>
<span class="line-added">+   return value;</span>
<span class="line-added">+ }</span>
  
  //------------------------------cast_not_null----------------------------------
  // Cast obj to not-null on this path
  Node* GraphKit::cast_not_null(Node* obj, bool do_replace_in_map) {
<span class="line-added">+   if (obj-&gt;is_InlineType()) {</span>
<span class="line-added">+     return obj;</span>
<span class="line-added">+   }</span>
    const Type *t = _gvn.type(obj);
    const Type *t_not_null = t-&gt;join_speculative(TypePtr::NOTNULL);
    // Object is already not-null?
    if( t == t_not_null ) return obj;
  
    Node *cast = new CastPPNode(obj,t_not_null);
    cast-&gt;init_req(0, control());
    cast = _gvn.transform( cast );
  
<span class="line-added">+   if (t-&gt;is_inlinetypeptr() &amp;&amp; t-&gt;inline_klass()-&gt;is_scalarizable()) {</span>
<span class="line-added">+     // Scalarize inline type now that we know it&#39;s non-null</span>
<span class="line-added">+     cast = InlineTypeNode::make_from_oop(this, cast, t-&gt;inline_klass())-&gt;as_ptr(&amp;gvn());</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
    // Scan for instances of &#39;obj&#39; in the current JVM mapping.
    // These instances are known to be not-null after the test.
    if (do_replace_in_map)
      replace_in_map(obj, cast);
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1510,11 ***</span>
      ld = LoadDNode::make_atomic(ctl, mem, adr, adr_type, t, mo, control_dependency, unaligned, mismatched, unsafe, barrier_data);
    } else {
      ld = LoadNode::make(_gvn, ctl, mem, adr, adr_type, t, bt, mo, control_dependency, unaligned, mismatched, unsafe, barrier_data);
    }
    ld = _gvn.transform(ld);
<span class="line-modified">!   if (((bt == T_OBJECT) &amp;&amp; C-&gt;do_escape_analysis()) || C-&gt;eliminate_boxing()) {</span>
      // Improve graph before escape analysis and boxing elimination.
      record_for_igvn(ld);
    }
    return ld;
  }
<span class="line-new-header">--- 1557,12 ---</span>
      ld = LoadDNode::make_atomic(ctl, mem, adr, adr_type, t, mo, control_dependency, unaligned, mismatched, unsafe, barrier_data);
    } else {
      ld = LoadNode::make(_gvn, ctl, mem, adr, adr_type, t, bt, mo, control_dependency, unaligned, mismatched, unsafe, barrier_data);
    }
    ld = _gvn.transform(ld);
<span class="line-modified">! </span>
<span class="line-added">+   if (((bt == T_OBJECT || bt == T_INLINE_TYPE) &amp;&amp; C-&gt;do_escape_analysis()) || C-&gt;eliminate_boxing()) {</span>
      // Improve graph before escape analysis and boxing elimination.
      record_for_igvn(ld);
    }
    return ld;
  }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1561,11 ***</span>
                                  Node* adr,
                                  const TypePtr* adr_type,
                                  Node* val,
                                  const Type* val_type,
                                  BasicType bt,
<span class="line-modified">!                                 DecoratorSet decorators) {</span>
    // Transformation of a value which could be NULL pointer (CastPP #NULL)
    // could be delayed during Parse (for example, in adjust_map_after_if()).
    // Execute transformation here to avoid barrier generation in such case.
    if (_gvn.type(val) == TypePtr::NULL_PTR) {
      val = _gvn.makecon(TypePtr::NULL_PTR);
<span class="line-new-header">--- 1609,12 ---</span>
                                  Node* adr,
                                  const TypePtr* adr_type,
                                  Node* val,
                                  const Type* val_type,
                                  BasicType bt,
<span class="line-modified">!                                 DecoratorSet decorators,</span>
<span class="line-added">+                                 bool safe_for_replace) {</span>
    // Transformation of a value which could be NULL pointer (CastPP #NULL)
    // could be delayed during Parse (for example, in adjust_map_after_if()).
    // Execute transformation here to avoid barrier generation in such case.
    if (_gvn.type(val) == TypePtr::NULL_PTR) {
      val = _gvn.makecon(TypePtr::NULL_PTR);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1574,10 ***</span>
<span class="line-new-header">--- 1623,17 ---</span>
    if (stopped()) {
      return top(); // Dead path ?
    }
  
    assert(val != NULL, &quot;not dead path&quot;);
<span class="line-added">+   if (val-&gt;is_InlineType()) {</span>
<span class="line-added">+     // Store to non-flattened field. Buffer the inline type and make sure</span>
<span class="line-added">+     // the store is re-executed if the allocation triggers deoptimization.</span>
<span class="line-added">+     PreserveReexecuteState preexecs(this);</span>
<span class="line-added">+     jvms()-&gt;set_should_reexecute(true);</span>
<span class="line-added">+     val = val-&gt;as_InlineType()-&gt;buffer(this, safe_for_replace);</span>
<span class="line-added">+   }</span>
  
    C2AccessValuePtr addr(adr, adr_type);
    C2AccessValue value(val, val_type);
    C2ParseAccess access(this, decorators | C2_WRITE_ACCESS, bt, obj, addr);
    if (access.is_raw()) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1590,17 ***</span>
  Node* GraphKit::access_load_at(Node* obj,   // containing obj
                                 Node* adr,   // actual adress to store val at
                                 const TypePtr* adr_type,
                                 const Type* val_type,
                                 BasicType bt,
<span class="line-modified">!                                DecoratorSet decorators) {</span>
    if (stopped()) {
      return top(); // Dead path ?
    }
  
    C2AccessValuePtr addr(adr, adr_type);
<span class="line-modified">!   C2ParseAccess access(this, decorators | C2_READ_ACCESS, bt, obj, addr);</span>
    if (access.is_raw()) {
      return _barrier_set-&gt;BarrierSetC2::load_at(access, val_type);
    } else {
      return _barrier_set-&gt;load_at(access, val_type);
    }
<span class="line-new-header">--- 1646,18 ---</span>
  Node* GraphKit::access_load_at(Node* obj,   // containing obj
                                 Node* adr,   // actual adress to store val at
                                 const TypePtr* adr_type,
                                 const Type* val_type,
                                 BasicType bt,
<span class="line-modified">!                                DecoratorSet decorators,</span>
<span class="line-added">+                                Node* ctl) {</span>
    if (stopped()) {
      return top(); // Dead path ?
    }
  
    C2AccessValuePtr addr(adr, adr_type);
<span class="line-modified">!   C2ParseAccess access(this, decorators | C2_READ_ACCESS, bt, obj, addr, ctl);</span>
    if (access.is_raw()) {
      return _barrier_set-&gt;BarrierSetC2::load_at(access, val_type);
    } else {
      return _barrier_set-&gt;load_at(access, val_type);
    }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1694,18 ***</span>
    } else {
      return _barrier_set-&gt;atomic_add_at(access, new_val, value_type);
    }
  }
  
<span class="line-modified">! void GraphKit::access_clone(Node* src, Node* dst, Node* size, bool is_array) {</span>
<span class="line-modified">!   return _barrier_set-&gt;clone(this, src, dst, size, is_array);</span>
  }
  
  //-------------------------array_element_address-------------------------
  Node* GraphKit::array_element_address(Node* ary, Node* idx, BasicType elembt,
                                        const TypeInt* sizetype, Node* ctrl) {
    uint shift  = exact_log2(type2aelembytes(elembt));
    uint header = arrayOopDesc::base_offset_in_bytes(elembt);
  
    // short-circuit a common case (saves lots of confusing waste motion)
    jint idx_con = find_int_con(idx, -1);
    if (idx_con &gt;= 0) {
<span class="line-new-header">--- 1751,23 ---</span>
    } else {
      return _barrier_set-&gt;atomic_add_at(access, new_val, value_type);
    }
  }
  
<span class="line-modified">! void GraphKit::access_clone(Node* src_base, Node* dst_base, Node* countx, bool is_array) {</span>
<span class="line-modified">!   return _barrier_set-&gt;clone(this, src_base, dst_base, countx, is_array);</span>
  }
  
  //-------------------------array_element_address-------------------------
  Node* GraphKit::array_element_address(Node* ary, Node* idx, BasicType elembt,
                                        const TypeInt* sizetype, Node* ctrl) {
    uint shift  = exact_log2(type2aelembytes(elembt));
<span class="line-added">+   ciKlass* arytype_klass = _gvn.type(ary)-&gt;is_aryptr()-&gt;klass();</span>
<span class="line-added">+   if (arytype_klass != NULL &amp;&amp; arytype_klass-&gt;is_flat_array_klass()) {</span>
<span class="line-added">+     ciFlatArrayKlass* vak = arytype_klass-&gt;as_flat_array_klass();</span>
<span class="line-added">+     shift = vak-&gt;log2_element_size();</span>
<span class="line-added">+   }</span>
    uint header = arrayOopDesc::base_offset_in_bytes(elembt);
  
    // short-circuit a common case (saves lots of confusing waste motion)
    jint idx_con = find_int_con(idx, -1);
    if (idx_con &gt;= 0) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1722,26 ***</span>
  
  //-------------------------load_array_element-------------------------
  Node* GraphKit::load_array_element(Node* ctl, Node* ary, Node* idx, const TypeAryPtr* arytype) {
    const Type* elemtype = arytype-&gt;elem();
    BasicType elembt = elemtype-&gt;array_element_basic_type();
    Node* adr = array_element_address(ary, idx, elembt, arytype-&gt;size());
    if (elembt == T_NARROWOOP) {
      elembt = T_OBJECT; // To satisfy switch in LoadNode::make()
    }
    Node* ld = make_load(ctl, adr, elemtype, elembt, arytype, MemNode::unordered);
    return ld;
  }
  
  //-------------------------set_arguments_for_java_call-------------------------
  // Arguments (pre-popped from the stack) are taken from the JVMS.
<span class="line-modified">! void GraphKit::set_arguments_for_java_call(CallJavaNode* call) {</span>
<span class="line-modified">!   // Add the call arguments:</span>
<span class="line-modified">!   uint nargs = call-&gt;method()-&gt;arg_size();</span>
<span class="line-modified">!   for (uint i = 0; i &lt; nargs; i++) {</span>
<span class="line-modified">!     Node* arg = argument(i);</span>
<span class="line-modified">!     call-&gt;init_req(i + TypeFunc::Parms, arg);</span>
    }
  }
  
  //---------------------------set_edges_for_java_call---------------------------
  // Connect a newly created call into the current JVMS.
<span class="line-new-header">--- 1784,61 ---</span>
  
  //-------------------------load_array_element-------------------------
  Node* GraphKit::load_array_element(Node* ctl, Node* ary, Node* idx, const TypeAryPtr* arytype) {
    const Type* elemtype = arytype-&gt;elem();
    BasicType elembt = elemtype-&gt;array_element_basic_type();
<span class="line-added">+   assert(elembt != T_INLINE_TYPE, &quot;inline types are not supported by this method&quot;);</span>
    Node* adr = array_element_address(ary, idx, elembt, arytype-&gt;size());
    if (elembt == T_NARROWOOP) {
      elembt = T_OBJECT; // To satisfy switch in LoadNode::make()
    }
    Node* ld = make_load(ctl, adr, elemtype, elembt, arytype, MemNode::unordered);
    return ld;
  }
  
  //-------------------------set_arguments_for_java_call-------------------------
  // Arguments (pre-popped from the stack) are taken from the JVMS.
<span class="line-modified">! void GraphKit::set_arguments_for_java_call(CallJavaNode* call, bool is_late_inline) {</span>
<span class="line-modified">!   PreserveReexecuteState preexecs(this);</span>
<span class="line-modified">!   if (EnableValhalla) {</span>
<span class="line-modified">!     // Make sure the call is re-executed, if buffering of inline type arguments triggers deoptimization</span>
<span class="line-modified">!     jvms()-&gt;set_should_reexecute(true);</span>
<span class="line-modified">!     int arg_size = method()-&gt;get_declared_signature_at_bci(bci())-&gt;arg_size_for_bc(java_bc());</span>
<span class="line-added">+     inc_sp(arg_size);</span>
<span class="line-added">+   }</span>
<span class="line-added">+   // Add the call arguments</span>
<span class="line-added">+   const TypeTuple* domain = call-&gt;tf()-&gt;domain_sig();</span>
<span class="line-added">+   ExtendedSignature sig_cc = ExtendedSignature(call-&gt;method()-&gt;get_sig_cc(), SigEntryFilter());</span>
<span class="line-added">+   uint nargs = domain-&gt;cnt();</span>
<span class="line-added">+   for (uint i = TypeFunc::Parms, idx = TypeFunc::Parms; i &lt; nargs; i++) {</span>
<span class="line-added">+     Node* arg = argument(i-TypeFunc::Parms);</span>
<span class="line-added">+     const Type* t = domain-&gt;field_at(i);</span>
<span class="line-added">+     if (call-&gt;method()-&gt;has_scalarized_args() &amp;&amp; t-&gt;is_inlinetypeptr() &amp;&amp; !t-&gt;maybe_null()) {</span>
<span class="line-added">+       // We don&#39;t pass inline type arguments by reference but instead pass each field of the inline type</span>
<span class="line-added">+       InlineTypeNode* vt = arg-&gt;as_InlineType();</span>
<span class="line-added">+       vt-&gt;pass_fields(this, call, sig_cc, idx);</span>
<span class="line-added">+       // If an inline type argument is passed as fields, attach the Method* to the call site</span>
<span class="line-added">+       // to be able to access the extended signature later via attached_method_before_pc().</span>
<span class="line-added">+       // For example, see CompiledMethod::preserve_callee_argument_oops().</span>
<span class="line-added">+       call-&gt;set_override_symbolic_info(true);</span>
<span class="line-added">+       continue;</span>
<span class="line-added">+     } else if (arg-&gt;is_InlineType()) {</span>
<span class="line-added">+       // Pass inline type argument via oop to callee</span>
<span class="line-added">+       arg = arg-&gt;as_InlineType()-&gt;buffer(this);</span>
<span class="line-added">+       if (!is_late_inline) {</span>
<span class="line-added">+         arg = arg-&gt;as_InlineTypePtr()-&gt;get_oop();</span>
<span class="line-added">+       }</span>
<span class="line-added">+     }</span>
<span class="line-added">+     call-&gt;init_req(idx++, arg);</span>
<span class="line-added">+     // Skip reserved arguments</span>
<span class="line-added">+     BasicType bt = t-&gt;basic_type();</span>
<span class="line-added">+     while (SigEntry::next_is_reserved(sig_cc, bt, true)) {</span>
<span class="line-added">+       call-&gt;init_req(idx++, top());</span>
<span class="line-added">+       if (type2size[bt] == 2) {</span>
<span class="line-added">+         call-&gt;init_req(idx++, top());</span>
<span class="line-added">+       }</span>
<span class="line-added">+     }</span>
    }
  }
  
  //---------------------------set_edges_for_java_call---------------------------
  // Connect a newly created call into the current JVMS.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1775,17 ***</span>
  }
  
  Node* GraphKit::set_results_for_java_call(CallJavaNode* call, bool separate_io_proj, bool deoptimize) {
    if (stopped())  return top();  // maybe the call folded up?
  
<span class="line-removed">-   // Capture the return value, if any.</span>
<span class="line-removed">-   Node* ret;</span>
<span class="line-removed">-   if (call-&gt;method() == NULL ||</span>
<span class="line-removed">-       call-&gt;method()-&gt;return_type()-&gt;basic_type() == T_VOID)</span>
<span class="line-removed">-         ret = top();</span>
<span class="line-removed">-   else  ret = _gvn.transform(new ProjNode(call, TypeFunc::Parms));</span>
<span class="line-removed">- </span>
    // Note:  Since any out-of-line call can produce an exception,
    // we always insert an I_O projection from the call into the result.
  
    make_slow_call_ex(call, env()-&gt;Throwable_klass(), separate_io_proj, deoptimize);
  
<span class="line-new-header">--- 1872,10 ---</span>
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1794,10 ***</span>
<span class="line-new-header">--- 1884,29 ---</span>
      // through and exceptional paths, so replace the projections for
      // the fall through path.
      set_i_o(_gvn.transform( new ProjNode(call, TypeFunc::I_O) ));
      set_all_memory(_gvn.transform( new ProjNode(call, TypeFunc::Memory) ));
    }
<span class="line-added">+ </span>
<span class="line-added">+   // Capture the return value, if any.</span>
<span class="line-added">+   Node* ret;</span>
<span class="line-added">+   if (call-&gt;method() == NULL || call-&gt;method()-&gt;return_type()-&gt;basic_type() == T_VOID) {</span>
<span class="line-added">+     ret = top();</span>
<span class="line-added">+   } else if (call-&gt;tf()-&gt;returns_inline_type_as_fields()) {</span>
<span class="line-added">+     // Return of multiple values (inline type fields): we create a</span>
<span class="line-added">+     // InlineType node, each field is a projection from the call.</span>
<span class="line-added">+     ciInlineKlass* vk = call-&gt;method()-&gt;return_type()-&gt;as_inline_klass();</span>
<span class="line-added">+     const Array&lt;SigEntry&gt;* sig_array = vk-&gt;extended_sig();</span>
<span class="line-added">+     GrowableArray&lt;SigEntry&gt; sig = GrowableArray&lt;SigEntry&gt;(sig_array-&gt;length());</span>
<span class="line-added">+     sig.appendAll(sig_array);</span>
<span class="line-added">+     ExtendedSignature sig_cc = ExtendedSignature(&amp;sig, SigEntryFilter());</span>
<span class="line-added">+     uint base_input = TypeFunc::Parms + 1;</span>
<span class="line-added">+     ret = InlineTypeNode::make_from_multi(this, call, sig_cc, vk, base_input, false);</span>
<span class="line-added">+   } else {</span>
<span class="line-added">+     ret = _gvn.transform(new ProjNode(call, TypeFunc::Parms));</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
    return ret;
  }
  
  //--------------------set_predefined_input_for_runtime_call--------------------
  // Reading and setting the memory state is way conservative here.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1884,80 ***</span>
    Node* ex_ctl = top();
  
    SafePointNode* final_state = stop();
  
    // Find all the needed outputs of this call
<span class="line-modified">!   CallProjections callprojs;</span>
<span class="line-removed">-   call-&gt;extract_projections(&amp;callprojs, true);</span>
  
    Unique_Node_List wl;
    Node* init_mem = call-&gt;in(TypeFunc::Memory);
    Node* final_mem = final_state-&gt;in(TypeFunc::Memory);
    Node* final_ctl = final_state-&gt;in(TypeFunc::Control);
    Node* final_io = final_state-&gt;in(TypeFunc::I_O);
  
    // Replace all the old call edges with the edges from the inlining result
<span class="line-modified">!   if (callprojs.fallthrough_catchproj != NULL) {</span>
<span class="line-modified">!     C-&gt;gvn_replace_by(callprojs.fallthrough_catchproj, final_ctl);</span>
    }
<span class="line-modified">!   if (callprojs.fallthrough_memproj != NULL) {</span>
      if (final_mem-&gt;is_MergeMem()) {
        // Parser&#39;s exits MergeMem was not transformed but may be optimized
        final_mem = _gvn.transform(final_mem);
      }
<span class="line-modified">!     C-&gt;gvn_replace_by(callprojs.fallthrough_memproj,   final_mem);</span>
      add_mergemem_users_to_worklist(wl, final_mem);
    }
<span class="line-modified">!   if (callprojs.fallthrough_ioproj != NULL) {</span>
<span class="line-modified">!     C-&gt;gvn_replace_by(callprojs.fallthrough_ioproj,    final_io);</span>
    }
  
    // Replace the result with the new result if it exists and is used
<span class="line-modified">!   if (callprojs.resproj != NULL &amp;&amp; result != NULL) {</span>
<span class="line-modified">!     C-&gt;gvn_replace_by(callprojs.resproj, result);</span>
    }
  
    if (ejvms == NULL) {
      // No exception edges to simply kill off those paths
<span class="line-modified">!     if (callprojs.catchall_catchproj != NULL) {</span>
<span class="line-modified">!       C-&gt;gvn_replace_by(callprojs.catchall_catchproj, C-&gt;top());</span>
      }
<span class="line-modified">!     if (callprojs.catchall_memproj != NULL) {</span>
<span class="line-modified">!       C-&gt;gvn_replace_by(callprojs.catchall_memproj,   C-&gt;top());</span>
      }
<span class="line-modified">!     if (callprojs.catchall_ioproj != NULL) {</span>
<span class="line-modified">!       C-&gt;gvn_replace_by(callprojs.catchall_ioproj,    C-&gt;top());</span>
      }
      // Replace the old exception object with top
<span class="line-modified">!     if (callprojs.exobj != NULL) {</span>
<span class="line-modified">!       C-&gt;gvn_replace_by(callprojs.exobj, C-&gt;top());</span>
      }
    } else {
      GraphKit ekit(ejvms);
  
      // Load my combined exception state into the kit, with all phis transformed:
      SafePointNode* ex_map = ekit.combine_and_pop_all_exception_states();
      replaced_nodes_exception = ex_map-&gt;replaced_nodes();
  
      Node* ex_oop = ekit.use_exception_state(ex_map);
  
<span class="line-modified">!     if (callprojs.catchall_catchproj != NULL) {</span>
<span class="line-modified">!       C-&gt;gvn_replace_by(callprojs.catchall_catchproj, ekit.control());</span>
        ex_ctl = ekit.control();
      }
<span class="line-modified">!     if (callprojs.catchall_memproj != NULL) {</span>
        Node* ex_mem = ekit.reset_memory();
<span class="line-modified">!       C-&gt;gvn_replace_by(callprojs.catchall_memproj,   ex_mem);</span>
        add_mergemem_users_to_worklist(wl, ex_mem);
      }
<span class="line-modified">!     if (callprojs.catchall_ioproj != NULL) {</span>
<span class="line-modified">!       C-&gt;gvn_replace_by(callprojs.catchall_ioproj,    ekit.i_o());</span>
      }
  
      // Replace the old exception object with the newly created one
<span class="line-modified">!     if (callprojs.exobj != NULL) {</span>
<span class="line-modified">!       C-&gt;gvn_replace_by(callprojs.exobj, ex_oop);</span>
      }
    }
  
    // Disconnect the call from the graph
    call-&gt;disconnect_inputs(NULL, C);
<span class="line-new-header">--- 1993,80 ---</span>
    Node* ex_ctl = top();
  
    SafePointNode* final_state = stop();
  
    // Find all the needed outputs of this call
<span class="line-modified">!   CallProjections* callprojs = call-&gt;extract_projections(true);</span>
  
    Unique_Node_List wl;
    Node* init_mem = call-&gt;in(TypeFunc::Memory);
    Node* final_mem = final_state-&gt;in(TypeFunc::Memory);
    Node* final_ctl = final_state-&gt;in(TypeFunc::Control);
    Node* final_io = final_state-&gt;in(TypeFunc::I_O);
  
    // Replace all the old call edges with the edges from the inlining result
<span class="line-modified">!   if (callprojs-&gt;fallthrough_catchproj != NULL) {</span>
<span class="line-modified">!     C-&gt;gvn_replace_by(callprojs-&gt;fallthrough_catchproj, final_ctl);</span>
    }
<span class="line-modified">!   if (callprojs-&gt;fallthrough_memproj != NULL) {</span>
      if (final_mem-&gt;is_MergeMem()) {
        // Parser&#39;s exits MergeMem was not transformed but may be optimized
        final_mem = _gvn.transform(final_mem);
      }
<span class="line-modified">!     C-&gt;gvn_replace_by(callprojs-&gt;fallthrough_memproj,   final_mem);</span>
      add_mergemem_users_to_worklist(wl, final_mem);
    }
<span class="line-modified">!   if (callprojs-&gt;fallthrough_ioproj != NULL) {</span>
<span class="line-modified">!     C-&gt;gvn_replace_by(callprojs-&gt;fallthrough_ioproj,    final_io);</span>
    }
  
    // Replace the result with the new result if it exists and is used
<span class="line-modified">!   if (callprojs-&gt;resproj[0] != NULL &amp;&amp; result != NULL) {</span>
<span class="line-modified">!     assert(callprojs-&gt;nb_resproj == 1, &quot;unexpected number of results&quot;);</span>
<span class="line-added">+     C-&gt;gvn_replace_by(callprojs-&gt;resproj[0], result);</span>
    }
  
    if (ejvms == NULL) {
      // No exception edges to simply kill off those paths
<span class="line-modified">!     if (callprojs-&gt;catchall_catchproj != NULL) {</span>
<span class="line-modified">!       C-&gt;gvn_replace_by(callprojs-&gt;catchall_catchproj, C-&gt;top());</span>
      }
<span class="line-modified">!     if (callprojs-&gt;catchall_memproj != NULL) {</span>
<span class="line-modified">!       C-&gt;gvn_replace_by(callprojs-&gt;catchall_memproj,   C-&gt;top());</span>
      }
<span class="line-modified">!     if (callprojs-&gt;catchall_ioproj != NULL) {</span>
<span class="line-modified">!       C-&gt;gvn_replace_by(callprojs-&gt;catchall_ioproj,    C-&gt;top());</span>
      }
      // Replace the old exception object with top
<span class="line-modified">!     if (callprojs-&gt;exobj != NULL) {</span>
<span class="line-modified">!       C-&gt;gvn_replace_by(callprojs-&gt;exobj, C-&gt;top());</span>
      }
    } else {
      GraphKit ekit(ejvms);
  
      // Load my combined exception state into the kit, with all phis transformed:
      SafePointNode* ex_map = ekit.combine_and_pop_all_exception_states();
      replaced_nodes_exception = ex_map-&gt;replaced_nodes();
  
      Node* ex_oop = ekit.use_exception_state(ex_map);
  
<span class="line-modified">!     if (callprojs-&gt;catchall_catchproj != NULL) {</span>
<span class="line-modified">!       C-&gt;gvn_replace_by(callprojs-&gt;catchall_catchproj, ekit.control());</span>
        ex_ctl = ekit.control();
      }
<span class="line-modified">!     if (callprojs-&gt;catchall_memproj != NULL) {</span>
        Node* ex_mem = ekit.reset_memory();
<span class="line-modified">!       C-&gt;gvn_replace_by(callprojs-&gt;catchall_memproj,   ex_mem);</span>
        add_mergemem_users_to_worklist(wl, ex_mem);
      }
<span class="line-modified">!     if (callprojs-&gt;catchall_ioproj != NULL) {</span>
<span class="line-modified">!       C-&gt;gvn_replace_by(callprojs-&gt;catchall_ioproj,    ekit.i_o());</span>
      }
  
      // Replace the old exception object with the newly created one
<span class="line-modified">!     if (callprojs-&gt;exobj != NULL) {</span>
<span class="line-modified">!       C-&gt;gvn_replace_by(callprojs-&gt;exobj, ex_oop);</span>
      }
    }
  
    // Disconnect the call from the graph
    call-&gt;disconnect_inputs(NULL, C);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1967,11 ***</span>
    // optimizer doesn&#39;t like that.
    while (wl.size() &gt; 0) {
      _gvn.transform(wl.pop());
    }
  
<span class="line-modified">!   if (callprojs.fallthrough_catchproj != NULL &amp;&amp; !final_ctl-&gt;is_top() &amp;&amp; do_replaced_nodes) {</span>
      replaced_nodes.apply(C, final_ctl);
    }
    if (!ex_ctl-&gt;is_top() &amp;&amp; do_replaced_nodes) {
      replaced_nodes_exception.apply(C, ex_ctl);
    }
<span class="line-new-header">--- 2076,11 ---</span>
    // optimizer doesn&#39;t like that.
    while (wl.size() &gt; 0) {
      _gvn.transform(wl.pop());
    }
  
<span class="line-modified">!   if (callprojs-&gt;fallthrough_catchproj != NULL &amp;&amp; !final_ctl-&gt;is_top() &amp;&amp; do_replaced_nodes) {</span>
      replaced_nodes.apply(C, final_ctl);
    }
    if (!ex_ctl-&gt;is_top() &amp;&amp; do_replaced_nodes) {
      replaced_nodes_exception.apply(C, ex_ctl);
    }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2188,11 ***</span>
    }
  
    if (speculative != current_type-&gt;speculative()) {
      // Build a type with a speculative type (what we think we know
      // about the type but will need a guard when we use it)
<span class="line-modified">!     const TypeOopPtr* spec_type = TypeOopPtr::make(TypePtr::BotPTR, Type::OffsetBot, TypeOopPtr::InstanceBot, speculative);</span>
      // We&#39;re changing the type, we need a new CheckCast node to carry
      // the new type. The new type depends on the control: what
      // profiling tells us is only valid from here as far as we can
      // tell.
      Node* cast = new CheckCastPPNode(control(), n, current_type-&gt;remove_speculative()-&gt;join_speculative(spec_type));
<span class="line-new-header">--- 2297,11 ---</span>
    }
  
    if (speculative != current_type-&gt;speculative()) {
      // Build a type with a speculative type (what we think we know
      // about the type but will need a guard when we use it)
<span class="line-modified">!     const TypeOopPtr* spec_type = TypeOopPtr::make(TypePtr::BotPTR, Type::Offset::bottom, TypeOopPtr::InstanceBot, speculative);</span>
      // We&#39;re changing the type, we need a new CheckCast node to carry
      // the new type. The new type depends on the control: what
      // profiling tells us is only valid from here as far as we can
      // tell.
      Node* cast = new CheckCastPPNode(control(), n, current_type-&gt;remove_speculative()-&gt;join_speculative(spec_type));
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2222,23 ***</span>
         java_bc() == Bytecodes::_instanceof ||
         java_bc() == Bytecodes::_aastore) &amp;&amp;
        method()-&gt;method_data()-&gt;is_mature()) {
      ciProfileData* data = method()-&gt;method_data()-&gt;bci_to_data(bci());
      if (data != NULL) {
<span class="line-modified">!       if (!data-&gt;as_BitData()-&gt;null_seen()) {</span>
<span class="line-modified">!         ptr_kind = ProfileNeverNull;</span>
        } else {
<span class="line-modified">!         assert(data-&gt;is_ReceiverTypeData(), &quot;bad profile data type&quot;);</span>
<span class="line-modified">!         ciReceiverTypeData* call = (ciReceiverTypeData*)data-&gt;as_ReceiverTypeData();</span>
<span class="line-modified">!         uint i = 0;</span>
<span class="line-modified">!         for (; i &lt; call-&gt;row_limit(); i++) {</span>
<span class="line-modified">!           ciKlass* receiver = call-&gt;receiver(i);</span>
<span class="line-modified">!           if (receiver != NULL) {</span>
<span class="line-modified">!             break;</span>
            }
          }
<span class="line-removed">-         ptr_kind = (i == call-&gt;row_limit()) ? ProfileAlwaysNull : ProfileMaybeNull;</span>
        }
      }
    }
    return record_profile_for_speculation(n, exact_kls, ptr_kind);
  }
<span class="line-new-header">--- 2331,34 ---</span>
         java_bc() == Bytecodes::_instanceof ||
         java_bc() == Bytecodes::_aastore) &amp;&amp;
        method()-&gt;method_data()-&gt;is_mature()) {
      ciProfileData* data = method()-&gt;method_data()-&gt;bci_to_data(bci());
      if (data != NULL) {
<span class="line-modified">!       if (java_bc() == Bytecodes::_aastore) {</span>
<span class="line-modified">!         ciKlass* array_type = NULL;</span>
<span class="line-added">+         ciKlass* element_type = NULL;</span>
<span class="line-added">+         ProfilePtrKind element_ptr = ProfileMaybeNull;</span>
<span class="line-added">+         bool flat_array = true;</span>
<span class="line-added">+         bool null_free_array = true;</span>
<span class="line-added">+         method()-&gt;array_access_profiled_type(bci(), array_type, element_type, element_ptr, flat_array, null_free_array);</span>
<span class="line-added">+         exact_kls = element_type;</span>
<span class="line-added">+         ptr_kind = element_ptr;</span>
        } else {
<span class="line-modified">!         if (!data-&gt;as_BitData()-&gt;null_seen()) {</span>
<span class="line-modified">!           ptr_kind = ProfileNeverNull;</span>
<span class="line-modified">!         } else {</span>
<span class="line-modified">!           assert(data-&gt;is_ReceiverTypeData(), &quot;bad profile data type&quot;);</span>
<span class="line-modified">!           ciReceiverTypeData* call = (ciReceiverTypeData*)data-&gt;as_ReceiverTypeData();</span>
<span class="line-modified">!           uint i = 0;</span>
<span class="line-modified">!           for (; i &lt; call-&gt;row_limit(); i++) {</span>
<span class="line-added">+             ciKlass* receiver = call-&gt;receiver(i);</span>
<span class="line-added">+             if (receiver != NULL) {</span>
<span class="line-added">+               break;</span>
<span class="line-added">+             }</span>
            }
<span class="line-added">+           ptr_kind = (i == call-&gt;row_limit()) ? ProfileAlwaysNull : ProfileMaybeNull;</span>
          }
        }
      }
    }
    return record_profile_for_speculation(n, exact_kls, ptr_kind);
  }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2253,14 ***</span>
  void GraphKit::record_profiled_arguments_for_speculation(ciMethod* dest_method, Bytecodes::Code bc) {
    if (!UseTypeSpeculation) {
      return;
    }
    const TypeFunc* tf    = TypeFunc::make(dest_method);
<span class="line-modified">!   int             nargs = tf-&gt;domain()-&gt;cnt() - TypeFunc::Parms;</span>
    int skip = Bytecodes::has_receiver(bc) ? 1 : 0;
    for (int j = skip, i = 0; j &lt; nargs &amp;&amp; i &lt; TypeProfileArgsLimit; j++) {
<span class="line-modified">!     const Type *targ = tf-&gt;domain()-&gt;field_at(j + TypeFunc::Parms);</span>
      if (is_reference_type(targ-&gt;basic_type())) {
        ProfilePtrKind ptr_kind = ProfileMaybeNull;
        ciKlass* better_type = NULL;
        if (method()-&gt;argument_profiled_type(bci(), i, better_type, ptr_kind)) {
          record_profile_for_speculation(argument(j), better_type, ptr_kind);
<span class="line-new-header">--- 2373,14 ---</span>
  void GraphKit::record_profiled_arguments_for_speculation(ciMethod* dest_method, Bytecodes::Code bc) {
    if (!UseTypeSpeculation) {
      return;
    }
    const TypeFunc* tf    = TypeFunc::make(dest_method);
<span class="line-modified">!   int             nargs = tf-&gt;domain_sig()-&gt;cnt() - TypeFunc::Parms;</span>
    int skip = Bytecodes::has_receiver(bc) ? 1 : 0;
    for (int j = skip, i = 0; j &lt; nargs &amp;&amp; i &lt; TypeProfileArgsLimit; j++) {
<span class="line-modified">!     const Type *targ = tf-&gt;domain_sig()-&gt;field_at(j + TypeFunc::Parms);</span>
      if (is_reference_type(targ-&gt;basic_type())) {
        ProfilePtrKind ptr_kind = ProfileMaybeNull;
        ciKlass* better_type = NULL;
        if (method()-&gt;argument_profiled_type(bci(), i, better_type, ptr_kind)) {
          record_profile_for_speculation(argument(j), better_type, ptr_kind);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2327,13 ***</span>
  
  void GraphKit::round_double_arguments(ciMethod* dest_method) {
    if (Matcher::strict_fp_requires_explicit_rounding) {
      // (Note:  TypeFunc::make has a cache that makes this fast.)
      const TypeFunc* tf    = TypeFunc::make(dest_method);
<span class="line-modified">!     int             nargs = tf-&gt;domain()-&gt;cnt() - TypeFunc::Parms;</span>
      for (int j = 0; j &lt; nargs; j++) {
<span class="line-modified">!       const Type *targ = tf-&gt;domain()-&gt;field_at(j + TypeFunc::Parms);</span>
        if (targ-&gt;basic_type() == T_DOUBLE) {
          // If any parameters are doubles, they must be rounded before
          // the call, dstore_rounding does gvn.transform
          Node *arg = argument(j);
          arg = dstore_rounding(arg);
<span class="line-new-header">--- 2447,13 ---</span>
  
  void GraphKit::round_double_arguments(ciMethod* dest_method) {
    if (Matcher::strict_fp_requires_explicit_rounding) {
      // (Note:  TypeFunc::make has a cache that makes this fast.)
      const TypeFunc* tf    = TypeFunc::make(dest_method);
<span class="line-modified">!     int             nargs = tf-&gt;domain_sig()-&gt;cnt() - TypeFunc::Parms;</span>
      for (int j = 0; j &lt; nargs; j++) {
<span class="line-modified">!       const Type *targ = tf-&gt;domain_sig()-&gt;field_at(j + TypeFunc::Parms);</span>
        if (targ-&gt;basic_type() == T_DOUBLE) {
          // If any parameters are doubles, they must be rounded before
          // the call, dstore_rounding does gvn.transform
          Node *arg = argument(j);
          arg = dstore_rounding(arg);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2809,56 ***</span>
    *ctrl = gvn.transform(r_ok_subtype);
    return gvn.transform(r_not_subtype);
  }
  
  Node* GraphKit::gen_subtype_check(Node* obj_or_subklass, Node* superklass) {
    if (ExpandSubTypeCheckAtParseTime) {
      MergeMemNode* mem = merged_memory();
      Node* ctrl = control();
      Node* subklass = obj_or_subklass;
<span class="line-modified">!     if (!_gvn.type(obj_or_subklass)-&gt;isa_klassptr()) {</span>
        subklass = load_object_klass(obj_or_subklass);
      }
<span class="line-removed">- </span>
      Node* n = Phase::gen_subtype_check(subklass, superklass, &amp;ctrl, mem, _gvn);
      set_control(ctrl);
      return n;
    }
  
<span class="line-removed">-   const TypePtr* adr_type = TypeKlassPtr::make(TypePtr::NotNull, C-&gt;env()-&gt;Object_klass(), Type::OffsetBot);</span>
    Node* check = _gvn.transform(new SubTypeCheckNode(C, obj_or_subklass, superklass));
    Node* bol = _gvn.transform(new BoolNode(check, BoolTest::eq));
    IfNode* iff = create_and_xform_if(control(), bol, PROB_STATIC_FREQUENT, COUNT_UNKNOWN);
    set_control(_gvn.transform(new IfTrueNode(iff)));
    return _gvn.transform(new IfFalseNode(iff));
  }
  
  // Profile-driven exact type check:
  Node* GraphKit::type_check_receiver(Node* receiver, ciKlass* klass,
<span class="line-modified">!                                     float prob,</span>
<span class="line-modified">!                                     Node* *casted_receiver) {</span>
    const TypeKlassPtr* tklass = TypeKlassPtr::make(klass);
    Node* recv_klass = load_object_klass(receiver);
<span class="line-modified">!   Node* want_klass = makecon(tklass);</span>
<span class="line-removed">-   Node* cmp = _gvn.transform( new CmpPNode(recv_klass, want_klass) );</span>
<span class="line-removed">-   Node* bol = _gvn.transform( new BoolNode(cmp, BoolTest::eq) );</span>
<span class="line-removed">-   IfNode* iff = create_and_xform_if(control(), bol, prob, COUNT_UNKNOWN);</span>
<span class="line-removed">-   set_control( _gvn.transform( new IfTrueNode (iff) ));</span>
<span class="line-removed">-   Node* fail = _gvn.transform( new IfFalseNode(iff) );</span>
<span class="line-removed">- </span>
    const TypeOopPtr* recv_xtype = tklass-&gt;as_instance_type();
    assert(recv_xtype-&gt;klass_is_exact(), &quot;&quot;);
  
    // Subsume downstream occurrences of receiver with a cast to
    // recv_xtype, since now we know what the type will be.
    Node* cast = new CheckCastPPNode(control(), receiver, recv_xtype);
<span class="line-modified">!   (*casted_receiver) = _gvn.transform(cast);</span>
    // (User must make the replace_in_map call.)
  
    return fail;
  }
  
  //------------------------------subtype_check_receiver-------------------------
  Node* GraphKit::subtype_check_receiver(Node* receiver, ciKlass* klass,
                                         Node** casted_receiver) {
    const TypeKlassPtr* tklass = TypeKlassPtr::make(klass);
    Node* want_klass = makecon(tklass);
<span class="line-new-header">--- 2929,80 ---</span>
    *ctrl = gvn.transform(r_ok_subtype);
    return gvn.transform(r_not_subtype);
  }
  
  Node* GraphKit::gen_subtype_check(Node* obj_or_subklass, Node* superklass) {
<span class="line-added">+   const Type* sub_t = _gvn.type(obj_or_subklass);</span>
<span class="line-added">+   if (sub_t-&gt;isa_inlinetype()) {</span>
<span class="line-added">+     obj_or_subklass = makecon(TypeKlassPtr::make(sub_t-&gt;inline_klass()));</span>
<span class="line-added">+   }</span>
    if (ExpandSubTypeCheckAtParseTime) {
      MergeMemNode* mem = merged_memory();
      Node* ctrl = control();
      Node* subklass = obj_or_subklass;
<span class="line-modified">!     if (!sub_t-&gt;isa_klassptr()) {</span>
        subklass = load_object_klass(obj_or_subklass);
      }
      Node* n = Phase::gen_subtype_check(subklass, superklass, &amp;ctrl, mem, _gvn);
      set_control(ctrl);
      return n;
    }
  
    Node* check = _gvn.transform(new SubTypeCheckNode(C, obj_or_subklass, superklass));
    Node* bol = _gvn.transform(new BoolNode(check, BoolTest::eq));
    IfNode* iff = create_and_xform_if(control(), bol, PROB_STATIC_FREQUENT, COUNT_UNKNOWN);
    set_control(_gvn.transform(new IfTrueNode(iff)));
    return _gvn.transform(new IfFalseNode(iff));
  }
  
  // Profile-driven exact type check:
  Node* GraphKit::type_check_receiver(Node* receiver, ciKlass* klass,
<span class="line-modified">!                                     float prob, Node* *casted_receiver) {</span>
<span class="line-modified">!   Node* fail = top();</span>
<span class="line-added">+   const Type* rec_t = _gvn.type(receiver);</span>
<span class="line-added">+   if (false &amp;&amp; rec_t-&gt;isa_inlinetype()) {</span>
<span class="line-added">+     if (klass-&gt;equals(rec_t-&gt;inline_klass())) {</span>
<span class="line-added">+       (*casted_receiver) = receiver; // Always passes</span>
<span class="line-added">+     } else {</span>
<span class="line-added">+       (*casted_receiver) = top();    // Always fails</span>
<span class="line-added">+       fail = control();</span>
<span class="line-added">+       set_control(top());</span>
<span class="line-added">+     }</span>
<span class="line-added">+     return fail;</span>
<span class="line-added">+   }</span>
    const TypeKlassPtr* tklass = TypeKlassPtr::make(klass);
    Node* recv_klass = load_object_klass(receiver);
<span class="line-modified">!   fail = type_check(recv_klass, tklass, prob);</span>
    const TypeOopPtr* recv_xtype = tklass-&gt;as_instance_type();
    assert(recv_xtype-&gt;klass_is_exact(), &quot;&quot;);
  
    // Subsume downstream occurrences of receiver with a cast to
    // recv_xtype, since now we know what the type will be.
    Node* cast = new CheckCastPPNode(control(), receiver, recv_xtype);
<span class="line-modified">!   Node* res = _gvn.transform(cast);</span>
<span class="line-added">+   if (recv_xtype-&gt;is_inlinetypeptr() &amp;&amp; recv_xtype-&gt;inline_klass()-&gt;is_scalarizable()) {</span>
<span class="line-added">+     assert(!gvn().type(res)-&gt;maybe_null(), &quot;receiver should never be null&quot;);</span>
<span class="line-added">+     res = InlineTypeNode::make_from_oop(this, res, recv_xtype-&gt;inline_klass());</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   (*casted_receiver) = res;</span>
    // (User must make the replace_in_map call.)
  
    return fail;
  }
  
<span class="line-added">+ Node* GraphKit::type_check(Node* recv_klass, const TypeKlassPtr* tklass,</span>
<span class="line-added">+                            float prob) {</span>
<span class="line-added">+   Node* want_klass = makecon(tklass);</span>
<span class="line-added">+   Node* cmp = _gvn.transform( new CmpPNode(recv_klass, want_klass));</span>
<span class="line-added">+   Node* bol = _gvn.transform( new BoolNode(cmp, BoolTest::eq) );</span>
<span class="line-added">+   IfNode* iff = create_and_xform_if(control(), bol, prob, COUNT_UNKNOWN);</span>
<span class="line-added">+   set_control(  _gvn.transform( new IfTrueNode (iff)));</span>
<span class="line-added">+   Node* fail = _gvn.transform( new IfFalseNode(iff));</span>
<span class="line-added">+   return fail;</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
  //------------------------------subtype_check_receiver-------------------------
  Node* GraphKit::subtype_check_receiver(Node* receiver, ciKlass* klass,
                                         Node** casted_receiver) {
    const TypeKlassPtr* tklass = TypeKlassPtr::make(klass);
    Node* want_klass = makecon(tklass);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2894,10 ***</span>
<span class="line-new-header">--- 3038,13 ---</span>
        return true;
      // If the profile has not seen a null, assume it won&#39;t happen.
      assert(java_bc() == Bytecodes::_checkcast ||
             java_bc() == Bytecodes::_instanceof ||
             java_bc() == Bytecodes::_aastore, &quot;MDO must collect null_seen bit here&quot;);
<span class="line-added">+     if (java_bc() == Bytecodes::_aastore) {</span>
<span class="line-added">+       return ((ciArrayLoadStoreData*)data-&gt;as_ArrayLoadStoreData())-&gt;element()-&gt;ptr_kind() == ProfileNeverNull;</span>
<span class="line-added">+     }</span>
      return !data-&gt;as_BitData()-&gt;null_seen();
    }
    speculating = false;
    return false;
  }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2973,11 ***</span>
  
    // (No, this isn&#39;t a call, but it&#39;s enough like a virtual call
    // to use the same ciMethod accessor to get the profile info...)
    // If we have a speculative type use it instead of profiling (which
    // may not help us)
<span class="line-modified">!   ciKlass* exact_kls = spec_klass == NULL ? profile_has_unique_klass() : spec_klass;</span>
    if (exact_kls != NULL) {// no cast failures here
      if (require_klass == NULL ||
          C-&gt;static_subtype_check(require_klass, exact_kls) == Compile::SSC_always_true) {
        // If we narrow the type to match what the type profile sees or
        // the speculative type, we can then remove the rest of the
<span class="line-new-header">--- 3120,24 ---</span>
  
    // (No, this isn&#39;t a call, but it&#39;s enough like a virtual call
    // to use the same ciMethod accessor to get the profile info...)
    // If we have a speculative type use it instead of profiling (which
    // may not help us)
<span class="line-modified">!   ciKlass* exact_kls = spec_klass;</span>
<span class="line-added">+   if (exact_kls == NULL) {</span>
<span class="line-added">+     if (java_bc() == Bytecodes::_aastore) {</span>
<span class="line-added">+       ciKlass* array_type = NULL;</span>
<span class="line-added">+       ciKlass* element_type = NULL;</span>
<span class="line-added">+       ProfilePtrKind element_ptr = ProfileMaybeNull;</span>
<span class="line-added">+       bool flat_array = true;</span>
<span class="line-added">+       bool null_free_array = true;</span>
<span class="line-added">+       method()-&gt;array_access_profiled_type(bci(), array_type, element_type, element_ptr, flat_array, null_free_array);</span>
<span class="line-added">+       exact_kls = element_type;</span>
<span class="line-added">+     } else {</span>
<span class="line-added">+       exact_kls = profile_has_unique_klass();</span>
<span class="line-added">+     }</span>
<span class="line-added">+   }</span>
    if (exact_kls != NULL) {// no cast failures here
      if (require_klass == NULL ||
          C-&gt;static_subtype_check(require_klass, exact_kls) == Compile::SSC_always_true) {
        // If we narrow the type to match what the type profile sees or
        // the speculative type, we can then remove the rest of the
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3078,14 ***</span>
      data = method()-&gt;method_data()-&gt;bci_to_data(bci());
    }
    bool speculative_not_null = false;
    bool never_see_null = (ProfileDynamicTypes  // aggressive use of profile
                           &amp;&amp; seems_never_null(obj, data, speculative_not_null));
  
    // Null check; get casted pointer; set region slot 3
    Node* null_ctl = top();
<span class="line-modified">!   Node* not_null_obj = null_check_oop(obj, &amp;null_ctl, never_see_null, safe_for_replace, speculative_not_null);</span>
  
    // If not_null_obj is dead, only null-path is taken
    if (stopped()) {              // Doing instance-of on a NULL?
      set_control(null_ctl);
      return intcon(0);
<span class="line-new-header">--- 3238,15 ---</span>
      data = method()-&gt;method_data()-&gt;bci_to_data(bci());
    }
    bool speculative_not_null = false;
    bool never_see_null = (ProfileDynamicTypes  // aggressive use of profile
                           &amp;&amp; seems_never_null(obj, data, speculative_not_null));
<span class="line-added">+   bool is_value = obj-&gt;is_InlineType();</span>
  
    // Null check; get casted pointer; set region slot 3
    Node* null_ctl = top();
<span class="line-modified">!   Node* not_null_obj = is_value ? obj : null_check_oop(obj, &amp;null_ctl, never_see_null, safe_for_replace, speculative_not_null);</span>
  
    // If not_null_obj is dead, only null-path is taken
    if (stopped()) {              // Doing instance-of on a NULL?
      set_control(null_ctl);
      return intcon(0);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3099,32 ***</span>
      region-&gt;del_req(_null_path);
      phi   -&gt;del_req(_null_path);
    }
  
    // Do we know the type check always succeed?
<span class="line-modified">!   bool known_statically = false;</span>
<span class="line-modified">!   if (_gvn.type(superklass)-&gt;singleton()) {</span>
<span class="line-modified">!     ciKlass* superk = _gvn.type(superklass)-&gt;is_klassptr()-&gt;klass();</span>
<span class="line-modified">!     ciKlass* subk = _gvn.type(obj)-&gt;is_oopptr()-&gt;klass();</span>
<span class="line-modified">!     if (subk != NULL &amp;&amp; subk-&gt;is_loaded()) {</span>
<span class="line-modified">!       int static_res = C-&gt;static_subtype_check(superk, subk);</span>
<span class="line-modified">!       known_statically = (static_res == Compile::SSC_always_true || static_res == Compile::SSC_always_false);</span>
      }
<span class="line-modified">!   }</span>
<span class="line-modified">! </span>
<span class="line-modified">!   if (!known_statically) {</span>
<span class="line-modified">!     const TypeOopPtr* obj_type = _gvn.type(obj)-&gt;is_oopptr();</span>
<span class="line-modified">!     // We may not have profiling here or it may not help us. If we</span>
<span class="line-modified">!     // have a speculative type use it to perform an exact cast.</span>
<span class="line-modified">!     ciKlass* spec_obj_type = obj_type-&gt;speculative_type();</span>
<span class="line-modified">!     if (spec_obj_type != NULL || (ProfileDynamicTypes &amp;&amp; data != NULL)) {</span>
<span class="line-modified">!       Node* cast_obj = maybe_cast_profiled_receiver(not_null_obj, NULL, spec_obj_type, safe_for_replace);</span>
<span class="line-modified">!       if (stopped()) {            // Profile disagrees with this path.</span>
<span class="line-modified">!         set_control(null_ctl);    // Null is the only remaining possibility.</span>
<span class="line-modified">!         return intcon(0);</span>
<span class="line-modified">!       }</span>
<span class="line-modified">!       if (cast_obj != NULL) {</span>
          }
        }
      }
    }
  
<span class="line-new-header">--- 3260,37 ---</span>
      region-&gt;del_req(_null_path);
      phi   -&gt;del_req(_null_path);
    }
  
    // Do we know the type check always succeed?
<span class="line-modified">!   if (!is_value) {</span>
<span class="line-modified">!     bool known_statically = false;</span>
<span class="line-modified">!     if (_gvn.type(superklass)-&gt;singleton()) {</span>
<span class="line-modified">!       ciKlass* superk = _gvn.type(superklass)-&gt;is_klassptr()-&gt;klass();</span>
<span class="line-modified">!       ciKlass* subk = _gvn.type(obj)-&gt;is_oopptr()-&gt;klass();</span>
<span class="line-modified">!       if (subk != NULL &amp;&amp; subk-&gt;is_loaded()) {</span>
<span class="line-modified">!         int static_res = C-&gt;static_subtype_check(superk, subk);</span>
<span class="line-added">+         known_statically = (static_res == Compile::SSC_always_true || static_res == Compile::SSC_always_false);</span>
<span class="line-added">+       }</span>
      }
<span class="line-modified">! </span>
<span class="line-modified">!     if (!known_statically) {</span>
<span class="line-modified">!       const TypeOopPtr* obj_type = _gvn.type(obj)-&gt;is_oopptr();</span>
<span class="line-modified">!       // We may not have profiling here or it may not help us. If we</span>
<span class="line-modified">!       // have a speculative type use it to perform an exact cast.</span>
<span class="line-modified">!       ciKlass* spec_obj_type = obj_type-&gt;speculative_type();</span>
<span class="line-modified">!       if (spec_obj_type != NULL || (ProfileDynamicTypes &amp;&amp; data != NULL)) {</span>
<span class="line-modified">!         Node* cast_obj = maybe_cast_profiled_receiver(not_null_obj, NULL, spec_obj_type, safe_for_replace);</span>
<span class="line-modified">!         if (stopped()) {            // Profile disagrees with this path.</span>
<span class="line-modified">!           set_control(null_ctl);    // Null is the only remaining possibility.</span>
<span class="line-modified">!           return intcon(0);</span>
<span class="line-modified">!         }</span>
<span class="line-modified">!         if (cast_obj != NULL &amp;&amp;</span>
<span class="line-modified">!             // A value that&#39;s sometimes null is not something we can optimize well</span>
<span class="line-added">+             !(cast_obj-&gt;is_InlineType() &amp;&amp; null_ctl != top())) {</span>
<span class="line-added">+           not_null_obj = cast_obj;</span>
<span class="line-added">+           is_value = not_null_obj-&gt;is_InlineType();</span>
          }
        }
      }
    }
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3144,11 ***</span>
    record_for_igvn(region);
  
    // If we know the type check always succeeds then we don&#39;t use the
    // profiling data at this bytecode. Don&#39;t lose it, feed it to the
    // type system as a speculative type.
<span class="line-modified">!   if (safe_for_replace) {</span>
      Node* casted_obj = record_profiled_receiver_for_speculation(obj);
      replace_in_map(obj, casted_obj);
    }
  
    return _gvn.transform(phi);
<span class="line-new-header">--- 3310,11 ---</span>
    record_for_igvn(region);
  
    // If we know the type check always succeeds then we don&#39;t use the
    // profiling data at this bytecode. Don&#39;t lose it, feed it to the
    // type system as a speculative type.
<span class="line-modified">!   if (safe_for_replace &amp;&amp; !is_value) {</span>
      Node* casted_obj = record_profiled_receiver_for_speculation(obj);
      replace_in_map(obj, casted_obj);
    }
  
    return _gvn.transform(phi);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3159,63 ***</span>
  // array store bytecode.  Stack must be as-if BEFORE doing the bytecode so the
  // uncommon-trap paths work.  Adjust stack after this call.
  // If failure_control is supplied and not null, it is filled in with
  // the control edge for the cast failure.  Otherwise, an appropriate
  // uncommon trap or exception is thrown.
<span class="line-modified">! Node* GraphKit::gen_checkcast(Node *obj, Node* superklass,</span>
<span class="line-removed">-                               Node* *failure_control) {</span>
    kill_dead_locals();           // Benefit all the uncommon traps
<span class="line-modified">!   const TypeKlassPtr *tk = _gvn.type(superklass)-&gt;is_klassptr();</span>
<span class="line-modified">!   const Type *toop = TypeOopPtr::make_from_klass(tk-&gt;klass());</span>
  
    // Fast cutout:  Check the case that the cast is vacuously true.
    // This detects the common cases where the test will short-circuit
    // away completely.  We do this before we perform the null check,
    // because if the test is going to turn into zero code, we don&#39;t
    // want a residual null check left around.  (Causes a slowdown,
    // for example, in some objArray manipulations, such as a[i]=a[j].)
    if (tk-&gt;singleton()) {
<span class="line-modified">!     const TypeOopPtr* objtp = _gvn.type(obj)-&gt;isa_oopptr();</span>
<span class="line-modified">!     if (objtp != NULL &amp;&amp; objtp-&gt;klass() != NULL) {</span>
<span class="line-modified">!       switch (C-&gt;static_subtype_check(tk-&gt;klass(), objtp-&gt;klass())) {</span>
        case Compile::SSC_always_true:
          // If we know the type check always succeed then we don&#39;t use
          // the profiling data at this bytecode. Don&#39;t lose it, feed it
          // to the type system as a speculative type.
<span class="line-modified">!         return record_profiled_receiver_for_speculation(obj);</span>
        case Compile::SSC_always_false:
<span class="line-modified">!         // It needs a null check because a null will *pass* the cast check.</span>
<span class="line-modified">!         // A non-null value will always produce an exception.</span>
<span class="line-modified">!         return null_assert(obj);</span>
        }
      }
    }
  
    ciProfileData* data = NULL;
    bool safe_for_replace = false;
    if (failure_control == NULL) {        // use MDO in regular case only
      assert(java_bc() == Bytecodes::_aastore ||
             java_bc() == Bytecodes::_checkcast,
             &quot;interpreter profiles type checks only for these BCs&quot;);
<span class="line-modified">!     data = method()-&gt;method_data()-&gt;bci_to_data(bci());</span>
      safe_for_replace = true;
    }
  
    // Make the merge point
    enum { _obj_path = 1, _null_path, PATH_LIMIT };
    RegionNode* region = new RegionNode(PATH_LIMIT);
    Node*       phi    = new PhiNode(region, toop);
    C-&gt;set_has_split_ifs(true); // Has chance for split-if optimization
  
    // Use null-cast information if it is available
    bool speculative_not_null = false;
    bool never_see_null = ((failure_control == NULL)  // regular case only
                           &amp;&amp; seems_never_null(obj, data, speculative_not_null));
  
    // Null check; get casted pointer; set region slot 3
    Node* null_ctl = top();
<span class="line-modified">!   Node* not_null_obj = null_check_oop(obj, &amp;null_ctl, never_see_null, safe_for_replace, speculative_not_null);</span>
  
    // If not_null_obj is dead, only null-path is taken
    if (stopped()) {              // Doing instance-of on a NULL?
      set_control(null_ctl);
      return null();
<span class="line-new-header">--- 3325,103 ---</span>
  // array store bytecode.  Stack must be as-if BEFORE doing the bytecode so the
  // uncommon-trap paths work.  Adjust stack after this call.
  // If failure_control is supplied and not null, it is filled in with
  // the control edge for the cast failure.  Otherwise, an appropriate
  // uncommon trap or exception is thrown.
<span class="line-modified">! Node* GraphKit::gen_checkcast(Node *obj, Node* superklass, Node* *failure_control) {</span>
    kill_dead_locals();           // Benefit all the uncommon traps
<span class="line-modified">!   const TypeKlassPtr* tk = _gvn.type(superklass)-&gt;is_klassptr();</span>
<span class="line-modified">!   const TypeOopPtr* toop = TypeOopPtr::make_from_klass(tk-&gt;klass());</span>
<span class="line-added">+ </span>
<span class="line-added">+   // Check if inline types are involved</span>
<span class="line-added">+   bool from_inline = obj-&gt;is_InlineType();</span>
<span class="line-added">+   bool to_inline = tk-&gt;klass()-&gt;is_inlinetype();</span>
  
    // Fast cutout:  Check the case that the cast is vacuously true.
    // This detects the common cases where the test will short-circuit
    // away completely.  We do this before we perform the null check,
    // because if the test is going to turn into zero code, we don&#39;t
    // want a residual null check left around.  (Causes a slowdown,
    // for example, in some objArray manipulations, such as a[i]=a[j].)
    if (tk-&gt;singleton()) {
<span class="line-modified">!     ciKlass* klass = NULL;</span>
<span class="line-modified">!     if (from_inline) {</span>
<span class="line-modified">!       klass = _gvn.type(obj)-&gt;inline_klass();</span>
<span class="line-added">+     } else {</span>
<span class="line-added">+       const TypeOopPtr* objtp = _gvn.type(obj)-&gt;isa_oopptr();</span>
<span class="line-added">+       if (objtp != NULL) {</span>
<span class="line-added">+         klass = objtp-&gt;klass();</span>
<span class="line-added">+       }</span>
<span class="line-added">+     }</span>
<span class="line-added">+     if (klass != NULL) {</span>
<span class="line-added">+       switch (C-&gt;static_subtype_check(tk-&gt;klass(), klass)) {</span>
        case Compile::SSC_always_true:
          // If we know the type check always succeed then we don&#39;t use
          // the profiling data at this bytecode. Don&#39;t lose it, feed it
          // to the type system as a speculative type.
<span class="line-modified">!         if (!from_inline) {</span>
<span class="line-added">+           obj = record_profiled_receiver_for_speculation(obj);</span>
<span class="line-added">+           if (to_inline) {</span>
<span class="line-added">+             obj = null_check(obj);</span>
<span class="line-added">+             if (toop-&gt;inline_klass()-&gt;is_scalarizable()) {</span>
<span class="line-added">+               obj = InlineTypeNode::make_from_oop(this, obj, toop-&gt;inline_klass());</span>
<span class="line-added">+             }</span>
<span class="line-added">+           }</span>
<span class="line-added">+         }</span>
<span class="line-added">+         return obj;</span>
        case Compile::SSC_always_false:
<span class="line-modified">!         if (from_inline || to_inline) {</span>
<span class="line-modified">!           if (!from_inline) {</span>
<span class="line-modified">!             null_check(obj);</span>
<span class="line-added">+           }</span>
<span class="line-added">+           // Inline type is never null. Always throw an exception.</span>
<span class="line-added">+           builtin_throw(Deoptimization::Reason_class_check, makecon(TypeKlassPtr::make(klass)));</span>
<span class="line-added">+           return top();</span>
<span class="line-added">+         } else {</span>
<span class="line-added">+           // It needs a null check because a null will *pass* the cast check.</span>
<span class="line-added">+           return null_assert(obj);</span>
<span class="line-added">+         }</span>
        }
      }
    }
  
    ciProfileData* data = NULL;
    bool safe_for_replace = false;
    if (failure_control == NULL) {        // use MDO in regular case only
      assert(java_bc() == Bytecodes::_aastore ||
             java_bc() == Bytecodes::_checkcast,
             &quot;interpreter profiles type checks only for these BCs&quot;);
<span class="line-modified">!     if (method()-&gt;method_data()-&gt;is_mature()) {</span>
<span class="line-added">+       data = method()-&gt;method_data()-&gt;bci_to_data(bci());</span>
<span class="line-added">+     }</span>
      safe_for_replace = true;
    }
  
    // Make the merge point
    enum { _obj_path = 1, _null_path, PATH_LIMIT };
    RegionNode* region = new RegionNode(PATH_LIMIT);
    Node*       phi    = new PhiNode(region, toop);
<span class="line-added">+   _gvn.set_type(region, Type::CONTROL);</span>
<span class="line-added">+   _gvn.set_type(phi, toop);</span>
<span class="line-added">+ </span>
    C-&gt;set_has_split_ifs(true); // Has chance for split-if optimization
  
    // Use null-cast information if it is available
    bool speculative_not_null = false;
    bool never_see_null = ((failure_control == NULL)  // regular case only
                           &amp;&amp; seems_never_null(obj, data, speculative_not_null));
  
    // Null check; get casted pointer; set region slot 3
    Node* null_ctl = top();
<span class="line-modified">!   Node* not_null_obj = NULL;</span>
<span class="line-added">+   if (from_inline) {</span>
<span class="line-added">+     not_null_obj = obj;</span>
<span class="line-added">+   } else if (to_inline) {</span>
<span class="line-added">+     not_null_obj = null_check(obj);</span>
<span class="line-added">+   } else {</span>
<span class="line-added">+     not_null_obj = null_check_oop(obj, &amp;null_ctl, never_see_null, safe_for_replace, speculative_not_null);</span>
<span class="line-added">+   }</span>
  
    // If not_null_obj is dead, only null-path is taken
    if (stopped()) {              // Doing instance-of on a NULL?
      set_control(null_ctl);
      return null();
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3229,21 ***</span>
      region-&gt;del_req(_null_path);
      phi   -&gt;del_req(_null_path);
    }
  
    Node* cast_obj = NULL;
<span class="line-modified">!   if (tk-&gt;klass_is_exact()) {</span>
      // The following optimization tries to statically cast the speculative type of the object
      // (for example obtained during profiling) to the type of the superklass and then do a
      // dynamic check that the type of the object is what we expect. To work correctly
      // for checkcast and aastore the type of superklass should be exact.
      const TypeOopPtr* obj_type = _gvn.type(obj)-&gt;is_oopptr();
      // We may not have profiling here or it may not help us. If we have
      // a speculative type use it to perform an exact cast.
      ciKlass* spec_obj_type = obj_type-&gt;speculative_type();
      if (spec_obj_type != NULL || data != NULL) {
        cast_obj = maybe_cast_profiled_receiver(not_null_obj, tk-&gt;klass(), spec_obj_type, safe_for_replace);
        if (cast_obj != NULL) {
          if (failure_control != NULL) // failure is now impossible
            (*failure_control) = top();
          // adjust the type of the phi to the exact klass:
          phi-&gt;raise_bottom_type(_gvn.type(cast_obj)-&gt;meet_speculative(TypePtr::NULL_PTR));
<span class="line-new-header">--- 3435,28 ---</span>
      region-&gt;del_req(_null_path);
      phi   -&gt;del_req(_null_path);
    }
  
    Node* cast_obj = NULL;
<span class="line-modified">!   if (!from_inline &amp;&amp; tk-&gt;klass_is_exact()) {</span>
      // The following optimization tries to statically cast the speculative type of the object
      // (for example obtained during profiling) to the type of the superklass and then do a
      // dynamic check that the type of the object is what we expect. To work correctly
      // for checkcast and aastore the type of superklass should be exact.
      const TypeOopPtr* obj_type = _gvn.type(obj)-&gt;is_oopptr();
      // We may not have profiling here or it may not help us. If we have
      // a speculative type use it to perform an exact cast.
      ciKlass* spec_obj_type = obj_type-&gt;speculative_type();
      if (spec_obj_type != NULL || data != NULL) {
        cast_obj = maybe_cast_profiled_receiver(not_null_obj, tk-&gt;klass(), spec_obj_type, safe_for_replace);
<span class="line-added">+       if (cast_obj != NULL &amp;&amp; cast_obj-&gt;is_InlineType()) {</span>
<span class="line-added">+         if (null_ctl != top()) {</span>
<span class="line-added">+           cast_obj = NULL; // A value that&#39;s sometimes null is not something we can optimize well</span>
<span class="line-added">+         } else {</span>
<span class="line-added">+           return cast_obj;</span>
<span class="line-added">+         }</span>
<span class="line-added">+       }</span>
        if (cast_obj != NULL) {
          if (failure_control != NULL) // failure is now impossible
            (*failure_control) = top();
          // adjust the type of the phi to the exact klass:
          phi-&gt;raise_bottom_type(_gvn.type(cast_obj)-&gt;meet_speculative(TypePtr::NULL_PTR));
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3251,20 ***</span>
      }
    }
  
    if (cast_obj == NULL) {
      // Generate the subtype check
<span class="line-modified">!     Node* not_subtype_ctrl = gen_subtype_check(not_null_obj, superklass );</span>
  
      // Plug in success path into the merge
<span class="line-modified">!     cast_obj = _gvn.transform(new CheckCastPPNode(control(), not_null_obj, toop));</span>
      // Failure path ends in uncommon trap (or may be dead - failure impossible)
      if (failure_control == NULL) {
        if (not_subtype_ctrl != top()) { // If failure is possible
          PreserveJVMState pjvms(this);
          set_control(not_subtype_ctrl);
<span class="line-modified">!         builtin_throw(Deoptimization::Reason_class_check, load_object_klass(not_null_obj));</span>
        }
      } else {
        (*failure_control) = not_subtype_ctrl;
      }
    }
<span class="line-new-header">--- 3464,26 ---</span>
      }
    }
  
    if (cast_obj == NULL) {
      // Generate the subtype check
<span class="line-modified">!     Node* not_subtype_ctrl = gen_subtype_check(not_null_obj, superklass);</span>
  
      // Plug in success path into the merge
<span class="line-modified">!     cast_obj = from_inline ? not_null_obj : _gvn.transform(new CheckCastPPNode(control(), not_null_obj, toop));</span>
      // Failure path ends in uncommon trap (or may be dead - failure impossible)
      if (failure_control == NULL) {
        if (not_subtype_ctrl != top()) { // If failure is possible
          PreserveJVMState pjvms(this);
          set_control(not_subtype_ctrl);
<span class="line-modified">!         Node* obj_klass = NULL;</span>
<span class="line-added">+         if (from_inline) {</span>
<span class="line-added">+           obj_klass = makecon(TypeKlassPtr::make(_gvn.type(not_null_obj)-&gt;inline_klass()));</span>
<span class="line-added">+         } else {</span>
<span class="line-added">+           obj_klass = load_object_klass(not_null_obj);</span>
<span class="line-added">+         }</span>
<span class="line-added">+         builtin_throw(Deoptimization::Reason_class_check, obj_klass);</span>
        }
      } else {
        (*failure_control) = not_subtype_ctrl;
      }
    }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3287,11 ***</span>
  
    // Return final merged results
    set_control( _gvn.transform(region) );
    record_for_igvn(region);
  
<span class="line-modified">!   return record_profiled_receiver_for_speculation(res);</span>
  }
  
  //------------------------------next_monitor-----------------------------------
  // What number should be given to the next monitor?
  int GraphKit::next_monitor() {
<span class="line-new-header">--- 3506,133 ---</span>
  
    // Return final merged results
    set_control( _gvn.transform(region) );
    record_for_igvn(region);
  
<span class="line-modified">!   bool not_inline = !toop-&gt;can_be_inline_type();</span>
<span class="line-added">+   bool not_flattened = !UseFlatArray || not_inline || (toop-&gt;is_inlinetypeptr() &amp;&amp; !toop-&gt;inline_klass()-&gt;flatten_array());</span>
<span class="line-added">+   if (EnableValhalla &amp;&amp; not_flattened) {</span>
<span class="line-added">+     // Check if obj has been loaded from an array</span>
<span class="line-added">+     obj = obj-&gt;isa_DecodeN() ? obj-&gt;in(1) : obj;</span>
<span class="line-added">+     Node* array = NULL;</span>
<span class="line-added">+     if (obj-&gt;isa_Load()) {</span>
<span class="line-added">+       Node* address = obj-&gt;in(MemNode::Address);</span>
<span class="line-added">+       if (address-&gt;isa_AddP()) {</span>
<span class="line-added">+         array = address-&gt;as_AddP()-&gt;in(AddPNode::Base);</span>
<span class="line-added">+       }</span>
<span class="line-added">+     } else if (obj-&gt;is_Phi()) {</span>
<span class="line-added">+       Node* region = obj-&gt;in(0);</span>
<span class="line-added">+       // TODO make this more robust (see JDK-8231346)</span>
<span class="line-added">+       if (region-&gt;req() == 3 &amp;&amp; region-&gt;in(2) != NULL &amp;&amp; region-&gt;in(2)-&gt;in(0) != NULL) {</span>
<span class="line-added">+         IfNode* iff = region-&gt;in(2)-&gt;in(0)-&gt;isa_If();</span>
<span class="line-added">+         if (iff != NULL) {</span>
<span class="line-added">+           iff-&gt;is_non_flattened_array_check(&amp;_gvn, &amp;array);</span>
<span class="line-added">+         }</span>
<span class="line-added">+       }</span>
<span class="line-added">+     }</span>
<span class="line-added">+     if (array != NULL) {</span>
<span class="line-added">+       const TypeAryPtr* ary_t = _gvn.type(array)-&gt;isa_aryptr();</span>
<span class="line-added">+       if (ary_t != NULL) {</span>
<span class="line-added">+         if (!ary_t-&gt;is_not_null_free() &amp;&amp; not_inline) {</span>
<span class="line-added">+           // Casting array element to a non-inline-type, mark array as not null-free.</span>
<span class="line-added">+           Node* cast = _gvn.transform(new CheckCastPPNode(control(), array, ary_t-&gt;cast_to_not_null_free()));</span>
<span class="line-added">+           replace_in_map(array, cast);</span>
<span class="line-added">+         } else if (!ary_t-&gt;is_not_flat()) {</span>
<span class="line-added">+           // Casting array element to a non-flattened type, mark array as not flat.</span>
<span class="line-added">+           Node* cast = _gvn.transform(new CheckCastPPNode(control(), array, ary_t-&gt;cast_to_not_flat()));</span>
<span class="line-added">+           replace_in_map(array, cast);</span>
<span class="line-added">+         }</span>
<span class="line-added">+       }</span>
<span class="line-added">+     }</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   if (!from_inline) {</span>
<span class="line-added">+     res = record_profiled_receiver_for_speculation(res);</span>
<span class="line-added">+     if (to_inline &amp;&amp; toop-&gt;inline_klass()-&gt;is_scalarizable()) {</span>
<span class="line-added">+       assert(!gvn().type(res)-&gt;maybe_null(), &quot;Inline types are null-free&quot;);</span>
<span class="line-added">+       res = InlineTypeNode::make_from_oop(this, res, toop-&gt;inline_klass());</span>
<span class="line-added">+     }</span>
<span class="line-added">+   }</span>
<span class="line-added">+   return res;</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ // Check if &#39;obj&#39; is an inline type by checking if it has the always_locked markWord pattern set.</span>
<span class="line-added">+ Node* GraphKit::is_inline_type(Node* obj) {</span>
<span class="line-added">+   Node* mark_addr = basic_plus_adr(obj, oopDesc::mark_offset_in_bytes());</span>
<span class="line-added">+   Node* mark = make_load(NULL, mark_addr, TypeX_X, TypeX_X-&gt;basic_type(), MemNode::unordered);</span>
<span class="line-added">+   Node* mask = _gvn.MakeConX(markWord::always_locked_pattern);</span>
<span class="line-added">+   Node* andx = _gvn.transform(new AndXNode(mark, mask));</span>
<span class="line-added">+   Node* cmp = _gvn.transform(new CmpXNode(andx, mask));</span>
<span class="line-added">+   return _gvn.transform(new BoolNode(cmp, BoolTest::eq));</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ // Check if &#39;ary&#39; is a non-flattened array</span>
<span class="line-added">+ Node* GraphKit::is_non_flattened_array(Node* ary) {</span>
<span class="line-added">+   Node* kls = load_object_klass(ary);</span>
<span class="line-added">+   Node* tag = load_lh_array_tag(kls);</span>
<span class="line-added">+   Node* cmp = gen_lh_array_test(kls, Klass::_lh_array_tag_vt_value);</span>
<span class="line-added">+   return _gvn.transform(new BoolNode(cmp, BoolTest::ne));</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ // Check if &#39;ary&#39; is a nullable array</span>
<span class="line-added">+ Node* GraphKit::is_nullable_array(Node* ary) {</span>
<span class="line-added">+   Node* kls = load_object_klass(ary);</span>
<span class="line-added">+   Node* lhp = basic_plus_adr(kls, in_bytes(Klass::layout_helper_offset()));</span>
<span class="line-added">+   Node* layout_val = _gvn.transform(LoadNode::make(_gvn, NULL, immutable_memory(), lhp, lhp-&gt;bottom_type()-&gt;is_ptr(), TypeInt::INT, T_INT, MemNode::unordered));</span>
<span class="line-added">+   Node* null_free = _gvn.transform(new RShiftINode(layout_val, intcon(Klass::_lh_null_free_shift)));</span>
<span class="line-added">+   null_free = _gvn.transform(new AndINode(null_free, intcon(Klass::_lh_null_free_mask)));</span>
<span class="line-added">+   Node* cmp = _gvn.transform(new CmpINode(null_free, intcon(0)));</span>
<span class="line-added">+   return _gvn.transform(new BoolNode(cmp, BoolTest::eq));</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ // Deoptimize if &#39;ary&#39; is a null-free inline type array and &#39;val&#39; is null</span>
<span class="line-added">+ Node* GraphKit::gen_inline_array_null_guard(Node* ary, Node* val, int nargs, bool safe_for_replace) {</span>
<span class="line-added">+   const Type* val_t = _gvn.type(val);</span>
<span class="line-added">+   if (val-&gt;is_InlineType() || !TypePtr::NULL_PTR-&gt;higher_equal(val_t)) {</span>
<span class="line-added">+     return ary; // Never null</span>
<span class="line-added">+   }</span>
<span class="line-added">+   RegionNode* region = new RegionNode(3);</span>
<span class="line-added">+   Node* null_ctl = top();</span>
<span class="line-added">+   null_check_oop(val, &amp;null_ctl);</span>
<span class="line-added">+   if (null_ctl != top()) {</span>
<span class="line-added">+     PreserveJVMState pjvms(this);</span>
<span class="line-added">+     set_control(null_ctl);</span>
<span class="line-added">+     {</span>
<span class="line-added">+       // Deoptimize if null-free array</span>
<span class="line-added">+       BuildCutout unless(this, is_nullable_array(ary), PROB_MAX);</span>
<span class="line-added">+       inc_sp(nargs);</span>
<span class="line-added">+       uncommon_trap(Deoptimization::Reason_null_check,</span>
<span class="line-added">+                     Deoptimization::Action_none);</span>
<span class="line-added">+     }</span>
<span class="line-added">+     region-&gt;init_req(1, control());</span>
<span class="line-added">+   }</span>
<span class="line-added">+   region-&gt;init_req(2, control());</span>
<span class="line-added">+   set_control(_gvn.transform(region));</span>
<span class="line-added">+   record_for_igvn(region);</span>
<span class="line-added">+   const TypeAryPtr* ary_t = _gvn.type(ary)-&gt;is_aryptr();</span>
<span class="line-added">+   if (val_t == TypePtr::NULL_PTR &amp;&amp; !ary_t-&gt;is_not_null_free()) {</span>
<span class="line-added">+     // Since we were just successfully storing null, the array can&#39;t be null free.</span>
<span class="line-added">+     ary_t = ary_t-&gt;cast_to_not_null_free();</span>
<span class="line-added">+     Node* cast = _gvn.transform(new CheckCastPPNode(control(), ary, ary_t));</span>
<span class="line-added">+     if (safe_for_replace) {</span>
<span class="line-added">+       replace_in_map(ary, cast);</span>
<span class="line-added">+     }</span>
<span class="line-added">+     ary = cast;</span>
<span class="line-added">+   }</span>
<span class="line-added">+   return ary;</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ Node* GraphKit::load_lh_array_tag(Node* kls) {</span>
<span class="line-added">+   Node* lhp = basic_plus_adr(kls, in_bytes(Klass::layout_helper_offset()));</span>
<span class="line-added">+   Node* layout_val = _gvn.transform(LoadNode::make(_gvn, NULL, immutable_memory(), lhp, lhp-&gt;bottom_type()-&gt;is_ptr(), TypeInt::INT, T_INT, MemNode::unordered));</span>
<span class="line-added">+   return _gvn.transform(new RShiftINode(layout_val, intcon(Klass::_lh_array_tag_shift)));</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ Node* GraphKit::gen_lh_array_test(Node* kls, unsigned int lh_value) {</span>
<span class="line-added">+   Node* layout_val = load_lh_array_tag(kls);</span>
<span class="line-added">+   Node* cmp = _gvn.transform(new CmpINode(layout_val, intcon(lh_value)));</span>
<span class="line-added">+   return cmp;</span>
  }
  
  //------------------------------next_monitor-----------------------------------
  // What number should be given to the next monitor?
  int GraphKit::next_monitor() {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3355,10 ***</span>
<span class="line-new-header">--- 3696,11 ---</span>
    // %%% SynchronizationEntryBCI is redundant; use InvocationEntryBci in interfaces
    assert(SynchronizationEntryBCI == InvocationEntryBci, &quot;&quot;);
  
    if( !GenerateSynchronizationCode )
      return NULL;                // Not locking things?
<span class="line-added">+ </span>
    if (stopped())                // Dead monitor?
      return NULL;
  
    assert(dead_locals_are_killed(), &quot;should kill locals before sync. point&quot;);
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3427,10 ***</span>
<span class="line-new-header">--- 3769,11 ---</span>
      return;
    if (stopped()) {               // Dead monitor?
      map()-&gt;pop_monitor();        // Kill monitor from debug info
      return;
    }
<span class="line-added">+   assert(!obj-&gt;is_InlineTypeBase(), &quot;should not unlock on inline type&quot;);</span>
  
    // Memory barrier to avoid floating things down past the locked region
    insert_mem_bar(Op_MemBarReleaseLock);
  
    const TypeFunc *tf = OptoRuntime::complete_monitor_exit_Type();
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3467,12 ***</span>
  // almost always feature constant types.
  Node* GraphKit::get_layout_helper(Node* klass_node, jint&amp; constant_value) {
    const TypeKlassPtr* inst_klass = _gvn.type(klass_node)-&gt;isa_klassptr();
    if (!StressReflectiveCode &amp;&amp; inst_klass != NULL) {
      ciKlass* klass = inst_klass-&gt;klass();
      bool    xklass = inst_klass-&gt;klass_is_exact();
<span class="line-modified">!     if (xklass || klass-&gt;is_array_klass()) {</span>
        jint lhelper = klass-&gt;layout_helper();
        if (lhelper != Klass::_lh_neutral_value) {
          constant_value = lhelper;
          return (Node*) NULL;
        }
<span class="line-new-header">--- 3810,18 ---</span>
  // almost always feature constant types.
  Node* GraphKit::get_layout_helper(Node* klass_node, jint&amp; constant_value) {
    const TypeKlassPtr* inst_klass = _gvn.type(klass_node)-&gt;isa_klassptr();
    if (!StressReflectiveCode &amp;&amp; inst_klass != NULL) {
      ciKlass* klass = inst_klass-&gt;klass();
<span class="line-added">+     assert(klass != NULL, &quot;klass should not be NULL&quot;);</span>
      bool    xklass = inst_klass-&gt;klass_is_exact();
<span class="line-modified">!     bool can_be_flattened = false;</span>
<span class="line-added">+     if (UseFlatArray &amp;&amp; klass-&gt;is_obj_array_klass()) {</span>
<span class="line-added">+       ciKlass* elem = klass-&gt;as_obj_array_klass()-&gt;element_klass();</span>
<span class="line-added">+       can_be_flattened = elem-&gt;can_be_inline_klass() &amp;&amp; (!elem-&gt;is_inlinetype() || elem-&gt;flatten_array());</span>
<span class="line-added">+     }</span>
<span class="line-added">+     if (xklass || (klass-&gt;is_array_klass() &amp;&amp; !can_be_flattened)) {</span>
        jint lhelper = klass-&gt;layout_helper();
        if (lhelper != Klass::_lh_neutral_value) {
          constant_value = lhelper;
          return (Node*) NULL;
        }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3530,21 ***</span>
      // and link them properly (as a group) to the InitializeNode.
      assert(init-&gt;in(InitializeNode::Memory) == malloc, &quot;&quot;);
      MergeMemNode* minit_in = MergeMemNode::make(malloc);
      init-&gt;set_req(InitializeNode::Memory, minit_in);
      record_for_igvn(minit_in); // fold it up later, if possible
      Node* minit_out = memory(rawidx);
      assert(minit_out-&gt;is_Proj() &amp;&amp; minit_out-&gt;in(0) == init, &quot;&quot;);
      // Add an edge in the MergeMem for the header fields so an access
      // to one of those has correct memory state
      set_memory(minit_out, C-&gt;get_alias_index(oop_type-&gt;add_offset(oopDesc::mark_offset_in_bytes())));
      set_memory(minit_out, C-&gt;get_alias_index(oop_type-&gt;add_offset(oopDesc::klass_offset_in_bytes())));
      if (oop_type-&gt;isa_aryptr()) {
<span class="line-modified">!       const TypePtr* telemref = oop_type-&gt;add_offset(Type::OffsetBot);</span>
<span class="line-modified">!       int            elemidx  = C-&gt;get_alias_index(telemref);</span>
<span class="line-modified">!       hook_memory_on_init(*this, elemidx, minit_in, minit_out);</span>
      } else if (oop_type-&gt;isa_instptr()) {
        ciInstanceKlass* ik = oop_type-&gt;klass()-&gt;as_instance_klass();
        for (int i = 0, len = ik-&gt;nof_nonstatic_fields(); i &lt; len; i++) {
          ciField* field = ik-&gt;nonstatic_field_at(i);
          if (field-&gt;offset() &gt;= TrackedInitializationLimit * HeapWordSize)
            continue;  // do not bother to track really large numbers of fields
<span class="line-new-header">--- 3879,46 ---</span>
      // and link them properly (as a group) to the InitializeNode.
      assert(init-&gt;in(InitializeNode::Memory) == malloc, &quot;&quot;);
      MergeMemNode* minit_in = MergeMemNode::make(malloc);
      init-&gt;set_req(InitializeNode::Memory, minit_in);
      record_for_igvn(minit_in); // fold it up later, if possible
<span class="line-added">+     _gvn.set_type(minit_in, Type::MEMORY);</span>
      Node* minit_out = memory(rawidx);
      assert(minit_out-&gt;is_Proj() &amp;&amp; minit_out-&gt;in(0) == init, &quot;&quot;);
      // Add an edge in the MergeMem for the header fields so an access
      // to one of those has correct memory state
      set_memory(minit_out, C-&gt;get_alias_index(oop_type-&gt;add_offset(oopDesc::mark_offset_in_bytes())));
      set_memory(minit_out, C-&gt;get_alias_index(oop_type-&gt;add_offset(oopDesc::klass_offset_in_bytes())));
      if (oop_type-&gt;isa_aryptr()) {
<span class="line-modified">!       const TypeAryPtr* arytype = oop_type-&gt;is_aryptr();</span>
<span class="line-modified">!       if (arytype-&gt;klass()-&gt;is_flat_array_klass()) {</span>
<span class="line-modified">!         // Initially all flattened array accesses share a single slice</span>
<span class="line-added">+         // but that changes after parsing. Prepare the memory graph so</span>
<span class="line-added">+         // it can optimize flattened array accesses properly once they</span>
<span class="line-added">+         // don&#39;t share a single slice.</span>
<span class="line-added">+         assert(C-&gt;flattened_accesses_share_alias(), &quot;should be set at parse time&quot;);</span>
<span class="line-added">+         C-&gt;set_flattened_accesses_share_alias(false);</span>
<span class="line-added">+         ciFlatArrayKlass* vak = arytype-&gt;klass()-&gt;as_flat_array_klass();</span>
<span class="line-added">+         ciInlineKlass* vk = vak-&gt;element_klass()-&gt;as_inline_klass();</span>
<span class="line-added">+         for (int i = 0, len = vk-&gt;nof_nonstatic_fields(); i &lt; len; i++) {</span>
<span class="line-added">+           ciField* field = vk-&gt;nonstatic_field_at(i);</span>
<span class="line-added">+           if (field-&gt;offset() &gt;= TrackedInitializationLimit * HeapWordSize)</span>
<span class="line-added">+             continue;  // do not bother to track really large numbers of fields</span>
<span class="line-added">+           int off_in_vt = field-&gt;offset() - vk-&gt;first_field_offset();</span>
<span class="line-added">+           const TypePtr* adr_type = arytype-&gt;with_field_offset(off_in_vt)-&gt;add_offset(Type::OffsetBot);</span>
<span class="line-added">+           int fieldidx = C-&gt;get_alias_index(adr_type, true);</span>
<span class="line-added">+           hook_memory_on_init(*this, fieldidx, minit_in, minit_out);</span>
<span class="line-added">+         }</span>
<span class="line-added">+         C-&gt;set_flattened_accesses_share_alias(true);</span>
<span class="line-added">+         hook_memory_on_init(*this, C-&gt;get_alias_index(TypeAryPtr::INLINES), minit_in, minit_out);</span>
<span class="line-added">+       } else {</span>
<span class="line-added">+         const TypePtr* telemref = oop_type-&gt;add_offset(Type::OffsetBot);</span>
<span class="line-added">+         int            elemidx  = C-&gt;get_alias_index(telemref);</span>
<span class="line-added">+         hook_memory_on_init(*this, elemidx, minit_in, minit_out);</span>
<span class="line-added">+       }</span>
      } else if (oop_type-&gt;isa_instptr()) {
<span class="line-added">+       set_memory(minit_out, C-&gt;get_alias_index(oop_type)); // mark word</span>
        ciInstanceKlass* ik = oop_type-&gt;klass()-&gt;as_instance_klass();
        for (int i = 0, len = ik-&gt;nof_nonstatic_fields(); i &lt; len; i++) {
          ciField* field = ik-&gt;nonstatic_field_at(i);
          if (field-&gt;offset() &gt;= TrackedInitializationLimit * HeapWordSize)
            continue;  // do not bother to track really large numbers of fields
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3591,18 ***</span>
  //  - If &#39;return_size_val&#39;, report the the total object size to the caller.
  //  - deoptimize_on_exception controls how Java exceptions are handled (rethrow vs deoptimize)
  Node* GraphKit::new_instance(Node* klass_node,
                               Node* extra_slow_test,
                               Node* *return_size_val,
<span class="line-modified">!                              bool deoptimize_on_exception) {</span>
    // Compute size in doublewords
    // The size is always an integral number of doublewords, represented
    // as a positive bytewise size stored in the klass&#39;s layout_helper.
    // The layout_helper also encodes (in a low bit) the need for a slow path.
    jint  layout_con = Klass::_lh_neutral_value;
    Node* layout_val = get_layout_helper(klass_node, layout_con);
<span class="line-modified">!   int   layout_is_con = (layout_val == NULL);</span>
  
    if (extra_slow_test == NULL)  extra_slow_test = intcon(0);
    // Generate the initial go-slow test.  It&#39;s either ALWAYS (return a
    // Node for 1) or NEVER (return a NULL) or perhaps (in the reflective
    // case) a computed value derived from the layout_helper.
<span class="line-new-header">--- 3965,19 ---</span>
  //  - If &#39;return_size_val&#39;, report the the total object size to the caller.
  //  - deoptimize_on_exception controls how Java exceptions are handled (rethrow vs deoptimize)
  Node* GraphKit::new_instance(Node* klass_node,
                               Node* extra_slow_test,
                               Node* *return_size_val,
<span class="line-modified">!                              bool deoptimize_on_exception,</span>
<span class="line-added">+                              InlineTypeBaseNode* inline_type_node) {</span>
    // Compute size in doublewords
    // The size is always an integral number of doublewords, represented
    // as a positive bytewise size stored in the klass&#39;s layout_helper.
    // The layout_helper also encodes (in a low bit) the need for a slow path.
    jint  layout_con = Klass::_lh_neutral_value;
    Node* layout_val = get_layout_helper(klass_node, layout_con);
<span class="line-modified">!   bool  layout_is_con = (layout_val == NULL);</span>
  
    if (extra_slow_test == NULL)  extra_slow_test = intcon(0);
    // Generate the initial go-slow test.  It&#39;s either ALWAYS (return a
    // Node for 1) or NEVER (return a NULL) or perhaps (in the reflective
    // case) a computed value derived from the layout_helper.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3649,34 ***</span>
    const TypeOopPtr* oop_type = tklass-&gt;as_instance_type();
  
    // Now generate allocation code
  
    // The entire memory state is needed for slow path of the allocation
<span class="line-modified">!   // since GC and deoptimization can happened.</span>
    Node *mem = reset_memory();
    set_all_memory(mem); // Create new memory state
  
    AllocateNode* alloc = new AllocateNode(C, AllocateNode::alloc_type(Type::TOP),
                                           control(), mem, i_o(),
                                           size, klass_node,
<span class="line-modified">!                                          initial_slow_test);</span>
  
    return set_output_for_allocation(alloc, oop_type, deoptimize_on_exception);
  }
  
  //-------------------------------new_array-------------------------------------
<span class="line-modified">! // helper for both newarray and anewarray</span>
  // The &#39;length&#39; parameter is (obviously) the length of the array.
  // See comments on new_instance for the meaning of the other arguments.
  Node* GraphKit::new_array(Node* klass_node,     // array klass (maybe variable)
                            Node* length,         // number of array elements
                            int   nargs,          // number of arguments to push back for uncommon trap
                            Node* *return_size_val,
                            bool deoptimize_on_exception) {
    jint  layout_con = Klass::_lh_neutral_value;
    Node* layout_val = get_layout_helper(klass_node, layout_con);
<span class="line-modified">!   int   layout_is_con = (layout_val == NULL);</span>
  
    if (!layout_is_con &amp;&amp; !StressReflectiveCode &amp;&amp;
        !too_many_traps(Deoptimization::Reason_class_check)) {
      // This is a reflective array creation site.
      // Optimistically assume that it is a subtype of Object[],
<span class="line-new-header">--- 4024,42 ---</span>
    const TypeOopPtr* oop_type = tklass-&gt;as_instance_type();
  
    // Now generate allocation code
  
    // The entire memory state is needed for slow path of the allocation
<span class="line-modified">!   // since GC and deoptimization can happen.</span>
    Node *mem = reset_memory();
    set_all_memory(mem); // Create new memory state
  
    AllocateNode* alloc = new AllocateNode(C, AllocateNode::alloc_type(Type::TOP),
                                           control(), mem, i_o(),
                                           size, klass_node,
<span class="line-modified">!                                          initial_slow_test, inline_type_node);</span>
  
    return set_output_for_allocation(alloc, oop_type, deoptimize_on_exception);
  }
  
<span class="line-added">+ // With compressed oops, the 64 bit init value for non flattened value</span>
<span class="line-added">+ // arrays is built from 2 32 bit compressed oops</span>
<span class="line-added">+ static Node* raw_default_for_coops(Node* default_value, GraphKit&amp; kit) {</span>
<span class="line-added">+   Node* lower = kit.gvn().transform(new CastP2XNode(kit.control(), default_value));</span>
<span class="line-added">+   Node* upper = kit.gvn().transform(new LShiftLNode(lower, kit.intcon(32)));</span>
<span class="line-added">+   return kit.gvn().transform(new OrLNode(lower, upper));</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
  //-------------------------------new_array-------------------------------------
<span class="line-modified">! // helper for newarray and anewarray</span>
  // The &#39;length&#39; parameter is (obviously) the length of the array.
  // See comments on new_instance for the meaning of the other arguments.
  Node* GraphKit::new_array(Node* klass_node,     // array klass (maybe variable)
                            Node* length,         // number of array elements
                            int   nargs,          // number of arguments to push back for uncommon trap
                            Node* *return_size_val,
                            bool deoptimize_on_exception) {
    jint  layout_con = Klass::_lh_neutral_value;
    Node* layout_val = get_layout_helper(klass_node, layout_con);
<span class="line-modified">!   bool  layout_is_con = (layout_val == NULL);</span>
  
    if (!layout_is_con &amp;&amp; !StressReflectiveCode &amp;&amp;
        !too_many_traps(Deoptimization::Reason_class_check)) {
      // This is a reflective array creation site.
      // Optimistically assume that it is a subtype of Object[],
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3702,11 ***</span>
    int fast_size_limit = FastAllocateSizeLimit;
    if (layout_is_con) {
      assert(!StressReflectiveCode, &quot;stress mode does not use these paths&quot;);
      // Increase the size limit if we have exact knowledge of array type.
      int log2_esize = Klass::layout_helper_log2_element_size(layout_con);
<span class="line-modified">!     fast_size_limit &lt;&lt;= (LogBytesPerLong - log2_esize);</span>
    }
  
    Node* initial_slow_cmp  = _gvn.transform( new CmpUNode( length, intcon( fast_size_limit ) ) );
    Node* initial_slow_test = _gvn.transform( new BoolNode( initial_slow_cmp, BoolTest::gt ) );
  
<span class="line-new-header">--- 4085,11 ---</span>
    int fast_size_limit = FastAllocateSizeLimit;
    if (layout_is_con) {
      assert(!StressReflectiveCode, &quot;stress mode does not use these paths&quot;);
      // Increase the size limit if we have exact knowledge of array type.
      int log2_esize = Klass::layout_helper_log2_element_size(layout_con);
<span class="line-modified">!     fast_size_limit &lt;&lt;= MAX2(LogBytesPerLong - log2_esize, 0);</span>
    }
  
    Node* initial_slow_cmp  = _gvn.transform( new CmpUNode( length, intcon( fast_size_limit ) ) );
    Node* initial_slow_test = _gvn.transform( new BoolNode( initial_slow_cmp, BoolTest::gt ) );
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3720,14 ***</span>
    int   header_size_min  = arrayOopDesc::base_offset_in_bytes(T_BYTE);
    // (T_BYTE has the weakest alignment and size restrictions...)
    if (layout_is_con) {
      int       hsize  = Klass::layout_helper_header_size(layout_con);
      int       eshift = Klass::layout_helper_log2_element_size(layout_con);
<span class="line-modified">!     BasicType etype  = Klass::layout_helper_element_type(layout_con);</span>
      if ((round_mask &amp; ~right_n_bits(eshift)) == 0)
        round_mask = 0;  // strength-reduce it if it goes away completely
<span class="line-modified">!     assert((hsize &amp; right_n_bits(eshift)) == 0, &quot;hsize is pre-rounded&quot;);</span>
      assert(header_size_min &lt;= hsize, &quot;generic minimum is smallest&quot;);
      header_size_min = hsize;
      header_size = intcon(hsize + round_mask);
    } else {
      Node* hss   = intcon(Klass::_lh_header_size_shift);
<span class="line-new-header">--- 4103,14 ---</span>
    int   header_size_min  = arrayOopDesc::base_offset_in_bytes(T_BYTE);
    // (T_BYTE has the weakest alignment and size restrictions...)
    if (layout_is_con) {
      int       hsize  = Klass::layout_helper_header_size(layout_con);
      int       eshift = Klass::layout_helper_log2_element_size(layout_con);
<span class="line-modified">!     bool is_flat_array = Klass::layout_helper_is_flatArray(layout_con);</span>
      if ((round_mask &amp; ~right_n_bits(eshift)) == 0)
        round_mask = 0;  // strength-reduce it if it goes away completely
<span class="line-modified">!     assert(is_flat_array || (hsize &amp; right_n_bits(eshift)) == 0, &quot;hsize is pre-rounded&quot;);</span>
      assert(header_size_min &lt;= hsize, &quot;generic minimum is smallest&quot;);
      header_size_min = hsize;
      header_size = intcon(hsize + round_mask);
    } else {
      Node* hss   = intcon(Klass::_lh_header_size_shift);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3807,33 ***</span>
    }
  
    // Now generate allocation code
  
    // The entire memory state is needed for slow path of the allocation
<span class="line-modified">!   // since GC and deoptimization can happened.</span>
    Node *mem = reset_memory();
    set_all_memory(mem); // Create new memory state
  
    if (initial_slow_test-&gt;is_Bool()) {
      // Hide it behind a CMoveI, or else PhaseIdealLoop::split_up will get sick.
      initial_slow_test = initial_slow_test-&gt;as_Bool()-&gt;as_int_value(&amp;_gvn);
    }
  
    // Create the AllocateArrayNode and its result projections
<span class="line-modified">!   AllocateArrayNode* alloc</span>
<span class="line-modified">!     = new AllocateArrayNode(C, AllocateArrayNode::alloc_type(TypeInt::INT),</span>
<span class="line-modified">!                             control(), mem, i_o(),</span>
<span class="line-modified">!                             size, klass_node,</span>
<span class="line-modified">!                             initial_slow_test,</span>
<span class="line-modified">!                             length);</span>
  
    // Cast to correct type.  Note that the klass_node may be constant or not,
    // and in the latter case the actual array type will be inexact also.
    // (This happens via a non-constant argument to inline_native_newArray.)
    // In any case, the value of klass_node provides the desired array type.
    const TypeInt* length_type = _gvn.find_int_type(length);
<span class="line-removed">-   const TypeOopPtr* ary_type = _gvn.type(klass_node)-&gt;is_klassptr()-&gt;as_instance_type();</span>
    if (ary_type-&gt;isa_aryptr() &amp;&amp; length_type != NULL) {
      // Try to get a better type than POS for the size
      ary_type = ary_type-&gt;is_aryptr()-&gt;cast_to_size(length_type);
    }
  
<span class="line-new-header">--- 4190,112 ---</span>
    }
  
    // Now generate allocation code
  
    // The entire memory state is needed for slow path of the allocation
<span class="line-modified">!   // since GC and deoptimization can happen.</span>
    Node *mem = reset_memory();
    set_all_memory(mem); // Create new memory state
  
    if (initial_slow_test-&gt;is_Bool()) {
      // Hide it behind a CMoveI, or else PhaseIdealLoop::split_up will get sick.
      initial_slow_test = initial_slow_test-&gt;as_Bool()-&gt;as_int_value(&amp;_gvn);
    }
  
<span class="line-added">+   const TypeKlassPtr* ary_klass = _gvn.type(klass_node)-&gt;isa_klassptr();</span>
<span class="line-added">+   const TypeOopPtr* ary_type = ary_klass-&gt;as_instance_type();</span>
<span class="line-added">+   const TypeAryPtr* ary_ptr = ary_type-&gt;isa_aryptr();</span>
<span class="line-added">+ </span>
<span class="line-added">+   // Inline type array variants:</span>
<span class="line-added">+   // - null-ok:              MyValue.ref[] (ciObjArrayKlass &quot;[LMyValue$ref&quot;)</span>
<span class="line-added">+   // - null-free:            MyValue.val[] (ciObjArrayKlass &quot;[QMyValue$val&quot;)</span>
<span class="line-added">+   // - null-free, flattened: MyValue.val[] (ciFlatArrayKlass &quot;[QMyValue$val&quot;)</span>
<span class="line-added">+   // Check if array is a null-free, non-flattened inline type array</span>
<span class="line-added">+   // that needs to be initialized with the default inline type.</span>
<span class="line-added">+   Node* default_value = NULL;</span>
<span class="line-added">+   Node* raw_default_value = NULL;</span>
<span class="line-added">+   if (ary_ptr != NULL &amp;&amp; ary_ptr-&gt;klass_is_exact()) {</span>
<span class="line-added">+     // Array type is known</span>
<span class="line-added">+     ciKlass* elem_klass = ary_ptr-&gt;klass()-&gt;as_array_klass()-&gt;element_klass();</span>
<span class="line-added">+     if (elem_klass != NULL &amp;&amp; elem_klass-&gt;is_inlinetype()) {</span>
<span class="line-added">+       ciInlineKlass* vk = elem_klass-&gt;as_inline_klass();</span>
<span class="line-added">+       if (!vk-&gt;flatten_array()) {</span>
<span class="line-added">+         default_value = InlineTypeNode::default_oop(gvn(), vk);</span>
<span class="line-added">+         if (UseCompressedOops) {</span>
<span class="line-added">+           default_value = _gvn.transform(new EncodePNode(default_value, default_value-&gt;bottom_type()-&gt;make_narrowoop()));</span>
<span class="line-added">+           raw_default_value = raw_default_for_coops(default_value, *this);</span>
<span class="line-added">+         } else {</span>
<span class="line-added">+           raw_default_value = _gvn.transform(new CastP2XNode(control(), default_value));</span>
<span class="line-added">+         }</span>
<span class="line-added">+       }</span>
<span class="line-added">+     }</span>
<span class="line-added">+   } else if (ary_klass-&gt;klass()-&gt;can_be_inline_array_klass()) {</span>
<span class="line-added">+     // Array type is not known, add runtime checks</span>
<span class="line-added">+     assert(!ary_klass-&gt;klass_is_exact(), &quot;unexpected exact type&quot;);</span>
<span class="line-added">+     Node* r = new RegionNode(4);</span>
<span class="line-added">+     default_value = new PhiNode(r, TypeInstPtr::BOTTOM);</span>
<span class="line-added">+ </span>
<span class="line-added">+     // Check if array is an object array</span>
<span class="line-added">+     Node* cmp = gen_lh_array_test(klass_node, Klass::_lh_array_tag_obj_value);</span>
<span class="line-added">+     Node* bol = _gvn.transform(new BoolNode(cmp, BoolTest::eq));</span>
<span class="line-added">+     IfNode* iff = create_and_map_if(control(), bol, PROB_FAIR, COUNT_UNKNOWN);</span>
<span class="line-added">+ </span>
<span class="line-added">+     // Not an object array, initialize with all zero</span>
<span class="line-added">+     r-&gt;init_req(1, _gvn.transform(new IfFalseNode(iff)));</span>
<span class="line-added">+     default_value-&gt;init_req(1, null());</span>
<span class="line-added">+ </span>
<span class="line-added">+     // Object array, check if null-free</span>
<span class="line-added">+     set_control(_gvn.transform(new IfTrueNode(iff)));</span>
<span class="line-added">+     Node* lhp = basic_plus_adr(klass_node, in_bytes(Klass::layout_helper_offset()));</span>
<span class="line-added">+     Node* layout_val = _gvn.transform(LoadNode::make(_gvn, NULL, immutable_memory(), lhp, lhp-&gt;bottom_type()-&gt;is_ptr(), TypeInt::INT, T_INT, MemNode::unordered));</span>
<span class="line-added">+     Node* null_free = _gvn.transform(new RShiftINode(layout_val, intcon(Klass::_lh_null_free_shift)));</span>
<span class="line-added">+     null_free = _gvn.transform(new AndINode(null_free, intcon(Klass::_lh_null_free_mask)));</span>
<span class="line-added">+     cmp = _gvn.transform(new CmpINode(null_free, intcon(0)));</span>
<span class="line-added">+     bol = _gvn.transform(new BoolNode(cmp, BoolTest::ne));</span>
<span class="line-added">+     iff = create_and_map_if(control(), bol, PROB_FAIR, COUNT_UNKNOWN);</span>
<span class="line-added">+ </span>
<span class="line-added">+     // Not null-free, initialize with all zero</span>
<span class="line-added">+     r-&gt;init_req(2, _gvn.transform(new IfFalseNode(iff)));</span>
<span class="line-added">+     default_value-&gt;init_req(2, null());</span>
<span class="line-added">+ </span>
<span class="line-added">+     // Null-free, non-flattened inline type array, initialize with the default value</span>
<span class="line-added">+     set_control(_gvn.transform(new IfTrueNode(iff)));</span>
<span class="line-added">+     Node* p = basic_plus_adr(klass_node, in_bytes(ArrayKlass::element_klass_offset()));</span>
<span class="line-added">+     Node* eklass = _gvn.transform(LoadKlassNode::make(_gvn, control(), immutable_memory(), p, TypeInstPtr::KLASS));</span>
<span class="line-added">+     Node* adr_fixed_block_addr = basic_plus_adr(eklass, in_bytes(InstanceKlass::adr_inlineklass_fixed_block_offset()));</span>
<span class="line-added">+     Node* adr_fixed_block = make_load(control(), adr_fixed_block_addr, TypeRawPtr::NOTNULL, T_ADDRESS, MemNode::unordered);</span>
<span class="line-added">+     Node* default_value_offset_addr = basic_plus_adr(adr_fixed_block, in_bytes(InlineKlass::default_value_offset_offset()));</span>
<span class="line-added">+     Node* default_value_offset = make_load(control(), default_value_offset_addr, TypeInt::INT, T_INT, MemNode::unordered);</span>
<span class="line-added">+     Node* elem_mirror = load_mirror_from_klass(eklass);</span>
<span class="line-added">+     Node* default_value_addr = basic_plus_adr(elem_mirror, ConvI2X(default_value_offset));</span>
<span class="line-added">+     Node* val = access_load_at(elem_mirror, default_value_addr, _gvn.type(default_value_addr)-&gt;is_ptr(), TypeInstPtr::BOTTOM, T_OBJECT, IN_HEAP);</span>
<span class="line-added">+     r-&gt;init_req(3, control());</span>
<span class="line-added">+     default_value-&gt;init_req(3, val);</span>
<span class="line-added">+ </span>
<span class="line-added">+     set_control(_gvn.transform(r));</span>
<span class="line-added">+     default_value = _gvn.transform(default_value);</span>
<span class="line-added">+     if (UseCompressedOops) {</span>
<span class="line-added">+       default_value = _gvn.transform(new EncodePNode(default_value, default_value-&gt;bottom_type()-&gt;make_narrowoop()));</span>
<span class="line-added">+       raw_default_value = raw_default_for_coops(default_value, *this);</span>
<span class="line-added">+     } else {</span>
<span class="line-added">+       raw_default_value = _gvn.transform(new CastP2XNode(control(), default_value));</span>
<span class="line-added">+     }</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
    // Create the AllocateArrayNode and its result projections
<span class="line-modified">!   AllocateArrayNode* alloc = new AllocateArrayNode(C, AllocateArrayNode::alloc_type(TypeInt::INT),</span>
<span class="line-modified">!                                                    control(), mem, i_o(),</span>
<span class="line-modified">!                                                    size, klass_node,</span>
<span class="line-modified">!                                                    initial_slow_test,</span>
<span class="line-modified">!                                                    length, default_value,</span>
<span class="line-modified">!                                                    raw_default_value);</span>
  
    // Cast to correct type.  Note that the klass_node may be constant or not,
    // and in the latter case the actual array type will be inexact also.
    // (This happens via a non-constant argument to inline_native_newArray.)
    // In any case, the value of klass_node provides the desired array type.
    const TypeInt* length_type = _gvn.find_int_type(length);
    if (ary_type-&gt;isa_aryptr() &amp;&amp; length_type != NULL) {
      // Try to get a better type than POS for the size
      ary_type = ary_type-&gt;is_aryptr()-&gt;cast_to_size(length_type);
    }
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3987,15 ***</span>
  }
  
  Node* GraphKit::load_String_value(Node* str, bool set_ctrl) {
    int value_offset = java_lang_String::value_offset();
    const TypeInstPtr* string_type = TypeInstPtr::make(TypePtr::NotNull, C-&gt;env()-&gt;String_klass(),
<span class="line-modified">!                                                      false, NULL, 0);</span>
    const TypePtr* value_field_type = string_type-&gt;add_offset(value_offset);
    const TypeAryPtr* value_type = TypeAryPtr::make(TypePtr::NotNull,
<span class="line-modified">!                                                   TypeAry::make(TypeInt::BYTE, TypeInt::POS),</span>
<span class="line-modified">!                                                   ciTypeArrayKlass::make(T_BYTE), true, 0);</span>
    Node* p = basic_plus_adr(str, str, value_offset);
    Node* load = access_load_at(str, p, value_field_type, value_type, T_OBJECT,
                                IN_HEAP | (set_ctrl ? C2_CONTROL_DEPENDENT_LOAD : 0) | MO_UNORDERED);
    return load;
  }
<span class="line-new-header">--- 4449,15 ---</span>
  }
  
  Node* GraphKit::load_String_value(Node* str, bool set_ctrl) {
    int value_offset = java_lang_String::value_offset();
    const TypeInstPtr* string_type = TypeInstPtr::make(TypePtr::NotNull, C-&gt;env()-&gt;String_klass(),
<span class="line-modified">!                                                      false, NULL, Type::Offset(0));</span>
    const TypePtr* value_field_type = string_type-&gt;add_offset(value_offset);
    const TypeAryPtr* value_type = TypeAryPtr::make(TypePtr::NotNull,
<span class="line-modified">!                                                   TypeAry::make(TypeInt::BYTE, TypeInt::POS, false, true, true),</span>
<span class="line-modified">!                                                   ciTypeArrayKlass::make(T_BYTE), true, Type::Offset(0));</span>
    Node* p = basic_plus_adr(str, str, value_offset);
    Node* load = access_load_at(str, p, value_field_type, value_type, T_OBJECT,
                                IN_HEAP | (set_ctrl ? C2_CONTROL_DEPENDENT_LOAD : 0) | MO_UNORDERED);
    return load;
  }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 4004,11 ***</span>
    if (!CompactStrings) {
      return intcon(java_lang_String::CODER_UTF16);
    }
    int coder_offset = java_lang_String::coder_offset();
    const TypeInstPtr* string_type = TypeInstPtr::make(TypePtr::NotNull, C-&gt;env()-&gt;String_klass(),
<span class="line-modified">!                                                      false, NULL, 0);</span>
    const TypePtr* coder_field_type = string_type-&gt;add_offset(coder_offset);
  
    Node* p = basic_plus_adr(str, str, coder_offset);
    Node* load = access_load_at(str, p, coder_field_type, TypeInt::BYTE, T_BYTE,
                                IN_HEAP | (set_ctrl ? C2_CONTROL_DEPENDENT_LOAD : 0) | MO_UNORDERED);
<span class="line-new-header">--- 4466,11 ---</span>
    if (!CompactStrings) {
      return intcon(java_lang_String::CODER_UTF16);
    }
    int coder_offset = java_lang_String::coder_offset();
    const TypeInstPtr* string_type = TypeInstPtr::make(TypePtr::NotNull, C-&gt;env()-&gt;String_klass(),
<span class="line-modified">!                                                      false, NULL, Type::Offset(0));</span>
    const TypePtr* coder_field_type = string_type-&gt;add_offset(coder_offset);
  
    Node* p = basic_plus_adr(str, str, coder_offset);
    Node* load = access_load_at(str, p, coder_field_type, TypeInt::BYTE, T_BYTE,
                                IN_HEAP | (set_ctrl ? C2_CONTROL_DEPENDENT_LOAD : 0) | MO_UNORDERED);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 4016,21 ***</span>
  }
  
  void GraphKit::store_String_value(Node* str, Node* value) {
    int value_offset = java_lang_String::value_offset();
    const TypeInstPtr* string_type = TypeInstPtr::make(TypePtr::NotNull, C-&gt;env()-&gt;String_klass(),
<span class="line-modified">!                                                      false, NULL, 0);</span>
    const TypePtr* value_field_type = string_type-&gt;add_offset(value_offset);
  
    access_store_at(str,  basic_plus_adr(str, value_offset), value_field_type,
                    value, TypeAryPtr::BYTES, T_OBJECT, IN_HEAP | MO_UNORDERED);
  }
  
  void GraphKit::store_String_coder(Node* str, Node* value) {
    int coder_offset = java_lang_String::coder_offset();
    const TypeInstPtr* string_type = TypeInstPtr::make(TypePtr::NotNull, C-&gt;env()-&gt;String_klass(),
<span class="line-modified">!                                                      false, NULL, 0);</span>
    const TypePtr* coder_field_type = string_type-&gt;add_offset(coder_offset);
  
    access_store_at(str, basic_plus_adr(str, coder_offset), coder_field_type,
                    value, TypeInt::BYTE, T_BYTE, IN_HEAP | MO_UNORDERED);
  }
<span class="line-new-header">--- 4478,21 ---</span>
  }
  
  void GraphKit::store_String_value(Node* str, Node* value) {
    int value_offset = java_lang_String::value_offset();
    const TypeInstPtr* string_type = TypeInstPtr::make(TypePtr::NotNull, C-&gt;env()-&gt;String_klass(),
<span class="line-modified">!                                                      false, NULL, Type::Offset(0));</span>
    const TypePtr* value_field_type = string_type-&gt;add_offset(value_offset);
  
    access_store_at(str,  basic_plus_adr(str, value_offset), value_field_type,
                    value, TypeAryPtr::BYTES, T_OBJECT, IN_HEAP | MO_UNORDERED);
  }
  
  void GraphKit::store_String_coder(Node* str, Node* value) {
    int coder_offset = java_lang_String::coder_offset();
    const TypeInstPtr* string_type = TypeInstPtr::make(TypePtr::NotNull, C-&gt;env()-&gt;String_klass(),
<span class="line-modified">!                                                      false, NULL, Type::Offset(0));</span>
    const TypePtr* coder_field_type = string_type-&gt;add_offset(coder_offset);
  
    access_store_at(str, basic_plus_adr(str, coder_offset), coder_field_type,
                    value, TypeInt::BYTE, T_BYTE, IN_HEAP | MO_UNORDERED);
  }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 4137,9 ***</span>
      }
    }
    const Type* con_type = Type::make_constant_from_field(field, holder, field-&gt;layout_type(),
                                                          /*is_unsigned_load=*/false);
    if (con_type != NULL) {
<span class="line-modified">!     return makecon(con_type);</span>
    }
    return NULL;
  }
<span class="line-new-header">--- 4599,25 ---</span>
      }
    }
    const Type* con_type = Type::make_constant_from_field(field, holder, field-&gt;layout_type(),
                                                          /*is_unsigned_load=*/false);
    if (con_type != NULL) {
<span class="line-modified">!     Node* con = makecon(con_type);</span>
<span class="line-added">+     assert(!field-&gt;type()-&gt;is_inlinetype() || (field-&gt;is_static() &amp;&amp; !con_type-&gt;is_zero_type()), &quot;sanity&quot;);</span>
<span class="line-added">+     // Check type of constant which might be more precise</span>
<span class="line-added">+     if (con_type-&gt;is_inlinetypeptr() &amp;&amp; con_type-&gt;inline_klass()-&gt;is_scalarizable()) {</span>
<span class="line-added">+       // Load inline type from constant oop</span>
<span class="line-added">+       con = InlineTypeNode::make_from_oop(this, con, con_type-&gt;inline_klass());</span>
<span class="line-added">+     }</span>
<span class="line-added">+     return con;</span>
    }
    return NULL;
  }
<span class="line-added">+ </span>
<span class="line-added">+ //---------------------------load_mirror_from_klass----------------------------</span>
<span class="line-added">+ // Given a klass oop, load its java mirror (a java.lang.Class oop).</span>
<span class="line-added">+ Node* GraphKit::load_mirror_from_klass(Node* klass) {</span>
<span class="line-added">+   Node* p = basic_plus_adr(klass, in_bytes(Klass::java_mirror_offset()));</span>
<span class="line-added">+   Node* load = make_load(NULL, p, TypeRawPtr::NOTNULL, T_ADDRESS, MemNode::unordered);</span>
<span class="line-added">+   // mirror = ((OopHandle)mirror)-&gt;resolve();</span>
<span class="line-added">+   return access_load(load, TypeInstPtr::MIRROR, T_OBJECT, IN_NATIVE);</span>
<span class="line-added">+ }</span>
</pre>
<center><a href="compile.hpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macro.cpp.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>