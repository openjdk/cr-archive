<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/x86_64.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="c1_CodeStubs_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../../share/adlc/main.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/x86_64.ad</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 1620 // Do we need to mask the count passed to shift instructions or does
 1621 // the cpu only look at the lower 5/6 bits anyway?
 1622 const bool Matcher::need_masked_shift_count = false;
 1623 
 1624 bool Matcher::narrow_oop_use_complex_address() {
 1625   assert(UseCompressedOops, &quot;only for compressed oops code&quot;);
 1626   return (LogMinObjAlignmentInBytes &lt;= 3);
 1627 }
 1628 
 1629 bool Matcher::narrow_klass_use_complex_address() {
 1630   assert(UseCompressedClassPointers, &quot;only for compressed klass code&quot;);
 1631   return (LogKlassAlignmentInBytes &lt;= 3);
 1632 }
 1633 
 1634 bool Matcher::const_oop_prefer_decode() {
 1635   // Prefer ConN+DecodeN over ConP.
 1636   return true;
 1637 }
 1638 
 1639 bool Matcher::const_klass_prefer_decode() {
<span class="line-modified"> 1640   // TODO: Either support matching DecodeNKlass (heap-based) in operand</span>
<span class="line-removed"> 1641   //       or condisider the following:</span>
<span class="line-removed"> 1642   // Prefer ConNKlass+DecodeNKlass over ConP in simple compressed klass mode.</span>
<span class="line-removed"> 1643   //return CompressedKlassPointers::base() == NULL;</span>
 1644   return true;
 1645 }
 1646 
 1647 // Is it better to copy float constants, or load them directly from
 1648 // memory?  Intel can load a float constant from a direct address,
 1649 // requiring no extra registers.  Most RISCs will have to materialize
 1650 // an address into a register first, so they would do better to copy
 1651 // the constant from stack.
 1652 const bool Matcher::rematerialize_float_constants = true; // XXX
 1653 
 1654 // If CPU can load and store mis-aligned doubles directly then no
 1655 // fixup is needed.  Else we split the double into 2 integer pieces
 1656 // and move it piece-by-piece.  Only happens when passing doubles into
 1657 // C code as the Java calling convention forces doubles to be aligned.
 1658 const bool Matcher::misaligned_doubles_ok = true;
 1659 
 1660 // No-op on amd64
 1661 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {}
 1662 
 1663 // Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.
</pre>
</td>
<td>
<hr />
<pre>
 1620 // Do we need to mask the count passed to shift instructions or does
 1621 // the cpu only look at the lower 5/6 bits anyway?
 1622 const bool Matcher::need_masked_shift_count = false;
 1623 
 1624 bool Matcher::narrow_oop_use_complex_address() {
 1625   assert(UseCompressedOops, &quot;only for compressed oops code&quot;);
 1626   return (LogMinObjAlignmentInBytes &lt;= 3);
 1627 }
 1628 
 1629 bool Matcher::narrow_klass_use_complex_address() {
 1630   assert(UseCompressedClassPointers, &quot;only for compressed klass code&quot;);
 1631   return (LogKlassAlignmentInBytes &lt;= 3);
 1632 }
 1633 
 1634 bool Matcher::const_oop_prefer_decode() {
 1635   // Prefer ConN+DecodeN over ConP.
 1636   return true;
 1637 }
 1638 
 1639 bool Matcher::const_klass_prefer_decode() {
<span class="line-modified"> 1640   // Prefer ConP over ConNKlass+DecodeNKlass.</span>



 1641   return true;
 1642 }
 1643 
 1644 // Is it better to copy float constants, or load them directly from
 1645 // memory?  Intel can load a float constant from a direct address,
 1646 // requiring no extra registers.  Most RISCs will have to materialize
 1647 // an address into a register first, so they would do better to copy
 1648 // the constant from stack.
 1649 const bool Matcher::rematerialize_float_constants = true; // XXX
 1650 
 1651 // If CPU can load and store mis-aligned doubles directly then no
 1652 // fixup is needed.  Else we split the double into 2 integer pieces
 1653 // and move it piece-by-piece.  Only happens when passing doubles into
 1654 // C code as the Java calling convention forces doubles to be aligned.
 1655 const bool Matcher::misaligned_doubles_ok = true;
 1656 
 1657 // No-op on amd64
 1658 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {}
 1659 
 1660 // Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.
</pre>
</td>
</tr>
</table>
<center><a href="c1_CodeStubs_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../../share/adlc/main.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>