<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff src/hotspot/cpu/x86/sharedRuntime_x86_64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="../s390/interp_masm_s390.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="stubGenerator_x86_64.cpp.cdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/sharedRuntime_x86_64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 26,10 ***</span>
<span class="line-new-header">--- 26,11 ---</span>
  #ifndef _WINDOWS
  #include &quot;alloca.h&quot;
  #endif
  #include &quot;asm/macroAssembler.hpp&quot;
  #include &quot;asm/macroAssembler.inline.hpp&quot;
<span class="line-added">+ #include &quot;classfile/symbolTable.hpp&quot;</span>
  #include &quot;code/debugInfoRec.hpp&quot;
  #include &quot;code/icBuffer.hpp&quot;
  #include &quot;code/nativeInst.hpp&quot;
  #include &quot;code/vtableStubs.hpp&quot;
  #include &quot;gc/shared/collectedHeap.hpp&quot;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 491,10 ***</span>
<span class="line-new-header">--- 492,11 ---</span>
        assert((i + 1) &lt; total_args_passed &amp;&amp; sig_bt[i + 1] == T_VOID, &quot;expecting half&quot;);
        // fall through
      case T_OBJECT:
      case T_ARRAY:
      case T_ADDRESS:
<span class="line-added">+     case T_INLINE_TYPE:</span>
        if (int_args &lt; Argument::n_int_register_parameters_j) {
          regs[i].set2(INT_ArgReg[int_args++]-&gt;as_VMReg());
        } else {
          regs[i].set2(VMRegImpl::stack2reg(stk_args));
          stk_args += 2;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 524,10 ***</span>
<span class="line-new-header">--- 526,92 ---</span>
    }
  
    return align_up(stk_args, 2);
  }
  
<span class="line-added">+ // Same as java_calling_convention() but for multiple return</span>
<span class="line-added">+ // values. There&#39;s no way to store them on the stack so if we don&#39;t</span>
<span class="line-added">+ // have enough registers, multiple values can&#39;t be returned.</span>
<span class="line-added">+ const uint SharedRuntime::java_return_convention_max_int = Argument::n_int_register_parameters_j+1;</span>
<span class="line-added">+ const uint SharedRuntime::java_return_convention_max_float = Argument::n_float_register_parameters_j;</span>
<span class="line-added">+ int SharedRuntime::java_return_convention(const BasicType *sig_bt,</span>
<span class="line-added">+                                           VMRegPair *regs,</span>
<span class="line-added">+                                           int total_args_passed) {</span>
<span class="line-added">+   // Create the mapping between argument positions and</span>
<span class="line-added">+   // registers.</span>
<span class="line-added">+   static const Register INT_ArgReg[java_return_convention_max_int] = {</span>
<span class="line-added">+     rax, j_rarg5, j_rarg4, j_rarg3, j_rarg2, j_rarg1, j_rarg0</span>
<span class="line-added">+   };</span>
<span class="line-added">+   static const XMMRegister FP_ArgReg[java_return_convention_max_float] = {</span>
<span class="line-added">+     j_farg0, j_farg1, j_farg2, j_farg3,</span>
<span class="line-added">+     j_farg4, j_farg5, j_farg6, j_farg7</span>
<span class="line-added">+   };</span>
<span class="line-added">+ </span>
<span class="line-added">+ </span>
<span class="line-added">+   uint int_args = 0;</span>
<span class="line-added">+   uint fp_args = 0;</span>
<span class="line-added">+ </span>
<span class="line-added">+   for (int i = 0; i &lt; total_args_passed; i++) {</span>
<span class="line-added">+     switch (sig_bt[i]) {</span>
<span class="line-added">+     case T_BOOLEAN:</span>
<span class="line-added">+     case T_CHAR:</span>
<span class="line-added">+     case T_BYTE:</span>
<span class="line-added">+     case T_SHORT:</span>
<span class="line-added">+     case T_INT:</span>
<span class="line-added">+       if (int_args &lt; Argument::n_int_register_parameters_j+1) {</span>
<span class="line-added">+         regs[i].set1(INT_ArgReg[int_args]-&gt;as_VMReg());</span>
<span class="line-added">+         int_args++;</span>
<span class="line-added">+       } else {</span>
<span class="line-added">+         return -1;</span>
<span class="line-added">+       }</span>
<span class="line-added">+       break;</span>
<span class="line-added">+     case T_VOID:</span>
<span class="line-added">+       // halves of T_LONG or T_DOUBLE</span>
<span class="line-added">+       assert(i != 0 &amp;&amp; (sig_bt[i - 1] == T_LONG || sig_bt[i - 1] == T_DOUBLE), &quot;expecting half&quot;);</span>
<span class="line-added">+       regs[i].set_bad();</span>
<span class="line-added">+       break;</span>
<span class="line-added">+     case T_LONG:</span>
<span class="line-added">+       assert(sig_bt[i + 1] == T_VOID, &quot;expecting half&quot;);</span>
<span class="line-added">+       // fall through</span>
<span class="line-added">+     case T_OBJECT:</span>
<span class="line-added">+     case T_INLINE_TYPE:</span>
<span class="line-added">+     case T_ARRAY:</span>
<span class="line-added">+     case T_ADDRESS:</span>
<span class="line-added">+     case T_METADATA:</span>
<span class="line-added">+       if (int_args &lt; Argument::n_int_register_parameters_j+1) {</span>
<span class="line-added">+         regs[i].set2(INT_ArgReg[int_args]-&gt;as_VMReg());</span>
<span class="line-added">+         int_args++;</span>
<span class="line-added">+       } else {</span>
<span class="line-added">+         return -1;</span>
<span class="line-added">+       }</span>
<span class="line-added">+       break;</span>
<span class="line-added">+     case T_FLOAT:</span>
<span class="line-added">+       if (fp_args &lt; Argument::n_float_register_parameters_j) {</span>
<span class="line-added">+         regs[i].set1(FP_ArgReg[fp_args]-&gt;as_VMReg());</span>
<span class="line-added">+         fp_args++;</span>
<span class="line-added">+       } else {</span>
<span class="line-added">+         return -1;</span>
<span class="line-added">+       }</span>
<span class="line-added">+       break;</span>
<span class="line-added">+     case T_DOUBLE:</span>
<span class="line-added">+       assert(sig_bt[i + 1] == T_VOID, &quot;expecting half&quot;);</span>
<span class="line-added">+       if (fp_args &lt; Argument::n_float_register_parameters_j) {</span>
<span class="line-added">+         regs[i].set2(FP_ArgReg[fp_args]-&gt;as_VMReg());</span>
<span class="line-added">+         fp_args++;</span>
<span class="line-added">+       } else {</span>
<span class="line-added">+         return -1;</span>
<span class="line-added">+       }</span>
<span class="line-added">+       break;</span>
<span class="line-added">+     default:</span>
<span class="line-added">+       ShouldNotReachHere();</span>
<span class="line-added">+       break;</span>
<span class="line-added">+     }</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   return int_args + fp_args;</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
  // Patch the callers callsite with entry to compiled code if it exists.
  static void patch_callers_callsite(MacroAssembler *masm) {
    Label L;
    __ cmpptr(Address(rbx, in_bytes(Method::code_offset())), (int32_t)NULL_WORD);
    __ jcc(Assembler::equal, L);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 566,31 ***</span>
    // restore sp
    __ mov(rsp, r13);
    __ bind(L);
  }
  
  
  static void gen_c2i_adapter(MacroAssembler *masm,
<span class="line-modified">!                             int total_args_passed,</span>
<span class="line-removed">-                             int comp_args_on_stack,</span>
<span class="line-removed">-                             const BasicType *sig_bt,</span>
                              const VMRegPair *regs,
<span class="line-modified">!                             Label&amp; skip_fixup) {</span>
    // Before we get into the guts of the C2I adapter, see if we should be here
    // at all.  We&#39;ve come from compiled code and are attempting to jump to the
    // interpreter, which means the caller made a static call to get here
    // (vcalls always get a compiled target if there is one).  Check for a
    // compiled target.  If there is one, we need to patch the caller&#39;s call.
    patch_callers_callsite(masm);
  
    __ bind(skip_fixup);
  
    // Since all args are passed on the stack, total_args_passed *
    // Interpreter::stackElementSize is the space we need. Plus 1 because
    // we also account for the return address location since
    // we store it first rather than hold it in rax across all the shuffling
<span class="line-modified">! </span>
    int extraspace = (total_args_passed * Interpreter::stackElementSize) + wordSize;
  
    // stack is aligned, keep it that way
    extraspace = align_up(extraspace, 2*wordSize);
  
<span class="line-new-header">--- 650,184 ---</span>
    // restore sp
    __ mov(rsp, r13);
    __ bind(L);
  }
  
<span class="line-added">+ // For each inline type argument, sig includes the list of fields of</span>
<span class="line-added">+ // the inline type. This utility function computes the number of</span>
<span class="line-added">+ // arguments for the call if inline types are passed by reference (the</span>
<span class="line-added">+ // calling convention the interpreter expects).</span>
<span class="line-added">+ static int compute_total_args_passed_int(const GrowableArray&lt;SigEntry&gt;* sig_extended) {</span>
<span class="line-added">+   int total_args_passed = 0;</span>
<span class="line-added">+   if (InlineTypePassFieldsAsArgs) {</span>
<span class="line-added">+     for (int i = 0; i &lt; sig_extended-&gt;length(); i++) {</span>
<span class="line-added">+       BasicType bt = sig_extended-&gt;at(i)._bt;</span>
<span class="line-added">+       if (SigEntry::is_reserved_entry(sig_extended, i)) {</span>
<span class="line-added">+         // Ignore reserved entry</span>
<span class="line-added">+       } else if (bt == T_INLINE_TYPE) {</span>
<span class="line-added">+         // In sig_extended, an inline type argument starts with:</span>
<span class="line-added">+         // T_INLINE_TYPE, followed by the types of the fields of the</span>
<span class="line-added">+         // inline type and T_VOID to mark the end of the value</span>
<span class="line-added">+         // type. Inline types are flattened so, for instance, in the</span>
<span class="line-added">+         // case of an inline type with an int field and an inline type</span>
<span class="line-added">+         // field that itself has 2 fields, an int and a long:</span>
<span class="line-added">+         // T_INLINE_TYPE T_INT T_INLINE_TYPE T_INT T_LONG T_VOID (second</span>
<span class="line-added">+         // slot for the T_LONG) T_VOID (inner T_INLINE_TYPE) T_VOID</span>
<span class="line-added">+         // (outer T_INLINE_TYPE)</span>
<span class="line-added">+         total_args_passed++;</span>
<span class="line-added">+         int vt = 1;</span>
<span class="line-added">+         do {</span>
<span class="line-added">+           i++;</span>
<span class="line-added">+           BasicType bt = sig_extended-&gt;at(i)._bt;</span>
<span class="line-added">+           BasicType prev_bt = sig_extended-&gt;at(i-1)._bt;</span>
<span class="line-added">+           if (bt == T_INLINE_TYPE) {</span>
<span class="line-added">+             vt++;</span>
<span class="line-added">+           } else if (bt == T_VOID &amp;&amp;</span>
<span class="line-added">+                      prev_bt != T_LONG &amp;&amp;</span>
<span class="line-added">+                      prev_bt != T_DOUBLE) {</span>
<span class="line-added">+             vt--;</span>
<span class="line-added">+           }</span>
<span class="line-added">+         } while (vt != 0);</span>
<span class="line-added">+       } else {</span>
<span class="line-added">+         total_args_passed++;</span>
<span class="line-added">+       }</span>
<span class="line-added">+     }</span>
<span class="line-added">+   } else {</span>
<span class="line-added">+     total_args_passed = sig_extended-&gt;length();</span>
<span class="line-added">+   }</span>
<span class="line-added">+   return total_args_passed;</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ </span>
<span class="line-added">+ static void gen_c2i_adapter_helper(MacroAssembler* masm,</span>
<span class="line-added">+                                    BasicType bt,</span>
<span class="line-added">+                                    BasicType prev_bt,</span>
<span class="line-added">+                                    size_t size_in_bytes,</span>
<span class="line-added">+                                    const VMRegPair&amp; reg_pair,</span>
<span class="line-added">+                                    const Address&amp; to,</span>
<span class="line-added">+                                    int extraspace,</span>
<span class="line-added">+                                    bool is_oop) {</span>
<span class="line-added">+   assert(bt != T_INLINE_TYPE || !InlineTypePassFieldsAsArgs, &quot;no inline type here&quot;);</span>
<span class="line-added">+   if (bt == T_VOID) {</span>
<span class="line-added">+     assert(prev_bt == T_LONG || prev_bt == T_DOUBLE, &quot;missing half&quot;);</span>
<span class="line-added">+     return;</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   // Say 4 args:</span>
<span class="line-added">+   // i   st_off</span>
<span class="line-added">+   // 0   32 T_LONG</span>
<span class="line-added">+   // 1   24 T_VOID</span>
<span class="line-added">+   // 2   16 T_OBJECT</span>
<span class="line-added">+   // 3    8 T_BOOL</span>
<span class="line-added">+   // -    0 return address</span>
<span class="line-added">+   //</span>
<span class="line-added">+   // However to make thing extra confusing. Because we can fit a long/double in</span>
<span class="line-added">+   // a single slot on a 64 bt vm and it would be silly to break them up, the interpreter</span>
<span class="line-added">+   // leaves one slot empty and only stores to a single slot. In this case the</span>
<span class="line-added">+   // slot that is occupied is the T_VOID slot. See I said it was confusing.</span>
<span class="line-added">+ </span>
<span class="line-added">+   bool wide = (size_in_bytes == wordSize);</span>
<span class="line-added">+   VMReg r_1 = reg_pair.first();</span>
<span class="line-added">+   VMReg r_2 = reg_pair.second();</span>
<span class="line-added">+   assert(r_2-&gt;is_valid() == wide, &quot;invalid size&quot;);</span>
<span class="line-added">+   if (!r_1-&gt;is_valid()) {</span>
<span class="line-added">+     assert(!r_2-&gt;is_valid(), &quot;must be invalid&quot;);</span>
<span class="line-added">+     return;</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   if (!r_1-&gt;is_XMMRegister()) {</span>
<span class="line-added">+     Register val = rax;</span>
<span class="line-added">+     if (r_1-&gt;is_stack()) {</span>
<span class="line-added">+       int ld_off = r_1-&gt;reg2stack() * VMRegImpl::stack_slot_size + extraspace;</span>
<span class="line-added">+       __ load_sized_value(val, Address(rsp, ld_off), size_in_bytes, /* is_signed */ false);</span>
<span class="line-added">+     } else {</span>
<span class="line-added">+       val = r_1-&gt;as_Register();</span>
<span class="line-added">+     }</span>
<span class="line-added">+     assert_different_registers(to.base(), val, rscratch1);</span>
<span class="line-added">+     if (is_oop) {</span>
<span class="line-added">+       __ push(r13);</span>
<span class="line-added">+       __ push(rbx);</span>
<span class="line-added">+       __ store_heap_oop(to, val, rscratch1, r13, rbx, IN_HEAP | ACCESS_WRITE | IS_DEST_UNINITIALIZED);</span>
<span class="line-added">+       __ pop(rbx);</span>
<span class="line-added">+       __ pop(r13);</span>
<span class="line-added">+     } else {</span>
<span class="line-added">+       __ store_sized_value(to, val, size_in_bytes);</span>
<span class="line-added">+     }</span>
<span class="line-added">+   } else {</span>
<span class="line-added">+     if (wide) {</span>
<span class="line-added">+       __ movdbl(to, r_1-&gt;as_XMMRegister());</span>
<span class="line-added">+     } else {</span>
<span class="line-added">+       __ movflt(to, r_1-&gt;as_XMMRegister());</span>
<span class="line-added">+     }</span>
<span class="line-added">+   }</span>
<span class="line-added">+ }</span>
  
  static void gen_c2i_adapter(MacroAssembler *masm,
<span class="line-modified">!                             const GrowableArray&lt;SigEntry&gt;* sig_extended,</span>
                              const VMRegPair *regs,
<span class="line-modified">!                             Label&amp; skip_fixup,</span>
<span class="line-added">+                             address start,</span>
<span class="line-added">+                             OopMapSet* oop_maps,</span>
<span class="line-added">+                             int&amp; frame_complete,</span>
<span class="line-added">+                             int&amp; frame_size_in_words,</span>
<span class="line-added">+                             bool alloc_inline_receiver) {</span>
    // Before we get into the guts of the C2I adapter, see if we should be here
    // at all.  We&#39;ve come from compiled code and are attempting to jump to the
    // interpreter, which means the caller made a static call to get here
    // (vcalls always get a compiled target if there is one).  Check for a
    // compiled target.  If there is one, we need to patch the caller&#39;s call.
    patch_callers_callsite(masm);
  
    __ bind(skip_fixup);
  
<span class="line-added">+   if (InlineTypePassFieldsAsArgs) {</span>
<span class="line-added">+     // Is there an inline type argument?</span>
<span class="line-added">+     bool has_inline_argument = false;</span>
<span class="line-added">+     for (int i = 0; i &lt; sig_extended-&gt;length() &amp;&amp; !has_inline_argument; i++) {</span>
<span class="line-added">+       has_inline_argument = (sig_extended-&gt;at(i)._bt == T_INLINE_TYPE);</span>
<span class="line-added">+     }</span>
<span class="line-added">+     if (has_inline_argument) {</span>
<span class="line-added">+       // There is at least an inline type argument: we&#39;re coming from</span>
<span class="line-added">+       // compiled code so we have no buffers to back the inline types.</span>
<span class="line-added">+       // Allocate the buffers here with a runtime call.</span>
<span class="line-added">+       OopMap* map = RegisterSaver::save_live_registers(masm, 0, &amp;frame_size_in_words);</span>
<span class="line-added">+ </span>
<span class="line-added">+       frame_complete = __ offset();</span>
<span class="line-added">+ </span>
<span class="line-added">+       __ set_last_Java_frame(noreg, noreg, NULL);</span>
<span class="line-added">+ </span>
<span class="line-added">+       __ mov(c_rarg0, r15_thread);</span>
<span class="line-added">+       __ mov(c_rarg1, rbx);</span>
<span class="line-added">+       __ mov64(c_rarg2, (int64_t)alloc_inline_receiver);</span>
<span class="line-added">+       __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, SharedRuntime::allocate_inline_types)));</span>
<span class="line-added">+ </span>
<span class="line-added">+       oop_maps-&gt;add_gc_map((int)(__ pc() - start), map);</span>
<span class="line-added">+       __ reset_last_Java_frame(false);</span>
<span class="line-added">+ </span>
<span class="line-added">+       RegisterSaver::restore_live_registers(masm);</span>
<span class="line-added">+ </span>
<span class="line-added">+       Label no_exception;</span>
<span class="line-added">+       __ cmpptr(Address(r15_thread, Thread::pending_exception_offset()), (int32_t)NULL_WORD);</span>
<span class="line-added">+       __ jcc(Assembler::equal, no_exception);</span>
<span class="line-added">+ </span>
<span class="line-added">+       __ movptr(Address(r15_thread, JavaThread::vm_result_offset()), (int)NULL_WORD);</span>
<span class="line-added">+       __ movptr(rax, Address(r15_thread, Thread::pending_exception_offset()));</span>
<span class="line-added">+       __ jump(RuntimeAddress(StubRoutines::forward_exception_entry()));</span>
<span class="line-added">+ </span>
<span class="line-added">+       __ bind(no_exception);</span>
<span class="line-added">+ </span>
<span class="line-added">+       // We get an array of objects from the runtime call</span>
<span class="line-added">+       __ get_vm_result(rscratch2, r15_thread); // Use rscratch2 (r11) as temporary because rscratch1 (r10) is trashed by movptr()</span>
<span class="line-added">+       __ get_vm_result_2(rbx, r15_thread); // TODO: required to keep the callee Method live?</span>
<span class="line-added">+     }</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
    // Since all args are passed on the stack, total_args_passed *
    // Interpreter::stackElementSize is the space we need. Plus 1 because
    // we also account for the return address location since
    // we store it first rather than hold it in rax across all the shuffling
<span class="line-modified">!   int total_args_passed = compute_total_args_passed_int(sig_extended);</span>
    int extraspace = (total_args_passed * Interpreter::stackElementSize) + wordSize;
  
    // stack is aligned, keep it that way
    extraspace = align_up(extraspace, 2*wordSize);
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 604,99 ***</span>
  
    // Store the return address in the expected location
    __ movptr(Address(rsp, 0), rax);
  
    // Now write the args into the outgoing interpreter space
<span class="line-modified">!   for (int i = 0; i &lt; total_args_passed; i++) {</span>
<span class="line-modified">!     if (sig_bt[i] == T_VOID) {</span>
<span class="line-modified">!       assert(i &gt; 0 &amp;&amp; (sig_bt[i-1] == T_LONG || sig_bt[i-1] == T_DOUBLE), &quot;missing half&quot;);</span>
<span class="line-modified">!       continue;</span>
<span class="line-modified">!     }</span>
<span class="line-modified">! </span>
<span class="line-modified">!     // offset to start parameters</span>
<span class="line-modified">!     int st_off   = (total_args_passed - i) * Interpreter::stackElementSize;</span>
<span class="line-modified">!     int next_off = st_off - Interpreter::stackElementSize;</span>
<span class="line-modified">! </span>
<span class="line-modified">!     // Say 4 args:</span>
<span class="line-modified">!     // i   st_off</span>
<span class="line-modified">!     // 0   32 T_LONG</span>
<span class="line-modified">!     // 1   24 T_VOID</span>
<span class="line-modified">!     // 2   16 T_OBJECT</span>
<span class="line-modified">!     // 3    8 T_BOOL</span>
<span class="line-modified">!     // -    0 return address</span>
<span class="line-modified">!     //</span>
<span class="line-modified">!     // However to make thing extra confusing. Because we can fit a long/double in</span>
<span class="line-removed">-     // a single slot on a 64 bt vm and it would be silly to break them up, the interpreter</span>
<span class="line-removed">-     // leaves one slot empty and only stores to a single slot. In this case the</span>
<span class="line-removed">-     // slot that is occupied is the T_VOID slot. See I said it was confusing.</span>
<span class="line-removed">- </span>
<span class="line-removed">-     VMReg r_1 = regs[i].first();</span>
<span class="line-removed">-     VMReg r_2 = regs[i].second();</span>
<span class="line-removed">-     if (!r_1-&gt;is_valid()) {</span>
<span class="line-removed">-       assert(!r_2-&gt;is_valid(), &quot;&quot;);</span>
<span class="line-removed">-       continue;</span>
<span class="line-removed">-     }</span>
<span class="line-removed">-     if (r_1-&gt;is_stack()) {</span>
<span class="line-removed">-       // memory to memory use rax</span>
<span class="line-removed">-       int ld_off = r_1-&gt;reg2stack() * VMRegImpl::stack_slot_size + extraspace;</span>
<span class="line-removed">-       if (!r_2-&gt;is_valid()) {</span>
<span class="line-removed">-         // sign extend??</span>
<span class="line-removed">-         __ movl(rax, Address(rsp, ld_off));</span>
<span class="line-removed">-         __ movptr(Address(rsp, st_off), rax);</span>
<span class="line-removed">- </span>
<span class="line-removed">-       } else {</span>
<span class="line-removed">- </span>
<span class="line-removed">-         __ movq(rax, Address(rsp, ld_off));</span>
<span class="line-removed">- </span>
<span class="line-removed">-         // Two VMREgs|OptoRegs can be T_OBJECT, T_ADDRESS, T_DOUBLE, T_LONG</span>
<span class="line-removed">-         // T_DOUBLE and T_LONG use two slots in the interpreter</span>
<span class="line-removed">-         if ( sig_bt[i] == T_LONG || sig_bt[i] == T_DOUBLE) {</span>
<span class="line-removed">-           // ld_off == LSW, ld_off+wordSize == MSW</span>
<span class="line-removed">-           // st_off == MSW, next_off == LSW</span>
<span class="line-removed">-           __ movq(Address(rsp, next_off), rax);</span>
<span class="line-removed">- #ifdef ASSERT</span>
<span class="line-removed">-           // Overwrite the unused slot with known junk</span>
<span class="line-removed">-           __ mov64(rax, CONST64(0xdeadffffdeadaaaa));</span>
<span class="line-removed">-           __ movptr(Address(rsp, st_off), rax);</span>
<span class="line-removed">- #endif /* ASSERT */</span>
<span class="line-removed">-         } else {</span>
<span class="line-removed">-           __ movq(Address(rsp, st_off), rax);</span>
          continue; // Ignore reserved entry
        }
<span class="line-modified">!     } else if (r_1-&gt;is_Register()) {</span>
<span class="line-modified">!       Register r = r_1-&gt;as_Register();</span>
<span class="line-modified">!       if (!r_2-&gt;is_valid()) {</span>
<span class="line-modified">!         // must be only an int (or less ) so move only 32bits to slot</span>
<span class="line-modified">!         // why not sign extend??</span>
<span class="line-modified">!         __ movl(Address(rsp, st_off), r);</span>
<span class="line-modified">!       } else {</span>
<span class="line-removed">-         // Two VMREgs|OptoRegs can be T_OBJECT, T_ADDRESS, T_DOUBLE, T_LONG</span>
<span class="line-removed">-         // T_DOUBLE and T_LONG use two slots in the interpreter</span>
<span class="line-removed">-         if ( sig_bt[i] == T_LONG || sig_bt[i] == T_DOUBLE) {</span>
<span class="line-removed">-           // long/double in gpr</span>
<span class="line-removed">- #ifdef ASSERT</span>
<span class="line-removed">-           // Overwrite the unused slot with known junk</span>
<span class="line-removed">-           __ mov64(rax, CONST64(0xdeadffffdeadaaab));</span>
<span class="line-removed">-           __ movptr(Address(rsp, st_off), rax);</span>
<span class="line-removed">- #endif /* ASSERT */</span>
<span class="line-removed">-           __ movq(Address(rsp, next_off), r);</span>
<span class="line-removed">-         } else {</span>
<span class="line-removed">-           __ movptr(Address(rsp, st_off), r);</span>
<span class="line-removed">-         }</span>
<span class="line-removed">-       }</span>
<span class="line-removed">-     } else {</span>
<span class="line-removed">-       assert(r_1-&gt;is_XMMRegister(), &quot;&quot;);</span>
<span class="line-removed">-       if (!r_2-&gt;is_valid()) {</span>
<span class="line-removed">-         // only a float use just part of the slot</span>
<span class="line-removed">-         __ movflt(Address(rsp, st_off), r_1-&gt;as_XMMRegister());</span>
<span class="line-removed">-       } else {</span>
  #ifdef ASSERT
          // Overwrite the unused slot with known junk
<span class="line-modified">!         __ mov64(rax, CONST64(0xdeadffffdeadaaac));</span>
          __ movptr(Address(rsp, st_off), rax);
<span class="line-modified">! #endif /* ASSERT */</span>
<span class="line-modified">!         __ movdbl(Address(rsp, next_off), r_1-&gt;as_XMMRegister());</span>
        __ movptr(Address(rsp, st_off), r14);
      }
    }
  
    // Schedule the branch target address early.
<span class="line-new-header">--- 841,82 ---</span>
  
    // Store the return address in the expected location
    __ movptr(Address(rsp, 0), rax);
  
    // Now write the args into the outgoing interpreter space
<span class="line-modified">! </span>
<span class="line-modified">!   // next_arg_comp is the next argument from the compiler point of</span>
<span class="line-modified">!   // view (inline type fields are passed in registers/on the stack). In</span>
<span class="line-modified">!   // sig_extended, an inline type argument starts with: T_INLINE_TYPE,</span>
<span class="line-modified">!   // followed by the types of the fields of the inline type and T_VOID</span>
<span class="line-modified">!   // to mark the end of the inline type. ignored counts the number of</span>
<span class="line-modified">!   // T_INLINE_TYPE/T_VOID. next_vt_arg is the next inline type argument:</span>
<span class="line-modified">!   // used to get the buffer for that argument from the pool of buffers</span>
<span class="line-modified">!   // we allocated above and want to pass to the</span>
<span class="line-modified">!   // interpreter. next_arg_int is the next argument from the</span>
<span class="line-modified">!   // interpreter point of view (inline types are passed by reference).</span>
<span class="line-modified">!   for (int next_arg_comp = 0, ignored = 0, next_vt_arg = 0, next_arg_int = 0;</span>
<span class="line-modified">!        next_arg_comp &lt; sig_extended-&gt;length(); next_arg_comp++) {</span>
<span class="line-modified">!     assert(ignored &lt;= next_arg_comp, &quot;shouldn&#39;t skip over more slots than there are arguments&quot;);</span>
<span class="line-modified">!     assert(next_arg_int &lt;= total_args_passed, &quot;more arguments for the interpreter than expected?&quot;);</span>
<span class="line-modified">!     BasicType bt = sig_extended-&gt;at(next_arg_comp)._bt;</span>
<span class="line-modified">!     int st_off = (total_args_passed - next_arg_int) * Interpreter::stackElementSize;</span>
<span class="line-modified">!     if (!InlineTypePassFieldsAsArgs || bt != T_INLINE_TYPE) {</span>
<span class="line-modified">!       if (SigEntry::is_reserved_entry(sig_extended, next_arg_comp)) {</span>
          continue; // Ignore reserved entry
        }
<span class="line-modified">!       int next_off = st_off - Interpreter::stackElementSize;</span>
<span class="line-modified">!       const int offset = (bt == T_LONG || bt == T_DOUBLE) ? next_off : st_off;</span>
<span class="line-modified">!       const VMRegPair reg_pair = regs[next_arg_comp-ignored];</span>
<span class="line-modified">!       size_t size_in_bytes = reg_pair.second()-&gt;is_valid() ? 8 : 4;</span>
<span class="line-modified">!       gen_c2i_adapter_helper(masm, bt, next_arg_comp &gt; 0 ? sig_extended-&gt;at(next_arg_comp-1)._bt : T_ILLEGAL,</span>
<span class="line-modified">!                              size_in_bytes, reg_pair, Address(rsp, offset), extraspace, false);</span>
<span class="line-modified">!       next_arg_int++;</span>
  #ifdef ASSERT
<span class="line-added">+       if (bt == T_LONG || bt == T_DOUBLE) {</span>
          // Overwrite the unused slot with known junk
<span class="line-modified">!         __ mov64(rax, CONST64(0xdeadffffdeadaaaa));</span>
          __ movptr(Address(rsp, st_off), rax);
<span class="line-modified">!       }</span>
<span class="line-modified">! #endif /* ASSERT */</span>
<span class="line-added">+     } else {</span>
<span class="line-added">+       ignored++;</span>
<span class="line-added">+       // get the buffer from the just allocated pool of buffers</span>
<span class="line-added">+       int index = arrayOopDesc::base_offset_in_bytes(T_OBJECT) + next_vt_arg * type2aelembytes(T_INLINE_TYPE);</span>
<span class="line-added">+       __ load_heap_oop(r14, Address(rscratch2, index));</span>
<span class="line-added">+       next_vt_arg++; next_arg_int++;</span>
<span class="line-added">+       int vt = 1;</span>
<span class="line-added">+       // write fields we get from compiled code in registers/stack</span>
<span class="line-added">+       // slots to the buffer: we know we are done with that inline type</span>
<span class="line-added">+       // argument when we hit the T_VOID that acts as an end of inline</span>
<span class="line-added">+       // type delimiter for this inline type. Inline types are flattened</span>
<span class="line-added">+       // so we might encounter embedded inline types. Each entry in</span>
<span class="line-added">+       // sig_extended contains a field offset in the buffer.</span>
<span class="line-added">+       do {</span>
<span class="line-added">+         next_arg_comp++;</span>
<span class="line-added">+         BasicType bt = sig_extended-&gt;at(next_arg_comp)._bt;</span>
<span class="line-added">+         BasicType prev_bt = sig_extended-&gt;at(next_arg_comp-1)._bt;</span>
<span class="line-added">+         if (bt == T_INLINE_TYPE) {</span>
<span class="line-added">+           vt++;</span>
<span class="line-added">+           ignored++;</span>
<span class="line-added">+         } else if (bt == T_VOID &amp;&amp;</span>
<span class="line-added">+                    prev_bt != T_LONG &amp;&amp;</span>
<span class="line-added">+                    prev_bt != T_DOUBLE) {</span>
<span class="line-added">+           vt--;</span>
<span class="line-added">+           ignored++;</span>
<span class="line-added">+         } else if (SigEntry::is_reserved_entry(sig_extended, next_arg_comp)) {</span>
<span class="line-added">+           // Ignore reserved entry</span>
<span class="line-added">+         } else {</span>
<span class="line-added">+           int off = sig_extended-&gt;at(next_arg_comp)._offset;</span>
<span class="line-added">+           assert(off &gt; 0, &quot;offset in object should be positive&quot;);</span>
<span class="line-added">+           size_t size_in_bytes = is_java_primitive(bt) ? type2aelembytes(bt) : wordSize;</span>
<span class="line-added">+           bool is_oop = is_reference_type(bt);</span>
<span class="line-added">+           gen_c2i_adapter_helper(masm, bt, next_arg_comp &gt; 0 ? sig_extended-&gt;at(next_arg_comp-1)._bt : T_ILLEGAL,</span>
<span class="line-added">+                                  size_in_bytes, regs[next_arg_comp-ignored], Address(r14, off), extraspace, is_oop);</span>
<span class="line-added">+         }</span>
<span class="line-added">+       } while (vt != 0);</span>
<span class="line-added">+       // pass the buffer to the interpreter</span>
        __ movptr(Address(rsp, st_off), r14);
      }
    }
  
    // Schedule the branch target address early.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 716,12 ***</span>
    __ jcc(Assembler::below, L_ok);
    __ bind(L_fail);
  }
  
  void SharedRuntime::gen_i2c_adapter(MacroAssembler *masm,
<span class="line-modified">!                                     int total_args_passed,</span>
<span class="line-removed">-                                     int comp_args_on_stack,</span>
                                      const GrowableArray&lt;SigEntry&gt;* sig,
                                      const VMRegPair *regs) {
  
    // Note: r13 contains the senderSP on entry. We must preserve it since
    // we may do a i2c -&gt; c2i transition if we lose a race where compiled
<span class="line-new-header">--- 936,11 ---</span>
    __ jcc(Assembler::below, L_ok);
    __ bind(L_fail);
  }
  
  void SharedRuntime::gen_i2c_adapter(MacroAssembler *masm,
<span class="line-modified">!                                     int comp_args_on_stack,</span>
                                      const GrowableArray&lt;SigEntry&gt;* sig,
                                      const VMRegPair *regs) {
  
    // Note: r13 contains the senderSP on entry. We must preserve it since
    // we may do a i2c -&gt; c2i transition if we lose a race where compiled
</pre>
<hr />
<pre>
<span class="line-old-header">*** 810,11 ***</span>
    const Register saved_sp = rax;
    __ movptr(saved_sp, r11);
  
    // Will jump to the compiled code just as if compiled code was doing it.
    // Pre-load the register-jump target early, to schedule it better.
<span class="line-modified">!   __ movptr(r11, Address(rbx, in_bytes(Method::from_compiled_offset())));</span>
  
  #if INCLUDE_JVMCI
    if (EnableJVMCI || UseAOT) {
      // check if this call should be routed towards a specific entry point
      __ cmpptr(Address(r15_thread, in_bytes(JavaThread::jvmci_alternate_call_target_offset())), 0);
<span class="line-new-header">--- 1029,11 ---</span>
    const Register saved_sp = rax;
    __ movptr(saved_sp, r11);
  
    // Will jump to the compiled code just as if compiled code was doing it.
    // Pre-load the register-jump target early, to schedule it better.
<span class="line-modified">!   __ movptr(r11, Address(rbx, in_bytes(Method::from_compiled_inline_offset())));</span>
  
  #if INCLUDE_JVMCI
    if (EnableJVMCI || UseAOT) {
      // check if this call should be routed towards a specific entry point
      __ cmpptr(Address(r15_thread, in_bytes(JavaThread::jvmci_alternate_call_target_offset())), 0);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 824,17 ***</span>
      __ movptr(Address(r15_thread, in_bytes(JavaThread::jvmci_alternate_call_target_offset())), 0);
      __ bind(no_alternative_target);
    }
  #endif // INCLUDE_JVMCI
  
    // Now generate the shuffle code.  Pick up all register args and move the
    // rest through the floating point stack top.
    for (int i = 0; i &lt; total_args_passed; i++) {
<span class="line-modified">!     if (sig_bt[i] == T_VOID) {</span>
        // Longs and doubles are passed in native word order, but misaligned
        // in the 32-bit build.
<span class="line-modified">!       assert(i &gt; 0 &amp;&amp; (sig_bt[i-1] == T_LONG || sig_bt[i-1] == T_DOUBLE), &quot;missing half&quot;);</span>
        continue;
      }
  
      // Pick up 0, 1 or 2 words from SP+offset.
  
<span class="line-new-header">--- 1043,22 ---</span>
      __ movptr(Address(r15_thread, in_bytes(JavaThread::jvmci_alternate_call_target_offset())), 0);
      __ bind(no_alternative_target);
    }
  #endif // INCLUDE_JVMCI
  
<span class="line-added">+   int total_args_passed = sig-&gt;length();</span>
<span class="line-added">+ </span>
    // Now generate the shuffle code.  Pick up all register args and move the
    // rest through the floating point stack top.
    for (int i = 0; i &lt; total_args_passed; i++) {
<span class="line-modified">!     BasicType bt = sig-&gt;at(i)._bt;</span>
<span class="line-added">+     assert(bt != T_INLINE_TYPE, &quot;i2c adapter doesn&#39;t unpack inline type args&quot;);</span>
<span class="line-added">+     if (bt == T_VOID) {</span>
        // Longs and doubles are passed in native word order, but misaligned
        // in the 32-bit build.
<span class="line-modified">!       BasicType prev_bt = (i &gt; 0) ? sig-&gt;at(i-1)._bt : T_ILLEGAL;</span>
<span class="line-added">+       assert(i &gt; 0 &amp;&amp; (prev_bt == T_LONG || prev_bt == T_DOUBLE), &quot;missing half&quot;);</span>
        continue;
      }
  
      // Pick up 0, 1 or 2 words from SP+offset.
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 872,11 ***</span>
          //
          // Interpreter local[n] == MSW, local[n+1] == LSW however locals
          // are accessed as negative so LSW is at LOW address
  
          // ld_off is MSW so get LSW
<span class="line-modified">!         const int offset = (sig_bt[i]==T_LONG||sig_bt[i]==T_DOUBLE)?</span>
                             next_off : ld_off;
          __ movq(r13, Address(saved_sp, offset));
          // st_off is LSW (i.e. reg.first())
          __ movq(Address(rsp, st_off), r13);
        }
<span class="line-new-header">--- 1096,11 ---</span>
          //
          // Interpreter local[n] == MSW, local[n+1] == LSW however locals
          // are accessed as negative so LSW is at LOW address
  
          // ld_off is MSW so get LSW
<span class="line-modified">!         const int offset = (bt==T_LONG||bt==T_DOUBLE)?</span>
                             next_off : ld_off;
          __ movq(r13, Address(saved_sp, offset));
          // st_off is LSW (i.e. reg.first())
          __ movq(Address(rsp, st_off), r13);
        }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 887,11 ***</span>
          //
          // We are using two VMRegs. This can be either T_OBJECT, T_ADDRESS, T_LONG, or T_DOUBLE
          // the interpreter allocates two slots but only uses one for thr T_LONG or T_DOUBLE case
          // So we must adjust where to pick up the data to match the interpreter.
  
<span class="line-modified">!         const int offset = (sig_bt[i]==T_LONG||sig_bt[i]==T_DOUBLE)?</span>
                             next_off : ld_off;
  
          // this can be a misaligned move
          __ movq(r, Address(saved_sp, offset));
        } else {
<span class="line-new-header">--- 1111,11 ---</span>
          //
          // We are using two VMRegs. This can be either T_OBJECT, T_ADDRESS, T_LONG, or T_DOUBLE
          // the interpreter allocates two slots but only uses one for thr T_LONG or T_DOUBLE case
          // So we must adjust where to pick up the data to match the interpreter.
  
<span class="line-modified">!         const int offset = (bt==T_LONG||bt==T_DOUBLE)?</span>
                             next_off : ld_off;
  
          // this can be a misaligned move
          __ movq(r, Address(saved_sp, offset));
        } else {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 918,26 ***</span>
    // and the vm will find there should this case occur.
  
    __ movptr(Address(r15_thread, JavaThread::callee_target_offset()), rbx);
  
    // put Method* where a c2i would expect should we end up there
<span class="line-modified">!   // only needed becaus eof c2 resolve stubs return Method* as a result in</span>
    // rax
    __ mov(rax, rbx);
    __ jmp(r11);
  }
  
  // ---------------------------------------------------------------
  AdapterHandlerEntry* SharedRuntime::generate_i2c2i_adapters(MacroAssembler *masm,
<span class="line-modified">!                                                             int total_args_passed,</span>
<span class="line-modified">!                                                             int comp_args_on_stack,</span>
<span class="line-modified">!                                                             const BasicType *sig_bt,</span>
<span class="line-modified">!                                                             const VMRegPair *regs,</span>
                                                              AdapterBlob*&amp; new_adapter) {
    address i2c_entry = __ pc();
<span class="line-modified">! </span>
<span class="line-removed">-   gen_i2c_adapter(masm, total_args_passed, comp_args_on_stack, sig_bt, regs);</span>
  
    // -------------------------------------------------------------------------
    // Generate a C2I adapter.  On entry we know rbx holds the Method* during calls
    // to the interpreter.  The args start out packed in the compiled layout.  They
    // need to be unpacked into the interpreter layout.  This will almost always
<span class="line-new-header">--- 1142,51 ---</span>
    // and the vm will find there should this case occur.
  
    __ movptr(Address(r15_thread, JavaThread::callee_target_offset()), rbx);
  
    // put Method* where a c2i would expect should we end up there
<span class="line-modified">!   // only needed because of c2 resolve stubs return Method* as a result in</span>
    // rax
    __ mov(rax, rbx);
    __ jmp(r11);
  }
  
<span class="line-added">+ static void gen_inline_cache_check(MacroAssembler *masm, Label&amp; skip_fixup) {</span>
<span class="line-added">+   Label ok;</span>
<span class="line-added">+ </span>
<span class="line-added">+   Register holder = rax;</span>
<span class="line-added">+   Register receiver = j_rarg0;</span>
<span class="line-added">+   Register temp = rbx;</span>
<span class="line-added">+ </span>
<span class="line-added">+   __ load_klass(temp, receiver, rscratch1);</span>
<span class="line-added">+   __ cmpptr(temp, Address(holder, CompiledICHolder::holder_klass_offset()));</span>
<span class="line-added">+   __ movptr(rbx, Address(holder, CompiledICHolder::holder_metadata_offset()));</span>
<span class="line-added">+   __ jcc(Assembler::equal, ok);</span>
<span class="line-added">+   __ jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));</span>
<span class="line-added">+ </span>
<span class="line-added">+   __ bind(ok);</span>
<span class="line-added">+   // Method might have been compiled since the call site was patched to</span>
<span class="line-added">+   // interpreted if that is the case treat it as a miss so we can get</span>
<span class="line-added">+   // the call site corrected.</span>
<span class="line-added">+   __ cmpptr(Address(rbx, in_bytes(Method::code_offset())), (int32_t)NULL_WORD);</span>
<span class="line-added">+   __ jcc(Assembler::equal, skip_fixup);</span>
<span class="line-added">+   __ jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
  // ---------------------------------------------------------------
  AdapterHandlerEntry* SharedRuntime::generate_i2c2i_adapters(MacroAssembler *masm,
<span class="line-modified">!                                                             int comp_args_on_stack,</span>
<span class="line-modified">!                                                             const GrowableArray&lt;SigEntry&gt;* sig,</span>
<span class="line-modified">!                                                             const VMRegPair* regs,</span>
<span class="line-modified">!                                                             const GrowableArray&lt;SigEntry&gt;* sig_cc,</span>
<span class="line-added">+                                                             const VMRegPair* regs_cc,</span>
<span class="line-added">+                                                             const GrowableArray&lt;SigEntry&gt;* sig_cc_ro,</span>
<span class="line-added">+                                                             const VMRegPair* regs_cc_ro,</span>
<span class="line-added">+                                                             AdapterFingerPrint* fingerprint,</span>
                                                              AdapterBlob*&amp; new_adapter) {
    address i2c_entry = __ pc();
<span class="line-modified">!   gen_i2c_adapter(masm, comp_args_on_stack, sig, regs);</span>
  
    // -------------------------------------------------------------------------
    // Generate a C2I adapter.  On entry we know rbx holds the Method* during calls
    // to the interpreter.  The args start out packed in the compiled layout.  They
    // need to be unpacked into the interpreter layout.  This will almost always
</pre>
<hr />
<pre>
<span class="line-old-header">*** 946,32 ***</span>
    // On exit from the interpreter, the interpreter will restore our SP (lest the
    // compiled code, which relys solely on SP and not RBP, get sick).
  
    address c2i_unverified_entry = __ pc();
    Label skip_fixup;
<span class="line-modified">!   Label ok;</span>
<span class="line-removed">- </span>
<span class="line-removed">-   Register holder = rax;</span>
<span class="line-removed">-   Register receiver = j_rarg0;</span>
<span class="line-removed">-   Register temp = rbx;</span>
<span class="line-removed">- </span>
<span class="line-removed">-   {</span>
<span class="line-removed">-     __ load_klass(temp, receiver, rscratch1);</span>
<span class="line-removed">-     __ cmpptr(temp, Address(holder, CompiledICHolder::holder_klass_offset()));</span>
<span class="line-removed">-     __ movptr(rbx, Address(holder, CompiledICHolder::holder_metadata_offset()));</span>
<span class="line-removed">-     __ jcc(Assembler::equal, ok);</span>
    gen_inline_cache_check(masm, skip_fixup);
  
<span class="line-modified">!     __ bind(ok);</span>
<span class="line-modified">!     // Method might have been compiled since the call site was patched to</span>
<span class="line-modified">!     // interpreted if that is the case treat it as a miss so we can get</span>
<span class="line-modified">!     // the call site corrected.</span>
<span class="line-modified">!     __ cmpptr(Address(rbx, in_bytes(Method::code_offset())), (int32_t)NULL_WORD);</span>
<span class="line-modified">!     __ jcc(Assembler::equal, skip_fixup);</span>
<span class="line-modified">!     __ jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));</span>
    }
  
    address c2i_entry = __ pc();
  
    // Class initialization barrier for static methods
    address c2i_no_clinit_check_entry = NULL;
    if (VM_Version::supports_fast_class_init_checks()) {
<span class="line-new-header">--- 1195,26 ---</span>
    // On exit from the interpreter, the interpreter will restore our SP (lest the
    // compiled code, which relys solely on SP and not RBP, get sick).
  
    address c2i_unverified_entry = __ pc();
    Label skip_fixup;
<span class="line-modified">! </span>
    gen_inline_cache_check(masm, skip_fixup);
  
<span class="line-modified">!   OopMapSet* oop_maps = new OopMapSet();</span>
<span class="line-modified">!   int frame_complete = CodeOffsets::frame_never_safe;</span>
<span class="line-modified">!   int frame_size_in_words = 0;</span>
<span class="line-modified">! </span>
<span class="line-modified">!   // Scalarized c2i adapter with non-scalarized receiver (i.e., don&#39;t pack receiver)</span>
<span class="line-modified">!   address c2i_inline_ro_entry = __ pc();</span>
<span class="line-modified">!   if (regs_cc != regs_cc_ro) {</span>
<span class="line-added">+     Label unused;</span>
<span class="line-added">+     gen_c2i_adapter(masm, sig_cc_ro, regs_cc_ro, skip_fixup, i2c_entry, oop_maps, frame_complete, frame_size_in_words, false);</span>
<span class="line-added">+     skip_fixup = unused;</span>
    }
  
<span class="line-added">+   // Scalarized c2i adapter</span>
    address c2i_entry = __ pc();
  
    // Class initialization barrier for static methods
    address c2i_no_clinit_check_entry = NULL;
    if (VM_Version::supports_fast_class_init_checks()) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 996,14 ***</span>
    }
  
    BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
    bs-&gt;c2i_entry_barrier(masm);
  
<span class="line-modified">!   gen_c2i_adapter(masm, total_args_passed, comp_args_on_stack, sig_bt, regs, skip_fixup);</span>
  
    __ flush();
<span class="line-modified">!   return AdapterHandlerLibrary::new_entry(fingerprint, i2c_entry, c2i_entry, c2i_unverified_entry, c2i_no_clinit_check_entry);</span>
  }
  
  int SharedRuntime::c_calling_convention(const BasicType *sig_bt,
                                           VMRegPair *regs,
                                           VMRegPair *regs2,
<span class="line-new-header">--- 1239,34 ---</span>
    }
  
    BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
    bs-&gt;c2i_entry_barrier(masm);
  
<span class="line-modified">!   gen_c2i_adapter(masm, sig_cc, regs_cc, skip_fixup, i2c_entry, oop_maps, frame_complete, frame_size_in_words, true);</span>
<span class="line-added">+ </span>
<span class="line-added">+   address c2i_unverified_inline_entry = c2i_unverified_entry;</span>
<span class="line-added">+ </span>
<span class="line-added">+   // Non-scalarized c2i adapter</span>
<span class="line-added">+   address c2i_inline_entry = c2i_entry;</span>
<span class="line-added">+   if (regs != regs_cc) {</span>
<span class="line-added">+     Label inline_entry_skip_fixup;</span>
<span class="line-added">+     c2i_unverified_inline_entry = __ pc();</span>
<span class="line-added">+     gen_inline_cache_check(masm, inline_entry_skip_fixup);</span>
<span class="line-added">+ </span>
<span class="line-added">+     c2i_inline_entry = __ pc();</span>
<span class="line-added">+     Label unused;</span>
<span class="line-added">+     gen_c2i_adapter(masm, sig, regs, inline_entry_skip_fixup, i2c_entry, oop_maps, frame_complete, frame_size_in_words, false);</span>
<span class="line-added">+   }</span>
  
    __ flush();
<span class="line-modified">! </span>
<span class="line-added">+   // The c2i adapters might safepoint and trigger a GC. The caller must make sure that</span>
<span class="line-added">+   // the GC knows about the location of oop argument locations passed to the c2i adapter.</span>
<span class="line-added">+   bool caller_must_gc_arguments = (regs != regs_cc);</span>
<span class="line-added">+   new_adapter = AdapterBlob::create(masm-&gt;code(), frame_complete, frame_size_in_words, oop_maps, caller_must_gc_arguments);</span>
<span class="line-added">+ </span>
<span class="line-added">+   return AdapterHandlerLibrary::new_entry(fingerprint, i2c_entry, c2i_entry, c2i_inline_entry, c2i_inline_ro_entry, c2i_unverified_entry, c2i_unverified_inline_entry, c2i_no_clinit_check_entry);</span>
  }
  
  int SharedRuntime::c_calling_convention(const BasicType *sig_bt,
                                           VMRegPair *regs,
                                           VMRegPair *regs2,
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1057,10 ***</span>
<span class="line-new-header">--- 1320,11 ---</span>
        case T_LONG:
          assert((i + 1) &lt; total_args_passed &amp;&amp; sig_bt[i + 1] == T_VOID, &quot;expecting half&quot;);
          // fall through
        case T_OBJECT:
        case T_ARRAY:
<span class="line-added">+       case T_INLINE_TYPE:</span>
        case T_ADDRESS:
        case T_METADATA:
          if (int_args &lt; Argument::n_int_register_parameters_c) {
            regs[i].set2(INT_ArgReg[int_args++]-&gt;as_VMReg());
  #ifdef _WIN64
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1407,11 ***</span>
          (in_sig_bt[i] == T_LONG || in_sig_bt[i] == T_ARRAY)) {
        int offset = slot * VMRegImpl::stack_slot_size;
        if (map != NULL) {
          __ movq(Address(rsp, offset), in_regs[i].first()-&gt;as_Register());
          if (in_sig_bt[i] == T_ARRAY) {
<span class="line-modified">!           map-&gt;set_oop(VMRegImpl::stack2reg(slot));;</span>
          }
        } else {
          __ movq(in_regs[i].first()-&gt;as_Register(), Address(rsp, offset));
        }
        slot += VMRegImpl::slots_per_word;
<span class="line-new-header">--- 1671,11 ---</span>
          (in_sig_bt[i] == T_LONG || in_sig_bt[i] == T_ARRAY)) {
        int offset = slot * VMRegImpl::stack_slot_size;
        if (map != NULL) {
          __ movq(Address(rsp, offset), in_regs[i].first()-&gt;as_Register());
          if (in_sig_bt[i] == T_ARRAY) {
<span class="line-modified">!           map-&gt;set_oop(VMRegImpl::stack2reg(slot));</span>
          }
        } else {
          __ movq(in_regs[i].first()-&gt;as_Register(), Address(rsp, offset));
        }
        slot += VMRegImpl::slots_per_word;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1441,10 ***</span>
<span class="line-new-header">--- 1705,11 ---</span>
          case T_ARRAY:
          case T_LONG:
            // handled above
            break;
          case T_OBJECT:
<span class="line-added">+         case T_INLINE_TYPE:</span>
          default: ShouldNotReachHere();
        }
      } else if (in_regs[i].first()-&gt;is_XMMRegister()) {
        if (in_sig_bt[i] == T_FLOAT) {
          int offset = slot * VMRegImpl::stack_slot_size;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2354,10 ***</span>
<span class="line-new-header">--- 2619,11 ---</span>
              freg_destroyed[out_regs[c_arg].first()-&gt;as_XMMRegister()-&gt;encoding()] = true;
            }
  #endif
            break;
          }
<span class="line-added">+       case T_INLINE_TYPE:</span>
        case T_OBJECT:
          assert(!is_critical_native, &quot;no oop arguments&quot;);
          object_move(masm, map, oop_handle_offset, stack_slots, in_regs[i], out_regs[c_arg],
                      ((i == 0) &amp;&amp; (!is_static)),
                      &amp;receiver_offset);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2489,10 ***</span>
<span class="line-new-header">--- 2755,14 ---</span>
      // Load immediate 1 into swap_reg %rax
      __ movl(swap_reg, 1);
  
      // Load (object-&gt;mark() | 1) into swap_reg %rax
      __ orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));
<span class="line-added">+     if (EnableValhalla &amp;&amp; !UseBiasedLocking) {</span>
<span class="line-added">+       // For slow path is_always_locked, using biased, which is never natural for !UseBiasLocking</span>
<span class="line-added">+       __ andptr(swap_reg, ~((int) markWord::biased_lock_bit_in_place));</span>
<span class="line-added">+     }</span>
  
      // Save (object-&gt;mark() | 1) into BasicLock&#39;s displaced header
      __ movptr(Address(lock_reg, mark_word_offset), swap_reg);
  
      // src -&gt; dest iff dest == rax else rax &lt;- dest
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2550,10 ***</span>
<span class="line-new-header">--- 2820,11 ---</span>
    case T_DOUBLE :
    case T_FLOAT  :
      // Result is in xmm0 we&#39;ll save as needed
      break;
    case T_ARRAY:                 // Really a handle
<span class="line-added">+   case T_INLINE_TYPE:           // Really a handle</span>
    case T_OBJECT:                // Really a handle
        break; // can&#39;t de-handlize until after safepoint check
    case T_VOID: break;
    case T_LONG: break;
    default       : ShouldNotReachHere();
</pre>
<hr />
<pre>
<span class="line-old-header">*** 4068,5 ***</span>
<span class="line-new-header">--- 4339,116 ---</span>
  
    // Set exception blob
    _exception_blob =  ExceptionBlob::create(&amp;buffer, oop_maps, SimpleRuntimeFrame::framesize &gt;&gt; 1);
  }
  #endif // COMPILER2
<span class="line-added">+ </span>
<span class="line-added">+ BufferedInlineTypeBlob* SharedRuntime::generate_buffered_inline_type_adapter(const InlineKlass* vk) {</span>
<span class="line-added">+   BufferBlob* buf = BufferBlob::create(&quot;inline types pack/unpack&quot;, 16 * K);</span>
<span class="line-added">+   CodeBuffer buffer(buf);</span>
<span class="line-added">+   short buffer_locs[20];</span>
<span class="line-added">+   buffer.insts()-&gt;initialize_shared_locs((relocInfo*)buffer_locs,</span>
<span class="line-added">+                                          sizeof(buffer_locs)/sizeof(relocInfo));</span>
<span class="line-added">+ </span>
<span class="line-added">+   MacroAssembler* masm = new MacroAssembler(&amp;buffer);</span>
<span class="line-added">+ </span>
<span class="line-added">+   const Array&lt;SigEntry&gt;* sig_vk = vk-&gt;extended_sig();</span>
<span class="line-added">+   const Array&lt;VMRegPair&gt;* regs = vk-&gt;return_regs();</span>
<span class="line-added">+ </span>
<span class="line-added">+   int pack_fields_jobject_off = __ offset();</span>
<span class="line-added">+   // Resolve pre-allocated buffer from JNI handle.</span>
<span class="line-added">+   // We cannot do this in generate_call_stub() because it requires GC code to be initialized.</span>
<span class="line-added">+   __ movptr(rax, Address(r13, 0));</span>
<span class="line-added">+   __ resolve_jobject(rax /* value */,</span>
<span class="line-added">+                      r15_thread /* thread */,</span>
<span class="line-added">+                      r12 /* tmp */);</span>
<span class="line-added">+   __ movptr(Address(r13, 0), rax);</span>
<span class="line-added">+ </span>
<span class="line-added">+   int pack_fields_off = __ offset();</span>
<span class="line-added">+ </span>
<span class="line-added">+   int j = 1;</span>
<span class="line-added">+   for (int i = 0; i &lt; sig_vk-&gt;length(); i++) {</span>
<span class="line-added">+     BasicType bt = sig_vk-&gt;at(i)._bt;</span>
<span class="line-added">+     if (bt == T_INLINE_TYPE) {</span>
<span class="line-added">+       continue;</span>
<span class="line-added">+     }</span>
<span class="line-added">+     if (bt == T_VOID) {</span>
<span class="line-added">+       if (sig_vk-&gt;at(i-1)._bt == T_LONG ||</span>
<span class="line-added">+           sig_vk-&gt;at(i-1)._bt == T_DOUBLE) {</span>
<span class="line-added">+         j++;</span>
<span class="line-added">+       }</span>
<span class="line-added">+       continue;</span>
<span class="line-added">+     }</span>
<span class="line-added">+     int off = sig_vk-&gt;at(i)._offset;</span>
<span class="line-added">+     assert(off &gt; 0, &quot;offset in object should be positive&quot;);</span>
<span class="line-added">+     VMRegPair pair = regs-&gt;at(j);</span>
<span class="line-added">+     VMReg r_1 = pair.first();</span>
<span class="line-added">+     VMReg r_2 = pair.second();</span>
<span class="line-added">+     Address to(rax, off);</span>
<span class="line-added">+     if (bt == T_FLOAT) {</span>
<span class="line-added">+       __ movflt(to, r_1-&gt;as_XMMRegister());</span>
<span class="line-added">+     } else if (bt == T_DOUBLE) {</span>
<span class="line-added">+       __ movdbl(to, r_1-&gt;as_XMMRegister());</span>
<span class="line-added">+     } else {</span>
<span class="line-added">+       Register val = r_1-&gt;as_Register();</span>
<span class="line-added">+       assert_different_registers(to.base(), val, r14, r13, rbx, rscratch1);</span>
<span class="line-added">+       if (is_reference_type(bt)) {</span>
<span class="line-added">+         __ store_heap_oop(to, val, r14, r13, rbx, IN_HEAP | ACCESS_WRITE | IS_DEST_UNINITIALIZED);</span>
<span class="line-added">+       } else {</span>
<span class="line-added">+         __ store_sized_value(to, r_1-&gt;as_Register(), type2aelembytes(bt));</span>
<span class="line-added">+       }</span>
<span class="line-added">+     }</span>
<span class="line-added">+     j++;</span>
<span class="line-added">+   }</span>
<span class="line-added">+   assert(j == regs-&gt;length(), &quot;missed a field?&quot;);</span>
<span class="line-added">+ </span>
<span class="line-added">+   __ ret(0);</span>
<span class="line-added">+ </span>
<span class="line-added">+   int unpack_fields_off = __ offset();</span>
<span class="line-added">+ </span>
<span class="line-added">+   j = 1;</span>
<span class="line-added">+   for (int i = 0; i &lt; sig_vk-&gt;length(); i++) {</span>
<span class="line-added">+     BasicType bt = sig_vk-&gt;at(i)._bt;</span>
<span class="line-added">+     if (bt == T_INLINE_TYPE) {</span>
<span class="line-added">+       continue;</span>
<span class="line-added">+     }</span>
<span class="line-added">+     if (bt == T_VOID) {</span>
<span class="line-added">+       if (sig_vk-&gt;at(i-1)._bt == T_LONG ||</span>
<span class="line-added">+           sig_vk-&gt;at(i-1)._bt == T_DOUBLE) {</span>
<span class="line-added">+         j++;</span>
<span class="line-added">+       }</span>
<span class="line-added">+       continue;</span>
<span class="line-added">+     }</span>
<span class="line-added">+     int off = sig_vk-&gt;at(i)._offset;</span>
<span class="line-added">+     assert(off &gt; 0, &quot;offset in object should be positive&quot;);</span>
<span class="line-added">+     VMRegPair pair = regs-&gt;at(j);</span>
<span class="line-added">+     VMReg r_1 = pair.first();</span>
<span class="line-added">+     VMReg r_2 = pair.second();</span>
<span class="line-added">+     Address from(rax, off);</span>
<span class="line-added">+     if (bt == T_FLOAT) {</span>
<span class="line-added">+       __ movflt(r_1-&gt;as_XMMRegister(), from);</span>
<span class="line-added">+     } else if (bt == T_DOUBLE) {</span>
<span class="line-added">+       __ movdbl(r_1-&gt;as_XMMRegister(), from);</span>
<span class="line-added">+     } else if (bt == T_OBJECT || bt == T_ARRAY) {</span>
<span class="line-added">+       assert_different_registers(rax, r_1-&gt;as_Register());</span>
<span class="line-added">+       __ load_heap_oop(r_1-&gt;as_Register(), from);</span>
<span class="line-added">+     } else {</span>
<span class="line-added">+       assert(is_java_primitive(bt), &quot;unexpected basic type&quot;);</span>
<span class="line-added">+       assert_different_registers(rax, r_1-&gt;as_Register());</span>
<span class="line-added">+       size_t size_in_bytes = type2aelembytes(bt);</span>
<span class="line-added">+       __ load_sized_value(r_1-&gt;as_Register(), from, size_in_bytes, bt != T_CHAR &amp;&amp; bt != T_BOOLEAN);</span>
<span class="line-added">+     }</span>
<span class="line-added">+     j++;</span>
<span class="line-added">+   }</span>
<span class="line-added">+   assert(j == regs-&gt;length(), &quot;missed a field?&quot;);</span>
<span class="line-added">+ </span>
<span class="line-added">+   if (StressInlineTypeReturnedAsFields) {</span>
<span class="line-added">+     __ load_klass(rax, rax, rscratch1);</span>
<span class="line-added">+     __ orptr(rax, 1);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   __ ret(0);</span>
<span class="line-added">+ </span>
<span class="line-added">+   __ flush();</span>
<span class="line-added">+ </span>
<span class="line-added">+   return BufferedInlineTypeBlob::create(&amp;buffer, pack_fields_off, pack_fields_jobject_off, unpack_fields_off);</span>
<span class="line-added">+ }</span>
</pre>
<center><a href="../s390/interp_masm_s390.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="stubGenerator_x86_64.cpp.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>