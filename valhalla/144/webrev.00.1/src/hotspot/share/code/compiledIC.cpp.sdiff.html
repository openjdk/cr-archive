<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/code/compiledIC.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="../../cpu/x86/vm_version_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../compiler/compileBroker.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/code/compiledIC.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
226 CompiledIC::CompiledIC(RelocIterator* iter)
227   : _method(iter-&gt;code())
228 {
229   _call = _method-&gt;call_wrapper_at(iter-&gt;addr());
230   address ic_call = _call-&gt;instruction_address();
231 
232   CompiledMethod* nm = iter-&gt;code();
233   assert(ic_call != NULL, &quot;ic_call address must be set&quot;);
234   assert(nm != NULL, &quot;must pass compiled method&quot;);
235   assert(nm-&gt;contains(ic_call), &quot;must be in compiled method&quot;);
236 
237   initialize_from_iter(iter);
238 }
239 
240 // This function may fail for two reasons: either due to running out of vtable
241 // stubs, or due to running out of IC stubs in an attempted transition to a
242 // transitional state. The needs_ic_stub_refill value will be set if the failure
243 // was due to running out of IC stubs, in which case the caller will refill IC
244 // stubs and retry.
245 bool CompiledIC::set_to_megamorphic(CallInfo* call_info, Bytecodes::Code bytecode,
<span class="line-modified">246                                     bool&amp; needs_ic_stub_refill, TRAPS) {</span>
247   assert(CompiledICLocker::is_safe(_method), &quot;mt unsafe call&quot;);
248   assert(!is_optimized(), &quot;cannot set an optimized virtual call to megamorphic&quot;);
249   assert(is_call_to_compiled() || is_call_to_interpreted(), &quot;going directly to megamorphic?&quot;);
250 
251   address entry;
252   if (call_info-&gt;call_kind() == CallInfo::itable_call) {
253     assert(bytecode == Bytecodes::_invokeinterface, &quot;&quot;);
254     int itable_index = call_info-&gt;itable_index();
<span class="line-modified">255     entry = VtableStubs::find_itable_stub(itable_index);</span>
256     if (entry == NULL) {
257       return false;
258     }
259 #ifdef ASSERT
260     int index = call_info-&gt;resolved_method()-&gt;itable_index();
261     assert(index == itable_index, &quot;CallInfo pre-computes this&quot;);
262     InstanceKlass* k = call_info-&gt;resolved_method()-&gt;method_holder();
263     assert(k-&gt;verify_itable_index(itable_index), &quot;sanity check&quot;);
264 #endif //ASSERT
265     CompiledICHolder* holder = new CompiledICHolder(call_info-&gt;resolved_method()-&gt;method_holder(),
266                                                     call_info-&gt;resolved_klass(), false);
267     holder-&gt;claim();
268     if (!InlineCacheBuffer::create_transition_stub(this, holder, entry)) {
269       delete holder;
270       needs_ic_stub_refill = true;
271       return false;
272     }
273   } else {
274     assert(call_info-&gt;call_kind() == CallInfo::vtable_call, &quot;either itable or vtable&quot;);
275     // Can be different than selected_method-&gt;vtable_index(), due to package-private etc.
276     int vtable_index = call_info-&gt;vtable_index();
277     assert(call_info-&gt;resolved_klass()-&gt;verify_vtable_index(vtable_index), &quot;sanity check&quot;);
<span class="line-modified">278     entry = VtableStubs::find_vtable_stub(vtable_index);</span>
279     if (entry == NULL) {
280       return false;
281     }
282     if (!InlineCacheBuffer::create_transition_stub(this, NULL, entry)) {
283       needs_ic_stub_refill = true;
284       return false;
285     }
286   }
287 
288   if (TraceICs) {
289     ResourceMark rm;
290     assert(call_info-&gt;selected_method() != NULL, &quot;Unexpected null selected method&quot;);
291     tty-&gt;print_cr (&quot;IC@&quot; INTPTR_FORMAT &quot;: to megamorphic %s entry: &quot; INTPTR_FORMAT,
292                    p2i(instruction_address()), call_info-&gt;selected_method()-&gt;print_value_string(), p2i(entry));
293   }
294 
295   // We can&#39;t check this anymore. With lazy deopt we could have already
296   // cleaned this IC entry before we even return. This is possible if
297   // we ran out of space in the inline cache buffer trying to do the
298   // set_next and we safepointed to free up space. This is a benign
</pre>
<hr />
<pre>
493   // cleaned this IC entry before we even return. This is possible if
494   // we ran out of space in the inline cache buffer trying to do the
495   // set_next and we safepointed to free up space. This is a benign
496   // race because the IC entry was complete when we safepointed so
497   // cleaning it immediately is harmless.
498   // assert(is_call_to_compiled() || is_call_to_interpreted(), &quot;sanity check&quot;);
499   return true;
500 }
501 
502 
503 // is_optimized: Compiler has generated an optimized call (i.e. fixed, no inline cache)
504 // static_bound: The call can be static bound. If it isn&#39;t also optimized, the property
505 // wasn&#39;t provable at time of compilation. An optimized call will have any necessary
506 // null check, while a static_bound won&#39;t. A static_bound (but not optimized) must
507 // therefore use the unverified entry point.
508 void CompiledIC::compute_monomorphic_entry(const methodHandle&amp; method,
509                                            Klass* receiver_klass,
510                                            bool is_optimized,
511                                            bool static_bound,
512                                            bool caller_is_nmethod,

513                                            CompiledICInfo&amp; info,
514                                            TRAPS) {
515   CompiledMethod* method_code = method-&gt;code();
516 
517   address entry = NULL;
518   if (method_code != NULL &amp;&amp; method_code-&gt;is_in_use()) {
519     assert(method_code-&gt;is_compiled(), &quot;must be compiled&quot;);
520     // Call to compiled code
521     //
522     // Note: the following problem exists with Compiler1:
523     //   - at compile time we may or may not know if the destination is final
524     //   - if we know that the destination is final (is_optimized), we will emit
525     //     an optimized virtual call (no inline cache), and need a Method* to make
526     //     a call to the interpreter
527     //   - if we don&#39;t know if the destination is final, we emit a standard
528     //     virtual call, and use CompiledICHolder to call interpreted code
529     //     (no static call stub has been generated)
530     //   - In the case that we here notice the call is static bound we
531     //     convert the call into what looks to be an optimized virtual call,
532     //     but we must use the unverified entry point (since there will be no
533     //     null check on a call when the target isn&#39;t loaded).
534     //     This causes problems when verifying the IC because
535     //     it looks vanilla but is optimized. Code in is_call_to_interpreted
536     //     is aware of this and weakens its asserts.
537     if (is_optimized) {
<span class="line-modified">538       entry      = method_code-&gt;verified_entry_point();</span>
539     } else {
<span class="line-modified">540       entry      = method_code-&gt;entry_point();</span>
541     }
542   }
543   bool far_c2a = entry != NULL &amp;&amp; caller_is_nmethod &amp;&amp; method_code-&gt;is_far_code();
544   if (entry != NULL &amp;&amp; !far_c2a) {
545     // Call to near compiled code (nmethod or aot).
546     info.set_compiled_entry(entry, is_optimized ? NULL : receiver_klass, is_optimized);
547   } else {
548     if (is_optimized) {
549       if (far_c2a) {
550         // Call to aot code from nmethod.
551         info.set_aot_entry(entry, method());
552       } else {
553         // Use stub entry
<span class="line-modified">554         info.set_interpreter_entry(method()-&gt;get_c2i_entry(), method());</span>

555       }
556     } else {
557       // Use icholder entry
558       assert(method_code == NULL || method_code-&gt;is_compiled(), &quot;must be compiled&quot;);
559       CompiledICHolder* holder = new CompiledICHolder(method(), receiver_klass);
<span class="line-modified">560       info.set_icholder_entry(method()-&gt;get_c2i_unverified_entry(), holder);</span>

561     }
562   }
563   assert(info.is_optimized() == is_optimized, &quot;must agree&quot;);
564 }
565 
566 
567 bool CompiledIC::is_icholder_entry(address entry) {
568   CodeBlob* cb = CodeCache::find_blob_unsafe(entry);
569   if (cb != NULL &amp;&amp; cb-&gt;is_adapter_blob()) {
570     return true;
571   }
572   // itable stubs also use CompiledICHolder
573   if (cb != NULL &amp;&amp; cb-&gt;is_vtable_blob()) {
574     VtableStub* s = VtableStubs::entry_point(entry);
575     return (s != NULL) &amp;&amp; s-&gt;is_itable_stub();
576   }
577 
578   return false;
579 }
580 
</pre>
<hr />
<pre>
639   // to track down - if cache entry gets invalid - we just clean it. In
640   // this way it is always the same code path that is responsible for
641   // updating and resolving an inline cache
642   assert(is_clean(), &quot;do not update a call entry - use clean&quot;);
643 
644   if (info._to_interpreter) {
645     // Call to interpreted code
646     set_to_interpreted(info.callee(), info.entry());
647 #if INCLUDE_AOT
648   } else if (info._to_aot) {
649     // Call to far code
650     set_to_far(info.callee(), info.entry());
651 #endif
652   } else {
653     set_to_compiled(info.entry());
654   }
655 }
656 
657 // Compute settings for a CompiledStaticCall. Since we might have to set
658 // the stub when calling to the interpreter, we need to return arguments.
<span class="line-modified">659 void CompiledStaticCall::compute_entry(const methodHandle&amp; m, bool caller_is_nmethod, StaticCallInfo&amp; info) {</span>

660   CompiledMethod* m_code = m-&gt;code();
661   info._callee = m;
662   if (m_code != NULL &amp;&amp; m_code-&gt;is_in_use()) {
663     if (caller_is_nmethod &amp;&amp; m_code-&gt;is_far_code()) {
664       // Call to far aot code from nmethod.
665       info._to_aot = true;
666     } else {
667       info._to_aot = false;
668     }
669     info._to_interpreter = false;
<span class="line-modified">670     info._entry  = m_code-&gt;verified_entry_point();</span>




671   } else {
672     // Callee is interpreted code.  In any case entering the interpreter
673     // puts a converter-frame on the stack to save arguments.
674     assert(!m-&gt;is_method_handle_intrinsic(), &quot;Compiled code should never call interpreter MH intrinsics&quot;);
675     info._to_interpreter = true;
<span class="line-modified">676     info._entry      = m()-&gt;get_c2i_entry();</span>







677   }
678 }
679 
680 address CompiledDirectStaticCall::find_stub_for(address instruction, bool is_aot) {
681   // Find reloc. information containing this call-site
682   RelocIterator iter((nmethod*)NULL, instruction);
683   while (iter.next()) {
684     if (iter.addr() == instruction) {
685       switch(iter.type()) {
686         case relocInfo::static_call_type:
687           return iter.static_call_reloc()-&gt;static_stub(is_aot);
688         // We check here for opt_virtual_call_type, since we reuse the code
689         // from the CompiledIC implementation
690         case relocInfo::opt_virtual_call_type:
691           return iter.opt_virtual_call_reloc()-&gt;static_stub(is_aot);
692         case relocInfo::poll_type:
693         case relocInfo::poll_return_type: // A safepoint can&#39;t overlap a call.
694         default:
695           ShouldNotReachHere();
696       }
</pre>
</td>
<td>
<hr />
<pre>
226 CompiledIC::CompiledIC(RelocIterator* iter)
227   : _method(iter-&gt;code())
228 {
229   _call = _method-&gt;call_wrapper_at(iter-&gt;addr());
230   address ic_call = _call-&gt;instruction_address();
231 
232   CompiledMethod* nm = iter-&gt;code();
233   assert(ic_call != NULL, &quot;ic_call address must be set&quot;);
234   assert(nm != NULL, &quot;must pass compiled method&quot;);
235   assert(nm-&gt;contains(ic_call), &quot;must be in compiled method&quot;);
236 
237   initialize_from_iter(iter);
238 }
239 
240 // This function may fail for two reasons: either due to running out of vtable
241 // stubs, or due to running out of IC stubs in an attempted transition to a
242 // transitional state. The needs_ic_stub_refill value will be set if the failure
243 // was due to running out of IC stubs, in which case the caller will refill IC
244 // stubs and retry.
245 bool CompiledIC::set_to_megamorphic(CallInfo* call_info, Bytecodes::Code bytecode,
<span class="line-modified">246                                     bool&amp; needs_ic_stub_refill, bool caller_is_c1, TRAPS) {</span>
247   assert(CompiledICLocker::is_safe(_method), &quot;mt unsafe call&quot;);
248   assert(!is_optimized(), &quot;cannot set an optimized virtual call to megamorphic&quot;);
249   assert(is_call_to_compiled() || is_call_to_interpreted(), &quot;going directly to megamorphic?&quot;);
250 
251   address entry;
252   if (call_info-&gt;call_kind() == CallInfo::itable_call) {
253     assert(bytecode == Bytecodes::_invokeinterface, &quot;&quot;);
254     int itable_index = call_info-&gt;itable_index();
<span class="line-modified">255     entry = VtableStubs::find_itable_stub(itable_index, caller_is_c1);</span>
256     if (entry == NULL) {
257       return false;
258     }
259 #ifdef ASSERT
260     int index = call_info-&gt;resolved_method()-&gt;itable_index();
261     assert(index == itable_index, &quot;CallInfo pre-computes this&quot;);
262     InstanceKlass* k = call_info-&gt;resolved_method()-&gt;method_holder();
263     assert(k-&gt;verify_itable_index(itable_index), &quot;sanity check&quot;);
264 #endif //ASSERT
265     CompiledICHolder* holder = new CompiledICHolder(call_info-&gt;resolved_method()-&gt;method_holder(),
266                                                     call_info-&gt;resolved_klass(), false);
267     holder-&gt;claim();
268     if (!InlineCacheBuffer::create_transition_stub(this, holder, entry)) {
269       delete holder;
270       needs_ic_stub_refill = true;
271       return false;
272     }
273   } else {
274     assert(call_info-&gt;call_kind() == CallInfo::vtable_call, &quot;either itable or vtable&quot;);
275     // Can be different than selected_method-&gt;vtable_index(), due to package-private etc.
276     int vtable_index = call_info-&gt;vtable_index();
277     assert(call_info-&gt;resolved_klass()-&gt;verify_vtable_index(vtable_index), &quot;sanity check&quot;);
<span class="line-modified">278     entry = VtableStubs::find_vtable_stub(vtable_index, caller_is_c1);</span>
279     if (entry == NULL) {
280       return false;
281     }
282     if (!InlineCacheBuffer::create_transition_stub(this, NULL, entry)) {
283       needs_ic_stub_refill = true;
284       return false;
285     }
286   }
287 
288   if (TraceICs) {
289     ResourceMark rm;
290     assert(call_info-&gt;selected_method() != NULL, &quot;Unexpected null selected method&quot;);
291     tty-&gt;print_cr (&quot;IC@&quot; INTPTR_FORMAT &quot;: to megamorphic %s entry: &quot; INTPTR_FORMAT,
292                    p2i(instruction_address()), call_info-&gt;selected_method()-&gt;print_value_string(), p2i(entry));
293   }
294 
295   // We can&#39;t check this anymore. With lazy deopt we could have already
296   // cleaned this IC entry before we even return. This is possible if
297   // we ran out of space in the inline cache buffer trying to do the
298   // set_next and we safepointed to free up space. This is a benign
</pre>
<hr />
<pre>
493   // cleaned this IC entry before we even return. This is possible if
494   // we ran out of space in the inline cache buffer trying to do the
495   // set_next and we safepointed to free up space. This is a benign
496   // race because the IC entry was complete when we safepointed so
497   // cleaning it immediately is harmless.
498   // assert(is_call_to_compiled() || is_call_to_interpreted(), &quot;sanity check&quot;);
499   return true;
500 }
501 
502 
503 // is_optimized: Compiler has generated an optimized call (i.e. fixed, no inline cache)
504 // static_bound: The call can be static bound. If it isn&#39;t also optimized, the property
505 // wasn&#39;t provable at time of compilation. An optimized call will have any necessary
506 // null check, while a static_bound won&#39;t. A static_bound (but not optimized) must
507 // therefore use the unverified entry point.
508 void CompiledIC::compute_monomorphic_entry(const methodHandle&amp; method,
509                                            Klass* receiver_klass,
510                                            bool is_optimized,
511                                            bool static_bound,
512                                            bool caller_is_nmethod,
<span class="line-added">513                                            bool caller_is_c1,</span>
514                                            CompiledICInfo&amp; info,
515                                            TRAPS) {
516   CompiledMethod* method_code = method-&gt;code();
517 
518   address entry = NULL;
519   if (method_code != NULL &amp;&amp; method_code-&gt;is_in_use()) {
520     assert(method_code-&gt;is_compiled(), &quot;must be compiled&quot;);
521     // Call to compiled code
522     //
523     // Note: the following problem exists with Compiler1:
524     //   - at compile time we may or may not know if the destination is final
525     //   - if we know that the destination is final (is_optimized), we will emit
526     //     an optimized virtual call (no inline cache), and need a Method* to make
527     //     a call to the interpreter
528     //   - if we don&#39;t know if the destination is final, we emit a standard
529     //     virtual call, and use CompiledICHolder to call interpreted code
530     //     (no static call stub has been generated)
531     //   - In the case that we here notice the call is static bound we
532     //     convert the call into what looks to be an optimized virtual call,
533     //     but we must use the unverified entry point (since there will be no
534     //     null check on a call when the target isn&#39;t loaded).
535     //     This causes problems when verifying the IC because
536     //     it looks vanilla but is optimized. Code in is_call_to_interpreted
537     //     is aware of this and weakens its asserts.
538     if (is_optimized) {
<span class="line-modified">539       entry      = caller_is_c1 ? method_code-&gt;verified_inline_entry_point() : method_code-&gt;verified_entry_point();</span>
540     } else {
<span class="line-modified">541       entry      = caller_is_c1 ? method_code-&gt;inline_entry_point() : method_code-&gt;entry_point();</span>
542     }
543   }
544   bool far_c2a = entry != NULL &amp;&amp; caller_is_nmethod &amp;&amp; method_code-&gt;is_far_code();
545   if (entry != NULL &amp;&amp; !far_c2a) {
546     // Call to near compiled code (nmethod or aot).
547     info.set_compiled_entry(entry, is_optimized ? NULL : receiver_klass, is_optimized);
548   } else {
549     if (is_optimized) {
550       if (far_c2a) {
551         // Call to aot code from nmethod.
552         info.set_aot_entry(entry, method());
553       } else {
554         // Use stub entry
<span class="line-modified">555         address entry = caller_is_c1 ? method()-&gt;get_c2i_inline_entry() : method()-&gt;get_c2i_entry();</span>
<span class="line-added">556         info.set_interpreter_entry(entry, method());</span>
557       }
558     } else {
559       // Use icholder entry
560       assert(method_code == NULL || method_code-&gt;is_compiled(), &quot;must be compiled&quot;);
561       CompiledICHolder* holder = new CompiledICHolder(method(), receiver_klass);
<span class="line-modified">562       entry = (caller_is_c1)? method()-&gt;get_c2i_unverified_inline_entry() : method()-&gt;get_c2i_unverified_entry();</span>
<span class="line-added">563       info.set_icholder_entry(entry, holder);</span>
564     }
565   }
566   assert(info.is_optimized() == is_optimized, &quot;must agree&quot;);
567 }
568 
569 
570 bool CompiledIC::is_icholder_entry(address entry) {
571   CodeBlob* cb = CodeCache::find_blob_unsafe(entry);
572   if (cb != NULL &amp;&amp; cb-&gt;is_adapter_blob()) {
573     return true;
574   }
575   // itable stubs also use CompiledICHolder
576   if (cb != NULL &amp;&amp; cb-&gt;is_vtable_blob()) {
577     VtableStub* s = VtableStubs::entry_point(entry);
578     return (s != NULL) &amp;&amp; s-&gt;is_itable_stub();
579   }
580 
581   return false;
582 }
583 
</pre>
<hr />
<pre>
642   // to track down - if cache entry gets invalid - we just clean it. In
643   // this way it is always the same code path that is responsible for
644   // updating and resolving an inline cache
645   assert(is_clean(), &quot;do not update a call entry - use clean&quot;);
646 
647   if (info._to_interpreter) {
648     // Call to interpreted code
649     set_to_interpreted(info.callee(), info.entry());
650 #if INCLUDE_AOT
651   } else if (info._to_aot) {
652     // Call to far code
653     set_to_far(info.callee(), info.entry());
654 #endif
655   } else {
656     set_to_compiled(info.entry());
657   }
658 }
659 
660 // Compute settings for a CompiledStaticCall. Since we might have to set
661 // the stub when calling to the interpreter, we need to return arguments.
<span class="line-modified">662 void CompiledStaticCall::compute_entry(const methodHandle&amp; m, CompiledMethod* caller_nm, StaticCallInfo&amp; info) {</span>
<span class="line-added">663   bool caller_is_nmethod = caller_nm-&gt;is_nmethod();</span>
664   CompiledMethod* m_code = m-&gt;code();
665   info._callee = m;
666   if (m_code != NULL &amp;&amp; m_code-&gt;is_in_use()) {
667     if (caller_is_nmethod &amp;&amp; m_code-&gt;is_far_code()) {
668       // Call to far aot code from nmethod.
669       info._to_aot = true;
670     } else {
671       info._to_aot = false;
672     }
673     info._to_interpreter = false;
<span class="line-modified">674     if (caller_nm-&gt;is_compiled_by_c1()) {</span>
<span class="line-added">675       info._entry = m_code-&gt;verified_inline_entry_point();</span>
<span class="line-added">676     } else {</span>
<span class="line-added">677       info._entry = m_code-&gt;verified_entry_point();</span>
<span class="line-added">678     }</span>
679   } else {
680     // Callee is interpreted code.  In any case entering the interpreter
681     // puts a converter-frame on the stack to save arguments.
682     assert(!m-&gt;is_method_handle_intrinsic(), &quot;Compiled code should never call interpreter MH intrinsics&quot;);
683     info._to_interpreter = true;
<span class="line-modified">684 </span>
<span class="line-added">685     if (caller_nm-&gt;is_compiled_by_c1()) {</span>
<span class="line-added">686       // C1 -&gt; interp: values passed as oops</span>
<span class="line-added">687       info._entry = m()-&gt;get_c2i_inline_entry();</span>
<span class="line-added">688     } else {</span>
<span class="line-added">689       // C2 -&gt; interp: values passed fields</span>
<span class="line-added">690       info._entry = m()-&gt;get_c2i_entry();</span>
<span class="line-added">691     }</span>
692   }
693 }
694 
695 address CompiledDirectStaticCall::find_stub_for(address instruction, bool is_aot) {
696   // Find reloc. information containing this call-site
697   RelocIterator iter((nmethod*)NULL, instruction);
698   while (iter.next()) {
699     if (iter.addr() == instruction) {
700       switch(iter.type()) {
701         case relocInfo::static_call_type:
702           return iter.static_call_reloc()-&gt;static_stub(is_aot);
703         // We check here for opt_virtual_call_type, since we reuse the code
704         // from the CompiledIC implementation
705         case relocInfo::opt_virtual_call_type:
706           return iter.opt_virtual_call_reloc()-&gt;static_stub(is_aot);
707         case relocInfo::poll_type:
708         case relocInfo::poll_return_type: // A safepoint can&#39;t overlap a call.
709         default:
710           ShouldNotReachHere();
711       }
</pre>
</td>
</tr>
</table>
<center><a href="../../cpu/x86/vm_version_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../compiler/compileBroker.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>