<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff src/hotspot/share/opto/compile.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="chaitin.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="compile.hpp.cdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/compile.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 49,10 ***</span>
<span class="line-new-header">--- 49,11 ---</span>
  #include &quot;opto/connode.hpp&quot;
  #include &quot;opto/convertnode.hpp&quot;
  #include &quot;opto/divnode.hpp&quot;
  #include &quot;opto/escape.hpp&quot;
  #include &quot;opto/idealGraphPrinter.hpp&quot;
<span class="line-added">+ #include &quot;opto/inlinetypenode.hpp&quot;</span>
  #include &quot;opto/loopnode.hpp&quot;
  #include &quot;opto/machnode.hpp&quot;
  #include &quot;opto/macro.hpp&quot;
  #include &quot;opto/matcher.hpp&quot;
  #include &quot;opto/mathexactnode.hpp&quot;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 403,10 ***</span>
<span class="line-new-header">--- 404,17 ---</span>
      Node* opaq = opaque4_node(i);
      if (!useful.member(opaq)) {
        remove_opaque4_node(opaq);
      }
    }
<span class="line-added">+   // Remove useless inline type nodes</span>
<span class="line-added">+   for (int i = _inline_type_nodes-&gt;length() - 1; i &gt;= 0; i--) {</span>
<span class="line-added">+     Node* vt = _inline_type_nodes-&gt;at(i);</span>
<span class="line-added">+     if (!useful.member(vt)) {</span>
<span class="line-added">+       _inline_type_nodes-&gt;remove(vt);</span>
<span class="line-added">+     }</span>
<span class="line-added">+   }</span>
    BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
    bs-&gt;eliminate_useless_gc_barriers(useful, this);
    // clean up the late inline lists
    remove_useless_late_inlines(&amp;_string_late_inlines, useful);
    remove_useless_late_inlines(&amp;_boxing_late_inlines, useful);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 628,21 ***</span>
      initial_gvn()-&gt;transform_no_reclaim(top());
  
      // Set up tf(), start(), and find a CallGenerator.
      CallGenerator* cg = NULL;
      if (is_osr_compilation()) {
<span class="line-modified">!       const TypeTuple *domain = StartOSRNode::osr_domain();</span>
<span class="line-modified">!       const TypeTuple *range = TypeTuple::make_range(method()-&gt;signature());</span>
<span class="line-removed">-       init_tf(TypeFunc::make(domain, range));</span>
<span class="line-removed">-       StartNode* s = new StartOSRNode(root(), domain);</span>
        initial_gvn()-&gt;set_type_bottom(s);
        init_start(s);
        cg = CallGenerator::for_osr(method(), entry_bci());
      } else {
        // Normal case.
        init_tf(TypeFunc::make(method()));
<span class="line-modified">!       StartNode* s = new StartNode(root(), tf()-&gt;domain());</span>
        initial_gvn()-&gt;set_type_bottom(s);
        init_start(s);
        if (method()-&gt;intrinsic_id() == vmIntrinsics::_Reference_get) {
          // With java.lang.ref.reference.get() we must go through the
          // intrinsic - even when get() is the root
<span class="line-new-header">--- 636,19 ---</span>
      initial_gvn()-&gt;transform_no_reclaim(top());
  
      // Set up tf(), start(), and find a CallGenerator.
      CallGenerator* cg = NULL;
      if (is_osr_compilation()) {
<span class="line-modified">!       init_tf(TypeFunc::make(method(), /* is_osr_compilation = */ true));</span>
<span class="line-modified">!       StartNode* s = new StartOSRNode(root(), tf()-&gt;domain_sig());</span>
        initial_gvn()-&gt;set_type_bottom(s);
        init_start(s);
        cg = CallGenerator::for_osr(method(), entry_bci());
      } else {
        // Normal case.
        init_tf(TypeFunc::make(method()));
<span class="line-modified">!       StartNode* s = new StartNode(root(), tf()-&gt;domain_cc());</span>
        initial_gvn()-&gt;set_type_bottom(s);
        init_start(s);
        if (method()-&gt;intrinsic_id() == vmIntrinsics::_Reference_get) {
          // With java.lang.ref.reference.get() we must go through the
          // intrinsic - even when get() is the root
</pre>
<hr />
<pre>
<span class="line-old-header">*** 763,10 ***</span>
<span class="line-new-header">--- 769,14 ---</span>
    }
  
    // Now that we know the size of all the monitors we can add a fixed slot
    // for the original deopt pc.
    int next_slot = fixed_slots() + (sizeof(address) / VMRegImpl::stack_slot_size);
<span class="line-added">+   if (needs_stack_repair()) {</span>
<span class="line-added">+     // One extra slot for the special stack increment value</span>
<span class="line-added">+     next_slot += 2;</span>
<span class="line-added">+   }</span>
    set_fixed_slots(next_slot);
  
    // Compute when to use implicit null checks. Used by matching trap based
    // nodes and NullCheck optimization.
    set_allowed_deopt_reasons();
</pre>
<hr />
<pre>
<span class="line-old-header">*** 916,10 ***</span>
<span class="line-new-header">--- 926,13 ---</span>
    Copy::zero_to_bytes(_trap_hist, sizeof(_trap_hist));
    set_decompile_count(0);
  
    set_do_freq_based_layout(_directive-&gt;BlockLayoutByFrequencyOption);
    _loop_opts_cnt = LoopOptsCount;
<span class="line-added">+   _has_flattened_accesses = false;</span>
<span class="line-added">+   _flattened_accesses_share_alias = true;</span>
<span class="line-added">+ </span>
    set_do_inlining(Inline);
    set_max_inline_size(MaxInlineSize);
    set_freq_inline_size(FreqInlineSize);
    set_do_scheduling(OptoScheduling);
    set_do_count_invocations(false);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 999,10 ***</span>
<span class="line-new-header">--- 1012,11 ---</span>
    _macro_nodes = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
    _predicate_opaqs = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
    _expensive_nodes = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
    _range_check_casts = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
    _opaque4_nodes = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
<span class="line-added">+   _inline_type_nodes = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);</span>
    register_library_intrinsics();
  #ifdef ASSERT
    _type_verify_symmetry = true;
    _phase_optimize_finished = false;
  #endif
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1227,11 ***</span>
    bool is_known_inst = tj-&gt;isa_oopptr() != NULL &amp;&amp;
                         tj-&gt;is_oopptr()-&gt;is_known_instance();
  
    // Process weird unsafe references.
    if (offset == Type::OffsetBot &amp;&amp; (tj-&gt;isa_instptr() /*|| tj-&gt;isa_klassptr()*/)) {
<span class="line-modified">!     assert(InlineUnsafeOps, &quot;indeterminate pointers come only from unsafe ops&quot;);</span>
      assert(!is_known_inst, &quot;scalarizable allocation should not have unsafe references&quot;);
      tj = TypeOopPtr::BOTTOM;
      ptr = tj-&gt;ptr();
      offset = tj-&gt;offset();
    }
<span class="line-new-header">--- 1241,12 ---</span>
    bool is_known_inst = tj-&gt;isa_oopptr() != NULL &amp;&amp;
                         tj-&gt;is_oopptr()-&gt;is_known_instance();
  
    // Process weird unsafe references.
    if (offset == Type::OffsetBot &amp;&amp; (tj-&gt;isa_instptr() /*|| tj-&gt;isa_klassptr()*/)) {
<span class="line-modified">!     bool default_value_load = EnableValhalla &amp;&amp; tj-&gt;is_instptr()-&gt;klass() == ciEnv::current()-&gt;Class_klass();</span>
<span class="line-added">+     assert(InlineUnsafeOps || default_value_load, &quot;indeterminate pointers come only from unsafe ops&quot;);</span>
      assert(!is_known_inst, &quot;scalarizable allocation should not have unsafe references&quot;);
      tj = TypeOopPtr::BOTTOM;
      ptr = tj-&gt;ptr();
      offset = tj-&gt;offset();
    }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1240,24 ***</span>
    const TypeAryPtr *ta = tj-&gt;isa_aryptr();
    if (ta &amp;&amp; ta-&gt;is_stable()) {
      // Erase stability property for alias analysis.
      tj = ta = ta-&gt;cast_to_stable(false);
    }
    if( ta &amp;&amp; is_known_inst ) {
      if ( offset != Type::OffsetBot &amp;&amp;
           offset &gt; arrayOopDesc::length_offset_in_bytes() ) {
        offset = Type::OffsetBot; // Flatten constant access into array body only
<span class="line-modified">!       tj = ta = TypeAryPtr::make(ptr, ta-&gt;ary(), ta-&gt;klass(), true, offset, ta-&gt;instance_id());</span>
      }
    } else if( ta &amp;&amp; _AliasLevel &gt;= 2 ) {
      // For arrays indexed by constant indices, we flatten the alias
      // space to include all of the array body.  Only the header, klass
      // and array length can be accessed un-aliased.
      if( offset != Type::OffsetBot ) {
        if( ta-&gt;const_oop() ) { // MethodData* or Method*
          offset = Type::OffsetBot;   // Flatten constant access into array body
<span class="line-modified">!         tj = ta = TypeAryPtr::make(ptr,ta-&gt;const_oop(),ta-&gt;ary(),ta-&gt;klass(),false,offset);</span>
        } else if( offset == arrayOopDesc::length_offset_in_bytes() ) {
          // range is OK as-is.
          tj = ta = TypeAryPtr::RANGE;
        } else if( offset == oopDesc::klass_offset_in_bytes() ) {
          tj = TypeInstPtr::KLASS; // all klass loads look alike
<span class="line-new-header">--- 1255,35 ---</span>
    const TypeAryPtr *ta = tj-&gt;isa_aryptr();
    if (ta &amp;&amp; ta-&gt;is_stable()) {
      // Erase stability property for alias analysis.
      tj = ta = ta-&gt;cast_to_stable(false);
    }
<span class="line-added">+   if (ta &amp;&amp; ta-&gt;is_not_flat()) {</span>
<span class="line-added">+     // Erase not flat property for alias analysis.</span>
<span class="line-added">+     tj = ta = ta-&gt;cast_to_not_flat(false);</span>
<span class="line-added">+   }</span>
<span class="line-added">+   if (ta &amp;&amp; ta-&gt;is_not_null_free()) {</span>
<span class="line-added">+     // Erase not null free property for alias analysis.</span>
<span class="line-added">+     tj = ta = ta-&gt;cast_to_not_null_free(false);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
    if( ta &amp;&amp; is_known_inst ) {
      if ( offset != Type::OffsetBot &amp;&amp;
           offset &gt; arrayOopDesc::length_offset_in_bytes() ) {
        offset = Type::OffsetBot; // Flatten constant access into array body only
<span class="line-modified">!       tj = ta = TypeAryPtr::make(ptr, ta-&gt;ary(), ta-&gt;klass(), true, Type::Offset(offset), ta-&gt;field_offset(), ta-&gt;instance_id());</span>
      }
    } else if( ta &amp;&amp; _AliasLevel &gt;= 2 ) {
      // For arrays indexed by constant indices, we flatten the alias
      // space to include all of the array body.  Only the header, klass
      // and array length can be accessed un-aliased.
<span class="line-added">+     // For flattened inline type array, each field has its own slice so</span>
<span class="line-added">+     // we must include the field offset.</span>
      if( offset != Type::OffsetBot ) {
        if( ta-&gt;const_oop() ) { // MethodData* or Method*
          offset = Type::OffsetBot;   // Flatten constant access into array body
<span class="line-modified">!         tj = ta = TypeAryPtr::make(ptr,ta-&gt;const_oop(),ta-&gt;ary(),ta-&gt;klass(),false,Type::Offset(offset), ta-&gt;field_offset());</span>
        } else if( offset == arrayOopDesc::length_offset_in_bytes() ) {
          // range is OK as-is.
          tj = ta = TypeAryPtr::RANGE;
        } else if( offset == oopDesc::klass_offset_in_bytes() ) {
          tj = TypeInstPtr::KLASS; // all klass loads look alike
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1267,39 ***</span>
          tj = TypeInstPtr::MARK;
          ta = TypeAryPtr::RANGE; // generic ignored junk
          ptr = TypePtr::BotPTR;
        } else {                  // Random constant offset into array body
          offset = Type::OffsetBot;   // Flatten constant access into array body
<span class="line-modified">!         tj = ta = TypeAryPtr::make(ptr,ta-&gt;ary(),ta-&gt;klass(),false,offset);</span>
        }
      }
      // Arrays of fixed size alias with arrays of unknown size.
      if (ta-&gt;size() != TypeInt::POS) {
        const TypeAry *tary = TypeAry::make(ta-&gt;elem(), TypeInt::POS);
<span class="line-modified">!       tj = ta = TypeAryPtr::make(ptr,ta-&gt;const_oop(),tary,ta-&gt;klass(),false,offset);</span>
      }
      // Arrays of known objects become arrays of unknown objects.
      if (ta-&gt;elem()-&gt;isa_narrowoop() &amp;&amp; ta-&gt;elem() != TypeNarrowOop::BOTTOM) {
        const TypeAry *tary = TypeAry::make(TypeNarrowOop::BOTTOM, ta-&gt;size());
<span class="line-modified">!       tj = ta = TypeAryPtr::make(ptr,ta-&gt;const_oop(),tary,NULL,false,offset);</span>
      }
      if (ta-&gt;elem()-&gt;isa_oopptr() &amp;&amp; ta-&gt;elem() != TypeInstPtr::BOTTOM) {
        const TypeAry *tary = TypeAry::make(TypeInstPtr::BOTTOM, ta-&gt;size());
<span class="line-modified">!       tj = ta = TypeAryPtr::make(ptr,ta-&gt;const_oop(),tary,NULL,false,offset);</span>
      }
      // Arrays of bytes and of booleans both use &#39;bastore&#39; and &#39;baload&#39; so
      // cannot be distinguished by bytecode alone.
      if (ta-&gt;elem() == TypeInt::BOOL) {
        const TypeAry *tary = TypeAry::make(TypeInt::BYTE, ta-&gt;size());
        ciKlass* aklass = ciTypeArrayKlass::make(T_BYTE);
<span class="line-modified">!       tj = ta = TypeAryPtr::make(ptr,ta-&gt;const_oop(),tary,aklass,false,offset);</span>
      }
      // During the 2nd round of IterGVN, NotNull castings are removed.
      // Make sure the Bottom and NotNull variants alias the same.
      // Also, make sure exact and non-exact variants alias the same.
      if (ptr == TypePtr::NotNull || ta-&gt;klass_is_exact() || ta-&gt;speculative() != NULL) {
<span class="line-modified">!       tj = ta = TypeAryPtr::make(TypePtr::BotPTR,ta-&gt;ary(),ta-&gt;klass(),false,offset);</span>
      }
    }
  
    // Oop pointers need some flattening
    const TypeInstPtr *to = tj-&gt;isa_instptr();
<span class="line-new-header">--- 1293,44 ---</span>
          tj = TypeInstPtr::MARK;
          ta = TypeAryPtr::RANGE; // generic ignored junk
          ptr = TypePtr::BotPTR;
        } else {                  // Random constant offset into array body
          offset = Type::OffsetBot;   // Flatten constant access into array body
<span class="line-modified">!         tj = ta = TypeAryPtr::make(ptr,ta-&gt;ary(),ta-&gt;klass(),false,Type::Offset(offset), ta-&gt;field_offset());</span>
        }
      }
      // Arrays of fixed size alias with arrays of unknown size.
      if (ta-&gt;size() != TypeInt::POS) {
        const TypeAry *tary = TypeAry::make(ta-&gt;elem(), TypeInt::POS);
<span class="line-modified">!       tj = ta = TypeAryPtr::make(ptr,ta-&gt;const_oop(),tary,ta-&gt;klass(),false,Type::Offset(offset), ta-&gt;field_offset());</span>
      }
      // Arrays of known objects become arrays of unknown objects.
      if (ta-&gt;elem()-&gt;isa_narrowoop() &amp;&amp; ta-&gt;elem() != TypeNarrowOop::BOTTOM) {
        const TypeAry *tary = TypeAry::make(TypeNarrowOop::BOTTOM, ta-&gt;size());
<span class="line-modified">!       tj = ta = TypeAryPtr::make(ptr,ta-&gt;const_oop(),tary,NULL,false,Type::Offset(offset), ta-&gt;field_offset());</span>
      }
      if (ta-&gt;elem()-&gt;isa_oopptr() &amp;&amp; ta-&gt;elem() != TypeInstPtr::BOTTOM) {
        const TypeAry *tary = TypeAry::make(TypeInstPtr::BOTTOM, ta-&gt;size());
<span class="line-modified">!       tj = ta = TypeAryPtr::make(ptr,ta-&gt;const_oop(),tary,NULL,false,Type::Offset(offset), ta-&gt;field_offset());</span>
<span class="line-added">+     }</span>
<span class="line-added">+     // Initially all flattened array accesses share a single slice</span>
<span class="line-added">+     if (ta-&gt;elem()-&gt;isa_inlinetype() &amp;&amp; ta-&gt;elem() != TypeInlineType::BOTTOM &amp;&amp; _flattened_accesses_share_alias) {</span>
<span class="line-added">+       const TypeAry *tary = TypeAry::make(TypeInlineType::BOTTOM, ta-&gt;size());</span>
<span class="line-added">+       tj = ta = TypeAryPtr::make(ptr,ta-&gt;const_oop(),tary,NULL,false,Type::Offset(offset), Type::Offset(Type::OffsetBot));</span>
      }
      // Arrays of bytes and of booleans both use &#39;bastore&#39; and &#39;baload&#39; so
      // cannot be distinguished by bytecode alone.
      if (ta-&gt;elem() == TypeInt::BOOL) {
        const TypeAry *tary = TypeAry::make(TypeInt::BYTE, ta-&gt;size());
        ciKlass* aklass = ciTypeArrayKlass::make(T_BYTE);
<span class="line-modified">!       tj = ta = TypeAryPtr::make(ptr,ta-&gt;const_oop(),tary,aklass,false,Type::Offset(offset), ta-&gt;field_offset());</span>
      }
      // During the 2nd round of IterGVN, NotNull castings are removed.
      // Make sure the Bottom and NotNull variants alias the same.
      // Also, make sure exact and non-exact variants alias the same.
      if (ptr == TypePtr::NotNull || ta-&gt;klass_is_exact() || ta-&gt;speculative() != NULL) {
<span class="line-modified">!       tj = ta = TypeAryPtr::make(TypePtr::BotPTR,ta-&gt;ary(),ta-&gt;klass(),false,Type::Offset(offset), ta-&gt;field_offset());</span>
      }
    }
  
    // Oop pointers need some flattening
    const TypeInstPtr *to = tj-&gt;isa_instptr();
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1309,29 ***</span>
        if (to-&gt;klass() != ciEnv::current()-&gt;Class_klass() ||
            offset &lt; k-&gt;size_helper() * wordSize) {
          // No constant oop pointers (such as Strings); they alias with
          // unknown strings.
          assert(!is_known_inst, &quot;not scalarizable allocation&quot;);
<span class="line-modified">!         tj = to = TypeInstPtr::make(TypePtr::BotPTR,to-&gt;klass(),false,0,offset);</span>
        }
      } else if( is_known_inst ) {
        tj = to; // Keep NotNull and klass_is_exact for instance type
      } else if( ptr == TypePtr::NotNull || to-&gt;klass_is_exact() ) {
        // During the 2nd round of IterGVN, NotNull castings are removed.
        // Make sure the Bottom and NotNull variants alias the same.
        // Also, make sure exact and non-exact variants alias the same.
<span class="line-modified">!       tj = to = TypeInstPtr::make(TypePtr::BotPTR,to-&gt;klass(),false,0,offset);</span>
      }
      if (to-&gt;speculative() != NULL) {
<span class="line-modified">!       tj = to = TypeInstPtr::make(to-&gt;ptr(),to-&gt;klass(),to-&gt;klass_is_exact(),to-&gt;const_oop(),to-&gt;offset(), to-&gt;instance_id());</span>
      }
      // Canonicalize the holder of this field
      if (offset &gt;= 0 &amp;&amp; offset &lt; instanceOopDesc::base_offset_in_bytes()) {
        // First handle header references such as a LoadKlassNode, even if the
        // object&#39;s klass is unloaded at compile time (4965979).
        if (!is_known_inst) { // Do it only for non-instance types
<span class="line-modified">!         tj = to = TypeInstPtr::make(TypePtr::BotPTR, env()-&gt;Object_klass(), false, NULL, offset);</span>
        }
      } else if (offset &lt; 0 || offset &gt;= k-&gt;size_helper() * wordSize) {
        // Static fields are in the space above the normal instance
        // fields in the java.lang.Class instance.
        if (to-&gt;klass() != ciEnv::current()-&gt;Class_klass()) {
<span class="line-new-header">--- 1340,29 ---</span>
        if (to-&gt;klass() != ciEnv::current()-&gt;Class_klass() ||
            offset &lt; k-&gt;size_helper() * wordSize) {
          // No constant oop pointers (such as Strings); they alias with
          // unknown strings.
          assert(!is_known_inst, &quot;not scalarizable allocation&quot;);
<span class="line-modified">!         tj = to = TypeInstPtr::make(TypePtr::BotPTR,to-&gt;klass(),false,0,Type::Offset(offset), to-&gt;klass()-&gt;flatten_array());</span>
        }
      } else if( is_known_inst ) {
        tj = to; // Keep NotNull and klass_is_exact for instance type
      } else if( ptr == TypePtr::NotNull || to-&gt;klass_is_exact() ) {
        // During the 2nd round of IterGVN, NotNull castings are removed.
        // Make sure the Bottom and NotNull variants alias the same.
        // Also, make sure exact and non-exact variants alias the same.
<span class="line-modified">!       tj = to = TypeInstPtr::make(TypePtr::BotPTR,to-&gt;klass(),false,0,Type::Offset(offset), to-&gt;klass()-&gt;flatten_array());</span>
      }
      if (to-&gt;speculative() != NULL) {
<span class="line-modified">!       tj = to = TypeInstPtr::make(to-&gt;ptr(),to-&gt;klass(),to-&gt;klass_is_exact(),to-&gt;const_oop(),Type::Offset(to-&gt;offset()), to-&gt;klass()-&gt;flatten_array(), to-&gt;instance_id());</span>
      }
      // Canonicalize the holder of this field
      if (offset &gt;= 0 &amp;&amp; offset &lt; instanceOopDesc::base_offset_in_bytes()) {
        // First handle header references such as a LoadKlassNode, even if the
        // object&#39;s klass is unloaded at compile time (4965979).
        if (!is_known_inst) { // Do it only for non-instance types
<span class="line-modified">!         tj = to = TypeInstPtr::make(TypePtr::BotPTR, env()-&gt;Object_klass(), false, NULL, Type::Offset(offset), false);</span>
        }
      } else if (offset &lt; 0 || offset &gt;= k-&gt;size_helper() * wordSize) {
        // Static fields are in the space above the normal instance
        // fields in the java.lang.Class instance.
        if (to-&gt;klass() != ciEnv::current()-&gt;Class_klass()) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1341,13 ***</span>
        }
      } else {
        ciInstanceKlass *canonical_holder = k-&gt;get_canonical_holder(offset);
        if (!k-&gt;equals(canonical_holder) || tj-&gt;offset() != offset) {
          if( is_known_inst ) {
<span class="line-modified">!           tj = to = TypeInstPtr::make(to-&gt;ptr(), canonical_holder, true, NULL, offset, to-&gt;instance_id());</span>
          } else {
<span class="line-modified">!           tj = to = TypeInstPtr::make(to-&gt;ptr(), canonical_holder, false, NULL, offset);</span>
          }
        }
      }
    }
  
<span class="line-new-header">--- 1372,13 ---</span>
        }
      } else {
        ciInstanceKlass *canonical_holder = k-&gt;get_canonical_holder(offset);
        if (!k-&gt;equals(canonical_holder) || tj-&gt;offset() != offset) {
          if( is_known_inst ) {
<span class="line-modified">!           tj = to = TypeInstPtr::make(to-&gt;ptr(), canonical_holder, true, NULL, Type::Offset(offset), canonical_holder-&gt;flatten_array(), to-&gt;instance_id());</span>
          } else {
<span class="line-modified">!           tj = to = TypeInstPtr::make(to-&gt;ptr(), canonical_holder, false, NULL, Type::Offset(offset), canonical_holder-&gt;flatten_array());</span>
          }
        }
      }
    }
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1360,19 ***</span>
      // use NotNull as the PTR.
      if ( offset == Type::OffsetBot || (offset &gt;= 0 &amp;&amp; (size_t)offset &lt; sizeof(Klass)) ) {
  
        tj = tk = TypeKlassPtr::make(TypePtr::NotNull,
                                     TypeKlassPtr::OBJECT-&gt;klass(),
<span class="line-modified">!                                    offset);</span>
      }
  
      ciKlass* klass = tk-&gt;klass();
<span class="line-modified">!     if( klass-&gt;is_obj_array_klass() ) {</span>
        ciKlass* k = TypeAryPtr::OOPS-&gt;klass();
        if( !k || !k-&gt;is_loaded() )                  // Only fails for some -Xcomp runs
          k = TypeInstPtr::BOTTOM-&gt;klass();
<span class="line-modified">!       tj = tk = TypeKlassPtr::make( TypePtr::NotNull, k, offset );</span>
      }
  
      // Check for precise loads from the primary supertype array and force them
      // to the supertype cache alias index.  Check for generic array loads from
      // the primary supertype array and also force them to the supertype cache
<span class="line-new-header">--- 1391,20 ---</span>
      // use NotNull as the PTR.
      if ( offset == Type::OffsetBot || (offset &gt;= 0 &amp;&amp; (size_t)offset &lt; sizeof(Klass)) ) {
  
        tj = tk = TypeKlassPtr::make(TypePtr::NotNull,
                                     TypeKlassPtr::OBJECT-&gt;klass(),
<span class="line-modified">!                                    Type::Offset(offset),</span>
<span class="line-added">+                                    false);</span>
      }
  
      ciKlass* klass = tk-&gt;klass();
<span class="line-modified">!     if (klass != NULL &amp;&amp; klass-&gt;is_obj_array_klass()) {</span>
        ciKlass* k = TypeAryPtr::OOPS-&gt;klass();
        if( !k || !k-&gt;is_loaded() )                  // Only fails for some -Xcomp runs
          k = TypeInstPtr::BOTTOM-&gt;klass();
<span class="line-modified">!       tj = tk = TypeKlassPtr::make(TypePtr::NotNull, k, Type::Offset(offset), false);</span>
      }
  
      // Check for precise loads from the primary supertype array and force them
      // to the supertype cache alias index.  Check for generic array loads from
      // the primary supertype array and also force them to the supertype cache
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1384,11 ***</span>
      if (offset == Type::OffsetBot ||
          (offset &gt;= primary_supers_offset &amp;&amp;
           offset &lt; (int)(primary_supers_offset + Klass::primary_super_limit() * wordSize)) ||
          offset == (int)in_bytes(Klass::secondary_super_cache_offset())) {
        offset = in_bytes(Klass::secondary_super_cache_offset());
<span class="line-modified">!       tj = tk = TypeKlassPtr::make( TypePtr::NotNull, tk-&gt;klass(), offset );</span>
      }
    }
  
    // Flatten all Raw pointers together.
    if (tj-&gt;base() == Type::RawPtr)
<span class="line-new-header">--- 1416,11 ---</span>
      if (offset == Type::OffsetBot ||
          (offset &gt;= primary_supers_offset &amp;&amp;
           offset &lt; (int)(primary_supers_offset + Klass::primary_super_limit() * wordSize)) ||
          offset == (int)in_bytes(Klass::secondary_super_cache_offset())) {
        offset = in_bytes(Klass::secondary_super_cache_offset());
<span class="line-modified">!       tj = tk = TypeKlassPtr::make(TypePtr::NotNull, tk-&gt;klass(), Type::Offset(offset), tk-&gt;flat_array());</span>
      }
    }
  
    // Flatten all Raw pointers together.
    if (tj-&gt;base() == Type::RawPtr)
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1523,17 ***</span>
    for (int i = 0; i &lt; new_ats; i++)  _alias_types[old_ats+i] = &amp;ats[i];
  }
  
  
  //--------------------------------find_alias_type------------------------------
<span class="line-modified">! Compile::AliasType* Compile::find_alias_type(const TypePtr* adr_type, bool no_create, ciField* original_field) {</span>
    if (_AliasLevel == 0)
      return alias_type(AliasIdxBot);
  
<span class="line-modified">!   AliasCacheEntry* ace = probe_alias_cache(adr_type);</span>
<span class="line-modified">!   if (ace-&gt;_adr_type == adr_type) {</span>
<span class="line-modified">!     return alias_type(ace-&gt;_index);</span>
    }
  
    // Handle special cases.
    if (adr_type == NULL)             return alias_type(AliasIdxTop);
    if (adr_type == TypePtr::BOTTOM)  return alias_type(AliasIdxBot);
<span class="line-new-header">--- 1555,20 ---</span>
    for (int i = 0; i &lt; new_ats; i++)  _alias_types[old_ats+i] = &amp;ats[i];
  }
  
  
  //--------------------------------find_alias_type------------------------------
<span class="line-modified">! Compile::AliasType* Compile::find_alias_type(const TypePtr* adr_type, bool no_create, ciField* original_field, bool uncached) {</span>
    if (_AliasLevel == 0)
      return alias_type(AliasIdxBot);
  
<span class="line-modified">!   AliasCacheEntry* ace = NULL;</span>
<span class="line-modified">!   if (!uncached) {</span>
<span class="line-modified">!     ace = probe_alias_cache(adr_type);</span>
<span class="line-added">+     if (ace-&gt;_adr_type == adr_type) {</span>
<span class="line-added">+       return alias_type(ace-&gt;_index);</span>
<span class="line-added">+     }</span>
    }
  
    // Handle special cases.
    if (adr_type == NULL)             return alias_type(AliasIdxTop);
    if (adr_type == TypePtr::BOTTOM)  return alias_type(AliasIdxBot);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1579,18 ***</span>
      if (flat-&gt;isa_instptr()) {
        if (flat-&gt;offset() == java_lang_Class::klass_offset()
            &amp;&amp; flat-&gt;is_instptr()-&gt;klass() == env()-&gt;Class_klass())
          alias_type(idx)-&gt;set_rewritable(false);
      }
      if (flat-&gt;isa_aryptr()) {
  #ifdef ASSERT
        const int header_size_min  = arrayOopDesc::base_offset_in_bytes(T_BYTE);
        // (T_BYTE has the weakest alignment and size restrictions...)
        assert(flat-&gt;offset() &lt; header_size_min, &quot;array body reference must be OffsetBot&quot;);
  #endif
        if (flat-&gt;offset() == TypePtr::OffsetBot) {
<span class="line-modified">!         alias_type(idx)-&gt;set_element(flat-&gt;is_aryptr()-&gt;elem());</span>
        }
      }
      if (flat-&gt;isa_klassptr()) {
        if (flat-&gt;offset() == in_bytes(Klass::super_check_offset_offset()))
          alias_type(idx)-&gt;set_rewritable(false);
<span class="line-new-header">--- 1614,28 ---</span>
      if (flat-&gt;isa_instptr()) {
        if (flat-&gt;offset() == java_lang_Class::klass_offset()
            &amp;&amp; flat-&gt;is_instptr()-&gt;klass() == env()-&gt;Class_klass())
          alias_type(idx)-&gt;set_rewritable(false);
      }
<span class="line-added">+     ciField* field = NULL;</span>
      if (flat-&gt;isa_aryptr()) {
  #ifdef ASSERT
        const int header_size_min  = arrayOopDesc::base_offset_in_bytes(T_BYTE);
        // (T_BYTE has the weakest alignment and size restrictions...)
        assert(flat-&gt;offset() &lt; header_size_min, &quot;array body reference must be OffsetBot&quot;);
  #endif
<span class="line-added">+       const Type* elemtype = flat-&gt;is_aryptr()-&gt;elem();</span>
        if (flat-&gt;offset() == TypePtr::OffsetBot) {
<span class="line-modified">!         alias_type(idx)-&gt;set_element(elemtype);</span>
<span class="line-added">+       }</span>
<span class="line-added">+       int field_offset = flat-&gt;is_aryptr()-&gt;field_offset().get();</span>
<span class="line-added">+       if (elemtype-&gt;isa_inlinetype() &amp;&amp;</span>
<span class="line-added">+           elemtype-&gt;inline_klass() != NULL &amp;&amp;</span>
<span class="line-added">+           field_offset != Type::OffsetBot) {</span>
<span class="line-added">+         ciInlineKlass* vk = elemtype-&gt;inline_klass();</span>
<span class="line-added">+         field_offset += vk-&gt;first_field_offset();</span>
<span class="line-added">+         field = vk-&gt;get_field_by_offset(field_offset, false);</span>
        }
      }
      if (flat-&gt;isa_klassptr()) {
        if (flat-&gt;offset() == in_bytes(Klass::super_check_offset_offset()))
          alias_type(idx)-&gt;set_rewritable(false);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1598,52 ***</span>
          alias_type(idx)-&gt;set_rewritable(false);
        if (flat-&gt;offset() == in_bytes(Klass::access_flags_offset()))
          alias_type(idx)-&gt;set_rewritable(false);
        if (flat-&gt;offset() == in_bytes(Klass::java_mirror_offset()))
          alias_type(idx)-&gt;set_rewritable(false);
        if (flat-&gt;offset() == in_bytes(Klass::secondary_super_cache_offset()))
          alias_type(idx)-&gt;set_rewritable(false);
      }
      // %%% (We would like to finalize JavaThread::threadObj_offset(),
      // but the base pointer type is not distinctive enough to identify
      // references into JavaThread.)
  
      // Check for final fields.
      const TypeInstPtr* tinst = flat-&gt;isa_instptr();
      if (tinst &amp;&amp; tinst-&gt;offset() &gt;= instanceOopDesc::base_offset_in_bytes()) {
<span class="line-removed">-       ciField* field;</span>
        if (tinst-&gt;const_oop() != NULL &amp;&amp;
            tinst-&gt;klass() == ciEnv::current()-&gt;Class_klass() &amp;&amp;
            tinst-&gt;offset() &gt;= (tinst-&gt;klass()-&gt;as_instance_klass()-&gt;size_helper() * wordSize)) {
          // static field
          ciInstanceKlass* k = tinst-&gt;const_oop()-&gt;as_instance()-&gt;java_lang_Class_klass()-&gt;as_instance_klass();
          field = k-&gt;get_field_by_offset(tinst-&gt;offset(), true);
        } else {
<span class="line-modified">!         ciInstanceKlass *k = tinst-&gt;klass()-&gt;as_instance_klass();</span>
          field = k-&gt;get_field_by_offset(tinst-&gt;offset(), false);
        }
<span class="line-modified">!       assert(field == NULL ||</span>
<span class="line-modified">!              original_field == NULL ||</span>
<span class="line-modified">!              (field-&gt;holder() == original_field-&gt;holder() &amp;&amp;</span>
<span class="line-modified">!               field-&gt;offset() == original_field-&gt;offset() &amp;&amp;</span>
<span class="line-modified">!               field-&gt;is_static() == original_field-&gt;is_static()), &quot;wrong field?&quot;);</span>
<span class="line-modified">!       // Set field() and is_rewritable() attributes.</span>
<span class="line-modified">!       if (field != NULL)  alias_type(idx)-&gt;set_field(field);</span>
      }
    }
  
    // Fill the cache for next time.
<span class="line-modified">!   ace-&gt;_adr_type = adr_type;</span>
<span class="line-modified">!   ace-&gt;_index    = idx;</span>
<span class="line-modified">!   assert(alias_type(adr_type) == alias_type(idx),  &quot;type must be installed&quot;);</span>
  
<span class="line-modified">!   // Might as well try to fill the cache for the flattened version, too.</span>
<span class="line-modified">!   AliasCacheEntry* face = probe_alias_cache(flat);</span>
<span class="line-modified">!   if (face-&gt;_adr_type == NULL) {</span>
<span class="line-modified">!     face-&gt;_adr_type = flat;</span>
<span class="line-modified">!     face-&gt;_index    = idx;</span>
<span class="line-modified">!     assert(alias_type(flat) == alias_type(idx), &quot;flat type must work too&quot;);</span>
    }
  
    return alias_type(idx);
  }
  
<span class="line-new-header">--- 1643,66 ---</span>
          alias_type(idx)-&gt;set_rewritable(false);
        if (flat-&gt;offset() == in_bytes(Klass::access_flags_offset()))
          alias_type(idx)-&gt;set_rewritable(false);
        if (flat-&gt;offset() == in_bytes(Klass::java_mirror_offset()))
          alias_type(idx)-&gt;set_rewritable(false);
<span class="line-added">+       if (flat-&gt;offset() == in_bytes(Klass::layout_helper_offset()))</span>
<span class="line-added">+         alias_type(idx)-&gt;set_rewritable(false);</span>
        if (flat-&gt;offset() == in_bytes(Klass::secondary_super_cache_offset()))
          alias_type(idx)-&gt;set_rewritable(false);
      }
      // %%% (We would like to finalize JavaThread::threadObj_offset(),
      // but the base pointer type is not distinctive enough to identify
      // references into JavaThread.)
  
      // Check for final fields.
      const TypeInstPtr* tinst = flat-&gt;isa_instptr();
      if (tinst &amp;&amp; tinst-&gt;offset() &gt;= instanceOopDesc::base_offset_in_bytes()) {
        if (tinst-&gt;const_oop() != NULL &amp;&amp;
            tinst-&gt;klass() == ciEnv::current()-&gt;Class_klass() &amp;&amp;
            tinst-&gt;offset() &gt;= (tinst-&gt;klass()-&gt;as_instance_klass()-&gt;size_helper() * wordSize)) {
          // static field
          ciInstanceKlass* k = tinst-&gt;const_oop()-&gt;as_instance()-&gt;java_lang_Class_klass()-&gt;as_instance_klass();
          field = k-&gt;get_field_by_offset(tinst-&gt;offset(), true);
<span class="line-added">+       } else if (tinst-&gt;klass()-&gt;is_inlinetype()) {</span>
<span class="line-added">+         // Inline type field</span>
<span class="line-added">+         ciInlineKlass* vk = tinst-&gt;inline_klass();</span>
<span class="line-added">+         field = vk-&gt;get_field_by_offset(tinst-&gt;offset(), false);</span>
        } else {
<span class="line-modified">!         ciInstanceKlass* k = tinst-&gt;klass()-&gt;as_instance_klass();</span>
          field = k-&gt;get_field_by_offset(tinst-&gt;offset(), false);
        }
<span class="line-modified">!     }</span>
<span class="line-modified">!     assert(field == NULL ||</span>
<span class="line-modified">!            original_field == NULL ||</span>
<span class="line-modified">!            (field-&gt;holder() == original_field-&gt;holder() &amp;&amp;</span>
<span class="line-modified">!             field-&gt;offset() == original_field-&gt;offset() &amp;&amp;</span>
<span class="line-modified">!             field-&gt;is_static() == original_field-&gt;is_static()), &quot;wrong field?&quot;);</span>
<span class="line-modified">!     // Set field() and is_rewritable() attributes.</span>
<span class="line-added">+     if (field != NULL) {</span>
<span class="line-added">+       alias_type(idx)-&gt;set_field(field);</span>
<span class="line-added">+       if (flat-&gt;isa_aryptr()) {</span>
<span class="line-added">+         // Fields of flat arrays are rewritable although they are declared final</span>
<span class="line-added">+         assert(flat-&gt;is_aryptr()-&gt;elem()-&gt;isa_inlinetype(), &quot;must be a flat array&quot;);</span>
<span class="line-added">+         alias_type(idx)-&gt;set_rewritable(true);</span>
<span class="line-added">+       }</span>
      }
    }
  
    // Fill the cache for next time.
<span class="line-modified">!   if (!uncached) {</span>
<span class="line-modified">!     ace-&gt;_adr_type = adr_type;</span>
<span class="line-modified">!     ace-&gt;_index    = idx;</span>
<span class="line-added">+     assert(alias_type(adr_type) == alias_type(idx),  &quot;type must be installed&quot;);</span>
  
<span class="line-modified">!     // Might as well try to fill the cache for the flattened version, too.</span>
<span class="line-modified">!     AliasCacheEntry* face = probe_alias_cache(flat);</span>
<span class="line-modified">!     if (face-&gt;_adr_type == NULL) {</span>
<span class="line-modified">!       face-&gt;_adr_type = flat;</span>
<span class="line-modified">!       face-&gt;_index    = idx;</span>
<span class="line-modified">!       assert(alias_type(flat) == alias_type(idx), &quot;flat type must work too&quot;);</span>
<span class="line-added">+     }</span>
    }
  
    return alias_type(idx);
  }
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1801,10 ***</span>
<span class="line-new-header">--- 1860,358 ---</span>
      igvn.replace_node(opaq, opaq-&gt;in(2));
    }
    assert(opaque4_count() == 0, &quot;should be empty&quot;);
  }
  
<span class="line-added">+ void Compile::add_inline_type(Node* n) {</span>
<span class="line-added">+   assert(n-&gt;is_InlineTypeBase(), &quot;unexpected node&quot;);</span>
<span class="line-added">+   if (_inline_type_nodes != NULL) {</span>
<span class="line-added">+     _inline_type_nodes-&gt;push(n);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ void Compile::remove_inline_type(Node* n) {</span>
<span class="line-added">+   assert(n-&gt;is_InlineTypeBase(), &quot;unexpected node&quot;);</span>
<span class="line-added">+   if (_inline_type_nodes != NULL &amp;&amp; _inline_type_nodes-&gt;contains(n)) {</span>
<span class="line-added">+     _inline_type_nodes-&gt;remove(n);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ // Does the return value keep otherwise useless inline type allocations alive?</span>
<span class="line-added">+ static bool return_val_keeps_allocations_alive(Node* ret_val) {</span>
<span class="line-added">+   ResourceMark rm;</span>
<span class="line-added">+   Unique_Node_List wq;</span>
<span class="line-added">+   wq.push(ret_val);</span>
<span class="line-added">+   bool some_allocations = false;</span>
<span class="line-added">+   for (uint i = 0; i &lt; wq.size(); i++) {</span>
<span class="line-added">+     Node* n = wq.at(i);</span>
<span class="line-added">+     assert(!n-&gt;is_InlineType(), &quot;chain of inline type nodes&quot;);</span>
<span class="line-added">+     if (n-&gt;outcnt() &gt; 1) {</span>
<span class="line-added">+       // Some other use for the allocation</span>
<span class="line-added">+       return false;</span>
<span class="line-added">+     } else if (n-&gt;is_InlineTypePtr()) {</span>
<span class="line-added">+       wq.push(n-&gt;in(1));</span>
<span class="line-added">+     } else if (n-&gt;is_Phi()) {</span>
<span class="line-added">+       for (uint j = 1; j &lt; n-&gt;req(); j++) {</span>
<span class="line-added">+         wq.push(n-&gt;in(j));</span>
<span class="line-added">+       }</span>
<span class="line-added">+     } else if (n-&gt;is_CheckCastPP() &amp;&amp;</span>
<span class="line-added">+                n-&gt;in(1)-&gt;is_Proj() &amp;&amp;</span>
<span class="line-added">+                n-&gt;in(1)-&gt;in(0)-&gt;is_Allocate()) {</span>
<span class="line-added">+       some_allocations = true;</span>
<span class="line-added">+     }</span>
<span class="line-added">+   }</span>
<span class="line-added">+   return some_allocations;</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ void Compile::process_inline_types(PhaseIterGVN &amp;igvn, bool post_ea) {</span>
<span class="line-added">+   // Make inline types scalar in safepoints</span>
<span class="line-added">+   for (int i = _inline_type_nodes-&gt;length()-1; i &gt;= 0; i--) {</span>
<span class="line-added">+     InlineTypeBaseNode* vt = _inline_type_nodes-&gt;at(i)-&gt;as_InlineTypeBase();</span>
<span class="line-added">+     vt-&gt;make_scalar_in_safepoints(&amp;igvn);</span>
<span class="line-added">+   }</span>
<span class="line-added">+   // Remove InlineTypePtr nodes only after EA to give scalar replacement a chance</span>
<span class="line-added">+   // to remove buffer allocations. InlineType nodes are kept until loop opts and</span>
<span class="line-added">+   // removed via InlineTypeNode::remove_redundant_allocations.</span>
<span class="line-added">+   if (post_ea) {</span>
<span class="line-added">+     while (_inline_type_nodes-&gt;length() &gt; 0) {</span>
<span class="line-added">+       InlineTypeBaseNode* vt = _inline_type_nodes-&gt;pop()-&gt;as_InlineTypeBase();</span>
<span class="line-added">+       if (vt-&gt;is_InlineTypePtr()) {</span>
<span class="line-added">+         igvn.replace_node(vt, vt-&gt;get_oop());</span>
<span class="line-added">+       }</span>
<span class="line-added">+     }</span>
<span class="line-added">+   }</span>
<span class="line-added">+   // Make sure that the return value does not keep an unused allocation alive</span>
<span class="line-added">+   if (tf()-&gt;returns_inline_type_as_fields()) {</span>
<span class="line-added">+     Node* ret = NULL;</span>
<span class="line-added">+     for (uint i = 1; i &lt; root()-&gt;req(); i++){</span>
<span class="line-added">+       Node* in = root()-&gt;in(i);</span>
<span class="line-added">+       if (in-&gt;Opcode() == Op_Return) {</span>
<span class="line-added">+         assert(ret == NULL, &quot;only one return&quot;);</span>
<span class="line-added">+         ret = in;</span>
<span class="line-added">+       }</span>
<span class="line-added">+     }</span>
<span class="line-added">+     if (ret != NULL) {</span>
<span class="line-added">+       Node* ret_val = ret-&gt;in(TypeFunc::Parms);</span>
<span class="line-added">+       if (igvn.type(ret_val)-&gt;isa_oopptr() &amp;&amp;</span>
<span class="line-added">+           return_val_keeps_allocations_alive(ret_val)) {</span>
<span class="line-added">+         igvn.replace_input_of(ret, TypeFunc::Parms, InlineTypeNode::tagged_klass(igvn.type(ret_val)-&gt;inline_klass(), igvn));</span>
<span class="line-added">+         assert(ret_val-&gt;outcnt() == 0, &quot;should be dead now&quot;);</span>
<span class="line-added">+         igvn.remove_dead_node(ret_val);</span>
<span class="line-added">+       }</span>
<span class="line-added">+     }</span>
<span class="line-added">+   }</span>
<span class="line-added">+   igvn.optimize();</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ void Compile::adjust_flattened_array_access_aliases(PhaseIterGVN&amp; igvn) {</span>
<span class="line-added">+   if (!_has_flattened_accesses) {</span>
<span class="line-added">+     return;</span>
<span class="line-added">+   }</span>
<span class="line-added">+   // Initially, all flattened array accesses share the same slice to</span>
<span class="line-added">+   // keep dependencies with Object[] array accesses (that could be</span>
<span class="line-added">+   // to a flattened array) correct. We&#39;re done with parsing so we</span>
<span class="line-added">+   // now know all flattened array accesses in this compile</span>
<span class="line-added">+   // unit. Let&#39;s move flattened array accesses to their own slice,</span>
<span class="line-added">+   // one per element field. This should help memory access</span>
<span class="line-added">+   // optimizations.</span>
<span class="line-added">+   ResourceMark rm;</span>
<span class="line-added">+   Unique_Node_List wq;</span>
<span class="line-added">+   wq.push(root());</span>
<span class="line-added">+ </span>
<span class="line-added">+   Node_List mergememnodes;</span>
<span class="line-added">+   Node_List memnodes;</span>
<span class="line-added">+ </span>
<span class="line-added">+   // Alias index currently shared by all flattened memory accesses</span>
<span class="line-added">+   int index = get_alias_index(TypeAryPtr::INLINES);</span>
<span class="line-added">+ </span>
<span class="line-added">+   // Find MergeMem nodes and flattened array accesses</span>
<span class="line-added">+   for (uint i = 0; i &lt; wq.size(); i++) {</span>
<span class="line-added">+     Node* n = wq.at(i);</span>
<span class="line-added">+     if (n-&gt;is_Mem()) {</span>
<span class="line-added">+       const TypePtr* adr_type = NULL;</span>
<span class="line-added">+       if (n-&gt;Opcode() == Op_StoreCM) {</span>
<span class="line-added">+         adr_type = get_adr_type(get_alias_index(n-&gt;in(MemNode::OopStore)-&gt;adr_type()));</span>
<span class="line-added">+       } else {</span>
<span class="line-added">+         adr_type = get_adr_type(get_alias_index(n-&gt;adr_type()));</span>
<span class="line-added">+       }</span>
<span class="line-added">+       if (adr_type == TypeAryPtr::INLINES) {</span>
<span class="line-added">+         memnodes.push(n);</span>
<span class="line-added">+       }</span>
<span class="line-added">+     } else if (n-&gt;is_MergeMem()) {</span>
<span class="line-added">+       MergeMemNode* mm = n-&gt;as_MergeMem();</span>
<span class="line-added">+       if (mm-&gt;memory_at(index) != mm-&gt;base_memory()) {</span>
<span class="line-added">+         mergememnodes.push(n);</span>
<span class="line-added">+       }</span>
<span class="line-added">+     }</span>
<span class="line-added">+     for (uint j = 0; j &lt; n-&gt;req(); j++) {</span>
<span class="line-added">+       Node* m = n-&gt;in(j);</span>
<span class="line-added">+       if (m != NULL) {</span>
<span class="line-added">+         wq.push(m);</span>
<span class="line-added">+       }</span>
<span class="line-added">+     }</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   if (memnodes.size() &gt; 0) {</span>
<span class="line-added">+     _flattened_accesses_share_alias = false;</span>
<span class="line-added">+ </span>
<span class="line-added">+     // We are going to change the slice for the flattened array</span>
<span class="line-added">+     // accesses so we need to clear the cache entries that refer to</span>
<span class="line-added">+     // them.</span>
<span class="line-added">+     for (uint i = 0; i &lt; AliasCacheSize; i++) {</span>
<span class="line-added">+       AliasCacheEntry* ace = &amp;_alias_cache[i];</span>
<span class="line-added">+       if (ace-&gt;_adr_type != NULL &amp;&amp;</span>
<span class="line-added">+           ace-&gt;_adr_type-&gt;isa_aryptr() &amp;&amp;</span>
<span class="line-added">+           ace-&gt;_adr_type-&gt;is_aryptr()-&gt;elem()-&gt;isa_inlinetype()) {</span>
<span class="line-added">+         ace-&gt;_adr_type = NULL;</span>
<span class="line-added">+         ace-&gt;_index = (i != 0) ? 0 : AliasIdxTop; // Make sure the NULL adr_type resolves to AliasIdxTop</span>
<span class="line-added">+       }</span>
<span class="line-added">+     }</span>
<span class="line-added">+ </span>
<span class="line-added">+     // Find what aliases we are going to add</span>
<span class="line-added">+     int start_alias = num_alias_types()-1;</span>
<span class="line-added">+     int stop_alias = 0;</span>
<span class="line-added">+ </span>
<span class="line-added">+     for (uint i = 0; i &lt; memnodes.size(); i++) {</span>
<span class="line-added">+       Node* m = memnodes.at(i);</span>
<span class="line-added">+       const TypePtr* adr_type = NULL;</span>
<span class="line-added">+       if (m-&gt;Opcode() == Op_StoreCM) {</span>
<span class="line-added">+         adr_type = m-&gt;in(MemNode::OopStore)-&gt;adr_type();</span>
<span class="line-added">+         Node* clone = new StoreCMNode(m-&gt;in(MemNode::Control), m-&gt;in(MemNode::Memory), m-&gt;in(MemNode::Address),</span>
<span class="line-added">+                                       m-&gt;adr_type(), m-&gt;in(MemNode::ValueIn), m-&gt;in(MemNode::OopStore),</span>
<span class="line-added">+                                       get_alias_index(adr_type));</span>
<span class="line-added">+         igvn.register_new_node_with_optimizer(clone);</span>
<span class="line-added">+         igvn.replace_node(m, clone);</span>
<span class="line-added">+       } else {</span>
<span class="line-added">+         adr_type = m-&gt;adr_type();</span>
<span class="line-added">+ #ifdef ASSERT</span>
<span class="line-added">+         m-&gt;as_Mem()-&gt;set_adr_type(adr_type);</span>
<span class="line-added">+ #endif</span>
<span class="line-added">+       }</span>
<span class="line-added">+       int idx = get_alias_index(adr_type);</span>
<span class="line-added">+       start_alias = MIN2(start_alias, idx);</span>
<span class="line-added">+       stop_alias = MAX2(stop_alias, idx);</span>
<span class="line-added">+     }</span>
<span class="line-added">+ </span>
<span class="line-added">+     assert(stop_alias &gt;= start_alias, &quot;should have expanded aliases&quot;);</span>
<span class="line-added">+ </span>
<span class="line-added">+     Node_Stack stack(0);</span>
<span class="line-added">+ #ifdef ASSERT</span>
<span class="line-added">+     VectorSet seen(Thread::current()-&gt;resource_area());</span>
<span class="line-added">+ #endif</span>
<span class="line-added">+     // Now let&#39;s fix the memory graph so each flattened array access</span>
<span class="line-added">+     // is moved to the right slice. Start from the MergeMem nodes.</span>
<span class="line-added">+     uint last = unique();</span>
<span class="line-added">+     for (uint i = 0; i &lt; mergememnodes.size(); i++) {</span>
<span class="line-added">+       MergeMemNode* current = mergememnodes.at(i)-&gt;as_MergeMem();</span>
<span class="line-added">+       Node* n = current-&gt;memory_at(index);</span>
<span class="line-added">+       MergeMemNode* mm = NULL;</span>
<span class="line-added">+       do {</span>
<span class="line-added">+         // Follow memory edges through memory accesses, phis and</span>
<span class="line-added">+         // narrow membars and push nodes on the stack. Once we hit</span>
<span class="line-added">+         // bottom memory, we pop element off the stack one at a</span>
<span class="line-added">+         // time, in reverse order, and move them to the right slice</span>
<span class="line-added">+         // by changing their memory edges.</span>
<span class="line-added">+         if ((n-&gt;is_Phi() &amp;&amp; n-&gt;adr_type() != TypePtr::BOTTOM) || n-&gt;is_Mem() || n-&gt;adr_type() == TypeAryPtr::INLINES) {</span>
<span class="line-added">+           assert(!seen.test_set(n-&gt;_idx), &quot;&quot;);</span>
<span class="line-added">+           // Uses (a load for instance) will need to be moved to the</span>
<span class="line-added">+           // right slice as well and will get a new memory state</span>
<span class="line-added">+           // that we don&#39;t know yet. The use could also be the</span>
<span class="line-added">+           // backedge of a loop. We put a place holder node between</span>
<span class="line-added">+           // the memory node and its uses. We replace that place</span>
<span class="line-added">+           // holder with the correct memory state once we know it,</span>
<span class="line-added">+           // i.e. when nodes are popped off the stack. Using the</span>
<span class="line-added">+           // place holder make the logic work in the presence of</span>
<span class="line-added">+           // loops.</span>
<span class="line-added">+           if (n-&gt;outcnt() &gt; 1) {</span>
<span class="line-added">+             Node* place_holder = NULL;</span>
<span class="line-added">+             assert(!n-&gt;has_out_with(Op_Node), &quot;&quot;);</span>
<span class="line-added">+             for (DUIterator k = n-&gt;outs(); n-&gt;has_out(k); k++) {</span>
<span class="line-added">+               Node* u = n-&gt;out(k);</span>
<span class="line-added">+               if (u != current &amp;&amp; u-&gt;_idx &lt; last) {</span>
<span class="line-added">+                 bool success = false;</span>
<span class="line-added">+                 for (uint l = 0; l &lt; u-&gt;req(); l++) {</span>
<span class="line-added">+                   if (!stack.is_empty() &amp;&amp; u == stack.node() &amp;&amp; l == stack.index()) {</span>
<span class="line-added">+                     continue;</span>
<span class="line-added">+                   }</span>
<span class="line-added">+                   Node* in = u-&gt;in(l);</span>
<span class="line-added">+                   if (in == n) {</span>
<span class="line-added">+                     if (place_holder == NULL) {</span>
<span class="line-added">+                       place_holder = new Node(1);</span>
<span class="line-added">+                       place_holder-&gt;init_req(0, n);</span>
<span class="line-added">+                     }</span>
<span class="line-added">+                     igvn.replace_input_of(u, l, place_holder);</span>
<span class="line-added">+                     success = true;</span>
<span class="line-added">+                   }</span>
<span class="line-added">+                 }</span>
<span class="line-added">+                 if (success) {</span>
<span class="line-added">+                   --k;</span>
<span class="line-added">+                 }</span>
<span class="line-added">+               }</span>
<span class="line-added">+             }</span>
<span class="line-added">+           }</span>
<span class="line-added">+           if (n-&gt;is_Phi()) {</span>
<span class="line-added">+             stack.push(n, 1);</span>
<span class="line-added">+             n = n-&gt;in(1);</span>
<span class="line-added">+           } else if (n-&gt;is_Mem()) {</span>
<span class="line-added">+             stack.push(n, n-&gt;req());</span>
<span class="line-added">+             n = n-&gt;in(MemNode::Memory);</span>
<span class="line-added">+           } else {</span>
<span class="line-added">+             assert(n-&gt;is_Proj() &amp;&amp; n-&gt;in(0)-&gt;Opcode() == Op_MemBarCPUOrder, &quot;&quot;);</span>
<span class="line-added">+             stack.push(n, n-&gt;req());</span>
<span class="line-added">+             n = n-&gt;in(0)-&gt;in(TypeFunc::Memory);</span>
<span class="line-added">+           }</span>
<span class="line-added">+         } else {</span>
<span class="line-added">+           assert(n-&gt;adr_type() == TypePtr::BOTTOM || (n-&gt;Opcode() == Op_Node &amp;&amp; n-&gt;_idx &gt;= last) || (n-&gt;is_Proj() &amp;&amp; n-&gt;in(0)-&gt;is_Initialize()), &quot;&quot;);</span>
<span class="line-added">+           // Build a new MergeMem node to carry the new memory state</span>
<span class="line-added">+           // as we build it. IGVN should fold extraneous MergeMem</span>
<span class="line-added">+           // nodes.</span>
<span class="line-added">+           mm = MergeMemNode::make(n);</span>
<span class="line-added">+           igvn.register_new_node_with_optimizer(mm);</span>
<span class="line-added">+           while (stack.size() &gt; 0) {</span>
<span class="line-added">+             Node* m = stack.node();</span>
<span class="line-added">+             uint idx = stack.index();</span>
<span class="line-added">+             if (m-&gt;is_Mem()) {</span>
<span class="line-added">+               // Move memory node to its new slice</span>
<span class="line-added">+               const TypePtr* adr_type = m-&gt;adr_type();</span>
<span class="line-added">+               int alias = get_alias_index(adr_type);</span>
<span class="line-added">+               Node* prev = mm-&gt;memory_at(alias);</span>
<span class="line-added">+               igvn.replace_input_of(m, MemNode::Memory, prev);</span>
<span class="line-added">+               mm-&gt;set_memory_at(alias, m);</span>
<span class="line-added">+             } else if (m-&gt;is_Phi()) {</span>
<span class="line-added">+               // We need as many new phis as there are new aliases</span>
<span class="line-added">+               igvn.replace_input_of(m, idx, mm);</span>
<span class="line-added">+               if (idx == m-&gt;req()-1) {</span>
<span class="line-added">+                 Node* r = m-&gt;in(0);</span>
<span class="line-added">+                 for (uint j = (uint)start_alias; j &lt;= (uint)stop_alias; j++) {</span>
<span class="line-added">+                   const Type* adr_type = get_adr_type(j);</span>
<span class="line-added">+                   if (!adr_type-&gt;isa_aryptr() || !adr_type-&gt;is_aryptr()-&gt;elem()-&gt;isa_inlinetype()) {</span>
<span class="line-added">+                     continue;</span>
<span class="line-added">+                   }</span>
<span class="line-added">+                   Node* phi = new PhiNode(r, Type::MEMORY, get_adr_type(j));</span>
<span class="line-added">+                   igvn.register_new_node_with_optimizer(phi);</span>
<span class="line-added">+                   for (uint k = 1; k &lt; m-&gt;req(); k++) {</span>
<span class="line-added">+                     phi-&gt;init_req(k, m-&gt;in(k)-&gt;as_MergeMem()-&gt;memory_at(j));</span>
<span class="line-added">+                   }</span>
<span class="line-added">+                   mm-&gt;set_memory_at(j, phi);</span>
<span class="line-added">+                 }</span>
<span class="line-added">+                 Node* base_phi = new PhiNode(r, Type::MEMORY, TypePtr::BOTTOM);</span>
<span class="line-added">+                 igvn.register_new_node_with_optimizer(base_phi);</span>
<span class="line-added">+                 for (uint k = 1; k &lt; m-&gt;req(); k++) {</span>
<span class="line-added">+                   base_phi-&gt;init_req(k, m-&gt;in(k)-&gt;as_MergeMem()-&gt;base_memory());</span>
<span class="line-added">+                 }</span>
<span class="line-added">+                 mm-&gt;set_base_memory(base_phi);</span>
<span class="line-added">+               }</span>
<span class="line-added">+             } else {</span>
<span class="line-added">+               // This is a MemBarCPUOrder node from</span>
<span class="line-added">+               // Parse::array_load()/Parse::array_store(), in the</span>
<span class="line-added">+               // branch that handles flattened arrays hidden under</span>
<span class="line-added">+               // an Object[] array. We also need one new membar per</span>
<span class="line-added">+               // new alias to keep the unknown access that the</span>
<span class="line-added">+               // membars protect properly ordered with accesses to</span>
<span class="line-added">+               // known flattened array.</span>
<span class="line-added">+               assert(m-&gt;is_Proj(), &quot;projection expected&quot;);</span>
<span class="line-added">+               Node* ctrl = m-&gt;in(0)-&gt;in(TypeFunc::Control);</span>
<span class="line-added">+               igvn.replace_input_of(m-&gt;in(0), TypeFunc::Control, top());</span>
<span class="line-added">+               for (uint j = (uint)start_alias; j &lt;= (uint)stop_alias; j++) {</span>
<span class="line-added">+                 const Type* adr_type = get_adr_type(j);</span>
<span class="line-added">+                 if (!adr_type-&gt;isa_aryptr() || !adr_type-&gt;is_aryptr()-&gt;elem()-&gt;isa_inlinetype()) {</span>
<span class="line-added">+                   continue;</span>
<span class="line-added">+                 }</span>
<span class="line-added">+                 MemBarNode* mb = new MemBarCPUOrderNode(this, j, NULL);</span>
<span class="line-added">+                 igvn.register_new_node_with_optimizer(mb);</span>
<span class="line-added">+                 Node* mem = mm-&gt;memory_at(j);</span>
<span class="line-added">+                 mb-&gt;init_req(TypeFunc::Control, ctrl);</span>
<span class="line-added">+                 mb-&gt;init_req(TypeFunc::Memory, mem);</span>
<span class="line-added">+                 ctrl = new ProjNode(mb, TypeFunc::Control);</span>
<span class="line-added">+                 igvn.register_new_node_with_optimizer(ctrl);</span>
<span class="line-added">+                 mem = new ProjNode(mb, TypeFunc::Memory);</span>
<span class="line-added">+                 igvn.register_new_node_with_optimizer(mem);</span>
<span class="line-added">+                 mm-&gt;set_memory_at(j, mem);</span>
<span class="line-added">+               }</span>
<span class="line-added">+               igvn.replace_node(m-&gt;in(0)-&gt;as_Multi()-&gt;proj_out(TypeFunc::Control), ctrl);</span>
<span class="line-added">+             }</span>
<span class="line-added">+             if (idx &lt; m-&gt;req()-1) {</span>
<span class="line-added">+               idx += 1;</span>
<span class="line-added">+               stack.set_index(idx);</span>
<span class="line-added">+               n = m-&gt;in(idx);</span>
<span class="line-added">+               break;</span>
<span class="line-added">+             }</span>
<span class="line-added">+             // Take care of place holder nodes</span>
<span class="line-added">+             if (m-&gt;has_out_with(Op_Node)) {</span>
<span class="line-added">+               Node* place_holder = m-&gt;find_out_with(Op_Node);</span>
<span class="line-added">+               if (place_holder != NULL) {</span>
<span class="line-added">+                 Node* mm_clone = mm-&gt;clone();</span>
<span class="line-added">+                 igvn.register_new_node_with_optimizer(mm_clone);</span>
<span class="line-added">+                 Node* hook = new Node(1);</span>
<span class="line-added">+                 hook-&gt;init_req(0, mm);</span>
<span class="line-added">+                 igvn.replace_node(place_holder, mm_clone);</span>
<span class="line-added">+                 hook-&gt;destruct();</span>
<span class="line-added">+               }</span>
<span class="line-added">+               assert(!m-&gt;has_out_with(Op_Node), &quot;place holder should be gone now&quot;);</span>
<span class="line-added">+             }</span>
<span class="line-added">+             stack.pop();</span>
<span class="line-added">+           }</span>
<span class="line-added">+         }</span>
<span class="line-added">+       } while(stack.size() &gt; 0);</span>
<span class="line-added">+       // Fix the memory state at the MergeMem we started from</span>
<span class="line-added">+       igvn.rehash_node_delayed(current);</span>
<span class="line-added">+       for (uint j = (uint)start_alias; j &lt;= (uint)stop_alias; j++) {</span>
<span class="line-added">+         const Type* adr_type = get_adr_type(j);</span>
<span class="line-added">+         if (!adr_type-&gt;isa_aryptr() || !adr_type-&gt;is_aryptr()-&gt;elem()-&gt;isa_inlinetype()) {</span>
<span class="line-added">+           continue;</span>
<span class="line-added">+         }</span>
<span class="line-added">+         current-&gt;set_memory_at(j, mm);</span>
<span class="line-added">+       }</span>
<span class="line-added">+       current-&gt;set_memory_at(index, current-&gt;base_memory());</span>
<span class="line-added">+     }</span>
<span class="line-added">+     igvn.optimize();</span>
<span class="line-added">+   }</span>
<span class="line-added">+   print_method(PHASE_SPLIT_INLINES_ARRAY, 2);</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ </span>
  // StringOpts and late inlining of string methods
  void Compile::inline_string_calls(bool parse_time) {
    {
      // remove useless nodes to make the usage analysis simpler
      ResourceMark rm;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2080,10 ***</span>
<span class="line-new-header">--- 2487,17 ---</span>
      set_for_igvn(&amp;new_worklist);
      igvn = PhaseIterGVN(initial_gvn());
      igvn.optimize();
    }
  
<span class="line-added">+   if (_inline_type_nodes-&gt;length() &gt; 0) {</span>
<span class="line-added">+     // Do this once all inlining is over to avoid getting inconsistent debug info</span>
<span class="line-added">+     process_inline_types(igvn);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   adjust_flattened_array_access_aliases(igvn);</span>
<span class="line-added">+ </span>
    // Perform escape analysis
    if (_do_escape_analysis &amp;&amp; ConnectionGraph::has_candidates(this)) {
      if (has_loops()) {
        // Cleanup graph (remove dead nodes).
        TracePhase tp(&quot;idealLoop&quot;, &amp;timers[_t_idealLoop]);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2112,10 ***</span>
<span class="line-new-header">--- 2526,15 ---</span>
  
        if (failing())  return;
      }
    }
  
<span class="line-added">+   if (_inline_type_nodes-&gt;length() &gt; 0) {</span>
<span class="line-added">+     // Process inline types again now that EA might have simplified the graph</span>
<span class="line-added">+     process_inline_types(igvn, /* post_ea= */ true);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
    // Loop transforms on the ideal graph.  Range Check Elimination,
    // peeling, unrolling, etc.
  
    // Set loop opts counter
    if((_loop_opts_cnt &gt; 0) &amp;&amp; (has_loops() || has_split_ifs())) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2754,10 ***</span>
<span class="line-new-header">--- 3173,11 ---</span>
        mem = prev-&gt;in(MemNode::Memory);
      }
    }
  }
  
<span class="line-added">+ </span>
  //------------------------------final_graph_reshaping_impl----------------------
  // Implement items 1-5 from final_graph_reshaping below.
  void Compile::final_graph_reshaping_impl( Node *n, Final_Reshape_Counts &amp;frc) {
  
    if ( n-&gt;outcnt() == 0 ) return; // dead node
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3492,10 ***</span>
<span class="line-new-header">--- 3912,18 ---</span>
        Node* cmp = new CmpLNode(andl, n-&gt;in(2));
        n-&gt;subsume_by(cmp, this);
      }
      break;
    }
<span class="line-added">+ #ifdef ASSERT</span>
<span class="line-added">+   case Op_InlineTypePtr:</span>
<span class="line-added">+   case Op_InlineType: {</span>
<span class="line-added">+     n-&gt;dump(-1);</span>
<span class="line-added">+     assert(false, &quot;inline type node was not removed&quot;);</span>
<span class="line-added">+     break;</span>
<span class="line-added">+   }</span>
<span class="line-added">+ #endif</span>
    default:
      assert(!n-&gt;is_Call(), &quot;&quot;);
      assert(!n-&gt;is_Mem(), &quot;&quot;);
      assert(nop != Op_ProfileBoolean, &quot;should be eliminated during IGVN&quot;);
      break;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3839,20 ***</span>
    if (holder-&gt;is_being_initialized()) {
      if (accessing_method-&gt;holder() == holder) {
        // Access inside a class. The barrier can be elided when access happens in &lt;clinit&gt;,
        // &lt;init&gt;, or a static method. In all those cases, there was an initialization
        // barrier on the holder klass passed.
<span class="line-modified">!       if (accessing_method-&gt;is_static_initializer() ||</span>
<span class="line-modified">!           accessing_method-&gt;is_object_initializer() ||</span>
            accessing_method-&gt;is_static()) {
          return false;
        }
      } else if (accessing_method-&gt;holder()-&gt;is_subclass_of(holder)) {
        // Access from a subclass. The barrier can be elided only when access happens in &lt;clinit&gt;.
        // In case of &lt;init&gt; or a static method, the barrier is on the subclass is not enough:
        // child class can become fully initialized while its parent class is still being initialized.
<span class="line-modified">!       if (accessing_method-&gt;is_static_initializer()) {</span>
          return false;
        }
      }
      ciMethod* root = method(); // the root method of compilation
      if (root != accessing_method) {
<span class="line-new-header">--- 4267,20 ---</span>
    if (holder-&gt;is_being_initialized()) {
      if (accessing_method-&gt;holder() == holder) {
        // Access inside a class. The barrier can be elided when access happens in &lt;clinit&gt;,
        // &lt;init&gt;, or a static method. In all those cases, there was an initialization
        // barrier on the holder klass passed.
<span class="line-modified">!       if (accessing_method-&gt;is_class_initializer() ||</span>
<span class="line-modified">!           accessing_method-&gt;is_object_constructor() ||</span>
            accessing_method-&gt;is_static()) {
          return false;
        }
      } else if (accessing_method-&gt;holder()-&gt;is_subclass_of(holder)) {
        // Access from a subclass. The barrier can be elided only when access happens in &lt;clinit&gt;.
        // In case of &lt;init&gt; or a static method, the barrier is on the subclass is not enough:
        // child class can become fully initialized while its parent class is still being initialized.
<span class="line-modified">!       if (accessing_method-&gt;is_class_initializer()) {</span>
          return false;
        }
      }
      ciMethod* root = method(); // the root method of compilation
      if (root != accessing_method) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3969,21 ***</span>
  // (0) superklass is java.lang.Object (can occur in reflective code)
  // (1) subklass is already limited to a subtype of superklass =&gt; always ok
  // (2) subklass does not overlap with superklass =&gt; always fail
  // (3) superklass has NO subtypes and we can check with a simple compare.
  int Compile::static_subtype_check(ciKlass* superk, ciKlass* subk) {
<span class="line-modified">!   if (StressReflectiveCode) {</span>
      return SSC_full_test;       // Let caller generate the general case.
    }
  
    if (superk == env()-&gt;Object_klass()) {
      return SSC_always_true;     // (0) this test cannot fail
    }
  
    ciType* superelem = superk;
<span class="line-modified">!   if (superelem-&gt;is_array_klass())</span>
      superelem = superelem-&gt;as_array_klass()-&gt;base_element_type();
  
    if (!subk-&gt;is_interface()) {  // cannot trust static interface types yet
      if (subk-&gt;is_subtype_of(superk)) {
        return SSC_always_true;   // (1) false path dead; no dynamic test needed
      }
<span class="line-new-header">--- 4397,23 ---</span>
  // (0) superklass is java.lang.Object (can occur in reflective code)
  // (1) subklass is already limited to a subtype of superklass =&gt; always ok
  // (2) subklass does not overlap with superklass =&gt; always fail
  // (3) superklass has NO subtypes and we can check with a simple compare.
  int Compile::static_subtype_check(ciKlass* superk, ciKlass* subk) {
<span class="line-modified">!   if (StressReflectiveCode || superk == NULL || subk == NULL) {</span>
      return SSC_full_test;       // Let caller generate the general case.
    }
  
    if (superk == env()-&gt;Object_klass()) {
      return SSC_always_true;     // (0) this test cannot fail
    }
  
    ciType* superelem = superk;
<span class="line-modified">!   if (superelem-&gt;is_array_klass()) {</span>
<span class="line-added">+     ciArrayKlass* ak = superelem-&gt;as_array_klass();</span>
      superelem = superelem-&gt;as_array_klass()-&gt;base_element_type();
<span class="line-added">+   }</span>
  
    if (!subk-&gt;is_interface()) {  // cannot trust static interface types yet
      if (subk-&gt;is_subtype_of(superk)) {
        return SSC_always_true;   // (1) false path dead; no dynamic test needed
      }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 4440,10 ***</span>
<span class="line-new-header">--- 4870,31 ---</span>
      igvn.check_no_speculative_types();
  #endif
    }
  }
  
<span class="line-added">+ Node* Compile::optimize_acmp(PhaseGVN* phase, Node* a, Node* b) {</span>
<span class="line-added">+   const TypeInstPtr* ta = phase-&gt;type(a)-&gt;isa_instptr();</span>
<span class="line-added">+   const TypeInstPtr* tb = phase-&gt;type(b)-&gt;isa_instptr();</span>
<span class="line-added">+   if (!EnableValhalla || ta == NULL || tb == NULL ||</span>
<span class="line-added">+       ta-&gt;is_zero_type() || tb-&gt;is_zero_type() ||</span>
<span class="line-added">+       !ta-&gt;can_be_inline_type() || !tb-&gt;can_be_inline_type()) {</span>
<span class="line-added">+     // Use old acmp if one operand is null or not an inline type</span>
<span class="line-added">+     return new CmpPNode(a, b);</span>
<span class="line-added">+   } else if (ta-&gt;is_inlinetypeptr() || tb-&gt;is_inlinetypeptr()) {</span>
<span class="line-added">+     // We know that one operand is an inline type. Therefore,</span>
<span class="line-added">+     // new acmp will only return true if both operands are NULL.</span>
<span class="line-added">+     // Check if both operands are null by or&#39;ing the oops.</span>
<span class="line-added">+     a = phase-&gt;transform(new CastP2XNode(NULL, a));</span>
<span class="line-added">+     b = phase-&gt;transform(new CastP2XNode(NULL, b));</span>
<span class="line-added">+     a = phase-&gt;transform(new OrXNode(a, b));</span>
<span class="line-added">+     return new CmpXNode(a, phase-&gt;MakeConX(0));</span>
<span class="line-added">+   }</span>
<span class="line-added">+   // Use new acmp</span>
<span class="line-added">+   return NULL;</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
  // Auxiliary method to support randomized stressing/fuzzing.
  //
  // This method can be called the arbitrary number of times, with current count
  // as the argument. The logic allows selecting a single candidate from the
  // running list of candidates as follows:
</pre>
<center><a href="chaitin.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="compile.hpp.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>