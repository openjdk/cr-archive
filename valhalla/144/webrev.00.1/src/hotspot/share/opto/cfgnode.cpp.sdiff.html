<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/cfgnode.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="c2_globals.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="chaitin.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/cfgnode.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;classfile/systemDictionary.hpp&quot;
  27 #include &quot;gc/shared/barrierSet.hpp&quot;
  28 #include &quot;gc/shared/c2/barrierSetC2.hpp&quot;
  29 #include &quot;memory/allocation.inline.hpp&quot;
  30 #include &quot;memory/resourceArea.hpp&quot;
  31 #include &quot;oops/objArrayKlass.hpp&quot;
  32 #include &quot;opto/addnode.hpp&quot;
  33 #include &quot;opto/castnode.hpp&quot;
  34 #include &quot;opto/cfgnode.hpp&quot;
  35 #include &quot;opto/connode.hpp&quot;
  36 #include &quot;opto/convertnode.hpp&quot;

  37 #include &quot;opto/loopnode.hpp&quot;
  38 #include &quot;opto/machnode.hpp&quot;
  39 #include &quot;opto/movenode.hpp&quot;
  40 #include &quot;opto/narrowptrnode.hpp&quot;
  41 #include &quot;opto/mulnode.hpp&quot;
  42 #include &quot;opto/phaseX.hpp&quot;
  43 #include &quot;opto/regmask.hpp&quot;
  44 #include &quot;opto/runtime.hpp&quot;
  45 #include &quot;opto/subnode.hpp&quot;
  46 #include &quot;utilities/vmError.hpp&quot;
  47 
  48 // Portions of code courtesy of Clifford Click
  49 
  50 // Optimization - Graph Style
  51 
  52 //=============================================================================
  53 //------------------------------Value------------------------------------------
  54 // Compute the type of the RegionNode.
  55 const Type* RegionNode::Value(PhaseGVN* phase) const {
  56   for( uint i=1; i&lt;req(); ++i ) {       // For all paths in
</pre>
<hr />
<pre>
 354   nstack.push(n);
 355   visited.set(n-&gt;_idx);
 356   while (nstack.size() != 0) {
 357     n = nstack.pop();
 358     uint max = n-&gt;outcnt();
 359     for (uint i = 0; i &lt; max; i++) {
 360       Node* m = n-&gt;raw_out(i);
 361       if (m != NULL &amp;&amp; m-&gt;is_CFG()) {
 362         if (phase-&gt;eqv(m, this)) {
 363           return false; // We reached the Region node - it is not dead.
 364         }
 365         if (!visited.test_set(m-&gt;_idx))
 366           nstack.push(m);
 367       }
 368     }
 369   }
 370 
 371   return true; // The Region node is unreachable - it is dead.
 372 }
 373 
<span class="line-modified"> 374 bool RegionNode::try_clean_mem_phi(PhaseGVN *phase) {</span>
 375   // Incremental inlining + PhaseStringOpts sometimes produce:
 376   //
 377   // cmpP with 1 top input
 378   //           |
 379   //          If
 380   //         /  \
 381   //   IfFalse  IfTrue  /- Some Node
 382   //         \  /      /    /
 383   //        Region    / /-MergeMem
 384   //             \---Phi
 385   //
 386   //
 387   // It&#39;s expected by PhaseStringOpts that the Region goes away and is
 388   // replaced by If&#39;s control input but because there&#39;s still a Phi,
 389   // the Region stays in the graph. The top input from the cmpP is
 390   // propagated forward and a subgraph that is useful goes away. The
 391   // code below replaces the Phi with the MergeMem so that the Region
 392   // is simplified.
 393 
<span class="line-modified"> 394   PhiNode* phi = has_unique_phi();</span>
<span class="line-removed"> 395   if (phi &amp;&amp; phi-&gt;type() == Type::MEMORY &amp;&amp; req() == 3 &amp;&amp; phi-&gt;is_diamond_phi(true)) {</span>
 396     MergeMemNode* m = NULL;
<span class="line-modified"> 397     assert(phi-&gt;req() == 3, &quot;same as region&quot;);</span>

 398     for (uint i = 1; i &lt; 3; ++i) {
<span class="line-modified"> 399       Node *mem = phi-&gt;in(i);</span>
<span class="line-modified"> 400       if (mem &amp;&amp; mem-&gt;is_MergeMem() &amp;&amp; in(i)-&gt;outcnt() == 1) {</span>
 401         // Nothing is control-dependent on path #i except the region itself.
 402         m = mem-&gt;as_MergeMem();
 403         uint j = 3 - i;
<span class="line-modified"> 404         Node* other = phi-&gt;in(j);</span>
 405         if (other &amp;&amp; other == m-&gt;base_memory()) {
 406           // m is a successor memory to other, and is not pinned inside the diamond, so push it out.
 407           // This will allow the diamond to collapse completely.
<span class="line-modified"> 408           phase-&gt;is_IterGVN()-&gt;replace_node(phi, m);</span>
<span class="line-removed"> 409           return true;</span>
 410         }
 411       }
 412     }
 413   }
<span class="line-modified"> 414   return false;</span>
 415 }
 416 
 417 //------------------------------Ideal------------------------------------------
 418 // Return a node which is more &quot;ideal&quot; than the current node.  Must preserve
 419 // the CFG, but we can still strip out dead paths.
 420 Node *RegionNode::Ideal(PhaseGVN *phase, bool can_reshape) {
 421   if( !can_reshape &amp;&amp; !in(0) ) return NULL;     // Already degraded to a Copy
 422   assert(!in(0) || !in(0)-&gt;is_Root(), &quot;not a specially hidden merge&quot;);
 423 
 424   // Check for RegionNode with no Phi users and both inputs come from either
 425   // arm of the same IF.  If found, then the control-flow split is useless.
 426   bool has_phis = false;
 427   if (can_reshape) {            // Need DU info to check for Phi users
 428     has_phis = (has_phi() != NULL);       // Cache result
<span class="line-modified"> 429     if (has_phis &amp;&amp; try_clean_mem_phi(phase)) {</span>
<span class="line-modified"> 430       has_phis = false;</span>







 431     }
 432 
 433     if (!has_phis) {            // No Phi users?  Nothing merging?
 434       for (uint i = 1; i &lt; req()-1; i++) {
 435         Node *if1 = in(i);
 436         if( !if1 ) continue;
 437         Node *iff = if1-&gt;in(0);
 438         if( !iff || !iff-&gt;is_If() ) continue;
 439         for( uint j=i+1; j&lt;req(); j++ ) {
 440           if( in(j) &amp;&amp; in(j)-&gt;in(0) == iff &amp;&amp;
 441               if1-&gt;Opcode() != in(j)-&gt;Opcode() ) {
 442             // Add the IF Projections to the worklist. They (and the IF itself)
 443             // will be eliminated if dead.
 444             phase-&gt;is_IterGVN()-&gt;add_users_to_worklist(iff);
 445             set_req(i, iff-&gt;in(0));// Skip around the useless IF diamond
 446             set_req(j, NULL);
 447             return this;      // Record progress
 448           }
 449         }
 450       }
</pre>
<hr />
<pre>
 878 
 879 //=============================================================================
 880 // note that these functions assume that the _adr_type field is flattened
 881 uint PhiNode::hash() const {
 882   const Type* at = _adr_type;
 883   return TypeNode::hash() + (at ? at-&gt;hash() : 0);
 884 }
 885 bool PhiNode::cmp( const Node &amp;n ) const {
 886   return TypeNode::cmp(n) &amp;&amp; _adr_type == ((PhiNode&amp;)n)._adr_type;
 887 }
 888 static inline
 889 const TypePtr* flatten_phi_adr_type(const TypePtr* at) {
 890   if (at == NULL || at == TypePtr::BOTTOM)  return at;
 891   return Compile::current()-&gt;alias_type(at)-&gt;adr_type();
 892 }
 893 
 894 //----------------------------make---------------------------------------------
 895 // create a new phi with edges matching r and set (initially) to x
 896 PhiNode* PhiNode::make(Node* r, Node* x, const Type *t, const TypePtr* at) {
 897   uint preds = r-&gt;req();   // Number of predecessor paths
<span class="line-modified"> 898   assert(t != Type::MEMORY || at == flatten_phi_adr_type(at), &quot;flatten at&quot;);</span>
 899   PhiNode* p = new PhiNode(r, t, at);
 900   for (uint j = 1; j &lt; preds; j++) {
 901     // Fill in all inputs, except those which the region does not yet have
 902     if (r-&gt;in(j) != NULL)
 903       p-&gt;init_req(j, x);
 904   }
 905   return p;
 906 }
 907 PhiNode* PhiNode::make(Node* r, Node* x) {
 908   const Type*    t  = x-&gt;bottom_type();
 909   const TypePtr* at = NULL;
 910   if (t == Type::MEMORY)  at = flatten_phi_adr_type(x-&gt;adr_type());
 911   return make(r, x, t, at);
 912 }
 913 PhiNode* PhiNode::make_blank(Node* r, Node* x) {
 914   const Type*    t  = x-&gt;bottom_type();
 915   const TypePtr* at = NULL;
 916   if (t == Type::MEMORY)  at = flatten_phi_adr_type(x-&gt;adr_type());
 917   return new PhiNode(r, t, at);
 918 }
</pre>
<hr />
<pre>
1088         }
1089       }
1090     } else if (l-&gt;in(LoopNode::LoopBackControl) != NULL &amp;&amp;
1091                in(LoopNode::EntryControl) != NULL &amp;&amp;
1092                phase-&gt;type(l-&gt;in(LoopNode::LoopBackControl)) == Type::TOP) {
1093       // During CCP, if we saturate the type of a counted loop&#39;s Phi
1094       // before the special code for counted loop above has a chance
1095       // to run (that is as long as the type of the backedge&#39;s control
1096       // is top), we might end up with non monotonic types
1097       return phase-&gt;type(in(LoopNode::EntryControl))-&gt;filter_speculative(_type);
1098     }
1099   }
1100 
1101   // Until we have harmony between classes and interfaces in the type
1102   // lattice, we must tread carefully around phis which implicitly
1103   // convert the one to the other.
1104   const TypePtr* ttp = _type-&gt;make_ptr();
1105   const TypeInstPtr* ttip = (ttp != NULL) ? ttp-&gt;isa_instptr() : NULL;
1106   const TypeKlassPtr* ttkp = (ttp != NULL) ? ttp-&gt;isa_klassptr() : NULL;
1107   bool is_intf = false;
<span class="line-modified">1108   if (ttip != NULL) {</span>
<span class="line-modified">1109     ciKlass* k = ttip-&gt;klass();</span>
<span class="line-modified">1110     if (k-&gt;is_loaded() &amp;&amp; k-&gt;is_interface())</span>
<span class="line-modified">1111       is_intf = true;</span>
<span class="line-removed">1112   }</span>
<span class="line-removed">1113   if (ttkp != NULL) {</span>
<span class="line-removed">1114     ciKlass* k = ttkp-&gt;klass();</span>
<span class="line-removed">1115     if (k-&gt;is_loaded() &amp;&amp; k-&gt;is_interface())</span>
<span class="line-removed">1116       is_intf = true;</span>
1117   }
1118 
1119   // Default case: merge all inputs
1120   const Type *t = Type::TOP;        // Merged type starting value
1121   for (uint i = 1; i &lt; req(); ++i) {// For all paths in
1122     // Reachable control path?
1123     if (r-&gt;in(i) &amp;&amp; phase-&gt;type(r-&gt;in(i)) == Type::CONTROL) {
1124       const Type* ti = phase-&gt;type(in(i));
1125       // We assume that each input of an interface-valued Phi is a true
1126       // subtype of that interface.  This might not be true of the meet
1127       // of all the input types.  The lattice is not distributive in
1128       // such cases.  Ward off asserts in type.cpp by refusing to do
1129       // meets between interfaces and proper classes.
1130       const TypePtr* tip = ti-&gt;make_ptr();
1131       const TypeInstPtr* tiip = (tip != NULL) ? tip-&gt;isa_instptr() : NULL;
1132       if (tiip) {
1133         bool ti_is_intf = false;
1134         ciKlass* k = tiip-&gt;klass();
1135         if (k-&gt;is_loaded() &amp;&amp; k-&gt;is_interface())
1136           ti_is_intf = true;
</pre>
<hr />
<pre>
1153   //   (Occurrences of this case suggest improvements to Value methods.)
1154   //
1155   // It is not possible to see Type::BOTTOM values as phi inputs,
1156   // because the ciTypeFlow pre-pass produces verifier-quality types.
1157   const Type* ft = t-&gt;filter_speculative(_type);  // Worst case type
1158 
1159 #ifdef ASSERT
1160   // The following logic has been moved into TypeOopPtr::filter.
1161   const Type* jt = t-&gt;join_speculative(_type);
1162   if (jt-&gt;empty()) {           // Emptied out???
1163 
1164     // Check for evil case of &#39;t&#39; being a class and &#39;_type&#39; expecting an
1165     // interface.  This can happen because the bytecodes do not contain
1166     // enough type info to distinguish a Java-level interface variable
1167     // from a Java-level object variable.  If we meet 2 classes which
1168     // both implement interface I, but their meet is at &#39;j/l/O&#39; which
1169     // doesn&#39;t implement I, we have no way to tell if the result should
1170     // be &#39;I&#39; or &#39;j/l/O&#39;.  Thus we&#39;ll pick &#39;j/l/O&#39;.  If this then flows
1171     // into a Phi which &quot;knows&quot; it&#39;s an Interface type we&#39;ll have to
1172     // uplift the type.
<span class="line-modified">1173     if (!t-&gt;empty() &amp;&amp; ttip &amp;&amp; ttip-&gt;is_loaded() &amp;&amp; ttip-&gt;klass()-&gt;is_interface()) {</span>
1174       assert(ft == _type, &quot;&quot;); // Uplift to interface
<span class="line-modified">1175     } else if (!t-&gt;empty() &amp;&amp; ttkp &amp;&amp; ttkp-&gt;is_loaded() &amp;&amp; ttkp-&gt;klass()-&gt;is_interface()) {</span>
1176       assert(ft == _type, &quot;&quot;); // Uplift to interface
1177     } else {
1178       // We also have to handle &#39;evil cases&#39; of interface- vs. class-arrays
1179       Type::get_arrays_base_elements(jt, _type, NULL, &amp;ttip);
1180       if (!t-&gt;empty() &amp;&amp; ttip != NULL &amp;&amp; ttip-&gt;is_loaded() &amp;&amp; ttip-&gt;klass()-&gt;is_interface()) {
1181           assert(ft == _type, &quot;&quot;);   // Uplift to array of interface
1182       } else {
1183         // Otherwise it&#39;s something stupid like non-overlapping int ranges
1184         // found on dying counted loops.
1185         assert(ft == Type::TOP, &quot;&quot;); // Canonical empty value
1186       }
1187     }
1188   }
1189 
1190   else {
1191 
1192     // If we have an interface-typed Phi and we narrow to a class type, the join
1193     // should report back the class.  However, if we have a J/L/Object
1194     // class-typed Phi and an interface flows in, it&#39;s possible that the meet &amp;
1195     // join report an interface back out.  This isn&#39;t possible but happens
</pre>
<hr />
<pre>
1317 
1318 //------------------------------Identity---------------------------------------
1319 // Check for Region being Identity.
1320 Node* PhiNode::Identity(PhaseGVN* phase) {
1321   // Check for no merging going on
1322   // (There used to be special-case code here when this-&gt;region-&gt;is_Loop.
1323   // It would check for a tributary phi on the backedge that the main phi
1324   // trivially, perhaps with a single cast.  The unique_input method
1325   // does all this and more, by reducing such tributaries to &#39;this&#39;.)
1326   Node* uin = unique_input(phase, false);
1327   if (uin != NULL) {
1328     return uin;
1329   }
1330 
1331   int true_path = is_diamond_phi();
1332   if (true_path != 0) {
1333     Node* id = is_cmove_id(phase, true_path);
1334     if (id != NULL)  return id;
1335   }
1336 








1337   return this;                     // No identity
1338 }
1339 
1340 //-----------------------------unique_input------------------------------------
1341 // Find the unique value, discounting top, self-loops, and casts.
1342 // Return top if there are no inputs, and self if there are multiple.
1343 Node* PhiNode::unique_input(PhaseTransform* phase, bool uncast) {
1344   //  1) One unique direct input,
1345   // or if uncast is true:
1346   //  2) some of the inputs have an intervening ConstraintCast
1347   //  3) an input is a self loop
1348   //
1349   //  1) input   or   2) input     or   3) input __
1350   //     /   \           /   \               \  /  \
1351   //     \   /          |    cast             phi  cast
1352   //      phi            \   /               /  \  /
1353   //                      phi               /    --
1354 
1355   Node* r = in(0);                      // RegionNode
1356   if (r == NULL)  return in(1);         // Already degraded to a Copy
</pre>
<hr />
<pre>
1839   }
1840   return delay;
1841 }
1842 
1843 //------------------------------Ideal------------------------------------------
1844 // Return a node which is more &quot;ideal&quot; than the current node.  Must preserve
1845 // the CFG, but we can still strip out dead paths.
1846 Node *PhiNode::Ideal(PhaseGVN *phase, bool can_reshape) {
1847   // The next should never happen after 6297035 fix.
1848   if( is_copy() )               // Already degraded to a Copy ?
1849     return NULL;                // No change
1850 
1851   Node *r = in(0);              // RegionNode
1852   assert(r-&gt;in(0) == NULL || !r-&gt;in(0)-&gt;is_Root(), &quot;not a specially hidden merge&quot;);
1853 
1854   // Note: During parsing, phis are often transformed before their regions.
1855   // This means we have to use type_or_null to defend against untyped regions.
1856   if( phase-&gt;type_or_null(r) == Type::TOP ) // Dead code?
1857     return NULL;                // No change
1858 


















1859   Node *top = phase-&gt;C-&gt;top();
1860   bool new_phi = (outcnt() == 0); // transforming new Phi
1861   // No change for igvn if new phi is not hooked
1862   if (new_phi &amp;&amp; can_reshape)
1863     return NULL;
1864 
1865   // The are 2 situations when only one valid phi&#39;s input is left
1866   // (in addition to Region input).
1867   // One: region is not loop - replace phi with this input.
1868   // Two: region is loop - replace phi with top since this data path is dead
1869   //                       and we need to break the dead data loop.
1870   Node* progress = NULL;        // Record if any progress made
1871   for( uint j = 1; j &lt; req(); ++j ){ // For all paths in
1872     // Check unreachable control paths
1873     Node* rc = r-&gt;in(j);
1874     Node* n = in(j);            // Get the input
1875     if (rc == NULL || phase-&gt;type(rc) == Type::TOP) {
1876       if (n != top) {           // Not already top?
1877         PhaseIterGVN *igvn = phase-&gt;is_IterGVN();
1878         if (can_reshape &amp;&amp; igvn != NULL) {
</pre>
<hr />
<pre>
2137           for (uint i = 1; i &lt; req(); i++) {
2138             offset-&gt;init_req(i, in(i)-&gt;in(AddPNode::Offset));
2139           }
2140           phase-&gt;is_IterGVN()-&gt;register_new_node_with_optimizer(offset);
2141         }
2142         return new AddPNode(base, address, offset);
2143       }
2144     }
2145   }
2146 
2147   // Split phis through memory merges, so that the memory merges will go away.
2148   // Piggy-back this transformation on the search for a unique input....
2149   // It will be as if the merged memory is the unique value of the phi.
2150   // (Do not attempt this optimization unless parsing is complete.
2151   // It would make the parser&#39;s memory-merge logic sick.)
2152   // (MergeMemNode is not dead_loop_safe - need to check for dead loop.)
2153   if (progress == NULL &amp;&amp; can_reshape &amp;&amp; type() == Type::MEMORY) {
2154     // see if this phi should be sliced
2155     uint merge_width = 0;
2156     bool saw_self = false;


2157     for( uint i=1; i&lt;req(); ++i ) {// For all paths in
2158       Node *ii = in(i);
2159       // TOP inputs should not be counted as safe inputs because if the
2160       // Phi references itself through all other inputs then splitting the
2161       // Phi through memory merges would create dead loop at later stage.
2162       if (ii == top) {
2163         return NULL; // Delay optimization until graph is cleaned.
2164       }
2165       if (ii-&gt;is_MergeMem()) {
2166         MergeMemNode* n = ii-&gt;as_MergeMem();
2167         merge_width = MAX2(merge_width, n-&gt;req());
2168         saw_self = saw_self || phase-&gt;eqv(n-&gt;base_memory(), this);


2169       }
2170     }
2171 
2172     // This restriction is temporarily necessary to ensure termination:
<span class="line-modified">2173     if (!saw_self &amp;&amp; adr_type() == TypePtr::BOTTOM)  merge_width = 0;</span>
2174 
2175     if (merge_width &gt; Compile::AliasIdxRaw) {
2176       // found at least one non-empty MergeMem
2177       const TypePtr* at = adr_type();
2178       if (at != TypePtr::BOTTOM) {
2179         // Patch the existing phi to select an input from the merge:
2180         // Phi:AT1(...MergeMem(m0, m1, m2)...) into
2181         //     Phi:AT1(...m1...)
2182         int alias_idx = phase-&gt;C-&gt;get_alias_index(at);
2183         for (uint i=1; i&lt;req(); ++i) {
2184           Node *ii = in(i);
2185           if (ii-&gt;is_MergeMem()) {
2186             MergeMemNode* n = ii-&gt;as_MergeMem();
2187             // compress paths and change unreachable cycles to TOP
2188             // If not, we can update the input infinitely along a MergeMem cycle
2189             // Equivalent code is in MemNode::Ideal_common
2190             Node *m  = phase-&gt;transform(n);
2191             if (outcnt() == 0) {  // Above transform() may kill us!
2192               return top;
2193             }
</pre>
<hr />
<pre>
2582   return in(0)-&gt;in(0);
2583 }
2584 
2585 
2586 #ifndef PRODUCT
2587 void CatchProjNode::dump_spec(outputStream *st) const {
2588   ProjNode::dump_spec(st);
2589   st-&gt;print(&quot;@bci %d &quot;,_handler_bci);
2590 }
2591 #endif
2592 
2593 //=============================================================================
2594 //------------------------------Identity---------------------------------------
2595 // Check for CreateEx being Identity.
2596 Node* CreateExNode::Identity(PhaseGVN* phase) {
2597   if( phase-&gt;type(in(1)) == Type::TOP ) return in(1);
2598   if( phase-&gt;type(in(0)) == Type::TOP ) return in(0);
2599   // We only come from CatchProj, unless the CatchProj goes away.
2600   // If the CatchProj is optimized away, then we just carry the
2601   // exception oop through.






2602   CallNode *call = in(1)-&gt;in(0)-&gt;as_Call();
2603 
2604   return ( in(0)-&gt;is_CatchProj() &amp;&amp; in(0)-&gt;in(0)-&gt;in(1) == in(1) )
2605     ? this
2606     : call-&gt;in(TypeFunc::Parms);
2607 }
2608 
2609 //=============================================================================
2610 //------------------------------Value------------------------------------------
2611 // Check for being unreachable.
2612 const Type* NeverBranchNode::Value(PhaseGVN* phase) const {
2613   if (!in(0) || in(0)-&gt;is_top()) return Type::TOP;
2614   return bottom_type();
2615 }
2616 
2617 //------------------------------Ideal------------------------------------------
2618 // Check for no longer being part of a loop
2619 Node *NeverBranchNode::Ideal(PhaseGVN *phase, bool can_reshape) {
2620   if (can_reshape &amp;&amp; !in(0)-&gt;is_Loop()) {
2621     // Dead code elimination can sometimes delete this projection so
</pre>
</td>
<td>
<hr />
<pre>
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;classfile/systemDictionary.hpp&quot;
  27 #include &quot;gc/shared/barrierSet.hpp&quot;
  28 #include &quot;gc/shared/c2/barrierSetC2.hpp&quot;
  29 #include &quot;memory/allocation.inline.hpp&quot;
  30 #include &quot;memory/resourceArea.hpp&quot;
  31 #include &quot;oops/objArrayKlass.hpp&quot;
  32 #include &quot;opto/addnode.hpp&quot;
  33 #include &quot;opto/castnode.hpp&quot;
  34 #include &quot;opto/cfgnode.hpp&quot;
  35 #include &quot;opto/connode.hpp&quot;
  36 #include &quot;opto/convertnode.hpp&quot;
<span class="line-added">  37 #include &quot;opto/inlinetypenode.hpp&quot;</span>
  38 #include &quot;opto/loopnode.hpp&quot;
  39 #include &quot;opto/machnode.hpp&quot;
  40 #include &quot;opto/movenode.hpp&quot;
  41 #include &quot;opto/narrowptrnode.hpp&quot;
  42 #include &quot;opto/mulnode.hpp&quot;
  43 #include &quot;opto/phaseX.hpp&quot;
  44 #include &quot;opto/regmask.hpp&quot;
  45 #include &quot;opto/runtime.hpp&quot;
  46 #include &quot;opto/subnode.hpp&quot;
  47 #include &quot;utilities/vmError.hpp&quot;
  48 
  49 // Portions of code courtesy of Clifford Click
  50 
  51 // Optimization - Graph Style
  52 
  53 //=============================================================================
  54 //------------------------------Value------------------------------------------
  55 // Compute the type of the RegionNode.
  56 const Type* RegionNode::Value(PhaseGVN* phase) const {
  57   for( uint i=1; i&lt;req(); ++i ) {       // For all paths in
</pre>
<hr />
<pre>
 355   nstack.push(n);
 356   visited.set(n-&gt;_idx);
 357   while (nstack.size() != 0) {
 358     n = nstack.pop();
 359     uint max = n-&gt;outcnt();
 360     for (uint i = 0; i &lt; max; i++) {
 361       Node* m = n-&gt;raw_out(i);
 362       if (m != NULL &amp;&amp; m-&gt;is_CFG()) {
 363         if (phase-&gt;eqv(m, this)) {
 364           return false; // We reached the Region node - it is not dead.
 365         }
 366         if (!visited.test_set(m-&gt;_idx))
 367           nstack.push(m);
 368       }
 369     }
 370   }
 371 
 372   return true; // The Region node is unreachable - it is dead.
 373 }
 374 
<span class="line-modified"> 375 Node* PhiNode::try_clean_mem_phi(PhaseGVN *phase) {</span>
 376   // Incremental inlining + PhaseStringOpts sometimes produce:
 377   //
 378   // cmpP with 1 top input
 379   //           |
 380   //          If
 381   //         /  \
 382   //   IfFalse  IfTrue  /- Some Node
 383   //         \  /      /    /
 384   //        Region    / /-MergeMem
 385   //             \---Phi
 386   //
 387   //
 388   // It&#39;s expected by PhaseStringOpts that the Region goes away and is
 389   // replaced by If&#39;s control input but because there&#39;s still a Phi,
 390   // the Region stays in the graph. The top input from the cmpP is
 391   // propagated forward and a subgraph that is useful goes away. The
 392   // code below replaces the Phi with the MergeMem so that the Region
 393   // is simplified.
 394 
<span class="line-modified"> 395   if (type() == Type::MEMORY &amp;&amp; is_diamond_phi(true)) {</span>

 396     MergeMemNode* m = NULL;
<span class="line-modified"> 397     assert(req() == 3, &quot;same as region&quot;);</span>
<span class="line-added"> 398     Node* r = in(0);</span>
 399     for (uint i = 1; i &lt; 3; ++i) {
<span class="line-modified"> 400       Node *mem = in(i);</span>
<span class="line-modified"> 401       if (mem &amp;&amp; mem-&gt;is_MergeMem() &amp;&amp; r-&gt;in(i)-&gt;outcnt() == 1) {</span>
 402         // Nothing is control-dependent on path #i except the region itself.
 403         m = mem-&gt;as_MergeMem();
 404         uint j = 3 - i;
<span class="line-modified"> 405         Node* other = in(j);</span>
 406         if (other &amp;&amp; other == m-&gt;base_memory()) {
 407           // m is a successor memory to other, and is not pinned inside the diamond, so push it out.
 408           // This will allow the diamond to collapse completely.
<span class="line-modified"> 409           return m;</span>

 410         }
 411       }
 412     }
 413   }
<span class="line-modified"> 414   return NULL;</span>
 415 }
 416 
 417 //------------------------------Ideal------------------------------------------
 418 // Return a node which is more &quot;ideal&quot; than the current node.  Must preserve
 419 // the CFG, but we can still strip out dead paths.
 420 Node *RegionNode::Ideal(PhaseGVN *phase, bool can_reshape) {
 421   if( !can_reshape &amp;&amp; !in(0) ) return NULL;     // Already degraded to a Copy
 422   assert(!in(0) || !in(0)-&gt;is_Root(), &quot;not a specially hidden merge&quot;);
 423 
 424   // Check for RegionNode with no Phi users and both inputs come from either
 425   // arm of the same IF.  If found, then the control-flow split is useless.
 426   bool has_phis = false;
 427   if (can_reshape) {            // Need DU info to check for Phi users
 428     has_phis = (has_phi() != NULL);       // Cache result
<span class="line-modified"> 429     if (has_phis) {</span>
<span class="line-modified"> 430       PhiNode* phi = has_unique_phi();</span>
<span class="line-added"> 431       if (phi != NULL) {</span>
<span class="line-added"> 432         Node* m = phi-&gt;try_clean_mem_phi(phase);</span>
<span class="line-added"> 433         if (m != NULL) {</span>
<span class="line-added"> 434           phase-&gt;is_IterGVN()-&gt;replace_node(phi, m);</span>
<span class="line-added"> 435           has_phis = false;</span>
<span class="line-added"> 436         }</span>
<span class="line-added"> 437       }</span>
 438     }
 439 
 440     if (!has_phis) {            // No Phi users?  Nothing merging?
 441       for (uint i = 1; i &lt; req()-1; i++) {
 442         Node *if1 = in(i);
 443         if( !if1 ) continue;
 444         Node *iff = if1-&gt;in(0);
 445         if( !iff || !iff-&gt;is_If() ) continue;
 446         for( uint j=i+1; j&lt;req(); j++ ) {
 447           if( in(j) &amp;&amp; in(j)-&gt;in(0) == iff &amp;&amp;
 448               if1-&gt;Opcode() != in(j)-&gt;Opcode() ) {
 449             // Add the IF Projections to the worklist. They (and the IF itself)
 450             // will be eliminated if dead.
 451             phase-&gt;is_IterGVN()-&gt;add_users_to_worklist(iff);
 452             set_req(i, iff-&gt;in(0));// Skip around the useless IF diamond
 453             set_req(j, NULL);
 454             return this;      // Record progress
 455           }
 456         }
 457       }
</pre>
<hr />
<pre>
 885 
 886 //=============================================================================
 887 // note that these functions assume that the _adr_type field is flattened
 888 uint PhiNode::hash() const {
 889   const Type* at = _adr_type;
 890   return TypeNode::hash() + (at ? at-&gt;hash() : 0);
 891 }
 892 bool PhiNode::cmp( const Node &amp;n ) const {
 893   return TypeNode::cmp(n) &amp;&amp; _adr_type == ((PhiNode&amp;)n)._adr_type;
 894 }
 895 static inline
 896 const TypePtr* flatten_phi_adr_type(const TypePtr* at) {
 897   if (at == NULL || at == TypePtr::BOTTOM)  return at;
 898   return Compile::current()-&gt;alias_type(at)-&gt;adr_type();
 899 }
 900 
 901 //----------------------------make---------------------------------------------
 902 // create a new phi with edges matching r and set (initially) to x
 903 PhiNode* PhiNode::make(Node* r, Node* x, const Type *t, const TypePtr* at) {
 904   uint preds = r-&gt;req();   // Number of predecessor paths
<span class="line-modified"> 905   assert(t != Type::MEMORY || at == flatten_phi_adr_type(at) || (flatten_phi_adr_type(at) == TypeAryPtr::INLINES &amp;&amp; Compile::current()-&gt;flattened_accesses_share_alias()), &quot;flatten at&quot;);</span>
 906   PhiNode* p = new PhiNode(r, t, at);
 907   for (uint j = 1; j &lt; preds; j++) {
 908     // Fill in all inputs, except those which the region does not yet have
 909     if (r-&gt;in(j) != NULL)
 910       p-&gt;init_req(j, x);
 911   }
 912   return p;
 913 }
 914 PhiNode* PhiNode::make(Node* r, Node* x) {
 915   const Type*    t  = x-&gt;bottom_type();
 916   const TypePtr* at = NULL;
 917   if (t == Type::MEMORY)  at = flatten_phi_adr_type(x-&gt;adr_type());
 918   return make(r, x, t, at);
 919 }
 920 PhiNode* PhiNode::make_blank(Node* r, Node* x) {
 921   const Type*    t  = x-&gt;bottom_type();
 922   const TypePtr* at = NULL;
 923   if (t == Type::MEMORY)  at = flatten_phi_adr_type(x-&gt;adr_type());
 924   return new PhiNode(r, t, at);
 925 }
</pre>
<hr />
<pre>
1095         }
1096       }
1097     } else if (l-&gt;in(LoopNode::LoopBackControl) != NULL &amp;&amp;
1098                in(LoopNode::EntryControl) != NULL &amp;&amp;
1099                phase-&gt;type(l-&gt;in(LoopNode::LoopBackControl)) == Type::TOP) {
1100       // During CCP, if we saturate the type of a counted loop&#39;s Phi
1101       // before the special code for counted loop above has a chance
1102       // to run (that is as long as the type of the backedge&#39;s control
1103       // is top), we might end up with non monotonic types
1104       return phase-&gt;type(in(LoopNode::EntryControl))-&gt;filter_speculative(_type);
1105     }
1106   }
1107 
1108   // Until we have harmony between classes and interfaces in the type
1109   // lattice, we must tread carefully around phis which implicitly
1110   // convert the one to the other.
1111   const TypePtr* ttp = _type-&gt;make_ptr();
1112   const TypeInstPtr* ttip = (ttp != NULL) ? ttp-&gt;isa_instptr() : NULL;
1113   const TypeKlassPtr* ttkp = (ttp != NULL) ? ttp-&gt;isa_klassptr() : NULL;
1114   bool is_intf = false;
<span class="line-modified">1115   if (ttip != NULL &amp;&amp; ttip-&gt;is_loaded() &amp;&amp; ttip-&gt;klass()-&gt;is_interface()) {</span>
<span class="line-modified">1116     is_intf = true;</span>
<span class="line-modified">1117   } else if (ttkp != NULL &amp;&amp; ttkp-&gt;is_loaded() &amp;&amp; ttkp-&gt;klass()-&gt;is_interface()) {</span>
<span class="line-modified">1118     is_intf = true;</span>





1119   }
1120 
1121   // Default case: merge all inputs
1122   const Type *t = Type::TOP;        // Merged type starting value
1123   for (uint i = 1; i &lt; req(); ++i) {// For all paths in
1124     // Reachable control path?
1125     if (r-&gt;in(i) &amp;&amp; phase-&gt;type(r-&gt;in(i)) == Type::CONTROL) {
1126       const Type* ti = phase-&gt;type(in(i));
1127       // We assume that each input of an interface-valued Phi is a true
1128       // subtype of that interface.  This might not be true of the meet
1129       // of all the input types.  The lattice is not distributive in
1130       // such cases.  Ward off asserts in type.cpp by refusing to do
1131       // meets between interfaces and proper classes.
1132       const TypePtr* tip = ti-&gt;make_ptr();
1133       const TypeInstPtr* tiip = (tip != NULL) ? tip-&gt;isa_instptr() : NULL;
1134       if (tiip) {
1135         bool ti_is_intf = false;
1136         ciKlass* k = tiip-&gt;klass();
1137         if (k-&gt;is_loaded() &amp;&amp; k-&gt;is_interface())
1138           ti_is_intf = true;
</pre>
<hr />
<pre>
1155   //   (Occurrences of this case suggest improvements to Value methods.)
1156   //
1157   // It is not possible to see Type::BOTTOM values as phi inputs,
1158   // because the ciTypeFlow pre-pass produces verifier-quality types.
1159   const Type* ft = t-&gt;filter_speculative(_type);  // Worst case type
1160 
1161 #ifdef ASSERT
1162   // The following logic has been moved into TypeOopPtr::filter.
1163   const Type* jt = t-&gt;join_speculative(_type);
1164   if (jt-&gt;empty()) {           // Emptied out???
1165 
1166     // Check for evil case of &#39;t&#39; being a class and &#39;_type&#39; expecting an
1167     // interface.  This can happen because the bytecodes do not contain
1168     // enough type info to distinguish a Java-level interface variable
1169     // from a Java-level object variable.  If we meet 2 classes which
1170     // both implement interface I, but their meet is at &#39;j/l/O&#39; which
1171     // doesn&#39;t implement I, we have no way to tell if the result should
1172     // be &#39;I&#39; or &#39;j/l/O&#39;.  Thus we&#39;ll pick &#39;j/l/O&#39;.  If this then flows
1173     // into a Phi which &quot;knows&quot; it&#39;s an Interface type we&#39;ll have to
1174     // uplift the type.
<span class="line-modified">1175     if (!t-&gt;empty() &amp;&amp; ttip != NULL &amp;&amp; ttip-&gt;is_loaded() &amp;&amp; ttip-&gt;klass()-&gt;is_interface()) {</span>
1176       assert(ft == _type, &quot;&quot;); // Uplift to interface
<span class="line-modified">1177     } else if (!t-&gt;empty() &amp;&amp; ttkp != NULL &amp;&amp; ttkp-&gt;is_loaded() &amp;&amp; ttkp-&gt;klass()-&gt;is_interface()) {</span>
1178       assert(ft == _type, &quot;&quot;); // Uplift to interface
1179     } else {
1180       // We also have to handle &#39;evil cases&#39; of interface- vs. class-arrays
1181       Type::get_arrays_base_elements(jt, _type, NULL, &amp;ttip);
1182       if (!t-&gt;empty() &amp;&amp; ttip != NULL &amp;&amp; ttip-&gt;is_loaded() &amp;&amp; ttip-&gt;klass()-&gt;is_interface()) {
1183           assert(ft == _type, &quot;&quot;);   // Uplift to array of interface
1184       } else {
1185         // Otherwise it&#39;s something stupid like non-overlapping int ranges
1186         // found on dying counted loops.
1187         assert(ft == Type::TOP, &quot;&quot;); // Canonical empty value
1188       }
1189     }
1190   }
1191 
1192   else {
1193 
1194     // If we have an interface-typed Phi and we narrow to a class type, the join
1195     // should report back the class.  However, if we have a J/L/Object
1196     // class-typed Phi and an interface flows in, it&#39;s possible that the meet &amp;
1197     // join report an interface back out.  This isn&#39;t possible but happens
</pre>
<hr />
<pre>
1319 
1320 //------------------------------Identity---------------------------------------
1321 // Check for Region being Identity.
1322 Node* PhiNode::Identity(PhaseGVN* phase) {
1323   // Check for no merging going on
1324   // (There used to be special-case code here when this-&gt;region-&gt;is_Loop.
1325   // It would check for a tributary phi on the backedge that the main phi
1326   // trivially, perhaps with a single cast.  The unique_input method
1327   // does all this and more, by reducing such tributaries to &#39;this&#39;.)
1328   Node* uin = unique_input(phase, false);
1329   if (uin != NULL) {
1330     return uin;
1331   }
1332 
1333   int true_path = is_diamond_phi();
1334   if (true_path != 0) {
1335     Node* id = is_cmove_id(phase, true_path);
1336     if (id != NULL)  return id;
1337   }
1338 
<span class="line-added">1339   if (phase-&gt;is_IterGVN()) {</span>
<span class="line-added">1340     Node* m = try_clean_mem_phi(phase);</span>
<span class="line-added">1341     if (m != NULL) {</span>
<span class="line-added">1342       return m;</span>
<span class="line-added">1343     }</span>
<span class="line-added">1344   }</span>
<span class="line-added">1345 </span>
<span class="line-added">1346 </span>
1347   return this;                     // No identity
1348 }
1349 
1350 //-----------------------------unique_input------------------------------------
1351 // Find the unique value, discounting top, self-loops, and casts.
1352 // Return top if there are no inputs, and self if there are multiple.
1353 Node* PhiNode::unique_input(PhaseTransform* phase, bool uncast) {
1354   //  1) One unique direct input,
1355   // or if uncast is true:
1356   //  2) some of the inputs have an intervening ConstraintCast
1357   //  3) an input is a self loop
1358   //
1359   //  1) input   or   2) input     or   3) input __
1360   //     /   \           /   \               \  /  \
1361   //     \   /          |    cast             phi  cast
1362   //      phi            \   /               /  \  /
1363   //                      phi               /    --
1364 
1365   Node* r = in(0);                      // RegionNode
1366   if (r == NULL)  return in(1);         // Already degraded to a Copy
</pre>
<hr />
<pre>
1849   }
1850   return delay;
1851 }
1852 
1853 //------------------------------Ideal------------------------------------------
1854 // Return a node which is more &quot;ideal&quot; than the current node.  Must preserve
1855 // the CFG, but we can still strip out dead paths.
1856 Node *PhiNode::Ideal(PhaseGVN *phase, bool can_reshape) {
1857   // The next should never happen after 6297035 fix.
1858   if( is_copy() )               // Already degraded to a Copy ?
1859     return NULL;                // No change
1860 
1861   Node *r = in(0);              // RegionNode
1862   assert(r-&gt;in(0) == NULL || !r-&gt;in(0)-&gt;is_Root(), &quot;not a specially hidden merge&quot;);
1863 
1864   // Note: During parsing, phis are often transformed before their regions.
1865   // This means we have to use type_or_null to defend against untyped regions.
1866   if( phase-&gt;type_or_null(r) == Type::TOP ) // Dead code?
1867     return NULL;                // No change
1868 
<span class="line-added">1869   // If all inputs are inline types of the same type, push the inline type node down</span>
<span class="line-added">1870   // through the phi because inline type nodes should be merged through their input values.</span>
<span class="line-added">1871   if (req() &gt; 2 &amp;&amp; in(1) != NULL &amp;&amp; in(1)-&gt;is_InlineTypeBase() &amp;&amp; (can_reshape || in(1)-&gt;is_InlineType())) {</span>
<span class="line-added">1872     int opcode = in(1)-&gt;Opcode();</span>
<span class="line-added">1873     uint i = 2;</span>
<span class="line-added">1874     // Check if inputs are values of the same type</span>
<span class="line-added">1875     for (; i &lt; req() &amp;&amp; in(i) &amp;&amp; in(i)-&gt;is_InlineTypeBase() &amp;&amp; in(i)-&gt;cmp(*in(1)); i++) {</span>
<span class="line-added">1876       assert(in(i)-&gt;Opcode() == opcode, &quot;mixing pointers and values?&quot;);</span>
<span class="line-added">1877     }</span>
<span class="line-added">1878     if (i == req()) {</span>
<span class="line-added">1879       InlineTypeBaseNode* vt = in(1)-&gt;as_InlineTypeBase()-&gt;clone_with_phis(phase, in(0));</span>
<span class="line-added">1880       for (uint i = 2; i &lt; req(); ++i) {</span>
<span class="line-added">1881         vt-&gt;merge_with(phase, in(i)-&gt;as_InlineTypeBase(), i, i == (req()-1));</span>
<span class="line-added">1882       }</span>
<span class="line-added">1883       return vt;</span>
<span class="line-added">1884     }</span>
<span class="line-added">1885   }</span>
<span class="line-added">1886 </span>
1887   Node *top = phase-&gt;C-&gt;top();
1888   bool new_phi = (outcnt() == 0); // transforming new Phi
1889   // No change for igvn if new phi is not hooked
1890   if (new_phi &amp;&amp; can_reshape)
1891     return NULL;
1892 
1893   // The are 2 situations when only one valid phi&#39;s input is left
1894   // (in addition to Region input).
1895   // One: region is not loop - replace phi with this input.
1896   // Two: region is loop - replace phi with top since this data path is dead
1897   //                       and we need to break the dead data loop.
1898   Node* progress = NULL;        // Record if any progress made
1899   for( uint j = 1; j &lt; req(); ++j ){ // For all paths in
1900     // Check unreachable control paths
1901     Node* rc = r-&gt;in(j);
1902     Node* n = in(j);            // Get the input
1903     if (rc == NULL || phase-&gt;type(rc) == Type::TOP) {
1904       if (n != top) {           // Not already top?
1905         PhaseIterGVN *igvn = phase-&gt;is_IterGVN();
1906         if (can_reshape &amp;&amp; igvn != NULL) {
</pre>
<hr />
<pre>
2165           for (uint i = 1; i &lt; req(); i++) {
2166             offset-&gt;init_req(i, in(i)-&gt;in(AddPNode::Offset));
2167           }
2168           phase-&gt;is_IterGVN()-&gt;register_new_node_with_optimizer(offset);
2169         }
2170         return new AddPNode(base, address, offset);
2171       }
2172     }
2173   }
2174 
2175   // Split phis through memory merges, so that the memory merges will go away.
2176   // Piggy-back this transformation on the search for a unique input....
2177   // It will be as if the merged memory is the unique value of the phi.
2178   // (Do not attempt this optimization unless parsing is complete.
2179   // It would make the parser&#39;s memory-merge logic sick.)
2180   // (MergeMemNode is not dead_loop_safe - need to check for dead loop.)
2181   if (progress == NULL &amp;&amp; can_reshape &amp;&amp; type() == Type::MEMORY) {
2182     // see if this phi should be sliced
2183     uint merge_width = 0;
2184     bool saw_self = false;
<span class="line-added">2185     // TODO revisit this with JDK-8247216</span>
<span class="line-added">2186     bool mergemem_only = true;</span>
2187     for( uint i=1; i&lt;req(); ++i ) {// For all paths in
2188       Node *ii = in(i);
2189       // TOP inputs should not be counted as safe inputs because if the
2190       // Phi references itself through all other inputs then splitting the
2191       // Phi through memory merges would create dead loop at later stage.
2192       if (ii == top) {
2193         return NULL; // Delay optimization until graph is cleaned.
2194       }
2195       if (ii-&gt;is_MergeMem()) {
2196         MergeMemNode* n = ii-&gt;as_MergeMem();
2197         merge_width = MAX2(merge_width, n-&gt;req());
2198         saw_self = saw_self || phase-&gt;eqv(n-&gt;base_memory(), this);
<span class="line-added">2199       } else {</span>
<span class="line-added">2200         mergemem_only = false;</span>
2201       }
2202     }
2203 
2204     // This restriction is temporarily necessary to ensure termination:
<span class="line-modified">2205     if (!mergemem_only &amp;&amp; !saw_self &amp;&amp; adr_type() == TypePtr::BOTTOM)  merge_width = 0;</span>
2206 
2207     if (merge_width &gt; Compile::AliasIdxRaw) {
2208       // found at least one non-empty MergeMem
2209       const TypePtr* at = adr_type();
2210       if (at != TypePtr::BOTTOM) {
2211         // Patch the existing phi to select an input from the merge:
2212         // Phi:AT1(...MergeMem(m0, m1, m2)...) into
2213         //     Phi:AT1(...m1...)
2214         int alias_idx = phase-&gt;C-&gt;get_alias_index(at);
2215         for (uint i=1; i&lt;req(); ++i) {
2216           Node *ii = in(i);
2217           if (ii-&gt;is_MergeMem()) {
2218             MergeMemNode* n = ii-&gt;as_MergeMem();
2219             // compress paths and change unreachable cycles to TOP
2220             // If not, we can update the input infinitely along a MergeMem cycle
2221             // Equivalent code is in MemNode::Ideal_common
2222             Node *m  = phase-&gt;transform(n);
2223             if (outcnt() == 0) {  // Above transform() may kill us!
2224               return top;
2225             }
</pre>
<hr />
<pre>
2614   return in(0)-&gt;in(0);
2615 }
2616 
2617 
2618 #ifndef PRODUCT
2619 void CatchProjNode::dump_spec(outputStream *st) const {
2620   ProjNode::dump_spec(st);
2621   st-&gt;print(&quot;@bci %d &quot;,_handler_bci);
2622 }
2623 #endif
2624 
2625 //=============================================================================
2626 //------------------------------Identity---------------------------------------
2627 // Check for CreateEx being Identity.
2628 Node* CreateExNode::Identity(PhaseGVN* phase) {
2629   if( phase-&gt;type(in(1)) == Type::TOP ) return in(1);
2630   if( phase-&gt;type(in(0)) == Type::TOP ) return in(0);
2631   // We only come from CatchProj, unless the CatchProj goes away.
2632   // If the CatchProj is optimized away, then we just carry the
2633   // exception oop through.
<span class="line-added">2634 </span>
<span class="line-added">2635   // CheckCastPPNode::Ideal() for inline types reuses the exception</span>
<span class="line-added">2636   // paths of a call to perform an allocation: we can see a Phi here.</span>
<span class="line-added">2637   if (in(1)-&gt;is_Phi()) {</span>
<span class="line-added">2638     return this;</span>
<span class="line-added">2639   }</span>
2640   CallNode *call = in(1)-&gt;in(0)-&gt;as_Call();
2641 
2642   return ( in(0)-&gt;is_CatchProj() &amp;&amp; in(0)-&gt;in(0)-&gt;in(1) == in(1) )
2643     ? this
2644     : call-&gt;in(TypeFunc::Parms);
2645 }
2646 
2647 //=============================================================================
2648 //------------------------------Value------------------------------------------
2649 // Check for being unreachable.
2650 const Type* NeverBranchNode::Value(PhaseGVN* phase) const {
2651   if (!in(0) || in(0)-&gt;is_top()) return Type::TOP;
2652   return bottom_type();
2653 }
2654 
2655 //------------------------------Ideal------------------------------------------
2656 // Check for no longer being part of a loop
2657 Node *NeverBranchNode::Ideal(PhaseGVN *phase, bool can_reshape) {
2658   if (can_reshape &amp;&amp; !in(0)-&gt;is_Loop()) {
2659     // Dead code elimination can sometimes delete this projection so
</pre>
</td>
</tr>
</table>
<center><a href="c2_globals.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="chaitin.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>