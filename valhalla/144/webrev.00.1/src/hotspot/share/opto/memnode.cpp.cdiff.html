<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff src/hotspot/share/opto/memnode.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="matcher.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="node.cpp.cdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/memnode.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 21,10 ***</span>
<span class="line-new-header">--- 21,11 ---</span>
   * questions.
   *
   */
  
  #include &quot;precompiled.hpp&quot;
<span class="line-added">+ #include &quot;ci/ciFlatArrayKlass.hpp&quot;</span>
  #include &quot;classfile/systemDictionary.hpp&quot;
  #include &quot;compiler/compileLog.hpp&quot;
  #include &quot;gc/shared/barrierSet.hpp&quot;
  #include &quot;gc/shared/c2/barrierSetC2.hpp&quot;
  #include &quot;memory/allocation.inline.hpp&quot;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 34,10 ***</span>
<span class="line-new-header">--- 35,11 ---</span>
  #include &quot;opto/arraycopynode.hpp&quot;
  #include &quot;opto/cfgnode.hpp&quot;
  #include &quot;opto/compile.hpp&quot;
  #include &quot;opto/connode.hpp&quot;
  #include &quot;opto/convertnode.hpp&quot;
<span class="line-added">+ #include &quot;opto/inlinetypenode.hpp&quot;</span>
  #include &quot;opto/loopnode.hpp&quot;
  #include &quot;opto/machnode.hpp&quot;
  #include &quot;opto/matcher.hpp&quot;
  #include &quot;opto/memnode.hpp&quot;
  #include &quot;opto/mulnode.hpp&quot;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 218,10 ***</span>
<span class="line-new-header">--- 220,15 ---</span>
             -&gt;is_oopptr()-&gt;cast_to_ptr_type(t_oop-&gt;ptr())
              -&gt;is_oopptr()-&gt;cast_to_instance_id(t_oop-&gt;instance_id()) == t_oop)) {
        // clone the Phi with our address type
        result = mphi-&gt;split_out_instance(t_adr, igvn);
      } else {
<span class="line-added">+       if (t-&gt;isa_aryptr()) {</span>
<span class="line-added">+         // In the case of a flattened inline type array, each field has its own slice.</span>
<span class="line-added">+         // TODO This should be re-evaluated with JDK-8251039</span>
<span class="line-added">+         t = t-&gt;is_aryptr()-&gt;with_field_offset(t_adr-&gt;is_aryptr()-&gt;field_offset().get());</span>
<span class="line-added">+       }</span>
        assert(phase-&gt;C-&gt;get_alias_index(t) == phase-&gt;C-&gt;get_alias_index(t_adr), &quot;correct memory chain&quot;);
      }
    }
    return result;
  }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 235,11 ***</span>
      assert(alias_idx &gt;= Compile::AliasIdxRaw, &quot;must not be a bad alias_idx&quot;);
      bool consistent =  adr_check == NULL || adr_check-&gt;empty() ||
                         phase-&gt;C-&gt;must_alias(adr_check, alias_idx );
      // Sometimes dead array references collapse to a[-1], a[-2], or a[-3]
      if( !consistent &amp;&amp; adr_check != NULL &amp;&amp; !adr_check-&gt;empty() &amp;&amp;
<span class="line-modified">!                tp-&gt;isa_aryptr() &amp;&amp;        tp-&gt;offset() == Type::OffsetBot &amp;&amp;</span>
          adr_check-&gt;isa_aryptr() &amp;&amp; adr_check-&gt;offset() != Type::OffsetBot &amp;&amp;
          ( adr_check-&gt;offset() == arrayOopDesc::length_offset_in_bytes() ||
            adr_check-&gt;offset() == oopDesc::klass_offset_in_bytes() ||
            adr_check-&gt;offset() == oopDesc::mark_offset_in_bytes() ) ) {
        // don&#39;t assert if it is dead code.
<span class="line-new-header">--- 242,11 ---</span>
      assert(alias_idx &gt;= Compile::AliasIdxRaw, &quot;must not be a bad alias_idx&quot;);
      bool consistent =  adr_check == NULL || adr_check-&gt;empty() ||
                         phase-&gt;C-&gt;must_alias(adr_check, alias_idx );
      // Sometimes dead array references collapse to a[-1], a[-2], or a[-3]
      if( !consistent &amp;&amp; adr_check != NULL &amp;&amp; !adr_check-&gt;empty() &amp;&amp;
<span class="line-modified">!         tp-&gt;isa_aryptr() &amp;&amp;        tp-&gt;offset() == Type::OffsetBot &amp;&amp;</span>
          adr_check-&gt;isa_aryptr() &amp;&amp; adr_check-&gt;offset() != Type::OffsetBot &amp;&amp;
          ( adr_check-&gt;offset() == arrayOopDesc::length_offset_in_bytes() ||
            adr_check-&gt;offset() == oopDesc::klass_offset_in_bytes() ||
            adr_check-&gt;offset() == oopDesc::mark_offset_in_bytes() ) ) {
        // don&#39;t assert if it is dead code.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 829,10 ***</span>
<span class="line-new-header">--- 836,11 ---</span>
    case T_SHORT:   load = new LoadSNode (ctl, mem, adr, adr_type, rt-&gt;is_int(),  mo, control_dependency); break;
    case T_LONG:    load = new LoadLNode (ctl, mem, adr, adr_type, rt-&gt;is_long(), mo, control_dependency); break;
    case T_FLOAT:   load = new LoadFNode (ctl, mem, adr, adr_type, rt,            mo, control_dependency); break;
    case T_DOUBLE:  load = new LoadDNode (ctl, mem, adr, adr_type, rt,            mo, control_dependency); break;
    case T_ADDRESS: load = new LoadPNode (ctl, mem, adr, adr_type, rt-&gt;is_ptr(),  mo, control_dependency); break;
<span class="line-added">+   case T_INLINE_TYPE:</span>
    case T_OBJECT:
  #ifdef _LP64
      if (adr-&gt;bottom_type()-&gt;is_ptr_to_narrowoop()) {
        load = new LoadNNode(ctl, mem, adr, adr_type, rt-&gt;make_narrowoop(), mo, control_dependency);
      } else
</pre>
<hr />
<pre>
<span class="line-old-header">*** 956,13 ***</span>
        assert(addp-&gt;in(AddPNode::Base) == addp-&gt;in(AddPNode::Address), &quot;should be&quot;);
        addp-&gt;set_req(AddPNode::Base, src);
        addp-&gt;set_req(AddPNode::Address, src);
  
        const TypeAryPtr* ary_t = phase-&gt;type(in(MemNode::Address))-&gt;isa_aryptr();
<span class="line-modified">!       BasicType ary_elem  = ary_t-&gt;klass()-&gt;as_array_klass()-&gt;element_type()-&gt;basic_type();</span>
        uint header = arrayOopDesc::base_offset_in_bytes(ary_elem);
        uint shift  = exact_log2(type2aelembytes(ary_elem));
  
        Node* diff = phase-&gt;transform(new SubINode(ac-&gt;in(ArrayCopyNode::SrcPos), ac-&gt;in(ArrayCopyNode::DestPos)));
  #ifdef _LP64
        diff = phase-&gt;transform(new ConvI2LNode(diff));
  #endif
<span class="line-new-header">--- 964,17 ---</span>
        assert(addp-&gt;in(AddPNode::Base) == addp-&gt;in(AddPNode::Address), &quot;should be&quot;);
        addp-&gt;set_req(AddPNode::Base, src);
        addp-&gt;set_req(AddPNode::Address, src);
  
        const TypeAryPtr* ary_t = phase-&gt;type(in(MemNode::Address))-&gt;isa_aryptr();
<span class="line-modified">!       BasicType ary_elem = ary_t-&gt;klass()-&gt;as_array_klass()-&gt;element_type()-&gt;basic_type();</span>
        uint header = arrayOopDesc::base_offset_in_bytes(ary_elem);
        uint shift  = exact_log2(type2aelembytes(ary_elem));
<span class="line-added">+       if (ary_t-&gt;klass()-&gt;is_flat_array_klass()) {</span>
<span class="line-added">+         ciFlatArrayKlass* vak = ary_t-&gt;klass()-&gt;as_flat_array_klass();</span>
<span class="line-added">+         shift = vak-&gt;log2_element_size();</span>
<span class="line-added">+       }</span>
  
        Node* diff = phase-&gt;transform(new SubINode(ac-&gt;in(ArrayCopyNode::SrcPos), ac-&gt;in(ArrayCopyNode::DestPos)));
  #ifdef _LP64
        diff = phase-&gt;transform(new ConvI2LNode(diff));
  #endif
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1086,10 ***</span>
<span class="line-new-header">--- 1098,16 ---</span>
          (ld_off &gt;= st-&gt;in(0)-&gt;as_Allocate()-&gt;minimum_header_size())) {
        // return a zero value for the load&#39;s basic type
        // (This is one of the few places where a generic PhaseTransform
        // can create new nodes.  Think of it as lazily manifesting
        // virtually pre-existing constants.)
<span class="line-added">+       assert(memory_type() != T_INLINE_TYPE, &quot;should not be used for inline types&quot;);</span>
<span class="line-added">+       Node* default_value = ld_alloc-&gt;in(AllocateNode::DefaultValue);</span>
<span class="line-added">+       if (default_value != NULL) {</span>
<span class="line-added">+         return default_value;</span>
<span class="line-added">+       }</span>
<span class="line-added">+       assert(ld_alloc-&gt;in(AllocateNode::RawDefaultValue) == NULL, &quot;default value may not be null&quot;);</span>
        return phase-&gt;zerocon(memory_type());
      }
  
      // A load from an initialization barrier can match a captured store.
      if (st-&gt;is_Proj() &amp;&amp; st-&gt;in(0)-&gt;is_Initialize()) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1143,10 ***</span>
<span class="line-new-header">--- 1161,37 ---</span>
  }
  
  //------------------------------Identity---------------------------------------
  // Loads are identity if previous store is to same address
  Node* LoadNode::Identity(PhaseGVN* phase) {
<span class="line-added">+   // Loading from an InlineTypePtr? The InlineTypePtr has the values of</span>
<span class="line-added">+   // all fields as input. Look for the field with matching offset.</span>
<span class="line-added">+   Node* addr = in(Address);</span>
<span class="line-added">+   intptr_t offset;</span>
<span class="line-added">+   Node* base = AddPNode::Ideal_base_and_offset(addr, phase, offset);</span>
<span class="line-added">+   if (base != NULL &amp;&amp; base-&gt;is_InlineTypePtr() &amp;&amp; offset &gt; oopDesc::klass_offset_in_bytes()) {</span>
<span class="line-added">+     Node* value = base-&gt;as_InlineTypePtr()-&gt;field_value_by_offset((int)offset, true);</span>
<span class="line-added">+     if (value-&gt;is_InlineType()) {</span>
<span class="line-added">+       // Non-flattened inline type field</span>
<span class="line-added">+       InlineTypeNode* vt = value-&gt;as_InlineType();</span>
<span class="line-added">+       if (vt-&gt;is_allocated(phase)) {</span>
<span class="line-added">+         value = vt-&gt;get_oop();</span>
<span class="line-added">+       } else {</span>
<span class="line-added">+         // Not yet allocated, bail out</span>
<span class="line-added">+         value = NULL;</span>
<span class="line-added">+       }</span>
<span class="line-added">+     }</span>
<span class="line-added">+     if (value != NULL) {</span>
<span class="line-added">+       if (Opcode() == Op_LoadN) {</span>
<span class="line-added">+         // Encode oop value if we are loading a narrow oop</span>
<span class="line-added">+         assert(!phase-&gt;type(value)-&gt;isa_narrowoop(), &quot;should already be decoded&quot;);</span>
<span class="line-added">+         value = phase-&gt;transform(new EncodePNode(value, bottom_type()));</span>
<span class="line-added">+       }</span>
<span class="line-added">+       return value;</span>
<span class="line-added">+     }</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
    // If the previous store-maker is the right kind of Store, and the store is
    // to the same address, then we are equal to the value stored.
    Node* mem = in(Memory);
    Node* value = can_see_stored_value(mem, phase);
    if( value ) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1700,15 ***</span>
        set_req(MemNode::Memory, prev_mem);
        return this;
      }
    }
  
<span class="line-modified">!   AllocateNode* alloc = is_new_object_mark_load(phase);</span>
<span class="line-modified">!   if (alloc != NULL &amp;&amp; alloc-&gt;Opcode() == Op_Allocate &amp;&amp; UseBiasedLocking) {</span>
      InitializeNode* init = alloc-&gt;initialization();
      Node* control = init-&gt;proj_out(0);
<span class="line-modified">!     return alloc-&gt;make_ideal_mark(phase, address, control, mem);</span>
    }
  
    return progress ? this : NULL;
  }
  
<span class="line-new-header">--- 1745,19 ---</span>
        set_req(MemNode::Memory, prev_mem);
        return this;
      }
    }
  
<span class="line-modified">!   AllocateNode* alloc = AllocateNode::Ideal_allocation(address, phase);</span>
<span class="line-modified">!   if (alloc != NULL &amp;&amp; mem-&gt;is_Proj() &amp;&amp;</span>
<span class="line-added">+       mem-&gt;in(0) != NULL &amp;&amp;</span>
<span class="line-added">+       mem-&gt;in(0) == alloc-&gt;initialization() &amp;&amp;</span>
<span class="line-added">+       Opcode() == Op_LoadX &amp;&amp;</span>
<span class="line-added">+       alloc-&gt;initialization()-&gt;proj_out_or_null(0) != NULL) {</span>
      InitializeNode* init = alloc-&gt;initialization();
      Node* control = init-&gt;proj_out(0);
<span class="line-modified">!     return alloc-&gt;make_ideal_mark(phase, control, mem);</span>
    }
  
    return progress ? this : NULL;
  }
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1796,10 ***</span>
<span class="line-new-header">--- 1845,11 ---</span>
      // In fact, that could have been the original type of p1, and p1 could have
      // had an original form like p1:(AddP x x (LShiftL quux 3)), where the
      // expression (LShiftL quux 3) independently optimized to the constant 8.
      if ((t-&gt;isa_int() == NULL) &amp;&amp; (t-&gt;isa_long() == NULL)
          &amp;&amp; (_type-&gt;isa_vect() == NULL)
<span class="line-added">+         &amp;&amp; t-&gt;isa_inlinetype() == NULL</span>
          &amp;&amp; Opcode() != Op_LoadKlass &amp;&amp; Opcode() != Op_LoadNKlass) {
        // t might actually be lower than _type, if _type is a unique
        // concrete subclass of abstract class t.
        if (off_beyond_header || off == Type::OffsetBot) {  // is the offset beyond the header?
          const Type* jt = t-&gt;join_speculative(_type);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1830,56 ***</span>
      }
    } else if (tp-&gt;base() == Type::InstPtr) {
      assert( off != Type::OffsetBot ||
              // arrays can be cast to Objects
              tp-&gt;is_oopptr()-&gt;klass()-&gt;is_java_lang_Object() ||
              // unsafe field access may not have a constant offset
              C-&gt;has_unsafe_access(),
              &quot;Field accesses must be precise&quot; );
      // For oop loads, we expect the _type to be precise.
  
<span class="line-modified">!     // Optimize loads from constant fields.</span>
      // Optimize loads from constant fields.
      ciObject* const_oop = tinst-&gt;const_oop();
      if (!is_mismatched_access() &amp;&amp; off != Type::OffsetBot &amp;&amp; const_oop != NULL &amp;&amp; const_oop-&gt;is_instance()) {
<span class="line-modified">!       const Type* con_type = Type::make_constant_from_field(const_oop-&gt;as_instance(), off, is_unsigned(), memory_type());</span>
        if (con_type != NULL) {
          return con_type;
        }
      }
    } else if (tp-&gt;base() == Type::KlassPtr) {
      assert( off != Type::OffsetBot ||
              // arrays can be cast to Objects
              tp-&gt;is_klassptr()-&gt;klass()-&gt;is_java_lang_Object() ||
              // also allow array-loading from the primary supertype
              // array during subtype checks
              Opcode() == Op_LoadKlass,
              &quot;Field accesses must be precise&quot; );
      // For klass/static loads, we expect the _type to be precise
<span class="line-modified">!   } else if (tp-&gt;base() == Type::RawPtr &amp;&amp; adr-&gt;is_Load() &amp;&amp; off == 0) {</span>
<span class="line-modified">!     /* With mirrors being an indirect in the Klass*</span>
<span class="line-modified">!      * the VM is now using two loads. LoadKlass(LoadP(LoadP(Klass, mirror_offset), zero_offset))</span>
<span class="line-modified">!      * The LoadP from the Klass has a RawPtr type (see LibraryCallKit::load_mirror_from_klass).</span>
<span class="line-modified">!      *</span>
<span class="line-modified">!      * So check the type and klass of the node before the LoadP.</span>
<span class="line-modified">!      */</span>
<span class="line-modified">!     Node* adr2 = adr-&gt;in(MemNode::Address);</span>
<span class="line-modified">!     const TypeKlassPtr* tkls = phase-&gt;type(adr2)-&gt;isa_klassptr();</span>
<span class="line-modified">!     if (tkls != NULL &amp;&amp; !StressReflectiveCode) {</span>
<span class="line-modified">!       ciKlass* klass = tkls-&gt;klass();</span>
<span class="line-modified">!       if (klass-&gt;is_loaded() &amp;&amp; tkls-&gt;klass_is_exact() &amp;&amp; tkls-&gt;offset() == in_bytes(Klass::java_mirror_offset())) {</span>
<span class="line-modified">!         assert(adr-&gt;Opcode() == Op_LoadP, &quot;must load an oop from _java_mirror&quot;);</span>
<span class="line-modified">!         assert(Opcode() == Op_LoadP, &quot;must load an oop from _java_mirror&quot;);</span>
<span class="line-modified">!         return TypeInstPtr::make(klass-&gt;java_mirror());</span>
        }
      }
    }
  
    const TypeKlassPtr *tkls = tp-&gt;isa_klassptr();
    if (tkls != NULL &amp;&amp; !StressReflectiveCode) {
      ciKlass* klass = tkls-&gt;klass();
<span class="line-modified">!     if (klass-&gt;is_loaded() &amp;&amp; tkls-&gt;klass_is_exact()) {</span>
        // We are loading a field from a Klass metaobject whose identity
        // is known at compile time (the type is &quot;exact&quot; or &quot;precise&quot;).
        // Check for fields we know are maintained as constants by the VM.
        if (tkls-&gt;offset() == in_bytes(Klass::super_check_offset_offset())) {
          // The field is Klass::_super_check_offset.  Return its (constant) value.
<span class="line-new-header">--- 1880,85 ---</span>
      }
    } else if (tp-&gt;base() == Type::InstPtr) {
      assert( off != Type::OffsetBot ||
              // arrays can be cast to Objects
              tp-&gt;is_oopptr()-&gt;klass()-&gt;is_java_lang_Object() ||
<span class="line-added">+             tp-&gt;is_oopptr()-&gt;klass() == ciEnv::current()-&gt;Class_klass() ||</span>
              // unsafe field access may not have a constant offset
              C-&gt;has_unsafe_access(),
              &quot;Field accesses must be precise&quot; );
      // For oop loads, we expect the _type to be precise.
  
<span class="line-modified">!     const TypeInstPtr* tinst = tp-&gt;is_instptr();</span>
<span class="line-added">+     BasicType bt = memory_type();</span>
<span class="line-added">+ </span>
      // Optimize loads from constant fields.
      ciObject* const_oop = tinst-&gt;const_oop();
      if (!is_mismatched_access() &amp;&amp; off != Type::OffsetBot &amp;&amp; const_oop != NULL &amp;&amp; const_oop-&gt;is_instance()) {
<span class="line-modified">!       ciType* mirror_type = const_oop-&gt;as_instance()-&gt;java_mirror_type();</span>
<span class="line-added">+       if (mirror_type != NULL &amp;&amp; mirror_type-&gt;is_inlinetype()) {</span>
<span class="line-added">+         ciInlineKlass* vk = mirror_type-&gt;as_inline_klass();</span>
<span class="line-added">+         if (off == vk-&gt;default_value_offset()) {</span>
<span class="line-added">+           // Loading a special hidden field that contains the oop of the default inline type</span>
<span class="line-added">+           const Type* const_oop = TypeInstPtr::make(vk-&gt;default_instance());</span>
<span class="line-added">+           return (bt == T_NARROWOOP) ? const_oop-&gt;make_narrowoop() : const_oop;</span>
<span class="line-added">+         }</span>
<span class="line-added">+       }</span>
<span class="line-added">+       const Type* con_type = Type::make_constant_from_field(const_oop-&gt;as_instance(), off, is_unsigned(), bt);</span>
        if (con_type != NULL) {
          return con_type;
        }
      }
    } else if (tp-&gt;base() == Type::KlassPtr) {
      assert( off != Type::OffsetBot ||
              // arrays can be cast to Objects
<span class="line-added">+             tp-&gt;is_klassptr()-&gt;klass() == NULL ||</span>
              tp-&gt;is_klassptr()-&gt;klass()-&gt;is_java_lang_Object() ||
              // also allow array-loading from the primary supertype
              // array during subtype checks
              Opcode() == Op_LoadKlass,
              &quot;Field accesses must be precise&quot; );
      // For klass/static loads, we expect the _type to be precise
<span class="line-modified">!   } else if (tp-&gt;base() == Type::RawPtr &amp;&amp; !StressReflectiveCode) {</span>
<span class="line-modified">!     if (adr-&gt;is_Load() &amp;&amp; off == 0) {</span>
<span class="line-modified">!       /* With mirrors being an indirect in the Klass*</span>
<span class="line-modified">!        * the VM is now using two loads. LoadKlass(LoadP(LoadP(Klass, mirror_offset), zero_offset))</span>
<span class="line-modified">!        * The LoadP from the Klass has a RawPtr type (see LibraryCallKit::load_mirror_from_klass).</span>
<span class="line-modified">!        *</span>
<span class="line-modified">!        * So check the type and klass of the node before the LoadP.</span>
<span class="line-modified">!        */</span>
<span class="line-modified">!       Node* adr2 = adr-&gt;in(MemNode::Address);</span>
<span class="line-modified">!       const TypeKlassPtr* tkls = phase-&gt;type(adr2)-&gt;isa_klassptr();</span>
<span class="line-modified">!       if (tkls != NULL) {</span>
<span class="line-modified">!         ciKlass* klass = tkls-&gt;klass();</span>
<span class="line-modified">!         if (klass != NULL &amp;&amp; klass-&gt;is_loaded() &amp;&amp; tkls-&gt;klass_is_exact() &amp;&amp; tkls-&gt;offset() == in_bytes(Klass::java_mirror_offset())) {</span>
<span class="line-modified">!           assert(adr-&gt;Opcode() == Op_LoadP, &quot;must load an oop from _java_mirror&quot;);</span>
<span class="line-modified">!           assert(Opcode() == Op_LoadP, &quot;must load an oop from _java_mirror&quot;);</span>
<span class="line-added">+           return TypeInstPtr::make(klass-&gt;java_mirror());</span>
<span class="line-added">+         }</span>
<span class="line-added">+       }</span>
<span class="line-added">+     } else {</span>
<span class="line-added">+       // Check for a load of the default value offset from the InlineKlassFixedBlock:</span>
<span class="line-added">+       // LoadI(LoadP(inline_klass, adr_inlineklass_fixed_block_offset), default_value_offset_offset)</span>
<span class="line-added">+       intptr_t offset = 0;</span>
<span class="line-added">+       Node* base = AddPNode::Ideal_base_and_offset(adr, phase, offset);</span>
<span class="line-added">+       if (base != NULL &amp;&amp; base-&gt;is_Load() &amp;&amp; offset == in_bytes(InlineKlass::default_value_offset_offset())) {</span>
<span class="line-added">+         const TypeKlassPtr* tkls = phase-&gt;type(base-&gt;in(MemNode::Address))-&gt;isa_klassptr();</span>
<span class="line-added">+         if (tkls != NULL &amp;&amp; tkls-&gt;is_loaded() &amp;&amp; tkls-&gt;klass_is_exact() &amp;&amp; tkls-&gt;isa_inlinetype() &amp;&amp;</span>
<span class="line-added">+             tkls-&gt;offset() == in_bytes(InstanceKlass::adr_inlineklass_fixed_block_offset())) {</span>
<span class="line-added">+           assert(base-&gt;Opcode() == Op_LoadP, &quot;must load an oop from klass&quot;);</span>
<span class="line-added">+           assert(Opcode() == Op_LoadI, &quot;must load an int from fixed block&quot;);</span>
<span class="line-added">+           return TypeInt::make(tkls-&gt;klass()-&gt;as_inline_klass()-&gt;default_value_offset());</span>
<span class="line-added">+         }</span>
        }
      }
    }
  
    const TypeKlassPtr *tkls = tp-&gt;isa_klassptr();
    if (tkls != NULL &amp;&amp; !StressReflectiveCode) {
      ciKlass* klass = tkls-&gt;klass();
<span class="line-modified">!     if (tkls-&gt;is_loaded() &amp;&amp; tkls-&gt;klass_is_exact()) {</span>
        // We are loading a field from a Klass metaobject whose identity
        // is known at compile time (the type is &quot;exact&quot; or &quot;precise&quot;).
        // Check for fields we know are maintained as constants by the VM.
        if (tkls-&gt;offset() == in_bytes(Klass::super_check_offset_offset())) {
          // The field is Klass::_super_check_offset.  Return its (constant) value.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1902,11 ***</span>
      }
  
      // We can still check if we are loading from the primary_supers array at a
      // shallow enough depth.  Even though the klass is not exact, entries less
      // than or equal to its super depth are correct.
<span class="line-modified">!     if (klass-&gt;is_loaded() ) {</span>
        ciType *inner = klass;
        while( inner-&gt;is_obj_array_klass() )
          inner = inner-&gt;as_obj_array_klass()-&gt;base_element_type();
        if( inner-&gt;is_instance_klass() &amp;&amp;
            !inner-&gt;as_instance_klass()-&gt;flags().is_interface() ) {
<span class="line-new-header">--- 1981,11 ---</span>
      }
  
      // We can still check if we are loading from the primary_supers array at a
      // shallow enough depth.  Even though the klass is not exact, entries less
      // than or equal to its super depth are correct.
<span class="line-modified">!     if (tkls-&gt;is_loaded()) {</span>
        ciType *inner = klass;
        while( inner-&gt;is_obj_array_klass() )
          inner = inner-&gt;as_obj_array_klass()-&gt;base_element_type();
        if( inner-&gt;is_instance_klass() &amp;&amp;
            !inner-&gt;as_instance_klass()-&gt;flags().is_interface() ) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2107,11 ***</span>
  }
  
  //=============================================================================
  //----------------------------LoadKlassNode::make------------------------------
  // Polymorphic factory method:
<span class="line-modified">! Node* LoadKlassNode::make(PhaseGVN&amp; gvn, Node* ctl, Node* mem, Node* adr, const TypePtr* at, const TypeKlassPtr* tk) {</span>
    // sanity check the alias category against the created node type
    const TypePtr *adr_type = adr-&gt;bottom_type()-&gt;isa_ptr();
    assert(adr_type != NULL, &quot;expecting TypeKlassPtr&quot;);
  #ifdef _LP64
    if (adr_type-&gt;is_ptr_to_narrowklass()) {
<span class="line-new-header">--- 2186,12 ---</span>
  }
  
  //=============================================================================
  //----------------------------LoadKlassNode::make------------------------------
  // Polymorphic factory method:
<span class="line-modified">! Node* LoadKlassNode::make(PhaseGVN&amp; gvn, Node* ctl, Node* mem, Node* adr, const TypePtr* at,</span>
<span class="line-added">+                           const TypeKlassPtr* tk) {</span>
    // sanity check the alias category against the created node type
    const TypePtr *adr_type = adr-&gt;bottom_type()-&gt;isa_ptr();
    assert(adr_type != NULL, &quot;expecting TypeKlassPtr&quot;);
  #ifdef _LP64
    if (adr_type-&gt;is_ptr_to_narrowklass()) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2194,65 ***</span>
          // Return precise klass
          return TypeKlassPtr::make(ik);
        }
  
        // Return root of possible klass
<span class="line-modified">!       return TypeKlassPtr::make(TypePtr::NotNull, ik, 0/*offset*/);</span>
      }
    }
  
    // Check for loading klass from an array
    const TypeAryPtr *tary = tp-&gt;isa_aryptr();
<span class="line-modified">!   if( tary != NULL ) {</span>
      ciKlass *tary_klass = tary-&gt;klass();
      if (tary_klass != NULL   // can be NULL when at BOTTOM or TOP
          &amp;&amp; tary-&gt;offset() == oopDesc::klass_offset_in_bytes()) {
        if (tary-&gt;klass_is_exact()) {
          return TypeKlassPtr::make(tary_klass);
        }
<span class="line-modified">!       ciArrayKlass *ak = tary-&gt;klass()-&gt;as_array_klass();</span>
        // If the klass is an object array, we defer the question to the
        // array component klass.
<span class="line-modified">!       if( ak-&gt;is_obj_array_klass() ) {</span>
<span class="line-modified">!         assert( ak-&gt;is_loaded(), &quot;&quot; );</span>
          ciKlass *base_k = ak-&gt;as_obj_array_klass()-&gt;base_element_klass();
<span class="line-modified">!         if( base_k-&gt;is_loaded() &amp;&amp; base_k-&gt;is_instance_klass() ) {</span>
<span class="line-modified">!           ciInstanceKlass* ik = base_k-&gt;as_instance_klass();</span>
            // See if we can become precise: no subklasses and no interface
            if (!ik-&gt;is_interface() &amp;&amp; !ik-&gt;has_subklass()) {
              // Add a dependence; if any subclass added we need to recompile
              if (!ik-&gt;is_final()) {
                phase-&gt;C-&gt;dependencies()-&gt;assert_leaf_type(ik);
              }
              // Return precise array klass
              return TypeKlassPtr::make(ak);
            }
          }
<span class="line-modified">!         return TypeKlassPtr::make(TypePtr::NotNull, ak, 0/*offset*/);</span>
<span class="line-modified">!       } else {                  // Found a type-array?</span>
<span class="line-modified">!         assert( ak-&gt;is_type_array_klass(), &quot;&quot; );</span>
          return TypeKlassPtr::make(ak); // These are always precise
        }
      }
    }
  
    // Check for loading klass from an array klass
    const TypeKlassPtr *tkls = tp-&gt;isa_klassptr();
    if (tkls != NULL &amp;&amp; !StressReflectiveCode) {
<span class="line-modified">!     ciKlass* klass = tkls-&gt;klass();</span>
<span class="line-removed">-     if( !klass-&gt;is_loaded() )</span>
        return _type;             // Bail out if not loaded
      if( klass-&gt;is_obj_array_klass() &amp;&amp;
          tkls-&gt;offset() == in_bytes(ObjArrayKlass::element_klass_offset())) {
        ciKlass* elem = klass-&gt;as_obj_array_klass()-&gt;element_klass();
        // // Always returning precise element type is incorrect,
        // // e.g., element type could be object and array may contain strings
        // return TypeKlassPtr::make(TypePtr::Constant, elem, 0);
  
        // The array&#39;s TypeKlassPtr was declared &#39;precise&#39; or &#39;not precise&#39;
        // according to the element type&#39;s subclassing.
<span class="line-modified">!       return TypeKlassPtr::make(tkls-&gt;ptr(), elem, 0/*offset*/);</span>
      }
      if( klass-&gt;is_instance_klass() &amp;&amp; tkls-&gt;klass_is_exact() &amp;&amp;
          tkls-&gt;offset() == in_bytes(Klass::super_offset())) {
        ciKlass* sup = klass-&gt;as_instance_klass()-&gt;super();
        // The field is Klass::_super.  Return its (constant) value.
<span class="line-new-header">--- 2274,70 ---</span>
          // Return precise klass
          return TypeKlassPtr::make(ik);
        }
  
        // Return root of possible klass
<span class="line-modified">!       return TypeKlassPtr::make(TypePtr::NotNull, ik, Type::Offset(0), tinst-&gt;flat_array());</span>
      }
    }
  
    // Check for loading klass from an array
    const TypeAryPtr *tary = tp-&gt;isa_aryptr();
<span class="line-modified">!   if (tary != NULL) {</span>
      ciKlass *tary_klass = tary-&gt;klass();
      if (tary_klass != NULL   // can be NULL when at BOTTOM or TOP
          &amp;&amp; tary-&gt;offset() == oopDesc::klass_offset_in_bytes()) {
        if (tary-&gt;klass_is_exact()) {
          return TypeKlassPtr::make(tary_klass);
        }
<span class="line-modified">!       ciArrayKlass* ak = tary_klass-&gt;as_array_klass();</span>
        // If the klass is an object array, we defer the question to the
        // array component klass.
<span class="line-modified">!       if (ak-&gt;is_obj_array_klass()) {</span>
<span class="line-modified">!         assert(ak-&gt;is_loaded(), &quot;&quot;);</span>
          ciKlass *base_k = ak-&gt;as_obj_array_klass()-&gt;base_element_klass();
<span class="line-modified">!         if (base_k-&gt;is_loaded() &amp;&amp; base_k-&gt;is_instance_klass()) {</span>
<span class="line-modified">!           ciInstanceKlass *ik = base_k-&gt;as_instance_klass();</span>
            // See if we can become precise: no subklasses and no interface
            if (!ik-&gt;is_interface() &amp;&amp; !ik-&gt;has_subklass()) {
              // Add a dependence; if any subclass added we need to recompile
              if (!ik-&gt;is_final()) {
                phase-&gt;C-&gt;dependencies()-&gt;assert_leaf_type(ik);
              }
              // Return precise array klass
              return TypeKlassPtr::make(ak);
            }
          }
<span class="line-modified">!         return TypeKlassPtr::make(TypePtr::NotNull, ak, Type::Offset(0), false);</span>
<span class="line-modified">!       } else if (ak-&gt;is_type_array_klass()) {</span>
<span class="line-modified">!         //assert(!UseExactTypes, &quot;this code should be useless with exact types&quot;);</span>
          return TypeKlassPtr::make(ak); // These are always precise
        }
      }
    }
  
    // Check for loading klass from an array klass
    const TypeKlassPtr *tkls = tp-&gt;isa_klassptr();
    if (tkls != NULL &amp;&amp; !StressReflectiveCode) {
<span class="line-modified">!     if (!tkls-&gt;is_loaded()) {</span>
        return _type;             // Bail out if not loaded
<span class="line-added">+     }</span>
<span class="line-added">+     ciKlass* klass = tkls-&gt;klass();</span>
      if( klass-&gt;is_obj_array_klass() &amp;&amp;
          tkls-&gt;offset() == in_bytes(ObjArrayKlass::element_klass_offset())) {
        ciKlass* elem = klass-&gt;as_obj_array_klass()-&gt;element_klass();
        // // Always returning precise element type is incorrect,
        // // e.g., element type could be object and array may contain strings
        // return TypeKlassPtr::make(TypePtr::Constant, elem, 0);
  
        // The array&#39;s TypeKlassPtr was declared &#39;precise&#39; or &#39;not precise&#39;
        // according to the element type&#39;s subclassing.
<span class="line-modified">!       return TypeKlassPtr::make(tkls-&gt;ptr(), elem, Type::Offset(0), elem-&gt;flatten_array());</span>
<span class="line-added">+     } else if (klass-&gt;is_flat_array_klass() &amp;&amp;</span>
<span class="line-added">+                tkls-&gt;offset() == in_bytes(ObjArrayKlass::element_klass_offset())) {</span>
<span class="line-added">+       ciKlass* elem = klass-&gt;as_flat_array_klass()-&gt;element_klass();</span>
<span class="line-added">+       return TypeKlassPtr::make(tkls-&gt;ptr(), elem, Type::Offset(0), /* flat_array= */ true);</span>
      }
      if( klass-&gt;is_instance_klass() &amp;&amp; tkls-&gt;klass_is_exact() &amp;&amp;
          tkls-&gt;offset() == in_bytes(Klass::super_offset())) {
        ciKlass* sup = klass-&gt;as_instance_klass()-&gt;super();
        // The field is Klass::_super.  Return its (constant) value.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2456,10 ***</span>
<span class="line-new-header">--- 2541,11 ---</span>
    case T_LONG:    return new StoreLNode(ctl, mem, adr, adr_type, val, mo);
    case T_FLOAT:   return new StoreFNode(ctl, mem, adr, adr_type, val, mo);
    case T_DOUBLE:  return new StoreDNode(ctl, mem, adr, adr_type, val, mo);
    case T_METADATA:
    case T_ADDRESS:
<span class="line-added">+   case T_INLINE_TYPE:</span>
    case T_OBJECT:
  #ifdef _LP64
      if (adr-&gt;bottom_type()-&gt;is_ptr_to_narrowoop()) {
        val = gvn.transform(new EncodePNode(val, val-&gt;bottom_type()-&gt;make_narrowoop()));
        return new StoreNNode(ctl, mem, adr, adr_type, val, mo);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2516,11 ***</span>
    Node* address = in(MemNode::Address);
    // Back-to-back stores to same address?  Fold em up.  Generally
    // unsafe if I have intervening uses...  Also disallowed for StoreCM
    // since they must follow each StoreP operation.  Redundant StoreCMs
    // are eliminated just before matching in final_graph_reshape.
<span class="line-modified">!   {</span>
      Node* st = mem;
      // If Store &#39;st&#39; has more than one use, we cannot fold &#39;st&#39; away.
      // For example, &#39;st&#39; might be the final state at a conditional
      // return.  Or, &#39;st&#39; might be used by some node which is live at
      // the same time &#39;st&#39; is live, which might be unschedulable.  So,
<span class="line-new-header">--- 2602,11 ---</span>
    Node* address = in(MemNode::Address);
    // Back-to-back stores to same address?  Fold em up.  Generally
    // unsafe if I have intervening uses...  Also disallowed for StoreCM
    // since they must follow each StoreP operation.  Redundant StoreCMs
    // are eliminated just before matching in final_graph_reshape.
<span class="line-modified">!   if (phase-&gt;C-&gt;get_adr_type(phase-&gt;C-&gt;get_alias_index(adr_type())) != TypeAryPtr::INLINES) {</span>
      Node* st = mem;
      // If Store &#39;st&#39; has more than one use, we cannot fold &#39;st&#39; away.
      // For example, &#39;st&#39; might be the final state at a conditional
      // return.  Or, &#39;st&#39; might be used by some node which is live at
      // the same time &#39;st&#39; is live, which might be unschedulable.  So,
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2534,10 ***</span>
<span class="line-new-header">--- 2620,11 ---</span>
               st-&gt;Opcode() == Op_StoreVector ||
               Opcode() == Op_StoreVector ||
               phase-&gt;C-&gt;get_alias_index(adr_type()) == Compile::AliasIdxRaw ||
               (Opcode() == Op_StoreL &amp;&amp; st-&gt;Opcode() == Op_StoreI) || // expanded ClearArrayNode
               (Opcode() == Op_StoreI &amp;&amp; st-&gt;Opcode() == Op_StoreL) || // initialization by arraycopy
<span class="line-added">+              (Opcode() == Op_StoreL &amp;&amp; st-&gt;Opcode() == Op_StoreN) ||</span>
               (is_mismatched_access() || st-&gt;as_Store()-&gt;is_mismatched_access()),
               &quot;no mismatched stores, except on raw memory: %s %s&quot;, NodeClassNames[Opcode()], NodeClassNames[st-&gt;Opcode()]);
  
        if (st-&gt;in(MemNode::Address)-&gt;eqv_uncast(address) &amp;&amp;
            st-&gt;as_Store()-&gt;memory_size() &lt;= this-&gt;memory_size()) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2619,14 ***</span>
    }
  
    // Store of zero anywhere into a freshly-allocated object?
    // Then the store is useless.
    // (It must already have been captured by the InitializeNode.)
<span class="line-modified">!   if (result == this &amp;&amp;</span>
<span class="line-removed">-       ReduceFieldZeroing &amp;&amp; phase-&gt;type(val)-&gt;is_zero_type()) {</span>
      // a newly allocated object is already all-zeroes everywhere
<span class="line-modified">!     if (mem-&gt;is_Proj() &amp;&amp; mem-&gt;in(0)-&gt;is_Allocate()) {</span>
        result = mem;
      }
  
      if (result == this) {
        // the store may also apply to zero-bits in an earlier object
<span class="line-new-header">--- 2706,15 ---</span>
    }
  
    // Store of zero anywhere into a freshly-allocated object?
    // Then the store is useless.
    // (It must already have been captured by the InitializeNode.)
<span class="line-modified">!   if (result == this &amp;&amp; ReduceFieldZeroing) {</span>
      // a newly allocated object is already all-zeroes everywhere
<span class="line-modified">!     if (mem-&gt;is_Proj() &amp;&amp; mem-&gt;in(0)-&gt;is_Allocate() &amp;&amp;</span>
<span class="line-added">+         (phase-&gt;type(val)-&gt;is_zero_type() || mem-&gt;in(0)-&gt;in(AllocateNode::DefaultValue) == val)) {</span>
<span class="line-added">+       assert(!phase-&gt;type(val)-&gt;is_zero_type() || mem-&gt;in(0)-&gt;in(AllocateNode::DefaultValue) == NULL, &quot;storing null to inline type array is forbidden&quot;);</span>
        result = mem;
      }
  
      if (result == this) {
        // the store may also apply to zero-bits in an earlier object
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2635,11 ***</span>
        if (prev_mem != NULL) {
          Node* prev_val = can_see_stored_value(prev_mem, phase);
          if (prev_val != NULL &amp;&amp; phase-&gt;eqv(prev_val, val)) {
            // prev_val and val might differ by a cast; it would be good
            // to keep the more informative of the two.
<span class="line-modified">!           result = mem;</span>
          }
        }
      }
    }
  
<span class="line-new-header">--- 2723,19 ---</span>
        if (prev_mem != NULL) {
          Node* prev_val = can_see_stored_value(prev_mem, phase);
          if (prev_val != NULL &amp;&amp; phase-&gt;eqv(prev_val, val)) {
            // prev_val and val might differ by a cast; it would be good
            // to keep the more informative of the two.
<span class="line-modified">!           if (phase-&gt;type(val)-&gt;is_zero_type()) {</span>
<span class="line-added">+             result = mem;</span>
<span class="line-added">+           } else if (prev_mem-&gt;is_Proj() &amp;&amp; prev_mem-&gt;in(0)-&gt;is_Initialize()) {</span>
<span class="line-added">+             InitializeNode* init = prev_mem-&gt;in(0)-&gt;as_Initialize();</span>
<span class="line-added">+             AllocateNode* alloc = init-&gt;allocation();</span>
<span class="line-added">+             if (alloc != NULL &amp;&amp; alloc-&gt;in(AllocateNode::DefaultValue) == val) {</span>
<span class="line-added">+               result = mem;</span>
<span class="line-added">+             }</span>
<span class="line-added">+           }</span>
          }
        }
      }
    }
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2944,11 ***</span>
    if (size &lt;= 0 || size % unit != 0)  return NULL;
    intptr_t count = size / unit;
    // Length too long; communicate this to matchers and assemblers.
    // Assemblers are responsible to produce fast hardware clears for it.
    if (size &gt; InitArrayShortSize) {
<span class="line-modified">!     return new ClearArrayNode(in(0), in(1), in(2), in(3), true);</span>
    }
    Node *mem = in(1);
    if( phase-&gt;type(mem)==Type::TOP ) return NULL;
    Node *adr = in(3);
    const Type* at = phase-&gt;type(adr);
<span class="line-new-header">--- 3040,11 ---</span>
    if (size &lt;= 0 || size % unit != 0)  return NULL;
    intptr_t count = size / unit;
    // Length too long; communicate this to matchers and assemblers.
    // Assemblers are responsible to produce fast hardware clears for it.
    if (size &gt; InitArrayShortSize) {
<span class="line-modified">!     return new ClearArrayNode(in(0), in(1), in(2), in(3), in(4), true);</span>
    }
    Node *mem = in(1);
    if( phase-&gt;type(mem)==Type::TOP ) return NULL;
    Node *adr = in(3);
    const Type* at = phase-&gt;type(adr);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2959,18 ***</span>
    else              atp = atp-&gt;add_offset(Type::OffsetBot);
    // Get base for derived pointer purposes
    if( adr-&gt;Opcode() != Op_AddP ) Unimplemented();
    Node *base = adr-&gt;in(1);
  
<span class="line-modified">!   Node *zero = phase-&gt;makecon(TypeLong::ZERO);</span>
    Node *off  = phase-&gt;MakeConX(BytesPerLong);
<span class="line-modified">!   mem = new StoreLNode(in(0),mem,adr,atp,zero,MemNode::unordered,false);</span>
    count--;
    while( count-- ) {
      mem = phase-&gt;transform(mem);
      adr = phase-&gt;transform(new AddPNode(base,adr,off));
<span class="line-modified">!     mem = new StoreLNode(in(0),mem,adr,atp,zero,MemNode::unordered,false);</span>
    }
    return mem;
  }
  
  //----------------------------step_through----------------------------------
<span class="line-new-header">--- 3055,18 ---</span>
    else              atp = atp-&gt;add_offset(Type::OffsetBot);
    // Get base for derived pointer purposes
    if( adr-&gt;Opcode() != Op_AddP ) Unimplemented();
    Node *base = adr-&gt;in(1);
  
<span class="line-modified">!   Node *val = in(4);</span>
    Node *off  = phase-&gt;MakeConX(BytesPerLong);
<span class="line-modified">!   mem = new StoreLNode(in(0), mem, adr, atp, val, MemNode::unordered, false);</span>
    count--;
    while( count-- ) {
      mem = phase-&gt;transform(mem);
      adr = phase-&gt;transform(new AddPNode(base,adr,off));
<span class="line-modified">!     mem = new StoreLNode(in(0), mem, adr, atp, val, MemNode::unordered, false);</span>
    }
    return mem;
  }
  
  //----------------------------step_through----------------------------------
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3000,31 ***</span>
  }
  
  //----------------------------clear_memory-------------------------------------
  // Generate code to initialize object storage to zero.
  Node* ClearArrayNode::clear_memory(Node* ctl, Node* mem, Node* dest,
                                     intptr_t start_offset,
                                     Node* end_offset,
                                     PhaseGVN* phase) {
    intptr_t offset = start_offset;
  
    int unit = BytesPerLong;
    if ((offset % unit) != 0) {
      Node* adr = new AddPNode(dest, dest, phase-&gt;MakeConX(offset));
      adr = phase-&gt;transform(adr);
      const TypePtr* atp = TypeRawPtr::BOTTOM;
<span class="line-modified">!     mem = StoreNode::make(*phase, ctl, mem, adr, atp, phase-&gt;zerocon(T_INT), T_INT, MemNode::unordered);</span>
      mem = phase-&gt;transform(mem);
      offset += BytesPerInt;
    }
    assert((offset % unit) == 0, &quot;&quot;);
  
    // Initialize the remaining stuff, if any, with a ClearArray.
<span class="line-modified">!   return clear_memory(ctl, mem, dest, phase-&gt;MakeConX(offset), end_offset, phase);</span>
  }
  
  Node* ClearArrayNode::clear_memory(Node* ctl, Node* mem, Node* dest,
                                     Node* start_offset,
                                     Node* end_offset,
                                     PhaseGVN* phase) {
    if (start_offset == end_offset) {
      // nothing to do
<span class="line-new-header">--- 3096,40 ---</span>
  }
  
  //----------------------------clear_memory-------------------------------------
  // Generate code to initialize object storage to zero.
  Node* ClearArrayNode::clear_memory(Node* ctl, Node* mem, Node* dest,
<span class="line-added">+                                    Node* val,</span>
<span class="line-added">+                                    Node* raw_val,</span>
                                     intptr_t start_offset,
                                     Node* end_offset,
                                     PhaseGVN* phase) {
    intptr_t offset = start_offset;
  
    int unit = BytesPerLong;
    if ((offset % unit) != 0) {
      Node* adr = new AddPNode(dest, dest, phase-&gt;MakeConX(offset));
      adr = phase-&gt;transform(adr);
      const TypePtr* atp = TypeRawPtr::BOTTOM;
<span class="line-modified">!     if (val != NULL) {</span>
<span class="line-added">+       assert(phase-&gt;type(val)-&gt;isa_narrowoop(), &quot;should be narrow oop&quot;);</span>
<span class="line-added">+       mem = new StoreNNode(ctl, mem, adr, atp, val, MemNode::unordered);</span>
<span class="line-added">+     } else {</span>
<span class="line-added">+       assert(raw_val == NULL, &quot;val may not be null&quot;);</span>
<span class="line-added">+       mem = StoreNode::make(*phase, ctl, mem, adr, atp, phase-&gt;zerocon(T_INT), T_INT, MemNode::unordered);</span>
<span class="line-added">+     }</span>
      mem = phase-&gt;transform(mem);
      offset += BytesPerInt;
    }
    assert((offset % unit) == 0, &quot;&quot;);
  
    // Initialize the remaining stuff, if any, with a ClearArray.
<span class="line-modified">!   return clear_memory(ctl, mem, dest, raw_val, phase-&gt;MakeConX(offset), end_offset, phase);</span>
  }
  
  Node* ClearArrayNode::clear_memory(Node* ctl, Node* mem, Node* dest,
<span class="line-added">+                                    Node* raw_val,</span>
                                     Node* start_offset,
                                     Node* end_offset,
                                     PhaseGVN* phase) {
    if (start_offset == end_offset) {
      // nothing to do
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3043,15 ***</span>
    }
  
    // Bulk clear double-words
    Node* zsize = phase-&gt;transform(new SubXNode(zend, zbase) );
    Node* adr = phase-&gt;transform(new AddPNode(dest, dest, start_offset) );
<span class="line-modified">!   mem = new ClearArrayNode(ctl, mem, zsize, adr, false);</span>
    return phase-&gt;transform(mem);
  }
  
  Node* ClearArrayNode::clear_memory(Node* ctl, Node* mem, Node* dest,
                                     intptr_t start_offset,
                                     intptr_t end_offset,
                                     PhaseGVN* phase) {
    if (start_offset == end_offset) {
      // nothing to do
<span class="line-new-header">--- 3148,20 ---</span>
    }
  
    // Bulk clear double-words
    Node* zsize = phase-&gt;transform(new SubXNode(zend, zbase) );
    Node* adr = phase-&gt;transform(new AddPNode(dest, dest, start_offset) );
<span class="line-modified">!   if (raw_val == NULL) {</span>
<span class="line-added">+     raw_val = phase-&gt;MakeConX(0);</span>
<span class="line-added">+   }</span>
<span class="line-added">+   mem = new ClearArrayNode(ctl, mem, zsize, adr, raw_val, false);</span>
    return phase-&gt;transform(mem);
  }
  
  Node* ClearArrayNode::clear_memory(Node* ctl, Node* mem, Node* dest,
<span class="line-added">+                                    Node* val,</span>
<span class="line-added">+                                    Node* raw_val,</span>
                                     intptr_t start_offset,
                                     intptr_t end_offset,
                                     PhaseGVN* phase) {
    if (start_offset == end_offset) {
      // nothing to do
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3062,18 ***</span>
    intptr_t done_offset = end_offset;
    if ((done_offset % BytesPerLong) != 0) {
      done_offset -= BytesPerInt;
    }
    if (done_offset &gt; start_offset) {
<span class="line-modified">!     mem = clear_memory(ctl, mem, dest,</span>
                         start_offset, phase-&gt;MakeConX(done_offset), phase);
    }
    if (done_offset &lt; end_offset) { // emit the final 32-bit store
      Node* adr = new AddPNode(dest, dest, phase-&gt;MakeConX(done_offset));
      adr = phase-&gt;transform(adr);
      const TypePtr* atp = TypeRawPtr::BOTTOM;
<span class="line-modified">!     mem = StoreNode::make(*phase, ctl, mem, adr, atp, phase-&gt;zerocon(T_INT), T_INT, MemNode::unordered);</span>
      mem = phase-&gt;transform(mem);
      done_offset += BytesPerInt;
    }
    assert(done_offset == end_offset, &quot;&quot;);
    return mem;
<span class="line-new-header">--- 3172,24 ---</span>
    intptr_t done_offset = end_offset;
    if ((done_offset % BytesPerLong) != 0) {
      done_offset -= BytesPerInt;
    }
    if (done_offset &gt; start_offset) {
<span class="line-modified">!     mem = clear_memory(ctl, mem, dest, val, raw_val,</span>
                         start_offset, phase-&gt;MakeConX(done_offset), phase);
    }
    if (done_offset &lt; end_offset) { // emit the final 32-bit store
      Node* adr = new AddPNode(dest, dest, phase-&gt;MakeConX(done_offset));
      adr = phase-&gt;transform(adr);
      const TypePtr* atp = TypeRawPtr::BOTTOM;
<span class="line-modified">!     if (val != NULL) {</span>
<span class="line-added">+       assert(phase-&gt;type(val)-&gt;isa_narrowoop(), &quot;should be narrow oop&quot;);</span>
<span class="line-added">+       mem = new StoreNNode(ctl, mem, adr, atp, val, MemNode::unordered);</span>
<span class="line-added">+     } else {</span>
<span class="line-added">+       assert(raw_val == NULL, &quot;val may not be null&quot;);</span>
<span class="line-added">+       mem = StoreNode::make(*phase, ctl, mem, adr, atp, phase-&gt;zerocon(T_INT), T_INT, MemNode::unordered);</span>
<span class="line-added">+     }</span>
      mem = phase-&gt;transform(mem);
      done_offset += BytesPerInt;
    }
    assert(done_offset == end_offset, &quot;&quot;);
    return mem;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3208,11 ***</span>
    return TypeTuple::MEMBAR;
  }
  
  //------------------------------match------------------------------------------
  // Construct projections for memory.
<span class="line-modified">! Node *MemBarNode::match( const ProjNode *proj, const Matcher *m ) {</span>
    switch (proj-&gt;_con) {
    case TypeFunc::Control:
    case TypeFunc::Memory:
      return new MachProjNode(this,proj-&gt;_con,RegMask::Empty,MachProjNode::unmatched_proj);
    }
<span class="line-new-header">--- 3324,11 ---</span>
    return TypeTuple::MEMBAR;
  }
  
  //------------------------------match------------------------------------------
  // Construct projections for memory.
<span class="line-modified">! Node *MemBarNode::match(const ProjNode *proj, const Matcher *m, const RegMask* mask) {</span>
    switch (proj-&gt;_con) {
    case TypeFunc::Control:
    case TypeFunc::Memory:
      return new MachProjNode(this,proj-&gt;_con,RegMask::Empty,MachProjNode::unmatched_proj);
    }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3494,11 ***</span>
  
  // convenience function
  // return false if the init contains any stores already
  bool AllocateNode::maybe_set_complete(PhaseGVN* phase) {
    InitializeNode* init = initialization();
<span class="line-modified">!   if (init == NULL || init-&gt;is_complete())  return false;</span>
    init-&gt;remove_extra_zeroes();
    // for now, if this allocation has already collected any inits, bail:
    if (init-&gt;is_non_zero())  return false;
    init-&gt;set_complete(phase);
    return true;
<span class="line-new-header">--- 3610,13 ---</span>
  
  // convenience function
  // return false if the init contains any stores already
  bool AllocateNode::maybe_set_complete(PhaseGVN* phase) {
    InitializeNode* init = initialization();
<span class="line-modified">!   if (init == NULL || init-&gt;is_complete()) {</span>
<span class="line-added">+     return false;</span>
<span class="line-added">+   }</span>
    init-&gt;remove_extra_zeroes();
    // for now, if this allocation has already collected any inits, bail:
    if (init-&gt;is_non_zero())  return false;
    init-&gt;set_complete(phase);
    return true;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 4252,10 ***</span>
<span class="line-new-header">--- 4370,12 ---</span>
        if (zeroes_needed &gt; zeroes_done) {
          intptr_t zsize = zeroes_needed - zeroes_done;
          // Do some incremental zeroing on rawmem, in parallel with inits.
          zeroes_done = align_down(zeroes_done, BytesPerInt);
          rawmem = ClearArrayNode::clear_memory(rawctl, rawmem, rawptr,
<span class="line-added">+                                               allocation()-&gt;in(AllocateNode::DefaultValue),</span>
<span class="line-added">+                                               allocation()-&gt;in(AllocateNode::RawDefaultValue),</span>
                                                zeroes_done, zeroes_needed,
                                                phase);
          zeroes_done = zeroes_needed;
          if (zsize &gt; InitArrayShortSize &amp;&amp; ++big_init_gaps &gt; 2)
            do_zeroing = false;   // leave the hole, next time
</pre>
<hr />
<pre>
<span class="line-old-header">*** 4311,10 ***</span>
<span class="line-new-header">--- 4431,12 ---</span>
            zeroes_done = size_limit;
        }
      }
      if (zeroes_done &lt; size_limit) {
        rawmem = ClearArrayNode::clear_memory(rawctl, rawmem, rawptr,
<span class="line-added">+                                             allocation()-&gt;in(AllocateNode::DefaultValue),</span>
<span class="line-added">+                                             allocation()-&gt;in(AllocateNode::RawDefaultValue),</span>
                                              zeroes_done, size_in_bytes, phase);
      }
    }
  
    set_complete(phase);
</pre>
<center><a href="matcher.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="node.cpp.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>