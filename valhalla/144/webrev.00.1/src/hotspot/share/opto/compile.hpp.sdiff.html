<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/compile.hpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="compile.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="escape.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/compile.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  31 #include &quot;compiler/compilerOracle.hpp&quot;
  32 #include &quot;compiler/compileBroker.hpp&quot;
  33 #include &quot;compiler/compilerEvent.hpp&quot;
  34 #include &quot;libadt/dict.hpp&quot;
  35 #include &quot;libadt/vectset.hpp&quot;
  36 #include &quot;memory/resourceArea.hpp&quot;
  37 #include &quot;oops/methodData.hpp&quot;
  38 #include &quot;opto/idealGraphPrinter.hpp&quot;
  39 #include &quot;opto/phasetype.hpp&quot;
  40 #include &quot;opto/phase.hpp&quot;
  41 #include &quot;opto/regmask.hpp&quot;
  42 #include &quot;runtime/deoptimization.hpp&quot;
  43 #include &quot;runtime/timerTrace.hpp&quot;
  44 #include &quot;runtime/vmThread.hpp&quot;
  45 #include &quot;utilities/ticks.hpp&quot;
  46 
  47 class AddPNode;
  48 class Block;
  49 class Bundle;
  50 class CallGenerator;

  51 class CloneMap;
  52 class ConnectionGraph;
  53 class IdealGraphPrinter;
  54 class InlineTree;
  55 class Int_Array;
  56 class Matcher;
  57 class MachConstantNode;
  58 class MachConstantBaseNode;
  59 class MachNode;
  60 class MachOper;
  61 class MachSafePointNode;
  62 class Node;
  63 class Node_Array;
  64 class Node_Notes;
  65 class NodeCloneInfo;
  66 class OptoReg;
  67 class PhaseCFG;
  68 class PhaseGVN;
  69 class PhaseIterGVN;
  70 class PhaseRegAlloc;
  71 class PhaseCCP;
  72 class PhaseCCP_DCE;
  73 class PhaseOutput;
  74 class RootNode;
  75 class relocInfo;
  76 class Scope;
  77 class StartNode;
  78 class SafePointNode;
  79 class JVMState;
  80 class Type;
  81 class TypeData;
  82 class TypeInt;
  83 class TypePtr;
  84 class TypeOopPtr;
  85 class TypeFunc;
  86 class TypeVect;
  87 class Unique_Node_List;

  88 class nmethod;
  89 class WarmCallInfo;
  90 class Node_Stack;
  91 struct Final_Reshape_Counts;
  92 
  93 enum LoopOptsMode {
  94   LoopOptsDefault,
  95   LoopOptsNone,
  96   LoopOptsMaxUnroll,
  97   LoopOptsShenandoahExpand,
  98   LoopOptsShenandoahPostExpand,
  99   LoopOptsSkipSplitIf,
 100   LoopOptsVerify
 101 };
 102 
 103 typedef unsigned int node_idx_t;
 104 class NodeCloneInfo {
 105  private:
 106   uint64_t _idx_clone_orig;
 107  public:
</pre>
<hr />
<pre>
 283   bool                  _do_count_invocations;  // True if we generate code to count invocations
 284   bool                  _do_method_data_update; // True if we generate code to update MethodData*s
 285   bool                  _do_vector_loop;        // True if allowed to execute loop in parallel iterations
 286   bool                  _use_cmove;             // True if CMove should be used without profitability analysis
 287   bool                  _age_code;              // True if we need to profile code age (decrement the aging counter)
 288   int                   _AliasLevel;            // Locally-adjusted version of AliasLevel flag.
 289   bool                  _print_assembly;        // True if we should dump assembly code for this compilation
 290   bool                  _print_inlining;        // True if we should print inlining for this compilation
 291   bool                  _print_intrinsics;      // True if we should print intrinsics for this compilation
 292 #ifndef PRODUCT
 293   bool                  _trace_opto_output;
 294   bool                  _print_ideal;
 295   bool                  _parsed_irreducible_loop; // True if ciTypeFlow detected irreducible loops during parsing
 296 #endif
 297   bool                  _has_irreducible_loop;  // Found irreducible loops
 298   // JSR 292
 299   bool                  _has_method_handle_invokes; // True if this method has MethodHandle invokes.
 300   RTMState              _rtm_state;             // State of Restricted Transactional Memory usage
 301   int                   _loop_opts_cnt;         // loop opts round
 302   bool                  _clinit_barrier_on_entry; // True if clinit barrier is needed on nmethod entry


 303 
 304   // Compilation environment.
 305   Arena                 _comp_arena;            // Arena with lifetime equivalent to Compile
 306   void*                 _barrier_set_state;     // Potential GC barrier state for Compile
 307   ciEnv*                _env;                   // CI interface
 308   DirectiveSet*         _directive;             // Compiler directive
 309   CompileLog*           _log;                   // from CompilerThread
 310   const char*           _failure_reason;        // for record_failure/failing pattern
 311   GrowableArray&lt;CallGenerator*&gt;* _intrinsics;   // List of intrinsics.
 312   GrowableArray&lt;Node*&gt;* _macro_nodes;           // List of nodes which need to be expanded before matching.
 313   GrowableArray&lt;Node*&gt;* _predicate_opaqs;       // List of Opaque1 nodes for the loop predicates.
 314   GrowableArray&lt;Node*&gt;* _expensive_nodes;       // List of nodes that are expensive to compute and that we&#39;d better not let the GVN freely common
 315   GrowableArray&lt;Node*&gt;* _range_check_casts;     // List of CastII nodes with a range check dependency
 316   GrowableArray&lt;Node*&gt;* _opaque4_nodes;         // List of Opaque4 nodes that have a default value

 317   ConnectionGraph*      _congraph;
 318 #ifndef PRODUCT
 319   IdealGraphPrinter*    _printer;
 320   static IdealGraphPrinter* _debug_file_printer;
 321   static IdealGraphPrinter* _debug_network_printer;
 322 #endif
 323 
 324 
 325   // Node management
 326   uint                  _unique;                // Counter for unique Node indices
 327   VectorSet             _dead_node_list;        // Set of dead nodes
 328   uint                  _dead_node_count;       // Number of dead nodes; VectorSet::Size() is O(N).
 329                                                 // So use this to keep count and make the call O(1).
 330   DEBUG_ONLY(Unique_Node_List* _modified_nodes;)   // List of nodes which inputs were modified
 331   DEBUG_ONLY(bool       _phase_optimize_finished;) // Used for live node verification while creating new nodes
 332 
 333   debug_only(static int _debug_idx;)            // Monotonic counter (not reset), use -XX:BreakAtNode=&lt;idx&gt;
 334   Arena                 _node_arena;            // Arena for new-space Nodes
 335   Arena                 _old_arena;             // Arena for old-space Nodes, lifetime during xform
 336   RootNode*             _root;                  // Unique root of compilation, or NULL after bail-out.
</pre>
<hr />
<pre>
 576   void          set_do_vector_loop(bool z)      { _do_vector_loop = z; }
 577   bool              use_cmove() const           { return _use_cmove; }
 578   void          set_use_cmove(bool z)           { _use_cmove = z; }
 579   bool              age_code() const             { return _age_code; }
 580   void          set_age_code(bool z)             { _age_code = z; }
 581   int               AliasLevel() const           { return _AliasLevel; }
 582   bool              print_assembly() const       { return _print_assembly; }
 583   void          set_print_assembly(bool z)       { _print_assembly = z; }
 584   bool              print_inlining() const       { return _print_inlining; }
 585   void          set_print_inlining(bool z)       { _print_inlining = z; }
 586   bool              print_intrinsics() const     { return _print_intrinsics; }
 587   void          set_print_intrinsics(bool z)     { _print_intrinsics = z; }
 588   RTMState          rtm_state()  const           { return _rtm_state; }
 589   void          set_rtm_state(RTMState s)        { _rtm_state = s; }
 590   bool              use_rtm() const              { return (_rtm_state &amp; NoRTM) == 0; }
 591   bool          profile_rtm() const              { return _rtm_state == ProfileRTM; }
 592   uint              max_node_limit() const       { return (uint)_max_node_limit; }
 593   void          set_max_node_limit(uint n)       { _max_node_limit = n; }
 594   bool              clinit_barrier_on_entry()       { return _clinit_barrier_on_entry; }
 595   void          set_clinit_barrier_on_entry(bool z) { _clinit_barrier_on_entry = z; }







 596 
 597   // check the CompilerOracle for special behaviours for this compile
 598   bool          method_has_option(const char * option) {
 599     return method() != NULL &amp;&amp; method()-&gt;has_option(option);
 600   }
 601 
 602 #ifndef PRODUCT
 603   bool          trace_opto_output() const       { return _trace_opto_output; }
 604   bool          print_ideal() const             { return _print_ideal; }
 605   bool              parsed_irreducible_loop() const { return _parsed_irreducible_loop; }
 606   void          set_parsed_irreducible_loop(bool z) { _parsed_irreducible_loop = z; }
 607   int _in_dump_cnt;  // Required for dumping ir nodes.
 608 #endif
 609   bool              has_irreducible_loop() const { return _has_irreducible_loop; }
 610   void          set_has_irreducible_loop(bool z) { _has_irreducible_loop = z; }
 611 
 612   // JSR 292
 613   bool              has_method_handle_invokes() const { return _has_method_handle_invokes;     }
 614   void          set_has_method_handle_invokes(bool z) {        _has_method_handle_invokes = z; }
 615 
</pre>
<hr />
<pre>
 693   void remove_range_check_cast(Node* n) {
 694     if (_range_check_casts-&gt;contains(n)) {
 695       _range_check_casts-&gt;remove(n);
 696     }
 697   }
 698   Node* range_check_cast_node(int idx) const { return _range_check_casts-&gt;at(idx);  }
 699   int   range_check_cast_count()       const { return _range_check_casts-&gt;length(); }
 700   // Remove all range check dependent CastIINodes.
 701   void  remove_range_check_casts(PhaseIterGVN &amp;igvn);
 702 
 703   void add_opaque4_node(Node* n);
 704   void remove_opaque4_node(Node* n) {
 705     if (_opaque4_nodes-&gt;contains(n)) {
 706       _opaque4_nodes-&gt;remove(n);
 707     }
 708   }
 709   Node* opaque4_node(int idx) const { return _opaque4_nodes-&gt;at(idx);  }
 710   int   opaque4_count()       const { return _opaque4_nodes-&gt;length(); }
 711   void  remove_opaque4_nodes(PhaseIterGVN &amp;igvn);
 712 







 713   void sort_macro_nodes();
 714 
 715   // remove the opaque nodes that protect the predicates so that the unused checks and
 716   // uncommon traps will be eliminated from the graph.
 717   void cleanup_loop_predicates(PhaseIterGVN &amp;igvn);
 718   bool is_predicate_opaq(Node * n) {
 719     return _predicate_opaqs-&gt;contains(n);
 720   }
 721 
 722   // Are there candidate expensive nodes for optimization?
 723   bool should_optimize_expensive_nodes(PhaseIterGVN &amp;igvn);
 724   // Check whether n1 and n2 are similar
 725   static int cmp_expensive_nodes(Node* n1, Node* n2);
 726   // Sort expensive nodes to locate similar expensive nodes
 727   void sort_expensive_nodes();
 728 
 729   // Compilation environment.
 730   Arena*      comp_arena()           { return &amp;_comp_arena; }
 731   ciEnv*      env() const            { return _env; }
 732   CompileLog* log() const            { return _log; }
</pre>
<hr />
<pre>
 833   Arena*            type_arena()                { return _type_arena; }
 834   Dict*             type_dict()                 { return _type_dict; }
 835   size_t            type_last_size()            { return _type_last_size; }
 836   int               num_alias_types()           { return _num_alias_types; }
 837 
 838   void          init_type_arena()                       { _type_arena = &amp;_Compile_types; }
 839   void          set_type_arena(Arena* a)                { _type_arena = a; }
 840   void          set_type_dict(Dict* d)                  { _type_dict = d; }
 841   void          set_type_last_size(size_t sz)           { _type_last_size = sz; }
 842 
 843   const TypeFunc* last_tf(ciMethod* m) {
 844     return (m == _last_tf_m) ? _last_tf : NULL;
 845   }
 846   void set_last_tf(ciMethod* m, const TypeFunc* tf) {
 847     assert(m != NULL || tf == NULL, &quot;&quot;);
 848     _last_tf_m = m;
 849     _last_tf = tf;
 850   }
 851 
 852   AliasType*        alias_type(int                idx)  { assert(idx &lt; num_alias_types(), &quot;oob&quot;); return _alias_types[idx]; }
<span class="line-modified"> 853   AliasType*        alias_type(const TypePtr* adr_type, ciField* field = NULL) { return find_alias_type(adr_type, false, field); }</span>
 854   bool         have_alias_type(const TypePtr* adr_type);
 855   AliasType*        alias_type(ciField*         field);
 856 
<span class="line-modified"> 857   int               get_alias_index(const TypePtr* at)  { return alias_type(at)-&gt;index(); }</span>
 858   const TypePtr*    get_adr_type(uint aidx)             { return alias_type(aidx)-&gt;adr_type(); }
 859   int               get_general_index(uint aidx)        { return alias_type(aidx)-&gt;general_index(); }
 860 
 861   // Building nodes
 862   void              rethrow_exceptions(JVMState* jvms);
 863   void              return_values(JVMState* jvms);
 864   JVMState*         build_start_state(StartNode* start, const TypeFunc* tf);
 865 
 866   // Decide how to build a call.
 867   // The profile factor is a discount to apply to this site&#39;s interp. profile.
 868   CallGenerator*    call_generator(ciMethod* call_method, int vtable_index, bool call_does_dispatch,
 869                                    JVMState* jvms, bool allow_inline, float profile_factor, ciKlass* speculative_receiver_type = NULL,
<span class="line-modified"> 870                                    bool allow_intrinsics = true);</span>
 871   bool should_delay_inlining(ciMethod* call_method, JVMState* jvms) {
 872     return should_delay_string_inlining(call_method, jvms) ||
 873            should_delay_boxing_inlining(call_method, jvms);
 874   }
 875   bool should_delay_string_inlining(ciMethod* call_method, JVMState* jvms);
 876   bool should_delay_boxing_inlining(ciMethod* call_method, JVMState* jvms);
 877 
 878   // Helper functions to identify inlining potential at call-site
 879   ciMethod* optimize_virtual_call(ciMethod* caller, int bci, ciInstanceKlass* klass,
 880                                   ciKlass* holder, ciMethod* callee,
 881                                   const TypeOopPtr* receiver_type, bool is_virtual,
 882                                   bool &amp;call_does_dispatch, int &amp;vtable_index,
 883                                   bool check_access = true);
 884   ciMethod* optimize_inlining(ciMethod* caller, int bci, ciInstanceKlass* klass,
 885                               ciMethod* callee, const TypeOopPtr* receiver_type,
 886                               bool check_access = true);
 887 
 888   // Report if there were too many traps at a current method and bci.
 889   // Report if a trap was recorded, and/or PerMethodTrapLimit was exceeded.
 890   // If there is no MDO at all, report no trap unless told to assume it.
</pre>
<hr />
<pre>
1061   uint varargs_C_out_slots_killed() const;
1062 
1063   // Number of Stack Slots consumed by a synchronization entry
1064   int sync_stack_slots() const;
1065 
1066   // Compute the name of old_SP.  See &lt;arch&gt;.ad for frame layout.
1067   OptoReg::Name compute_old_SP();
1068 
1069  private:
1070   // Phase control:
1071   void Init(int aliaslevel);                     // Prepare for a single compilation
1072   int  Inline_Warm();                            // Find more inlining work.
1073   void Finish_Warm();                            // Give up on further inlines.
1074   void Optimize();                               // Given a graph, optimize it
1075   void Code_Gen();                               // Generate code from a graph
1076 
1077   // Management of the AliasType table.
1078   void grow_alias_types();
1079   AliasCacheEntry* probe_alias_cache(const TypePtr* adr_type);
1080   const TypePtr *flatten_alias_type(const TypePtr* adr_type) const;
<span class="line-modified">1081   AliasType* find_alias_type(const TypePtr* adr_type, bool no_create, ciField* field);</span>
1082 
1083   void verify_top(Node*) const PRODUCT_RETURN;
1084 
1085   // Intrinsic setup.
1086   void           register_library_intrinsics();                            // initializer
1087   CallGenerator* make_vm_intrinsic(ciMethod* m, bool is_virtual);          // constructor
1088   int            intrinsic_insertion_index(ciMethod* m, bool is_virtual, bool&amp; found);  // helper
1089   CallGenerator* find_intrinsic(ciMethod* m, bool is_virtual);             // query fn
1090   void           register_intrinsic(CallGenerator* cg);                    // update fn
1091 
1092 #ifndef PRODUCT
1093   static juint  _intrinsic_hist_count[vmIntrinsics::ID_LIMIT];
1094   static jubyte _intrinsic_hist_flags[vmIntrinsics::ID_LIMIT];
1095 #endif
1096   // Function calls made by the public function final_graph_reshaping.
1097   // No need to be made public as they are not called elsewhere.
1098   void final_graph_reshaping_impl( Node *n, Final_Reshape_Counts &amp;frc);
1099   void final_graph_reshaping_main_switch(Node* n, Final_Reshape_Counts&amp; frc, uint nop);
1100   void final_graph_reshaping_walk( Node_Stack &amp;nstack, Node *root, Final_Reshape_Counts &amp;frc );
1101   void eliminate_redundant_card_marks(Node* n);
</pre>
<hr />
<pre>
1134   // End-of-run dumps.
1135   static void print_statistics() PRODUCT_RETURN;
1136 
1137   // Verify ADLC assumptions during startup
1138   static void adlc_verification() PRODUCT_RETURN;
1139 
1140   // Definitions of pd methods
1141   static void pd_compiler2_init();
1142 
1143   // Static parse-time type checking logic for gen_subtype_check:
1144   enum { SSC_always_false, SSC_always_true, SSC_easy_test, SSC_full_test };
1145   int static_subtype_check(ciKlass* superk, ciKlass* subk);
1146 
1147   static Node* conv_I2X_index(PhaseGVN* phase, Node* offset, const TypeInt* sizetype,
1148                               // Optional control dependency (for example, on range check)
1149                               Node* ctrl = NULL);
1150 
1151   // Convert integer value to a narrowed long type dependent on ctrl (for example, a range check)
1152   static Node* constrained_convI2L(PhaseGVN* phase, Node* value, const TypeInt* itype, Node* ctrl);
1153 


1154   // Auxiliary method for randomized fuzzing/stressing
1155   static bool randomized_select(int count);
1156 
1157   // supporting clone_map
1158   CloneMap&amp;     clone_map();
1159   void          set_clone_map(Dict* d);
1160 
1161   bool needs_clinit_barrier(ciField* ik,         ciMethod* accessing_method);
1162   bool needs_clinit_barrier(ciMethod* ik,        ciMethod* accessing_method);
1163   bool needs_clinit_barrier(ciInstanceKlass* ik, ciMethod* accessing_method);
1164 
1165 #ifdef IA32
1166  private:
1167   bool _select_24_bit_instr;   // We selected an instruction with a 24-bit result
1168   bool _in_24_bit_fp_mode;     // We are emitting instructions with 24-bit results
1169 
1170   // Remember if this compilation changes hardware mode to 24-bit precision.
1171   void set_24_bit_selection_and_mode(bool selection, bool mode) {
1172     _select_24_bit_instr = selection;
1173     _in_24_bit_fp_mode   = mode;
</pre>
</td>
<td>
<hr />
<pre>
  31 #include &quot;compiler/compilerOracle.hpp&quot;
  32 #include &quot;compiler/compileBroker.hpp&quot;
  33 #include &quot;compiler/compilerEvent.hpp&quot;
  34 #include &quot;libadt/dict.hpp&quot;
  35 #include &quot;libadt/vectset.hpp&quot;
  36 #include &quot;memory/resourceArea.hpp&quot;
  37 #include &quot;oops/methodData.hpp&quot;
  38 #include &quot;opto/idealGraphPrinter.hpp&quot;
  39 #include &quot;opto/phasetype.hpp&quot;
  40 #include &quot;opto/phase.hpp&quot;
  41 #include &quot;opto/regmask.hpp&quot;
  42 #include &quot;runtime/deoptimization.hpp&quot;
  43 #include &quot;runtime/timerTrace.hpp&quot;
  44 #include &quot;runtime/vmThread.hpp&quot;
  45 #include &quot;utilities/ticks.hpp&quot;
  46 
  47 class AddPNode;
  48 class Block;
  49 class Bundle;
  50 class CallGenerator;
<span class="line-added">  51 class CallNode;</span>
  52 class CloneMap;
  53 class ConnectionGraph;
  54 class IdealGraphPrinter;
  55 class InlineTree;
  56 class Int_Array;
  57 class Matcher;
  58 class MachConstantNode;
  59 class MachConstantBaseNode;
  60 class MachNode;
  61 class MachOper;
  62 class MachSafePointNode;
  63 class Node;
  64 class Node_Array;
  65 class Node_Notes;
  66 class NodeCloneInfo;
  67 class OptoReg;
  68 class PhaseCFG;
  69 class PhaseGVN;
  70 class PhaseIterGVN;
  71 class PhaseRegAlloc;
  72 class PhaseCCP;
  73 class PhaseCCP_DCE;
  74 class PhaseOutput;
  75 class RootNode;
  76 class relocInfo;
  77 class Scope;
  78 class StartNode;
  79 class SafePointNode;
  80 class JVMState;
  81 class Type;
  82 class TypeData;
  83 class TypeInt;
  84 class TypePtr;
  85 class TypeOopPtr;
  86 class TypeFunc;
  87 class TypeVect;
  88 class Unique_Node_List;
<span class="line-added">  89 class InlineTypeBaseNode;</span>
  90 class nmethod;
  91 class WarmCallInfo;
  92 class Node_Stack;
  93 struct Final_Reshape_Counts;
  94 
  95 enum LoopOptsMode {
  96   LoopOptsDefault,
  97   LoopOptsNone,
  98   LoopOptsMaxUnroll,
  99   LoopOptsShenandoahExpand,
 100   LoopOptsShenandoahPostExpand,
 101   LoopOptsSkipSplitIf,
 102   LoopOptsVerify
 103 };
 104 
 105 typedef unsigned int node_idx_t;
 106 class NodeCloneInfo {
 107  private:
 108   uint64_t _idx_clone_orig;
 109  public:
</pre>
<hr />
<pre>
 285   bool                  _do_count_invocations;  // True if we generate code to count invocations
 286   bool                  _do_method_data_update; // True if we generate code to update MethodData*s
 287   bool                  _do_vector_loop;        // True if allowed to execute loop in parallel iterations
 288   bool                  _use_cmove;             // True if CMove should be used without profitability analysis
 289   bool                  _age_code;              // True if we need to profile code age (decrement the aging counter)
 290   int                   _AliasLevel;            // Locally-adjusted version of AliasLevel flag.
 291   bool                  _print_assembly;        // True if we should dump assembly code for this compilation
 292   bool                  _print_inlining;        // True if we should print inlining for this compilation
 293   bool                  _print_intrinsics;      // True if we should print intrinsics for this compilation
 294 #ifndef PRODUCT
 295   bool                  _trace_opto_output;
 296   bool                  _print_ideal;
 297   bool                  _parsed_irreducible_loop; // True if ciTypeFlow detected irreducible loops during parsing
 298 #endif
 299   bool                  _has_irreducible_loop;  // Found irreducible loops
 300   // JSR 292
 301   bool                  _has_method_handle_invokes; // True if this method has MethodHandle invokes.
 302   RTMState              _rtm_state;             // State of Restricted Transactional Memory usage
 303   int                   _loop_opts_cnt;         // loop opts round
 304   bool                  _clinit_barrier_on_entry; // True if clinit barrier is needed on nmethod entry
<span class="line-added"> 305   bool                  _has_flattened_accesses; // Any known flattened array accesses?</span>
<span class="line-added"> 306   bool                  _flattened_accesses_share_alias; // Initially all flattened array share a single slice</span>
 307 
 308   // Compilation environment.
 309   Arena                 _comp_arena;            // Arena with lifetime equivalent to Compile
 310   void*                 _barrier_set_state;     // Potential GC barrier state for Compile
 311   ciEnv*                _env;                   // CI interface
 312   DirectiveSet*         _directive;             // Compiler directive
 313   CompileLog*           _log;                   // from CompilerThread
 314   const char*           _failure_reason;        // for record_failure/failing pattern
 315   GrowableArray&lt;CallGenerator*&gt;* _intrinsics;   // List of intrinsics.
 316   GrowableArray&lt;Node*&gt;* _macro_nodes;           // List of nodes which need to be expanded before matching.
 317   GrowableArray&lt;Node*&gt;* _predicate_opaqs;       // List of Opaque1 nodes for the loop predicates.
 318   GrowableArray&lt;Node*&gt;* _expensive_nodes;       // List of nodes that are expensive to compute and that we&#39;d better not let the GVN freely common
 319   GrowableArray&lt;Node*&gt;* _range_check_casts;     // List of CastII nodes with a range check dependency
 320   GrowableArray&lt;Node*&gt;* _opaque4_nodes;         // List of Opaque4 nodes that have a default value
<span class="line-added"> 321   GrowableArray&lt;Node*&gt;* _inline_type_nodes;     // List of InlineType nodes</span>
 322   ConnectionGraph*      _congraph;
 323 #ifndef PRODUCT
 324   IdealGraphPrinter*    _printer;
 325   static IdealGraphPrinter* _debug_file_printer;
 326   static IdealGraphPrinter* _debug_network_printer;
 327 #endif
 328 
 329 
 330   // Node management
 331   uint                  _unique;                // Counter for unique Node indices
 332   VectorSet             _dead_node_list;        // Set of dead nodes
 333   uint                  _dead_node_count;       // Number of dead nodes; VectorSet::Size() is O(N).
 334                                                 // So use this to keep count and make the call O(1).
 335   DEBUG_ONLY(Unique_Node_List* _modified_nodes;)   // List of nodes which inputs were modified
 336   DEBUG_ONLY(bool       _phase_optimize_finished;) // Used for live node verification while creating new nodes
 337 
 338   debug_only(static int _debug_idx;)            // Monotonic counter (not reset), use -XX:BreakAtNode=&lt;idx&gt;
 339   Arena                 _node_arena;            // Arena for new-space Nodes
 340   Arena                 _old_arena;             // Arena for old-space Nodes, lifetime during xform
 341   RootNode*             _root;                  // Unique root of compilation, or NULL after bail-out.
</pre>
<hr />
<pre>
 581   void          set_do_vector_loop(bool z)      { _do_vector_loop = z; }
 582   bool              use_cmove() const           { return _use_cmove; }
 583   void          set_use_cmove(bool z)           { _use_cmove = z; }
 584   bool              age_code() const             { return _age_code; }
 585   void          set_age_code(bool z)             { _age_code = z; }
 586   int               AliasLevel() const           { return _AliasLevel; }
 587   bool              print_assembly() const       { return _print_assembly; }
 588   void          set_print_assembly(bool z)       { _print_assembly = z; }
 589   bool              print_inlining() const       { return _print_inlining; }
 590   void          set_print_inlining(bool z)       { _print_inlining = z; }
 591   bool              print_intrinsics() const     { return _print_intrinsics; }
 592   void          set_print_intrinsics(bool z)     { _print_intrinsics = z; }
 593   RTMState          rtm_state()  const           { return _rtm_state; }
 594   void          set_rtm_state(RTMState s)        { _rtm_state = s; }
 595   bool              use_rtm() const              { return (_rtm_state &amp; NoRTM) == 0; }
 596   bool          profile_rtm() const              { return _rtm_state == ProfileRTM; }
 597   uint              max_node_limit() const       { return (uint)_max_node_limit; }
 598   void          set_max_node_limit(uint n)       { _max_node_limit = n; }
 599   bool              clinit_barrier_on_entry()       { return _clinit_barrier_on_entry; }
 600   void          set_clinit_barrier_on_entry(bool z) { _clinit_barrier_on_entry = z; }
<span class="line-added"> 601   void          set_flattened_accesses()         { _has_flattened_accesses = true; }</span>
<span class="line-added"> 602   bool          flattened_accesses_share_alias() const { return _flattened_accesses_share_alias; }</span>
<span class="line-added"> 603   void          set_flattened_accesses_share_alias(bool z) { _flattened_accesses_share_alias = z; }</span>
<span class="line-added"> 604 </span>
<span class="line-added"> 605   // Support for scalarized inline type calling convention</span>
<span class="line-added"> 606   bool              has_scalarized_args() const  { return _method != NULL &amp;&amp; _method-&gt;has_scalarized_args(); }</span>
<span class="line-added"> 607   bool              needs_stack_repair()  const  { return _method != NULL &amp;&amp; _method-&gt;get_Method()-&gt;c2_needs_stack_repair(); }</span>
 608 
 609   // check the CompilerOracle for special behaviours for this compile
 610   bool          method_has_option(const char * option) {
 611     return method() != NULL &amp;&amp; method()-&gt;has_option(option);
 612   }
 613 
 614 #ifndef PRODUCT
 615   bool          trace_opto_output() const       { return _trace_opto_output; }
 616   bool          print_ideal() const             { return _print_ideal; }
 617   bool              parsed_irreducible_loop() const { return _parsed_irreducible_loop; }
 618   void          set_parsed_irreducible_loop(bool z) { _parsed_irreducible_loop = z; }
 619   int _in_dump_cnt;  // Required for dumping ir nodes.
 620 #endif
 621   bool              has_irreducible_loop() const { return _has_irreducible_loop; }
 622   void          set_has_irreducible_loop(bool z) { _has_irreducible_loop = z; }
 623 
 624   // JSR 292
 625   bool              has_method_handle_invokes() const { return _has_method_handle_invokes;     }
 626   void          set_has_method_handle_invokes(bool z) {        _has_method_handle_invokes = z; }
 627 
</pre>
<hr />
<pre>
 705   void remove_range_check_cast(Node* n) {
 706     if (_range_check_casts-&gt;contains(n)) {
 707       _range_check_casts-&gt;remove(n);
 708     }
 709   }
 710   Node* range_check_cast_node(int idx) const { return _range_check_casts-&gt;at(idx);  }
 711   int   range_check_cast_count()       const { return _range_check_casts-&gt;length(); }
 712   // Remove all range check dependent CastIINodes.
 713   void  remove_range_check_casts(PhaseIterGVN &amp;igvn);
 714 
 715   void add_opaque4_node(Node* n);
 716   void remove_opaque4_node(Node* n) {
 717     if (_opaque4_nodes-&gt;contains(n)) {
 718       _opaque4_nodes-&gt;remove(n);
 719     }
 720   }
 721   Node* opaque4_node(int idx) const { return _opaque4_nodes-&gt;at(idx);  }
 722   int   opaque4_count()       const { return _opaque4_nodes-&gt;length(); }
 723   void  remove_opaque4_nodes(PhaseIterGVN &amp;igvn);
 724 
<span class="line-added"> 725   // Keep track of inline type nodes for later processing</span>
<span class="line-added"> 726   void add_inline_type(Node* n);</span>
<span class="line-added"> 727   void remove_inline_type(Node* n);</span>
<span class="line-added"> 728   void process_inline_types(PhaseIterGVN &amp;igvn, bool post_ea = false);</span>
<span class="line-added"> 729 </span>
<span class="line-added"> 730   void adjust_flattened_array_access_aliases(PhaseIterGVN&amp; igvn);</span>
<span class="line-added"> 731 </span>
 732   void sort_macro_nodes();
 733 
 734   // remove the opaque nodes that protect the predicates so that the unused checks and
 735   // uncommon traps will be eliminated from the graph.
 736   void cleanup_loop_predicates(PhaseIterGVN &amp;igvn);
 737   bool is_predicate_opaq(Node * n) {
 738     return _predicate_opaqs-&gt;contains(n);
 739   }
 740 
 741   // Are there candidate expensive nodes for optimization?
 742   bool should_optimize_expensive_nodes(PhaseIterGVN &amp;igvn);
 743   // Check whether n1 and n2 are similar
 744   static int cmp_expensive_nodes(Node* n1, Node* n2);
 745   // Sort expensive nodes to locate similar expensive nodes
 746   void sort_expensive_nodes();
 747 
 748   // Compilation environment.
 749   Arena*      comp_arena()           { return &amp;_comp_arena; }
 750   ciEnv*      env() const            { return _env; }
 751   CompileLog* log() const            { return _log; }
</pre>
<hr />
<pre>
 852   Arena*            type_arena()                { return _type_arena; }
 853   Dict*             type_dict()                 { return _type_dict; }
 854   size_t            type_last_size()            { return _type_last_size; }
 855   int               num_alias_types()           { return _num_alias_types; }
 856 
 857   void          init_type_arena()                       { _type_arena = &amp;_Compile_types; }
 858   void          set_type_arena(Arena* a)                { _type_arena = a; }
 859   void          set_type_dict(Dict* d)                  { _type_dict = d; }
 860   void          set_type_last_size(size_t sz)           { _type_last_size = sz; }
 861 
 862   const TypeFunc* last_tf(ciMethod* m) {
 863     return (m == _last_tf_m) ? _last_tf : NULL;
 864   }
 865   void set_last_tf(ciMethod* m, const TypeFunc* tf) {
 866     assert(m != NULL || tf == NULL, &quot;&quot;);
 867     _last_tf_m = m;
 868     _last_tf = tf;
 869   }
 870 
 871   AliasType*        alias_type(int                idx)  { assert(idx &lt; num_alias_types(), &quot;oob&quot;); return _alias_types[idx]; }
<span class="line-modified"> 872   AliasType*        alias_type(const TypePtr* adr_type, ciField* field = NULL, bool uncached = false) { return find_alias_type(adr_type, false, field, uncached); }</span>
 873   bool         have_alias_type(const TypePtr* adr_type);
 874   AliasType*        alias_type(ciField*         field);
 875 
<span class="line-modified"> 876   int               get_alias_index(const TypePtr* at, bool uncached = false) { return alias_type(at, NULL, uncached)-&gt;index(); }</span>
 877   const TypePtr*    get_adr_type(uint aidx)             { return alias_type(aidx)-&gt;adr_type(); }
 878   int               get_general_index(uint aidx)        { return alias_type(aidx)-&gt;general_index(); }
 879 
 880   // Building nodes
 881   void              rethrow_exceptions(JVMState* jvms);
 882   void              return_values(JVMState* jvms);
 883   JVMState*         build_start_state(StartNode* start, const TypeFunc* tf);
 884 
 885   // Decide how to build a call.
 886   // The profile factor is a discount to apply to this site&#39;s interp. profile.
 887   CallGenerator*    call_generator(ciMethod* call_method, int vtable_index, bool call_does_dispatch,
 888                                    JVMState* jvms, bool allow_inline, float profile_factor, ciKlass* speculative_receiver_type = NULL,
<span class="line-modified"> 889                                    bool allow_intrinsics = true, bool delayed_forbidden = false);</span>
 890   bool should_delay_inlining(ciMethod* call_method, JVMState* jvms) {
 891     return should_delay_string_inlining(call_method, jvms) ||
 892            should_delay_boxing_inlining(call_method, jvms);
 893   }
 894   bool should_delay_string_inlining(ciMethod* call_method, JVMState* jvms);
 895   bool should_delay_boxing_inlining(ciMethod* call_method, JVMState* jvms);
 896 
 897   // Helper functions to identify inlining potential at call-site
 898   ciMethod* optimize_virtual_call(ciMethod* caller, int bci, ciInstanceKlass* klass,
 899                                   ciKlass* holder, ciMethod* callee,
 900                                   const TypeOopPtr* receiver_type, bool is_virtual,
 901                                   bool &amp;call_does_dispatch, int &amp;vtable_index,
 902                                   bool check_access = true);
 903   ciMethod* optimize_inlining(ciMethod* caller, int bci, ciInstanceKlass* klass,
 904                               ciMethod* callee, const TypeOopPtr* receiver_type,
 905                               bool check_access = true);
 906 
 907   // Report if there were too many traps at a current method and bci.
 908   // Report if a trap was recorded, and/or PerMethodTrapLimit was exceeded.
 909   // If there is no MDO at all, report no trap unless told to assume it.
</pre>
<hr />
<pre>
1080   uint varargs_C_out_slots_killed() const;
1081 
1082   // Number of Stack Slots consumed by a synchronization entry
1083   int sync_stack_slots() const;
1084 
1085   // Compute the name of old_SP.  See &lt;arch&gt;.ad for frame layout.
1086   OptoReg::Name compute_old_SP();
1087 
1088  private:
1089   // Phase control:
1090   void Init(int aliaslevel);                     // Prepare for a single compilation
1091   int  Inline_Warm();                            // Find more inlining work.
1092   void Finish_Warm();                            // Give up on further inlines.
1093   void Optimize();                               // Given a graph, optimize it
1094   void Code_Gen();                               // Generate code from a graph
1095 
1096   // Management of the AliasType table.
1097   void grow_alias_types();
1098   AliasCacheEntry* probe_alias_cache(const TypePtr* adr_type);
1099   const TypePtr *flatten_alias_type(const TypePtr* adr_type) const;
<span class="line-modified">1100   AliasType* find_alias_type(const TypePtr* adr_type, bool no_create, ciField* field, bool uncached = false);</span>
1101 
1102   void verify_top(Node*) const PRODUCT_RETURN;
1103 
1104   // Intrinsic setup.
1105   void           register_library_intrinsics();                            // initializer
1106   CallGenerator* make_vm_intrinsic(ciMethod* m, bool is_virtual);          // constructor
1107   int            intrinsic_insertion_index(ciMethod* m, bool is_virtual, bool&amp; found);  // helper
1108   CallGenerator* find_intrinsic(ciMethod* m, bool is_virtual);             // query fn
1109   void           register_intrinsic(CallGenerator* cg);                    // update fn
1110 
1111 #ifndef PRODUCT
1112   static juint  _intrinsic_hist_count[vmIntrinsics::ID_LIMIT];
1113   static jubyte _intrinsic_hist_flags[vmIntrinsics::ID_LIMIT];
1114 #endif
1115   // Function calls made by the public function final_graph_reshaping.
1116   // No need to be made public as they are not called elsewhere.
1117   void final_graph_reshaping_impl( Node *n, Final_Reshape_Counts &amp;frc);
1118   void final_graph_reshaping_main_switch(Node* n, Final_Reshape_Counts&amp; frc, uint nop);
1119   void final_graph_reshaping_walk( Node_Stack &amp;nstack, Node *root, Final_Reshape_Counts &amp;frc );
1120   void eliminate_redundant_card_marks(Node* n);
</pre>
<hr />
<pre>
1153   // End-of-run dumps.
1154   static void print_statistics() PRODUCT_RETURN;
1155 
1156   // Verify ADLC assumptions during startup
1157   static void adlc_verification() PRODUCT_RETURN;
1158 
1159   // Definitions of pd methods
1160   static void pd_compiler2_init();
1161 
1162   // Static parse-time type checking logic for gen_subtype_check:
1163   enum { SSC_always_false, SSC_always_true, SSC_easy_test, SSC_full_test };
1164   int static_subtype_check(ciKlass* superk, ciKlass* subk);
1165 
1166   static Node* conv_I2X_index(PhaseGVN* phase, Node* offset, const TypeInt* sizetype,
1167                               // Optional control dependency (for example, on range check)
1168                               Node* ctrl = NULL);
1169 
1170   // Convert integer value to a narrowed long type dependent on ctrl (for example, a range check)
1171   static Node* constrained_convI2L(PhaseGVN* phase, Node* value, const TypeInt* itype, Node* ctrl);
1172 
<span class="line-added">1173   Node* optimize_acmp(PhaseGVN* phase, Node* a, Node* b);</span>
<span class="line-added">1174 </span>
1175   // Auxiliary method for randomized fuzzing/stressing
1176   static bool randomized_select(int count);
1177 
1178   // supporting clone_map
1179   CloneMap&amp;     clone_map();
1180   void          set_clone_map(Dict* d);
1181 
1182   bool needs_clinit_barrier(ciField* ik,         ciMethod* accessing_method);
1183   bool needs_clinit_barrier(ciMethod* ik,        ciMethod* accessing_method);
1184   bool needs_clinit_barrier(ciInstanceKlass* ik, ciMethod* accessing_method);
1185 
1186 #ifdef IA32
1187  private:
1188   bool _select_24_bit_instr;   // We selected an instruction with a 24-bit result
1189   bool _in_24_bit_fp_mode;     // We are emitting instructions with 24-bit results
1190 
1191   // Remember if this compilation changes hardware mode to 24-bit precision.
1192   void set_24_bit_selection_and_mode(bool selection, bool mode) {
1193     _select_24_bit_instr = selection;
1194     _in_24_bit_fp_mode   = mode;
</pre>
</td>
</tr>
</table>
<center><a href="compile.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="escape.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>