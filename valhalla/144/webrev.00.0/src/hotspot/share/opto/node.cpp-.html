<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/share/opto/node.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /*
   2  * Copyright (c) 1997, 2016, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;gc/shared/barrierSet.hpp&quot;
  27 #include &quot;gc/shared/c2/barrierSetC2.hpp&quot;
  28 #include &quot;libadt/vectset.hpp&quot;
  29 #include &quot;memory/allocation.inline.hpp&quot;
  30 #include &quot;memory/resourceArea.hpp&quot;
  31 #include &quot;opto/ad.hpp&quot;
  32 #include &quot;opto/castnode.hpp&quot;
  33 #include &quot;opto/cfgnode.hpp&quot;
  34 #include &quot;opto/connode.hpp&quot;
  35 #include &quot;opto/loopnode.hpp&quot;
  36 #include &quot;opto/machnode.hpp&quot;
  37 #include &quot;opto/matcher.hpp&quot;
  38 #include &quot;opto/node.hpp&quot;
  39 #include &quot;opto/opcodes.hpp&quot;
  40 #include &quot;opto/regmask.hpp&quot;
  41 #include &quot;opto/rootnode.hpp&quot;
  42 #include &quot;opto/type.hpp&quot;
  43 #include &quot;utilities/copy.hpp&quot;
  44 #include &quot;utilities/macros.hpp&quot;
  45 #include &quot;utilities/powerOfTwo.hpp&quot;
  46 
  47 class RegMask;
  48 // #include &quot;phase.hpp&quot;
  49 class PhaseTransform;
  50 class PhaseGVN;
  51 
  52 // Arena we are currently building Nodes in
  53 const uint Node::NotAMachineReg = 0xffff0000;
  54 
  55 #ifndef PRODUCT
  56 extern int nodes_created;
  57 #endif
  58 #ifdef __clang__
  59 #pragma clang diagnostic push
  60 #pragma GCC diagnostic ignored &quot;-Wuninitialized&quot;
  61 #endif
  62 
  63 #ifdef ASSERT
  64 
  65 //-------------------------- construct_node------------------------------------
  66 // Set a breakpoint here to identify where a particular node index is built.
  67 void Node::verify_construction() {
  68   _debug_orig = NULL;
  69   int old_debug_idx = Compile::debug_idx();
  70   int new_debug_idx = old_debug_idx+1;
  71   if (new_debug_idx &gt; 0) {
  72     // Arrange that the lowest five decimal digits of _debug_idx
  73     // will repeat those of _idx. In case this is somehow pathological,
  74     // we continue to assign negative numbers (!) consecutively.
  75     const int mod = 100000;
  76     int bump = (int)(_idx - new_debug_idx) % mod;
  77     if (bump &lt; 0)  bump += mod;
  78     assert(bump &gt;= 0 &amp;&amp; bump &lt; mod, &quot;&quot;);
  79     new_debug_idx += bump;
  80   }
  81   Compile::set_debug_idx(new_debug_idx);
  82   set_debug_idx( new_debug_idx );
  83   assert(Compile::current()-&gt;unique() &lt; (INT_MAX - 1), &quot;Node limit exceeded INT_MAX&quot;);
  84   assert(Compile::current()-&gt;live_nodes() &lt; Compile::current()-&gt;max_node_limit(), &quot;Live Node limit exceeded limit&quot;);
  85   if (BreakAtNode != 0 &amp;&amp; (_debug_idx == BreakAtNode || (int)_idx == BreakAtNode)) {
  86     tty-&gt;print_cr(&quot;BreakAtNode: _idx=%d _debug_idx=%d&quot;, _idx, _debug_idx);
  87     BREAKPOINT;
  88   }
  89 #if OPTO_DU_ITERATOR_ASSERT
  90   _last_del = NULL;
  91   _del_tick = 0;
  92 #endif
  93   _hash_lock = 0;
  94 }
  95 
  96 
  97 // #ifdef ASSERT ...
  98 
  99 #if OPTO_DU_ITERATOR_ASSERT
 100 void DUIterator_Common::sample(const Node* node) {
 101   _vdui     = VerifyDUIterators;
 102   _node     = node;
 103   _outcnt   = node-&gt;_outcnt;
 104   _del_tick = node-&gt;_del_tick;
 105   _last     = NULL;
 106 }
 107 
 108 void DUIterator_Common::verify(const Node* node, bool at_end_ok) {
 109   assert(_node     == node, &quot;consistent iterator source&quot;);
 110   assert(_del_tick == node-&gt;_del_tick, &quot;no unexpected deletions allowed&quot;);
 111 }
 112 
 113 void DUIterator_Common::verify_resync() {
 114   // Ensure that the loop body has just deleted the last guy produced.
 115   const Node* node = _node;
 116   // Ensure that at least one copy of the last-seen edge was deleted.
 117   // Note:  It is OK to delete multiple copies of the last-seen edge.
 118   // Unfortunately, we have no way to verify that all the deletions delete
 119   // that same edge.  On this point we must use the Honor System.
 120   assert(node-&gt;_del_tick &gt;= _del_tick+1, &quot;must have deleted an edge&quot;);
 121   assert(node-&gt;_last_del == _last, &quot;must have deleted the edge just produced&quot;);
 122   // We liked this deletion, so accept the resulting outcnt and tick.
 123   _outcnt   = node-&gt;_outcnt;
 124   _del_tick = node-&gt;_del_tick;
 125 }
 126 
 127 void DUIterator_Common::reset(const DUIterator_Common&amp; that) {
 128   if (this == &amp;that)  return;  // ignore assignment to self
 129   if (!_vdui) {
 130     // We need to initialize everything, overwriting garbage values.
 131     _last = that._last;
 132     _vdui = that._vdui;
 133   }
 134   // Note:  It is legal (though odd) for an iterator over some node x
 135   // to be reassigned to iterate over another node y.  Some doubly-nested
 136   // progress loops depend on being able to do this.
 137   const Node* node = that._node;
 138   // Re-initialize everything, except _last.
 139   _node     = node;
 140   _outcnt   = node-&gt;_outcnt;
 141   _del_tick = node-&gt;_del_tick;
 142 }
 143 
 144 void DUIterator::sample(const Node* node) {
 145   DUIterator_Common::sample(node);      // Initialize the assertion data.
 146   _refresh_tick = 0;                    // No refreshes have happened, as yet.
 147 }
 148 
 149 void DUIterator::verify(const Node* node, bool at_end_ok) {
 150   DUIterator_Common::verify(node, at_end_ok);
 151   assert(_idx      &lt;  node-&gt;_outcnt + (uint)at_end_ok, &quot;idx in range&quot;);
 152 }
 153 
 154 void DUIterator::verify_increment() {
 155   if (_refresh_tick &amp; 1) {
 156     // We have refreshed the index during this loop.
 157     // Fix up _idx to meet asserts.
 158     if (_idx &gt; _outcnt)  _idx = _outcnt;
 159   }
 160   verify(_node, true);
 161 }
 162 
 163 void DUIterator::verify_resync() {
 164   // Note:  We do not assert on _outcnt, because insertions are OK here.
 165   DUIterator_Common::verify_resync();
 166   // Make sure we are still in sync, possibly with no more out-edges:
 167   verify(_node, true);
 168 }
 169 
 170 void DUIterator::reset(const DUIterator&amp; that) {
 171   if (this == &amp;that)  return;  // self assignment is always a no-op
 172   assert(that._refresh_tick == 0, &quot;assign only the result of Node::outs()&quot;);
 173   assert(that._idx          == 0, &quot;assign only the result of Node::outs()&quot;);
 174   assert(_idx               == that._idx, &quot;already assigned _idx&quot;);
 175   if (!_vdui) {
 176     // We need to initialize everything, overwriting garbage values.
 177     sample(that._node);
 178   } else {
 179     DUIterator_Common::reset(that);
 180     if (_refresh_tick &amp; 1) {
 181       _refresh_tick++;                  // Clear the &quot;was refreshed&quot; flag.
 182     }
 183     assert(_refresh_tick &lt; 2*100000, &quot;DU iteration must converge quickly&quot;);
 184   }
 185 }
 186 
 187 void DUIterator::refresh() {
 188   DUIterator_Common::sample(_node);     // Re-fetch assertion data.
 189   _refresh_tick |= 1;                   // Set the &quot;was refreshed&quot; flag.
 190 }
 191 
 192 void DUIterator::verify_finish() {
 193   // If the loop has killed the node, do not require it to re-run.
 194   if (_node-&gt;_outcnt == 0)  _refresh_tick &amp;= ~1;
 195   // If this assert triggers, it means that a loop used refresh_out_pos
 196   // to re-synch an iteration index, but the loop did not correctly
 197   // re-run itself, using a &quot;while (progress)&quot; construct.
 198   // This iterator enforces the rule that you must keep trying the loop
 199   // until it &quot;runs clean&quot; without any need for refreshing.
 200   assert(!(_refresh_tick &amp; 1), &quot;the loop must run once with no refreshing&quot;);
 201 }
 202 
 203 
 204 void DUIterator_Fast::verify(const Node* node, bool at_end_ok) {
 205   DUIterator_Common::verify(node, at_end_ok);
 206   Node** out    = node-&gt;_out;
 207   uint   cnt    = node-&gt;_outcnt;
 208   assert(cnt == _outcnt, &quot;no insertions allowed&quot;);
 209   assert(_outp &gt;= out &amp;&amp; _outp &lt;= out + cnt - !at_end_ok, &quot;outp in range&quot;);
 210   // This last check is carefully designed to work for NO_OUT_ARRAY.
 211 }
 212 
 213 void DUIterator_Fast::verify_limit() {
 214   const Node* node = _node;
 215   verify(node, true);
 216   assert(_outp == node-&gt;_out + node-&gt;_outcnt, &quot;limit still correct&quot;);
 217 }
 218 
 219 void DUIterator_Fast::verify_resync() {
 220   const Node* node = _node;
 221   if (_outp == node-&gt;_out + _outcnt) {
 222     // Note that the limit imax, not the pointer i, gets updated with the
 223     // exact count of deletions.  (For the pointer it&#39;s always &quot;--i&quot;.)
 224     assert(node-&gt;_outcnt+node-&gt;_del_tick == _outcnt+_del_tick, &quot;no insertions allowed with deletion(s)&quot;);
 225     // This is a limit pointer, with a name like &quot;imax&quot;.
 226     // Fudge the _last field so that the common assert will be happy.
 227     _last = (Node*) node-&gt;_last_del;
 228     DUIterator_Common::verify_resync();
 229   } else {
 230     assert(node-&gt;_outcnt &lt; _outcnt, &quot;no insertions allowed with deletion(s)&quot;);
 231     // A normal internal pointer.
 232     DUIterator_Common::verify_resync();
 233     // Make sure we are still in sync, possibly with no more out-edges:
 234     verify(node, true);
 235   }
 236 }
 237 
 238 void DUIterator_Fast::verify_relimit(uint n) {
 239   const Node* node = _node;
 240   assert((int)n &gt; 0, &quot;use imax -= n only with a positive count&quot;);
 241   // This must be a limit pointer, with a name like &quot;imax&quot;.
 242   assert(_outp == node-&gt;_out + node-&gt;_outcnt, &quot;apply -= only to a limit (imax)&quot;);
 243   // The reported number of deletions must match what the node saw.
 244   assert(node-&gt;_del_tick == _del_tick + n, &quot;must have deleted n edges&quot;);
 245   // Fudge the _last field so that the common assert will be happy.
 246   _last = (Node*) node-&gt;_last_del;
 247   DUIterator_Common::verify_resync();
 248 }
 249 
 250 void DUIterator_Fast::reset(const DUIterator_Fast&amp; that) {
 251   assert(_outp              == that._outp, &quot;already assigned _outp&quot;);
 252   DUIterator_Common::reset(that);
 253 }
 254 
 255 void DUIterator_Last::verify(const Node* node, bool at_end_ok) {
 256   // at_end_ok means the _outp is allowed to underflow by 1
 257   _outp += at_end_ok;
 258   DUIterator_Fast::verify(node, at_end_ok);  // check _del_tick, etc.
 259   _outp -= at_end_ok;
 260   assert(_outp == (node-&gt;_out + node-&gt;_outcnt) - 1, &quot;pointer must point to end of nodes&quot;);
 261 }
 262 
 263 void DUIterator_Last::verify_limit() {
 264   // Do not require the limit address to be resynched.
 265   //verify(node, true);
 266   assert(_outp == _node-&gt;_out, &quot;limit still correct&quot;);
 267 }
 268 
 269 void DUIterator_Last::verify_step(uint num_edges) {
 270   assert((int)num_edges &gt; 0, &quot;need non-zero edge count for loop progress&quot;);
 271   _outcnt   -= num_edges;
 272   _del_tick += num_edges;
 273   // Make sure we are still in sync, possibly with no more out-edges:
 274   const Node* node = _node;
 275   verify(node, true);
 276   assert(node-&gt;_last_del == _last, &quot;must have deleted the edge just produced&quot;);
 277 }
 278 
 279 #endif //OPTO_DU_ITERATOR_ASSERT
 280 
 281 
 282 #endif //ASSERT
 283 
 284 
 285 // This constant used to initialize _out may be any non-null value.
 286 // The value NULL is reserved for the top node only.
 287 #define NO_OUT_ARRAY ((Node**)-1)
 288 
 289 // Out-of-line code from node constructors.
 290 // Executed only when extra debug info. is being passed around.
 291 static void init_node_notes(Compile* C, int idx, Node_Notes* nn) {
 292   C-&gt;set_node_notes_at(idx, nn);
 293 }
 294 
 295 // Shared initialization code.
 296 inline int Node::Init(int req) {
 297   Compile* C = Compile::current();
 298   int idx = C-&gt;next_unique();
 299 
 300   // Allocate memory for the necessary number of edges.
 301   if (req &gt; 0) {
 302     // Allocate space for _in array to have double alignment.
 303     _in = (Node **) ((char *) (C-&gt;node_arena()-&gt;Amalloc_D(req * sizeof(void*))));
 304   }
 305   // If there are default notes floating around, capture them:
 306   Node_Notes* nn = C-&gt;default_node_notes();
 307   if (nn != NULL)  init_node_notes(C, idx, nn);
 308 
 309   // Note:  At this point, C is dead,
 310   // and we begin to initialize the new Node.
 311 
 312   _cnt = _max = req;
 313   _outcnt = _outmax = 0;
 314   _class_id = Class_Node;
 315   _flags = 0;
 316   _out = NO_OUT_ARRAY;
 317   return idx;
 318 }
 319 
 320 //------------------------------Node-------------------------------------------
 321 // Create a Node, with a given number of required edges.
 322 Node::Node(uint req)
 323   : _idx(Init(req))
 324 #ifdef ASSERT
 325   , _parse_idx(_idx)
 326 #endif
 327 {
 328   assert( req &lt; Compile::current()-&gt;max_node_limit() - NodeLimitFudgeFactor, &quot;Input limit exceeded&quot; );
 329   debug_only( verify_construction() );
 330   NOT_PRODUCT(nodes_created++);
 331   if (req == 0) {
 332     _in = NULL;
 333   } else {
 334     Node** to = _in;
 335     for(uint i = 0; i &lt; req; i++) {
 336       to[i] = NULL;
 337     }
 338   }
 339 }
 340 
 341 //------------------------------Node-------------------------------------------
 342 Node::Node(Node *n0)
 343   : _idx(Init(1))
 344 #ifdef ASSERT
 345   , _parse_idx(_idx)
 346 #endif
 347 {
 348   debug_only( verify_construction() );
 349   NOT_PRODUCT(nodes_created++);
 350   assert( is_not_dead(n0), &quot;can not use dead node&quot;);
 351   _in[0] = n0; if (n0 != NULL) n0-&gt;add_out((Node *)this);
 352 }
 353 
 354 //------------------------------Node-------------------------------------------
 355 Node::Node(Node *n0, Node *n1)
 356   : _idx(Init(2))
 357 #ifdef ASSERT
 358   , _parse_idx(_idx)
 359 #endif
 360 {
 361   debug_only( verify_construction() );
 362   NOT_PRODUCT(nodes_created++);
 363   assert( is_not_dead(n0), &quot;can not use dead node&quot;);
 364   assert( is_not_dead(n1), &quot;can not use dead node&quot;);
 365   _in[0] = n0; if (n0 != NULL) n0-&gt;add_out((Node *)this);
 366   _in[1] = n1; if (n1 != NULL) n1-&gt;add_out((Node *)this);
 367 }
 368 
 369 //------------------------------Node-------------------------------------------
 370 Node::Node(Node *n0, Node *n1, Node *n2)
 371   : _idx(Init(3))
 372 #ifdef ASSERT
 373   , _parse_idx(_idx)
 374 #endif
 375 {
 376   debug_only( verify_construction() );
 377   NOT_PRODUCT(nodes_created++);
 378   assert( is_not_dead(n0), &quot;can not use dead node&quot;);
 379   assert( is_not_dead(n1), &quot;can not use dead node&quot;);
 380   assert( is_not_dead(n2), &quot;can not use dead node&quot;);
 381   _in[0] = n0; if (n0 != NULL) n0-&gt;add_out((Node *)this);
 382   _in[1] = n1; if (n1 != NULL) n1-&gt;add_out((Node *)this);
 383   _in[2] = n2; if (n2 != NULL) n2-&gt;add_out((Node *)this);
 384 }
 385 
 386 //------------------------------Node-------------------------------------------
 387 Node::Node(Node *n0, Node *n1, Node *n2, Node *n3)
 388   : _idx(Init(4))
 389 #ifdef ASSERT
 390   , _parse_idx(_idx)
 391 #endif
 392 {
 393   debug_only( verify_construction() );
 394   NOT_PRODUCT(nodes_created++);
 395   assert( is_not_dead(n0), &quot;can not use dead node&quot;);
 396   assert( is_not_dead(n1), &quot;can not use dead node&quot;);
 397   assert( is_not_dead(n2), &quot;can not use dead node&quot;);
 398   assert( is_not_dead(n3), &quot;can not use dead node&quot;);
 399   _in[0] = n0; if (n0 != NULL) n0-&gt;add_out((Node *)this);
 400   _in[1] = n1; if (n1 != NULL) n1-&gt;add_out((Node *)this);
 401   _in[2] = n2; if (n2 != NULL) n2-&gt;add_out((Node *)this);
 402   _in[3] = n3; if (n3 != NULL) n3-&gt;add_out((Node *)this);
 403 }
 404 
 405 //------------------------------Node-------------------------------------------
 406 Node::Node(Node *n0, Node *n1, Node *n2, Node *n3, Node *n4)
 407   : _idx(Init(5))
 408 #ifdef ASSERT
 409   , _parse_idx(_idx)
 410 #endif
 411 {
 412   debug_only( verify_construction() );
 413   NOT_PRODUCT(nodes_created++);
 414   assert( is_not_dead(n0), &quot;can not use dead node&quot;);
 415   assert( is_not_dead(n1), &quot;can not use dead node&quot;);
 416   assert( is_not_dead(n2), &quot;can not use dead node&quot;);
 417   assert( is_not_dead(n3), &quot;can not use dead node&quot;);
 418   assert( is_not_dead(n4), &quot;can not use dead node&quot;);
 419   _in[0] = n0; if (n0 != NULL) n0-&gt;add_out((Node *)this);
 420   _in[1] = n1; if (n1 != NULL) n1-&gt;add_out((Node *)this);
 421   _in[2] = n2; if (n2 != NULL) n2-&gt;add_out((Node *)this);
 422   _in[3] = n3; if (n3 != NULL) n3-&gt;add_out((Node *)this);
 423   _in[4] = n4; if (n4 != NULL) n4-&gt;add_out((Node *)this);
 424 }
 425 
 426 //------------------------------Node-------------------------------------------
 427 Node::Node(Node *n0, Node *n1, Node *n2, Node *n3,
 428                      Node *n4, Node *n5)
 429   : _idx(Init(6))
 430 #ifdef ASSERT
 431   , _parse_idx(_idx)
 432 #endif
 433 {
 434   debug_only( verify_construction() );
 435   NOT_PRODUCT(nodes_created++);
 436   assert( is_not_dead(n0), &quot;can not use dead node&quot;);
 437   assert( is_not_dead(n1), &quot;can not use dead node&quot;);
 438   assert( is_not_dead(n2), &quot;can not use dead node&quot;);
 439   assert( is_not_dead(n3), &quot;can not use dead node&quot;);
 440   assert( is_not_dead(n4), &quot;can not use dead node&quot;);
 441   assert( is_not_dead(n5), &quot;can not use dead node&quot;);
 442   _in[0] = n0; if (n0 != NULL) n0-&gt;add_out((Node *)this);
 443   _in[1] = n1; if (n1 != NULL) n1-&gt;add_out((Node *)this);
 444   _in[2] = n2; if (n2 != NULL) n2-&gt;add_out((Node *)this);
 445   _in[3] = n3; if (n3 != NULL) n3-&gt;add_out((Node *)this);
 446   _in[4] = n4; if (n4 != NULL) n4-&gt;add_out((Node *)this);
 447   _in[5] = n5; if (n5 != NULL) n5-&gt;add_out((Node *)this);
 448 }
 449 
 450 //------------------------------Node-------------------------------------------
 451 Node::Node(Node *n0, Node *n1, Node *n2, Node *n3,
 452                      Node *n4, Node *n5, Node *n6)
 453   : _idx(Init(7))
 454 #ifdef ASSERT
 455   , _parse_idx(_idx)
 456 #endif
 457 {
 458   debug_only( verify_construction() );
 459   NOT_PRODUCT(nodes_created++);
 460   assert( is_not_dead(n0), &quot;can not use dead node&quot;);
 461   assert( is_not_dead(n1), &quot;can not use dead node&quot;);
 462   assert( is_not_dead(n2), &quot;can not use dead node&quot;);
 463   assert( is_not_dead(n3), &quot;can not use dead node&quot;);
 464   assert( is_not_dead(n4), &quot;can not use dead node&quot;);
 465   assert( is_not_dead(n5), &quot;can not use dead node&quot;);
 466   assert( is_not_dead(n6), &quot;can not use dead node&quot;);
 467   _in[0] = n0; if (n0 != NULL) n0-&gt;add_out((Node *)this);
 468   _in[1] = n1; if (n1 != NULL) n1-&gt;add_out((Node *)this);
 469   _in[2] = n2; if (n2 != NULL) n2-&gt;add_out((Node *)this);
 470   _in[3] = n3; if (n3 != NULL) n3-&gt;add_out((Node *)this);
 471   _in[4] = n4; if (n4 != NULL) n4-&gt;add_out((Node *)this);
 472   _in[5] = n5; if (n5 != NULL) n5-&gt;add_out((Node *)this);
 473   _in[6] = n6; if (n6 != NULL) n6-&gt;add_out((Node *)this);
 474 }
 475 
 476 #ifdef __clang__
 477 #pragma clang diagnostic pop
 478 #endif
 479 
 480 
 481 //------------------------------clone------------------------------------------
 482 // Clone a Node.
 483 Node *Node::clone() const {
 484   Compile* C = Compile::current();
 485   uint s = size_of();           // Size of inherited Node
 486   Node *n = (Node*)C-&gt;node_arena()-&gt;Amalloc_D(size_of() + _max*sizeof(Node*));
 487   Copy::conjoint_words_to_lower((HeapWord*)this, (HeapWord*)n, s);
 488   // Set the new input pointer array
 489   n-&gt;_in = (Node**)(((char*)n)+s);
 490   // Cannot share the old output pointer array, so kill it
 491   n-&gt;_out = NO_OUT_ARRAY;
 492   // And reset the counters to 0
 493   n-&gt;_outcnt = 0;
 494   n-&gt;_outmax = 0;
 495   // Unlock this guy, since he is not in any hash table.
 496   debug_only(n-&gt;_hash_lock = 0);
 497   // Walk the old node&#39;s input list to duplicate its edges
 498   uint i;
 499   for( i = 0; i &lt; len(); i++ ) {
 500     Node *x = in(i);
 501     n-&gt;_in[i] = x;
 502     if (x != NULL) x-&gt;add_out(n);
 503   }
 504   if (is_macro())
 505     C-&gt;add_macro_node(n);
 506   if (is_expensive())
 507     C-&gt;add_expensive_node(n);
 508   BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
 509   bs-&gt;register_potential_barrier_node(n);
 510   // If the cloned node is a range check dependent CastII, add it to the list.
 511   CastIINode* cast = n-&gt;isa_CastII();
 512   if (cast != NULL &amp;&amp; cast-&gt;has_range_check()) {
 513     C-&gt;add_range_check_cast(cast);
 514   }
 515   if (n-&gt;Opcode() == Op_Opaque4) {
 516     C-&gt;add_opaque4_node(n);
 517   }
 518 
 519   n-&gt;set_idx(C-&gt;next_unique()); // Get new unique index as well
 520   debug_only( n-&gt;verify_construction() );
 521   NOT_PRODUCT(nodes_created++);
 522   // Do not patch over the debug_idx of a clone, because it makes it
 523   // impossible to break on the clone&#39;s moment of creation.
 524   //debug_only( n-&gt;set_debug_idx( debug_idx() ) );
 525 
 526   C-&gt;copy_node_notes_to(n, (Node*) this);
 527 
 528   // MachNode clone
 529   uint nopnds;
 530   if (this-&gt;is_Mach() &amp;&amp; (nopnds = this-&gt;as_Mach()-&gt;num_opnds()) &gt; 0) {
 531     MachNode *mach  = n-&gt;as_Mach();
 532     MachNode *mthis = this-&gt;as_Mach();
 533     // Get address of _opnd_array.
 534     // It should be the same offset since it is the clone of this node.
 535     MachOper **from = mthis-&gt;_opnds;
 536     MachOper **to = (MachOper **)((size_t)(&amp;mach-&gt;_opnds) +
 537                     pointer_delta((const void*)from,
 538                                   (const void*)(&amp;mthis-&gt;_opnds), 1));
 539     mach-&gt;_opnds = to;
 540     for ( uint i = 0; i &lt; nopnds; ++i ) {
 541       to[i] = from[i]-&gt;clone();
 542     }
 543   }
 544   // cloning CallNode may need to clone JVMState
 545   if (n-&gt;is_Call()) {
 546     n-&gt;as_Call()-&gt;clone_jvms(C);
 547   }
 548   if (n-&gt;is_SafePoint()) {
 549     n-&gt;as_SafePoint()-&gt;clone_replaced_nodes();
 550   }
 551   if (n-&gt;is_InlineTypeBase()) {
 552     C-&gt;add_inline_type(n);
 553   }
 554   return n;                     // Return the clone
 555 }
 556 
 557 //---------------------------setup_is_top--------------------------------------
 558 // Call this when changing the top node, to reassert the invariants
 559 // required by Node::is_top.  See Compile::set_cached_top_node.
 560 void Node::setup_is_top() {
 561   if (this == (Node*)Compile::current()-&gt;top()) {
 562     // This node has just become top.  Kill its out array.
 563     _outcnt = _outmax = 0;
 564     _out = NULL;                           // marker value for top
 565     assert(is_top(), &quot;must be top&quot;);
 566   } else {
 567     if (_out == NULL)  _out = NO_OUT_ARRAY;
 568     assert(!is_top(), &quot;must not be top&quot;);
 569   }
 570 }
 571 
 572 //------------------------------~Node------------------------------------------
 573 // Fancy destructor; eagerly attempt to reclaim Node numberings and storage
 574 void Node::destruct() {
 575   // Eagerly reclaim unique Node numberings
 576   Compile* compile = Compile::current();
 577   if ((uint)_idx+1 == compile-&gt;unique()) {
 578     compile-&gt;set_unique(compile-&gt;unique()-1);
 579   }
 580   // Clear debug info:
 581   Node_Notes* nn = compile-&gt;node_notes_at(_idx);
 582   if (nn != NULL)  nn-&gt;clear();
 583   // Walk the input array, freeing the corresponding output edges
 584   _cnt = _max;  // forget req/prec distinction
 585   uint i;
 586   for( i = 0; i &lt; _max; i++ ) {
 587     set_req(i, NULL);
 588     //assert(def-&gt;out(def-&gt;outcnt()-1) == (Node *)this,&quot;bad def-use hacking in reclaim&quot;);
 589   }
 590   assert(outcnt() == 0, &quot;deleting a node must not leave a dangling use&quot;);
 591   // See if the input array was allocated just prior to the object
 592   int edge_size = _max*sizeof(void*);
 593   int out_edge_size = _outmax*sizeof(void*);
 594   char *edge_end = ((char*)_in) + edge_size;
 595   char *out_array = (char*)(_out == NO_OUT_ARRAY? NULL: _out);
 596   int node_size = size_of();
 597 
 598   // Free the output edge array
 599   if (out_edge_size &gt; 0) {
 600     compile-&gt;node_arena()-&gt;Afree(out_array, out_edge_size);
 601   }
 602 
 603   // Free the input edge array and the node itself
 604   if( edge_end == (char*)this ) {
 605     // It was; free the input array and object all in one hit
 606 #ifndef ASSERT
 607     compile-&gt;node_arena()-&gt;Afree(_in,edge_size+node_size);
 608 #endif
 609   } else {
 610     // Free just the input array
 611     compile-&gt;node_arena()-&gt;Afree(_in,edge_size);
 612 
 613     // Free just the object
 614 #ifndef ASSERT
 615     compile-&gt;node_arena()-&gt;Afree(this,node_size);
 616 #endif
 617   }
 618   if (is_macro()) {
 619     compile-&gt;remove_macro_node(this);
 620   }
 621   if (is_expensive()) {
 622     compile-&gt;remove_expensive_node(this);
 623   }
 624   CastIINode* cast = isa_CastII();
 625   if (cast != NULL &amp;&amp; cast-&gt;has_range_check()) {
 626     compile-&gt;remove_range_check_cast(cast);
 627   }
 628   if (Opcode() == Op_Opaque4) {
 629     compile-&gt;remove_opaque4_node(this);
 630   }
 631   if (is_InlineTypeBase()) {
 632     compile-&gt;remove_inline_type(this);
 633   }
 634 
 635   if (is_SafePoint()) {
 636     as_SafePoint()-&gt;delete_replaced_nodes();
 637   }
 638   BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
 639   bs-&gt;unregister_potential_barrier_node(this);
 640 #ifdef ASSERT
 641   // We will not actually delete the storage, but we&#39;ll make the node unusable.
 642   *(address*)this = badAddress;  // smash the C++ vtbl, probably
 643   _in = _out = (Node**) badAddress;
 644   _max = _cnt = _outmax = _outcnt = 0;
 645   compile-&gt;remove_modified_node(this);
 646 #endif
 647 }
 648 
 649 //------------------------------grow-------------------------------------------
 650 // Grow the input array, making space for more edges
 651 void Node::grow( uint len ) {
 652   Arena* arena = Compile::current()-&gt;node_arena();
 653   uint new_max = _max;
 654   if( new_max == 0 ) {
 655     _max = 4;
 656     _in = (Node**)arena-&gt;Amalloc(4*sizeof(Node*));
 657     Node** to = _in;
 658     to[0] = NULL;
 659     to[1] = NULL;
 660     to[2] = NULL;
 661     to[3] = NULL;
 662     return;
 663   }
 664   new_max = next_power_of_2(len);
 665   // Trimming to limit allows a uint8 to handle up to 255 edges.
 666   // Previously I was using only powers-of-2 which peaked at 128 edges.
 667   //if( new_max &gt;= limit ) new_max = limit-1;
 668   _in = (Node**)arena-&gt;Arealloc(_in, _max*sizeof(Node*), new_max*sizeof(Node*));
 669   Copy::zero_to_bytes(&amp;_in[_max], (new_max-_max)*sizeof(Node*)); // NULL all new space
 670   _max = new_max;               // Record new max length
 671   // This assertion makes sure that Node::_max is wide enough to
 672   // represent the numerical value of new_max.
 673   assert(_max == new_max &amp;&amp; _max &gt; len, &quot;int width of _max is too small&quot;);
 674 }
 675 
 676 //-----------------------------out_grow----------------------------------------
 677 // Grow the input array, making space for more edges
 678 void Node::out_grow( uint len ) {
 679   assert(!is_top(), &quot;cannot grow a top node&#39;s out array&quot;);
 680   Arena* arena = Compile::current()-&gt;node_arena();
 681   uint new_max = _outmax;
 682   if( new_max == 0 ) {
 683     _outmax = 4;
 684     _out = (Node **)arena-&gt;Amalloc(4*sizeof(Node*));
 685     return;
 686   }
 687   new_max = next_power_of_2(len);
 688   // Trimming to limit allows a uint8 to handle up to 255 edges.
 689   // Previously I was using only powers-of-2 which peaked at 128 edges.
 690   //if( new_max &gt;= limit ) new_max = limit-1;
 691   assert(_out != NULL &amp;&amp; _out != NO_OUT_ARRAY, &quot;out must have sensible value&quot;);
 692   _out = (Node**)arena-&gt;Arealloc(_out,_outmax*sizeof(Node*),new_max*sizeof(Node*));
 693   //Copy::zero_to_bytes(&amp;_out[_outmax], (new_max-_outmax)*sizeof(Node*)); // NULL all new space
 694   _outmax = new_max;               // Record new max length
 695   // This assertion makes sure that Node::_max is wide enough to
 696   // represent the numerical value of new_max.
 697   assert(_outmax == new_max &amp;&amp; _outmax &gt; len, &quot;int width of _outmax is too small&quot;);
 698 }
 699 
 700 #ifdef ASSERT
 701 //------------------------------is_dead----------------------------------------
 702 bool Node::is_dead() const {
 703   // Mach and pinch point nodes may look like dead.
 704   if( is_top() || is_Mach() || (Opcode() == Op_Node &amp;&amp; _outcnt &gt; 0) )
 705     return false;
 706   for( uint i = 0; i &lt; _max; i++ )
 707     if( _in[i] != NULL )
 708       return false;
 709   dump();
 710   return true;
 711 }
 712 
 713 bool Node::is_reachable_from_root() const {
 714   ResourceMark rm;
 715   Unique_Node_List wq;
 716   wq.push((Node*)this);
 717   RootNode* root = Compile::current()-&gt;root();
 718   for (uint i = 0; i &lt; wq.size(); i++) {
 719     Node* m = wq.at(i);
 720     if (m == root) {
 721       return true;
 722     }
 723     for (DUIterator_Fast jmax, j = m-&gt;fast_outs(jmax); j &lt; jmax; j++) {
 724       Node* u = m-&gt;fast_out(j);
 725       wq.push(u);
 726     }
 727   }
 728   return false;
 729 }
 730 #endif
 731 
 732 //------------------------------is_unreachable---------------------------------
 733 bool Node::is_unreachable(PhaseIterGVN &amp;igvn) const {
 734   assert(!is_Mach(), &quot;doesn&#39;t work with MachNodes&quot;);
 735   return outcnt() == 0 || igvn.type(this) == Type::TOP || (in(0) != NULL &amp;&amp; in(0)-&gt;is_top());
 736 }
 737 
 738 //------------------------------add_req----------------------------------------
 739 // Add a new required input at the end
 740 void Node::add_req( Node *n ) {
 741   assert( is_not_dead(n), &quot;can not use dead node&quot;);
 742 
 743   // Look to see if I can move precedence down one without reallocating
 744   if( (_cnt &gt;= _max) || (in(_max-1) != NULL) )
 745     grow( _max+1 );
 746 
 747   // Find a precedence edge to move
 748   if( in(_cnt) != NULL ) {       // Next precedence edge is busy?
 749     uint i;
 750     for( i=_cnt; i&lt;_max; i++ )
 751       if( in(i) == NULL )       // Find the NULL at end of prec edge list
 752         break;                  // There must be one, since we grew the array
 753     _in[i] = in(_cnt);          // Move prec over, making space for req edge
 754   }
 755   _in[_cnt++] = n;            // Stuff over old prec edge
 756   if (n != NULL) n-&gt;add_out((Node *)this);
 757 }
 758 
 759 //---------------------------add_req_batch-------------------------------------
 760 // Add a new required input at the end
 761 void Node::add_req_batch( Node *n, uint m ) {
 762   assert( is_not_dead(n), &quot;can not use dead node&quot;);
 763   // check various edge cases
 764   if ((int)m &lt;= 1) {
 765     assert((int)m &gt;= 0, &quot;oob&quot;);
 766     if (m != 0)  add_req(n);
 767     return;
 768   }
 769 
 770   // Look to see if I can move precedence down one without reallocating
 771   if( (_cnt+m) &gt; _max || _in[_max-m] )
 772     grow( _max+m );
 773 
 774   // Find a precedence edge to move
 775   if( _in[_cnt] != NULL ) {     // Next precedence edge is busy?
 776     uint i;
 777     for( i=_cnt; i&lt;_max; i++ )
 778       if( _in[i] == NULL )      // Find the NULL at end of prec edge list
 779         break;                  // There must be one, since we grew the array
 780     // Slide all the precs over by m positions (assume #prec &lt;&lt; m).
 781     Copy::conjoint_words_to_higher((HeapWord*)&amp;_in[_cnt], (HeapWord*)&amp;_in[_cnt+m], ((i-_cnt)*sizeof(Node*)));
 782   }
 783 
 784   // Stuff over the old prec edges
 785   for(uint i=0; i&lt;m; i++ ) {
 786     _in[_cnt++] = n;
 787   }
 788 
 789   // Insert multiple out edges on the node.
 790   if (n != NULL &amp;&amp; !n-&gt;is_top()) {
 791     for(uint i=0; i&lt;m; i++ ) {
 792       n-&gt;add_out((Node *)this);
 793     }
 794   }
 795 }
 796 
 797 //------------------------------del_req----------------------------------------
 798 // Delete the required edge and compact the edge array
 799 void Node::del_req( uint idx ) {
 800   assert( idx &lt; _cnt, &quot;oob&quot;);
 801   assert( !VerifyHashTableKeys || _hash_lock == 0,
 802           &quot;remove node from hash table before modifying it&quot;);
 803   // First remove corresponding def-use edge
 804   Node *n = in(idx);
 805   if (n != NULL) n-&gt;del_out((Node *)this);
 806   _in[idx] = in(--_cnt); // Compact the array
 807   // Avoid spec violation: Gap in prec edges.
 808   close_prec_gap_at(_cnt);
 809   Compile::current()-&gt;record_modified_node(this);
 810 }
 811 
 812 //------------------------------del_req_ordered--------------------------------
 813 // Delete the required edge and compact the edge array with preserved order
 814 void Node::del_req_ordered( uint idx ) {
 815   assert( idx &lt; _cnt, &quot;oob&quot;);
 816   assert( !VerifyHashTableKeys || _hash_lock == 0,
 817           &quot;remove node from hash table before modifying it&quot;);
 818   // First remove corresponding def-use edge
 819   Node *n = in(idx);
 820   if (n != NULL) n-&gt;del_out((Node *)this);
 821   if (idx &lt; --_cnt) {    // Not last edge ?
 822     Copy::conjoint_words_to_lower((HeapWord*)&amp;_in[idx+1], (HeapWord*)&amp;_in[idx], ((_cnt-idx)*sizeof(Node*)));
 823   }
 824   // Avoid spec violation: Gap in prec edges.
 825   close_prec_gap_at(_cnt);
 826   Compile::current()-&gt;record_modified_node(this);
 827 }
 828 
 829 //------------------------------ins_req----------------------------------------
 830 // Insert a new required input at the end
 831 void Node::ins_req( uint idx, Node *n ) {
 832   assert( is_not_dead(n), &quot;can not use dead node&quot;);
 833   add_req(NULL);                // Make space
 834   assert( idx &lt; _max, &quot;Must have allocated enough space&quot;);
 835   // Slide over
 836   if(_cnt-idx-1 &gt; 0) {
 837     Copy::conjoint_words_to_higher((HeapWord*)&amp;_in[idx], (HeapWord*)&amp;_in[idx+1], ((_cnt-idx-1)*sizeof(Node*)));
 838   }
 839   _in[idx] = n;                            // Stuff over old required edge
 840   if (n != NULL) n-&gt;add_out((Node *)this); // Add reciprocal def-use edge
 841 }
 842 
 843 //-----------------------------find_edge---------------------------------------
 844 int Node::find_edge(Node* n) {
 845   for (uint i = 0; i &lt; len(); i++) {
 846     if (_in[i] == n)  return i;
 847   }
 848   return -1;
 849 }
 850 
 851 //----------------------------replace_edge-------------------------------------
 852 int Node::replace_edge(Node* old, Node* neww) {
 853   if (old == neww)  return 0;  // nothing to do
 854   uint nrep = 0;
 855   for (uint i = 0; i &lt; len(); i++) {
 856     if (in(i) == old) {
 857       if (i &lt; req()) {
 858         set_req(i, neww);
 859       } else {
 860         assert(find_prec_edge(neww) == -1, &quot;spec violation: duplicated prec edge (node %d -&gt; %d)&quot;, _idx, neww-&gt;_idx);
 861         set_prec(i, neww);
 862       }
 863       nrep++;
 864     }
 865   }
 866   return nrep;
 867 }
 868 
 869 /**
 870  * Replace input edges in the range pointing to &#39;old&#39; node.
 871  */
 872 int Node::replace_edges_in_range(Node* old, Node* neww, int start, int end) {
 873   if (old == neww)  return 0;  // nothing to do
 874   uint nrep = 0;
 875   for (int i = start; i &lt; end; i++) {
 876     if (in(i) == old) {
 877       set_req(i, neww);
 878       nrep++;
 879     }
 880   }
 881   return nrep;
 882 }
 883 
 884 //-------------------------disconnect_inputs-----------------------------------
 885 // NULL out all inputs to eliminate incoming Def-Use edges.
 886 // Return the number of edges between &#39;n&#39; and &#39;this&#39;
 887 int Node::disconnect_inputs(Node *n, Compile* C) {
 888   int edges_to_n = 0;
 889 
 890   uint cnt = req();
 891   for( uint i = 0; i &lt; cnt; ++i ) {
 892     if( in(i) == 0 ) continue;
 893     if( in(i) == n ) ++edges_to_n;
 894     set_req(i, NULL);
 895   }
 896   // Remove precedence edges if any exist
 897   // Note: Safepoints may have precedence edges, even during parsing
 898   if( (req() != len()) &amp;&amp; (in(req()) != NULL) ) {
 899     uint max = len();
 900     for( uint i = 0; i &lt; max; ++i ) {
 901       if( in(i) == 0 ) continue;
 902       if( in(i) == n ) ++edges_to_n;
 903       set_prec(i, NULL);
 904     }
 905   }
 906 
 907   // Node::destruct requires all out edges be deleted first
 908   // debug_only(destruct();)   // no reuse benefit expected
 909   if (edges_to_n == 0) {
 910     C-&gt;record_dead_node(_idx);
 911   }
 912   return edges_to_n;
 913 }
 914 
 915 //-----------------------------uncast---------------------------------------
 916 // %%% Temporary, until we sort out CheckCastPP vs. CastPP.
 917 // Strip away casting.  (It is depth-limited.)
 918 // Optionally, keep casts with dependencies.
 919 Node* Node::uncast(bool keep_deps) const {
 920   // Should be inline:
 921   //return is_ConstraintCast() ? uncast_helper(this) : (Node*) this;
 922   if (is_ConstraintCast()) {
 923     return uncast_helper(this, keep_deps);
 924   } else {
 925     return (Node*) this;
 926   }
 927 }
 928 
 929 // Find out of current node that matches opcode.
 930 Node* Node::find_out_with(int opcode) {
 931   for (DUIterator_Fast imax, i = fast_outs(imax); i &lt; imax; i++) {
 932     Node* use = fast_out(i);
 933     if (use-&gt;Opcode() == opcode) {
 934       return use;
 935     }
 936   }
 937   return NULL;
 938 }
 939 
 940 // Return true if the current node has an out that matches opcode.
 941 bool Node::has_out_with(int opcode) {
 942   return (find_out_with(opcode) != NULL);
 943 }
 944 
 945 // Return true if the current node has an out that matches any of the opcodes.
 946 bool Node::has_out_with(int opcode1, int opcode2, int opcode3, int opcode4) {
 947   for (DUIterator_Fast imax, i = fast_outs(imax); i &lt; imax; i++) {
 948       int opcode = fast_out(i)-&gt;Opcode();
 949       if (opcode == opcode1 || opcode == opcode2 || opcode == opcode3 || opcode == opcode4) {
 950         return true;
 951       }
 952   }
 953   return false;
 954 }
 955 
 956 
 957 //---------------------------uncast_helper-------------------------------------
 958 Node* Node::uncast_helper(const Node* p, bool keep_deps) {
 959 #ifdef ASSERT
 960   uint depth_count = 0;
 961   const Node* orig_p = p;
 962 #endif
 963 
 964   while (true) {
 965 #ifdef ASSERT
 966     if (depth_count &gt;= K) {
 967       orig_p-&gt;dump(4);
 968       if (p != orig_p)
 969         p-&gt;dump(1);
 970     }
 971     assert(depth_count++ &lt; K, &quot;infinite loop in Node::uncast_helper&quot;);
 972 #endif
 973     if (p == NULL || p-&gt;req() != 2) {
 974       break;
 975     } else if (p-&gt;is_ConstraintCast()) {
 976       if (keep_deps &amp;&amp; p-&gt;as_ConstraintCast()-&gt;carry_dependency()) {
 977         break; // stop at casts with dependencies
 978       }
 979       p = p-&gt;in(1);
 980     } else {
 981       break;
 982     }
 983   }
 984   return (Node*) p;
 985 }
 986 
 987 //------------------------------add_prec---------------------------------------
 988 // Add a new precedence input.  Precedence inputs are unordered, with
 989 // duplicates removed and NULLs packed down at the end.
 990 void Node::add_prec( Node *n ) {
 991   assert( is_not_dead(n), &quot;can not use dead node&quot;);
 992 
 993   // Check for NULL at end
 994   if( _cnt &gt;= _max || in(_max-1) )
 995     grow( _max+1 );
 996 
 997   // Find a precedence edge to move
 998   uint i = _cnt;
 999   while( in(i) != NULL ) {
1000     if (in(i) == n) return; // Avoid spec violation: duplicated prec edge.
1001     i++;
1002   }
1003   _in[i] = n;                                // Stuff prec edge over NULL
1004   if ( n != NULL) n-&gt;add_out((Node *)this);  // Add mirror edge
1005 
1006 #ifdef ASSERT
1007   while ((++i)&lt;_max) { assert(_in[i] == NULL, &quot;spec violation: Gap in prec edges (node %d)&quot;, _idx); }
1008 #endif
1009 }
1010 
1011 //------------------------------rm_prec----------------------------------------
1012 // Remove a precedence input.  Precedence inputs are unordered, with
1013 // duplicates removed and NULLs packed down at the end.
1014 void Node::rm_prec( uint j ) {
1015   assert(j &lt; _max, &quot;oob: i=%d, _max=%d&quot;, j, _max);
1016   assert(j &gt;= _cnt, &quot;not a precedence edge&quot;);
1017   if (_in[j] == NULL) return;   // Avoid spec violation: Gap in prec edges.
1018   _in[j]-&gt;del_out((Node *)this);
1019   close_prec_gap_at(j);
1020 }
1021 
1022 //------------------------------size_of----------------------------------------
1023 uint Node::size_of() const { return sizeof(*this); }
1024 
1025 //------------------------------ideal_reg--------------------------------------
1026 uint Node::ideal_reg() const { return 0; }
1027 
1028 //------------------------------jvms-------------------------------------------
1029 JVMState* Node::jvms() const { return NULL; }
1030 
1031 #ifdef ASSERT
1032 //------------------------------jvms-------------------------------------------
1033 bool Node::verify_jvms(const JVMState* using_jvms) const {
1034   for (JVMState* jvms = this-&gt;jvms(); jvms != NULL; jvms = jvms-&gt;caller()) {
1035     if (jvms == using_jvms)  return true;
1036   }
1037   return false;
1038 }
1039 
1040 //------------------------------init_NodeProperty------------------------------
1041 void Node::init_NodeProperty() {
1042   assert(_max_classes &lt;= max_jushort, &quot;too many NodeProperty classes&quot;);
1043   assert(max_flags() &lt;= max_jushort, &quot;too many NodeProperty flags&quot;);
1044 }
1045 
1046 //-----------------------------max_flags---------------------------------------
1047 juint Node::max_flags() {
1048   return (PD::_last_flag &lt;&lt; 1) - 1; // allow flags combination
1049 }
1050 #endif
1051 
1052 //------------------------------format-----------------------------------------
1053 // Print as assembly
1054 void Node::format( PhaseRegAlloc *, outputStream *st ) const {}
1055 //------------------------------emit-------------------------------------------
1056 // Emit bytes starting at parameter &#39;ptr&#39;.
1057 void Node::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {}
1058 //------------------------------size-------------------------------------------
1059 // Size of instruction in bytes
1060 uint Node::size(PhaseRegAlloc *ra_) const { return 0; }
1061 
1062 //------------------------------CFG Construction-------------------------------
1063 // Nodes that end basic blocks, e.g. IfTrue/IfFalse, JumpProjNode, Root,
1064 // Goto and Return.
1065 const Node *Node::is_block_proj() const { return 0; }
1066 
1067 // Minimum guaranteed type
1068 const Type *Node::bottom_type() const { return Type::BOTTOM; }
1069 
1070 
1071 //------------------------------raise_bottom_type------------------------------
1072 // Get the worst-case Type output for this Node.
1073 void Node::raise_bottom_type(const Type* new_type) {
1074   if (is_Type()) {
1075     TypeNode *n = this-&gt;as_Type();
1076     if (VerifyAliases) {
1077       assert(new_type-&gt;higher_equal_speculative(n-&gt;type()), &quot;new type must refine old type&quot;);
1078     }
1079     n-&gt;set_type(new_type);
1080   } else if (is_Load()) {
1081     LoadNode *n = this-&gt;as_Load();
1082     if (VerifyAliases) {
1083       assert(new_type-&gt;higher_equal_speculative(n-&gt;type()), &quot;new type must refine old type&quot;);
1084     }
1085     n-&gt;set_type(new_type);
1086   }
1087 }
1088 
1089 //------------------------------Identity---------------------------------------
1090 // Return a node that the given node is equivalent to.
1091 Node* Node::Identity(PhaseGVN* phase) {
1092   return this;                  // Default to no identities
1093 }
1094 
1095 //------------------------------Value------------------------------------------
1096 // Compute a new Type for a node using the Type of the inputs.
1097 const Type* Node::Value(PhaseGVN* phase) const {
1098   return bottom_type();         // Default to worst-case Type
1099 }
1100 
1101 //------------------------------Ideal------------------------------------------
1102 //
1103 // &#39;Idealize&#39; the graph rooted at this Node.
1104 //
1105 // In order to be efficient and flexible there are some subtle invariants
1106 // these Ideal calls need to hold.  Running with &#39;+VerifyIterativeGVN&#39; checks
1107 // these invariants, although its too slow to have on by default.  If you are
1108 // hacking an Ideal call, be sure to test with +VerifyIterativeGVN!
1109 //
1110 // The Ideal call almost arbitrarily reshape the graph rooted at the &#39;this&#39;
1111 // pointer.  If ANY change is made, it must return the root of the reshaped
1112 // graph - even if the root is the same Node.  Example: swapping the inputs
1113 // to an AddINode gives the same answer and same root, but you still have to
1114 // return the &#39;this&#39; pointer instead of NULL.
1115 //
1116 // You cannot return an OLD Node, except for the &#39;this&#39; pointer.  Use the
1117 // Identity call to return an old Node; basically if Identity can find
1118 // another Node have the Ideal call make no change and return NULL.
1119 // Example: AddINode::Ideal must check for add of zero; in this case it
1120 // returns NULL instead of doing any graph reshaping.
1121 //
1122 // You cannot modify any old Nodes except for the &#39;this&#39; pointer.  Due to
1123 // sharing there may be other users of the old Nodes relying on their current
1124 // semantics.  Modifying them will break the other users.
1125 // Example: when reshape &quot;(X+3)+4&quot; into &quot;X+7&quot; you must leave the Node for
1126 // &quot;X+3&quot; unchanged in case it is shared.
1127 //
1128 // If you modify the &#39;this&#39; pointer&#39;s inputs, you should use
1129 // &#39;set_req&#39;.  If you are making a new Node (either as the new root or
1130 // some new internal piece) you may use &#39;init_req&#39; to set the initial
1131 // value.  You can make a new Node with either &#39;new&#39; or &#39;clone&#39;.  In
1132 // either case, def-use info is correctly maintained.
1133 //
1134 // Example: reshape &quot;(X+3)+4&quot; into &quot;X+7&quot;:
1135 //    set_req(1, in(1)-&gt;in(1));
1136 //    set_req(2, phase-&gt;intcon(7));
1137 //    return this;
1138 // Example: reshape &quot;X*4&quot; into &quot;X&lt;&lt;2&quot;
1139 //    return new LShiftINode(in(1), phase-&gt;intcon(2));
1140 //
1141 // You must call &#39;phase-&gt;transform(X)&#39; on any new Nodes X you make, except
1142 // for the returned root node.  Example: reshape &quot;X*31&quot; with &quot;(X&lt;&lt;5)-X&quot;.
1143 //    Node *shift=phase-&gt;transform(new LShiftINode(in(1),phase-&gt;intcon(5)));
1144 //    return new AddINode(shift, in(1));
1145 //
1146 // When making a Node for a constant use &#39;phase-&gt;makecon&#39; or &#39;phase-&gt;intcon&#39;.
1147 // These forms are faster than &#39;phase-&gt;transform(new ConNode())&#39; and Do
1148 // The Right Thing with def-use info.
1149 //
1150 // You cannot bury the &#39;this&#39; Node inside of a graph reshape.  If the reshaped
1151 // graph uses the &#39;this&#39; Node it must be the root.  If you want a Node with
1152 // the same Opcode as the &#39;this&#39; pointer use &#39;clone&#39;.
1153 //
1154 Node *Node::Ideal(PhaseGVN *phase, bool can_reshape) {
1155   return NULL;                  // Default to being Ideal already
1156 }
1157 
1158 // Some nodes have specific Ideal subgraph transformations only if they are
1159 // unique users of specific nodes. Such nodes should be put on IGVN worklist
1160 // for the transformations to happen.
1161 bool Node::has_special_unique_user() const {
1162   assert(outcnt() == 1, &quot;match only for unique out&quot;);
1163   Node* n = unique_out();
1164   int op  = Opcode();
1165   if (this-&gt;is_Store()) {
1166     // Condition for back-to-back stores folding.
1167     return n-&gt;Opcode() == op &amp;&amp; n-&gt;in(MemNode::Memory) == this;
1168   } else if (this-&gt;is_Load() || this-&gt;is_DecodeN() || this-&gt;is_Phi()) {
1169     // Condition for removing an unused LoadNode or DecodeNNode from the MemBarAcquire precedence input
1170     return n-&gt;Opcode() == Op_MemBarAcquire;
1171   } else if (op == Op_AddL) {
1172     // Condition for convL2I(addL(x,y)) ==&gt; addI(convL2I(x),convL2I(y))
1173     return n-&gt;Opcode() == Op_ConvL2I &amp;&amp; n-&gt;in(1) == this;
1174   } else if (op == Op_SubI || op == Op_SubL) {
1175     // Condition for subI(x,subI(y,z)) ==&gt; subI(addI(x,z),y)
1176     return n-&gt;Opcode() == op &amp;&amp; n-&gt;in(2) == this;
1177   } else if (is_If() &amp;&amp; (n-&gt;is_IfFalse() || n-&gt;is_IfTrue())) {
1178     // See IfProjNode::Identity()
1179     return true;
1180   } else {
1181     return false;
1182   }
1183 };
1184 
1185 //--------------------------find_exact_control---------------------------------
1186 // Skip Proj and CatchProj nodes chains. Check for Null and Top.
1187 Node* Node::find_exact_control(Node* ctrl) {
1188   if (ctrl == NULL &amp;&amp; this-&gt;is_Region())
1189     ctrl = this-&gt;as_Region()-&gt;is_copy();
1190 
1191   if (ctrl != NULL &amp;&amp; ctrl-&gt;is_CatchProj()) {
1192     if (ctrl-&gt;as_CatchProj()-&gt;_con == CatchProjNode::fall_through_index)
1193       ctrl = ctrl-&gt;in(0);
1194     if (ctrl != NULL &amp;&amp; !ctrl-&gt;is_top())
1195       ctrl = ctrl-&gt;in(0);
1196   }
1197 
1198   if (ctrl != NULL &amp;&amp; ctrl-&gt;is_Proj())
1199     ctrl = ctrl-&gt;in(0);
1200 
1201   return ctrl;
1202 }
1203 
1204 //--------------------------dominates------------------------------------------
1205 // Helper function for MemNode::all_controls_dominate().
1206 // Check if &#39;this&#39; control node dominates or equal to &#39;sub&#39; control node.
1207 // We already know that if any path back to Root or Start reaches &#39;this&#39;,
1208 // then all paths so, so this is a simple search for one example,
1209 // not an exhaustive search for a counterexample.
1210 bool Node::dominates(Node* sub, Node_List &amp;nlist) {
1211   assert(this-&gt;is_CFG(), &quot;expecting control&quot;);
1212   assert(sub != NULL &amp;&amp; sub-&gt;is_CFG(), &quot;expecting control&quot;);
1213 
1214   // detect dead cycle without regions
1215   int iterations_without_region_limit = DominatorSearchLimit;
1216 
1217   Node* orig_sub = sub;
1218   Node* dom      = this;
1219   bool  met_dom  = false;
1220   nlist.clear();
1221 
1222   // Walk &#39;sub&#39; backward up the chain to &#39;dom&#39;, watching for regions.
1223   // After seeing &#39;dom&#39;, continue up to Root or Start.
1224   // If we hit a region (backward split point), it may be a loop head.
1225   // Keep going through one of the region&#39;s inputs.  If we reach the
1226   // same region again, go through a different input.  Eventually we
1227   // will either exit through the loop head, or give up.
1228   // (If we get confused, break out and return a conservative &#39;false&#39;.)
1229   while (sub != NULL) {
1230     if (sub-&gt;is_top())  break; // Conservative answer for dead code.
1231     if (sub == dom) {
1232       if (nlist.size() == 0) {
1233         // No Region nodes except loops were visited before and the EntryControl
1234         // path was taken for loops: it did not walk in a cycle.
1235         return true;
1236       } else if (met_dom) {
1237         break;          // already met before: walk in a cycle
1238       } else {
1239         // Region nodes were visited. Continue walk up to Start or Root
1240         // to make sure that it did not walk in a cycle.
1241         met_dom = true; // first time meet
1242         iterations_without_region_limit = DominatorSearchLimit; // Reset
1243      }
1244     }
1245     if (sub-&gt;is_Start() || sub-&gt;is_Root()) {
1246       // Success if we met &#39;dom&#39; along a path to Start or Root.
1247       // We assume there are no alternative paths that avoid &#39;dom&#39;.
1248       // (This assumption is up to the caller to ensure!)
1249       return met_dom;
1250     }
1251     Node* up = sub-&gt;in(0);
1252     // Normalize simple pass-through regions and projections:
1253     up = sub-&gt;find_exact_control(up);
1254     // If sub == up, we found a self-loop.  Try to push past it.
1255     if (sub == up &amp;&amp; sub-&gt;is_Loop()) {
1256       // Take loop entry path on the way up to &#39;dom&#39;.
1257       up = sub-&gt;in(1); // in(LoopNode::EntryControl);
1258     } else if (sub == up &amp;&amp; sub-&gt;is_Region() &amp;&amp; sub-&gt;req() == 2) {
1259       // Take in(1) path on the way up to &#39;dom&#39; for regions with only one input
1260       up = sub-&gt;in(1);
1261     } else if (sub == up &amp;&amp; sub-&gt;is_Region() &amp;&amp; sub-&gt;req() == 3) {
1262       // Try both paths for Regions with 2 input paths (it may be a loop head).
1263       // It could give conservative &#39;false&#39; answer without information
1264       // which region&#39;s input is the entry path.
1265       iterations_without_region_limit = DominatorSearchLimit; // Reset
1266 
1267       bool region_was_visited_before = false;
1268       // Was this Region node visited before?
1269       // If so, we have reached it because we accidentally took a
1270       // loop-back edge from &#39;sub&#39; back into the body of the loop,
1271       // and worked our way up again to the loop header &#39;sub&#39;.
1272       // So, take the first unexplored path on the way up to &#39;dom&#39;.
1273       for (int j = nlist.size() - 1; j &gt;= 0; j--) {
1274         intptr_t ni = (intptr_t)nlist.at(j);
1275         Node* visited = (Node*)(ni &amp; ~1);
1276         bool  visited_twice_already = ((ni &amp; 1) != 0);
1277         if (visited == sub) {
1278           if (visited_twice_already) {
1279             // Visited 2 paths, but still stuck in loop body.  Give up.
1280             return false;
1281           }
1282           // The Region node was visited before only once.
1283           // (We will repush with the low bit set, below.)
1284           nlist.remove(j);
1285           // We will find a new edge and re-insert.
1286           region_was_visited_before = true;
1287           break;
1288         }
1289       }
1290 
1291       // Find an incoming edge which has not been seen yet; walk through it.
1292       assert(up == sub, &quot;&quot;);
1293       uint skip = region_was_visited_before ? 1 : 0;
1294       for (uint i = 1; i &lt; sub-&gt;req(); i++) {
1295         Node* in = sub-&gt;in(i);
1296         if (in != NULL &amp;&amp; !in-&gt;is_top() &amp;&amp; in != sub) {
1297           if (skip == 0) {
1298             up = in;
1299             break;
1300           }
1301           --skip;               // skip this nontrivial input
1302         }
1303       }
1304 
1305       // Set 0 bit to indicate that both paths were taken.
1306       nlist.push((Node*)((intptr_t)sub + (region_was_visited_before ? 1 : 0)));
1307     }
1308 
1309     if (up == sub) {
1310       break;    // some kind of tight cycle
1311     }
1312     if (up == orig_sub &amp;&amp; met_dom) {
1313       // returned back after visiting &#39;dom&#39;
1314       break;    // some kind of cycle
1315     }
1316     if (--iterations_without_region_limit &lt; 0) {
1317       break;    // dead cycle
1318     }
1319     sub = up;
1320   }
1321 
1322   // Did not meet Root or Start node in pred. chain.
1323   // Conservative answer for dead code.
1324   return false;
1325 }
1326 
1327 //------------------------------remove_dead_region-----------------------------
1328 // This control node is dead.  Follow the subgraph below it making everything
1329 // using it dead as well.  This will happen normally via the usual IterGVN
1330 // worklist but this call is more efficient.  Do not update use-def info
1331 // inside the dead region, just at the borders.
1332 static void kill_dead_code( Node *dead, PhaseIterGVN *igvn ) {
1333   // Con&#39;s are a popular node to re-hit in the hash table again.
1334   if( dead-&gt;is_Con() ) return;
1335 
1336   ResourceMark rm;
1337   Node_List  nstack(Thread::current()-&gt;resource_area());
1338 
1339   Node *top = igvn-&gt;C-&gt;top();
1340   nstack.push(dead);
1341   bool has_irreducible_loop = igvn-&gt;C-&gt;has_irreducible_loop();
1342 
1343   while (nstack.size() &gt; 0) {
1344     dead = nstack.pop();
1345     if (dead-&gt;Opcode() == Op_SafePoint) {
1346       dead-&gt;as_SafePoint()-&gt;disconnect_from_root(igvn);
1347     }
1348     if (dead-&gt;outcnt() &gt; 0) {
1349       // Keep dead node on stack until all uses are processed.
1350       nstack.push(dead);
1351       // For all Users of the Dead...    ;-)
1352       for (DUIterator_Last kmin, k = dead-&gt;last_outs(kmin); k &gt;= kmin; ) {
1353         Node* use = dead-&gt;last_out(k);
1354         igvn-&gt;hash_delete(use);       // Yank from hash table prior to mod
1355         if (use-&gt;in(0) == dead) {     // Found another dead node
1356           assert (!use-&gt;is_Con(), &quot;Control for Con node should be Root node.&quot;);
1357           use-&gt;set_req(0, top);       // Cut dead edge to prevent processing
1358           nstack.push(use);           // the dead node again.
1359         } else if (!has_irreducible_loop &amp;&amp; // Backedge could be alive in irreducible loop
1360                    use-&gt;is_Loop() &amp;&amp; !use-&gt;is_Root() &amp;&amp;       // Don&#39;t kill Root (RootNode extends LoopNode)
1361                    use-&gt;in(LoopNode::EntryControl) == dead) { // Dead loop if its entry is dead
1362           use-&gt;set_req(LoopNode::EntryControl, top);          // Cut dead edge to prevent processing
1363           use-&gt;set_req(0, top);       // Cut self edge
1364           nstack.push(use);
1365         } else {                      // Else found a not-dead user
1366           // Dead if all inputs are top or null
1367           bool dead_use = !use-&gt;is_Root(); // Keep empty graph alive
1368           for (uint j = 1; j &lt; use-&gt;req(); j++) {
1369             Node* in = use-&gt;in(j);
1370             if (in == dead) {         // Turn all dead inputs into TOP
1371               use-&gt;set_req(j, top);
1372             } else if (in != NULL &amp;&amp; !in-&gt;is_top()) {
1373               dead_use = false;
1374             }
1375           }
1376           if (dead_use) {
1377             if (use-&gt;is_Region()) {
1378               use-&gt;set_req(0, top);   // Cut self edge
1379             }
1380             nstack.push(use);
1381           } else {
1382             igvn-&gt;_worklist.push(use);
1383           }
1384         }
1385         // Refresh the iterator, since any number of kills might have happened.
1386         k = dead-&gt;last_outs(kmin);
1387       }
1388     } else { // (dead-&gt;outcnt() == 0)
1389       // Done with outputs.
1390       igvn-&gt;hash_delete(dead);
1391       igvn-&gt;_worklist.remove(dead);
1392       igvn-&gt;C-&gt;remove_modified_node(dead);
1393       igvn-&gt;set_type(dead, Type::TOP);
1394       if (dead-&gt;is_macro()) {
1395         igvn-&gt;C-&gt;remove_macro_node(dead);
1396       }
1397       if (dead-&gt;is_expensive()) {
1398         igvn-&gt;C-&gt;remove_expensive_node(dead);
1399       }
1400       CastIINode* cast = dead-&gt;isa_CastII();
1401       if (cast != NULL &amp;&amp; cast-&gt;has_range_check()) {
1402         igvn-&gt;C-&gt;remove_range_check_cast(cast);
1403       }
1404       if (dead-&gt;Opcode() == Op_Opaque4) {
1405         igvn-&gt;C-&gt;remove_opaque4_node(dead);
1406       }
1407       if (dead-&gt;is_InlineTypeBase()) {
1408         igvn-&gt;C-&gt;remove_inline_type(dead);
1409       }
1410       BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
1411       bs-&gt;unregister_potential_barrier_node(dead);
1412       igvn-&gt;C-&gt;record_dead_node(dead-&gt;_idx);
1413       // Kill all inputs to the dead guy
1414       for (uint i=0; i &lt; dead-&gt;req(); i++) {
1415         Node *n = dead-&gt;in(i);      // Get input to dead guy
1416         if (n != NULL &amp;&amp; !n-&gt;is_top()) { // Input is valid?
1417           dead-&gt;set_req(i, top);    // Smash input away
1418           if (n-&gt;outcnt() == 0) {   // Input also goes dead?
1419             if (!n-&gt;is_Con())
1420               nstack.push(n);       // Clear it out as well
1421           } else if (n-&gt;outcnt() == 1 &amp;&amp;
1422                      n-&gt;has_special_unique_user()) {
1423             igvn-&gt;add_users_to_worklist( n );
1424           } else if (n-&gt;outcnt() &lt;= 2 &amp;&amp; n-&gt;is_Store()) {
1425             // Push store&#39;s uses on worklist to enable folding optimization for
1426             // store/store and store/load to the same address.
1427             // The restriction (outcnt() &lt;= 2) is the same as in set_req_X()
1428             // and remove_globally_dead_node().
1429             igvn-&gt;add_users_to_worklist( n );
1430           } else {
1431             BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;enqueue_useful_gc_barrier(igvn, n);
1432           }
1433         }
1434       }
1435     } // (dead-&gt;outcnt() == 0)
1436   }   // while (nstack.size() &gt; 0) for outputs
1437   return;
1438 }
1439 
1440 //------------------------------remove_dead_region-----------------------------
1441 bool Node::remove_dead_region(PhaseGVN *phase, bool can_reshape) {
1442   Node *n = in(0);
1443   if( !n ) return false;
1444   // Lost control into this guy?  I.e., it became unreachable?
1445   // Aggressively kill all unreachable code.
1446   if (can_reshape &amp;&amp; n-&gt;is_top()) {
1447     kill_dead_code(this, phase-&gt;is_IterGVN());
1448     return false; // Node is dead.
1449   }
1450 
1451   if( n-&gt;is_Region() &amp;&amp; n-&gt;as_Region()-&gt;is_copy() ) {
1452     Node *m = n-&gt;nonnull_req();
1453     set_req(0, m);
1454     return true;
1455   }
1456   return false;
1457 }
1458 
1459 //------------------------------hash-------------------------------------------
1460 // Hash function over Nodes.
1461 uint Node::hash() const {
1462   uint sum = 0;
1463   for( uint i=0; i&lt;_cnt; i++ )  // Add in all inputs
1464     sum = (sum&lt;&lt;1)-(uintptr_t)in(i);        // Ignore embedded NULLs
1465   return (sum&gt;&gt;2) + _cnt + Opcode();
1466 }
1467 
1468 //------------------------------cmp--------------------------------------------
1469 // Compare special parts of simple Nodes
1470 bool Node::cmp( const Node &amp;n ) const {
1471   return true;                  // Must be same
1472 }
1473 
1474 //------------------------------rematerialize-----------------------------------
1475 // Should we clone rather than spill this instruction?
1476 bool Node::rematerialize() const {
1477   if ( is_Mach() )
1478     return this-&gt;as_Mach()-&gt;rematerialize();
1479   else
1480     return (_flags &amp; Flag_rematerialize) != 0;
1481 }
1482 
1483 //------------------------------needs_anti_dependence_check---------------------
1484 // Nodes which use memory without consuming it, hence need antidependences.
1485 bool Node::needs_anti_dependence_check() const {
1486   if (req() &lt; 2 || (_flags &amp; Flag_needs_anti_dependence_check) == 0) {
1487     return false;
1488   }
1489   return in(1)-&gt;bottom_type()-&gt;has_memory();
1490 }
1491 
1492 // Get an integer constant from a ConNode (or CastIINode).
1493 // Return a default value if there is no apparent constant here.
1494 const TypeInt* Node::find_int_type() const {
1495   if (this-&gt;is_Type()) {
1496     return this-&gt;as_Type()-&gt;type()-&gt;isa_int();
1497   } else if (this-&gt;is_Con()) {
1498     assert(is_Mach(), &quot;should be ConNode(TypeNode) or else a MachNode&quot;);
1499     return this-&gt;bottom_type()-&gt;isa_int();
1500   }
1501   return NULL;
1502 }
1503 
1504 // Get a pointer constant from a ConstNode.
1505 // Returns the constant if it is a pointer ConstNode
1506 intptr_t Node::get_ptr() const {
1507   assert( Opcode() == Op_ConP, &quot;&quot; );
1508   return ((ConPNode*)this)-&gt;type()-&gt;is_ptr()-&gt;get_con();
1509 }
1510 
1511 // Get a narrow oop constant from a ConNNode.
1512 intptr_t Node::get_narrowcon() const {
1513   assert( Opcode() == Op_ConN, &quot;&quot; );
1514   return ((ConNNode*)this)-&gt;type()-&gt;is_narrowoop()-&gt;get_con();
1515 }
1516 
1517 // Get a long constant from a ConNode.
1518 // Return a default value if there is no apparent constant here.
1519 const TypeLong* Node::find_long_type() const {
1520   if (this-&gt;is_Type()) {
1521     return this-&gt;as_Type()-&gt;type()-&gt;isa_long();
1522   } else if (this-&gt;is_Con()) {
1523     assert(is_Mach(), &quot;should be ConNode(TypeNode) or else a MachNode&quot;);
1524     return this-&gt;bottom_type()-&gt;isa_long();
1525   }
1526   return NULL;
1527 }
1528 
1529 
1530 /**
1531  * Return a ptr type for nodes which should have it.
1532  */
1533 const TypePtr* Node::get_ptr_type() const {
1534   const TypePtr* tp = this-&gt;bottom_type()-&gt;make_ptr();
1535 #ifdef ASSERT
1536   if (tp == NULL) {
1537     this-&gt;dump(1);
1538     assert((tp != NULL), &quot;unexpected node type&quot;);
1539   }
1540 #endif
1541   return tp;
1542 }
1543 
1544 // Get a double constant from a ConstNode.
1545 // Returns the constant if it is a double ConstNode
1546 jdouble Node::getd() const {
1547   assert( Opcode() == Op_ConD, &quot;&quot; );
1548   return ((ConDNode*)this)-&gt;type()-&gt;is_double_constant()-&gt;getd();
1549 }
1550 
1551 // Get a float constant from a ConstNode.
1552 // Returns the constant if it is a float ConstNode
1553 jfloat Node::getf() const {
1554   assert( Opcode() == Op_ConF, &quot;&quot; );
1555   return ((ConFNode*)this)-&gt;type()-&gt;is_float_constant()-&gt;getf();
1556 }
1557 
1558 #ifndef PRODUCT
1559 
1560 //------------------------------find------------------------------------------
1561 // Find a neighbor of this Node with the given _idx
1562 // If idx is negative, find its absolute value, following both _in and _out.
1563 static void find_recur(Compile* C,  Node* &amp;result, Node *n, int idx, bool only_ctrl,
1564                         VectorSet* old_space, VectorSet* new_space ) {
1565   int node_idx = (idx &gt;= 0) ? idx : -idx;
1566   if (NotANode(n))  return;  // Gracefully handle NULL, -1, 0xabababab, etc.
1567   // Contained in new_space or old_space?   Check old_arena first since it&#39;s mostly empty.
1568   VectorSet *v = C-&gt;old_arena()-&gt;contains(n) ? old_space : new_space;
1569   if( v-&gt;test(n-&gt;_idx) ) return;
1570   if( (int)n-&gt;_idx == node_idx
1571       debug_only(|| n-&gt;debug_idx() == node_idx) ) {
1572     if (result != NULL)
1573       tty-&gt;print(&quot;find: &quot; INTPTR_FORMAT &quot; and &quot; INTPTR_FORMAT &quot; both have idx==%d\n&quot;,
1574                  (uintptr_t)result, (uintptr_t)n, node_idx);
1575     result = n;
1576   }
1577   v-&gt;set(n-&gt;_idx);
1578   for( uint i=0; i&lt;n-&gt;len(); i++ ) {
1579     if( only_ctrl &amp;&amp; !(n-&gt;is_Region()) &amp;&amp; (n-&gt;Opcode() != Op_Root) &amp;&amp; (i != TypeFunc::Control) ) continue;
1580     find_recur(C, result, n-&gt;in(i), idx, only_ctrl, old_space, new_space );
1581   }
1582   // Search along forward edges also:
1583   if (idx &lt; 0 &amp;&amp; !only_ctrl) {
1584     for( uint j=0; j&lt;n-&gt;outcnt(); j++ ) {
1585       find_recur(C, result, n-&gt;raw_out(j), idx, only_ctrl, old_space, new_space );
1586     }
1587   }
1588 #ifdef ASSERT
1589   // Search along debug_orig edges last, checking for cycles
1590   Node* orig = n-&gt;debug_orig();
1591   if (orig != NULL) {
1592     do {
1593       if (NotANode(orig))  break;
1594       find_recur(C, result, orig, idx, only_ctrl, old_space, new_space );
1595       orig = orig-&gt;debug_orig();
1596     } while (orig != NULL &amp;&amp; orig != n-&gt;debug_orig());
1597   }
1598 #endif //ASSERT
1599 }
1600 
1601 // call this from debugger:
1602 Node* find_node(Node* n, int idx) {
1603   return n-&gt;find(idx);
1604 }
1605 
1606 // call this from debugger with root node as default:
1607 Node* find_node(int idx) {
1608   return Compile::current()-&gt;root()-&gt;find(idx);
1609 }
1610 
1611 //------------------------------find-------------------------------------------
1612 Node* Node::find(int idx) const {
1613   ResourceArea *area = Thread::current()-&gt;resource_area();
1614   VectorSet old_space(area), new_space(area);
1615   Node* result = NULL;
1616   find_recur(Compile::current(), result, (Node*) this, idx, false, &amp;old_space, &amp;new_space );
1617   return result;
1618 }
1619 
1620 //------------------------------find_ctrl--------------------------------------
1621 // Find an ancestor to this node in the control history with given _idx
1622 Node* Node::find_ctrl(int idx) const {
1623   ResourceArea *area = Thread::current()-&gt;resource_area();
1624   VectorSet old_space(area), new_space(area);
1625   Node* result = NULL;
1626   find_recur(Compile::current(), result, (Node*) this, idx, true, &amp;old_space, &amp;new_space );
1627   return result;
1628 }
1629 #endif
1630 
1631 
1632 
1633 #ifndef PRODUCT
1634 
1635 // -----------------------------Name-------------------------------------------
1636 extern const char *NodeClassNames[];
1637 const char *Node::Name() const { return NodeClassNames[Opcode()]; }
1638 
1639 static bool is_disconnected(const Node* n) {
1640   for (uint i = 0; i &lt; n-&gt;req(); i++) {
1641     if (n-&gt;in(i) != NULL)  return false;
1642   }
1643   return true;
1644 }
1645 
1646 #ifdef ASSERT
1647 void Node::dump_orig(outputStream *st, bool print_key) const {
1648   Compile* C = Compile::current();
1649   Node* orig = _debug_orig;
1650   if (NotANode(orig)) orig = NULL;
1651   if (orig != NULL &amp;&amp; !C-&gt;node_arena()-&gt;contains(orig)) orig = NULL;
1652   if (orig == NULL) return;
1653   if (print_key) {
1654     st-&gt;print(&quot; !orig=&quot;);
1655   }
1656   Node* fast = orig-&gt;debug_orig(); // tortoise &amp; hare algorithm to detect loops
1657   if (NotANode(fast)) fast = NULL;
1658   while (orig != NULL) {
1659     bool discon = is_disconnected(orig);  // if discon, print [123] else 123
1660     if (discon) st-&gt;print(&quot;[&quot;);
1661     if (!Compile::current()-&gt;node_arena()-&gt;contains(orig))
1662       st-&gt;print(&quot;o&quot;);
1663     st-&gt;print(&quot;%d&quot;, orig-&gt;_idx);
1664     if (discon) st-&gt;print(&quot;]&quot;);
1665     orig = orig-&gt;debug_orig();
1666     if (NotANode(orig)) orig = NULL;
1667     if (orig != NULL &amp;&amp; !C-&gt;node_arena()-&gt;contains(orig)) orig = NULL;
1668     if (orig != NULL) st-&gt;print(&quot;,&quot;);
1669     if (fast != NULL) {
1670       // Step fast twice for each single step of orig:
1671       fast = fast-&gt;debug_orig();
1672       if (NotANode(fast)) fast = NULL;
1673       if (fast != NULL &amp;&amp; fast != orig) {
1674         fast = fast-&gt;debug_orig();
1675         if (NotANode(fast)) fast = NULL;
1676       }
1677       if (fast == orig) {
1678         st-&gt;print(&quot;...&quot;);
1679         break;
1680       }
1681     }
1682   }
1683 }
1684 
1685 void Node::set_debug_orig(Node* orig) {
1686   _debug_orig = orig;
1687   if (BreakAtNode == 0)  return;
1688   if (NotANode(orig))  orig = NULL;
1689   int trip = 10;
1690   while (orig != NULL) {
1691     if (orig-&gt;debug_idx() == BreakAtNode || (int)orig-&gt;_idx == BreakAtNode) {
1692       tty-&gt;print_cr(&quot;BreakAtNode: _idx=%d _debug_idx=%d orig._idx=%d orig._debug_idx=%d&quot;,
1693                     this-&gt;_idx, this-&gt;debug_idx(), orig-&gt;_idx, orig-&gt;debug_idx());
1694       BREAKPOINT;
1695     }
1696     orig = orig-&gt;debug_orig();
1697     if (NotANode(orig))  orig = NULL;
1698     if (trip-- &lt;= 0)  break;
1699   }
1700 }
1701 #endif //ASSERT
1702 
1703 //------------------------------dump------------------------------------------
1704 // Dump a Node
1705 void Node::dump(const char* suffix, bool mark, outputStream *st) const {
1706   Compile* C = Compile::current();
1707   bool is_new = C-&gt;node_arena()-&gt;contains(this);
1708   C-&gt;_in_dump_cnt++;
1709   st-&gt;print(&quot;%c%d%s\t%s\t=== &quot;, is_new ? &#39; &#39; : &#39;o&#39;, _idx, mark ? &quot; &gt;&quot; : &quot;&quot;, Name());
1710 
1711   // Dump the required and precedence inputs
1712   dump_req(st);
1713   dump_prec(st);
1714   // Dump the outputs
1715   dump_out(st);
1716 
1717   if (is_disconnected(this)) {
1718 #ifdef ASSERT
1719     st-&gt;print(&quot;  [%d]&quot;,debug_idx());
1720     dump_orig(st);
1721 #endif
1722     st-&gt;cr();
1723     C-&gt;_in_dump_cnt--;
1724     return;                     // don&#39;t process dead nodes
1725   }
1726 
1727   if (C-&gt;clone_map().value(_idx) != 0) {
1728     C-&gt;clone_map().dump(_idx);
1729   }
1730   // Dump node-specific info
1731   dump_spec(st);
1732 #ifdef ASSERT
1733   // Dump the non-reset _debug_idx
1734   if (Verbose &amp;&amp; WizardMode) {
1735     st-&gt;print(&quot;  [%d]&quot;,debug_idx());
1736   }
1737 #endif
1738 
1739   const Type *t = bottom_type();
1740 
1741   if (t != NULL &amp;&amp; (t-&gt;isa_instptr() || t-&gt;isa_klassptr())) {
1742     const TypeInstPtr  *toop = t-&gt;isa_instptr();
1743     const TypeKlassPtr *tkls = t-&gt;isa_klassptr();
1744     ciKlass*           klass = toop ? toop-&gt;klass() : (tkls ? tkls-&gt;klass() : NULL );
1745     if (klass &amp;&amp; klass-&gt;is_loaded() &amp;&amp; klass-&gt;is_interface()) {
1746       st-&gt;print(&quot;  Interface:&quot;);
1747     } else if (toop) {
1748       st-&gt;print(&quot;  Oop:&quot;);
1749     } else if (tkls) {
1750       st-&gt;print(&quot;  Klass:&quot;);
1751     }
1752     t-&gt;dump_on(st);
1753   } else if (t == Type::MEMORY) {
1754     st-&gt;print(&quot;  Memory:&quot;);
1755     MemNode::dump_adr_type(this, adr_type(), st);
1756   } else if (Verbose || WizardMode) {
1757     st-&gt;print(&quot;  Type:&quot;);
1758     if (t) {
1759       t-&gt;dump_on(st);
1760     } else {
1761       st-&gt;print(&quot;no type&quot;);
1762     }
1763   } else if (t-&gt;isa_vect() &amp;&amp; this-&gt;is_MachSpillCopy()) {
1764     // Dump MachSpillcopy vector type.
1765     t-&gt;dump_on(st);
1766   }
1767   if (is_new) {
1768     DEBUG_ONLY(dump_orig(st));
1769     Node_Notes* nn = C-&gt;node_notes_at(_idx);
1770     if (nn != NULL &amp;&amp; !nn-&gt;is_clear()) {
1771       if (nn-&gt;jvms() != NULL) {
1772         st-&gt;print(&quot; !jvms:&quot;);
1773         nn-&gt;jvms()-&gt;dump_spec(st);
1774       }
1775     }
1776   }
1777   if (suffix) st-&gt;print(&quot;%s&quot;, suffix);
1778   C-&gt;_in_dump_cnt--;
1779 }
1780 
1781 //------------------------------dump_req--------------------------------------
1782 void Node::dump_req(outputStream *st) const {
1783   // Dump the required input edges
1784   for (uint i = 0; i &lt; req(); i++) {    // For all required inputs
1785     Node* d = in(i);
1786     if (d == NULL) {
1787       st-&gt;print(&quot;_ &quot;);
1788     } else if (NotANode(d)) {
1789       st-&gt;print(&quot;NotANode &quot;);  // uninitialized, sentinel, garbage, etc.
1790     } else {
1791       st-&gt;print(&quot;%c%d &quot;, Compile::current()-&gt;node_arena()-&gt;contains(d) ? &#39; &#39; : &#39;o&#39;, d-&gt;_idx);
1792     }
1793   }
1794 }
1795 
1796 
1797 //------------------------------dump_prec-------------------------------------
1798 void Node::dump_prec(outputStream *st) const {
1799   // Dump the precedence edges
1800   int any_prec = 0;
1801   for (uint i = req(); i &lt; len(); i++) {       // For all precedence inputs
1802     Node* p = in(i);
1803     if (p != NULL) {
1804       if (!any_prec++) st-&gt;print(&quot; |&quot;);
1805       if (NotANode(p)) { st-&gt;print(&quot;NotANode &quot;); continue; }
1806       st-&gt;print(&quot;%c%d &quot;, Compile::current()-&gt;node_arena()-&gt;contains(in(i)) ? &#39; &#39; : &#39;o&#39;, in(i)-&gt;_idx);
1807     }
1808   }
1809 }
1810 
1811 //------------------------------dump_out--------------------------------------
1812 void Node::dump_out(outputStream *st) const {
1813   // Delimit the output edges
1814   st-&gt;print(&quot; [[&quot;);
1815   // Dump the output edges
1816   for (uint i = 0; i &lt; _outcnt; i++) {    // For all outputs
1817     Node* u = _out[i];
1818     if (u == NULL) {
1819       st-&gt;print(&quot;_ &quot;);
1820     } else if (NotANode(u)) {
1821       st-&gt;print(&quot;NotANode &quot;);
1822     } else {
1823       st-&gt;print(&quot;%c%d &quot;, Compile::current()-&gt;node_arena()-&gt;contains(u) ? &#39; &#39; : &#39;o&#39;, u-&gt;_idx);
1824     }
1825   }
1826   st-&gt;print(&quot;]] &quot;);
1827 }
1828 
1829 //----------------------------collect_nodes_i----------------------------------
1830 // Collects nodes from an Ideal graph, starting from a given start node and
1831 // moving in a given direction until a certain depth (distance from the start
1832 // node) is reached. Duplicates are ignored.
1833 // Arguments:
1834 //   nstack:        the nodes are collected into this array.
1835 //   start:         the node at which to start collecting.
1836 //   direction:     if this is a positive number, collect input nodes; if it is
1837 //                  a negative number, collect output nodes.
1838 //   depth:         collect nodes up to this distance from the start node.
1839 //   include_start: whether to include the start node in the result collection.
1840 //   only_ctrl:     whether to regard control edges only during traversal.
1841 //   only_data:     whether to regard data edges only during traversal.
1842 static void collect_nodes_i(GrowableArray&lt;Node*&gt; *nstack, const Node* start, int direction, uint depth, bool include_start, bool only_ctrl, bool only_data) {
1843   Node* s = (Node*) start; // remove const
1844   nstack-&gt;append(s);
1845   int begin = 0;
1846   int end = 0;
1847   for(uint i = 0; i &lt; depth; i++) {
1848     end = nstack-&gt;length();
1849     for(int j = begin; j &lt; end; j++) {
1850       Node* tp  = nstack-&gt;at(j);
1851       uint limit = direction &gt; 0 ? tp-&gt;len() : tp-&gt;outcnt();
1852       for(uint k = 0; k &lt; limit; k++) {
1853         Node* n = direction &gt; 0 ? tp-&gt;in(k) : tp-&gt;raw_out(k);
1854 
1855         if (NotANode(n))  continue;
1856         // do not recurse through top or the root (would reach unrelated stuff)
1857         if (n-&gt;is_Root() || n-&gt;is_top()) continue;
1858         if (only_ctrl &amp;&amp; !n-&gt;is_CFG()) continue;
1859         if (only_data &amp;&amp; n-&gt;is_CFG()) continue;
1860 
1861         bool on_stack = nstack-&gt;contains(n);
1862         if (!on_stack) {
1863           nstack-&gt;append(n);
1864         }
1865       }
1866     }
1867     begin = end;
1868   }
1869   if (!include_start) {
1870     nstack-&gt;remove(s);
1871   }
1872 }
1873 
1874 //------------------------------dump_nodes-------------------------------------
1875 static void dump_nodes(const Node* start, int d, bool only_ctrl) {
1876   if (NotANode(start)) return;
1877 
1878   GrowableArray &lt;Node *&gt; nstack(Compile::current()-&gt;live_nodes());
1879   collect_nodes_i(&amp;nstack, start, d, (uint) ABS(d), true, only_ctrl, false);
1880 
1881   int end = nstack.length();
1882   if (d &gt; 0) {
1883     for(int j = end-1; j &gt;= 0; j--) {
1884       nstack.at(j)-&gt;dump();
1885     }
1886   } else {
1887     for(int j = 0; j &lt; end; j++) {
1888       nstack.at(j)-&gt;dump();
1889     }
1890   }
1891 }
1892 
1893 //------------------------------dump-------------------------------------------
1894 void Node::dump(int d) const {
1895   dump_nodes(this, d, false);
1896 }
1897 
1898 //------------------------------dump_ctrl--------------------------------------
1899 // Dump a Node&#39;s control history to depth
1900 void Node::dump_ctrl(int d) const {
1901   dump_nodes(this, d, true);
1902 }
1903 
1904 //-----------------------------dump_compact------------------------------------
1905 void Node::dump_comp() const {
1906   this-&gt;dump_comp(&quot;\n&quot;);
1907 }
1908 
1909 //-----------------------------dump_compact------------------------------------
1910 // Dump a Node in compact representation, i.e., just print its name and index.
1911 // Nodes can specify additional specifics to print in compact representation by
1912 // implementing dump_compact_spec.
1913 void Node::dump_comp(const char* suffix, outputStream *st) const {
1914   Compile* C = Compile::current();
1915   C-&gt;_in_dump_cnt++;
1916   st-&gt;print(&quot;%s(%d)&quot;, Name(), _idx);
1917   this-&gt;dump_compact_spec(st);
1918   if (suffix) {
1919     st-&gt;print(&quot;%s&quot;, suffix);
1920   }
1921   C-&gt;_in_dump_cnt--;
1922 }
1923 
1924 //----------------------------dump_related-------------------------------------
1925 // Dump a Node&#39;s related nodes - the notion of &quot;related&quot; depends on the Node at
1926 // hand and is determined by the implementation of the virtual method rel.
1927 void Node::dump_related() const {
1928   Compile* C = Compile::current();
1929   GrowableArray &lt;Node *&gt; in_rel(C-&gt;unique());
1930   GrowableArray &lt;Node *&gt; out_rel(C-&gt;unique());
1931   this-&gt;related(&amp;in_rel, &amp;out_rel, false);
1932   for (int i = in_rel.length() - 1; i &gt;= 0; i--) {
1933     in_rel.at(i)-&gt;dump();
1934   }
1935   this-&gt;dump(&quot;\n&quot;, true);
1936   for (int i = 0; i &lt; out_rel.length(); i++) {
1937     out_rel.at(i)-&gt;dump();
1938   }
1939 }
1940 
1941 //----------------------------dump_related-------------------------------------
1942 // Dump a Node&#39;s related nodes up to a given depth (distance from the start
1943 // node).
1944 // Arguments:
1945 //   d_in:  depth for input nodes.
1946 //   d_out: depth for output nodes (note: this also is a positive number).
1947 void Node::dump_related(uint d_in, uint d_out) const {
1948   Compile* C = Compile::current();
1949   GrowableArray &lt;Node *&gt; in_rel(C-&gt;unique());
1950   GrowableArray &lt;Node *&gt; out_rel(C-&gt;unique());
1951 
1952   // call collect_nodes_i directly
1953   collect_nodes_i(&amp;in_rel, this, 1, d_in, false, false, false);
1954   collect_nodes_i(&amp;out_rel, this, -1, d_out, false, false, false);
1955 
1956   for (int i = in_rel.length() - 1; i &gt;= 0; i--) {
1957     in_rel.at(i)-&gt;dump();
1958   }
1959   this-&gt;dump(&quot;\n&quot;, true);
1960   for (int i = 0; i &lt; out_rel.length(); i++) {
1961     out_rel.at(i)-&gt;dump();
1962   }
1963 }
1964 
1965 //------------------------dump_related_compact---------------------------------
1966 // Dump a Node&#39;s related nodes in compact representation. The notion of
1967 // &quot;related&quot; depends on the Node at hand and is determined by the implementation
1968 // of the virtual method rel.
1969 void Node::dump_related_compact() const {
1970   Compile* C = Compile::current();
1971   GrowableArray &lt;Node *&gt; in_rel(C-&gt;unique());
1972   GrowableArray &lt;Node *&gt; out_rel(C-&gt;unique());
1973   this-&gt;related(&amp;in_rel, &amp;out_rel, true);
1974   int n_in = in_rel.length();
1975   int n_out = out_rel.length();
1976 
1977   this-&gt;dump_comp(n_in == 0 ? &quot;\n&quot; : &quot;  &quot;);
1978   for (int i = 0; i &lt; n_in; i++) {
1979     in_rel.at(i)-&gt;dump_comp(i == n_in - 1 ? &quot;\n&quot; : &quot;  &quot;);
1980   }
1981   for (int i = 0; i &lt; n_out; i++) {
1982     out_rel.at(i)-&gt;dump_comp(i == n_out - 1 ? &quot;\n&quot; : &quot;  &quot;);
1983   }
1984 }
1985 
1986 //------------------------------related----------------------------------------
1987 // Collect a Node&#39;s related nodes. The default behaviour just collects the
1988 // inputs and outputs at depth 1, including both control and data flow edges,
1989 // regardless of whether the presentation is compact or not. For data nodes,
1990 // the default is to collect all data inputs (till level 1 if compact), and
1991 // outputs till level 1.
1992 void Node::related(GrowableArray&lt;Node*&gt; *in_rel, GrowableArray&lt;Node*&gt; *out_rel, bool compact) const {
1993   if (this-&gt;is_CFG()) {
1994     collect_nodes_i(in_rel, this, 1, 1, false, false, false);
1995     collect_nodes_i(out_rel, this, -1, 1, false, false, false);
1996   } else {
1997     if (compact) {
1998       this-&gt;collect_nodes(in_rel, 1, false, true);
1999     } else {
2000       this-&gt;collect_nodes_in_all_data(in_rel, false);
2001     }
2002     this-&gt;collect_nodes(out_rel, -1, false, false);
2003   }
2004 }
2005 
2006 //---------------------------collect_nodes-------------------------------------
2007 // An entry point to the low-level node collection facility, to start from a
2008 // given node in the graph. The start node is by default not included in the
2009 // result.
2010 // Arguments:
2011 //   ns:   collect the nodes into this data structure.
2012 //   d:    the depth (distance from start node) to which nodes should be
2013 //         collected. A value &gt;0 indicates input nodes, a value &lt;0, output
2014 //         nodes.
2015 //   ctrl: include only control nodes.
2016 //   data: include only data nodes.
2017 void Node::collect_nodes(GrowableArray&lt;Node*&gt; *ns, int d, bool ctrl, bool data) const {
2018   if (ctrl &amp;&amp; data) {
2019     // ignore nonsensical combination
2020     return;
2021   }
2022   collect_nodes_i(ns, this, d, (uint) ABS(d), false, ctrl, data);
2023 }
2024 
2025 //--------------------------collect_nodes_in-----------------------------------
2026 static void collect_nodes_in(Node* start, GrowableArray&lt;Node*&gt; *ns, bool primary_is_data, bool collect_secondary) {
2027   // The maximum depth is determined using a BFS that visits all primary (data
2028   // or control) inputs and increments the depth at each level.
2029   uint d_in = 0;
2030   GrowableArray&lt;Node*&gt; nodes(Compile::current()-&gt;unique());
2031   nodes.push(start);
2032   int nodes_at_current_level = 1;
2033   int n_idx = 0;
2034   while (nodes_at_current_level &gt; 0) {
2035     // Add all primary inputs reachable from the current level to the list, and
2036     // increase the depth if there were any.
2037     int nodes_at_next_level = 0;
2038     bool nodes_added = false;
2039     while (nodes_at_current_level &gt; 0) {
2040       nodes_at_current_level--;
2041       Node* current = nodes.at(n_idx++);
2042       for (uint i = 0; i &lt; current-&gt;len(); i++) {
2043         Node* n = current-&gt;in(i);
2044         if (NotANode(n)) {
2045           continue;
2046         }
2047         if ((primary_is_data &amp;&amp; n-&gt;is_CFG()) || (!primary_is_data &amp;&amp; !n-&gt;is_CFG())) {
2048           continue;
2049         }
2050         if (!nodes.contains(n)) {
2051           nodes.push(n);
2052           nodes_added = true;
2053           nodes_at_next_level++;
2054         }
2055       }
2056     }
2057     if (nodes_added) {
2058       d_in++;
2059     }
2060     nodes_at_current_level = nodes_at_next_level;
2061   }
2062   start-&gt;collect_nodes(ns, d_in, !primary_is_data, primary_is_data);
2063   if (collect_secondary) {
2064     // Now, iterate over the secondary nodes in ns and add the respective
2065     // boundary reachable from them.
2066     GrowableArray&lt;Node*&gt; sns(Compile::current()-&gt;unique());
2067     for (GrowableArrayIterator&lt;Node*&gt; it = ns-&gt;begin(); it != ns-&gt;end(); ++it) {
2068       Node* n = *it;
2069       n-&gt;collect_nodes(&amp;sns, 1, primary_is_data, !primary_is_data);
2070       for (GrowableArrayIterator&lt;Node*&gt; d = sns.begin(); d != sns.end(); ++d) {
2071         ns-&gt;append_if_missing(*d);
2072       }
2073       sns.clear();
2074     }
2075   }
2076 }
2077 
2078 //---------------------collect_nodes_in_all_data-------------------------------
2079 // Collect the entire data input graph. Include the control boundary if
2080 // requested.
2081 // Arguments:
2082 //   ns:   collect the nodes into this data structure.
2083 //   ctrl: if true, include the control boundary.
2084 void Node::collect_nodes_in_all_data(GrowableArray&lt;Node*&gt; *ns, bool ctrl) const {
2085   collect_nodes_in((Node*) this, ns, true, ctrl);
2086 }
2087 
2088 //--------------------------collect_nodes_in_all_ctrl--------------------------
2089 // Collect the entire control input graph. Include the data boundary if
2090 // requested.
2091 //   ns:   collect the nodes into this data structure.
2092 //   data: if true, include the control boundary.
2093 void Node::collect_nodes_in_all_ctrl(GrowableArray&lt;Node*&gt; *ns, bool data) const {
2094   collect_nodes_in((Node*) this, ns, false, data);
2095 }
2096 
2097 //------------------collect_nodes_out_all_ctrl_boundary------------------------
2098 // Collect the entire output graph until hitting control node boundaries, and
2099 // include those.
2100 void Node::collect_nodes_out_all_ctrl_boundary(GrowableArray&lt;Node*&gt; *ns) const {
2101   // Perform a BFS and stop at control nodes.
2102   GrowableArray&lt;Node*&gt; nodes(Compile::current()-&gt;unique());
2103   nodes.push((Node*) this);
2104   while (nodes.length() &gt; 0) {
2105     Node* current = nodes.pop();
2106     if (NotANode(current)) {
2107       continue;
2108     }
2109     ns-&gt;append_if_missing(current);
2110     if (!current-&gt;is_CFG()) {
2111       for (DUIterator i = current-&gt;outs(); current-&gt;has_out(i); i++) {
2112         nodes.push(current-&gt;out(i));
2113       }
2114     }
2115   }
2116   ns-&gt;remove((Node*) this);
2117 }
2118 
2119 // VERIFICATION CODE
2120 // For each input edge to a node (ie - for each Use-Def edge), verify that
2121 // there is a corresponding Def-Use edge.
2122 //------------------------------verify_edges-----------------------------------
2123 void Node::verify_edges(Unique_Node_List &amp;visited) {
2124   uint i, j, idx;
2125   int  cnt;
2126   Node *n;
2127 
2128   // Recursive termination test
2129   if (visited.member(this))  return;
2130   visited.push(this);
2131 
2132   // Walk over all input edges, checking for correspondence
2133   for( i = 0; i &lt; len(); i++ ) {
2134     n = in(i);
2135     if (n != NULL &amp;&amp; !n-&gt;is_top()) {
2136       // Count instances of (Node *)this
2137       cnt = 0;
2138       for (idx = 0; idx &lt; n-&gt;_outcnt; idx++ ) {
2139         if (n-&gt;_out[idx] == (Node *)this)  cnt++;
2140       }
2141       assert( cnt &gt; 0,&quot;Failed to find Def-Use edge.&quot; );
2142       // Check for duplicate edges
2143       // walk the input array downcounting the input edges to n
2144       for( j = 0; j &lt; len(); j++ ) {
2145         if( in(j) == n ) cnt--;
2146       }
2147       assert( cnt == 0,&quot;Mismatched edge count.&quot;);
2148     } else if (n == NULL) {
2149       assert(i &gt;= req() || i == 0 || is_Region() || is_Phi() || is_ArrayCopy() ||
2150              (is_Allocate() &amp;&amp; i &gt;= AllocateNode::InlineTypeNode) ||
2151              (is_Unlock() &amp;&amp; i == req()-1),
2152              &quot;only region, phi, arraycopy, allocate or unlock nodes have null data edges&quot;);
2153     } else {
2154       assert(n-&gt;is_top(), &quot;sanity&quot;);
2155       // Nothing to check.
2156     }
2157   }
2158   // Recursive walk over all input edges
2159   for( i = 0; i &lt; len(); i++ ) {
2160     n = in(i);
2161     if( n != NULL )
2162       in(i)-&gt;verify_edges(visited);
2163   }
2164 }
2165 
2166 // Verify all nodes if verify_depth is negative
2167 void Node::verify(Node* n, int verify_depth) {
2168   assert(verify_depth != 0, &quot;depth should not be 0&quot;);
2169   ResourceMark rm;
2170   ResourceArea* area = Thread::current()-&gt;resource_area();
2171   VectorSet old_space(area);
2172   VectorSet new_space(area);
2173   Node_List worklist(area);
2174   worklist.push(n);
2175   Compile* C = Compile::current();
2176   uint last_index_on_current_depth = 0;
2177   verify_depth--; // Visiting the first node on depth 1
2178   // Only add nodes to worklist if verify_depth is negative (visit all nodes) or greater than 0
2179   bool add_to_worklist = verify_depth != 0;
2180 
2181 
2182   for (uint list_index = 0; list_index &lt; worklist.size(); list_index++) {
2183     n = worklist[list_index];
2184 
2185     if (n-&gt;is_Con() &amp;&amp; n-&gt;bottom_type() == Type::TOP) {
2186       if (C-&gt;cached_top_node() == NULL) {
2187         C-&gt;set_cached_top_node((Node*)n);
2188       }
2189       assert(C-&gt;cached_top_node() == n, &quot;TOP node must be unique&quot;);
2190     }
2191 
2192     for (uint i = 0; i &lt; n-&gt;len(); i++) {
2193       Node* x = n-&gt;in(i);
2194       if (!x || x-&gt;is_top()) {
2195         continue;
2196       }
2197 
2198       // Verify my input has a def-use edge to me
2199       // Count use-def edges from n to x
2200       int cnt = 0;
2201       for (uint j = 0; j &lt; n-&gt;len(); j++) {
2202         if (n-&gt;in(j) == x) {
2203           cnt++;
2204         }
2205       }
2206 
2207       // Count def-use edges from x to n
2208       uint max = x-&gt;_outcnt;
2209       for (uint k = 0; k &lt; max; k++) {
2210         if (x-&gt;_out[k] == n) {
2211           cnt--;
2212         }
2213       }
2214       assert(cnt == 0, &quot;mismatched def-use edge counts&quot;);
2215 
2216       // Contained in new_space or old_space?
2217       VectorSet* v = C-&gt;node_arena()-&gt;contains(x) ? &amp;new_space : &amp;old_space;
2218       // Check for visited in the proper space. Numberings are not unique
2219       // across spaces so we need a separate VectorSet for each space.
2220       if (add_to_worklist &amp;&amp; !v-&gt;test_set(x-&gt;_idx)) {
2221         worklist.push(x);
2222       }
2223     }
2224 
2225     if (verify_depth &gt; 0 &amp;&amp; list_index == last_index_on_current_depth) {
2226       // All nodes on this depth were processed and its inputs are on the worklist. Decrement verify_depth and
2227       // store the current last list index which is the last node in the list with the new depth. All nodes
2228       // added afterwards will have a new depth again. Stop adding new nodes if depth limit is reached (=0).
2229       verify_depth--;
2230       if (verify_depth == 0) {
2231         add_to_worklist = false;
2232       }
2233       last_index_on_current_depth = worklist.size() - 1;
2234     }
2235   }
2236 }
2237 #endif
2238 
2239 //------------------------------walk-------------------------------------------
2240 // Graph walk, with both pre-order and post-order functions
2241 void Node::walk(NFunc pre, NFunc post, void *env) {
2242   VectorSet visited(Thread::current()-&gt;resource_area()); // Setup for local walk
2243   walk_(pre, post, env, visited);
2244 }
2245 
2246 void Node::walk_(NFunc pre, NFunc post, void *env, VectorSet &amp;visited) {
2247   if( visited.test_set(_idx) ) return;
2248   pre(*this,env);               // Call the pre-order walk function
2249   for( uint i=0; i&lt;_max; i++ )
2250     if( in(i) )                 // Input exists and is not walked?
2251       in(i)-&gt;walk_(pre,post,env,visited); // Walk it with pre &amp; post functions
2252   post(*this,env);              // Call the post-order walk function
2253 }
2254 
2255 void Node::nop(Node &amp;, void*) {}
2256 
2257 //------------------------------Registers--------------------------------------
2258 // Do we Match on this edge index or not?  Generally false for Control
2259 // and true for everything else.  Weird for calls &amp; returns.
2260 uint Node::match_edge(uint idx) const {
2261   return idx;                   // True for other than index 0 (control)
2262 }
2263 
2264 static RegMask _not_used_at_all;
2265 // Register classes are defined for specific machines
2266 const RegMask &amp;Node::out_RegMask() const {
2267   ShouldNotCallThis();
2268   return _not_used_at_all;
2269 }
2270 
2271 const RegMask &amp;Node::in_RegMask(uint) const {
2272   ShouldNotCallThis();
2273   return _not_used_at_all;
2274 }
2275 
2276 //=============================================================================
2277 //-----------------------------------------------------------------------------
2278 void Node_Array::reset( Arena *new_arena ) {
2279   _a-&gt;Afree(_nodes,_max*sizeof(Node*));
2280   _max   = 0;
2281   _nodes = NULL;
2282   _a     = new_arena;
2283 }
2284 
2285 //------------------------------clear------------------------------------------
2286 // Clear all entries in _nodes to NULL but keep storage
2287 void Node_Array::clear() {
2288   Copy::zero_to_bytes( _nodes, _max*sizeof(Node*) );
2289 }
2290 
2291 //-----------------------------------------------------------------------------
2292 void Node_Array::grow( uint i ) {
2293   if( !_max ) {
2294     _max = 1;
2295     _nodes = (Node**)_a-&gt;Amalloc( _max * sizeof(Node*) );
2296     _nodes[0] = NULL;
2297   }
2298   uint old = _max;
2299   _max = next_power_of_2(i);
2300   _nodes = (Node**)_a-&gt;Arealloc( _nodes, old*sizeof(Node*),_max*sizeof(Node*));
2301   Copy::zero_to_bytes( &amp;_nodes[old], (_max-old)*sizeof(Node*) );
2302 }
2303 
2304 //-----------------------------------------------------------------------------
2305 void Node_Array::insert( uint i, Node *n ) {
2306   if( _nodes[_max-1] ) grow(_max);      // Get more space if full
2307   Copy::conjoint_words_to_higher((HeapWord*)&amp;_nodes[i], (HeapWord*)&amp;_nodes[i+1], ((_max-i-1)*sizeof(Node*)));
2308   _nodes[i] = n;
2309 }
2310 
2311 //-----------------------------------------------------------------------------
2312 void Node_Array::remove( uint i ) {
2313   Copy::conjoint_words_to_lower((HeapWord*)&amp;_nodes[i+1], (HeapWord*)&amp;_nodes[i], ((_max-i-1)*sizeof(Node*)));
2314   _nodes[_max-1] = NULL;
2315 }
2316 
2317 //-----------------------------------------------------------------------------
2318 void Node_Array::sort( C_sort_func_t func) {
2319   qsort( _nodes, _max, sizeof( Node* ), func );
2320 }
2321 
2322 //-----------------------------------------------------------------------------
2323 void Node_Array::dump() const {
2324 #ifndef PRODUCT
2325   for( uint i = 0; i &lt; _max; i++ ) {
2326     Node *nn = _nodes[i];
2327     if( nn != NULL ) {
2328       tty-&gt;print(&quot;%5d--&gt; &quot;,i); nn-&gt;dump();
2329     }
2330   }
2331 #endif
2332 }
2333 
2334 //--------------------------is_iteratively_computed------------------------------
2335 // Operation appears to be iteratively computed (such as an induction variable)
2336 // It is possible for this operation to return false for a loop-varying
2337 // value, if it appears (by local graph inspection) to be computed by a simple conditional.
2338 bool Node::is_iteratively_computed() {
2339   if (ideal_reg()) { // does operation have a result register?
2340     for (uint i = 1; i &lt; req(); i++) {
2341       Node* n = in(i);
2342       if (n != NULL &amp;&amp; n-&gt;is_Phi()) {
2343         for (uint j = 1; j &lt; n-&gt;req(); j++) {
2344           if (n-&gt;in(j) == this) {
2345             return true;
2346           }
2347         }
2348       }
2349     }
2350   }
2351   return false;
2352 }
2353 
2354 //--------------------------find_similar------------------------------
2355 // Return a node with opcode &quot;opc&quot; and same inputs as &quot;this&quot; if one can
2356 // be found; Otherwise return NULL;
2357 Node* Node::find_similar(int opc) {
2358   if (req() &gt;= 2) {
2359     Node* def = in(1);
2360     if (def &amp;&amp; def-&gt;outcnt() &gt;= 2) {
2361       for (DUIterator_Fast dmax, i = def-&gt;fast_outs(dmax); i &lt; dmax; i++) {
2362         Node* use = def-&gt;fast_out(i);
2363         if (use != this &amp;&amp;
2364             use-&gt;Opcode() == opc &amp;&amp;
2365             use-&gt;req() == req()) {
2366           uint j;
2367           for (j = 0; j &lt; use-&gt;req(); j++) {
2368             if (use-&gt;in(j) != in(j)) {
2369               break;
2370             }
2371           }
2372           if (j == use-&gt;req()) {
2373             return use;
2374           }
2375         }
2376       }
2377     }
2378   }
2379   return NULL;
2380 }
2381 
2382 
2383 //--------------------------unique_ctrl_out------------------------------
2384 // Return the unique control out if only one. Null if none or more than one.
2385 Node* Node::unique_ctrl_out() const {
2386   Node* found = NULL;
2387   for (uint i = 0; i &lt; outcnt(); i++) {
2388     Node* use = raw_out(i);
2389     if (use-&gt;is_CFG() &amp;&amp; use != this) {
2390       if (found != NULL) return NULL;
2391       found = use;
2392     }
2393   }
2394   return found;
2395 }
2396 
2397 void Node::ensure_control_or_add_prec(Node* c) {
2398   if (in(0) == NULL) {
2399     set_req(0, c);
2400   } else if (in(0) != c) {
2401     add_prec(c);
2402   }
2403 }
2404 
2405 //=============================================================================
2406 //------------------------------yank-------------------------------------------
2407 // Find and remove
2408 void Node_List::yank( Node *n ) {
2409   uint i;
2410   for( i = 0; i &lt; _cnt; i++ )
2411     if( _nodes[i] == n )
2412       break;
2413 
2414   if( i &lt; _cnt )
2415     _nodes[i] = _nodes[--_cnt];
2416 }
2417 
2418 //------------------------------dump-------------------------------------------
2419 void Node_List::dump() const {
2420 #ifndef PRODUCT
2421   for( uint i = 0; i &lt; _cnt; i++ )
2422     if( _nodes[i] ) {
2423       tty-&gt;print(&quot;%5d--&gt; &quot;,i);
2424       _nodes[i]-&gt;dump();
2425     }
2426 #endif
2427 }
2428 
2429 void Node_List::dump_simple() const {
2430 #ifndef PRODUCT
2431   for( uint i = 0; i &lt; _cnt; i++ )
2432     if( _nodes[i] ) {
2433       tty-&gt;print(&quot; %d&quot;, _nodes[i]-&gt;_idx);
2434     } else {
2435       tty-&gt;print(&quot; NULL&quot;);
2436     }
2437 #endif
2438 }
2439 
2440 //=============================================================================
2441 //------------------------------remove-----------------------------------------
2442 void Unique_Node_List::remove(Node* n) {
2443   if (_in_worklist.test(n-&gt;_idx)) {
2444     for (uint i = 0; i &lt; size(); i++) {
2445       if (_nodes[i] == n) {
2446         map(i, Node_List::pop());
2447         _in_worklist.remove(n-&gt;_idx);
2448         return;
2449       }
2450     }
2451     ShouldNotReachHere();
2452   }
2453 }
2454 
2455 //-----------------------remove_useless_nodes----------------------------------
2456 // Remove useless nodes from worklist
2457 void Unique_Node_List::remove_useless_nodes(VectorSet &amp;useful) {
2458 
2459   for (uint i = 0; i &lt; size(); ++i) {
2460     Node *n = at(i);
2461     assert( n != NULL, &quot;Did not expect null entries in worklist&quot;);
2462     if (!useful.test(n-&gt;_idx)) {
2463       _in_worklist.remove(n-&gt;_idx);
2464       map(i,Node_List::pop());
2465       // Node *replacement = Node_List::pop();
2466       // if( i != size() ) { // Check if removing last entry
2467       //   _nodes[i] = replacement;
2468       // }
2469       --i;  // Visit popped node
2470       // If it was last entry, loop terminates since size() was also reduced
2471     }
2472   }
2473 }
2474 
2475 //=============================================================================
2476 void Node_Stack::grow() {
2477   size_t old_top = pointer_delta(_inode_top,_inodes,sizeof(INode)); // save _top
2478   size_t old_max = pointer_delta(_inode_max,_inodes,sizeof(INode));
2479   size_t max = old_max &lt;&lt; 1;             // max * 2
2480   _inodes = REALLOC_ARENA_ARRAY(_a, INode, _inodes, old_max, max);
2481   _inode_max = _inodes + max;
2482   _inode_top = _inodes + old_top;        // restore _top
2483 }
2484 
2485 // Node_Stack is used to map nodes.
2486 Node* Node_Stack::find(uint idx) const {
2487   uint sz = size();
2488   for (uint i=0; i &lt; sz; i++) {
2489     if (idx == index_at(i) )
2490       return node_at(i);
2491   }
2492   return NULL;
2493 }
2494 
2495 //=============================================================================
2496 uint TypeNode::size_of() const { return sizeof(*this); }
2497 #ifndef PRODUCT
2498 void TypeNode::dump_spec(outputStream *st) const {
2499   if( !Verbose &amp;&amp; !WizardMode ) {
2500     // standard dump does this in Verbose and WizardMode
2501     st-&gt;print(&quot; #&quot;); _type-&gt;dump_on(st);
2502   }
2503 }
2504 
2505 void TypeNode::dump_compact_spec(outputStream *st) const {
2506   st-&gt;print(&quot;#&quot;);
2507   _type-&gt;dump_on(st);
2508 }
2509 #endif
2510 uint TypeNode::hash() const {
2511   return Node::hash() + _type-&gt;hash();
2512 }
2513 bool TypeNode::cmp( const Node &amp;n ) const
2514 { return !Type::cmp( _type, ((TypeNode&amp;)n)._type ); }
2515 const Type *TypeNode::bottom_type() const { return _type; }
2516 const Type* TypeNode::Value(PhaseGVN* phase) const { return _type; }
2517 
2518 //------------------------------ideal_reg--------------------------------------
2519 uint TypeNode::ideal_reg() const {
2520   return _type-&gt;ideal_reg();
2521 }
    </pre>
  </body>
</html>