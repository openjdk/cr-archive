<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/memory/metaspaceShared.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="../jvmci/vmStructs_jvmci.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../oops/method.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/memory/metaspaceShared.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 648 
 649 class CollectClassesClosure : public KlassClosure {
 650   void do_klass(Klass* k) {
 651     if (k-&gt;is_instance_klass() &amp;&amp;
 652         SystemDictionaryShared::is_excluded_class(InstanceKlass::cast(k))) {
 653       // Don&#39;t add to the _global_klass_objects
 654     } else {
 655       _global_klass_objects-&gt;append_if_missing(k);
 656     }
 657     if (k-&gt;is_array_klass()) {
 658       // Add in the array classes too
 659       ArrayKlass* ak = ArrayKlass::cast(k);
 660       Klass* h = ak-&gt;higher_dimension();
 661       if (h != NULL) {
 662         h-&gt;array_klasses_do(collect_array_classes);
 663       }
 664     }
 665   }
 666 };
 667 



























 668 static void remove_unshareable_in_classes() {
 669   for (int i = 0; i &lt; _global_klass_objects-&gt;length(); i++) {
 670     Klass* k = _global_klass_objects-&gt;at(i);
 671     if (!k-&gt;is_objArray_klass()) {
 672       // InstanceKlass and TypeArrayKlass will in turn call remove_unshareable_info
 673       // on their array classes.
 674       assert(k-&gt;is_instance_klass() || k-&gt;is_typeArray_klass(), &quot;must be&quot;);
 675       k-&gt;remove_unshareable_info();
 676     }
 677   }
 678 }
 679 
 680 static void remove_java_mirror_in_classes() {
 681   for (int i = 0; i &lt; _global_klass_objects-&gt;length(); i++) {
 682     Klass* k = _global_klass_objects-&gt;at(i);
 683     if (!k-&gt;is_objArray_klass()) {
 684       // InstanceKlass and TypeArrayKlass will in turn call remove_unshareable_info
 685       // on their array classes.
 686       assert(k-&gt;is_instance_klass() || k-&gt;is_typeArray_klass(), &quot;must be&quot;);
 687       k-&gt;remove_java_mirror();
</pre>
<hr />
<pre>
1227   void dump_java_heap_objects() NOT_CDS_JAVA_HEAP_RETURN;
1228   void dump_archive_heap_oopmaps() NOT_CDS_JAVA_HEAP_RETURN;
1229   void dump_archive_heap_oopmaps(GrowableArray&lt;MemRegion&gt;* regions,
1230                                  GrowableArray&lt;ArchiveHeapOopmapInfo&gt;* oopmaps);
1231   void dump_symbols();
1232   char* dump_read_only_tables();
1233   void print_class_stats();
1234   void print_region_stats(FileMapInfo* map_info);
1235   void print_bitmap_region_stats(size_t size, size_t total_size);
1236   void print_heap_region_stats(GrowableArray&lt;MemRegion&gt; *heap_mem,
1237                                const char *name, size_t total_size);
1238   void relocate_to_requested_base_address(CHeapBitMap* ptrmap);
1239 
1240 public:
1241 
1242   VMOp_Type type() const { return VMOp_PopulateDumpSharedSpace; }
1243   void doit();   // outline because gdb sucks
1244   bool allow_nested_vm_operations() const { return true; }
1245 }; // class VM_PopulateDumpSharedSpace
1246 
<span class="line-removed">1247 class SortedSymbolClosure: public SymbolClosure {</span>
<span class="line-removed">1248   GrowableArray&lt;Symbol*&gt; _symbols;</span>
<span class="line-removed">1249   virtual void do_symbol(Symbol** sym) {</span>
<span class="line-removed">1250     assert((*sym)-&gt;is_permanent(), &quot;archived symbols must be permanent&quot;);</span>
<span class="line-removed">1251     _symbols.append(*sym);</span>
<span class="line-removed">1252   }</span>
<span class="line-removed">1253   static int compare_symbols_by_address(Symbol** a, Symbol** b) {</span>
<span class="line-removed">1254     if (a[0] &lt; b[0]) {</span>
<span class="line-removed">1255       return -1;</span>
<span class="line-removed">1256     } else if (a[0] == b[0]) {</span>
<span class="line-removed">1257       ResourceMark rm;</span>
<span class="line-removed">1258       log_warning(cds)(&quot;Duplicated symbol %s unexpected&quot;, (*a)-&gt;as_C_string());</span>
<span class="line-removed">1259       return 0;</span>
<span class="line-removed">1260     } else {</span>
<span class="line-removed">1261       return 1;</span>
<span class="line-removed">1262     }</span>
<span class="line-removed">1263   }</span>
<span class="line-removed">1264 </span>
<span class="line-removed">1265 public:</span>
<span class="line-removed">1266   SortedSymbolClosure() {</span>
<span class="line-removed">1267     SymbolTable::symbols_do(this);</span>
<span class="line-removed">1268     _symbols.sort(compare_symbols_by_address);</span>
<span class="line-removed">1269   }</span>
<span class="line-removed">1270   GrowableArray&lt;Symbol*&gt;* get_sorted_symbols() {</span>
<span class="line-removed">1271     return &amp;_symbols;</span>
<span class="line-removed">1272   }</span>
<span class="line-removed">1273 };</span>
<span class="line-removed">1274 </span>
1275 // ArchiveCompactor --
1276 //
1277 // This class is the central piece of shared archive compaction -- all metaspace data are
1278 // initially allocated outside of the shared regions. ArchiveCompactor copies the
1279 // metaspace data into their final location in the shared regions.
1280 
1281 class ArchiveCompactor : AllStatic {
1282   static const int INITIAL_TABLE_SIZE = 8087;
1283   static const int MAX_TABLE_SIZE     = 1000000;
1284 
1285   static DumpAllocStats* _alloc_stats;
<span class="line-removed">1286   static SortedSymbolClosure* _ssc;</span>
1287 
1288   typedef KVHashtable&lt;address, address, mtInternal&gt; RelocationTable;
1289   static RelocationTable* _new_loc_table;
1290 
1291 public:
1292   static void initialize() {
1293     _alloc_stats = new(ResourceObj::C_HEAP, mtInternal)DumpAllocStats;
1294     _new_loc_table = new RelocationTable(INITIAL_TABLE_SIZE);
1295   }
1296   static DumpAllocStats* alloc_stats() {
1297     return _alloc_stats;
1298   }
1299 
1300   // Use this when you allocate space with MetaspaceShare::read_only_space_alloc()
1301   // outside of ArchiveCompactor::allocate(). These are usually for misc tables
1302   // that are allocated in the RO space.
1303   class OtherROAllocMark {
1304     char* _oldtop;
1305   public:
1306     OtherROAllocMark() {
</pre>
<hr />
<pre>
1424     }
1425   };
1426 
1427 #ifdef ASSERT
1428   class IsRefInArchiveChecker: public MetaspaceClosure {
1429   public:
1430     virtual bool do_ref(Ref* ref, bool read_only) {
1431       if (ref-&gt;not_null()) {
1432         char* obj = (char*)ref-&gt;obj();
1433         assert(_ro_region.contains(obj) || _rw_region.contains(obj),
1434                &quot;must be relocated to point to CDS archive&quot;);
1435       }
1436       return false; // Do not recurse.
1437     }
1438   };
1439 #endif
1440 
1441 public:
1442   static void copy_and_compact() {
1443     ResourceMark rm;
<span class="line-removed">1444     SortedSymbolClosure the_ssc; // StackObj</span>
<span class="line-removed">1445     _ssc = &amp;the_ssc;</span>
1446 
1447     log_info(cds)(&quot;Scanning all metaspace objects ... &quot;);
1448     {
1449       // allocate and shallow-copy RW objects, immediately following the MC region
1450       log_info(cds)(&quot;Allocating RW objects ... &quot;);
1451       _mc_region.pack(&amp;_rw_region);
1452 
1453       ResourceMark rm;
1454       ShallowCopier rw_copier(false);
1455       iterate_roots(&amp;rw_copier);
1456     }
1457     {
1458       // allocate and shallow-copy of RO object, immediately following the RW region
1459       log_info(cds)(&quot;Allocating RO objects ... &quot;);
1460       _rw_region.pack(&amp;_ro_region);
1461 
1462       ResourceMark rm;
1463       ShallowCopier ro_copier(true);
1464       iterate_roots(&amp;ro_copier);
1465     }
1466     {
1467       log_info(cds)(&quot;Relocating embedded pointers ... &quot;);
1468       ResourceMark rm;
1469       ShallowCopyEmbeddedRefRelocator emb_reloc;
1470       iterate_roots(&amp;emb_reloc);
1471     }
1472     {
1473       log_info(cds)(&quot;Relocating external roots ... &quot;);
1474       ResourceMark rm;
1475       RefRelocator ext_reloc;
1476       iterate_roots(&amp;ext_reloc);
1477     }
1478     {
1479       log_info(cds)(&quot;Fixing symbol identity hash ... &quot;);
1480       os::init_random(0x12345678);
<span class="line-modified">1481       GrowableArray&lt;Symbol*&gt;* symbols = _ssc-&gt;get_sorted_symbols();</span>
<span class="line-modified">1482       for (int i=0; i&lt;symbols-&gt;length(); i++) {</span>
<span class="line-modified">1483         symbols-&gt;at(i)-&gt;update_identity_hash();</span>


1484       }
1485     }
1486 #ifdef ASSERT
1487     {
1488       log_info(cds)(&quot;Verifying external roots ... &quot;);
1489       ResourceMark rm;
1490       IsRefInArchiveChecker checker;
1491       iterate_roots(&amp;checker);
1492     }
1493 #endif
<span class="line-removed">1494 </span>
<span class="line-removed">1495 </span>
<span class="line-removed">1496     // cleanup</span>
<span class="line-removed">1497     _ssc = NULL;</span>
1498   }
1499 
1500   // We must relocate the System::_well_known_klasses only after we have copied the
1501   // java objects in during dump_java_heap_objects(): during the object copy, we operate on
1502   // old objects which assert that their klass is the original klass.
1503   static void relocate_well_known_klasses() {
1504     {
1505       log_info(cds)(&quot;Relocating SystemDictionary::_well_known_klasses[] ... &quot;);
1506       ResourceMark rm;
1507       RefRelocator ext_reloc;
1508       SystemDictionary::well_known_klasses_do(&amp;ext_reloc);
1509     }
1510     // NOTE: after this point, we shouldn&#39;t have any globals that can reach the old
1511     // objects.
1512 
1513     // We cannot use any of the objects in the heap anymore (except for the
1514     // shared strings) because their headers no longer point to valid Klasses.
1515   }
1516 
1517   static void iterate_roots(MetaspaceClosure* it) {
1518     // To ensure deterministic contents in the archive, we just need to ensure that
1519     // we iterate the MetsapceObjs in a deterministic order. It doesn&#39;t matter where
1520     // the MetsapceObjs are located originally, as they are copied sequentially into
1521     // the archive during the iteration.
1522     //
1523     // The only issue here is that the symbol table and the system directories may be
1524     // randomly ordered, so we copy the symbols and klasses into two arrays and sort
1525     // them deterministically.
1526     //
1527     // During -Xshare:dump, the order of Symbol creation is strictly determined by
1528     // the SharedClassListFile (class loading is done in a single thread and the JIT
1529     // is disabled). Also, Symbols are allocated in monotonically increasing addresses
1530     // (see Symbol::operator new(size_t, int)). So if we iterate the Symbols by
1531     // ascending address order, we ensure that all Symbols are copied into deterministic
1532     // locations in the archive.
<span class="line-modified">1533     GrowableArray&lt;Symbol*&gt;* symbols = _ssc-&gt;get_sorted_symbols();</span>
<span class="line-modified">1534     for (int i=0; i&lt;symbols-&gt;length(); i++) {</span>
1535       it-&gt;push(symbols-&gt;adr_at(i));
1536     }
1537     if (_global_klass_objects != NULL) {
1538       // Need to fix up the pointers
1539       for (int i = 0; i &lt; _global_klass_objects-&gt;length(); i++) {
1540         // NOTE -- this requires that the vtable is NOT yet patched, or else we are hosed.
1541         it-&gt;push(_global_klass_objects-&gt;adr_at(i));
1542       }
1543     }
1544     FileMapInfo::metaspace_pointers_do(it, false);
1545     SystemDictionaryShared::dumptime_classes_do(it);
1546     Universe::metaspace_pointers_do(it);
1547     SymbolTable::metaspace_pointers_do(it);
1548     vmSymbols::metaspace_pointers_do(it);
1549 
1550     it-&gt;finish();
1551   }
1552 
1553   static Klass* get_relocated_klass(Klass* orig_klass) {
1554     assert(DumpSharedSpaces, &quot;dump time only&quot;);
1555     address* pp = _new_loc_table-&gt;lookup((address)orig_klass);
1556     assert(pp != NULL, &quot;must be&quot;);
1557     Klass* klass = (Klass*)(*pp);
1558     assert(klass-&gt;is_klass(), &quot;must be&quot;);
1559     return klass;
1560   }
1561 };
1562 
1563 DumpAllocStats* ArchiveCompactor::_alloc_stats;
<span class="line-removed">1564 SortedSymbolClosure* ArchiveCompactor::_ssc;</span>
1565 ArchiveCompactor::RelocationTable* ArchiveCompactor::_new_loc_table;
1566 
1567 void VM_PopulateDumpSharedSpace::dump_symbols() {
1568   log_info(cds)(&quot;Dumping symbol table ...&quot;);
1569 
1570   NOT_PRODUCT(SymbolTable::verify());
1571   SymbolTable::write_to_archive();
1572 }
1573 
1574 char* VM_PopulateDumpSharedSpace::dump_read_only_tables() {
1575   ArchiveCompactor::OtherROAllocMark mark;
1576 
1577   log_info(cds)(&quot;Removing java_mirror ... &quot;);
1578   if (!HeapShared::is_heap_object_archiving_allowed()) {
1579     clear_basic_type_mirrors();
1580   }
1581   remove_java_mirror_in_classes();
1582   log_info(cds)(&quot;done. &quot;);
1583 
1584   SystemDictionaryShared::write_to_archive();
</pre>
</td>
<td>
<hr />
<pre>
 648 
 649 class CollectClassesClosure : public KlassClosure {
 650   void do_klass(Klass* k) {
 651     if (k-&gt;is_instance_klass() &amp;&amp;
 652         SystemDictionaryShared::is_excluded_class(InstanceKlass::cast(k))) {
 653       // Don&#39;t add to the _global_klass_objects
 654     } else {
 655       _global_klass_objects-&gt;append_if_missing(k);
 656     }
 657     if (k-&gt;is_array_klass()) {
 658       // Add in the array classes too
 659       ArrayKlass* ak = ArrayKlass::cast(k);
 660       Klass* h = ak-&gt;higher_dimension();
 661       if (h != NULL) {
 662         h-&gt;array_klasses_do(collect_array_classes);
 663       }
 664     }
 665   }
 666 };
 667 
<span class="line-added"> 668 // Global object for holding symbols that created during class loading. See SymbolTable::new_symbol</span>
<span class="line-added"> 669 static GrowableArray&lt;Symbol*&gt;* _global_symbol_objects = NULL;</span>
<span class="line-added"> 670 </span>
<span class="line-added"> 671 static int compare_symbols_by_address(Symbol** a, Symbol** b) {</span>
<span class="line-added"> 672   if (a[0] &lt; b[0]) {</span>
<span class="line-added"> 673     return -1;</span>
<span class="line-added"> 674   } else if (a[0] == b[0]) {</span>
<span class="line-added"> 675     ResourceMark rm;</span>
<span class="line-added"> 676     log_warning(cds)(&quot;Duplicated symbol %s unexpected&quot;, (*a)-&gt;as_C_string());</span>
<span class="line-added"> 677     return 0;</span>
<span class="line-added"> 678   } else {</span>
<span class="line-added"> 679     return 1;</span>
<span class="line-added"> 680   }</span>
<span class="line-added"> 681 }</span>
<span class="line-added"> 682 </span>
<span class="line-added"> 683 void MetaspaceShared::add_symbol(Symbol* sym) {</span>
<span class="line-added"> 684   MutexLocker ml(CDSAddSymbol_lock, Mutex::_no_safepoint_check_flag);</span>
<span class="line-added"> 685   if (_global_symbol_objects == NULL) {</span>
<span class="line-added"> 686     _global_symbol_objects = new (ResourceObj::C_HEAP, mtSymbol) GrowableArray&lt;Symbol*&gt;(2048, mtSymbol);</span>
<span class="line-added"> 687   }</span>
<span class="line-added"> 688   _global_symbol_objects-&gt;append(sym);</span>
<span class="line-added"> 689 }</span>
<span class="line-added"> 690 </span>
<span class="line-added"> 691 GrowableArray&lt;Symbol*&gt;* MetaspaceShared::collected_symbols() {</span>
<span class="line-added"> 692   return _global_symbol_objects;</span>
<span class="line-added"> 693 }</span>
<span class="line-added"> 694 </span>
 695 static void remove_unshareable_in_classes() {
 696   for (int i = 0; i &lt; _global_klass_objects-&gt;length(); i++) {
 697     Klass* k = _global_klass_objects-&gt;at(i);
 698     if (!k-&gt;is_objArray_klass()) {
 699       // InstanceKlass and TypeArrayKlass will in turn call remove_unshareable_info
 700       // on their array classes.
 701       assert(k-&gt;is_instance_klass() || k-&gt;is_typeArray_klass(), &quot;must be&quot;);
 702       k-&gt;remove_unshareable_info();
 703     }
 704   }
 705 }
 706 
 707 static void remove_java_mirror_in_classes() {
 708   for (int i = 0; i &lt; _global_klass_objects-&gt;length(); i++) {
 709     Klass* k = _global_klass_objects-&gt;at(i);
 710     if (!k-&gt;is_objArray_klass()) {
 711       // InstanceKlass and TypeArrayKlass will in turn call remove_unshareable_info
 712       // on their array classes.
 713       assert(k-&gt;is_instance_klass() || k-&gt;is_typeArray_klass(), &quot;must be&quot;);
 714       k-&gt;remove_java_mirror();
</pre>
<hr />
<pre>
1254   void dump_java_heap_objects() NOT_CDS_JAVA_HEAP_RETURN;
1255   void dump_archive_heap_oopmaps() NOT_CDS_JAVA_HEAP_RETURN;
1256   void dump_archive_heap_oopmaps(GrowableArray&lt;MemRegion&gt;* regions,
1257                                  GrowableArray&lt;ArchiveHeapOopmapInfo&gt;* oopmaps);
1258   void dump_symbols();
1259   char* dump_read_only_tables();
1260   void print_class_stats();
1261   void print_region_stats(FileMapInfo* map_info);
1262   void print_bitmap_region_stats(size_t size, size_t total_size);
1263   void print_heap_region_stats(GrowableArray&lt;MemRegion&gt; *heap_mem,
1264                                const char *name, size_t total_size);
1265   void relocate_to_requested_base_address(CHeapBitMap* ptrmap);
1266 
1267 public:
1268 
1269   VMOp_Type type() const { return VMOp_PopulateDumpSharedSpace; }
1270   void doit();   // outline because gdb sucks
1271   bool allow_nested_vm_operations() const { return true; }
1272 }; // class VM_PopulateDumpSharedSpace
1273 




























1274 // ArchiveCompactor --
1275 //
1276 // This class is the central piece of shared archive compaction -- all metaspace data are
1277 // initially allocated outside of the shared regions. ArchiveCompactor copies the
1278 // metaspace data into their final location in the shared regions.
1279 
1280 class ArchiveCompactor : AllStatic {
1281   static const int INITIAL_TABLE_SIZE = 8087;
1282   static const int MAX_TABLE_SIZE     = 1000000;
1283 
1284   static DumpAllocStats* _alloc_stats;

1285 
1286   typedef KVHashtable&lt;address, address, mtInternal&gt; RelocationTable;
1287   static RelocationTable* _new_loc_table;
1288 
1289 public:
1290   static void initialize() {
1291     _alloc_stats = new(ResourceObj::C_HEAP, mtInternal)DumpAllocStats;
1292     _new_loc_table = new RelocationTable(INITIAL_TABLE_SIZE);
1293   }
1294   static DumpAllocStats* alloc_stats() {
1295     return _alloc_stats;
1296   }
1297 
1298   // Use this when you allocate space with MetaspaceShare::read_only_space_alloc()
1299   // outside of ArchiveCompactor::allocate(). These are usually for misc tables
1300   // that are allocated in the RO space.
1301   class OtherROAllocMark {
1302     char* _oldtop;
1303   public:
1304     OtherROAllocMark() {
</pre>
<hr />
<pre>
1422     }
1423   };
1424 
1425 #ifdef ASSERT
1426   class IsRefInArchiveChecker: public MetaspaceClosure {
1427   public:
1428     virtual bool do_ref(Ref* ref, bool read_only) {
1429       if (ref-&gt;not_null()) {
1430         char* obj = (char*)ref-&gt;obj();
1431         assert(_ro_region.contains(obj) || _rw_region.contains(obj),
1432                &quot;must be relocated to point to CDS archive&quot;);
1433       }
1434       return false; // Do not recurse.
1435     }
1436   };
1437 #endif
1438 
1439 public:
1440   static void copy_and_compact() {
1441     ResourceMark rm;


1442 
1443     log_info(cds)(&quot;Scanning all metaspace objects ... &quot;);
1444     {
1445       // allocate and shallow-copy RW objects, immediately following the MC region
1446       log_info(cds)(&quot;Allocating RW objects ... &quot;);
1447       _mc_region.pack(&amp;_rw_region);
1448 
1449       ResourceMark rm;
1450       ShallowCopier rw_copier(false);
1451       iterate_roots(&amp;rw_copier);
1452     }
1453     {
1454       // allocate and shallow-copy of RO object, immediately following the RW region
1455       log_info(cds)(&quot;Allocating RO objects ... &quot;);
1456       _rw_region.pack(&amp;_ro_region);
1457 
1458       ResourceMark rm;
1459       ShallowCopier ro_copier(true);
1460       iterate_roots(&amp;ro_copier);
1461     }
1462     {
1463       log_info(cds)(&quot;Relocating embedded pointers ... &quot;);
1464       ResourceMark rm;
1465       ShallowCopyEmbeddedRefRelocator emb_reloc;
1466       iterate_roots(&amp;emb_reloc);
1467     }
1468     {
1469       log_info(cds)(&quot;Relocating external roots ... &quot;);
1470       ResourceMark rm;
1471       RefRelocator ext_reloc;
1472       iterate_roots(&amp;ext_reloc);
1473     }
1474     {
1475       log_info(cds)(&quot;Fixing symbol identity hash ... &quot;);
1476       os::init_random(0x12345678);
<span class="line-modified">1477       GrowableArray&lt;Symbol*&gt;* all_symbols = MetaspaceShared::collected_symbols();</span>
<span class="line-modified">1478       all_symbols-&gt;sort(compare_symbols_by_address);</span>
<span class="line-modified">1479       for (int i = 0; i &lt; all_symbols-&gt;length(); i++) {</span>
<span class="line-added">1480         assert(all_symbols-&gt;at(i)-&gt;is_permanent(), &quot;archived symbols must be permanent&quot;);</span>
<span class="line-added">1481         all_symbols-&gt;at(i)-&gt;update_identity_hash();</span>
1482       }
1483     }
1484 #ifdef ASSERT
1485     {
1486       log_info(cds)(&quot;Verifying external roots ... &quot;);
1487       ResourceMark rm;
1488       IsRefInArchiveChecker checker;
1489       iterate_roots(&amp;checker);
1490     }
1491 #endif




1492   }
1493 
1494   // We must relocate the System::_well_known_klasses only after we have copied the
1495   // java objects in during dump_java_heap_objects(): during the object copy, we operate on
1496   // old objects which assert that their klass is the original klass.
1497   static void relocate_well_known_klasses() {
1498     {
1499       log_info(cds)(&quot;Relocating SystemDictionary::_well_known_klasses[] ... &quot;);
1500       ResourceMark rm;
1501       RefRelocator ext_reloc;
1502       SystemDictionary::well_known_klasses_do(&amp;ext_reloc);
1503     }
1504     // NOTE: after this point, we shouldn&#39;t have any globals that can reach the old
1505     // objects.
1506 
1507     // We cannot use any of the objects in the heap anymore (except for the
1508     // shared strings) because their headers no longer point to valid Klasses.
1509   }
1510 
1511   static void iterate_roots(MetaspaceClosure* it) {
1512     // To ensure deterministic contents in the archive, we just need to ensure that
1513     // we iterate the MetsapceObjs in a deterministic order. It doesn&#39;t matter where
1514     // the MetsapceObjs are located originally, as they are copied sequentially into
1515     // the archive during the iteration.
1516     //
1517     // The only issue here is that the symbol table and the system directories may be
1518     // randomly ordered, so we copy the symbols and klasses into two arrays and sort
1519     // them deterministically.
1520     //
1521     // During -Xshare:dump, the order of Symbol creation is strictly determined by
1522     // the SharedClassListFile (class loading is done in a single thread and the JIT
1523     // is disabled). Also, Symbols are allocated in monotonically increasing addresses
1524     // (see Symbol::operator new(size_t, int)). So if we iterate the Symbols by
1525     // ascending address order, we ensure that all Symbols are copied into deterministic
1526     // locations in the archive.
<span class="line-modified">1527     GrowableArray&lt;Symbol*&gt;* symbols = _global_symbol_objects;</span>
<span class="line-modified">1528     for (int i = 0; i &lt; symbols-&gt;length(); i++) {</span>
1529       it-&gt;push(symbols-&gt;adr_at(i));
1530     }
1531     if (_global_klass_objects != NULL) {
1532       // Need to fix up the pointers
1533       for (int i = 0; i &lt; _global_klass_objects-&gt;length(); i++) {
1534         // NOTE -- this requires that the vtable is NOT yet patched, or else we are hosed.
1535         it-&gt;push(_global_klass_objects-&gt;adr_at(i));
1536       }
1537     }
1538     FileMapInfo::metaspace_pointers_do(it, false);
1539     SystemDictionaryShared::dumptime_classes_do(it);
1540     Universe::metaspace_pointers_do(it);
1541     SymbolTable::metaspace_pointers_do(it);
1542     vmSymbols::metaspace_pointers_do(it);
1543 
1544     it-&gt;finish();
1545   }
1546 
1547   static Klass* get_relocated_klass(Klass* orig_klass) {
1548     assert(DumpSharedSpaces, &quot;dump time only&quot;);
1549     address* pp = _new_loc_table-&gt;lookup((address)orig_klass);
1550     assert(pp != NULL, &quot;must be&quot;);
1551     Klass* klass = (Klass*)(*pp);
1552     assert(klass-&gt;is_klass(), &quot;must be&quot;);
1553     return klass;
1554   }
1555 };
1556 
1557 DumpAllocStats* ArchiveCompactor::_alloc_stats;

1558 ArchiveCompactor::RelocationTable* ArchiveCompactor::_new_loc_table;
1559 
1560 void VM_PopulateDumpSharedSpace::dump_symbols() {
1561   log_info(cds)(&quot;Dumping symbol table ...&quot;);
1562 
1563   NOT_PRODUCT(SymbolTable::verify());
1564   SymbolTable::write_to_archive();
1565 }
1566 
1567 char* VM_PopulateDumpSharedSpace::dump_read_only_tables() {
1568   ArchiveCompactor::OtherROAllocMark mark;
1569 
1570   log_info(cds)(&quot;Removing java_mirror ... &quot;);
1571   if (!HeapShared::is_heap_object_archiving_allowed()) {
1572     clear_basic_type_mirrors();
1573   }
1574   remove_java_mirror_in_classes();
1575   log_info(cds)(&quot;done. &quot;);
1576 
1577   SystemDictionaryShared::write_to_archive();
</pre>
</td>
</tr>
</table>
<center><a href="../jvmci/vmStructs_jvmci.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../oops/method.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>