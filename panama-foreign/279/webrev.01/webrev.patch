diff a/src/hotspot/cpu/x86/frame_x86.cpp b/src/hotspot/cpu/x86/frame_x86.cpp
--- a/src/hotspot/cpu/x86/frame_x86.cpp
+++ b/src/hotspot/cpu/x86/frame_x86.cpp
@@ -341,10 +341,15 @@
   }
   map->clear();
   assert(map->include_argument_oops(), "should be set by clear");
   vmassert(jfa->last_Java_pc() != NULL, "not walkable");
   frame fr(jfa->last_Java_sp(), jfa->last_Java_fp(), jfa->last_Java_pc());
+
+  if (jfa->saved_rbp_address()) {
+    update_map_with_saved_link(map, jfa->saved_rbp_address());
+  }
+
   return fr;
 }
 
 //------------------------------------------------------------------------------
 // frame::verify_deopt_original_pc
diff a/src/hotspot/cpu/x86/javaFrameAnchor_x86.hpp b/src/hotspot/cpu/x86/javaFrameAnchor_x86.hpp
--- a/src/hotspot/cpu/x86/javaFrameAnchor_x86.hpp
+++ b/src/hotspot/cpu/x86/javaFrameAnchor_x86.hpp
@@ -28,10 +28,13 @@
 private:
 
   // FP value associated with _last_Java_sp:
   intptr_t* volatile        _last_Java_fp;           // pointer is volatile not what it points to
 
+  // (Optional) location of saved RBP register, which GCs want to inspect
+  intptr_t** volatile _saved_rbp_address;
+
 public:
   // Each arch must define reset, save, restore
   // These are used by objects that only care about:
   //  1 - initializing a new state (thread creation, javaCalls)
   //  2 - saving a current state (javaCalls)
@@ -41,10 +44,11 @@
     // clearing _last_Java_sp must be first
     _last_Java_sp = NULL;
     // fence?
     _last_Java_fp = NULL;
     _last_Java_pc = NULL;
+    _saved_rbp_address = NULL;
   }
 
   void copy(JavaFrameAnchor* src) {
     // In order to make sure the transition state is valid for "this"
     // We must clear _last_Java_sp before copying the rest of the new data
@@ -58,23 +62,28 @@
 
     _last_Java_fp = src->_last_Java_fp;
     _last_Java_pc = src->_last_Java_pc;
     // Must be last so profiler will always see valid frame if has_last_frame() is true
     _last_Java_sp = src->_last_Java_sp;
+
+    _saved_rbp_address = src->_saved_rbp_address;
   }
 
   bool walkable(void)                            { return _last_Java_sp != NULL && _last_Java_pc != NULL; }
   void make_walkable(JavaThread* thread);
   void capture_last_Java_pc(void);
 
   intptr_t* last_Java_sp(void) const             { return _last_Java_sp; }
 
   address last_Java_pc(void)                     { return _last_Java_pc; }
 
+  intptr_t** saved_rbp_address(void) const       { return _saved_rbp_address; }
+
 private:
 
   static ByteSize last_Java_fp_offset()          { return byte_offset_of(JavaFrameAnchor, _last_Java_fp); }
+  static ByteSize saved_rbp_address_offset()     { return byte_offset_of(JavaFrameAnchor, _saved_rbp_address); }
 
 public:
 
   void set_last_Java_sp(intptr_t* sp)            { _last_Java_sp = sp; }
 
diff a/src/hotspot/cpu/x86/macroAssembler_x86.cpp b/src/hotspot/cpu/x86/macroAssembler_x86.cpp
--- a/src/hotspot/cpu/x86/macroAssembler_x86.cpp
+++ b/src/hotspot/cpu/x86/macroAssembler_x86.cpp
@@ -2676,10 +2676,11 @@
   if (clear_fp) {
     movslq(Address(java_thread, JavaThread::last_Java_fp_offset()), NULL_WORD);
   }
   // Always clear the pc because it could have been set by make_walkable()
   movslq(Address(java_thread, JavaThread::last_Java_pc_offset()), NULL_WORD);
+  movslq(Address(java_thread, JavaThread::saved_rbp_address_offset()), NULL_WORD);
   vzeroupper();
 }
 
 void MacroAssembler::restore_rax(Register tmp) {
   if (tmp == noreg) pop(rax);
diff a/src/hotspot/cpu/x86/sharedRuntime_x86_64.cpp b/src/hotspot/cpu/x86/sharedRuntime_x86_64.cpp
--- a/src/hotspot/cpu/x86/sharedRuntime_x86_64.cpp
+++ b/src/hotspot/cpu/x86/sharedRuntime_x86_64.cpp
@@ -3764,19 +3764,20 @@
   assert(!(target_uses_register(r15_thread->as_VMReg()) || target_uses_register(rscratch1->as_VMReg())), "Register conflict");
 
   MacroAssembler* masm = _masm;
   __ enter();
 
-  Address java_pc(r15_thread,
-                  JavaThread::frame_anchor_offset() + JavaFrameAnchor::last_Java_pc_offset());
+  Address java_pc(r15_thread, JavaThread::last_Java_pc_offset());
   __ movptr(rscratch1, Address(rsp, 8)); // read return address from stack
   __ movptr(java_pc, rscratch1);
 
   __ movptr(rscratch1, rsp);
-  __ addptr(rscratch1, 16);
+  __ addptr(rscratch1, 16); // skip return and frame
   __ movptr(Address(r15_thread, JavaThread::last_Java_sp_offset()), rscratch1);
 
+  __ movptr(Address(r15_thread, JavaThread::saved_rbp_address_offset()), rsp); // rsp points at saved RBP
+
     // State transition
   __ movl(Address(r15_thread, JavaThread::thread_state_offset()), _thread_in_native);
 
   if (_shadow_space_bytes != 0) {
     // needed here for correct stack args offset on Windows
diff a/src/hotspot/share/c1/c1_IR.hpp b/src/hotspot/share/c1/c1_IR.hpp
--- a/src/hotspot/share/c1/c1_IR.hpp
+++ b/src/hotspot/share/c1/c1_IR.hpp
@@ -242,11 +242,11 @@
     DebugToken* monvals = recorder->create_monitor_values(monitors());
     // reexecute allowed only for the topmost frame
     bool reexecute = topmost ? should_reexecute() : false;
     bool return_oop = false; // This flag will be ignored since it used only for C2 with escape analysis.
     bool rethrow_exception = false;
-    recorder->describe_scope(pc_offset, methodHandle(), scope()->method(), bci(), reexecute, rethrow_exception, is_method_handle_invoke, return_oop, locvals, expvals, monvals);
+    recorder->describe_scope(pc_offset, methodHandle(), scope()->method(), bci(), reexecute, rethrow_exception, is_method_handle_invoke, false /* is opt native */, return_oop, locvals, expvals, monvals);
   }
 };
 
 
 class CodeEmitInfo: public CompilationResourceObj {
diff a/src/hotspot/share/code/compiledMethod.cpp b/src/hotspot/share/code/compiledMethod.cpp
--- a/src/hotspot/share/code/compiledMethod.cpp
+++ b/src/hotspot/share/code/compiledMethod.cpp
@@ -355,10 +355,11 @@
 // called with a frame corresponding to a Java invoke
 void CompiledMethod::preserve_callee_argument_oops(frame fr, const RegisterMap *reg_map, OopClosure* f) {
   if (method() != NULL && !method()->is_native()) {
     address pc = fr.pc();
     SimpleScopeDesc ssd(this, pc);
+    if (ssd.is_optimized_linkToNative()) return; // call was replaced
     Bytecode_invoke call(methodHandle(Thread::current(), ssd.method()), ssd.bci());
     bool has_receiver = call.has_receiver();
     bool has_appendix = call.has_appendix();
     Symbol* signature = call.signature();
 
diff a/src/hotspot/share/code/debugInfoRec.cpp b/src/hotspot/share/code/debugInfoRec.cpp
--- a/src/hotspot/share/code/debugInfoRec.cpp
+++ b/src/hotspot/share/code/debugInfoRec.cpp
@@ -284,10 +284,11 @@
                                               ciMethod*   method,
                                               int         bci,
                                               bool        reexecute,
                                               bool        rethrow_exception,
                                               bool        is_method_handle_invoke,
+                                              bool        is_optimized_linkToNative,
                                               bool        return_oop,
                                               DebugToken* locals,
                                               DebugToken* expressions,
                                               DebugToken* monitors) {
   assert(_recording_state != rs_null, "nesting of recording calls");
@@ -300,10 +301,11 @@
 
   // Record flags into pcDesc.
   last_pd->set_should_reexecute(reexecute);
   last_pd->set_rethrow_exception(rethrow_exception);
   last_pd->set_is_method_handle_invoke(is_method_handle_invoke);
+  last_pd->set_is_optimized_linkToNative(is_optimized_linkToNative);
   last_pd->set_return_oop(return_oop);
 
   // serialize sender stream offest
   stream()->write_int(sender_stream_offset);
 
diff a/src/hotspot/share/code/debugInfoRec.hpp b/src/hotspot/share/code/debugInfoRec.hpp
--- a/src/hotspot/share/code/debugInfoRec.hpp
+++ b/src/hotspot/share/code/debugInfoRec.hpp
@@ -102,10 +102,11 @@
                       ciMethod*   method,
                       int         bci,
                       bool        reexecute,
                       bool        rethrow_exception = false,
                       bool        is_method_handle_invoke = false,
+                      bool        is_optimized_linkToNative = false,
                       bool        return_oop = false,
                       DebugToken* locals      = NULL,
                       DebugToken* expressions = NULL,
                       DebugToken* monitors    = NULL);
 
diff a/src/hotspot/share/code/pcDesc.hpp b/src/hotspot/share/code/pcDesc.hpp
--- a/src/hotspot/share/code/pcDesc.hpp
+++ b/src/hotspot/share/code/pcDesc.hpp
@@ -37,14 +37,15 @@
   int _pc_offset;           // offset from start of nmethod
   int _scope_decode_offset; // offset for scope in nmethod
   int _obj_decode_offset;
 
   enum {
-    PCDESC_reexecute               = 1 << 0,
-    PCDESC_is_method_handle_invoke = 1 << 1,
-    PCDESC_return_oop              = 1 << 2,
-    PCDESC_rethrow_exception       = 1 << 3
+    PCDESC_reexecute                 = 1 << 0,
+    PCDESC_is_method_handle_invoke   = 1 << 1,
+    PCDESC_return_oop                = 1 << 2,
+    PCDESC_rethrow_exception         = 1 << 3,
+    PCDESC_is_optimized_linkToNative = 1 << 4
   };
 
   int _flags;
 
   void set_flag(int mask, bool z) {
@@ -84,10 +85,13 @@
   }
 
   bool     is_method_handle_invoke()       const { return (_flags & PCDESC_is_method_handle_invoke) != 0;     }
   void set_is_method_handle_invoke(bool z)       { set_flag(PCDESC_is_method_handle_invoke, z); }
 
+  bool     is_optimized_linkToNative()     const { return (_flags & PCDESC_is_optimized_linkToNative) != 0;     }
+  void set_is_optimized_linkToNative(bool z)     { set_flag(PCDESC_is_optimized_linkToNative, z); }
+
   bool     return_oop()                    const { return (_flags & PCDESC_return_oop) != 0;     }
   void set_return_oop(bool z)                    { set_flag(PCDESC_return_oop, z); }
 
   // Returns the real pc
   address real_pc(const CompiledMethod* code) const;
diff a/src/hotspot/share/code/scopeDesc.hpp b/src/hotspot/share/code/scopeDesc.hpp
--- a/src/hotspot/share/code/scopeDesc.hpp
+++ b/src/hotspot/share/code/scopeDesc.hpp
@@ -37,23 +37,27 @@
 
 class SimpleScopeDesc : public StackObj {
  private:
   Method* _method;
   int _bci;
+  bool _is_optimized_linkToNative;
 
  public:
   SimpleScopeDesc(CompiledMethod* code, address pc) {
     PcDesc* pc_desc = code->pc_desc_at(pc);
     assert(pc_desc != NULL, "Must be able to find matching PcDesc");
+    // save this here so we only have to look up the PcDesc once
+    _is_optimized_linkToNative = pc_desc->is_optimized_linkToNative();
     DebugInfoReadStream buffer(code, pc_desc->scope_decode_offset());
     int ignore_sender = buffer.read_int();
     _method           = buffer.read_method();
     _bci              = buffer.read_bci();
   }
 
   Method* method() { return _method; }
   int bci() { return _bci; }
+  bool is_optimized_linkToNative() { return _is_optimized_linkToNative; }
 };
 
 // ScopeDescs contain the information that makes source-level debugging of
 // nmethods possible; each scopeDesc describes a method activation
 
diff a/src/hotspot/share/jvmci/jvmciCodeInstaller.cpp b/src/hotspot/share/jvmci/jvmciCodeInstaller.cpp
--- a/src/hotspot/share/jvmci/jvmciCodeInstaller.cpp
+++ b/src/hotspot/share/jvmci/jvmciCodeInstaller.cpp
@@ -1179,11 +1179,11 @@
     monitors_token = _debug_recorder->create_monitor_values(monitors);
 
     throw_exception = jvmci_env()->get_BytecodeFrame_rethrowException(frame) == JNI_TRUE;
   }
 
-  _debug_recorder->describe_scope(pc_offset, method, NULL, bci, reexecute, throw_exception, false, return_oop,
+  _debug_recorder->describe_scope(pc_offset, method, NULL, bci, reexecute, throw_exception, false, false, return_oop,
                                   locals_token, expressions_token, monitors_token);
 }
 
 void CodeInstaller::site_Safepoint(CodeBuffer& buffer, jint pc_offset, JVMCIObject site, JVMCI_TRAPS) {
   JVMCIObject debug_info = jvmci_env()->get_site_Infopoint_debugInfo(site);
diff a/src/hotspot/share/opto/lcm.cpp b/src/hotspot/share/opto/lcm.cpp
--- a/src/hotspot/share/opto/lcm.cpp
+++ b/src/hotspot/share/opto/lcm.cpp
@@ -876,11 +876,11 @@
   // find them.  CallLeaf and CallLeafNoFP are ok because they can't
   // have debug info on them.  Strictly speaking this only needs to be
   // done for oops since idealreg2debugmask takes care of debug info
   // references but there no way to handle oops differently than other
   // pointers as far as the kill mask goes.
-  bool exclude_soe = op == Op_CallRuntime;
+  bool exclude_soe = op == Op_CallRuntime || op == Op_CallNative;
 
   // If the call is a MethodHandle invoke, we need to exclude the
   // register which is used to save the SP value over MH invokes from
   // the mask.  Otherwise this register could be used for
   // deoptimization information.
diff a/src/hotspot/share/opto/output.cpp b/src/hotspot/share/opto/output.cpp
--- a/src/hotspot/share/opto/output.cpp
+++ b/src/hotspot/share/opto/output.cpp
@@ -1066,11 +1066,24 @@
     assert(jvms->bci() >= InvocationEntryBci && jvms->bci() <= 0x10000, "must be a valid or entry BCI");
     assert(!jvms->should_reexecute() || depth == max_depth, "reexecute allowed only for the youngest");
     // Now we can describe the scope.
     methodHandle null_mh;
     bool rethrow_exception = false;
-    C->debug_info()->describe_scope(safepoint_pc_offset, null_mh, scope_method, jvms->bci(), jvms->should_reexecute(), rethrow_exception, is_method_handle_invoke, return_oop, locvals, expvals, monvals);
+    C->debug_info()->describe_scope(
+      safepoint_pc_offset,
+      null_mh,
+      scope_method,
+      jvms->bci(),
+      jvms->should_reexecute(),
+      rethrow_exception,
+      is_method_handle_invoke,
+      mach->is_MachCallNative(),
+      return_oop,
+      locvals,
+      expvals,
+      monvals
+    );
   } // End jvms loop
 
   // Mark the end of the scope set.
   C->debug_info()->end_safepoint(safepoint_pc_offset);
 }
diff a/src/hotspot/share/runtime/frame.cpp b/src/hotspot/share/runtime/frame.cpp
--- a/src/hotspot/share/runtime/frame.cpp
+++ b/src/hotspot/share/runtime/frame.cpp
@@ -937,10 +937,11 @@
   virtual void handle_oop_offset() {
     // Extract low order register number from register array.
     // In LP64-land, the high-order bits are valid but unhelpful.
     VMReg reg = _regs[_offset].first();
     oop *loc = _fr.oopmapreg_to_location(reg, _reg_map);
+    assert(loc != NULL, "missing register map entry");
     _f->do_oop(loc);
   }
 
  public:
   CompiledArgumentOopFinder(Symbol* signature, bool has_receiver, bool has_appendix, OopClosure* f, frame fr, const RegisterMap* reg_map)
diff a/src/hotspot/share/runtime/thread.hpp b/src/hotspot/share/runtime/thread.hpp
--- a/src/hotspot/share/runtime/thread.hpp
+++ b/src/hotspot/share/runtime/thread.hpp
@@ -1790,10 +1790,14 @@
     return byte_offset_of(JavaThread, _anchor) + JavaFrameAnchor::last_Java_pc_offset();
   }
   static ByteSize frame_anchor_offset() {
     return byte_offset_of(JavaThread, _anchor);
   }
+  static ByteSize saved_rbp_address_offset() {
+    return byte_offset_of(JavaThread, _anchor) + JavaFrameAnchor::saved_rbp_address_offset();
+  }
+
   static ByteSize callee_target_offset()         { return byte_offset_of(JavaThread, _callee_target); }
   static ByteSize vm_result_offset()             { return byte_offset_of(JavaThread, _vm_result); }
   static ByteSize vm_result_2_offset()           { return byte_offset_of(JavaThread, _vm_result_2); }
   static ByteSize thread_state_offset()          { return byte_offset_of(JavaThread, _thread_state); }
   static ByteSize saved_exception_pc_offset()    { return byte_offset_of(JavaThread, _saved_exception_pc); }
