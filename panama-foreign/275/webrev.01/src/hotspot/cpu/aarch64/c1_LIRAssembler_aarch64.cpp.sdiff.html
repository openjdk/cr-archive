<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/aarch64/c1_LIRAssembler_aarch64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="assembler_aarch64.inline.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_LIRAssembler_aarch64.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/aarch64/c1_LIRAssembler_aarch64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 194       return Address(base, tmp, Address::lsl(addr-&gt;scale()));
 195     }
 196   }
 197   return Address();
 198 }
 199 
 200 Address LIR_Assembler::as_Address_hi(LIR_Address* addr) {
 201   ShouldNotReachHere();
 202   return Address();
 203 }
 204 
 205 Address LIR_Assembler::as_Address(LIR_Address* addr) {
 206   return as_Address(addr, rscratch1);
 207 }
 208 
 209 Address LIR_Assembler::as_Address_lo(LIR_Address* addr) {
 210   return as_Address(addr, rscratch1);  // Ouch
 211   // FIXME: This needs to be much more clever.  See x86.
 212 }
 213 













 214 
 215 void LIR_Assembler::osr_entry() {
 216   offsets()-&gt;set_value(CodeOffsets::OSR_Entry, code_offset());
 217   BlockBegin* osr_entry = compilation()-&gt;hir()-&gt;osr_entry();
 218   ValueStack* entry_state = osr_entry-&gt;state();
 219   int number_of_locks = entry_state-&gt;locks_size();
 220 
 221   // we jump here if osr happens with the interpreter
 222   // state set up to continue at the beginning of the
 223   // loop that triggered osr - in particular, we have
 224   // the following registers setup:
 225   //
 226   // r2: osr buffer
 227   //
 228 
 229   // build frame
 230   ciMethod* m = compilation()-&gt;method();
 231   __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes());
 232 
 233   // OSR buffer is
</pre>
<hr />
<pre>
 718     Register f_lo = src-&gt;as_register_lo();
 719     Register f_hi = src-&gt;as_register_hi();
 720     Register t_lo = dest-&gt;as_register_lo();
 721     Register t_hi = dest-&gt;as_register_hi();
 722     assert(f_hi == f_lo, &quot;must be same&quot;);
 723     assert(t_hi == t_lo, &quot;must be same&quot;);
 724     move_regs(f_lo, t_lo);
 725 
 726   } else if (dest-&gt;is_single_fpu()) {
 727     __ fmovs(dest-&gt;as_float_reg(), src-&gt;as_float_reg());
 728 
 729   } else if (dest-&gt;is_double_fpu()) {
 730     __ fmovd(dest-&gt;as_double_reg(), src-&gt;as_double_reg());
 731 
 732   } else {
 733     ShouldNotReachHere();
 734   }
 735 }
 736 
 737 void LIR_Assembler::reg2stack(LIR_Opr src, LIR_Opr dest, BasicType type, bool pop_fpu_stack) {





 738   if (src-&gt;is_single_cpu()) {

 739     if (is_reference_type(type)) {
<span class="line-modified"> 740       __ str(src-&gt;as_register(), frame_map()-&gt;address_for_slot(dest-&gt;single_stack_ix()));</span>
 741       __ verify_oop(src-&gt;as_register());
 742     } else if (type == T_METADATA || type == T_DOUBLE || type == T_ADDRESS) {
<span class="line-modified"> 743       __ str(src-&gt;as_register(), frame_map()-&gt;address_for_slot(dest-&gt;single_stack_ix()));</span>
 744     } else {
<span class="line-modified"> 745       __ strw(src-&gt;as_register(), frame_map()-&gt;address_for_slot(dest-&gt;single_stack_ix()));</span>
 746     }
 747 
 748   } else if (src-&gt;is_double_cpu()) {
<span class="line-modified"> 749     Address dest_addr_LO = frame_map()-&gt;address_for_slot(dest-&gt;double_stack_ix(), lo_word_offset_in_bytes);</span>

 750     __ str(src-&gt;as_register_lo(), dest_addr_LO);
 751 
 752   } else if (src-&gt;is_single_fpu()) {
<span class="line-modified"> 753     Address dest_addr = frame_map()-&gt;address_for_slot(dest-&gt;single_stack_ix());</span>
<span class="line-modified"> 754     __ strs(src-&gt;as_float_reg(), dest_addr);</span>
 755 
 756   } else if (src-&gt;is_double_fpu()) {
<span class="line-modified"> 757     Address dest_addr = frame_map()-&gt;address_for_slot(dest-&gt;double_stack_ix());</span>
<span class="line-modified"> 758     __ strd(src-&gt;as_double_reg(), dest_addr);</span>
 759 
 760   } else {
 761     ShouldNotReachHere();
 762   }
<span class="line-removed"> 763 </span>
 764 }
 765 
 766 
 767 void LIR_Assembler::reg2mem(LIR_Opr src, LIR_Opr dest, BasicType type, LIR_PatchCode patch_code, CodeEmitInfo* info, bool pop_fpu_stack, bool wide, bool /* unaligned */) {
 768   LIR_Address* to_addr = dest-&gt;as_address_ptr();
 769   PatchingStub* patch = NULL;
 770   Register compressed_src = rscratch1;
 771 
 772   if (patch_code != lir_patch_none) {
 773     deoptimize_trap(info);
 774     return;
 775   }
 776 
 777   if (is_reference_type(type)) {
 778     __ verify_oop(src-&gt;as_register());
 779 
 780     if (UseCompressedOops &amp;&amp; !wide) {
 781       __ encode_heap_oop(compressed_src, src-&gt;as_register());
 782     } else {
 783       compressed_src = src-&gt;as_register();
</pre>
<hr />
<pre>
 828     case T_BOOLEAN: {
 829       __ strb(src-&gt;as_register(), as_Address(to_addr));
 830       break;
 831     }
 832 
 833     case T_CHAR:    // fall through
 834     case T_SHORT:
 835       __ strh(src-&gt;as_register(), as_Address(to_addr));
 836       break;
 837 
 838     default:
 839       ShouldNotReachHere();
 840   }
 841   if (info != NULL) {
 842     add_debug_info_for_null_check(null_check_here, info);
 843   }
 844 }
 845 
 846 
 847 void LIR_Assembler::stack2reg(LIR_Opr src, LIR_Opr dest, BasicType type) {
<span class="line-modified"> 848   assert(src-&gt;is_stack(), &quot;should not call otherwise&quot;);</span>
<span class="line-modified"> 849   assert(dest-&gt;is_register(), &quot;should not call otherwise&quot;);</span>


 850 
 851   if (dest-&gt;is_single_cpu()) {

 852     if (is_reference_type(type)) {
<span class="line-modified"> 853       __ ldr(dest-&gt;as_register(), frame_map()-&gt;address_for_slot(src-&gt;single_stack_ix()));</span>
 854       __ verify_oop(dest-&gt;as_register());
 855     } else if (type == T_METADATA || type == T_ADDRESS) {
<span class="line-modified"> 856       __ ldr(dest-&gt;as_register(), frame_map()-&gt;address_for_slot(src-&gt;single_stack_ix()));</span>
 857     } else {
<span class="line-modified"> 858       __ ldrw(dest-&gt;as_register(), frame_map()-&gt;address_for_slot(src-&gt;single_stack_ix()));</span>
 859     }
 860 
 861   } else if (dest-&gt;is_double_cpu()) {
<span class="line-modified"> 862     Address src_addr_LO = frame_map()-&gt;address_for_slot(src-&gt;double_stack_ix(), lo_word_offset_in_bytes);</span>

 863     __ ldr(dest-&gt;as_register_lo(), src_addr_LO);
 864 
 865   } else if (dest-&gt;is_single_fpu()) {
<span class="line-modified"> 866     Address src_addr = frame_map()-&gt;address_for_slot(src-&gt;single_stack_ix());</span>
<span class="line-modified"> 867     __ ldrs(dest-&gt;as_float_reg(), src_addr);</span>
 868 
 869   } else if (dest-&gt;is_double_fpu()) {
<span class="line-modified"> 870     Address src_addr = frame_map()-&gt;address_for_slot(src-&gt;double_stack_ix());</span>
<span class="line-modified"> 871     __ ldrd(dest-&gt;as_double_reg(), src_addr);</span>
 872 
 873   } else {
 874     ShouldNotReachHere();
 875   }
 876 }
 877 
 878 
 879 void LIR_Assembler::klass2reg_with_patching(Register reg, CodeEmitInfo* info) {
 880   address target = NULL;
 881   relocInfo::relocType reloc_type = relocInfo::none;
 882 
 883   switch (patching_id(info)) {
 884   case PatchingStub::access_field_id:
 885     target = Runtime1::entry_for(Runtime1::access_field_patching_id);
 886     reloc_type = relocInfo::section_word_type;
 887     break;
 888   case PatchingStub::load_klass_id:
 889     target = Runtime1::entry_for(Runtime1::load_klass_patching_id);
 890     reloc_type = relocInfo::metadata_type;
 891     break;
</pre>
<hr />
<pre>
2068   __ relocate(static_stub_Relocation::spec(call_pc));
2069   __ emit_static_call_stub();
2070 
2071   assert(__ offset() - start + CompiledStaticCall::to_trampoline_stub_size()
2072         &lt;= call_stub_size(), &quot;stub too big&quot;);
2073   __ end_a_stub();
2074 }
2075 
2076 
2077 void LIR_Assembler::throw_op(LIR_Opr exceptionPC, LIR_Opr exceptionOop, CodeEmitInfo* info) {
2078   assert(exceptionOop-&gt;as_register() == r0, &quot;must match&quot;);
2079   assert(exceptionPC-&gt;as_register() == r3, &quot;must match&quot;);
2080 
2081   // exception object is not added to oop map by LinearScan
2082   // (LinearScan assumes that no oops are in fixed registers)
2083   info-&gt;add_register_oop(exceptionOop);
2084   Runtime1::StubID unwind_id;
2085 
2086   // get current pc information
2087   // pc is only needed if the method has an exception handler, the unwind code does not need it.







2088   int pc_for_athrow_offset = __ offset();
2089   InternalAddress pc_for_athrow(__ pc());
2090   __ adr(exceptionPC-&gt;as_register(), pc_for_athrow);
2091   add_call_info(pc_for_athrow_offset, info); // for exception handler
2092 
2093   __ verify_not_null_oop(r0);
2094   // search an exception handler (r0: exception oop, r3: throwing pc)
2095   if (compilation()-&gt;has_fpu_code()) {
2096     unwind_id = Runtime1::handle_exception_id;
2097   } else {
2098     unwind_id = Runtime1::handle_exception_nofpu_id;
2099   }
2100   __ far_call(RuntimeAddress(Runtime1::entry_for(unwind_id)));
2101 
2102   // FIXME: enough room for two byte trap   ????
2103   __ nop();
2104 }
2105 
2106 
2107 void LIR_Assembler::unwind_op(LIR_Opr exceptionOop) {
</pre>
</td>
<td>
<hr />
<pre>
 194       return Address(base, tmp, Address::lsl(addr-&gt;scale()));
 195     }
 196   }
 197   return Address();
 198 }
 199 
 200 Address LIR_Assembler::as_Address_hi(LIR_Address* addr) {
 201   ShouldNotReachHere();
 202   return Address();
 203 }
 204 
 205 Address LIR_Assembler::as_Address(LIR_Address* addr) {
 206   return as_Address(addr, rscratch1);
 207 }
 208 
 209 Address LIR_Assembler::as_Address_lo(LIR_Address* addr) {
 210   return as_Address(addr, rscratch1);  // Ouch
 211   // FIXME: This needs to be much more clever.  See x86.
 212 }
 213 
<span class="line-added"> 214 // Ensure a valid Address (base + offset) to a stack-slot. If stack access is</span>
<span class="line-added"> 215 // not encodable as a base + (immediate) offset, generate an explicit address</span>
<span class="line-added"> 216 // calculation to hold the address in a temporary register.</span>
<span class="line-added"> 217 Address LIR_Assembler::stack_slot_address(int index, uint size, Register tmp, int adjust) {</span>
<span class="line-added"> 218   precond(size == 4 || size == 8);</span>
<span class="line-added"> 219   Address addr = frame_map()-&gt;address_for_slot(index, adjust);</span>
<span class="line-added"> 220   precond(addr.getMode() == Address::base_plus_offset);</span>
<span class="line-added"> 221   precond(addr.base() == sp);</span>
<span class="line-added"> 222   precond(addr.offset() &gt; 0);</span>
<span class="line-added"> 223   uint mask = size - 1;</span>
<span class="line-added"> 224   assert((addr.offset() &amp; mask) == 0, &quot;scaled offsets only&quot;);</span>
<span class="line-added"> 225   return __ legitimize_address(addr, size, tmp);</span>
<span class="line-added"> 226 }</span>
 227 
 228 void LIR_Assembler::osr_entry() {
 229   offsets()-&gt;set_value(CodeOffsets::OSR_Entry, code_offset());
 230   BlockBegin* osr_entry = compilation()-&gt;hir()-&gt;osr_entry();
 231   ValueStack* entry_state = osr_entry-&gt;state();
 232   int number_of_locks = entry_state-&gt;locks_size();
 233 
 234   // we jump here if osr happens with the interpreter
 235   // state set up to continue at the beginning of the
 236   // loop that triggered osr - in particular, we have
 237   // the following registers setup:
 238   //
 239   // r2: osr buffer
 240   //
 241 
 242   // build frame
 243   ciMethod* m = compilation()-&gt;method();
 244   __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes());
 245 
 246   // OSR buffer is
</pre>
<hr />
<pre>
 731     Register f_lo = src-&gt;as_register_lo();
 732     Register f_hi = src-&gt;as_register_hi();
 733     Register t_lo = dest-&gt;as_register_lo();
 734     Register t_hi = dest-&gt;as_register_hi();
 735     assert(f_hi == f_lo, &quot;must be same&quot;);
 736     assert(t_hi == t_lo, &quot;must be same&quot;);
 737     move_regs(f_lo, t_lo);
 738 
 739   } else if (dest-&gt;is_single_fpu()) {
 740     __ fmovs(dest-&gt;as_float_reg(), src-&gt;as_float_reg());
 741 
 742   } else if (dest-&gt;is_double_fpu()) {
 743     __ fmovd(dest-&gt;as_double_reg(), src-&gt;as_double_reg());
 744 
 745   } else {
 746     ShouldNotReachHere();
 747   }
 748 }
 749 
 750 void LIR_Assembler::reg2stack(LIR_Opr src, LIR_Opr dest, BasicType type, bool pop_fpu_stack) {
<span class="line-added"> 751   precond(src-&gt;is_register() &amp;&amp; dest-&gt;is_stack());</span>
<span class="line-added"> 752 </span>
<span class="line-added"> 753   uint const c_sz32 = sizeof(uint32_t);</span>
<span class="line-added"> 754   uint const c_sz64 = sizeof(uint64_t);</span>
<span class="line-added"> 755 </span>
 756   if (src-&gt;is_single_cpu()) {
<span class="line-added"> 757     int index = dest-&gt;single_stack_ix();</span>
 758     if (is_reference_type(type)) {
<span class="line-modified"> 759       __ str(src-&gt;as_register(), stack_slot_address(index, c_sz64, rscratch1));</span>
 760       __ verify_oop(src-&gt;as_register());
 761     } else if (type == T_METADATA || type == T_DOUBLE || type == T_ADDRESS) {
<span class="line-modified"> 762       __ str(src-&gt;as_register(), stack_slot_address(index, c_sz64, rscratch1));</span>
 763     } else {
<span class="line-modified"> 764       __ strw(src-&gt;as_register(), stack_slot_address(index, c_sz32, rscratch1));</span>
 765     }
 766 
 767   } else if (src-&gt;is_double_cpu()) {
<span class="line-modified"> 768     int index = dest-&gt;double_stack_ix();</span>
<span class="line-added"> 769     Address dest_addr_LO = stack_slot_address(index, c_sz64, rscratch1, lo_word_offset_in_bytes);</span>
 770     __ str(src-&gt;as_register_lo(), dest_addr_LO);
 771 
 772   } else if (src-&gt;is_single_fpu()) {
<span class="line-modified"> 773     int index = dest-&gt;single_stack_ix();</span>
<span class="line-modified"> 774     __ strs(src-&gt;as_float_reg(), stack_slot_address(index, c_sz32, rscratch1));</span>
 775 
 776   } else if (src-&gt;is_double_fpu()) {
<span class="line-modified"> 777     int index = dest-&gt;double_stack_ix();</span>
<span class="line-modified"> 778     __ strd(src-&gt;as_double_reg(), stack_slot_address(index, c_sz64, rscratch1));</span>
 779 
 780   } else {
 781     ShouldNotReachHere();
 782   }

 783 }
 784 
 785 
 786 void LIR_Assembler::reg2mem(LIR_Opr src, LIR_Opr dest, BasicType type, LIR_PatchCode patch_code, CodeEmitInfo* info, bool pop_fpu_stack, bool wide, bool /* unaligned */) {
 787   LIR_Address* to_addr = dest-&gt;as_address_ptr();
 788   PatchingStub* patch = NULL;
 789   Register compressed_src = rscratch1;
 790 
 791   if (patch_code != lir_patch_none) {
 792     deoptimize_trap(info);
 793     return;
 794   }
 795 
 796   if (is_reference_type(type)) {
 797     __ verify_oop(src-&gt;as_register());
 798 
 799     if (UseCompressedOops &amp;&amp; !wide) {
 800       __ encode_heap_oop(compressed_src, src-&gt;as_register());
 801     } else {
 802       compressed_src = src-&gt;as_register();
</pre>
<hr />
<pre>
 847     case T_BOOLEAN: {
 848       __ strb(src-&gt;as_register(), as_Address(to_addr));
 849       break;
 850     }
 851 
 852     case T_CHAR:    // fall through
 853     case T_SHORT:
 854       __ strh(src-&gt;as_register(), as_Address(to_addr));
 855       break;
 856 
 857     default:
 858       ShouldNotReachHere();
 859   }
 860   if (info != NULL) {
 861     add_debug_info_for_null_check(null_check_here, info);
 862   }
 863 }
 864 
 865 
 866 void LIR_Assembler::stack2reg(LIR_Opr src, LIR_Opr dest, BasicType type) {
<span class="line-modified"> 867   precond(src-&gt;is_stack() &amp;&amp; dest-&gt;is_register());</span>
<span class="line-modified"> 868 </span>
<span class="line-added"> 869   uint const c_sz32 = sizeof(uint32_t);</span>
<span class="line-added"> 870   uint const c_sz64 = sizeof(uint64_t);</span>
 871 
 872   if (dest-&gt;is_single_cpu()) {
<span class="line-added"> 873     int index = src-&gt;single_stack_ix();</span>
 874     if (is_reference_type(type)) {
<span class="line-modified"> 875       __ ldr(dest-&gt;as_register(), stack_slot_address(index, c_sz64, rscratch1));</span>
 876       __ verify_oop(dest-&gt;as_register());
 877     } else if (type == T_METADATA || type == T_ADDRESS) {
<span class="line-modified"> 878       __ ldr(dest-&gt;as_register(), stack_slot_address(index, c_sz64, rscratch1));</span>
 879     } else {
<span class="line-modified"> 880       __ ldrw(dest-&gt;as_register(), stack_slot_address(index, c_sz32, rscratch1));</span>
 881     }
 882 
 883   } else if (dest-&gt;is_double_cpu()) {
<span class="line-modified"> 884     int index = src-&gt;double_stack_ix();</span>
<span class="line-added"> 885     Address src_addr_LO = stack_slot_address(index, c_sz64, rscratch1, lo_word_offset_in_bytes);</span>
 886     __ ldr(dest-&gt;as_register_lo(), src_addr_LO);
 887 
 888   } else if (dest-&gt;is_single_fpu()) {
<span class="line-modified"> 889     int index = src-&gt;single_stack_ix();</span>
<span class="line-modified"> 890     __ ldrs(dest-&gt;as_float_reg(), stack_slot_address(index, c_sz32, rscratch1));</span>
 891 
 892   } else if (dest-&gt;is_double_fpu()) {
<span class="line-modified"> 893     int index = src-&gt;double_stack_ix();</span>
<span class="line-modified"> 894     __ ldrd(dest-&gt;as_double_reg(), stack_slot_address(index, c_sz64, rscratch1));</span>
 895 
 896   } else {
 897     ShouldNotReachHere();
 898   }
 899 }
 900 
 901 
 902 void LIR_Assembler::klass2reg_with_patching(Register reg, CodeEmitInfo* info) {
 903   address target = NULL;
 904   relocInfo::relocType reloc_type = relocInfo::none;
 905 
 906   switch (patching_id(info)) {
 907   case PatchingStub::access_field_id:
 908     target = Runtime1::entry_for(Runtime1::access_field_patching_id);
 909     reloc_type = relocInfo::section_word_type;
 910     break;
 911   case PatchingStub::load_klass_id:
 912     target = Runtime1::entry_for(Runtime1::load_klass_patching_id);
 913     reloc_type = relocInfo::metadata_type;
 914     break;
</pre>
<hr />
<pre>
2091   __ relocate(static_stub_Relocation::spec(call_pc));
2092   __ emit_static_call_stub();
2093 
2094   assert(__ offset() - start + CompiledStaticCall::to_trampoline_stub_size()
2095         &lt;= call_stub_size(), &quot;stub too big&quot;);
2096   __ end_a_stub();
2097 }
2098 
2099 
2100 void LIR_Assembler::throw_op(LIR_Opr exceptionPC, LIR_Opr exceptionOop, CodeEmitInfo* info) {
2101   assert(exceptionOop-&gt;as_register() == r0, &quot;must match&quot;);
2102   assert(exceptionPC-&gt;as_register() == r3, &quot;must match&quot;);
2103 
2104   // exception object is not added to oop map by LinearScan
2105   // (LinearScan assumes that no oops are in fixed registers)
2106   info-&gt;add_register_oop(exceptionOop);
2107   Runtime1::StubID unwind_id;
2108 
2109   // get current pc information
2110   // pc is only needed if the method has an exception handler, the unwind code does not need it.
<span class="line-added">2111   if (compilation()-&gt;debug_info_recorder()-&gt;last_pc_offset() == __ offset()) {</span>
<span class="line-added">2112     // As no instructions have been generated yet for this LIR node it&#39;s</span>
<span class="line-added">2113     // possible that an oop map already exists for the current offset.</span>
<span class="line-added">2114     // In that case insert an dummy NOP here to ensure all oop map PCs</span>
<span class="line-added">2115     // are unique. See JDK-8237483.</span>
<span class="line-added">2116     __ nop();</span>
<span class="line-added">2117   }</span>
2118   int pc_for_athrow_offset = __ offset();
2119   InternalAddress pc_for_athrow(__ pc());
2120   __ adr(exceptionPC-&gt;as_register(), pc_for_athrow);
2121   add_call_info(pc_for_athrow_offset, info); // for exception handler
2122 
2123   __ verify_not_null_oop(r0);
2124   // search an exception handler (r0: exception oop, r3: throwing pc)
2125   if (compilation()-&gt;has_fpu_code()) {
2126     unwind_id = Runtime1::handle_exception_id;
2127   } else {
2128     unwind_id = Runtime1::handle_exception_nofpu_id;
2129   }
2130   __ far_call(RuntimeAddress(Runtime1::entry_for(unwind_id)));
2131 
2132   // FIXME: enough room for two byte trap   ????
2133   __ nop();
2134 }
2135 
2136 
2137 void LIR_Assembler::unwind_op(LIR_Opr exceptionOop) {
</pre>
</td>
</tr>
</table>
<center><a href="assembler_aarch64.inline.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_LIRAssembler_aarch64.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>