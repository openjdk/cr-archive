<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/cpu/aarch64/aarch64.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
    1 //
    2 // Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.
    3 // Copyright (c) 2014, 2020, Red Hat, Inc. All rights reserved.
    4 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    5 //
    6 // This code is free software; you can redistribute it and/or modify it
    7 // under the terms of the GNU General Public License version 2 only, as
    8 // published by the Free Software Foundation.
    9 //
   10 // This code is distributed in the hope that it will be useful, but WITHOUT
   11 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   12 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   13 // version 2 for more details (a copy is included in the LICENSE file that
   14 // accompanied this code).
   15 //
   16 // You should have received a copy of the GNU General Public License version
   17 // 2 along with this work; if not, write to the Free Software Foundation,
   18 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   19 //
   20 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   21 // or visit www.oracle.com if you need additional information or have any
   22 // questions.
   23 //
   24 //
   25 
   26 // AArch64 Architecture Description File
   27 
   28 //----------REGISTER DEFINITION BLOCK------------------------------------------
   29 // This information is used by the matcher and the register allocator to
   30 // describe individual registers and classes of registers within the target
   31 // archtecture.
   32 
   33 register %{
   34 //----------Architecture Description Register Definitions----------------------
   35 // General Registers
   36 // &quot;reg_def&quot;  name ( register save type, C convention save type,
   37 //                   ideal register type, encoding );
   38 // Register Save Types:
   39 //
   40 // NS  = No-Save:       The register allocator assumes that these registers
   41 //                      can be used without saving upon entry to the method, &amp;
   42 //                      that they do not need to be saved at call sites.
   43 //
   44 // SOC = Save-On-Call:  The register allocator assumes that these registers
   45 //                      can be used without saving upon entry to the method,
   46 //                      but that they must be saved at call sites.
   47 //
   48 // SOE = Save-On-Entry: The register allocator assumes that these registers
   49 //                      must be saved before using them upon entry to the
   50 //                      method, but they do not need to be saved at call
   51 //                      sites.
   52 //
   53 // AS  = Always-Save:   The register allocator assumes that these registers
   54 //                      must be saved before using them upon entry to the
   55 //                      method, &amp; that they must be saved at call sites.
   56 //
   57 // Ideal Register Type is used to determine how to save &amp; restore a
   58 // register.  Op_RegI will get spilled with LoadI/StoreI, Op_RegP will get
   59 // spilled with LoadP/StoreP.  If the register supports both, use Op_RegI.
   60 //
   61 // The encoding number is the actual bit-pattern placed into the opcodes.
   62 
   63 // We must define the 64 bit int registers in two 32 bit halves, the
   64 // real lower register and a virtual upper half register. upper halves
   65 // are used by the register allocator but are not actually supplied as
   66 // operands to memory ops.
   67 //
   68 // follow the C1 compiler in making registers
   69 //
   70 //   r0-r7,r10-r26 volatile (caller save)
   71 //   r27-r32 system (no save, no allocate)
   72 //   r8-r9 invisible to the allocator (so we can use them as scratch regs)
   73 //
   74 // as regards Java usage. we don&#39;t use any callee save registers
   75 // because this makes it difficult to de-optimise a frame (see comment
   76 // in x86 implementation of Deoptimization::unwind_callee_save_values)
   77 //
   78 
   79 // General Registers
   80 
   81 reg_def R0      ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()         );
   82 reg_def R0_H    ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()-&gt;next() );
   83 reg_def R1      ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()         );
   84 reg_def R1_H    ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()-&gt;next() );
   85 reg_def R2      ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()         );
   86 reg_def R2_H    ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()-&gt;next() );
   87 reg_def R3      ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()         );
   88 reg_def R3_H    ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()-&gt;next() );
   89 reg_def R4      ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()         );
   90 reg_def R4_H    ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()-&gt;next() );
   91 reg_def R5      ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()         );
   92 reg_def R5_H    ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()-&gt;next() );
   93 reg_def R6      ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()         );
   94 reg_def R6_H    ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()-&gt;next() );
   95 reg_def R7      ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()         );
   96 reg_def R7_H    ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()-&gt;next() );
   97 reg_def R10     ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()        );
   98 reg_def R10_H   ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()-&gt;next());
   99 reg_def R11     ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()        );
  100 reg_def R11_H   ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()-&gt;next());
  101 reg_def R12     ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()        );
  102 reg_def R12_H   ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()-&gt;next());
  103 reg_def R13     ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()        );
  104 reg_def R13_H   ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()-&gt;next());
  105 reg_def R14     ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()        );
  106 reg_def R14_H   ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()-&gt;next());
  107 reg_def R15     ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()        );
  108 reg_def R15_H   ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()-&gt;next());
  109 reg_def R16     ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()        );
  110 reg_def R16_H   ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()-&gt;next());
  111 reg_def R17     ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()        );
  112 reg_def R17_H   ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()-&gt;next());
  113 reg_def R18     ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()        );
  114 reg_def R18_H   ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()-&gt;next());
  115 reg_def R19     ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()        );
  116 reg_def R19_H   ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()-&gt;next());
  117 reg_def R20     ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()        ); // caller esp
  118 reg_def R20_H   ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()-&gt;next());
  119 reg_def R21     ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()        );
  120 reg_def R21_H   ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()-&gt;next());
  121 reg_def R22     ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()        );
  122 reg_def R22_H   ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()-&gt;next());
  123 reg_def R23     ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()        );
  124 reg_def R23_H   ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()-&gt;next());
  125 reg_def R24     ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()        );
  126 reg_def R24_H   ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()-&gt;next());
  127 reg_def R25     ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()        );
  128 reg_def R25_H   ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()-&gt;next());
  129 reg_def R26     ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()        );
  130 reg_def R26_H   ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()-&gt;next());
  131 reg_def R27     ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()        ); // heapbase
  132 reg_def R27_H   ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()-&gt;next());
  133 reg_def R28     (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()        ); // thread
  134 reg_def R28_H   (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()-&gt;next());
  135 reg_def R29     (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()        ); // fp
  136 reg_def R29_H   (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()-&gt;next());
  137 reg_def R30     (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()        ); // lr
  138 reg_def R30_H   (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()-&gt;next());
  139 reg_def R31     (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()     ); // sp
  140 reg_def R31_H   (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()-&gt;next());
  141 
  142 // ----------------------------
  143 // Float/Double Registers
  144 // ----------------------------
  145 
  146 // Double Registers
  147 
  148 // The rules of ADL require that double registers be defined in pairs.
  149 // Each pair must be two 32-bit values, but not necessarily a pair of
  150 // single float registers. In each pair, ADLC-assigned register numbers
  151 // must be adjacent, with the lower number even. Finally, when the
  152 // CPU stores such a register pair to memory, the word associated with
  153 // the lower ADLC-assigned number must be stored to the lower address.
  154 
  155 // AArch64 has 32 floating-point registers. Each can store a vector of
  156 // single or double precision floating-point values up to 8 * 32
  157 // floats, 4 * 64 bit floats or 2 * 128 bit floats.  We currently only
  158 // use the first float or double element of the vector.
  159 
  160 // for Java use float registers v0-v15 are always save on call whereas
  161 // the platform ABI treats v8-v15 as callee save). float registers
  162 // v16-v31 are SOC as per the platform spec
  163 
  164   reg_def V0   ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()          );
  165   reg_def V0_H ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next()  );
  166   reg_def V0_J ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(2) );
  167   reg_def V0_K ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(3) );
  168 
  169   reg_def V1   ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()          );
  170   reg_def V1_H ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next()  );
  171   reg_def V1_J ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(2) );
  172   reg_def V1_K ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(3) );
  173 
  174   reg_def V2   ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()          );
  175   reg_def V2_H ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next()  );
  176   reg_def V2_J ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(2) );
  177   reg_def V2_K ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(3) );
  178 
  179   reg_def V3   ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()          );
  180   reg_def V3_H ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next()  );
  181   reg_def V3_J ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(2) );
  182   reg_def V3_K ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(3) );
  183 
  184   reg_def V4   ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()          );
  185   reg_def V4_H ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next()  );
  186   reg_def V4_J ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(2) );
  187   reg_def V4_K ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(3) );
  188 
  189   reg_def V5   ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()          );
  190   reg_def V5_H ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next()  );
  191   reg_def V5_J ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(2) );
  192   reg_def V5_K ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(3) );
  193 
  194   reg_def V6   ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()          );
  195   reg_def V6_H ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next()  );
  196   reg_def V6_J ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(2) );
  197   reg_def V6_K ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(3) );
  198 
  199   reg_def V7   ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()          );
  200   reg_def V7_H ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next()  );
  201   reg_def V7_J ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(2) );
  202   reg_def V7_K ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(3) );
  203 
  204   reg_def V8   ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()          );
  205   reg_def V8_H ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next()  );
  206   reg_def V8_J ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(2) );
  207   reg_def V8_K ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(3) );
  208 
  209   reg_def V9   ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()          );
  210   reg_def V9_H ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next()  );
  211   reg_def V9_J ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(2) );
  212   reg_def V9_K ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(3) );
  213 
  214   reg_def V10  ( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()         );
  215   reg_def V10_H( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next() );
  216   reg_def V10_J( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(2));
  217   reg_def V10_K( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(3));
  218 
  219   reg_def V11  ( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()         );
  220   reg_def V11_H( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next() );
  221   reg_def V11_J( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(2));
  222   reg_def V11_K( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(3));
  223 
  224   reg_def V12  ( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()         );
  225   reg_def V12_H( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next() );
  226   reg_def V12_J( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(2));
  227   reg_def V12_K( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(3));
  228 
  229   reg_def V13  ( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()         );
  230   reg_def V13_H( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next() );
  231   reg_def V13_J( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(2));
  232   reg_def V13_K( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(3));
  233 
  234   reg_def V14  ( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()         );
  235   reg_def V14_H( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next() );
  236   reg_def V14_J( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(2));
  237   reg_def V14_K( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(3));
  238 
  239   reg_def V15  ( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()         );
  240   reg_def V15_H( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next() );
  241   reg_def V15_J( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(2));
  242   reg_def V15_K( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(3));
  243 
  244   reg_def V16  ( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()         );
  245   reg_def V16_H( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next() );
  246   reg_def V16_J( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(2));
  247   reg_def V16_K( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(3));
  248 
  249   reg_def V17  ( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()         );
  250   reg_def V17_H( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next() );
  251   reg_def V17_J( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(2));
  252   reg_def V17_K( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(3));
  253 
  254   reg_def V18  ( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()         );
  255   reg_def V18_H( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next() );
  256   reg_def V18_J( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(2));
  257   reg_def V18_K( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(3));
  258 
  259   reg_def V19  ( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()         );
  260   reg_def V19_H( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next() );
  261   reg_def V19_J( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(2));
  262   reg_def V19_K( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(3));
  263 
  264   reg_def V20  ( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()         );
  265   reg_def V20_H( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next() );
  266   reg_def V20_J( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(2));
  267   reg_def V20_K( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(3));
  268 
  269   reg_def V21  ( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()         );
  270   reg_def V21_H( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next() );
  271   reg_def V21_J( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(2));
  272   reg_def V21_K( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(3));
  273 
  274   reg_def V22  ( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()         );
  275   reg_def V22_H( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next() );
  276   reg_def V22_J( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(2));
  277   reg_def V22_K( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(3));
  278 
  279   reg_def V23  ( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()         );
  280   reg_def V23_H( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next() );
  281   reg_def V23_J( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(2));
  282   reg_def V23_K( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(3));
  283 
  284   reg_def V24  ( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()         );
  285   reg_def V24_H( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next() );
  286   reg_def V24_J( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(2));
  287   reg_def V24_K( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(3));
  288 
  289   reg_def V25  ( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()         );
  290   reg_def V25_H( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next() );
  291   reg_def V25_J( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(2));
  292   reg_def V25_K( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(3));
  293 
  294   reg_def V26  ( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()         );
  295   reg_def V26_H( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next() );
  296   reg_def V26_J( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(2));
  297   reg_def V26_K( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(3));
  298 
  299   reg_def V27  ( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()         );
  300   reg_def V27_H( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next() );
  301   reg_def V27_J( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(2));
  302   reg_def V27_K( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(3));
  303 
  304   reg_def V28  ( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()         );
  305   reg_def V28_H( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next() );
  306   reg_def V28_J( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(2));
  307   reg_def V28_K( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(3));
  308 
  309   reg_def V29  ( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()         );
  310   reg_def V29_H( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next() );
  311   reg_def V29_J( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(2));
  312   reg_def V29_K( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(3));
  313 
  314   reg_def V30  ( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()         );
  315   reg_def V30_H( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next() );
  316   reg_def V30_J( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(2));
  317   reg_def V30_K( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(3));
  318 
  319   reg_def V31  ( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()         );
  320   reg_def V31_H( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next() );
  321   reg_def V31_J( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(2));
  322   reg_def V31_K( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(3));
  323 
  324 // ----------------------------
  325 // Special Registers
  326 // ----------------------------
  327 
  328 // the AArch64 CSPR status flag register is not directly acessible as
  329 // instruction operand. the FPSR status flag register is a system
  330 // register which can be written/read using MSR/MRS but again does not
  331 // appear as an operand (a code identifying the FSPR occurs as an
  332 // immediate value in the instruction).
  333 
  334 reg_def RFLAGS(SOC, SOC, 0, 32, VMRegImpl::Bad());
  335 
  336 
  337 // Specify priority of register selection within phases of register
  338 // allocation.  Highest priority is first.  A useful heuristic is to
  339 // give registers a low priority when they are required by machine
  340 // instructions, like EAX and EDX on I486, and choose no-save registers
  341 // before save-on-call, &amp; save-on-call before save-on-entry.  Registers
  342 // which participate in fixed calling sequences should come last.
  343 // Registers which are used as pairs must fall on an even boundary.
  344 
  345 alloc_class chunk0(
  346     // volatiles
  347     R10, R10_H,
  348     R11, R11_H,
  349     R12, R12_H,
  350     R13, R13_H,
  351     R14, R14_H,
  352     R15, R15_H,
  353     R16, R16_H,
  354     R17, R17_H,
  355     R18, R18_H,
  356 
  357     // arg registers
  358     R0, R0_H,
  359     R1, R1_H,
  360     R2, R2_H,
  361     R3, R3_H,
  362     R4, R4_H,
  363     R5, R5_H,
  364     R6, R6_H,
  365     R7, R7_H,
  366 
  367     // non-volatiles
  368     R19, R19_H,
  369     R20, R20_H,
  370     R21, R21_H,
  371     R22, R22_H,
  372     R23, R23_H,
  373     R24, R24_H,
  374     R25, R25_H,
  375     R26, R26_H,
  376 
  377     // non-allocatable registers
  378 
  379     R27, R27_H, // heapbase
  380     R28, R28_H, // thread
  381     R29, R29_H, // fp
  382     R30, R30_H, // lr
  383     R31, R31_H, // sp
  384 );
  385 
  386 alloc_class chunk1(
  387 
  388     // no save
  389     V16, V16_H, V16_J, V16_K,
  390     V17, V17_H, V17_J, V17_K,
  391     V18, V18_H, V18_J, V18_K,
  392     V19, V19_H, V19_J, V19_K,
  393     V20, V20_H, V20_J, V20_K,
  394     V21, V21_H, V21_J, V21_K,
  395     V22, V22_H, V22_J, V22_K,
  396     V23, V23_H, V23_J, V23_K,
  397     V24, V24_H, V24_J, V24_K,
  398     V25, V25_H, V25_J, V25_K,
  399     V26, V26_H, V26_J, V26_K,
  400     V27, V27_H, V27_J, V27_K,
  401     V28, V28_H, V28_J, V28_K,
  402     V29, V29_H, V29_J, V29_K,
  403     V30, V30_H, V30_J, V30_K,
  404     V31, V31_H, V31_J, V31_K,
  405 
  406     // arg registers
  407     V0, V0_H, V0_J, V0_K,
  408     V1, V1_H, V1_J, V1_K,
  409     V2, V2_H, V2_J, V2_K,
  410     V3, V3_H, V3_J, V3_K,
  411     V4, V4_H, V4_J, V4_K,
  412     V5, V5_H, V5_J, V5_K,
  413     V6, V6_H, V6_J, V6_K,
  414     V7, V7_H, V7_J, V7_K,
  415 
  416     // non-volatiles
  417     V8, V8_H, V8_J, V8_K,
  418     V9, V9_H, V9_J, V9_K,
  419     V10, V10_H, V10_J, V10_K,
  420     V11, V11_H, V11_J, V11_K,
  421     V12, V12_H, V12_J, V12_K,
  422     V13, V13_H, V13_J, V13_K,
  423     V14, V14_H, V14_J, V14_K,
  424     V15, V15_H, V15_J, V15_K,
  425 );
  426 
  427 alloc_class chunk2(RFLAGS);
  428 
  429 //----------Architecture Description Register Classes--------------------------
  430 // Several register classes are automatically defined based upon information in
  431 // this architecture description.
  432 // 1) reg_class inline_cache_reg           ( /* as def&#39;d in frame section */ )
  433 // 2) reg_class compiler_method_oop_reg    ( /* as def&#39;d in frame section */ )
  434 // 2) reg_class interpreter_method_oop_reg ( /* as def&#39;d in frame section */ )
  435 // 3) reg_class stack_slots( /* one chunk of stack-based &quot;registers&quot; */ )
  436 //
  437 
  438 // Class for all 32 bit general purpose registers
  439 reg_class all_reg32(
  440     R0,
  441     R1,
  442     R2,
  443     R3,
  444     R4,
  445     R5,
  446     R6,
  447     R7,
  448     R10,
  449     R11,
  450     R12,
  451     R13,
  452     R14,
  453     R15,
  454     R16,
  455     R17,
  456     R18,
  457     R19,
  458     R20,
  459     R21,
  460     R22,
  461     R23,
  462     R24,
  463     R25,
  464     R26,
  465     R27,
  466     R28,
  467     R29,
  468     R30,
  469     R31
  470 );
  471 
  472 
  473 // Class for all 32 bit integer registers (excluding SP which
  474 // will never be used as an integer register)
  475 reg_class any_reg32 %{
  476   return _ANY_REG32_mask;
  477 %}
  478 
  479 // Singleton class for R0 int register
  480 reg_class int_r0_reg(R0);
  481 
  482 // Singleton class for R2 int register
  483 reg_class int_r2_reg(R2);
  484 
  485 // Singleton class for R3 int register
  486 reg_class int_r3_reg(R3);
  487 
  488 // Singleton class for R4 int register
  489 reg_class int_r4_reg(R4);
  490 
  491 // Singleton class for R31 int register
  492 reg_class int_r31_reg(R31);
  493 
  494 // Class for all 64 bit general purpose registers
  495 reg_class all_reg(
  496     R0, R0_H,
  497     R1, R1_H,
  498     R2, R2_H,
  499     R3, R3_H,
  500     R4, R4_H,
  501     R5, R5_H,
  502     R6, R6_H,
  503     R7, R7_H,
  504     R10, R10_H,
  505     R11, R11_H,
  506     R12, R12_H,
  507     R13, R13_H,
  508     R14, R14_H,
  509     R15, R15_H,
  510     R16, R16_H,
  511     R17, R17_H,
  512     R18, R18_H,
  513     R19, R19_H,
  514     R20, R20_H,
  515     R21, R21_H,
  516     R22, R22_H,
  517     R23, R23_H,
  518     R24, R24_H,
  519     R25, R25_H,
  520     R26, R26_H,
  521     R27, R27_H,
  522     R28, R28_H,
  523     R29, R29_H,
  524     R30, R30_H,
  525     R31, R31_H
  526 );
  527 
  528 // Class for all long integer registers (including SP)
  529 reg_class any_reg %{
  530   return _ANY_REG_mask;
  531 %}
  532 
  533 // Class for non-allocatable 32 bit registers
  534 reg_class non_allocatable_reg32(
  535     R28,                        // thread
  536     R30,                        // lr
  537     R31                         // sp
  538 );
  539 
  540 // Class for non-allocatable 64 bit registers
  541 reg_class non_allocatable_reg(
  542     R28, R28_H,                 // thread
  543     R30, R30_H,                 // lr
  544     R31, R31_H                  // sp
  545 );
  546 
  547 // Class for all non-special integer registers
  548 reg_class no_special_reg32 %{
  549   return _NO_SPECIAL_REG32_mask;
  550 %}
  551 
  552 // Class for all non-special long integer registers
  553 reg_class no_special_reg %{
  554   return _NO_SPECIAL_REG_mask;
  555 %}
  556 
  557 // Class for 64 bit register r0
  558 reg_class r0_reg(
  559     R0, R0_H
  560 );
  561 
  562 // Class for 64 bit register r1
  563 reg_class r1_reg(
  564     R1, R1_H
  565 );
  566 
  567 // Class for 64 bit register r2
  568 reg_class r2_reg(
  569     R2, R2_H
  570 );
  571 
  572 // Class for 64 bit register r3
  573 reg_class r3_reg(
  574     R3, R3_H
  575 );
  576 
  577 // Class for 64 bit register r4
  578 reg_class r4_reg(
  579     R4, R4_H
  580 );
  581 
  582 // Class for 64 bit register r5
  583 reg_class r5_reg(
  584     R5, R5_H
  585 );
  586 
  587 // Class for 64 bit register r10
  588 reg_class r10_reg(
  589     R10, R10_H
  590 );
  591 
  592 // Class for 64 bit register r11
  593 reg_class r11_reg(
  594     R11, R11_H
  595 );
  596 
  597 // Class for method register
  598 reg_class method_reg(
  599     R12, R12_H
  600 );
  601 
  602 // Class for heapbase register
  603 reg_class heapbase_reg(
  604     R27, R27_H
  605 );
  606 
  607 // Class for thread register
  608 reg_class thread_reg(
  609     R28, R28_H
  610 );
  611 
  612 // Class for frame pointer register
  613 reg_class fp_reg(
  614     R29, R29_H
  615 );
  616 
  617 // Class for link register
  618 reg_class lr_reg(
  619     R30, R30_H
  620 );
  621 
  622 // Class for long sp register
  623 reg_class sp_reg(
  624   R31, R31_H
  625 );
  626 
  627 // Class for all pointer registers
  628 reg_class ptr_reg %{
  629   return _PTR_REG_mask;
  630 %}
  631 
  632 // Class for all non_special pointer registers
  633 reg_class no_special_ptr_reg %{
  634   return _NO_SPECIAL_PTR_REG_mask;
  635 %}
  636 
  637 // Class for all float registers
  638 reg_class float_reg(
  639     V0,
  640     V1,
  641     V2,
  642     V3,
  643     V4,
  644     V5,
  645     V6,
  646     V7,
  647     V8,
  648     V9,
  649     V10,
  650     V11,
  651     V12,
  652     V13,
  653     V14,
  654     V15,
  655     V16,
  656     V17,
  657     V18,
  658     V19,
  659     V20,
  660     V21,
  661     V22,
  662     V23,
  663     V24,
  664     V25,
  665     V26,
  666     V27,
  667     V28,
  668     V29,
  669     V30,
  670     V31
  671 );
  672 
  673 // Double precision float registers have virtual `high halves&#39; that
  674 // are needed by the allocator.
  675 // Class for all double registers
  676 reg_class double_reg(
  677     V0, V0_H,
  678     V1, V1_H,
  679     V2, V2_H,
  680     V3, V3_H,
  681     V4, V4_H,
  682     V5, V5_H,
  683     V6, V6_H,
  684     V7, V7_H,
  685     V8, V8_H,
  686     V9, V9_H,
  687     V10, V10_H,
  688     V11, V11_H,
  689     V12, V12_H,
  690     V13, V13_H,
  691     V14, V14_H,
  692     V15, V15_H,
  693     V16, V16_H,
  694     V17, V17_H,
  695     V18, V18_H,
  696     V19, V19_H,
  697     V20, V20_H,
  698     V21, V21_H,
  699     V22, V22_H,
  700     V23, V23_H,
  701     V24, V24_H,
  702     V25, V25_H,
  703     V26, V26_H,
  704     V27, V27_H,
  705     V28, V28_H,
  706     V29, V29_H,
  707     V30, V30_H,
  708     V31, V31_H
  709 );
  710 
  711 // Class for all 64bit vector registers
  712 reg_class vectord_reg(
  713     V0, V0_H,
  714     V1, V1_H,
  715     V2, V2_H,
  716     V3, V3_H,
  717     V4, V4_H,
  718     V5, V5_H,
  719     V6, V6_H,
  720     V7, V7_H,
  721     V8, V8_H,
  722     V9, V9_H,
  723     V10, V10_H,
  724     V11, V11_H,
  725     V12, V12_H,
  726     V13, V13_H,
  727     V14, V14_H,
  728     V15, V15_H,
  729     V16, V16_H,
  730     V17, V17_H,
  731     V18, V18_H,
  732     V19, V19_H,
  733     V20, V20_H,
  734     V21, V21_H,
  735     V22, V22_H,
  736     V23, V23_H,
  737     V24, V24_H,
  738     V25, V25_H,
  739     V26, V26_H,
  740     V27, V27_H,
  741     V28, V28_H,
  742     V29, V29_H,
  743     V30, V30_H,
  744     V31, V31_H
  745 );
  746 
  747 // Class for all 128bit vector registers
  748 reg_class vectorx_reg(
  749     V0, V0_H, V0_J, V0_K,
  750     V1, V1_H, V1_J, V1_K,
  751     V2, V2_H, V2_J, V2_K,
  752     V3, V3_H, V3_J, V3_K,
  753     V4, V4_H, V4_J, V4_K,
  754     V5, V5_H, V5_J, V5_K,
  755     V6, V6_H, V6_J, V6_K,
  756     V7, V7_H, V7_J, V7_K,
  757     V8, V8_H, V8_J, V8_K,
  758     V9, V9_H, V9_J, V9_K,
  759     V10, V10_H, V10_J, V10_K,
  760     V11, V11_H, V11_J, V11_K,
  761     V12, V12_H, V12_J, V12_K,
  762     V13, V13_H, V13_J, V13_K,
  763     V14, V14_H, V14_J, V14_K,
  764     V15, V15_H, V15_J, V15_K,
  765     V16, V16_H, V16_J, V16_K,
  766     V17, V17_H, V17_J, V17_K,
  767     V18, V18_H, V18_J, V18_K,
  768     V19, V19_H, V19_J, V19_K,
  769     V20, V20_H, V20_J, V20_K,
  770     V21, V21_H, V21_J, V21_K,
  771     V22, V22_H, V22_J, V22_K,
  772     V23, V23_H, V23_J, V23_K,
  773     V24, V24_H, V24_J, V24_K,
  774     V25, V25_H, V25_J, V25_K,
  775     V26, V26_H, V26_J, V26_K,
  776     V27, V27_H, V27_J, V27_K,
  777     V28, V28_H, V28_J, V28_K,
  778     V29, V29_H, V29_J, V29_K,
  779     V30, V30_H, V30_J, V30_K,
  780     V31, V31_H, V31_J, V31_K
  781 );
  782 
  783 // Class for 128 bit register v0
  784 reg_class v0_reg(
  785     V0, V0_H
  786 );
  787 
  788 // Class for 128 bit register v1
  789 reg_class v1_reg(
  790     V1, V1_H
  791 );
  792 
  793 // Class for 128 bit register v2
  794 reg_class v2_reg(
  795     V2, V2_H
  796 );
  797 
  798 // Class for 128 bit register v3
  799 reg_class v3_reg(
  800     V3, V3_H
  801 );
  802 
  803 // Class for 128 bit register v4
  804 reg_class v4_reg(
  805     V4, V4_H
  806 );
  807 
  808 // Class for 128 bit register v5
  809 reg_class v5_reg(
  810     V5, V5_H
  811 );
  812 
  813 // Class for 128 bit register v6
  814 reg_class v6_reg(
  815     V6, V6_H
  816 );
  817 
  818 // Class for 128 bit register v7
  819 reg_class v7_reg(
  820     V7, V7_H
  821 );
  822 
  823 // Class for 128 bit register v8
  824 reg_class v8_reg(
  825     V8, V8_H
  826 );
  827 
  828 // Class for 128 bit register v9
  829 reg_class v9_reg(
  830     V9, V9_H
  831 );
  832 
  833 // Class for 128 bit register v10
  834 reg_class v10_reg(
  835     V10, V10_H
  836 );
  837 
  838 // Class for 128 bit register v11
  839 reg_class v11_reg(
  840     V11, V11_H
  841 );
  842 
  843 // Class for 128 bit register v12
  844 reg_class v12_reg(
  845     V12, V12_H
  846 );
  847 
  848 // Class for 128 bit register v13
  849 reg_class v13_reg(
  850     V13, V13_H
  851 );
  852 
  853 // Class for 128 bit register v14
  854 reg_class v14_reg(
  855     V14, V14_H
  856 );
  857 
  858 // Class for 128 bit register v15
  859 reg_class v15_reg(
  860     V15, V15_H
  861 );
  862 
  863 // Class for 128 bit register v16
  864 reg_class v16_reg(
  865     V16, V16_H
  866 );
  867 
  868 // Class for 128 bit register v17
  869 reg_class v17_reg(
  870     V17, V17_H
  871 );
  872 
  873 // Class for 128 bit register v18
  874 reg_class v18_reg(
  875     V18, V18_H
  876 );
  877 
  878 // Class for 128 bit register v19
  879 reg_class v19_reg(
  880     V19, V19_H
  881 );
  882 
  883 // Class for 128 bit register v20
  884 reg_class v20_reg(
  885     V20, V20_H
  886 );
  887 
  888 // Class for 128 bit register v21
  889 reg_class v21_reg(
  890     V21, V21_H
  891 );
  892 
  893 // Class for 128 bit register v22
  894 reg_class v22_reg(
  895     V22, V22_H
  896 );
  897 
  898 // Class for 128 bit register v23
  899 reg_class v23_reg(
  900     V23, V23_H
  901 );
  902 
  903 // Class for 128 bit register v24
  904 reg_class v24_reg(
  905     V24, V24_H
  906 );
  907 
  908 // Class for 128 bit register v25
  909 reg_class v25_reg(
  910     V25, V25_H
  911 );
  912 
  913 // Class for 128 bit register v26
  914 reg_class v26_reg(
  915     V26, V26_H
  916 );
  917 
  918 // Class for 128 bit register v27
  919 reg_class v27_reg(
  920     V27, V27_H
  921 );
  922 
  923 // Class for 128 bit register v28
  924 reg_class v28_reg(
  925     V28, V28_H
  926 );
  927 
  928 // Class for 128 bit register v29
  929 reg_class v29_reg(
  930     V29, V29_H
  931 );
  932 
  933 // Class for 128 bit register v30
  934 reg_class v30_reg(
  935     V30, V30_H
  936 );
  937 
  938 // Class for 128 bit register v31
  939 reg_class v31_reg(
  940     V31, V31_H
  941 );
  942 
  943 // Singleton class for condition codes
  944 reg_class int_flags(RFLAGS);
  945 
  946 %}
  947 
  948 //----------DEFINITION BLOCK---------------------------------------------------
  949 // Define name --&gt; value mappings to inform the ADLC of an integer valued name
  950 // Current support includes integer values in the range [0, 0x7FFFFFFF]
  951 // Format:
  952 //        int_def  &lt;name&gt;         ( &lt;int_value&gt;, &lt;expression&gt;);
  953 // Generated Code in ad_&lt;arch&gt;.hpp
  954 //        #define  &lt;name&gt;   (&lt;expression&gt;)
  955 //        // value == &lt;int_value&gt;
  956 // Generated code in ad_&lt;arch&gt;.cpp adlc_verification()
  957 //        assert( &lt;name&gt; == &lt;int_value&gt;, &quot;Expect (&lt;expression&gt;) to equal &lt;int_value&gt;&quot;);
  958 //
  959 
  960 // we follow the ppc-aix port in using a simple cost model which ranks
  961 // register operations as cheap, memory ops as more expensive and
  962 // branches as most expensive. the first two have a low as well as a
  963 // normal cost. huge cost appears to be a way of saying don&#39;t do
  964 // something
  965 
  966 definitions %{
  967   // The default cost (of a register move instruction).
  968   int_def INSN_COST            (    100,     100);
  969   int_def BRANCH_COST          (    200,     2 * INSN_COST);
  970   int_def CALL_COST            (    200,     2 * INSN_COST);
  971   int_def VOLATILE_REF_COST    (   1000,     10 * INSN_COST);
  972 %}
  973 
  974 
  975 //----------SOURCE BLOCK-------------------------------------------------------
  976 // This is a block of C++ code which provides values, functions, and
  977 // definitions necessary in the rest of the architecture description
  978 
  979 source_hpp %{
  980 
  981 #include &quot;asm/macroAssembler.hpp&quot;
  982 #include &quot;gc/shared/cardTable.hpp&quot;
  983 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;
  984 #include &quot;gc/shared/collectedHeap.hpp&quot;
  985 #include &quot;opto/addnode.hpp&quot;
  986 #include &quot;opto/convertnode.hpp&quot;
  987 
  988 extern RegMask _ANY_REG32_mask;
  989 extern RegMask _ANY_REG_mask;
  990 extern RegMask _PTR_REG_mask;
  991 extern RegMask _NO_SPECIAL_REG32_mask;
  992 extern RegMask _NO_SPECIAL_REG_mask;
  993 extern RegMask _NO_SPECIAL_PTR_REG_mask;
  994 
  995 class CallStubImpl {
  996 
  997   //--------------------------------------------------------------
  998   //---&lt;  Used for optimization in Compile::shorten_branches  &gt;---
  999   //--------------------------------------------------------------
 1000 
 1001  public:
 1002   // Size of call trampoline stub.
 1003   static uint size_call_trampoline() {
 1004     return 0; // no call trampolines on this platform
 1005   }
 1006 
 1007   // number of relocations needed by a call trampoline stub
 1008   static uint reloc_call_trampoline() {
 1009     return 0; // no call trampolines on this platform
 1010   }
 1011 };
 1012 
 1013 class HandlerImpl {
 1014 
 1015  public:
 1016 
 1017   static int emit_exception_handler(CodeBuffer &amp;cbuf);
 1018   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
 1019 
 1020   static uint size_exception_handler() {
 1021     return MacroAssembler::far_branch_size();
 1022   }
 1023 
 1024   static uint size_deopt_handler() {
 1025     // count one adr and one far branch instruction
 1026     return 4 * NativeInstruction::instruction_size;
 1027   }
 1028 };
 1029 
 1030 class Node::PD {
 1031 public:
 1032   enum NodeFlags {
 1033     _last_flag = Node::_last_flag
 1034   };
 1035 };
 1036 
 1037  bool is_CAS(int opcode, bool maybe_volatile);
 1038 
 1039   // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1040 
 1041   bool unnecessary_acquire(const Node *barrier);
 1042   bool needs_acquiring_load(const Node *load);
 1043 
 1044   // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1045 
 1046   bool unnecessary_release(const Node *barrier);
 1047   bool unnecessary_volatile(const Node *barrier);
 1048   bool needs_releasing_store(const Node *store);
 1049 
 1050   // predicate controlling translation of CompareAndSwapX
 1051   bool needs_acquiring_load_exclusive(const Node *load);
 1052 
 1053   // predicate controlling addressing modes
 1054   bool size_fits_all_mem_uses(AddPNode* addp, int shift);
 1055 %}
 1056 
 1057 source %{
 1058 
 1059   // Derived RegMask with conditionally allocatable registers
 1060 
 1061   void PhaseOutput::pd_perform_mach_node_analysis() {
 1062   }
 1063 
 1064   int MachNode::pd_alignment_required() const {
 1065     return 1;
 1066   }
 1067 
 1068   int MachNode::compute_padding(int current_offset) const {
 1069     return 0;
 1070   }
 1071 
 1072   RegMask _ANY_REG32_mask;
 1073   RegMask _ANY_REG_mask;
 1074   RegMask _PTR_REG_mask;
 1075   RegMask _NO_SPECIAL_REG32_mask;
 1076   RegMask _NO_SPECIAL_REG_mask;
 1077   RegMask _NO_SPECIAL_PTR_REG_mask;
 1078 
 1079   void reg_mask_init() {
 1080     // We derive below RegMask(s) from the ones which are auto-generated from
 1081     // adlc register classes to make AArch64 rheapbase (r27) and rfp (r29)
 1082     // registers conditionally reserved.
 1083 
 1084     _ANY_REG32_mask = _ALL_REG32_mask;
 1085     _ANY_REG32_mask.Remove(OptoReg::as_OptoReg(r31_sp-&gt;as_VMReg()));
 1086 
 1087     _ANY_REG_mask = _ALL_REG_mask;
 1088 
 1089     _PTR_REG_mask = _ALL_REG_mask;
 1090 
 1091     _NO_SPECIAL_REG32_mask = _ALL_REG32_mask;
 1092     _NO_SPECIAL_REG32_mask.SUBTRACT(_NON_ALLOCATABLE_REG32_mask);
 1093 
 1094     _NO_SPECIAL_REG_mask = _ALL_REG_mask;
 1095     _NO_SPECIAL_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1096 
 1097     _NO_SPECIAL_PTR_REG_mask = _ALL_REG_mask;
 1098     _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1099 
 1100     // r27 is not allocatable when compressed oops is on and heapbase is not
 1101     // zero, compressed klass pointers doesn&#39;t use r27 after JDK-8234794
 1102     if (UseCompressedOops &amp;&amp; (CompressedOops::ptrs_base() != NULL || UseAOT)) {
 1103       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r27-&gt;as_VMReg()));
 1104       _NO_SPECIAL_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1105       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1106     }
 1107 
 1108     // r29 is not allocatable when PreserveFramePointer is on
 1109     if (PreserveFramePointer) {
 1110       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r29-&gt;as_VMReg()));
 1111       _NO_SPECIAL_REG_mask.SUBTRACT(_FP_REG_mask);
 1112       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_FP_REG_mask);
 1113     }
 1114   }
 1115 
 1116   // Optimizaton of volatile gets and puts
 1117   // -------------------------------------
 1118   //
 1119   // AArch64 has ldar&lt;x&gt; and stlr&lt;x&gt; instructions which we can safely
 1120   // use to implement volatile reads and writes. For a volatile read
 1121   // we simply need
 1122   //
 1123   //   ldar&lt;x&gt;
 1124   //
 1125   // and for a volatile write we need
 1126   //
 1127   //   stlr&lt;x&gt;
 1128   //
 1129   // Alternatively, we can implement them by pairing a normal
 1130   // load/store with a memory barrier. For a volatile read we need
 1131   //
 1132   //   ldr&lt;x&gt;
 1133   //   dmb ishld
 1134   //
 1135   // for a volatile write
 1136   //
 1137   //   dmb ish
 1138   //   str&lt;x&gt;
 1139   //   dmb ish
 1140   //
 1141   // We can also use ldaxr and stlxr to implement compare and swap CAS
 1142   // sequences. These are normally translated to an instruction
 1143   // sequence like the following
 1144   //
 1145   //   dmb      ish
 1146   // retry:
 1147   //   ldxr&lt;x&gt;   rval raddr
 1148   //   cmp       rval rold
 1149   //   b.ne done
 1150   //   stlxr&lt;x&gt;  rval, rnew, rold
 1151   //   cbnz      rval retry
 1152   // done:
 1153   //   cset      r0, eq
 1154   //   dmb ishld
 1155   //
 1156   // Note that the exclusive store is already using an stlxr
 1157   // instruction. That is required to ensure visibility to other
 1158   // threads of the exclusive write (assuming it succeeds) before that
 1159   // of any subsequent writes.
 1160   //
 1161   // The following instruction sequence is an improvement on the above
 1162   //
 1163   // retry:
 1164   //   ldaxr&lt;x&gt;  rval raddr
 1165   //   cmp       rval rold
 1166   //   b.ne done
 1167   //   stlxr&lt;x&gt;  rval, rnew, rold
 1168   //   cbnz      rval retry
 1169   // done:
 1170   //   cset      r0, eq
 1171   //
 1172   // We don&#39;t need the leading dmb ish since the stlxr guarantees
 1173   // visibility of prior writes in the case that the swap is
 1174   // successful. Crucially we don&#39;t have to worry about the case where
 1175   // the swap is not successful since no valid program should be
 1176   // relying on visibility of prior changes by the attempting thread
 1177   // in the case where the CAS fails.
 1178   //
 1179   // Similarly, we don&#39;t need the trailing dmb ishld if we substitute
 1180   // an ldaxr instruction since that will provide all the guarantees we
 1181   // require regarding observation of changes made by other threads
 1182   // before any change to the CAS address observed by the load.
 1183   //
 1184   // In order to generate the desired instruction sequence we need to
 1185   // be able to identify specific &#39;signature&#39; ideal graph node
 1186   // sequences which i) occur as a translation of a volatile reads or
 1187   // writes or CAS operations and ii) do not occur through any other
 1188   // translation or graph transformation. We can then provide
 1189   // alternative aldc matching rules which translate these node
 1190   // sequences to the desired machine code sequences. Selection of the
 1191   // alternative rules can be implemented by predicates which identify
 1192   // the relevant node sequences.
 1193   //
 1194   // The ideal graph generator translates a volatile read to the node
 1195   // sequence
 1196   //
 1197   //   LoadX[mo_acquire]
 1198   //   MemBarAcquire
 1199   //
 1200   // As a special case when using the compressed oops optimization we
 1201   // may also see this variant
 1202   //
 1203   //   LoadN[mo_acquire]
 1204   //   DecodeN
 1205   //   MemBarAcquire
 1206   //
 1207   // A volatile write is translated to the node sequence
 1208   //
 1209   //   MemBarRelease
 1210   //   StoreX[mo_release] {CardMark}-optional
 1211   //   MemBarVolatile
 1212   //
 1213   // n.b. the above node patterns are generated with a strict
 1214   // &#39;signature&#39; configuration of input and output dependencies (see
 1215   // the predicates below for exact details). The card mark may be as
 1216   // simple as a few extra nodes or, in a few GC configurations, may
 1217   // include more complex control flow between the leading and
 1218   // trailing memory barriers. However, whatever the card mark
 1219   // configuration these signatures are unique to translated volatile
 1220   // reads/stores -- they will not appear as a result of any other
 1221   // bytecode translation or inlining nor as a consequence of
 1222   // optimizing transforms.
 1223   //
 1224   // We also want to catch inlined unsafe volatile gets and puts and
 1225   // be able to implement them using either ldar&lt;x&gt;/stlr&lt;x&gt; or some
 1226   // combination of ldr&lt;x&gt;/stlr&lt;x&gt; and dmb instructions.
 1227   //
 1228   // Inlined unsafe volatiles puts manifest as a minor variant of the
 1229   // normal volatile put node sequence containing an extra cpuorder
 1230   // membar
 1231   //
 1232   //   MemBarRelease
 1233   //   MemBarCPUOrder
 1234   //   StoreX[mo_release] {CardMark}-optional
 1235   //   MemBarCPUOrder
 1236   //   MemBarVolatile
 1237   //
 1238   // n.b. as an aside, a cpuorder membar is not itself subject to
 1239   // matching and translation by adlc rules.  However, the rule
 1240   // predicates need to detect its presence in order to correctly
 1241   // select the desired adlc rules.
 1242   //
 1243   // Inlined unsafe volatile gets manifest as a slightly different
 1244   // node sequence to a normal volatile get because of the
 1245   // introduction of some CPUOrder memory barriers to bracket the
 1246   // Load. However, but the same basic skeleton of a LoadX feeding a
 1247   // MemBarAcquire, possibly thorugh an optional DecodeN, is still
 1248   // present
 1249   //
 1250   //   MemBarCPUOrder
 1251   //        ||       \\
 1252   //   MemBarCPUOrder LoadX[mo_acquire]
 1253   //        ||            |
 1254   //        ||       {DecodeN} optional
 1255   //        ||       /
 1256   //     MemBarAcquire
 1257   //
 1258   // In this case the acquire membar does not directly depend on the
 1259   // load. However, we can be sure that the load is generated from an
 1260   // inlined unsafe volatile get if we see it dependent on this unique
 1261   // sequence of membar nodes. Similarly, given an acquire membar we
 1262   // can know that it was added because of an inlined unsafe volatile
 1263   // get if it is fed and feeds a cpuorder membar and if its feed
 1264   // membar also feeds an acquiring load.
 1265   //
 1266   // Finally an inlined (Unsafe) CAS operation is translated to the
 1267   // following ideal graph
 1268   //
 1269   //   MemBarRelease
 1270   //   MemBarCPUOrder
 1271   //   CompareAndSwapX {CardMark}-optional
 1272   //   MemBarCPUOrder
 1273   //   MemBarAcquire
 1274   //
 1275   // So, where we can identify these volatile read and write
 1276   // signatures we can choose to plant either of the above two code
 1277   // sequences. For a volatile read we can simply plant a normal
 1278   // ldr&lt;x&gt; and translate the MemBarAcquire to a dmb. However, we can
 1279   // also choose to inhibit translation of the MemBarAcquire and
 1280   // inhibit planting of the ldr&lt;x&gt;, instead planting an ldar&lt;x&gt;.
 1281   //
 1282   // When we recognise a volatile store signature we can choose to
 1283   // plant at a dmb ish as a translation for the MemBarRelease, a
 1284   // normal str&lt;x&gt; and then a dmb ish for the MemBarVolatile.
 1285   // Alternatively, we can inhibit translation of the MemBarRelease
 1286   // and MemBarVolatile and instead plant a simple stlr&lt;x&gt;
 1287   // instruction.
 1288   //
 1289   // when we recognise a CAS signature we can choose to plant a dmb
 1290   // ish as a translation for the MemBarRelease, the conventional
 1291   // macro-instruction sequence for the CompareAndSwap node (which
 1292   // uses ldxr&lt;x&gt;) and then a dmb ishld for the MemBarAcquire.
 1293   // Alternatively, we can elide generation of the dmb instructions
 1294   // and plant the alternative CompareAndSwap macro-instruction
 1295   // sequence (which uses ldaxr&lt;x&gt;).
 1296   //
 1297   // Of course, the above only applies when we see these signature
 1298   // configurations. We still want to plant dmb instructions in any
 1299   // other cases where we may see a MemBarAcquire, MemBarRelease or
 1300   // MemBarVolatile. For example, at the end of a constructor which
 1301   // writes final/volatile fields we will see a MemBarRelease
 1302   // instruction and this needs a &#39;dmb ish&#39; lest we risk the
 1303   // constructed object being visible without making the
 1304   // final/volatile field writes visible.
 1305   //
 1306   // n.b. the translation rules below which rely on detection of the
 1307   // volatile signatures and insert ldar&lt;x&gt; or stlr&lt;x&gt; are failsafe.
 1308   // If we see anything other than the signature configurations we
 1309   // always just translate the loads and stores to ldr&lt;x&gt; and str&lt;x&gt;
 1310   // and translate acquire, release and volatile membars to the
 1311   // relevant dmb instructions.
 1312   //
 1313 
 1314   // is_CAS(int opcode, bool maybe_volatile)
 1315   //
 1316   // return true if opcode is one of the possible CompareAndSwapX
 1317   // values otherwise false.
 1318 
 1319   bool is_CAS(int opcode, bool maybe_volatile)
 1320   {
 1321     switch(opcode) {
 1322       // We handle these
 1323     case Op_CompareAndSwapI:
 1324     case Op_CompareAndSwapL:
 1325     case Op_CompareAndSwapP:
 1326     case Op_CompareAndSwapN:
 1327     case Op_ShenandoahCompareAndSwapP:
 1328     case Op_ShenandoahCompareAndSwapN:
 1329     case Op_CompareAndSwapB:
 1330     case Op_CompareAndSwapS:
 1331     case Op_GetAndSetI:
 1332     case Op_GetAndSetL:
 1333     case Op_GetAndSetP:
 1334     case Op_GetAndSetN:
 1335     case Op_GetAndAddI:
 1336     case Op_GetAndAddL:
 1337       return true;
 1338     case Op_CompareAndExchangeI:
 1339     case Op_CompareAndExchangeN:
 1340     case Op_CompareAndExchangeB:
 1341     case Op_CompareAndExchangeS:
 1342     case Op_CompareAndExchangeL:
 1343     case Op_CompareAndExchangeP:
 1344     case Op_WeakCompareAndSwapB:
 1345     case Op_WeakCompareAndSwapS:
 1346     case Op_WeakCompareAndSwapI:
 1347     case Op_WeakCompareAndSwapL:
 1348     case Op_WeakCompareAndSwapP:
 1349     case Op_WeakCompareAndSwapN:
 1350     case Op_ShenandoahWeakCompareAndSwapP:
 1351     case Op_ShenandoahWeakCompareAndSwapN:
 1352     case Op_ShenandoahCompareAndExchangeP:
 1353     case Op_ShenandoahCompareAndExchangeN:
 1354       return maybe_volatile;
 1355     default:
 1356       return false;
 1357     }
 1358   }
 1359 
 1360   // helper to determine the maximum number of Phi nodes we may need to
 1361   // traverse when searching from a card mark membar for the merge mem
 1362   // feeding a trailing membar or vice versa
 1363 
 1364 // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt;
 1365 
 1366 bool unnecessary_acquire(const Node *barrier)
 1367 {
 1368   assert(barrier-&gt;is_MemBar(), &quot;expecting a membar&quot;);
 1369 
 1370   MemBarNode* mb = barrier-&gt;as_MemBar();
 1371 
 1372   if (mb-&gt;trailing_load()) {
 1373     return true;
 1374   }
 1375 
 1376   if (mb-&gt;trailing_load_store()) {
 1377     Node* load_store = mb-&gt;in(MemBarNode::Precedent);
 1378     assert(load_store-&gt;is_LoadStore(), &quot;unexpected graph shape&quot;);
 1379     return is_CAS(load_store-&gt;Opcode(), true);
 1380   }
 1381 
 1382   return false;
 1383 }
 1384 
 1385 bool needs_acquiring_load(const Node *n)
 1386 {
 1387   assert(n-&gt;is_Load(), &quot;expecting a load&quot;);
 1388   LoadNode *ld = n-&gt;as_Load();
 1389   return ld-&gt;is_acquire();
 1390 }
 1391 
 1392 bool unnecessary_release(const Node *n)
 1393 {
 1394   assert((n-&gt;is_MemBar() &amp;&amp;
 1395           n-&gt;Opcode() == Op_MemBarRelease),
 1396          &quot;expecting a release membar&quot;);
 1397 
 1398   MemBarNode *barrier = n-&gt;as_MemBar();
 1399   if (!barrier-&gt;leading()) {
 1400     return false;
 1401   } else {
 1402     Node* trailing = barrier-&gt;trailing_membar();
 1403     MemBarNode* trailing_mb = trailing-&gt;as_MemBar();
 1404     assert(trailing_mb-&gt;trailing(), &quot;Not a trailing membar?&quot;);
 1405     assert(trailing_mb-&gt;leading_membar() == n, &quot;inconsistent leading/trailing membars&quot;);
 1406 
 1407     Node* mem = trailing_mb-&gt;in(MemBarNode::Precedent);
 1408     if (mem-&gt;is_Store()) {
 1409       assert(mem-&gt;as_Store()-&gt;is_release(), &quot;&quot;);
 1410       assert(trailing_mb-&gt;Opcode() == Op_MemBarVolatile, &quot;&quot;);
 1411       return true;
 1412     } else {
 1413       assert(mem-&gt;is_LoadStore(), &quot;&quot;);
 1414       assert(trailing_mb-&gt;Opcode() == Op_MemBarAcquire, &quot;&quot;);
 1415       return is_CAS(mem-&gt;Opcode(), true);
 1416     }
 1417   }
 1418   return false;
 1419 }
 1420 
 1421 bool unnecessary_volatile(const Node *n)
 1422 {
 1423   // assert n-&gt;is_MemBar();
 1424   MemBarNode *mbvol = n-&gt;as_MemBar();
 1425 
 1426   bool release = mbvol-&gt;trailing_store();
 1427   assert(!release || (mbvol-&gt;in(MemBarNode::Precedent)-&gt;is_Store() &amp;&amp; mbvol-&gt;in(MemBarNode::Precedent)-&gt;as_Store()-&gt;is_release()), &quot;&quot;);
 1428 #ifdef ASSERT
 1429   if (release) {
 1430     Node* leading = mbvol-&gt;leading_membar();
 1431     assert(leading-&gt;Opcode() == Op_MemBarRelease, &quot;&quot;);
 1432     assert(leading-&gt;as_MemBar()-&gt;leading_store(), &quot;&quot;);
 1433     assert(leading-&gt;as_MemBar()-&gt;trailing_membar() == mbvol, &quot;&quot;);
 1434   }
 1435 #endif
 1436 
 1437   return release;
 1438 }
 1439 
 1440 // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt;
 1441 
 1442 bool needs_releasing_store(const Node *n)
 1443 {
 1444   // assert n-&gt;is_Store();
 1445   StoreNode *st = n-&gt;as_Store();
 1446   return st-&gt;trailing_membar() != NULL;
 1447 }
 1448 
 1449 // predicate controlling translation of CAS
 1450 //
 1451 // returns true if CAS needs to use an acquiring load otherwise false
 1452 
 1453 bool needs_acquiring_load_exclusive(const Node *n)
 1454 {
 1455   assert(is_CAS(n-&gt;Opcode(), true), &quot;expecting a compare and swap&quot;);
 1456   LoadStoreNode* ldst = n-&gt;as_LoadStore();
 1457   if (is_CAS(n-&gt;Opcode(), false)) {
 1458     assert(ldst-&gt;trailing_membar() != NULL, &quot;expected trailing membar&quot;);
 1459   } else {
 1460     return ldst-&gt;trailing_membar() != NULL;
 1461   }
 1462 
 1463   // so we can just return true here
 1464   return true;
 1465 }
 1466 
 1467 #define __ _masm.
 1468 
 1469 // advance declarations for helper functions to convert register
 1470 // indices to register objects
 1471 
 1472 // the ad file has to provide implementations of certain methods
 1473 // expected by the generic code
 1474 //
 1475 // REQUIRED FUNCTIONALITY
 1476 
 1477 //=============================================================================
 1478 
 1479 // !!!!! Special hack to get all types of calls to specify the byte offset
 1480 //       from the start of the call to the point where the return address
 1481 //       will point.
 1482 
 1483 int MachCallStaticJavaNode::ret_addr_offset()
 1484 {
 1485   // call should be a simple bl
 1486   int off = 4;
 1487   return off;
 1488 }
 1489 
 1490 int MachCallDynamicJavaNode::ret_addr_offset()
 1491 {
 1492   return 16; // movz, movk, movk, bl
 1493 }
 1494 
 1495 int MachCallRuntimeNode::ret_addr_offset() {
 1496   // for generated stubs the call will be
 1497   //   far_call(addr)
 1498   // for real runtime callouts it will be six instructions
 1499   // see aarch64_enc_java_to_runtime
 1500   //   adr(rscratch2, retaddr)
 1501   //   lea(rscratch1, RuntimeAddress(addr)
 1502   //   stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)))
 1503   //   blr(rscratch1)
 1504   CodeBlob *cb = CodeCache::find_blob(_entry_point);
 1505   if (cb) {
 1506     return MacroAssembler::far_branch_size();
 1507   } else {
 1508     return 6 * NativeInstruction::instruction_size;
 1509   }
 1510 }
 1511 
 1512 int MachCallNativeNode::ret_addr_offset() {
 1513   ShouldNotReachHere();
 1514   return -1;
 1515 }
 1516 
 1517 // Indicate if the safepoint node needs the polling page as an input
 1518 
 1519 // the shared code plants the oop data at the start of the generated
 1520 // code for the safepoint node and that needs ot be at the load
 1521 // instruction itself. so we cannot plant a mov of the safepoint poll
 1522 // address followed by a load. setting this to true means the mov is
 1523 // scheduled as a prior instruction. that&#39;s better for scheduling
 1524 // anyway.
 1525 
 1526 bool SafePointNode::needs_polling_address_input()
 1527 {
 1528   return true;
 1529 }
 1530 
 1531 //=============================================================================
 1532 
 1533 #ifndef PRODUCT
 1534 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1535   st-&gt;print(&quot;BREAKPOINT&quot;);
 1536 }
 1537 #endif
 1538 
 1539 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1540   C2_MacroAssembler _masm(&amp;cbuf);
 1541   __ brk(0);
 1542 }
 1543 
 1544 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
 1545   return MachNode::size(ra_);
 1546 }
 1547 
 1548 //=============================================================================
 1549 
 1550 #ifndef PRODUCT
 1551   void MachNopNode::format(PhaseRegAlloc*, outputStream* st) const {
 1552     st-&gt;print(&quot;nop \t# %d bytes pad for loops and calls&quot;, _count);
 1553   }
 1554 #endif
 1555 
 1556   void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc*) const {
 1557     C2_MacroAssembler _masm(&amp;cbuf);
 1558     for (int i = 0; i &lt; _count; i++) {
 1559       __ nop();
 1560     }
 1561   }
 1562 
 1563   uint MachNopNode::size(PhaseRegAlloc*) const {
 1564     return _count * NativeInstruction::instruction_size;
 1565   }
 1566 
 1567 //=============================================================================
 1568 const RegMask&amp; MachConstantBaseNode::_out_RegMask = RegMask::Empty;
 1569 
 1570 int ConstantTable::calculate_table_base_offset() const {
 1571   return 0;  // absolute addressing, no offset
 1572 }
 1573 
 1574 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
 1575 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1576   ShouldNotReachHere();
 1577 }
 1578 
 1579 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1580   // Empty encoding
 1581 }
 1582 
 1583 uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
 1584   return 0;
 1585 }
 1586 
 1587 #ifndef PRODUCT
 1588 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1589   st-&gt;print(&quot;-- \t// MachConstantBaseNode (empty encoding)&quot;);
 1590 }
 1591 #endif
 1592 
 1593 #ifndef PRODUCT
 1594 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1595   Compile* C = ra_-&gt;C;
 1596 
 1597   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1598 
 1599   if (C-&gt;output()-&gt;need_stack_bang(framesize))
 1600     st-&gt;print(&quot;# stack bang size=%d\n\t&quot;, framesize);
 1601 
 1602   if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1603     st-&gt;print(&quot;sub  sp, sp, #%d\n\t&quot;, framesize);
 1604     st-&gt;print(&quot;stp  rfp, lr, [sp, #%d]&quot;, framesize - 2 * wordSize);
 1605     if (PreserveFramePointer) st-&gt;print(&quot;\n\tadd  rfp, sp, #%d&quot;, framesize - 2 * wordSize);
 1606   } else {
 1607     st-&gt;print(&quot;stp  lr, rfp, [sp, #%d]!\n\t&quot;, -(2 * wordSize));
 1608     if (PreserveFramePointer) st-&gt;print(&quot;mov  rfp, sp\n\t&quot;);
 1609     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1610     st-&gt;print(&quot;sub  sp, sp, rscratch1&quot;);
 1611   }
 1612   if (C-&gt;stub_function() == NULL &amp;&amp; BarrierSet::barrier_set()-&gt;barrier_set_nmethod() != NULL) {
 1613     st-&gt;print(&quot;\n\t&quot;);
 1614     st-&gt;print(&quot;ldr  rscratch1, [guard]\n\t&quot;);
 1615     st-&gt;print(&quot;dmb ishld\n\t&quot;);
 1616     st-&gt;print(&quot;ldr  rscratch2, [rthread, #thread_disarmed_offset]\n\t&quot;);
 1617     st-&gt;print(&quot;cmp  rscratch1, rscratch2\n\t&quot;);
 1618     st-&gt;print(&quot;b.eq skip&quot;);
 1619     st-&gt;print(&quot;\n\t&quot;);
 1620     st-&gt;print(&quot;blr #nmethod_entry_barrier_stub\n\t&quot;);
 1621     st-&gt;print(&quot;b skip\n\t&quot;);
 1622     st-&gt;print(&quot;guard: int\n\t&quot;);
 1623     st-&gt;print(&quot;\n\t&quot;);
 1624     st-&gt;print(&quot;skip:\n\t&quot;);
 1625   }
 1626 }
 1627 #endif
 1628 
 1629 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1630   Compile* C = ra_-&gt;C;
 1631   C2_MacroAssembler _masm(&amp;cbuf);
 1632 
 1633   // n.b. frame size includes space for return pc and rfp
 1634   const int framesize = C-&gt;output()-&gt;frame_size_in_bytes();
 1635   assert(framesize%(2*wordSize) == 0, &quot;must preserve 2*wordSize alignment&quot;);
 1636 
 1637   // insert a nop at the start of the prolog so we can patch in a
 1638   // branch if we need to invalidate the method later
 1639   __ nop();
 1640 
 1641   if (C-&gt;clinit_barrier_on_entry()) {
 1642     assert(!C-&gt;method()-&gt;holder()-&gt;is_not_initialized(), &quot;initialization should have been started&quot;);
 1643 
 1644     Label L_skip_barrier;
 1645 
 1646     __ mov_metadata(rscratch2, C-&gt;method()-&gt;holder()-&gt;constant_encoding());
 1647     __ clinit_barrier(rscratch2, rscratch1, &amp;L_skip_barrier);
 1648     __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));
 1649     __ bind(L_skip_barrier);
 1650   }
 1651 
 1652   int bangsize = C-&gt;output()-&gt;bang_size_in_bytes();
 1653   if (C-&gt;output()-&gt;need_stack_bang(bangsize) &amp;&amp; UseStackBanging)
 1654     __ generate_stack_overflow_check(bangsize);
 1655 
 1656   __ build_frame(framesize);
 1657 
 1658   if (C-&gt;stub_function() == NULL) {
 1659     BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
 1660     bs-&gt;nmethod_entry_barrier(&amp;_masm);
 1661   }
 1662 
 1663   if (VerifyStackAtCalls) {
 1664     Unimplemented();
 1665   }
 1666 
 1667   C-&gt;output()-&gt;set_frame_complete(cbuf.insts_size());
 1668 
 1669   if (C-&gt;has_mach_constant_base_node()) {
 1670     // NOTE: We set the table base offset here because users might be
 1671     // emitted before MachConstantBaseNode.
 1672     ConstantTable&amp; constant_table = C-&gt;output()-&gt;constant_table();
 1673     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
 1674   }
 1675 }
 1676 
 1677 uint MachPrologNode::size(PhaseRegAlloc* ra_) const
 1678 {
 1679   return MachNode::size(ra_); // too many variables; just compute it
 1680                               // the hard way
 1681 }
 1682 
 1683 int MachPrologNode::reloc() const
 1684 {
 1685   return 0;
 1686 }
 1687 
 1688 //=============================================================================
 1689 
 1690 #ifndef PRODUCT
 1691 void MachEpilogNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1692   Compile* C = ra_-&gt;C;
 1693   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1694 
 1695   st-&gt;print(&quot;# pop frame %d\n\t&quot;,framesize);
 1696 
 1697   if (framesize == 0) {
 1698     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1699   } else if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1700     st-&gt;print(&quot;ldp  lr, rfp, [sp,#%d]\n\t&quot;, framesize - 2 * wordSize);
 1701     st-&gt;print(&quot;add  sp, sp, #%d\n\t&quot;, framesize);
 1702   } else {
 1703     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1704     st-&gt;print(&quot;add  sp, sp, rscratch1\n\t&quot;);
 1705     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1706   }
 1707 
 1708   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1709     st-&gt;print(&quot;# touch polling page\n\t&quot;);
 1710     st-&gt;print(&quot;ldr rscratch1, [rthread],#polling_page_offset\n\t&quot;);
 1711     st-&gt;print(&quot;ldr zr, [rscratch1]&quot;);
 1712   }
 1713 }
 1714 #endif
 1715 
 1716 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1717   Compile* C = ra_-&gt;C;
 1718   C2_MacroAssembler _masm(&amp;cbuf);
 1719   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1720 
 1721   __ remove_frame(framesize);
 1722 
 1723   if (StackReservedPages &gt; 0 &amp;&amp; C-&gt;has_reserved_stack_access()) {
 1724     __ reserved_stack_check();
 1725   }
 1726 
 1727   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1728     __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);
 1729   }
 1730 }
 1731 
 1732 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
 1733   // Variable size. Determine dynamically.
 1734   return MachNode::size(ra_);
 1735 }
 1736 
 1737 int MachEpilogNode::reloc() const {
 1738   // Return number of relocatable values contained in this instruction.
 1739   return 1; // 1 for polling page.
 1740 }
 1741 
 1742 const Pipeline * MachEpilogNode::pipeline() const {
 1743   return MachNode::pipeline_class();
 1744 }
 1745 
 1746 //=============================================================================
 1747 
 1748 // Figure out which register class each belongs in: rc_int, rc_float or
 1749 // rc_stack.
 1750 enum RC { rc_bad, rc_int, rc_float, rc_stack };
 1751 
 1752 static enum RC rc_class(OptoReg::Name reg) {
 1753 
 1754   if (reg == OptoReg::Bad) {
 1755     return rc_bad;
 1756   }
 1757 
 1758   // we have 30 int registers * 2 halves
 1759   // (rscratch1 and rscratch2 are omitted)
 1760   int slots_of_int_registers = RegisterImpl::max_slots_per_register * (RegisterImpl::number_of_registers - 2);
 1761 
 1762   if (reg &lt; slots_of_int_registers) {
 1763     return rc_int;
 1764   }
 1765 
 1766   // we have 32 float register * 4 halves
 1767   if (reg &lt; slots_of_int_registers + FloatRegisterImpl::max_slots_per_register * FloatRegisterImpl::number_of_registers) {
 1768     return rc_float;
 1769   }
 1770 
 1771   // Between float regs &amp; stack is the flags regs.
 1772   assert(OptoReg::is_stack(reg), &quot;blow up if spilling flags&quot;);
 1773 
 1774   return rc_stack;
 1775 }
 1776 
 1777 uint MachSpillCopyNode::implementation(CodeBuffer *cbuf, PhaseRegAlloc *ra_, bool do_size, outputStream *st) const {
 1778   Compile* C = ra_-&gt;C;
 1779 
 1780   // Get registers to move.
 1781   OptoReg::Name src_hi = ra_-&gt;get_reg_second(in(1));
 1782   OptoReg::Name src_lo = ra_-&gt;get_reg_first(in(1));
 1783   OptoReg::Name dst_hi = ra_-&gt;get_reg_second(this);
 1784   OptoReg::Name dst_lo = ra_-&gt;get_reg_first(this);
 1785 
 1786   enum RC src_hi_rc = rc_class(src_hi);
 1787   enum RC src_lo_rc = rc_class(src_lo);
 1788   enum RC dst_hi_rc = rc_class(dst_hi);
 1789   enum RC dst_lo_rc = rc_class(dst_lo);
 1790 
 1791   assert(src_lo != OptoReg::Bad &amp;&amp; dst_lo != OptoReg::Bad, &quot;must move at least 1 register&quot;);
 1792 
 1793   if (src_hi != OptoReg::Bad) {
 1794     assert((src_lo&amp;1)==0 &amp;&amp; src_lo+1==src_hi &amp;&amp;
 1795            (dst_lo&amp;1)==0 &amp;&amp; dst_lo+1==dst_hi,
 1796            &quot;expected aligned-adjacent pairs&quot;);
 1797   }
 1798 
 1799   if (src_lo == dst_lo &amp;&amp; src_hi == dst_hi) {
 1800     return 0;            // Self copy, no move.
 1801   }
 1802 
 1803   bool is64 = (src_lo &amp; 1) == 0 &amp;&amp; src_lo + 1 == src_hi &amp;&amp;
 1804               (dst_lo &amp; 1) == 0 &amp;&amp; dst_lo + 1 == dst_hi;
 1805   int src_offset = ra_-&gt;reg2offset(src_lo);
 1806   int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1807 
 1808   if (bottom_type()-&gt;isa_vect() != NULL) {
 1809     uint ireg = ideal_reg();
 1810     assert(ireg == Op_VecD || ireg == Op_VecX, &quot;must be 64 bit or 128 bit vector&quot;);
 1811     if (cbuf) {
 1812       C2_MacroAssembler _masm(cbuf);
 1813       assert((src_lo_rc != rc_int &amp;&amp; dst_lo_rc != rc_int), &quot;sanity&quot;);
 1814       if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1815         // stack-&gt;stack
 1816         assert((src_offset &amp; 7) == 0 &amp;&amp; (dst_offset &amp; 7) == 0, &quot;unaligned stack offset&quot;);
 1817         if (ireg == Op_VecD) {
 1818           __ unspill(rscratch1, true, src_offset);
 1819           __ spill(rscratch1, true, dst_offset);
 1820         } else {
 1821           __ spill_copy128(src_offset, dst_offset);
 1822         }
 1823       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_float) {
 1824         __ mov(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1825                ireg == Op_VecD ? __ T8B : __ T16B,
 1826                as_FloatRegister(Matcher::_regEncode[src_lo]));
 1827       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_stack) {
 1828         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1829                        ireg == Op_VecD ? __ D : __ Q,
 1830                        ra_-&gt;reg2offset(dst_lo));
 1831       } else if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_float) {
 1832         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1833                        ireg == Op_VecD ? __ D : __ Q,
 1834                        ra_-&gt;reg2offset(src_lo));
 1835       } else {
 1836         ShouldNotReachHere();
 1837       }
 1838     }
 1839   } else if (cbuf) {
 1840     C2_MacroAssembler _masm(cbuf);
 1841     switch (src_lo_rc) {
 1842     case rc_int:
 1843       if (dst_lo_rc == rc_int) {  // gpr --&gt; gpr copy
 1844         if (is64) {
 1845             __ mov(as_Register(Matcher::_regEncode[dst_lo]),
 1846                    as_Register(Matcher::_regEncode[src_lo]));
 1847         } else {
 1848             C2_MacroAssembler _masm(cbuf);
 1849             __ movw(as_Register(Matcher::_regEncode[dst_lo]),
 1850                     as_Register(Matcher::_regEncode[src_lo]));
 1851         }
 1852       } else if (dst_lo_rc == rc_float) { // gpr --&gt; fpr copy
 1853         if (is64) {
 1854             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1855                      as_Register(Matcher::_regEncode[src_lo]));
 1856         } else {
 1857             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1858                      as_Register(Matcher::_regEncode[src_lo]));
 1859         }
 1860       } else {                    // gpr --&gt; stack spill
 1861         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1862         __ spill(as_Register(Matcher::_regEncode[src_lo]), is64, dst_offset);
 1863       }
 1864       break;
 1865     case rc_float:
 1866       if (dst_lo_rc == rc_int) {  // fpr --&gt; gpr copy
 1867         if (is64) {
 1868             __ fmovd(as_Register(Matcher::_regEncode[dst_lo]),
 1869                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1870         } else {
 1871             __ fmovs(as_Register(Matcher::_regEncode[dst_lo]),
 1872                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1873         }
 1874       } else if (dst_lo_rc == rc_float) { // fpr --&gt; fpr copy
 1875           if (cbuf) {
 1876             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1877                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1878         } else {
 1879             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1880                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1881         }
 1882       } else {                    // fpr --&gt; stack spill
 1883         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1884         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1885                  is64 ? __ D : __ S, dst_offset);
 1886       }
 1887       break;
 1888     case rc_stack:
 1889       if (dst_lo_rc == rc_int) {  // stack --&gt; gpr load
 1890         __ unspill(as_Register(Matcher::_regEncode[dst_lo]), is64, src_offset);
 1891       } else if (dst_lo_rc == rc_float) { // stack --&gt; fpr load
 1892         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1893                    is64 ? __ D : __ S, src_offset);
 1894       } else {                    // stack --&gt; stack copy
 1895         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1896         __ unspill(rscratch1, is64, src_offset);
 1897         __ spill(rscratch1, is64, dst_offset);
 1898       }
 1899       break;
 1900     default:
 1901       assert(false, &quot;bad rc_class for spill&quot;);
 1902       ShouldNotReachHere();
 1903     }
 1904   }
 1905 
 1906   if (st) {
 1907     st-&gt;print(&quot;spill &quot;);
 1908     if (src_lo_rc == rc_stack) {
 1909       st-&gt;print(&quot;[sp, #%d] -&gt; &quot;, ra_-&gt;reg2offset(src_lo));
 1910     } else {
 1911       st-&gt;print(&quot;%s -&gt; &quot;, Matcher::regName[src_lo]);
 1912     }
 1913     if (dst_lo_rc == rc_stack) {
 1914       st-&gt;print(&quot;[sp, #%d]&quot;, ra_-&gt;reg2offset(dst_lo));
 1915     } else {
 1916       st-&gt;print(&quot;%s&quot;, Matcher::regName[dst_lo]);
 1917     }
 1918     if (bottom_type()-&gt;isa_vect() != NULL) {
 1919       st-&gt;print(&quot;\t# vector spill size = %d&quot;, ideal_reg()==Op_VecD ? 64:128);
 1920     } else {
 1921       st-&gt;print(&quot;\t# spill size = %d&quot;, is64 ? 64:32);
 1922     }
 1923   }
 1924 
 1925   return 0;
 1926 
 1927 }
 1928 
 1929 #ifndef PRODUCT
 1930 void MachSpillCopyNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1931   if (!ra_)
 1932     st-&gt;print(&quot;N%d = SpillCopy(N%d)&quot;, _idx, in(1)-&gt;_idx);
 1933   else
 1934     implementation(NULL, ra_, false, st);
 1935 }
 1936 #endif
 1937 
 1938 void MachSpillCopyNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1939   implementation(&amp;cbuf, ra_, false, NULL);
 1940 }
 1941 
 1942 uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
 1943   return MachNode::size(ra_);
 1944 }
 1945 
 1946 //=============================================================================
 1947 
 1948 #ifndef PRODUCT
 1949 void BoxLockNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1950   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1951   int reg = ra_-&gt;get_reg_first(this);
 1952   st-&gt;print(&quot;add %s, rsp, #%d]\t# box lock&quot;,
 1953             Matcher::regName[reg], offset);
 1954 }
 1955 #endif
 1956 
 1957 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1958   C2_MacroAssembler _masm(&amp;cbuf);
 1959 
 1960   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1961   int reg    = ra_-&gt;get_encode(this);
 1962 
 1963   // This add will handle any 24-bit signed offset. 24 bits allows an
 1964   // 8 megabyte stack frame.
 1965   __ add(as_Register(reg), sp, offset);
 1966 }
 1967 
 1968 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 1969   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_).
 1970   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1971 
 1972   if (Assembler::operand_valid_for_add_sub_immediate(offset)) {
 1973     return NativeInstruction::instruction_size;
 1974   } else {
 1975     return 2 * NativeInstruction::instruction_size;
 1976   }
 1977 }
 1978 
 1979 //=============================================================================
 1980 
 1981 #ifndef PRODUCT
 1982 void MachUEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 1983 {
 1984   st-&gt;print_cr(&quot;# MachUEPNode&quot;);
 1985   if (UseCompressedClassPointers) {
 1986     st-&gt;print_cr(&quot;\tldrw rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1987     if (CompressedKlassPointers::shift() != 0) {
 1988       st-&gt;print_cr(&quot;\tdecode_klass_not_null rscratch1, rscratch1&quot;);
 1989     }
 1990   } else {
 1991    st-&gt;print_cr(&quot;\tldr rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1992   }
 1993   st-&gt;print_cr(&quot;\tcmp r0, rscratch1\t # Inline cache check&quot;);
 1994   st-&gt;print_cr(&quot;\tbne, SharedRuntime::_ic_miss_stub&quot;);
 1995 }
 1996 #endif
 1997 
 1998 void MachUEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 1999 {
 2000   // This is the unverified entry point.
 2001   C2_MacroAssembler _masm(&amp;cbuf);
 2002 
 2003   __ cmp_klass(j_rarg0, rscratch2, rscratch1);
 2004   Label skip;
 2005   // TODO
 2006   // can we avoid this skip and still use a reloc?
 2007   __ br(Assembler::EQ, skip);
 2008   __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 2009   __ bind(skip);
 2010 }
 2011 
 2012 uint MachUEPNode::size(PhaseRegAlloc* ra_) const
 2013 {
 2014   return MachNode::size(ra_);
 2015 }
 2016 
 2017 // REQUIRED EMIT CODE
 2018 
 2019 //=============================================================================
 2020 
 2021 // Emit exception handler code.
 2022 int HandlerImpl::emit_exception_handler(CodeBuffer&amp; cbuf)
 2023 {
 2024   // mov rscratch1 #exception_blob_entry_point
 2025   // br rscratch1
 2026   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2027   // That&#39;s why we must use the macroassembler to generate a handler.
 2028   C2_MacroAssembler _masm(&amp;cbuf);
 2029   address base = __ start_a_stub(size_exception_handler());
 2030   if (base == NULL) {
 2031     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2032     return 0;  // CodeBuffer::expand failed
 2033   }
 2034   int offset = __ offset();
 2035   __ far_jump(RuntimeAddress(OptoRuntime::exception_blob()-&gt;entry_point()));
 2036   assert(__ offset() - offset &lt;= (int) size_exception_handler(), &quot;overflow&quot;);
 2037   __ end_a_stub();
 2038   return offset;
 2039 }
 2040 
 2041 // Emit deopt handler code.
 2042 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf)
 2043 {
 2044   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2045   // That&#39;s why we must use the macroassembler to generate a handler.
 2046   C2_MacroAssembler _masm(&amp;cbuf);
 2047   address base = __ start_a_stub(size_deopt_handler());
 2048   if (base == NULL) {
 2049     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2050     return 0;  // CodeBuffer::expand failed
 2051   }
 2052   int offset = __ offset();
 2053 
 2054   __ adr(lr, __ pc());
 2055   __ far_jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 2056 
 2057   assert(__ offset() - offset &lt;= (int) size_deopt_handler(), &quot;overflow&quot;);
 2058   __ end_a_stub();
 2059   return offset;
 2060 }
 2061 
 2062 // REQUIRED MATCHER CODE
 2063 
 2064 //=============================================================================
 2065 
 2066 const bool Matcher::match_rule_supported(int opcode) {
 2067   if (!has_match_rule(opcode))
 2068     return false;
 2069 
 2070   bool ret_value = true;
 2071   switch (opcode) {
 2072     case Op_CacheWB:
 2073     case Op_CacheWBPreSync:
 2074     case Op_CacheWBPostSync:
 2075       if (!VM_Version::supports_data_cache_line_flush()) {
 2076         ret_value = false;
 2077       }
 2078       break;
 2079   }
 2080 
 2081   return ret_value; // Per default match rules are supported.
 2082 }
 2083 
 2084 // Identify extra cases that we might want to provide match rules for vector nodes and
 2085 // other intrinsics guarded with vector length (vlen) and element type (bt).
 2086 const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {
 2087   if (!match_rule_supported(opcode)) {
 2088     return false;
 2089   }
 2090 
 2091   // Special cases which require vector length
 2092   switch (opcode) {
 2093     case Op_MulAddVS2VI: {
 2094       if (vlen != 4) {
 2095         return false;
 2096       }
 2097       break;
 2098     }
 2099   }
 2100 
 2101   return true; // Per default match rules are supported.
 2102 }
 2103 
 2104 const bool Matcher::has_predicated_vectors(void) {
 2105   return false;
 2106 }
 2107 
 2108 const int Matcher::float_pressure(int default_pressure_threshold) {
 2109   return default_pressure_threshold;
 2110 }
 2111 
 2112 int Matcher::regnum_to_fpu_offset(int regnum)
 2113 {
 2114   Unimplemented();
 2115   return 0;
 2116 }
 2117 
 2118 // Is this branch offset short enough that a short branch can be used?
 2119 //
 2120 // NOTE: If the platform does not provide any short branch variants, then
 2121 //       this method should return false for offset 0.
 2122 bool Matcher::is_short_branch_offset(int rule, int br_size, int offset) {
 2123   // The passed offset is relative to address of the branch.
 2124 
 2125   return (-32768 &lt;= offset &amp;&amp; offset &lt; 32768);
 2126 }
 2127 
 2128 const bool Matcher::isSimpleConstant64(jlong value) {
 2129   // Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.
 2130   // Probably always true, even if a temp register is required.
 2131   return true;
 2132 }
 2133 
 2134 // true just means we have fast l2f conversion
 2135 const bool Matcher::convL2FSupported(void) {
 2136   return true;
 2137 }
 2138 
 2139 // Vector width in bytes.
 2140 const int Matcher::vector_width_in_bytes(BasicType bt) {
 2141   int size = MIN2(16,(int)MaxVectorSize);
 2142   // Minimum 2 values in vector
 2143   if (size &lt; 2*type2aelembytes(bt)) size = 0;
 2144   // But never &lt; 4
 2145   if (size &lt; 4) size = 0;
 2146   return size;
 2147 }
 2148 
 2149 // Limits on vector size (number of elements) loaded into vector.
 2150 const int Matcher::max_vector_size(const BasicType bt) {
 2151   return vector_width_in_bytes(bt)/type2aelembytes(bt);
 2152 }
 2153 const int Matcher::min_vector_size(const BasicType bt) {
 2154 //  For the moment limit the vector size to 8 bytes
 2155     int size = 8 / type2aelembytes(bt);
 2156     if (size &lt; 2) size = 2;
 2157     return size;
 2158 }
 2159 
 2160 // Vector ideal reg.
 2161 const uint Matcher::vector_ideal_reg(int len) {
 2162   switch(len) {
 2163     case  8: return Op_VecD;
 2164     case 16: return Op_VecX;
 2165   }
 2166   ShouldNotReachHere();
 2167   return 0;
 2168 }
 2169 
 2170 // AES support not yet implemented
 2171 const bool Matcher::pass_original_key_for_aes() {
 2172   return false;
 2173 }
 2174 
 2175 // aarch64 supports misaligned vectors store/load.
 2176 const bool Matcher::misaligned_vectors_ok() {
 2177   return true;
 2178 }
 2179 
 2180 // false =&gt; size gets scaled to BytesPerLong, ok.
 2181 const bool Matcher::init_array_count_is_in_bytes = false;
 2182 
 2183 // Use conditional move (CMOVL)
 2184 const int Matcher::long_cmove_cost() {
 2185   // long cmoves are no more expensive than int cmoves
 2186   return 0;
 2187 }
 2188 
 2189 const int Matcher::float_cmove_cost() {
 2190   // float cmoves are no more expensive than int cmoves
 2191   return 0;
 2192 }
 2193 
 2194 // Does the CPU require late expand (see block.cpp for description of late expand)?
 2195 const bool Matcher::require_postalloc_expand = false;
 2196 
 2197 // Do we need to mask the count passed to shift instructions or does
 2198 // the cpu only look at the lower 5/6 bits anyway?
 2199 const bool Matcher::need_masked_shift_count = false;
 2200 
 2201 // No support for generic vector operands.
 2202 const bool Matcher::supports_generic_vector_operands  = false;
 2203 
 2204 MachOper* Matcher::pd_specialize_generic_vector_operand(MachOper* original_opnd, uint ideal_reg, bool is_temp) {
 2205   ShouldNotReachHere(); // generic vector operands not supported
 2206   return NULL;
 2207 }
 2208 
 2209 bool Matcher::is_generic_reg2reg_move(MachNode* m) {
 2210   ShouldNotReachHere();  // generic vector operands not supported
 2211   return false;
 2212 }
 2213 
 2214 bool Matcher::is_generic_vector(MachOper* opnd)  {
 2215   ShouldNotReachHere();  // generic vector operands not supported
 2216   return false;
 2217 }
 2218 
 2219 // This affects two different things:
 2220 //  - how Decode nodes are matched
 2221 //  - how ImplicitNullCheck opportunities are recognized
 2222 // If true, the matcher will try to remove all Decodes and match them
 2223 // (as operands) into nodes. NullChecks are not prepared to deal with
 2224 // Decodes by final_graph_reshaping().
 2225 // If false, final_graph_reshaping() forces the decode behind the Cmp
 2226 // for a NullCheck. The matcher matches the Decode node into a register.
 2227 // Implicit_null_check optimization moves the Decode along with the
 2228 // memory operation back up before the NullCheck.
 2229 bool Matcher::narrow_oop_use_complex_address() {
 2230   return CompressedOops::shift() == 0;
 2231 }
 2232 
 2233 bool Matcher::narrow_klass_use_complex_address() {
 2234 // TODO
 2235 // decide whether we need to set this to true
 2236   return false;
 2237 }
 2238 
 2239 bool Matcher::const_oop_prefer_decode() {
 2240   // Prefer ConN+DecodeN over ConP in simple compressed oops mode.
 2241   return CompressedOops::base() == NULL;
 2242 }
 2243 
 2244 bool Matcher::const_klass_prefer_decode() {
 2245   // Prefer ConNKlass+DecodeNKlass over ConP in simple compressed klass mode.
 2246   return CompressedKlassPointers::base() == NULL;
 2247 }
 2248 
 2249 // Is it better to copy float constants, or load them directly from
 2250 // memory?  Intel can load a float constant from a direct address,
 2251 // requiring no extra registers.  Most RISCs will have to materialize
 2252 // an address into a register first, so they would do better to copy
 2253 // the constant from stack.
 2254 const bool Matcher::rematerialize_float_constants = false;
 2255 
 2256 // If CPU can load and store mis-aligned doubles directly then no
 2257 // fixup is needed.  Else we split the double into 2 integer pieces
 2258 // and move it piece-by-piece.  Only happens when passing doubles into
 2259 // C code as the Java calling convention forces doubles to be aligned.
 2260 const bool Matcher::misaligned_doubles_ok = true;
 2261 
 2262 // No-op on amd64
 2263 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 2264   Unimplemented();
 2265 }
 2266 
 2267 // Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.
 2268 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 2269 
 2270 // Are floats converted to double when stored to stack during
 2271 // deoptimization?
 2272 bool Matcher::float_in_double() { return false; }
 2273 
 2274 // Do ints take an entire long register or just half?
 2275 // The relevant question is how the int is callee-saved:
 2276 // the whole long is written but de-opt&#39;ing will have to extract
 2277 // the relevant 32 bits.
 2278 const bool Matcher::int_in_long = true;
 2279 
 2280 // Return whether or not this register is ever used as an argument.
 2281 // This function is used on startup to build the trampoline stubs in
 2282 // generateOptoStub.  Registers not mentioned will be killed by the VM
 2283 // call in the trampoline, and arguments in those registers not be
 2284 // available to the callee.
 2285 bool Matcher::can_be_java_arg(int reg)
 2286 {
 2287   return
 2288     reg ==  R0_num || reg == R0_H_num ||
 2289     reg ==  R1_num || reg == R1_H_num ||
 2290     reg ==  R2_num || reg == R2_H_num ||
 2291     reg ==  R3_num || reg == R3_H_num ||
 2292     reg ==  R4_num || reg == R4_H_num ||
 2293     reg ==  R5_num || reg == R5_H_num ||
 2294     reg ==  R6_num || reg == R6_H_num ||
 2295     reg ==  R7_num || reg == R7_H_num ||
 2296     reg ==  V0_num || reg == V0_H_num ||
 2297     reg ==  V1_num || reg == V1_H_num ||
 2298     reg ==  V2_num || reg == V2_H_num ||
 2299     reg ==  V3_num || reg == V3_H_num ||
 2300     reg ==  V4_num || reg == V4_H_num ||
 2301     reg ==  V5_num || reg == V5_H_num ||
 2302     reg ==  V6_num || reg == V6_H_num ||
 2303     reg ==  V7_num || reg == V7_H_num;
 2304 }
 2305 
 2306 bool Matcher::is_spillable_arg(int reg)
 2307 {
 2308   return can_be_java_arg(reg);
 2309 }
 2310 
 2311 bool Matcher::use_asm_for_ldiv_by_con(jlong divisor) {
 2312   return false;
 2313 }
 2314 
 2315 RegMask Matcher::divI_proj_mask() {
 2316   ShouldNotReachHere();
 2317   return RegMask();
 2318 }
 2319 
 2320 // Register for MODI projection of divmodI.
 2321 RegMask Matcher::modI_proj_mask() {
 2322   ShouldNotReachHere();
 2323   return RegMask();
 2324 }
 2325 
 2326 // Register for DIVL projection of divmodL.
 2327 RegMask Matcher::divL_proj_mask() {
 2328   ShouldNotReachHere();
 2329   return RegMask();
 2330 }
 2331 
 2332 // Register for MODL projection of divmodL.
 2333 RegMask Matcher::modL_proj_mask() {
 2334   ShouldNotReachHere();
 2335   return RegMask();
 2336 }
 2337 
 2338 const RegMask Matcher::method_handle_invoke_SP_save_mask() {
 2339   return FP_REG_mask();
 2340 }
 2341 
 2342 bool size_fits_all_mem_uses(AddPNode* addp, int shift) {
 2343   for (DUIterator_Fast imax, i = addp-&gt;fast_outs(imax); i &lt; imax; i++) {
 2344     Node* u = addp-&gt;fast_out(i);
 2345     if (u-&gt;is_Mem()) {
 2346       int opsize = u-&gt;as_Mem()-&gt;memory_size();
 2347       assert(opsize &gt; 0, &quot;unexpected memory operand size&quot;);
 2348       if (u-&gt;as_Mem()-&gt;memory_size() != (1&lt;&lt;shift)) {
 2349         return false;
 2350       }
 2351     }
 2352   }
 2353   return true;
 2354 }
 2355 
 2356 const bool Matcher::convi2l_type_required = false;
 2357 
 2358 // Should the matcher clone input &#39;m&#39; of node &#39;n&#39;?
 2359 bool Matcher::pd_clone_node(Node* n, Node* m, Matcher::MStack&amp; mstack) {
 2360   if (is_vshift_con_pattern(n, m)) { // ShiftV src (ShiftCntV con)
 2361     mstack.push(m, Visit);           // m = ShiftCntV
 2362     return true;
 2363   }
 2364   return false;
 2365 }
 2366 
 2367 // Should the Matcher clone shifts on addressing modes, expecting them
 2368 // to be subsumed into complex addressing expressions or compute them
 2369 // into registers?
 2370 bool Matcher::pd_clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
 2371   if (clone_base_plus_offset_address(m, mstack, address_visited)) {
 2372     return true;
 2373   }
 2374 
 2375   Node *off = m-&gt;in(AddPNode::Offset);
 2376   if (off-&gt;Opcode() == Op_LShiftL &amp;&amp; off-&gt;in(2)-&gt;is_Con() &amp;&amp;
 2377       size_fits_all_mem_uses(m, off-&gt;in(2)-&gt;get_int()) &amp;&amp;
 2378       // Are there other uses besides address expressions?
 2379       !is_visited(off)) {
 2380     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2381     mstack.push(off-&gt;in(2), Visit);
 2382     Node *conv = off-&gt;in(1);
 2383     if (conv-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2384         // Are there other uses besides address expressions?
 2385         !is_visited(conv)) {
 2386       address_visited.set(conv-&gt;_idx); // Flag as address_visited
 2387       mstack.push(conv-&gt;in(1), Pre_Visit);
 2388     } else {
 2389       mstack.push(conv, Pre_Visit);
 2390     }
 2391     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2392     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2393     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2394     return true;
 2395   } else if (off-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2396              // Are there other uses besides address expressions?
 2397              !is_visited(off)) {
 2398     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2399     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2400     mstack.push(off-&gt;in(1), Pre_Visit);
 2401     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2402     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2403     return true;
 2404   }
 2405   return false;
 2406 }
 2407 
 2408 void Compile::reshape_address(AddPNode* addp) {
 2409 }
 2410 
 2411 
 2412 #define MOV_VOLATILE(REG, BASE, INDEX, SCALE, DISP, SCRATCH, INSN)      \
 2413   C2_MacroAssembler _masm(&amp;cbuf);                                       \
 2414   {                                                                     \
 2415     guarantee(INDEX == -1, &quot;mode not permitted for volatile&quot;);          \
 2416     guarantee(DISP == 0, &quot;mode not permitted for volatile&quot;);            \
 2417     guarantee(SCALE == 0, &quot;mode not permitted for volatile&quot;);           \
 2418     __ INSN(REG, as_Register(BASE));                                    \
 2419   }
 2420 
 2421 
 2422 static Address mem2address(int opcode, Register base, int index, int size, int disp)
 2423   {
 2424     Address::extend scale;
 2425 
 2426     // Hooboy, this is fugly.  We need a way to communicate to the
 2427     // encoder that the index needs to be sign extended, so we have to
 2428     // enumerate all the cases.
 2429     switch (opcode) {
 2430     case INDINDEXSCALEDI2L:
 2431     case INDINDEXSCALEDI2LN:
 2432     case INDINDEXI2L:
 2433     case INDINDEXI2LN:
 2434       scale = Address::sxtw(size);
 2435       break;
 2436     default:
 2437       scale = Address::lsl(size);
 2438     }
 2439 
 2440     if (index == -1) {
 2441       return Address(base, disp);
 2442     } else {
 2443       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2444       return Address(base, as_Register(index), scale);
 2445     }
 2446   }
 2447 
 2448 
 2449 typedef void (MacroAssembler::* mem_insn)(Register Rt, const Address &amp;adr);
 2450 typedef void (MacroAssembler::* mem_insn2)(Register Rt, Register adr);
 2451 typedef void (MacroAssembler::* mem_float_insn)(FloatRegister Rt, const Address &amp;adr);
 2452 typedef void (MacroAssembler::* mem_vector_insn)(FloatRegister Rt,
 2453                                   MacroAssembler::SIMD_RegVariant T, const Address &amp;adr);
 2454 
 2455   // Used for all non-volatile memory accesses.  The use of
 2456   // $mem-&gt;opcode() to discover whether this pattern uses sign-extended
 2457   // offsets is something of a kludge.
 2458   static void loadStore(C2_MacroAssembler masm, mem_insn insn,
 2459                         Register reg, int opcode,
 2460                         Register base, int index, int scale, int disp,
 2461                         int size_in_memory)
 2462   {
 2463     Address addr = mem2address(opcode, base, index, scale, disp);
 2464     if (addr.getMode() == Address::base_plus_offset) {
 2465       /* If we get an out-of-range offset it is a bug in the compiler,
 2466          so we assert here. */
 2467       assert(Address::offset_ok_for_immed(addr.offset(), exact_log2(size_in_memory)),
 2468              &quot;c2 compiler bug&quot;);
 2469       /* Fix up any out-of-range offsets. */
 2470       assert_different_registers(rscratch1, base);
 2471       assert_different_registers(rscratch1, reg);
 2472       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2473     }
 2474     (masm.*insn)(reg, addr);
 2475   }
 2476 
 2477   static void loadStore(C2_MacroAssembler masm, mem_float_insn insn,
 2478                         FloatRegister reg, int opcode,
 2479                         Register base, int index, int size, int disp,
 2480                         int size_in_memory)
 2481   {
 2482     Address::extend scale;
 2483 
 2484     switch (opcode) {
 2485     case INDINDEXSCALEDI2L:
 2486     case INDINDEXSCALEDI2LN:
 2487       scale = Address::sxtw(size);
 2488       break;
 2489     default:
 2490       scale = Address::lsl(size);
 2491     }
 2492 
 2493     if (index == -1) {
 2494       /* If we get an out-of-range offset it is a bug in the compiler,
 2495          so we assert here. */
 2496       assert(Address::offset_ok_for_immed(disp, exact_log2(size_in_memory)), &quot;c2 compiler bug&quot;);
 2497       /* Fix up any out-of-range offsets. */
 2498       assert_different_registers(rscratch1, base);
 2499       Address addr = Address(base, disp);
 2500       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2501       (masm.*insn)(reg, addr);
 2502     } else {
 2503       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2504       (masm.*insn)(reg, Address(base, as_Register(index), scale));
 2505     }
 2506   }
 2507 
 2508   static void loadStore(C2_MacroAssembler masm, mem_vector_insn insn,
 2509                         FloatRegister reg, MacroAssembler::SIMD_RegVariant T,
 2510                         int opcode, Register base, int index, int size, int disp)
 2511   {
 2512     if (index == -1) {
 2513       (masm.*insn)(reg, T, Address(base, disp));
 2514     } else {
 2515       assert(disp == 0, &quot;unsupported address mode&quot;);
 2516       (masm.*insn)(reg, T, Address(base, as_Register(index), Address::lsl(size)));
 2517     }
 2518   }
 2519 
 2520 %}
 2521 
 2522 
 2523 
 2524 //----------ENCODING BLOCK-----------------------------------------------------
 2525 // This block specifies the encoding classes used by the compiler to
 2526 // output byte streams.  Encoding classes are parameterized macros
 2527 // used by Machine Instruction Nodes in order to generate the bit
 2528 // encoding of the instruction.  Operands specify their base encoding
 2529 // interface with the interface keyword.  There are currently
 2530 // supported four interfaces, REG_INTER, CONST_INTER, MEMORY_INTER, &amp;
 2531 // COND_INTER.  REG_INTER causes an operand to generate a function
 2532 // which returns its register number when queried.  CONST_INTER causes
 2533 // an operand to generate a function which returns the value of the
 2534 // constant when queried.  MEMORY_INTER causes an operand to generate
 2535 // four functions which return the Base Register, the Index Register,
 2536 // the Scale Value, and the Offset Value of the operand when queried.
 2537 // COND_INTER causes an operand to generate six functions which return
 2538 // the encoding code (ie - encoding bits for the instruction)
 2539 // associated with each basic boolean condition for a conditional
 2540 // instruction.
 2541 //
 2542 // Instructions specify two basic values for encoding.  Again, a
 2543 // function is available to check if the constant displacement is an
 2544 // oop. They use the ins_encode keyword to specify their encoding
 2545 // classes (which must be a sequence of enc_class names, and their
 2546 // parameters, specified in the encoding block), and they use the
 2547 // opcode keyword to specify, in order, their primary, secondary, and
 2548 // tertiary opcode.  Only the opcode sections which a particular
 2549 // instruction needs for encoding need to be specified.
 2550 encode %{
 2551   // Build emit functions for each basic byte or larger field in the
 2552   // intel encoding scheme (opcode, rm, sib, immediate), and call them
 2553   // from C++ code in the enc_class source block.  Emit functions will
 2554   // live in the main source block for now.  In future, we can
 2555   // generalize this by adding a syntax that specifies the sizes of
 2556   // fields in an order, so that the adlc can build the emit functions
 2557   // automagically
 2558 
 2559   // catch all for unimplemented encodings
 2560   enc_class enc_unimplemented %{
 2561     C2_MacroAssembler _masm(&amp;cbuf);
 2562     __ unimplemented(&quot;C2 catch all&quot;);
 2563   %}
 2564 
 2565   // BEGIN Non-volatile memory access
 2566 
 2567   // This encoding class is generated automatically from ad_encode.m4.
 2568   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2569   enc_class aarch64_enc_ldrsbw(iRegI dst, memory1 mem) %{
 2570     Register dst_reg = as_Register($dst$$reg);
 2571     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsbw, dst_reg, $mem-&gt;opcode(),
 2572                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2573   %}
 2574 
 2575   // This encoding class is generated automatically from ad_encode.m4.
 2576   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2577   enc_class aarch64_enc_ldrsb(iRegI dst, memory1 mem) %{
 2578     Register dst_reg = as_Register($dst$$reg);
 2579     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsb, dst_reg, $mem-&gt;opcode(),
 2580                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2581   %}
 2582 
 2583   // This encoding class is generated automatically from ad_encode.m4.
 2584   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2585   enc_class aarch64_enc_ldrb(iRegI dst, memory1 mem) %{
 2586     Register dst_reg = as_Register($dst$$reg);
 2587     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2588                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2589   %}
 2590 
 2591   // This encoding class is generated automatically from ad_encode.m4.
 2592   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2593   enc_class aarch64_enc_ldrb(iRegL dst, memory1 mem) %{
 2594     Register dst_reg = as_Register($dst$$reg);
 2595     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2596                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2597   %}
 2598 
 2599   // This encoding class is generated automatically from ad_encode.m4.
 2600   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2601   enc_class aarch64_enc_ldrshw(iRegI dst, memory2 mem) %{
 2602     Register dst_reg = as_Register($dst$$reg);
 2603     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrshw, dst_reg, $mem-&gt;opcode(),
 2604                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2605   %}
 2606 
 2607   // This encoding class is generated automatically from ad_encode.m4.
 2608   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2609   enc_class aarch64_enc_ldrsh(iRegI dst, memory2 mem) %{
 2610     Register dst_reg = as_Register($dst$$reg);
 2611     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsh, dst_reg, $mem-&gt;opcode(),
 2612                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2613   %}
 2614 
 2615   // This encoding class is generated automatically from ad_encode.m4.
 2616   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2617   enc_class aarch64_enc_ldrh(iRegI dst, memory2 mem) %{
 2618     Register dst_reg = as_Register($dst$$reg);
 2619     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2620                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2621   %}
 2622 
 2623   // This encoding class is generated automatically from ad_encode.m4.
 2624   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2625   enc_class aarch64_enc_ldrh(iRegL dst, memory2 mem) %{
 2626     Register dst_reg = as_Register($dst$$reg);
 2627     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2628                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2629   %}
 2630 
 2631   // This encoding class is generated automatically from ad_encode.m4.
 2632   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2633   enc_class aarch64_enc_ldrw(iRegI dst, memory4 mem) %{
 2634     Register dst_reg = as_Register($dst$$reg);
 2635     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2636                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2637   %}
 2638 
 2639   // This encoding class is generated automatically from ad_encode.m4.
 2640   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2641   enc_class aarch64_enc_ldrw(iRegL dst, memory4 mem) %{
 2642     Register dst_reg = as_Register($dst$$reg);
 2643     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2644                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2645   %}
 2646 
 2647   // This encoding class is generated automatically from ad_encode.m4.
 2648   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2649   enc_class aarch64_enc_ldrsw(iRegL dst, memory4 mem) %{
 2650     Register dst_reg = as_Register($dst$$reg);
 2651     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsw, dst_reg, $mem-&gt;opcode(),
 2652                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2653   %}
 2654 
 2655   // This encoding class is generated automatically from ad_encode.m4.
 2656   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2657   enc_class aarch64_enc_ldr(iRegL dst, memory8 mem) %{
 2658     Register dst_reg = as_Register($dst$$reg);
 2659     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, $mem-&gt;opcode(),
 2660                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2661   %}
 2662 
 2663   // This encoding class is generated automatically from ad_encode.m4.
 2664   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2665   enc_class aarch64_enc_ldrs(vRegF dst, memory4 mem) %{
 2666     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2667     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, dst_reg, $mem-&gt;opcode(),
 2668                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2669   %}
 2670 
 2671   // This encoding class is generated automatically from ad_encode.m4.
 2672   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2673   enc_class aarch64_enc_ldrd(vRegD dst, memory8 mem) %{
 2674     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2675     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, dst_reg, $mem-&gt;opcode(),
 2676                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2677   %}
 2678 
 2679   // This encoding class is generated automatically from ad_encode.m4.
 2680   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2681   enc_class aarch64_enc_strb(iRegI src, memory1 mem) %{
 2682     Register src_reg = as_Register($src$$reg);
 2683     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strb, src_reg, $mem-&gt;opcode(),
 2684                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2685   %}
 2686 
 2687   // This encoding class is generated automatically from ad_encode.m4.
 2688   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2689   enc_class aarch64_enc_strb0(memory1 mem) %{
 2690     C2_MacroAssembler _masm(&amp;cbuf);
 2691     loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2692                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2693   %}
 2694 
 2695   // This encoding class is generated automatically from ad_encode.m4.
 2696   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2697   enc_class aarch64_enc_strh(iRegI src, memory2 mem) %{
 2698     Register src_reg = as_Register($src$$reg);
 2699     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strh, src_reg, $mem-&gt;opcode(),
 2700                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2701   %}
 2702 
 2703   // This encoding class is generated automatically from ad_encode.m4.
 2704   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2705   enc_class aarch64_enc_strh0(memory2 mem) %{
 2706     C2_MacroAssembler _masm(&amp;cbuf);
 2707     loadStore(_masm, &amp;MacroAssembler::strh, zr, $mem-&gt;opcode(),
 2708                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2709   %}
 2710 
 2711   // This encoding class is generated automatically from ad_encode.m4.
 2712   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2713   enc_class aarch64_enc_strw(iRegI src, memory4 mem) %{
 2714     Register src_reg = as_Register($src$$reg);
 2715     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strw, src_reg, $mem-&gt;opcode(),
 2716                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2717   %}
 2718 
 2719   // This encoding class is generated automatically from ad_encode.m4.
 2720   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2721   enc_class aarch64_enc_strw0(memory4 mem) %{
 2722     C2_MacroAssembler _masm(&amp;cbuf);
 2723     loadStore(_masm, &amp;MacroAssembler::strw, zr, $mem-&gt;opcode(),
 2724                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2725   %}
 2726 
 2727   // This encoding class is generated automatically from ad_encode.m4.
 2728   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2729   enc_class aarch64_enc_str(iRegL src, memory8 mem) %{
 2730     Register src_reg = as_Register($src$$reg);
 2731     // we sometimes get asked to store the stack pointer into the
 2732     // current thread -- we cannot do that directly on AArch64
 2733     if (src_reg == r31_sp) {
 2734       C2_MacroAssembler _masm(&amp;cbuf);
 2735       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2736       __ mov(rscratch2, sp);
 2737       src_reg = rscratch2;
 2738     }
 2739     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, $mem-&gt;opcode(),
 2740                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2741   %}
 2742 
 2743   // This encoding class is generated automatically from ad_encode.m4.
 2744   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2745   enc_class aarch64_enc_str0(memory8 mem) %{
 2746     C2_MacroAssembler _masm(&amp;cbuf);
 2747     loadStore(_masm, &amp;MacroAssembler::str, zr, $mem-&gt;opcode(),
 2748                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2749   %}
 2750 
 2751   // This encoding class is generated automatically from ad_encode.m4.
 2752   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2753   enc_class aarch64_enc_strs(vRegF src, memory4 mem) %{
 2754     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2755     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strs, src_reg, $mem-&gt;opcode(),
 2756                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2757   %}
 2758 
 2759   // This encoding class is generated automatically from ad_encode.m4.
 2760   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2761   enc_class aarch64_enc_strd(vRegD src, memory8 mem) %{
 2762     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2763     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strd, src_reg, $mem-&gt;opcode(),
 2764                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2765   %}
 2766 
 2767   // This encoding class is generated automatically from ad_encode.m4.
 2768   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2769   enc_class aarch64_enc_strw_immn(immN src, memory1 mem) %{
 2770     C2_MacroAssembler _masm(&amp;cbuf);
 2771     address con = (address)$src$$constant;
 2772     // need to do this the hard way until we can manage relocs
 2773     // for 32 bit constants
 2774     __ movoop(rscratch2, (jobject)con);
 2775     if (con) __ encode_heap_oop_not_null(rscratch2);
 2776     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2777                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2778   %}
 2779 
 2780   // This encoding class is generated automatically from ad_encode.m4.
 2781   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2782   enc_class aarch64_enc_strw_immnk(immN src, memory4 mem) %{
 2783     C2_MacroAssembler _masm(&amp;cbuf);
 2784     address con = (address)$src$$constant;
 2785     // need to do this the hard way until we can manage relocs
 2786     // for 32 bit constants
 2787     __ movoop(rscratch2, (jobject)con);
 2788     __ encode_klass_not_null(rscratch2);
 2789     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2790                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2791   %}
 2792 
 2793   // This encoding class is generated automatically from ad_encode.m4.
 2794   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2795   enc_class aarch64_enc_strb0_ordered(memory4 mem) %{
 2796       C2_MacroAssembler _masm(&amp;cbuf);
 2797       __ membar(Assembler::StoreStore);
 2798       loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2799                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2800   %}
 2801 
 2802   // END Non-volatile memory access
 2803 
 2804   // Vector loads and stores
 2805   enc_class aarch64_enc_ldrvS(vecD dst, memory mem) %{
 2806     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2807     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::S,
 2808        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2809   %}
 2810 
 2811   enc_class aarch64_enc_ldrvD(vecD dst, memory mem) %{
 2812     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2813     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::D,
 2814        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2815   %}
 2816 
 2817   enc_class aarch64_enc_ldrvQ(vecX dst, memory mem) %{
 2818     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2819     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::Q,
 2820        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2821   %}
 2822 
 2823   enc_class aarch64_enc_strvS(vecD src, memory mem) %{
 2824     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2825     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::S,
 2826        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2827   %}
 2828 
 2829   enc_class aarch64_enc_strvD(vecD src, memory mem) %{
 2830     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2831     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::D,
 2832        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2833   %}
 2834 
 2835   enc_class aarch64_enc_strvQ(vecX src, memory mem) %{
 2836     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2837     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::Q,
 2838        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2839   %}
 2840 
 2841   // volatile loads and stores
 2842 
 2843   enc_class aarch64_enc_stlrb(iRegI src, memory mem) %{
 2844     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2845                  rscratch1, stlrb);
 2846   %}
 2847 
 2848   enc_class aarch64_enc_stlrh(iRegI src, memory mem) %{
 2849     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2850                  rscratch1, stlrh);
 2851   %}
 2852 
 2853   enc_class aarch64_enc_stlrw(iRegI src, memory mem) %{
 2854     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2855                  rscratch1, stlrw);
 2856   %}
 2857 
 2858 
 2859   enc_class aarch64_enc_ldarsbw(iRegI dst, memory mem) %{
 2860     Register dst_reg = as_Register($dst$$reg);
 2861     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2862              rscratch1, ldarb);
 2863     __ sxtbw(dst_reg, dst_reg);
 2864   %}
 2865 
 2866   enc_class aarch64_enc_ldarsb(iRegL dst, memory mem) %{
 2867     Register dst_reg = as_Register($dst$$reg);
 2868     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2869              rscratch1, ldarb);
 2870     __ sxtb(dst_reg, dst_reg);
 2871   %}
 2872 
 2873   enc_class aarch64_enc_ldarbw(iRegI dst, memory mem) %{
 2874     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2875              rscratch1, ldarb);
 2876   %}
 2877 
 2878   enc_class aarch64_enc_ldarb(iRegL dst, memory mem) %{
 2879     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2880              rscratch1, ldarb);
 2881   %}
 2882 
 2883   enc_class aarch64_enc_ldarshw(iRegI dst, memory mem) %{
 2884     Register dst_reg = as_Register($dst$$reg);
 2885     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2886              rscratch1, ldarh);
 2887     __ sxthw(dst_reg, dst_reg);
 2888   %}
 2889 
 2890   enc_class aarch64_enc_ldarsh(iRegL dst, memory mem) %{
 2891     Register dst_reg = as_Register($dst$$reg);
 2892     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2893              rscratch1, ldarh);
 2894     __ sxth(dst_reg, dst_reg);
 2895   %}
 2896 
 2897   enc_class aarch64_enc_ldarhw(iRegI dst, memory mem) %{
 2898     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2899              rscratch1, ldarh);
 2900   %}
 2901 
 2902   enc_class aarch64_enc_ldarh(iRegL dst, memory mem) %{
 2903     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2904              rscratch1, ldarh);
 2905   %}
 2906 
 2907   enc_class aarch64_enc_ldarw(iRegI dst, memory mem) %{
 2908     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2909              rscratch1, ldarw);
 2910   %}
 2911 
 2912   enc_class aarch64_enc_ldarw(iRegL dst, memory mem) %{
 2913     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2914              rscratch1, ldarw);
 2915   %}
 2916 
 2917   enc_class aarch64_enc_ldar(iRegL dst, memory mem) %{
 2918     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2919              rscratch1, ldar);
 2920   %}
 2921 
 2922   enc_class aarch64_enc_fldars(vRegF dst, memory mem) %{
 2923     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2924              rscratch1, ldarw);
 2925     __ fmovs(as_FloatRegister($dst$$reg), rscratch1);
 2926   %}
 2927 
 2928   enc_class aarch64_enc_fldard(vRegD dst, memory mem) %{
 2929     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2930              rscratch1, ldar);
 2931     __ fmovd(as_FloatRegister($dst$$reg), rscratch1);
 2932   %}
 2933 
 2934   enc_class aarch64_enc_stlr(iRegL src, memory mem) %{
 2935     Register src_reg = as_Register($src$$reg);
 2936     // we sometimes get asked to store the stack pointer into the
 2937     // current thread -- we cannot do that directly on AArch64
 2938     if (src_reg == r31_sp) {
 2939       C2_MacroAssembler _masm(&amp;cbuf);
 2940       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2941       __ mov(rscratch2, sp);
 2942       src_reg = rscratch2;
 2943     }
 2944     MOV_VOLATILE(src_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2945                  rscratch1, stlr);
 2946   %}
 2947 
 2948   enc_class aarch64_enc_fstlrs(vRegF src, memory mem) %{
 2949     {
 2950       C2_MacroAssembler _masm(&amp;cbuf);
 2951       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2952       __ fmovs(rscratch2, src_reg);
 2953     }
 2954     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2955                  rscratch1, stlrw);
 2956   %}
 2957 
 2958   enc_class aarch64_enc_fstlrd(vRegD src, memory mem) %{
 2959     {
 2960       C2_MacroAssembler _masm(&amp;cbuf);
 2961       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2962       __ fmovd(rscratch2, src_reg);
 2963     }
 2964     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2965                  rscratch1, stlr);
 2966   %}
 2967 
 2968   // synchronized read/update encodings
 2969 
 2970   enc_class aarch64_enc_ldaxr(iRegL dst, memory8 mem) %{
 2971     C2_MacroAssembler _masm(&amp;cbuf);
 2972     Register dst_reg = as_Register($dst$$reg);
 2973     Register base = as_Register($mem$$base);
 2974     int index = $mem$$index;
 2975     int scale = $mem$$scale;
 2976     int disp = $mem$$disp;
 2977     if (index == -1) {
 2978        if (disp != 0) {
 2979         __ lea(rscratch1, Address(base, disp));
 2980         __ ldaxr(dst_reg, rscratch1);
 2981       } else {
 2982         // TODO
 2983         // should we ever get anything other than this case?
 2984         __ ldaxr(dst_reg, base);
 2985       }
 2986     } else {
 2987       Register index_reg = as_Register(index);
 2988       if (disp == 0) {
 2989         __ lea(rscratch1, Address(base, index_reg, Address::lsl(scale)));
 2990         __ ldaxr(dst_reg, rscratch1);
 2991       } else {
 2992         __ lea(rscratch1, Address(base, disp));
 2993         __ lea(rscratch1, Address(rscratch1, index_reg, Address::lsl(scale)));
 2994         __ ldaxr(dst_reg, rscratch1);
 2995       }
 2996     }
 2997   %}
 2998 
 2999   enc_class aarch64_enc_stlxr(iRegLNoSp src, memory8 mem) %{
 3000     C2_MacroAssembler _masm(&amp;cbuf);
 3001     Register src_reg = as_Register($src$$reg);
 3002     Register base = as_Register($mem$$base);
 3003     int index = $mem$$index;
 3004     int scale = $mem$$scale;
 3005     int disp = $mem$$disp;
 3006     if (index == -1) {
 3007        if (disp != 0) {
 3008         __ lea(rscratch2, Address(base, disp));
 3009         __ stlxr(rscratch1, src_reg, rscratch2);
 3010       } else {
 3011         // TODO
 3012         // should we ever get anything other than this case?
 3013         __ stlxr(rscratch1, src_reg, base);
 3014       }
 3015     } else {
 3016       Register index_reg = as_Register(index);
 3017       if (disp == 0) {
 3018         __ lea(rscratch2, Address(base, index_reg, Address::lsl(scale)));
 3019         __ stlxr(rscratch1, src_reg, rscratch2);
 3020       } else {
 3021         __ lea(rscratch2, Address(base, disp));
 3022         __ lea(rscratch2, Address(rscratch2, index_reg, Address::lsl(scale)));
 3023         __ stlxr(rscratch1, src_reg, rscratch2);
 3024       }
 3025     }
 3026     __ cmpw(rscratch1, zr);
 3027   %}
 3028 
 3029   enc_class aarch64_enc_cmpxchg(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3030     C2_MacroAssembler _masm(&amp;cbuf);
 3031     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3032     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3033                Assembler::xword, /*acquire*/ false, /*release*/ true,
 3034                /*weak*/ false, noreg);
 3035   %}
 3036 
 3037   enc_class aarch64_enc_cmpxchgw(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3038     C2_MacroAssembler _masm(&amp;cbuf);
 3039     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3040     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3041                Assembler::word, /*acquire*/ false, /*release*/ true,
 3042                /*weak*/ false, noreg);
 3043   %}
 3044 
 3045   enc_class aarch64_enc_cmpxchgs(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3046     C2_MacroAssembler _masm(&amp;cbuf);
 3047     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3048     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3049                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 3050                /*weak*/ false, noreg);
 3051   %}
 3052 
 3053   enc_class aarch64_enc_cmpxchgb(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3054     C2_MacroAssembler _masm(&amp;cbuf);
 3055     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3056     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3057                Assembler::byte, /*acquire*/ false, /*release*/ true,
 3058                /*weak*/ false, noreg);
 3059   %}
 3060 
 3061 
 3062   // The only difference between aarch64_enc_cmpxchg and
 3063   // aarch64_enc_cmpxchg_acq is that we use load-acquire in the
 3064   // CompareAndSwap sequence to serve as a barrier on acquiring a
 3065   // lock.
 3066   enc_class aarch64_enc_cmpxchg_acq(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3067     C2_MacroAssembler _masm(&amp;cbuf);
 3068     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3069     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3070                Assembler::xword, /*acquire*/ true, /*release*/ true,
 3071                /*weak*/ false, noreg);
 3072   %}
 3073 
 3074   enc_class aarch64_enc_cmpxchgw_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3075     C2_MacroAssembler _masm(&amp;cbuf);
 3076     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3077     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3078                Assembler::word, /*acquire*/ true, /*release*/ true,
 3079                /*weak*/ false, noreg);
 3080   %}
 3081 
 3082   enc_class aarch64_enc_cmpxchgs_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3083     C2_MacroAssembler _masm(&amp;cbuf);
 3084     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3085     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3086                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 3087                /*weak*/ false, noreg);
 3088   %}
 3089 
 3090   enc_class aarch64_enc_cmpxchgb_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3091     C2_MacroAssembler _masm(&amp;cbuf);
 3092     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3093     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3094                Assembler::byte, /*acquire*/ true, /*release*/ true,
 3095                /*weak*/ false, noreg);
 3096   %}
 3097 
 3098   // auxiliary used for CompareAndSwapX to set result register
 3099   enc_class aarch64_enc_cset_eq(iRegINoSp res) %{
 3100     C2_MacroAssembler _masm(&amp;cbuf);
 3101     Register res_reg = as_Register($res$$reg);
 3102     __ cset(res_reg, Assembler::EQ);
 3103   %}
 3104 
 3105   // prefetch encodings
 3106 
 3107   enc_class aarch64_enc_prefetchw(memory mem) %{
 3108     C2_MacroAssembler _masm(&amp;cbuf);
 3109     Register base = as_Register($mem$$base);
 3110     int index = $mem$$index;
 3111     int scale = $mem$$scale;
 3112     int disp = $mem$$disp;
 3113     if (index == -1) {
 3114       __ prfm(Address(base, disp), PSTL1KEEP);
 3115     } else {
 3116       Register index_reg = as_Register(index);
 3117       if (disp == 0) {
 3118         __ prfm(Address(base, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3119       } else {
 3120         __ lea(rscratch1, Address(base, disp));
 3121 	__ prfm(Address(rscratch1, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3122       }
 3123     }
 3124   %}
 3125 
 3126   /// mov envcodings
 3127 
 3128   enc_class aarch64_enc_movw_imm(iRegI dst, immI src) %{
 3129     C2_MacroAssembler _masm(&amp;cbuf);
 3130     uint32_t con = (uint32_t)$src$$constant;
 3131     Register dst_reg = as_Register($dst$$reg);
 3132     if (con == 0) {
 3133       __ movw(dst_reg, zr);
 3134     } else {
 3135       __ movw(dst_reg, con);
 3136     }
 3137   %}
 3138 
 3139   enc_class aarch64_enc_mov_imm(iRegL dst, immL src) %{
 3140     C2_MacroAssembler _masm(&amp;cbuf);
 3141     Register dst_reg = as_Register($dst$$reg);
 3142     uint64_t con = (uint64_t)$src$$constant;
 3143     if (con == 0) {
 3144       __ mov(dst_reg, zr);
 3145     } else {
 3146       __ mov(dst_reg, con);
 3147     }
 3148   %}
 3149 
 3150   enc_class aarch64_enc_mov_p(iRegP dst, immP src) %{
 3151     C2_MacroAssembler _masm(&amp;cbuf);
 3152     Register dst_reg = as_Register($dst$$reg);
 3153     address con = (address)$src$$constant;
 3154     if (con == NULL || con == (address)1) {
 3155       ShouldNotReachHere();
 3156     } else {
 3157       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3158       if (rtype == relocInfo::oop_type) {
 3159         __ movoop(dst_reg, (jobject)con, /*immediate*/true);
 3160       } else if (rtype == relocInfo::metadata_type) {
 3161         __ mov_metadata(dst_reg, (Metadata*)con);
 3162       } else {
 3163         assert(rtype == relocInfo::none, &quot;unexpected reloc type&quot;);
 3164         if (con &lt; (address)(uintptr_t)os::vm_page_size()) {
 3165           __ mov(dst_reg, con);
 3166         } else {
 3167           uintptr_t offset;
 3168           __ adrp(dst_reg, con, offset);
 3169           __ add(dst_reg, dst_reg, offset);
 3170         }
 3171       }
 3172     }
 3173   %}
 3174 
 3175   enc_class aarch64_enc_mov_p0(iRegP dst, immP0 src) %{
 3176     C2_MacroAssembler _masm(&amp;cbuf);
 3177     Register dst_reg = as_Register($dst$$reg);
 3178     __ mov(dst_reg, zr);
 3179   %}
 3180 
 3181   enc_class aarch64_enc_mov_p1(iRegP dst, immP_1 src) %{
 3182     C2_MacroAssembler _masm(&amp;cbuf);
 3183     Register dst_reg = as_Register($dst$$reg);
 3184     __ mov(dst_reg, (uint64_t)1);
 3185   %}
 3186 
 3187   enc_class aarch64_enc_mov_byte_map_base(iRegP dst, immByteMapBase src) %{
 3188     C2_MacroAssembler _masm(&amp;cbuf);
 3189     __ load_byte_map_base($dst$$Register);
 3190   %}
 3191 
 3192   enc_class aarch64_enc_mov_n(iRegN dst, immN src) %{
 3193     C2_MacroAssembler _masm(&amp;cbuf);
 3194     Register dst_reg = as_Register($dst$$reg);
 3195     address con = (address)$src$$constant;
 3196     if (con == NULL) {
 3197       ShouldNotReachHere();
 3198     } else {
 3199       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3200       assert(rtype == relocInfo::oop_type, &quot;unexpected reloc type&quot;);
 3201       __ set_narrow_oop(dst_reg, (jobject)con);
 3202     }
 3203   %}
 3204 
 3205   enc_class aarch64_enc_mov_n0(iRegN dst, immN0 src) %{
 3206     C2_MacroAssembler _masm(&amp;cbuf);
 3207     Register dst_reg = as_Register($dst$$reg);
 3208     __ mov(dst_reg, zr);
 3209   %}
 3210 
 3211   enc_class aarch64_enc_mov_nk(iRegN dst, immNKlass src) %{
 3212     C2_MacroAssembler _masm(&amp;cbuf);
 3213     Register dst_reg = as_Register($dst$$reg);
 3214     address con = (address)$src$$constant;
 3215     if (con == NULL) {
 3216       ShouldNotReachHere();
 3217     } else {
 3218       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3219       assert(rtype == relocInfo::metadata_type, &quot;unexpected reloc type&quot;);
 3220       __ set_narrow_klass(dst_reg, (Klass *)con);
 3221     }
 3222   %}
 3223 
 3224   // arithmetic encodings
 3225 
 3226   enc_class aarch64_enc_addsubw_imm(iRegI dst, iRegI src1, immIAddSub src2) %{
 3227     C2_MacroAssembler _masm(&amp;cbuf);
 3228     Register dst_reg = as_Register($dst$$reg);
 3229     Register src_reg = as_Register($src1$$reg);
 3230     int32_t con = (int32_t)$src2$$constant;
 3231     // add has primary == 0, subtract has primary == 1
 3232     if ($primary) { con = -con; }
 3233     if (con &lt; 0) {
 3234       __ subw(dst_reg, src_reg, -con);
 3235     } else {
 3236       __ addw(dst_reg, src_reg, con);
 3237     }
 3238   %}
 3239 
 3240   enc_class aarch64_enc_addsub_imm(iRegL dst, iRegL src1, immLAddSub src2) %{
 3241     C2_MacroAssembler _masm(&amp;cbuf);
 3242     Register dst_reg = as_Register($dst$$reg);
 3243     Register src_reg = as_Register($src1$$reg);
 3244     int32_t con = (int32_t)$src2$$constant;
 3245     // add has primary == 0, subtract has primary == 1
 3246     if ($primary) { con = -con; }
 3247     if (con &lt; 0) {
 3248       __ sub(dst_reg, src_reg, -con);
 3249     } else {
 3250       __ add(dst_reg, src_reg, con);
 3251     }
 3252   %}
 3253 
 3254   enc_class aarch64_enc_divw(iRegI dst, iRegI src1, iRegI src2) %{
 3255     C2_MacroAssembler _masm(&amp;cbuf);
 3256    Register dst_reg = as_Register($dst$$reg);
 3257    Register src1_reg = as_Register($src1$$reg);
 3258    Register src2_reg = as_Register($src2$$reg);
 3259     __ corrected_idivl(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3260   %}
 3261 
 3262   enc_class aarch64_enc_div(iRegI dst, iRegI src1, iRegI src2) %{
 3263     C2_MacroAssembler _masm(&amp;cbuf);
 3264    Register dst_reg = as_Register($dst$$reg);
 3265    Register src1_reg = as_Register($src1$$reg);
 3266    Register src2_reg = as_Register($src2$$reg);
 3267     __ corrected_idivq(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3268   %}
 3269 
 3270   enc_class aarch64_enc_modw(iRegI dst, iRegI src1, iRegI src2) %{
 3271     C2_MacroAssembler _masm(&amp;cbuf);
 3272    Register dst_reg = as_Register($dst$$reg);
 3273    Register src1_reg = as_Register($src1$$reg);
 3274    Register src2_reg = as_Register($src2$$reg);
 3275     __ corrected_idivl(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3276   %}
 3277 
 3278   enc_class aarch64_enc_mod(iRegI dst, iRegI src1, iRegI src2) %{
 3279     C2_MacroAssembler _masm(&amp;cbuf);
 3280    Register dst_reg = as_Register($dst$$reg);
 3281    Register src1_reg = as_Register($src1$$reg);
 3282    Register src2_reg = as_Register($src2$$reg);
 3283     __ corrected_idivq(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3284   %}
 3285 
 3286   // compare instruction encodings
 3287 
 3288   enc_class aarch64_enc_cmpw(iRegI src1, iRegI src2) %{
 3289     C2_MacroAssembler _masm(&amp;cbuf);
 3290     Register reg1 = as_Register($src1$$reg);
 3291     Register reg2 = as_Register($src2$$reg);
 3292     __ cmpw(reg1, reg2);
 3293   %}
 3294 
 3295   enc_class aarch64_enc_cmpw_imm_addsub(iRegI src1, immIAddSub src2) %{
 3296     C2_MacroAssembler _masm(&amp;cbuf);
 3297     Register reg = as_Register($src1$$reg);
 3298     int32_t val = $src2$$constant;
 3299     if (val &gt;= 0) {
 3300       __ subsw(zr, reg, val);
 3301     } else {
 3302       __ addsw(zr, reg, -val);
 3303     }
 3304   %}
 3305 
 3306   enc_class aarch64_enc_cmpw_imm(iRegI src1, immI src2) %{
 3307     C2_MacroAssembler _masm(&amp;cbuf);
 3308     Register reg1 = as_Register($src1$$reg);
 3309     uint32_t val = (uint32_t)$src2$$constant;
 3310     __ movw(rscratch1, val);
 3311     __ cmpw(reg1, rscratch1);
 3312   %}
 3313 
 3314   enc_class aarch64_enc_cmp(iRegL src1, iRegL src2) %{
 3315     C2_MacroAssembler _masm(&amp;cbuf);
 3316     Register reg1 = as_Register($src1$$reg);
 3317     Register reg2 = as_Register($src2$$reg);
 3318     __ cmp(reg1, reg2);
 3319   %}
 3320 
 3321   enc_class aarch64_enc_cmp_imm_addsub(iRegL src1, immL12 src2) %{
 3322     C2_MacroAssembler _masm(&amp;cbuf);
 3323     Register reg = as_Register($src1$$reg);
 3324     int64_t val = $src2$$constant;
 3325     if (val &gt;= 0) {
 3326       __ subs(zr, reg, val);
 3327     } else if (val != -val) {
 3328       __ adds(zr, reg, -val);
 3329     } else {
 3330     // aargh, Long.MIN_VALUE is a special case
 3331       __ orr(rscratch1, zr, (uint64_t)val);
 3332       __ subs(zr, reg, rscratch1);
 3333     }
 3334   %}
 3335 
 3336   enc_class aarch64_enc_cmp_imm(iRegL src1, immL src2) %{
 3337     C2_MacroAssembler _masm(&amp;cbuf);
 3338     Register reg1 = as_Register($src1$$reg);
 3339     uint64_t val = (uint64_t)$src2$$constant;
 3340     __ mov(rscratch1, val);
 3341     __ cmp(reg1, rscratch1);
 3342   %}
 3343 
 3344   enc_class aarch64_enc_cmpp(iRegP src1, iRegP src2) %{
 3345     C2_MacroAssembler _masm(&amp;cbuf);
 3346     Register reg1 = as_Register($src1$$reg);
 3347     Register reg2 = as_Register($src2$$reg);
 3348     __ cmp(reg1, reg2);
 3349   %}
 3350 
 3351   enc_class aarch64_enc_cmpn(iRegN src1, iRegN src2) %{
 3352     C2_MacroAssembler _masm(&amp;cbuf);
 3353     Register reg1 = as_Register($src1$$reg);
 3354     Register reg2 = as_Register($src2$$reg);
 3355     __ cmpw(reg1, reg2);
 3356   %}
 3357 
 3358   enc_class aarch64_enc_testp(iRegP src) %{
 3359     C2_MacroAssembler _masm(&amp;cbuf);
 3360     Register reg = as_Register($src$$reg);
 3361     __ cmp(reg, zr);
 3362   %}
 3363 
 3364   enc_class aarch64_enc_testn(iRegN src) %{
 3365     C2_MacroAssembler _masm(&amp;cbuf);
 3366     Register reg = as_Register($src$$reg);
 3367     __ cmpw(reg, zr);
 3368   %}
 3369 
 3370   enc_class aarch64_enc_b(label lbl) %{
 3371     C2_MacroAssembler _masm(&amp;cbuf);
 3372     Label *L = $lbl$$label;
 3373     __ b(*L);
 3374   %}
 3375 
 3376   enc_class aarch64_enc_br_con(cmpOp cmp, label lbl) %{
 3377     C2_MacroAssembler _masm(&amp;cbuf);
 3378     Label *L = $lbl$$label;
 3379     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3380   %}
 3381 
 3382   enc_class aarch64_enc_br_conU(cmpOpU cmp, label lbl) %{
 3383     C2_MacroAssembler _masm(&amp;cbuf);
 3384     Label *L = $lbl$$label;
 3385     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3386   %}
 3387 
 3388   enc_class aarch64_enc_partial_subtype_check(iRegP sub, iRegP super, iRegP temp, iRegP result)
 3389   %{
 3390      Register sub_reg = as_Register($sub$$reg);
 3391      Register super_reg = as_Register($super$$reg);
 3392      Register temp_reg = as_Register($temp$$reg);
 3393      Register result_reg = as_Register($result$$reg);
 3394 
 3395      Label miss;
 3396      C2_MacroAssembler _masm(&amp;cbuf);
 3397      __ check_klass_subtype_slow_path(sub_reg, super_reg, temp_reg, result_reg,
 3398                                      NULL, &amp;miss,
 3399                                      /*set_cond_codes:*/ true);
 3400      if ($primary) {
 3401        __ mov(result_reg, zr);
 3402      }
 3403      __ bind(miss);
 3404   %}
 3405 
 3406   enc_class aarch64_enc_java_static_call(method meth) %{
 3407     C2_MacroAssembler _masm(&amp;cbuf);
 3408 
 3409     address addr = (address)$meth$$method;
 3410     address call;
 3411     if (!_method) {
 3412       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
 3413       call = __ trampoline_call(Address(addr, relocInfo::runtime_call_type), &amp;cbuf);
 3414     } else {
 3415       int method_index = resolved_method_index(cbuf);
 3416       RelocationHolder rspec = _optimized_virtual ? opt_virtual_call_Relocation::spec(method_index)
 3417                                                   : static_call_Relocation::spec(method_index);
 3418       call = __ trampoline_call(Address(addr, rspec), &amp;cbuf);
 3419 
 3420       // Emit stub for static call
 3421       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 3422       if (stub == NULL) {
 3423         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3424         return;
 3425       }
 3426     }
 3427     if (call == NULL) {
 3428       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3429       return;
 3430     }
 3431   %}
 3432 
 3433   enc_class aarch64_enc_java_dynamic_call(method meth) %{
 3434     C2_MacroAssembler _masm(&amp;cbuf);
 3435     int method_index = resolved_method_index(cbuf);
 3436     address call = __ ic_call((address)$meth$$method, method_index);
 3437     if (call == NULL) {
 3438       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3439       return;
 3440     }
 3441   %}
 3442 
 3443   enc_class aarch64_enc_call_epilog() %{
 3444     C2_MacroAssembler _masm(&amp;cbuf);
 3445     if (VerifyStackAtCalls) {
 3446       // Check that stack depth is unchanged: find majik cookie on stack
 3447       __ call_Unimplemented();
 3448     }
 3449   %}
 3450 
 3451   enc_class aarch64_enc_java_to_runtime(method meth) %{
 3452     C2_MacroAssembler _masm(&amp;cbuf);
 3453 
 3454     // some calls to generated routines (arraycopy code) are scheduled
 3455     // by C2 as runtime calls. if so we can call them using a br (they
 3456     // will be in a reachable segment) otherwise we have to use a blr
 3457     // which loads the absolute address into a register.
 3458     address entry = (address)$meth$$method;
 3459     CodeBlob *cb = CodeCache::find_blob(entry);
 3460     if (cb) {
 3461       address call = __ trampoline_call(Address(entry, relocInfo::runtime_call_type));
 3462       if (call == NULL) {
 3463         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3464         return;
 3465       }
 3466     } else {
 3467       Label retaddr;
 3468       __ adr(rscratch2, retaddr);
 3469       __ lea(rscratch1, RuntimeAddress(entry));
 3470       // Leave a breadcrumb for JavaFrameAnchor::capture_last_Java_pc()
 3471       __ stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)));
 3472       __ blr(rscratch1);
 3473       __ bind(retaddr);
 3474       __ add(sp, sp, 2 * wordSize);
 3475     }
 3476   %}
 3477 
 3478   enc_class aarch64_enc_rethrow() %{
 3479     C2_MacroAssembler _masm(&amp;cbuf);
 3480     __ far_jump(RuntimeAddress(OptoRuntime::rethrow_stub()));
 3481   %}
 3482 
 3483   enc_class aarch64_enc_ret() %{
 3484     C2_MacroAssembler _masm(&amp;cbuf);
 3485     __ ret(lr);
 3486   %}
 3487 
 3488   enc_class aarch64_enc_tail_call(iRegP jump_target) %{
 3489     C2_MacroAssembler _masm(&amp;cbuf);
 3490     Register target_reg = as_Register($jump_target$$reg);
 3491     __ br(target_reg);
 3492   %}
 3493 
 3494   enc_class aarch64_enc_tail_jmp(iRegP jump_target) %{
 3495     C2_MacroAssembler _masm(&amp;cbuf);
 3496     Register target_reg = as_Register($jump_target$$reg);
 3497     // exception oop should be in r0
 3498     // ret addr has been popped into lr
 3499     // callee expects it in r3
 3500     __ mov(r3, lr);
 3501     __ br(target_reg);
 3502   %}
 3503 
 3504   enc_class aarch64_enc_fast_lock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3505     C2_MacroAssembler _masm(&amp;cbuf);
 3506     Register oop = as_Register($object$$reg);
 3507     Register box = as_Register($box$$reg);
 3508     Register disp_hdr = as_Register($tmp$$reg);
 3509     Register tmp = as_Register($tmp2$$reg);
 3510     Label cont;
 3511     Label object_has_monitor;
 3512     Label cas_failed;
 3513 
 3514     assert_different_registers(oop, box, tmp, disp_hdr);
 3515 
 3516     // Load markWord from object into displaced_header.
 3517     __ ldr(disp_hdr, Address(oop, oopDesc::mark_offset_in_bytes()));
 3518 
 3519     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3520       __ biased_locking_enter(box, oop, disp_hdr, tmp, true, cont);
 3521     }
 3522 
 3523     // Check for existing monitor
 3524     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3525 
 3526     // Set tmp to be (markWord of object | UNLOCK_VALUE).
 3527     __ orr(tmp, disp_hdr, markWord::unlocked_value);
 3528 
 3529     // Initialize the box. (Must happen before we update the object mark!)
 3530     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3531 
 3532     // Compare object markWord with an unlocked value (tmp) and if
 3533     // equal exchange the stack address of our box with object markWord.
 3534     // On failure disp_hdr contains the possibly locked markWord.
 3535     __ cmpxchg(oop, tmp, box, Assembler::xword, /*acquire*/ true,
 3536                /*release*/ true, /*weak*/ false, disp_hdr);
 3537     __ br(Assembler::EQ, cont);
 3538 
 3539     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3540 
 3541     // If the compare-and-exchange succeeded, then we found an unlocked
 3542     // object, will have now locked it will continue at label cont
 3543 
 3544     __ bind(cas_failed);
 3545     // We did not see an unlocked object so try the fast recursive case.
 3546 
 3547     // Check if the owner is self by comparing the value in the
 3548     // markWord of object (disp_hdr) with the stack pointer.
 3549     __ mov(rscratch1, sp);
 3550     __ sub(disp_hdr, disp_hdr, rscratch1);
 3551     __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));
 3552     // If condition is true we are cont and hence we can store 0 as the
 3553     // displaced header in the box, which indicates that it is a recursive lock.
 3554     __ ands(tmp/*==0?*/, disp_hdr, tmp);   // Sets flags for result
 3555     __ str(tmp/*==0, perhaps*/, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3556 
 3557     __ b(cont);
 3558 
 3559     // Handle existing monitor.
 3560     __ bind(object_has_monitor);
 3561 
 3562     // The object&#39;s monitor m is unlocked iff m-&gt;owner == NULL,
 3563     // otherwise m-&gt;owner may contain a thread or a stack address.
 3564     //
 3565     // Try to CAS m-&gt;owner from NULL to current thread.
 3566     __ add(tmp, disp_hdr, (ObjectMonitor::owner_offset_in_bytes()-markWord::monitor_value));
 3567     __ cmpxchg(tmp, zr, rthread, Assembler::xword, /*acquire*/ true,
 3568                /*release*/ true, /*weak*/ false, noreg); // Sets flags for result
 3569 
 3570     // Store a non-null value into the box to avoid looking like a re-entrant
 3571     // lock. The fast-path monitor unlock code checks for
 3572     // markWord::monitor_value so use markWord::unused_mark which has the
 3573     // relevant bit set, and also matches ObjectSynchronizer::enter.
 3574     __ mov(tmp, (address)markWord::unused_mark().value());
 3575     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3576 
 3577     __ bind(cont);
 3578     // flag == EQ indicates success
 3579     // flag == NE indicates failure
 3580   %}
 3581 
 3582   enc_class aarch64_enc_fast_unlock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3583     C2_MacroAssembler _masm(&amp;cbuf);
 3584     Register oop = as_Register($object$$reg);
 3585     Register box = as_Register($box$$reg);
 3586     Register disp_hdr = as_Register($tmp$$reg);
 3587     Register tmp = as_Register($tmp2$$reg);
 3588     Label cont;
 3589     Label object_has_monitor;
 3590 
 3591     assert_different_registers(oop, box, tmp, disp_hdr);
 3592 
 3593     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3594       __ biased_locking_exit(oop, tmp, cont);
 3595     }
 3596 
 3597     // Find the lock address and load the displaced header from the stack.
 3598     __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3599 
 3600     // If the displaced header is 0, we have a recursive unlock.
 3601     __ cmp(disp_hdr, zr);
 3602     __ br(Assembler::EQ, cont);
 3603 
 3604     // Handle existing monitor.
 3605     __ ldr(tmp, Address(oop, oopDesc::mark_offset_in_bytes()));
 3606     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3607 
 3608     // Check if it is still a light weight lock, this is is true if we
 3609     // see the stack address of the basicLock in the markWord of the
 3610     // object.
 3611 
 3612     __ cmpxchg(oop, box, disp_hdr, Assembler::xword, /*acquire*/ false,
 3613                /*release*/ true, /*weak*/ false, tmp);
 3614     __ b(cont);
 3615 
 3616     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3617 
 3618     // Handle existing monitor.
 3619     __ bind(object_has_monitor);
 3620     STATIC_ASSERT(markWord::monitor_value &lt;= INT_MAX);
 3621     __ add(tmp, tmp, -(int)markWord::monitor_value); // monitor
 3622     __ ldr(rscratch1, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3623     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::recursions_offset_in_bytes()));
 3624     __ eor(rscratch1, rscratch1, rthread); // Will be 0 if we are the owner.
 3625     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if there are 0 recursions
 3626     __ cmp(rscratch1, zr); // Sets flags for result
 3627     __ br(Assembler::NE, cont);
 3628 
 3629     __ ldr(rscratch1, Address(tmp, ObjectMonitor::EntryList_offset_in_bytes()));
 3630     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::cxq_offset_in_bytes()));
 3631     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if both are 0.
 3632     __ cmp(rscratch1, zr); // Sets flags for result
 3633     __ cbnz(rscratch1, cont);
 3634     // need a release store here
 3635     __ lea(tmp, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3636     __ stlr(zr, tmp); // set unowned
 3637 
 3638     __ bind(cont);
 3639     // flag == EQ indicates success
 3640     // flag == NE indicates failure
 3641   %}
 3642 
 3643 %}
 3644 
 3645 //----------FRAME--------------------------------------------------------------
 3646 // Definition of frame structure and management information.
 3647 //
 3648 //  S T A C K   L A Y O U T    Allocators stack-slot number
 3649 //                             |   (to get allocators register number
 3650 //  G  Owned by    |        |  v    add OptoReg::stack0())
 3651 //  r   CALLER     |        |
 3652 //  o     |        +--------+      pad to even-align allocators stack-slot
 3653 //  w     V        |  pad0  |        numbers; owned by CALLER
 3654 //  t   -----------+--------+----&gt; Matcher::_in_arg_limit, unaligned
 3655 //  h     ^        |   in   |  5
 3656 //        |        |  args  |  4   Holes in incoming args owned by SELF
 3657 //  |     |        |        |  3
 3658 //  |     |        +--------+
 3659 //  V     |        | old out|      Empty on Intel, window on Sparc
 3660 //        |    old |preserve|      Must be even aligned.
 3661 //        |     SP-+--------+----&gt; Matcher::_old_SP, even aligned
 3662 //        |        |   in   |  3   area for Intel ret address
 3663 //     Owned by    |preserve|      Empty on Sparc.
 3664 //       SELF      +--------+
 3665 //        |        |  pad2  |  2   pad to align old SP
 3666 //        |        +--------+  1
 3667 //        |        | locks  |  0
 3668 //        |        +--------+----&gt; OptoReg::stack0(), even aligned
 3669 //        |        |  pad1  | 11   pad to align new SP
 3670 //        |        +--------+
 3671 //        |        |        | 10
 3672 //        |        | spills |  9   spills
 3673 //        V        |        |  8   (pad0 slot for callee)
 3674 //      -----------+--------+----&gt; Matcher::_out_arg_limit, unaligned
 3675 //        ^        |  out   |  7
 3676 //        |        |  args  |  6   Holes in outgoing args owned by CALLEE
 3677 //     Owned by    +--------+
 3678 //      CALLEE     | new out|  6   Empty on Intel, window on Sparc
 3679 //        |    new |preserve|      Must be even-aligned.
 3680 //        |     SP-+--------+----&gt; Matcher::_new_SP, even aligned
 3681 //        |        |        |
 3682 //
 3683 // Note 1: Only region 8-11 is determined by the allocator.  Region 0-5 is
 3684 //         known from SELF&#39;s arguments and the Java calling convention.
 3685 //         Region 6-7 is determined per call site.
 3686 // Note 2: If the calling convention leaves holes in the incoming argument
 3687 //         area, those holes are owned by SELF.  Holes in the outgoing area
 3688 //         are owned by the CALLEE.  Holes should not be nessecary in the
 3689 //         incoming area, as the Java calling convention is completely under
 3690 //         the control of the AD file.  Doubles can be sorted and packed to
 3691 //         avoid holes.  Holes in the outgoing arguments may be nessecary for
 3692 //         varargs C calling conventions.
 3693 // Note 3: Region 0-3 is even aligned, with pad2 as needed.  Region 3-5 is
 3694 //         even aligned with pad0 as needed.
 3695 //         Region 6 is even aligned.  Region 6-7 is NOT even aligned;
 3696 //           (the latter is true on Intel but is it false on AArch64?)
 3697 //         region 6-11 is even aligned; it may be padded out more so that
 3698 //         the region from SP to FP meets the minimum stack alignment.
 3699 // Note 4: For I2C adapters, the incoming FP may not meet the minimum stack
 3700 //         alignment.  Region 11, pad1, may be dynamically extended so that
 3701 //         SP meets the minimum alignment.
 3702 
 3703 frame %{
 3704   // What direction does stack grow in (assumed to be same for C &amp; Java)
 3705   stack_direction(TOWARDS_LOW);
 3706 
 3707   // These three registers define part of the calling convention
 3708   // between compiled code and the interpreter.
 3709 
 3710   // Inline Cache Register or methodOop for I2C.
 3711   inline_cache_reg(R12);
 3712 
 3713   // Method Oop Register when calling interpreter.
 3714   interpreter_method_oop_reg(R12);
 3715 
 3716   // Number of stack slots consumed by locking an object
 3717   sync_stack_slots(2);
 3718 
 3719   // Compiled code&#39;s Frame Pointer
 3720   frame_pointer(R31);
 3721 
 3722   // Interpreter stores its frame pointer in a register which is
 3723   // stored to the stack by I2CAdaptors.
 3724   // I2CAdaptors convert from interpreted java to compiled java.
 3725   interpreter_frame_pointer(R29);
 3726 
 3727   // Stack alignment requirement
 3728   stack_alignment(StackAlignmentInBytes); // Alignment size in bytes (128-bit -&gt; 16 bytes)
 3729 
 3730   // Number of stack slots between incoming argument block and the start of
 3731   // a new frame.  The PROLOG must add this many slots to the stack.  The
 3732   // EPILOG must remove this many slots. aarch64 needs two slots for
 3733   // return address and fp.
 3734   // TODO think this is correct but check
 3735   in_preserve_stack_slots(4);
 3736 
 3737   // Number of outgoing stack slots killed above the out_preserve_stack_slots
 3738   // for calls to C.  Supports the var-args backing area for register parms.
 3739   varargs_C_out_slots_killed(frame::arg_reg_save_area_bytes/BytesPerInt);
 3740 
 3741   // The after-PROLOG location of the return address.  Location of
 3742   // return address specifies a type (REG or STACK) and a number
 3743   // representing the register number (i.e. - use a register name) or
 3744   // stack slot.
 3745   // Ret Addr is on stack in slot 0 if no locks or verification or alignment.
 3746   // Otherwise, it is above the locks and verification slot and alignment word
 3747   // TODO this may well be correct but need to check why that - 2 is there
 3748   // ppc port uses 0 but we definitely need to allow for fixed_slots
 3749   // which folds in the space used for monitors
 3750   return_addr(STACK - 2 +
 3751               align_up((Compile::current()-&gt;in_preserve_stack_slots() +
 3752                         Compile::current()-&gt;fixed_slots()),
 3753                        stack_alignment_in_slots()));
 3754 
 3755   // Body of function which returns an integer array locating
 3756   // arguments either in registers or in stack slots.  Passed an array
 3757   // of ideal registers called &quot;sig&quot; and a &quot;length&quot; count.  Stack-slot
 3758   // offsets are based on outgoing arguments, i.e. a CALLER setting up
 3759   // arguments for a CALLEE.  Incoming stack arguments are
 3760   // automatically biased by the preserve_stack_slots field above.
 3761 
 3762   calling_convention
 3763   %{
 3764     // No difference between ingoing/outgoing just pass false
 3765     SharedRuntime::java_calling_convention(sig_bt, regs, length, false);
 3766   %}
 3767 
 3768   c_calling_convention
 3769   %{
 3770     // This is obviously always outgoing
 3771     (void) SharedRuntime::c_calling_convention(sig_bt, regs, NULL, length);
 3772   %}
 3773 
 3774   // Location of compiled Java return values.  Same as C for now.
 3775   return_value
 3776   %{
 3777     // TODO do we allow ideal_reg == Op_RegN???
 3778     assert(ideal_reg &gt;= Op_RegI &amp;&amp; ideal_reg &lt;= Op_RegL,
 3779            &quot;only return normal values&quot;);
 3780 
 3781     static const int lo[Op_RegL + 1] = { // enum name
 3782       0,                                 // Op_Node
 3783       0,                                 // Op_Set
 3784       R0_num,                            // Op_RegN
 3785       R0_num,                            // Op_RegI
 3786       R0_num,                            // Op_RegP
 3787       V0_num,                            // Op_RegF
 3788       V0_num,                            // Op_RegD
 3789       R0_num                             // Op_RegL
 3790     };
 3791 
 3792     static const int hi[Op_RegL + 1] = { // enum name
 3793       0,                                 // Op_Node
 3794       0,                                 // Op_Set
 3795       OptoReg::Bad,                      // Op_RegN
 3796       OptoReg::Bad,                      // Op_RegI
 3797       R0_H_num,                          // Op_RegP
 3798       OptoReg::Bad,                      // Op_RegF
 3799       V0_H_num,                          // Op_RegD
 3800       R0_H_num                           // Op_RegL
 3801     };
 3802 
 3803     return OptoRegPair(hi[ideal_reg], lo[ideal_reg]);
 3804   %}
 3805 %}
 3806 
 3807 //----------ATTRIBUTES---------------------------------------------------------
 3808 //----------Operand Attributes-------------------------------------------------
 3809 op_attrib op_cost(1);        // Required cost attribute
 3810 
 3811 //----------Instruction Attributes---------------------------------------------
 3812 ins_attrib ins_cost(INSN_COST); // Required cost attribute
 3813 ins_attrib ins_size(32);        // Required size attribute (in bits)
 3814 ins_attrib ins_short_branch(0); // Required flag: is this instruction
 3815                                 // a non-matching short branch variant
 3816                                 // of some long branch?
 3817 ins_attrib ins_alignment(4);    // Required alignment attribute (must
 3818                                 // be a power of 2) specifies the
 3819                                 // alignment that some part of the
 3820                                 // instruction (not necessarily the
 3821                                 // start) requires.  If &gt; 1, a
 3822                                 // compute_padding() function must be
 3823                                 // provided for the instruction
 3824 
 3825 //----------OPERANDS-----------------------------------------------------------
 3826 // Operand definitions must precede instruction definitions for correct parsing
 3827 // in the ADLC because operands constitute user defined types which are used in
 3828 // instruction definitions.
 3829 
 3830 //----------Simple Operands----------------------------------------------------
 3831 
 3832 // Integer operands 32 bit
 3833 // 32 bit immediate
 3834 operand immI()
 3835 %{
 3836   match(ConI);
 3837 
 3838   op_cost(0);
 3839   format %{ %}
 3840   interface(CONST_INTER);
 3841 %}
 3842 
 3843 // 32 bit zero
 3844 operand immI0()
 3845 %{
 3846   predicate(n-&gt;get_int() == 0);
 3847   match(ConI);
 3848 
 3849   op_cost(0);
 3850   format %{ %}
 3851   interface(CONST_INTER);
 3852 %}
 3853 
 3854 // 32 bit unit increment
 3855 operand immI_1()
 3856 %{
 3857   predicate(n-&gt;get_int() == 1);
 3858   match(ConI);
 3859 
 3860   op_cost(0);
 3861   format %{ %}
 3862   interface(CONST_INTER);
 3863 %}
 3864 
 3865 // 32 bit unit decrement
 3866 operand immI_M1()
 3867 %{
 3868   predicate(n-&gt;get_int() == -1);
 3869   match(ConI);
 3870 
 3871   op_cost(0);
 3872   format %{ %}
 3873   interface(CONST_INTER);
 3874 %}
 3875 
 3876 // Shift values for add/sub extension shift
 3877 operand immIExt()
 3878 %{
 3879   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 4));
 3880   match(ConI);
 3881 
 3882   op_cost(0);
 3883   format %{ %}
 3884   interface(CONST_INTER);
 3885 %}
 3886 
 3887 operand immI_le_4()
 3888 %{
 3889   predicate(n-&gt;get_int() &lt;= 4);
 3890   match(ConI);
 3891 
 3892   op_cost(0);
 3893   format %{ %}
 3894   interface(CONST_INTER);
 3895 %}
 3896 
 3897 operand immI_31()
 3898 %{
 3899   predicate(n-&gt;get_int() == 31);
 3900   match(ConI);
 3901 
 3902   op_cost(0);
 3903   format %{ %}
 3904   interface(CONST_INTER);
 3905 %}
 3906 
 3907 operand immI_8()
 3908 %{
 3909   predicate(n-&gt;get_int() == 8);
 3910   match(ConI);
 3911 
 3912   op_cost(0);
 3913   format %{ %}
 3914   interface(CONST_INTER);
 3915 %}
 3916 
 3917 operand immI_16()
 3918 %{
 3919   predicate(n-&gt;get_int() == 16);
 3920   match(ConI);
 3921 
 3922   op_cost(0);
 3923   format %{ %}
 3924   interface(CONST_INTER);
 3925 %}
 3926 
 3927 operand immI_24()
 3928 %{
 3929   predicate(n-&gt;get_int() == 24);
 3930   match(ConI);
 3931 
 3932   op_cost(0);
 3933   format %{ %}
 3934   interface(CONST_INTER);
 3935 %}
 3936 
 3937 operand immI_32()
 3938 %{
 3939   predicate(n-&gt;get_int() == 32);
 3940   match(ConI);
 3941 
 3942   op_cost(0);
 3943   format %{ %}
 3944   interface(CONST_INTER);
 3945 %}
 3946 
 3947 operand immI_48()
 3948 %{
 3949   predicate(n-&gt;get_int() == 48);
 3950   match(ConI);
 3951 
 3952   op_cost(0);
 3953   format %{ %}
 3954   interface(CONST_INTER);
 3955 %}
 3956 
 3957 operand immI_56()
 3958 %{
 3959   predicate(n-&gt;get_int() == 56);
 3960   match(ConI);
 3961 
 3962   op_cost(0);
 3963   format %{ %}
 3964   interface(CONST_INTER);
 3965 %}
 3966 
 3967 operand immI_63()
 3968 %{
 3969   predicate(n-&gt;get_int() == 63);
 3970   match(ConI);
 3971 
 3972   op_cost(0);
 3973   format %{ %}
 3974   interface(CONST_INTER);
 3975 %}
 3976 
 3977 operand immI_64()
 3978 %{
 3979   predicate(n-&gt;get_int() == 64);
 3980   match(ConI);
 3981 
 3982   op_cost(0);
 3983   format %{ %}
 3984   interface(CONST_INTER);
 3985 %}
 3986 
 3987 operand immI_255()
 3988 %{
 3989   predicate(n-&gt;get_int() == 255);
 3990   match(ConI);
 3991 
 3992   op_cost(0);
 3993   format %{ %}
 3994   interface(CONST_INTER);
 3995 %}
 3996 
 3997 operand immI_65535()
 3998 %{
 3999   predicate(n-&gt;get_int() == 65535);
 4000   match(ConI);
 4001 
 4002   op_cost(0);
 4003   format %{ %}
 4004   interface(CONST_INTER);
 4005 %}
 4006 
 4007 operand immL_255()
 4008 %{
 4009   predicate(n-&gt;get_long() == 255L);
 4010   match(ConL);
 4011 
 4012   op_cost(0);
 4013   format %{ %}
 4014   interface(CONST_INTER);
 4015 %}
 4016 
 4017 operand immL_65535()
 4018 %{
 4019   predicate(n-&gt;get_long() == 65535L);
 4020   match(ConL);
 4021 
 4022   op_cost(0);
 4023   format %{ %}
 4024   interface(CONST_INTER);
 4025 %}
 4026 
 4027 operand immL_4294967295()
 4028 %{
 4029   predicate(n-&gt;get_long() == 4294967295L);
 4030   match(ConL);
 4031 
 4032   op_cost(0);
 4033   format %{ %}
 4034   interface(CONST_INTER);
 4035 %}
 4036 
 4037 operand immL_bitmask()
 4038 %{
 4039   predicate((n-&gt;get_long() != 0)
 4040             &amp;&amp; ((n-&gt;get_long() &amp; 0xc000000000000000l) == 0)
 4041             &amp;&amp; is_power_of_2(n-&gt;get_long() + 1));
 4042   match(ConL);
 4043 
 4044   op_cost(0);
 4045   format %{ %}
 4046   interface(CONST_INTER);
 4047 %}
 4048 
 4049 operand immI_bitmask()
 4050 %{
 4051   predicate((n-&gt;get_int() != 0)
 4052             &amp;&amp; ((n-&gt;get_int() &amp; 0xc0000000) == 0)
 4053             &amp;&amp; is_power_of_2(n-&gt;get_int() + 1));
 4054   match(ConI);
 4055 
 4056   op_cost(0);
 4057   format %{ %}
 4058   interface(CONST_INTER);
 4059 %}
 4060 
 4061 // Scale values for scaled offset addressing modes (up to long but not quad)
 4062 operand immIScale()
 4063 %{
 4064   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 3));
 4065   match(ConI);
 4066 
 4067   op_cost(0);
 4068   format %{ %}
 4069   interface(CONST_INTER);
 4070 %}
 4071 
 4072 // 26 bit signed offset -- for pc-relative branches
 4073 operand immI26()
 4074 %{
 4075   predicate(((-(1 &lt;&lt; 25)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 25)));
 4076   match(ConI);
 4077 
 4078   op_cost(0);
 4079   format %{ %}
 4080   interface(CONST_INTER);
 4081 %}
 4082 
 4083 // 19 bit signed offset -- for pc-relative loads
 4084 operand immI19()
 4085 %{
 4086   predicate(((-(1 &lt;&lt; 18)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 18)));
 4087   match(ConI);
 4088 
 4089   op_cost(0);
 4090   format %{ %}
 4091   interface(CONST_INTER);
 4092 %}
 4093 
 4094 // 12 bit unsigned offset -- for base plus immediate loads
 4095 operand immIU12()
 4096 %{
 4097   predicate((0 &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 12)));
 4098   match(ConI);
 4099 
 4100   op_cost(0);
 4101   format %{ %}
 4102   interface(CONST_INTER);
 4103 %}
 4104 
 4105 operand immLU12()
 4106 %{
 4107   predicate((0 &lt;= n-&gt;get_long()) &amp;&amp; (n-&gt;get_long() &lt; (1 &lt;&lt; 12)));
 4108   match(ConL);
 4109 
 4110   op_cost(0);
 4111   format %{ %}
 4112   interface(CONST_INTER);
 4113 %}
 4114 
 4115 // Offset for scaled or unscaled immediate loads and stores
 4116 operand immIOffset()
 4117 %{
 4118   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4119   match(ConI);
 4120 
 4121   op_cost(0);
 4122   format %{ %}
 4123   interface(CONST_INTER);
 4124 %}
 4125 
 4126 operand immIOffset1()
 4127 %{
 4128   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4129   match(ConI);
 4130 
 4131   op_cost(0);
 4132   format %{ %}
 4133   interface(CONST_INTER);
 4134 %}
 4135 
 4136 operand immIOffset2()
 4137 %{
 4138   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 1));
 4139   match(ConI);
 4140 
 4141   op_cost(0);
 4142   format %{ %}
 4143   interface(CONST_INTER);
 4144 %}
 4145 
 4146 operand immIOffset4()
 4147 %{
 4148   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 2));
 4149   match(ConI);
 4150 
 4151   op_cost(0);
 4152   format %{ %}
 4153   interface(CONST_INTER);
 4154 %}
 4155 
 4156 operand immIOffset8()
 4157 %{
 4158   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 3));
 4159   match(ConI);
 4160 
 4161   op_cost(0);
 4162   format %{ %}
 4163   interface(CONST_INTER);
 4164 %}
 4165 
 4166 operand immIOffset16()
 4167 %{
 4168   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 4));
 4169   match(ConI);
 4170 
 4171   op_cost(0);
 4172   format %{ %}
 4173   interface(CONST_INTER);
 4174 %}
 4175 
 4176 operand immLoffset()
 4177 %{
 4178   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4179   match(ConL);
 4180 
 4181   op_cost(0);
 4182   format %{ %}
 4183   interface(CONST_INTER);
 4184 %}
 4185 
 4186 operand immLoffset1()
 4187 %{
 4188   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4189   match(ConL);
 4190 
 4191   op_cost(0);
 4192   format %{ %}
 4193   interface(CONST_INTER);
 4194 %}
 4195 
 4196 operand immLoffset2()
 4197 %{
 4198   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 1));
 4199   match(ConL);
 4200 
 4201   op_cost(0);
 4202   format %{ %}
 4203   interface(CONST_INTER);
 4204 %}
 4205 
 4206 operand immLoffset4()
 4207 %{
 4208   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 2));
 4209   match(ConL);
 4210 
 4211   op_cost(0);
 4212   format %{ %}
 4213   interface(CONST_INTER);
 4214 %}
 4215 
 4216 operand immLoffset8()
 4217 %{
 4218   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 3));
 4219   match(ConL);
 4220 
 4221   op_cost(0);
 4222   format %{ %}
 4223   interface(CONST_INTER);
 4224 %}
 4225 
 4226 operand immLoffset16()
 4227 %{
 4228   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 4));
 4229   match(ConL);
 4230 
 4231   op_cost(0);
 4232   format %{ %}
 4233   interface(CONST_INTER);
 4234 %}
 4235 
 4236 // 32 bit integer valid for add sub immediate
 4237 operand immIAddSub()
 4238 %{
 4239   predicate(Assembler::operand_valid_for_add_sub_immediate((int64_t)n-&gt;get_int()));
 4240   match(ConI);
 4241   op_cost(0);
 4242   format %{ %}
 4243   interface(CONST_INTER);
 4244 %}
 4245 
 4246 // 32 bit unsigned integer valid for logical immediate
 4247 // TODO -- check this is right when e.g the mask is 0x80000000
 4248 operand immILog()
 4249 %{
 4250   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/true, (uint64_t)n-&gt;get_int()));
 4251   match(ConI);
 4252 
 4253   op_cost(0);
 4254   format %{ %}
 4255   interface(CONST_INTER);
 4256 %}
 4257 
 4258 // Integer operands 64 bit
 4259 // 64 bit immediate
 4260 operand immL()
 4261 %{
 4262   match(ConL);
 4263 
 4264   op_cost(0);
 4265   format %{ %}
 4266   interface(CONST_INTER);
 4267 %}
 4268 
 4269 // 64 bit zero
 4270 operand immL0()
 4271 %{
 4272   predicate(n-&gt;get_long() == 0);
 4273   match(ConL);
 4274 
 4275   op_cost(0);
 4276   format %{ %}
 4277   interface(CONST_INTER);
 4278 %}
 4279 
 4280 // 64 bit unit increment
 4281 operand immL_1()
 4282 %{
 4283   predicate(n-&gt;get_long() == 1);
 4284   match(ConL);
 4285 
 4286   op_cost(0);
 4287   format %{ %}
 4288   interface(CONST_INTER);
 4289 %}
 4290 
 4291 // 64 bit unit decrement
 4292 operand immL_M1()
 4293 %{
 4294   predicate(n-&gt;get_long() == -1);
 4295   match(ConL);
 4296 
 4297   op_cost(0);
 4298   format %{ %}
 4299   interface(CONST_INTER);
 4300 %}
 4301 
 4302 // 32 bit offset of pc in thread anchor
 4303 
 4304 operand immL_pc_off()
 4305 %{
 4306   predicate(n-&gt;get_long() == in_bytes(JavaThread::frame_anchor_offset()) +
 4307                              in_bytes(JavaFrameAnchor::last_Java_pc_offset()));
 4308   match(ConL);
 4309 
 4310   op_cost(0);
 4311   format %{ %}
 4312   interface(CONST_INTER);
 4313 %}
 4314 
 4315 // 64 bit integer valid for add sub immediate
 4316 operand immLAddSub()
 4317 %{
 4318   predicate(Assembler::operand_valid_for_add_sub_immediate(n-&gt;get_long()));
 4319   match(ConL);
 4320   op_cost(0);
 4321   format %{ %}
 4322   interface(CONST_INTER);
 4323 %}
 4324 
 4325 // 64 bit integer valid for logical immediate
 4326 operand immLLog()
 4327 %{
 4328   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/false, (uint64_t)n-&gt;get_long()));
 4329   match(ConL);
 4330   op_cost(0);
 4331   format %{ %}
 4332   interface(CONST_INTER);
 4333 %}
 4334 
 4335 // Long Immediate: low 32-bit mask
 4336 operand immL_32bits()
 4337 %{
 4338   predicate(n-&gt;get_long() == 0xFFFFFFFFL);
 4339   match(ConL);
 4340   op_cost(0);
 4341   format %{ %}
 4342   interface(CONST_INTER);
 4343 %}
 4344 
 4345 // Pointer operands
 4346 // Pointer Immediate
 4347 operand immP()
 4348 %{
 4349   match(ConP);
 4350 
 4351   op_cost(0);
 4352   format %{ %}
 4353   interface(CONST_INTER);
 4354 %}
 4355 
 4356 // NULL Pointer Immediate
 4357 operand immP0()
 4358 %{
 4359   predicate(n-&gt;get_ptr() == 0);
 4360   match(ConP);
 4361 
 4362   op_cost(0);
 4363   format %{ %}
 4364   interface(CONST_INTER);
 4365 %}
 4366 
 4367 // Pointer Immediate One
 4368 // this is used in object initialization (initial object header)
 4369 operand immP_1()
 4370 %{
 4371   predicate(n-&gt;get_ptr() == 1);
 4372   match(ConP);
 4373 
 4374   op_cost(0);
 4375   format %{ %}
 4376   interface(CONST_INTER);
 4377 %}
 4378 
 4379 // Card Table Byte Map Base
 4380 operand immByteMapBase()
 4381 %{
 4382   // Get base of card map
 4383   predicate(BarrierSet::barrier_set()-&gt;is_a(BarrierSet::CardTableBarrierSet) &amp;&amp;
 4384             (CardTable::CardValue*)n-&gt;get_ptr() == ((CardTableBarrierSet*)(BarrierSet::barrier_set()))-&gt;card_table()-&gt;byte_map_base());
 4385   match(ConP);
 4386 
 4387   op_cost(0);
 4388   format %{ %}
 4389   interface(CONST_INTER);
 4390 %}
 4391 
 4392 // Pointer Immediate Minus One
 4393 // this is used when we want to write the current PC to the thread anchor
 4394 operand immP_M1()
 4395 %{
 4396   predicate(n-&gt;get_ptr() == -1);
 4397   match(ConP);
 4398 
 4399   op_cost(0);
 4400   format %{ %}
 4401   interface(CONST_INTER);
 4402 %}
 4403 
 4404 // Pointer Immediate Minus Two
 4405 // this is used when we want to write the current PC to the thread anchor
 4406 operand immP_M2()
 4407 %{
 4408   predicate(n-&gt;get_ptr() == -2);
 4409   match(ConP);
 4410 
 4411   op_cost(0);
 4412   format %{ %}
 4413   interface(CONST_INTER);
 4414 %}
 4415 
 4416 // Float and Double operands
 4417 // Double Immediate
 4418 operand immD()
 4419 %{
 4420   match(ConD);
 4421   op_cost(0);
 4422   format %{ %}
 4423   interface(CONST_INTER);
 4424 %}
 4425 
 4426 // Double Immediate: +0.0d
 4427 operand immD0()
 4428 %{
 4429   predicate(jlong_cast(n-&gt;getd()) == 0);
 4430   match(ConD);
 4431 
 4432   op_cost(0);
 4433   format %{ %}
 4434   interface(CONST_INTER);
 4435 %}
 4436 
 4437 // constant &#39;double +0.0&#39;.
 4438 operand immDPacked()
 4439 %{
 4440   predicate(Assembler::operand_valid_for_float_immediate(n-&gt;getd()));
 4441   match(ConD);
 4442   op_cost(0);
 4443   format %{ %}
 4444   interface(CONST_INTER);
 4445 %}
 4446 
 4447 // Float Immediate
 4448 operand immF()
 4449 %{
 4450   match(ConF);
 4451   op_cost(0);
 4452   format %{ %}
 4453   interface(CONST_INTER);
 4454 %}
 4455 
 4456 // Float Immediate: +0.0f.
 4457 operand immF0()
 4458 %{
 4459   predicate(jint_cast(n-&gt;getf()) == 0);
 4460   match(ConF);
 4461 
 4462   op_cost(0);
 4463   format %{ %}
 4464   interface(CONST_INTER);
 4465 %}
 4466 
 4467 //
 4468 operand immFPacked()
 4469 %{
 4470   predicate(Assembler::operand_valid_for_float_immediate((double)n-&gt;getf()));
 4471   match(ConF);
 4472   op_cost(0);
 4473   format %{ %}
 4474   interface(CONST_INTER);
 4475 %}
 4476 
 4477 // Narrow pointer operands
 4478 // Narrow Pointer Immediate
 4479 operand immN()
 4480 %{
 4481   match(ConN);
 4482 
 4483   op_cost(0);
 4484   format %{ %}
 4485   interface(CONST_INTER);
 4486 %}
 4487 
 4488 // Narrow NULL Pointer Immediate
 4489 operand immN0()
 4490 %{
 4491   predicate(n-&gt;get_narrowcon() == 0);
 4492   match(ConN);
 4493 
 4494   op_cost(0);
 4495   format %{ %}
 4496   interface(CONST_INTER);
 4497 %}
 4498 
 4499 operand immNKlass()
 4500 %{
 4501   match(ConNKlass);
 4502 
 4503   op_cost(0);
 4504   format %{ %}
 4505   interface(CONST_INTER);
 4506 %}
 4507 
 4508 // Integer 32 bit Register Operands
 4509 // Integer 32 bitRegister (excludes SP)
 4510 operand iRegI()
 4511 %{
 4512   constraint(ALLOC_IN_RC(any_reg32));
 4513   match(RegI);
 4514   match(iRegINoSp);
 4515   op_cost(0);
 4516   format %{ %}
 4517   interface(REG_INTER);
 4518 %}
 4519 
 4520 // Integer 32 bit Register not Special
 4521 operand iRegINoSp()
 4522 %{
 4523   constraint(ALLOC_IN_RC(no_special_reg32));
 4524   match(RegI);
 4525   op_cost(0);
 4526   format %{ %}
 4527   interface(REG_INTER);
 4528 %}
 4529 
 4530 // Integer 64 bit Register Operands
 4531 // Integer 64 bit Register (includes SP)
 4532 operand iRegL()
 4533 %{
 4534   constraint(ALLOC_IN_RC(any_reg));
 4535   match(RegL);
 4536   match(iRegLNoSp);
 4537   op_cost(0);
 4538   format %{ %}
 4539   interface(REG_INTER);
 4540 %}
 4541 
 4542 // Integer 64 bit Register not Special
 4543 operand iRegLNoSp()
 4544 %{
 4545   constraint(ALLOC_IN_RC(no_special_reg));
 4546   match(RegL);
 4547   match(iRegL_R0);
 4548   format %{ %}
 4549   interface(REG_INTER);
 4550 %}
 4551 
 4552 // Pointer Register Operands
 4553 // Pointer Register
 4554 operand iRegP()
 4555 %{
 4556   constraint(ALLOC_IN_RC(ptr_reg));
 4557   match(RegP);
 4558   match(iRegPNoSp);
 4559   match(iRegP_R0);
 4560   //match(iRegP_R2);
 4561   //match(iRegP_R4);
 4562   //match(iRegP_R5);
 4563   match(thread_RegP);
 4564   op_cost(0);
 4565   format %{ %}
 4566   interface(REG_INTER);
 4567 %}
 4568 
 4569 // Pointer 64 bit Register not Special
 4570 operand iRegPNoSp()
 4571 %{
 4572   constraint(ALLOC_IN_RC(no_special_ptr_reg));
 4573   match(RegP);
 4574   // match(iRegP);
 4575   // match(iRegP_R0);
 4576   // match(iRegP_R2);
 4577   // match(iRegP_R4);
 4578   // match(iRegP_R5);
 4579   // match(thread_RegP);
 4580   op_cost(0);
 4581   format %{ %}
 4582   interface(REG_INTER);
 4583 %}
 4584 
 4585 // Pointer 64 bit Register R0 only
 4586 operand iRegP_R0()
 4587 %{
 4588   constraint(ALLOC_IN_RC(r0_reg));
 4589   match(RegP);
 4590   // match(iRegP);
 4591   match(iRegPNoSp);
 4592   op_cost(0);
 4593   format %{ %}
 4594   interface(REG_INTER);
 4595 %}
 4596 
 4597 // Pointer 64 bit Register R1 only
 4598 operand iRegP_R1()
 4599 %{
 4600   constraint(ALLOC_IN_RC(r1_reg));
 4601   match(RegP);
 4602   // match(iRegP);
 4603   match(iRegPNoSp);
 4604   op_cost(0);
 4605   format %{ %}
 4606   interface(REG_INTER);
 4607 %}
 4608 
 4609 // Pointer 64 bit Register R2 only
 4610 operand iRegP_R2()
 4611 %{
 4612   constraint(ALLOC_IN_RC(r2_reg));
 4613   match(RegP);
 4614   // match(iRegP);
 4615   match(iRegPNoSp);
 4616   op_cost(0);
 4617   format %{ %}
 4618   interface(REG_INTER);
 4619 %}
 4620 
 4621 // Pointer 64 bit Register R3 only
 4622 operand iRegP_R3()
 4623 %{
 4624   constraint(ALLOC_IN_RC(r3_reg));
 4625   match(RegP);
 4626   // match(iRegP);
 4627   match(iRegPNoSp);
 4628   op_cost(0);
 4629   format %{ %}
 4630   interface(REG_INTER);
 4631 %}
 4632 
 4633 // Pointer 64 bit Register R4 only
 4634 operand iRegP_R4()
 4635 %{
 4636   constraint(ALLOC_IN_RC(r4_reg));
 4637   match(RegP);
 4638   // match(iRegP);
 4639   match(iRegPNoSp);
 4640   op_cost(0);
 4641   format %{ %}
 4642   interface(REG_INTER);
 4643 %}
 4644 
 4645 // Pointer 64 bit Register R5 only
 4646 operand iRegP_R5()
 4647 %{
 4648   constraint(ALLOC_IN_RC(r5_reg));
 4649   match(RegP);
 4650   // match(iRegP);
 4651   match(iRegPNoSp);
 4652   op_cost(0);
 4653   format %{ %}
 4654   interface(REG_INTER);
 4655 %}
 4656 
 4657 // Pointer 64 bit Register R10 only
 4658 operand iRegP_R10()
 4659 %{
 4660   constraint(ALLOC_IN_RC(r10_reg));
 4661   match(RegP);
 4662   // match(iRegP);
 4663   match(iRegPNoSp);
 4664   op_cost(0);
 4665   format %{ %}
 4666   interface(REG_INTER);
 4667 %}
 4668 
 4669 // Long 64 bit Register R0 only
 4670 operand iRegL_R0()
 4671 %{
 4672   constraint(ALLOC_IN_RC(r0_reg));
 4673   match(RegL);
 4674   match(iRegLNoSp);
 4675   op_cost(0);
 4676   format %{ %}
 4677   interface(REG_INTER);
 4678 %}
 4679 
 4680 // Long 64 bit Register R2 only
 4681 operand iRegL_R2()
 4682 %{
 4683   constraint(ALLOC_IN_RC(r2_reg));
 4684   match(RegL);
 4685   match(iRegLNoSp);
 4686   op_cost(0);
 4687   format %{ %}
 4688   interface(REG_INTER);
 4689 %}
 4690 
 4691 // Long 64 bit Register R3 only
 4692 operand iRegL_R3()
 4693 %{
 4694   constraint(ALLOC_IN_RC(r3_reg));
 4695   match(RegL);
 4696   match(iRegLNoSp);
 4697   op_cost(0);
 4698   format %{ %}
 4699   interface(REG_INTER);
 4700 %}
 4701 
 4702 // Long 64 bit Register R11 only
 4703 operand iRegL_R11()
 4704 %{
 4705   constraint(ALLOC_IN_RC(r11_reg));
 4706   match(RegL);
 4707   match(iRegLNoSp);
 4708   op_cost(0);
 4709   format %{ %}
 4710   interface(REG_INTER);
 4711 %}
 4712 
 4713 // Pointer 64 bit Register FP only
 4714 operand iRegP_FP()
 4715 %{
 4716   constraint(ALLOC_IN_RC(fp_reg));
 4717   match(RegP);
 4718   // match(iRegP);
 4719   op_cost(0);
 4720   format %{ %}
 4721   interface(REG_INTER);
 4722 %}
 4723 
 4724 // Register R0 only
 4725 operand iRegI_R0()
 4726 %{
 4727   constraint(ALLOC_IN_RC(int_r0_reg));
 4728   match(RegI);
 4729   match(iRegINoSp);
 4730   op_cost(0);
 4731   format %{ %}
 4732   interface(REG_INTER);
 4733 %}
 4734 
 4735 // Register R2 only
 4736 operand iRegI_R2()
 4737 %{
 4738   constraint(ALLOC_IN_RC(int_r2_reg));
 4739   match(RegI);
 4740   match(iRegINoSp);
 4741   op_cost(0);
 4742   format %{ %}
 4743   interface(REG_INTER);
 4744 %}
 4745 
 4746 // Register R3 only
 4747 operand iRegI_R3()
 4748 %{
 4749   constraint(ALLOC_IN_RC(int_r3_reg));
 4750   match(RegI);
 4751   match(iRegINoSp);
 4752   op_cost(0);
 4753   format %{ %}
 4754   interface(REG_INTER);
 4755 %}
 4756 
 4757 
 4758 // Register R4 only
 4759 operand iRegI_R4()
 4760 %{
 4761   constraint(ALLOC_IN_RC(int_r4_reg));
 4762   match(RegI);
 4763   match(iRegINoSp);
 4764   op_cost(0);
 4765   format %{ %}
 4766   interface(REG_INTER);
 4767 %}
 4768 
 4769 
 4770 // Pointer Register Operands
 4771 // Narrow Pointer Register
 4772 operand iRegN()
 4773 %{
 4774   constraint(ALLOC_IN_RC(any_reg32));
 4775   match(RegN);
 4776   match(iRegNNoSp);
 4777   op_cost(0);
 4778   format %{ %}
 4779   interface(REG_INTER);
 4780 %}
 4781 
 4782 operand iRegN_R0()
 4783 %{
 4784   constraint(ALLOC_IN_RC(r0_reg));
 4785   match(iRegN);
 4786   op_cost(0);
 4787   format %{ %}
 4788   interface(REG_INTER);
 4789 %}
 4790 
 4791 operand iRegN_R2()
 4792 %{
 4793   constraint(ALLOC_IN_RC(r2_reg));
 4794   match(iRegN);
 4795   op_cost(0);
 4796   format %{ %}
 4797   interface(REG_INTER);
 4798 %}
 4799 
 4800 operand iRegN_R3()
 4801 %{
 4802   constraint(ALLOC_IN_RC(r3_reg));
 4803   match(iRegN);
 4804   op_cost(0);
 4805   format %{ %}
 4806   interface(REG_INTER);
 4807 %}
 4808 
 4809 // Integer 64 bit Register not Special
 4810 operand iRegNNoSp()
 4811 %{
 4812   constraint(ALLOC_IN_RC(no_special_reg32));
 4813   match(RegN);
 4814   op_cost(0);
 4815   format %{ %}
 4816   interface(REG_INTER);
 4817 %}
 4818 
 4819 // heap base register -- used for encoding immN0
 4820 
 4821 operand iRegIHeapbase()
 4822 %{
 4823   constraint(ALLOC_IN_RC(heapbase_reg));
 4824   match(RegI);
 4825   op_cost(0);
 4826   format %{ %}
 4827   interface(REG_INTER);
 4828 %}
 4829 
 4830 // Float Register
 4831 // Float register operands
 4832 operand vRegF()
 4833 %{
 4834   constraint(ALLOC_IN_RC(float_reg));
 4835   match(RegF);
 4836 
 4837   op_cost(0);
 4838   format %{ %}
 4839   interface(REG_INTER);
 4840 %}
 4841 
 4842 // Double Register
 4843 // Double register operands
 4844 operand vRegD()
 4845 %{
 4846   constraint(ALLOC_IN_RC(double_reg));
 4847   match(RegD);
 4848 
 4849   op_cost(0);
 4850   format %{ %}
 4851   interface(REG_INTER);
 4852 %}
 4853 
 4854 operand vecD()
 4855 %{
 4856   constraint(ALLOC_IN_RC(vectord_reg));
 4857   match(VecD);
 4858 
 4859   op_cost(0);
 4860   format %{ %}
 4861   interface(REG_INTER);
 4862 %}
 4863 
 4864 operand vecX()
 4865 %{
 4866   constraint(ALLOC_IN_RC(vectorx_reg));
 4867   match(VecX);
 4868 
 4869   op_cost(0);
 4870   format %{ %}
 4871   interface(REG_INTER);
 4872 %}
 4873 
 4874 operand vRegD_V0()
 4875 %{
 4876   constraint(ALLOC_IN_RC(v0_reg));
 4877   match(RegD);
 4878   op_cost(0);
 4879   format %{ %}
 4880   interface(REG_INTER);
 4881 %}
 4882 
 4883 operand vRegD_V1()
 4884 %{
 4885   constraint(ALLOC_IN_RC(v1_reg));
 4886   match(RegD);
 4887   op_cost(0);
 4888   format %{ %}
 4889   interface(REG_INTER);
 4890 %}
 4891 
 4892 operand vRegD_V2()
 4893 %{
 4894   constraint(ALLOC_IN_RC(v2_reg));
 4895   match(RegD);
 4896   op_cost(0);
 4897   format %{ %}
 4898   interface(REG_INTER);
 4899 %}
 4900 
 4901 operand vRegD_V3()
 4902 %{
 4903   constraint(ALLOC_IN_RC(v3_reg));
 4904   match(RegD);
 4905   op_cost(0);
 4906   format %{ %}
 4907   interface(REG_INTER);
 4908 %}
 4909 
 4910 operand vRegD_V4()
 4911 %{
 4912   constraint(ALLOC_IN_RC(v4_reg));
 4913   match(RegD);
 4914   op_cost(0);
 4915   format %{ %}
 4916   interface(REG_INTER);
 4917 %}
 4918 
 4919 operand vRegD_V5()
 4920 %{
 4921   constraint(ALLOC_IN_RC(v5_reg));
 4922   match(RegD);
 4923   op_cost(0);
 4924   format %{ %}
 4925   interface(REG_INTER);
 4926 %}
 4927 
 4928 operand vRegD_V6()
 4929 %{
 4930   constraint(ALLOC_IN_RC(v6_reg));
 4931   match(RegD);
 4932   op_cost(0);
 4933   format %{ %}
 4934   interface(REG_INTER);
 4935 %}
 4936 
 4937 operand vRegD_V7()
 4938 %{
 4939   constraint(ALLOC_IN_RC(v7_reg));
 4940   match(RegD);
 4941   op_cost(0);
 4942   format %{ %}
 4943   interface(REG_INTER);
 4944 %}
 4945 
 4946 operand vRegD_V8()
 4947 %{
 4948   constraint(ALLOC_IN_RC(v8_reg));
 4949   match(RegD);
 4950   op_cost(0);
 4951   format %{ %}
 4952   interface(REG_INTER);
 4953 %}
 4954 
 4955 operand vRegD_V9()
 4956 %{
 4957   constraint(ALLOC_IN_RC(v9_reg));
 4958   match(RegD);
 4959   op_cost(0);
 4960   format %{ %}
 4961   interface(REG_INTER);
 4962 %}
 4963 
 4964 operand vRegD_V10()
 4965 %{
 4966   constraint(ALLOC_IN_RC(v10_reg));
 4967   match(RegD);
 4968   op_cost(0);
 4969   format %{ %}
 4970   interface(REG_INTER);
 4971 %}
 4972 
 4973 operand vRegD_V11()
 4974 %{
 4975   constraint(ALLOC_IN_RC(v11_reg));
 4976   match(RegD);
 4977   op_cost(0);
 4978   format %{ %}
 4979   interface(REG_INTER);
 4980 %}
 4981 
 4982 operand vRegD_V12()
 4983 %{
 4984   constraint(ALLOC_IN_RC(v12_reg));
 4985   match(RegD);
 4986   op_cost(0);
 4987   format %{ %}
 4988   interface(REG_INTER);
 4989 %}
 4990 
 4991 operand vRegD_V13()
 4992 %{
 4993   constraint(ALLOC_IN_RC(v13_reg));
 4994   match(RegD);
 4995   op_cost(0);
 4996   format %{ %}
 4997   interface(REG_INTER);
 4998 %}
 4999 
 5000 operand vRegD_V14()
 5001 %{
 5002   constraint(ALLOC_IN_RC(v14_reg));
 5003   match(RegD);
 5004   op_cost(0);
 5005   format %{ %}
 5006   interface(REG_INTER);
 5007 %}
 5008 
 5009 operand vRegD_V15()
 5010 %{
 5011   constraint(ALLOC_IN_RC(v15_reg));
 5012   match(RegD);
 5013   op_cost(0);
 5014   format %{ %}
 5015   interface(REG_INTER);
 5016 %}
 5017 
 5018 operand vRegD_V16()
 5019 %{
 5020   constraint(ALLOC_IN_RC(v16_reg));
 5021   match(RegD);
 5022   op_cost(0);
 5023   format %{ %}
 5024   interface(REG_INTER);
 5025 %}
 5026 
 5027 operand vRegD_V17()
 5028 %{
 5029   constraint(ALLOC_IN_RC(v17_reg));
 5030   match(RegD);
 5031   op_cost(0);
 5032   format %{ %}
 5033   interface(REG_INTER);
 5034 %}
 5035 
 5036 operand vRegD_V18()
 5037 %{
 5038   constraint(ALLOC_IN_RC(v18_reg));
 5039   match(RegD);
 5040   op_cost(0);
 5041   format %{ %}
 5042   interface(REG_INTER);
 5043 %}
 5044 
 5045 operand vRegD_V19()
 5046 %{
 5047   constraint(ALLOC_IN_RC(v19_reg));
 5048   match(RegD);
 5049   op_cost(0);
 5050   format %{ %}
 5051   interface(REG_INTER);
 5052 %}
 5053 
 5054 operand vRegD_V20()
 5055 %{
 5056   constraint(ALLOC_IN_RC(v20_reg));
 5057   match(RegD);
 5058   op_cost(0);
 5059   format %{ %}
 5060   interface(REG_INTER);
 5061 %}
 5062 
 5063 operand vRegD_V21()
 5064 %{
 5065   constraint(ALLOC_IN_RC(v21_reg));
 5066   match(RegD);
 5067   op_cost(0);
 5068   format %{ %}
 5069   interface(REG_INTER);
 5070 %}
 5071 
 5072 operand vRegD_V22()
 5073 %{
 5074   constraint(ALLOC_IN_RC(v22_reg));
 5075   match(RegD);
 5076   op_cost(0);
 5077   format %{ %}
 5078   interface(REG_INTER);
 5079 %}
 5080 
 5081 operand vRegD_V23()
 5082 %{
 5083   constraint(ALLOC_IN_RC(v23_reg));
 5084   match(RegD);
 5085   op_cost(0);
 5086   format %{ %}
 5087   interface(REG_INTER);
 5088 %}
 5089 
 5090 operand vRegD_V24()
 5091 %{
 5092   constraint(ALLOC_IN_RC(v24_reg));
 5093   match(RegD);
 5094   op_cost(0);
 5095   format %{ %}
 5096   interface(REG_INTER);
 5097 %}
 5098 
 5099 operand vRegD_V25()
 5100 %{
 5101   constraint(ALLOC_IN_RC(v25_reg));
 5102   match(RegD);
 5103   op_cost(0);
 5104   format %{ %}
 5105   interface(REG_INTER);
 5106 %}
 5107 
 5108 operand vRegD_V26()
 5109 %{
 5110   constraint(ALLOC_IN_RC(v26_reg));
 5111   match(RegD);
 5112   op_cost(0);
 5113   format %{ %}
 5114   interface(REG_INTER);
 5115 %}
 5116 
 5117 operand vRegD_V27()
 5118 %{
 5119   constraint(ALLOC_IN_RC(v27_reg));
 5120   match(RegD);
 5121   op_cost(0);
 5122   format %{ %}
 5123   interface(REG_INTER);
 5124 %}
 5125 
 5126 operand vRegD_V28()
 5127 %{
 5128   constraint(ALLOC_IN_RC(v28_reg));
 5129   match(RegD);
 5130   op_cost(0);
 5131   format %{ %}
 5132   interface(REG_INTER);
 5133 %}
 5134 
 5135 operand vRegD_V29()
 5136 %{
 5137   constraint(ALLOC_IN_RC(v29_reg));
 5138   match(RegD);
 5139   op_cost(0);
 5140   format %{ %}
 5141   interface(REG_INTER);
 5142 %}
 5143 
 5144 operand vRegD_V30()
 5145 %{
 5146   constraint(ALLOC_IN_RC(v30_reg));
 5147   match(RegD);
 5148   op_cost(0);
 5149   format %{ %}
 5150   interface(REG_INTER);
 5151 %}
 5152 
 5153 operand vRegD_V31()
 5154 %{
 5155   constraint(ALLOC_IN_RC(v31_reg));
 5156   match(RegD);
 5157   op_cost(0);
 5158   format %{ %}
 5159   interface(REG_INTER);
 5160 %}
 5161 
 5162 // Flags register, used as output of signed compare instructions
 5163 
 5164 // note that on AArch64 we also use this register as the output for
 5165 // for floating point compare instructions (CmpF CmpD). this ensures
 5166 // that ordered inequality tests use GT, GE, LT or LE none of which
 5167 // pass through cases where the result is unordered i.e. one or both
 5168 // inputs to the compare is a NaN. this means that the ideal code can
 5169 // replace e.g. a GT with an LE and not end up capturing the NaN case
 5170 // (where the comparison should always fail). EQ and NE tests are
 5171 // always generated in ideal code so that unordered folds into the NE
 5172 // case, matching the behaviour of AArch64 NE.
 5173 //
 5174 // This differs from x86 where the outputs of FP compares use a
 5175 // special FP flags registers and where compares based on this
 5176 // register are distinguished into ordered inequalities (cmpOpUCF) and
 5177 // EQ/NEQ tests (cmpOpUCF2). x86 has to special case the latter tests
 5178 // to explicitly handle the unordered case in branches. x86 also has
 5179 // to include extra CMoveX rules to accept a cmpOpUCF input.
 5180 
 5181 operand rFlagsReg()
 5182 %{
 5183   constraint(ALLOC_IN_RC(int_flags));
 5184   match(RegFlags);
 5185 
 5186   op_cost(0);
 5187   format %{ &quot;RFLAGS&quot; %}
 5188   interface(REG_INTER);
 5189 %}
 5190 
 5191 // Flags register, used as output of unsigned compare instructions
 5192 operand rFlagsRegU()
 5193 %{
 5194   constraint(ALLOC_IN_RC(int_flags));
 5195   match(RegFlags);
 5196 
 5197   op_cost(0);
 5198   format %{ &quot;RFLAGSU&quot; %}
 5199   interface(REG_INTER);
 5200 %}
 5201 
 5202 // Special Registers
 5203 
 5204 // Method Register
 5205 operand inline_cache_RegP(iRegP reg)
 5206 %{
 5207   constraint(ALLOC_IN_RC(method_reg)); // inline_cache_reg
 5208   match(reg);
 5209   match(iRegPNoSp);
 5210   op_cost(0);
 5211   format %{ %}
 5212   interface(REG_INTER);
 5213 %}
 5214 
 5215 operand interpreter_method_oop_RegP(iRegP reg)
 5216 %{
 5217   constraint(ALLOC_IN_RC(method_reg)); // interpreter_method_oop_reg
 5218   match(reg);
 5219   match(iRegPNoSp);
 5220   op_cost(0);
 5221   format %{ %}
 5222   interface(REG_INTER);
 5223 %}
 5224 
 5225 // Thread Register
 5226 operand thread_RegP(iRegP reg)
 5227 %{
 5228   constraint(ALLOC_IN_RC(thread_reg)); // link_reg
 5229   match(reg);
 5230   op_cost(0);
 5231   format %{ %}
 5232   interface(REG_INTER);
 5233 %}
 5234 
 5235 operand lr_RegP(iRegP reg)
 5236 %{
 5237   constraint(ALLOC_IN_RC(lr_reg)); // link_reg
 5238   match(reg);
 5239   op_cost(0);
 5240   format %{ %}
 5241   interface(REG_INTER);
 5242 %}
 5243 
 5244 //----------Memory Operands----------------------------------------------------
 5245 
 5246 operand indirect(iRegP reg)
 5247 %{
 5248   constraint(ALLOC_IN_RC(ptr_reg));
 5249   match(reg);
 5250   op_cost(0);
 5251   format %{ &quot;[$reg]&quot; %}
 5252   interface(MEMORY_INTER) %{
 5253     base($reg);
 5254     index(0xffffffff);
 5255     scale(0x0);
 5256     disp(0x0);
 5257   %}
 5258 %}
 5259 
 5260 operand indIndexScaledI2L(iRegP reg, iRegI ireg, immIScale scale)
 5261 %{
 5262   constraint(ALLOC_IN_RC(ptr_reg));
 5263   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5264   match(AddP reg (LShiftL (ConvI2L ireg) scale));
 5265   op_cost(0);
 5266   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L&quot; %}
 5267   interface(MEMORY_INTER) %{
 5268     base($reg);
 5269     index($ireg);
 5270     scale($scale);
 5271     disp(0x0);
 5272   %}
 5273 %}
 5274 
 5275 operand indIndexScaled(iRegP reg, iRegL lreg, immIScale scale)
 5276 %{
 5277   constraint(ALLOC_IN_RC(ptr_reg));
 5278   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5279   match(AddP reg (LShiftL lreg scale));
 5280   op_cost(0);
 5281   format %{ &quot;$reg, $lreg lsl($scale)&quot; %}
 5282   interface(MEMORY_INTER) %{
 5283     base($reg);
 5284     index($lreg);
 5285     scale($scale);
 5286     disp(0x0);
 5287   %}
 5288 %}
 5289 
 5290 operand indIndexI2L(iRegP reg, iRegI ireg)
 5291 %{
 5292   constraint(ALLOC_IN_RC(ptr_reg));
 5293   match(AddP reg (ConvI2L ireg));
 5294   op_cost(0);
 5295   format %{ &quot;$reg, $ireg, 0, I2L&quot; %}
 5296   interface(MEMORY_INTER) %{
 5297     base($reg);
 5298     index($ireg);
 5299     scale(0x0);
 5300     disp(0x0);
 5301   %}
 5302 %}
 5303 
 5304 operand indIndex(iRegP reg, iRegL lreg)
 5305 %{
 5306   constraint(ALLOC_IN_RC(ptr_reg));
 5307   match(AddP reg lreg);
 5308   op_cost(0);
 5309   format %{ &quot;$reg, $lreg&quot; %}
 5310   interface(MEMORY_INTER) %{
 5311     base($reg);
 5312     index($lreg);
 5313     scale(0x0);
 5314     disp(0x0);
 5315   %}
 5316 %}
 5317 
 5318 operand indOffI(iRegP reg, immIOffset off)
 5319 %{
 5320   constraint(ALLOC_IN_RC(ptr_reg));
 5321   match(AddP reg off);
 5322   op_cost(0);
 5323   format %{ &quot;[$reg, $off]&quot; %}
 5324   interface(MEMORY_INTER) %{
 5325     base($reg);
 5326     index(0xffffffff);
 5327     scale(0x0);
 5328     disp($off);
 5329   %}
 5330 %}
 5331 
 5332 operand indOffI1(iRegP reg, immIOffset1 off)
 5333 %{
 5334   constraint(ALLOC_IN_RC(ptr_reg));
 5335   match(AddP reg off);
 5336   op_cost(0);
 5337   format %{ &quot;[$reg, $off]&quot; %}
 5338   interface(MEMORY_INTER) %{
 5339     base($reg);
 5340     index(0xffffffff);
 5341     scale(0x0);
 5342     disp($off);
 5343   %}
 5344 %}
 5345 
 5346 operand indOffI2(iRegP reg, immIOffset2 off)
 5347 %{
 5348   constraint(ALLOC_IN_RC(ptr_reg));
 5349   match(AddP reg off);
 5350   op_cost(0);
 5351   format %{ &quot;[$reg, $off]&quot; %}
 5352   interface(MEMORY_INTER) %{
 5353     base($reg);
 5354     index(0xffffffff);
 5355     scale(0x0);
 5356     disp($off);
 5357   %}
 5358 %}
 5359 
 5360 operand indOffI4(iRegP reg, immIOffset4 off)
 5361 %{
 5362   constraint(ALLOC_IN_RC(ptr_reg));
 5363   match(AddP reg off);
 5364   op_cost(0);
 5365   format %{ &quot;[$reg, $off]&quot; %}
 5366   interface(MEMORY_INTER) %{
 5367     base($reg);
 5368     index(0xffffffff);
 5369     scale(0x0);
 5370     disp($off);
 5371   %}
 5372 %}
 5373 
 5374 operand indOffI8(iRegP reg, immIOffset8 off)
 5375 %{
 5376   constraint(ALLOC_IN_RC(ptr_reg));
 5377   match(AddP reg off);
 5378   op_cost(0);
 5379   format %{ &quot;[$reg, $off]&quot; %}
 5380   interface(MEMORY_INTER) %{
 5381     base($reg);
 5382     index(0xffffffff);
 5383     scale(0x0);
 5384     disp($off);
 5385   %}
 5386 %}
 5387 
 5388 operand indOffI16(iRegP reg, immIOffset16 off)
 5389 %{
 5390   constraint(ALLOC_IN_RC(ptr_reg));
 5391   match(AddP reg off);
 5392   op_cost(0);
 5393   format %{ &quot;[$reg, $off]&quot; %}
 5394   interface(MEMORY_INTER) %{
 5395     base($reg);
 5396     index(0xffffffff);
 5397     scale(0x0);
 5398     disp($off);
 5399   %}
 5400 %}
 5401 
 5402 operand indOffL(iRegP reg, immLoffset off)
 5403 %{
 5404   constraint(ALLOC_IN_RC(ptr_reg));
 5405   match(AddP reg off);
 5406   op_cost(0);
 5407   format %{ &quot;[$reg, $off]&quot; %}
 5408   interface(MEMORY_INTER) %{
 5409     base($reg);
 5410     index(0xffffffff);
 5411     scale(0x0);
 5412     disp($off);
 5413   %}
 5414 %}
 5415 
 5416 operand indOffL1(iRegP reg, immLoffset1 off)
 5417 %{
 5418   constraint(ALLOC_IN_RC(ptr_reg));
 5419   match(AddP reg off);
 5420   op_cost(0);
 5421   format %{ &quot;[$reg, $off]&quot; %}
 5422   interface(MEMORY_INTER) %{
 5423     base($reg);
 5424     index(0xffffffff);
 5425     scale(0x0);
 5426     disp($off);
 5427   %}
 5428 %}
 5429 
 5430 operand indOffL2(iRegP reg, immLoffset2 off)
 5431 %{
 5432   constraint(ALLOC_IN_RC(ptr_reg));
 5433   match(AddP reg off);
 5434   op_cost(0);
 5435   format %{ &quot;[$reg, $off]&quot; %}
 5436   interface(MEMORY_INTER) %{
 5437     base($reg);
 5438     index(0xffffffff);
 5439     scale(0x0);
 5440     disp($off);
 5441   %}
 5442 %}
 5443 
 5444 operand indOffL4(iRegP reg, immLoffset4 off)
 5445 %{
 5446   constraint(ALLOC_IN_RC(ptr_reg));
 5447   match(AddP reg off);
 5448   op_cost(0);
 5449   format %{ &quot;[$reg, $off]&quot; %}
 5450   interface(MEMORY_INTER) %{
 5451     base($reg);
 5452     index(0xffffffff);
 5453     scale(0x0);
 5454     disp($off);
 5455   %}
 5456 %}
 5457 
 5458 operand indOffL8(iRegP reg, immLoffset8 off)
 5459 %{
 5460   constraint(ALLOC_IN_RC(ptr_reg));
 5461   match(AddP reg off);
 5462   op_cost(0);
 5463   format %{ &quot;[$reg, $off]&quot; %}
 5464   interface(MEMORY_INTER) %{
 5465     base($reg);
 5466     index(0xffffffff);
 5467     scale(0x0);
 5468     disp($off);
 5469   %}
 5470 %}
 5471 
 5472 operand indOffL16(iRegP reg, immLoffset16 off)
 5473 %{
 5474   constraint(ALLOC_IN_RC(ptr_reg));
 5475   match(AddP reg off);
 5476   op_cost(0);
 5477   format %{ &quot;[$reg, $off]&quot; %}
 5478   interface(MEMORY_INTER) %{
 5479     base($reg);
 5480     index(0xffffffff);
 5481     scale(0x0);
 5482     disp($off);
 5483   %}
 5484 %}
 5485 
 5486 operand indirectN(iRegN reg)
 5487 %{
 5488   predicate(CompressedOops::shift() == 0);
 5489   constraint(ALLOC_IN_RC(ptr_reg));
 5490   match(DecodeN reg);
 5491   op_cost(0);
 5492   format %{ &quot;[$reg]\t# narrow&quot; %}
 5493   interface(MEMORY_INTER) %{
 5494     base($reg);
 5495     index(0xffffffff);
 5496     scale(0x0);
 5497     disp(0x0);
 5498   %}
 5499 %}
 5500 
 5501 operand indIndexScaledI2LN(iRegN reg, iRegI ireg, immIScale scale)
 5502 %{
 5503   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5504   constraint(ALLOC_IN_RC(ptr_reg));
 5505   match(AddP (DecodeN reg) (LShiftL (ConvI2L ireg) scale));
 5506   op_cost(0);
 5507   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L\t# narrow&quot; %}
 5508   interface(MEMORY_INTER) %{
 5509     base($reg);
 5510     index($ireg);
 5511     scale($scale);
 5512     disp(0x0);
 5513   %}
 5514 %}
 5515 
 5516 operand indIndexScaledN(iRegN reg, iRegL lreg, immIScale scale)
 5517 %{
 5518   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5519   constraint(ALLOC_IN_RC(ptr_reg));
 5520   match(AddP (DecodeN reg) (LShiftL lreg scale));
 5521   op_cost(0);
 5522   format %{ &quot;$reg, $lreg lsl($scale)\t# narrow&quot; %}
 5523   interface(MEMORY_INTER) %{
 5524     base($reg);
 5525     index($lreg);
 5526     scale($scale);
 5527     disp(0x0);
 5528   %}
 5529 %}
 5530 
 5531 operand indIndexI2LN(iRegN reg, iRegI ireg)
 5532 %{
 5533   predicate(CompressedOops::shift() == 0);
 5534   constraint(ALLOC_IN_RC(ptr_reg));
 5535   match(AddP (DecodeN reg) (ConvI2L ireg));
 5536   op_cost(0);
 5537   format %{ &quot;$reg, $ireg, 0, I2L\t# narrow&quot; %}
 5538   interface(MEMORY_INTER) %{
 5539     base($reg);
 5540     index($ireg);
 5541     scale(0x0);
 5542     disp(0x0);
 5543   %}
 5544 %}
 5545 
 5546 operand indIndexN(iRegN reg, iRegL lreg)
 5547 %{
 5548   predicate(CompressedOops::shift() == 0);
 5549   constraint(ALLOC_IN_RC(ptr_reg));
 5550   match(AddP (DecodeN reg) lreg);
 5551   op_cost(0);
 5552   format %{ &quot;$reg, $lreg\t# narrow&quot; %}
 5553   interface(MEMORY_INTER) %{
 5554     base($reg);
 5555     index($lreg);
 5556     scale(0x0);
 5557     disp(0x0);
 5558   %}
 5559 %}
 5560 
 5561 operand indOffIN(iRegN reg, immIOffset off)
 5562 %{
 5563   predicate(CompressedOops::shift() == 0);
 5564   constraint(ALLOC_IN_RC(ptr_reg));
 5565   match(AddP (DecodeN reg) off);
 5566   op_cost(0);
 5567   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5568   interface(MEMORY_INTER) %{
 5569     base($reg);
 5570     index(0xffffffff);
 5571     scale(0x0);
 5572     disp($off);
 5573   %}
 5574 %}
 5575 
 5576 operand indOffLN(iRegN reg, immLoffset off)
 5577 %{
 5578   predicate(CompressedOops::shift() == 0);
 5579   constraint(ALLOC_IN_RC(ptr_reg));
 5580   match(AddP (DecodeN reg) off);
 5581   op_cost(0);
 5582   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5583   interface(MEMORY_INTER) %{
 5584     base($reg);
 5585     index(0xffffffff);
 5586     scale(0x0);
 5587     disp($off);
 5588   %}
 5589 %}
 5590 
 5591 
 5592 
 5593 // AArch64 opto stubs need to write to the pc slot in the thread anchor
 5594 operand thread_anchor_pc(thread_RegP reg, immL_pc_off off)
 5595 %{
 5596   constraint(ALLOC_IN_RC(ptr_reg));
 5597   match(AddP reg off);
 5598   op_cost(0);
 5599   format %{ &quot;[$reg, $off]&quot; %}
 5600   interface(MEMORY_INTER) %{
 5601     base($reg);
 5602     index(0xffffffff);
 5603     scale(0x0);
 5604     disp($off);
 5605   %}
 5606 %}
 5607 
 5608 //----------Special Memory Operands--------------------------------------------
 5609 // Stack Slot Operand - This operand is used for loading and storing temporary
 5610 //                      values on the stack where a match requires a value to
 5611 //                      flow through memory.
 5612 operand stackSlotP(sRegP reg)
 5613 %{
 5614   constraint(ALLOC_IN_RC(stack_slots));
 5615   op_cost(100);
 5616   // No match rule because this operand is only generated in matching
 5617   // match(RegP);
 5618   format %{ &quot;[$reg]&quot; %}
 5619   interface(MEMORY_INTER) %{
 5620     base(0x1e);  // RSP
 5621     index(0x0);  // No Index
 5622     scale(0x0);  // No Scale
 5623     disp($reg);  // Stack Offset
 5624   %}
 5625 %}
 5626 
 5627 operand stackSlotI(sRegI reg)
 5628 %{
 5629   constraint(ALLOC_IN_RC(stack_slots));
 5630   // No match rule because this operand is only generated in matching
 5631   // match(RegI);
 5632   format %{ &quot;[$reg]&quot; %}
 5633   interface(MEMORY_INTER) %{
 5634     base(0x1e);  // RSP
 5635     index(0x0);  // No Index
 5636     scale(0x0);  // No Scale
 5637     disp($reg);  // Stack Offset
 5638   %}
 5639 %}
 5640 
 5641 operand stackSlotF(sRegF reg)
 5642 %{
 5643   constraint(ALLOC_IN_RC(stack_slots));
 5644   // No match rule because this operand is only generated in matching
 5645   // match(RegF);
 5646   format %{ &quot;[$reg]&quot; %}
 5647   interface(MEMORY_INTER) %{
 5648     base(0x1e);  // RSP
 5649     index(0x0);  // No Index
 5650     scale(0x0);  // No Scale
 5651     disp($reg);  // Stack Offset
 5652   %}
 5653 %}
 5654 
 5655 operand stackSlotD(sRegD reg)
 5656 %{
 5657   constraint(ALLOC_IN_RC(stack_slots));
 5658   // No match rule because this operand is only generated in matching
 5659   // match(RegD);
 5660   format %{ &quot;[$reg]&quot; %}
 5661   interface(MEMORY_INTER) %{
 5662     base(0x1e);  // RSP
 5663     index(0x0);  // No Index
 5664     scale(0x0);  // No Scale
 5665     disp($reg);  // Stack Offset
 5666   %}
 5667 %}
 5668 
 5669 operand stackSlotL(sRegL reg)
 5670 %{
 5671   constraint(ALLOC_IN_RC(stack_slots));
 5672   // No match rule because this operand is only generated in matching
 5673   // match(RegL);
 5674   format %{ &quot;[$reg]&quot; %}
 5675   interface(MEMORY_INTER) %{
 5676     base(0x1e);  // RSP
 5677     index(0x0);  // No Index
 5678     scale(0x0);  // No Scale
 5679     disp($reg);  // Stack Offset
 5680   %}
 5681 %}
 5682 
 5683 // Operands for expressing Control Flow
 5684 // NOTE: Label is a predefined operand which should not be redefined in
 5685 //       the AD file. It is generically handled within the ADLC.
 5686 
 5687 //----------Conditional Branch Operands----------------------------------------
 5688 // Comparison Op  - This is the operation of the comparison, and is limited to
 5689 //                  the following set of codes:
 5690 //                  L (&lt;), LE (&lt;=), G (&gt;), GE (&gt;=), E (==), NE (!=)
 5691 //
 5692 // Other attributes of the comparison, such as unsignedness, are specified
 5693 // by the comparison instruction that sets a condition code flags register.
 5694 // That result is represented by a flags operand whose subtype is appropriate
 5695 // to the unsignedness (etc.) of the comparison.
 5696 //
 5697 // Later, the instruction which matches both the Comparison Op (a Bool) and
 5698 // the flags (produced by the Cmp) specifies the coding of the comparison op
 5699 // by matching a specific subtype of Bool operand below, such as cmpOpU.
 5700 
 5701 // used for signed integral comparisons and fp comparisons
 5702 
 5703 operand cmpOp()
 5704 %{
 5705   match(Bool);
 5706 
 5707   format %{ &quot;&quot; %}
 5708   interface(COND_INTER) %{
 5709     equal(0x0, &quot;eq&quot;);
 5710     not_equal(0x1, &quot;ne&quot;);
 5711     less(0xb, &quot;lt&quot;);
 5712     greater_equal(0xa, &quot;ge&quot;);
 5713     less_equal(0xd, &quot;le&quot;);
 5714     greater(0xc, &quot;gt&quot;);
 5715     overflow(0x6, &quot;vs&quot;);
 5716     no_overflow(0x7, &quot;vc&quot;);
 5717   %}
 5718 %}
 5719 
 5720 // used for unsigned integral comparisons
 5721 
 5722 operand cmpOpU()
 5723 %{
 5724   match(Bool);
 5725 
 5726   format %{ &quot;&quot; %}
 5727   interface(COND_INTER) %{
 5728     equal(0x0, &quot;eq&quot;);
 5729     not_equal(0x1, &quot;ne&quot;);
 5730     less(0x3, &quot;lo&quot;);
 5731     greater_equal(0x2, &quot;hs&quot;);
 5732     less_equal(0x9, &quot;ls&quot;);
 5733     greater(0x8, &quot;hi&quot;);
 5734     overflow(0x6, &quot;vs&quot;);
 5735     no_overflow(0x7, &quot;vc&quot;);
 5736   %}
 5737 %}
 5738 
 5739 // used for certain integral comparisons which can be
 5740 // converted to cbxx or tbxx instructions
 5741 
 5742 operand cmpOpEqNe()
 5743 %{
 5744   match(Bool);
 5745   op_cost(0);
 5746   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5747             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq);
 5748 
 5749   format %{ &quot;&quot; %}
 5750   interface(COND_INTER) %{
 5751     equal(0x0, &quot;eq&quot;);
 5752     not_equal(0x1, &quot;ne&quot;);
 5753     less(0xb, &quot;lt&quot;);
 5754     greater_equal(0xa, &quot;ge&quot;);
 5755     less_equal(0xd, &quot;le&quot;);
 5756     greater(0xc, &quot;gt&quot;);
 5757     overflow(0x6, &quot;vs&quot;);
 5758     no_overflow(0x7, &quot;vc&quot;);
 5759   %}
 5760 %}
 5761 
 5762 // used for certain integral comparisons which can be
 5763 // converted to cbxx or tbxx instructions
 5764 
 5765 operand cmpOpLtGe()
 5766 %{
 5767   match(Bool);
 5768   op_cost(0);
 5769 
 5770   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5771             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5772 
 5773   format %{ &quot;&quot; %}
 5774   interface(COND_INTER) %{
 5775     equal(0x0, &quot;eq&quot;);
 5776     not_equal(0x1, &quot;ne&quot;);
 5777     less(0xb, &quot;lt&quot;);
 5778     greater_equal(0xa, &quot;ge&quot;);
 5779     less_equal(0xd, &quot;le&quot;);
 5780     greater(0xc, &quot;gt&quot;);
 5781     overflow(0x6, &quot;vs&quot;);
 5782     no_overflow(0x7, &quot;vc&quot;);
 5783   %}
 5784 %}
 5785 
 5786 // used for certain unsigned integral comparisons which can be
 5787 // converted to cbxx or tbxx instructions
 5788 
 5789 operand cmpOpUEqNeLtGe()
 5790 %{
 5791   match(Bool);
 5792   op_cost(0);
 5793 
 5794   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq
 5795             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5796             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5797             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5798 
 5799   format %{ &quot;&quot; %}
 5800   interface(COND_INTER) %{
 5801     equal(0x0, &quot;eq&quot;);
 5802     not_equal(0x1, &quot;ne&quot;);
 5803     less(0xb, &quot;lt&quot;);
 5804     greater_equal(0xa, &quot;ge&quot;);
 5805     less_equal(0xd, &quot;le&quot;);
 5806     greater(0xc, &quot;gt&quot;);
 5807     overflow(0x6, &quot;vs&quot;);
 5808     no_overflow(0x7, &quot;vc&quot;);
 5809   %}
 5810 %}
 5811 
 5812 // Special operand allowing long args to int ops to be truncated for free
 5813 
 5814 operand iRegL2I(iRegL reg) %{
 5815 
 5816   op_cost(0);
 5817 
 5818   match(ConvL2I reg);
 5819 
 5820   format %{ &quot;l2i($reg)&quot; %}
 5821 
 5822   interface(REG_INTER)
 5823 %}
 5824 
 5825 opclass vmem4(indirect, indIndex, indOffI4, indOffL4);
 5826 opclass vmem8(indirect, indIndex, indOffI8, indOffL8);
 5827 opclass vmem16(indirect, indIndex, indOffI16, indOffL16);
 5828 
 5829 //----------OPERAND CLASSES----------------------------------------------------
 5830 // Operand Classes are groups of operands that are used as to simplify
 5831 // instruction definitions by not requiring the AD writer to specify
 5832 // separate instructions for every form of operand when the
 5833 // instruction accepts multiple operand types with the same basic
 5834 // encoding and format. The classic case of this is memory operands.
 5835 
 5836 // memory is used to define read/write location for load/store
 5837 // instruction defs. we can turn a memory op into an Address
 5838 
 5839 opclass memory1(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI1, indOffL1,
 5840                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5841 
 5842 opclass memory2(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI2, indOffL2,
 5843                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5844 
 5845 opclass memory4(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI4, indOffL4,
 5846                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5847 
 5848 opclass memory8(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI8, indOffL8,
 5849                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5850 
 5851 // All of the memory operands. For the pipeline description.
 5852 opclass memory(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex,
 5853                indOffI1, indOffL1, indOffI2, indOffL2, indOffI4, indOffL4, indOffI8, indOffL8,
 5854                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5855 
 5856 
 5857 // iRegIorL2I is used for src inputs in rules for 32 bit int (I)
 5858 // operations. it allows the src to be either an iRegI or a (ConvL2I
 5859 // iRegL). in the latter case the l2i normally planted for a ConvL2I
 5860 // can be elided because the 32-bit instruction will just employ the
 5861 // lower 32 bits anyway.
 5862 //
 5863 // n.b. this does not elide all L2I conversions. if the truncated
 5864 // value is consumed by more than one operation then the ConvL2I
 5865 // cannot be bundled into the consuming nodes so an l2i gets planted
 5866 // (actually a movw $dst $src) and the downstream instructions consume
 5867 // the result of the l2i as an iRegI input. That&#39;s a shame since the
 5868 // movw is actually redundant but its not too costly.
 5869 
 5870 opclass iRegIorL2I(iRegI, iRegL2I);
 5871 
 5872 //----------PIPELINE-----------------------------------------------------------
 5873 // Rules which define the behavior of the target architectures pipeline.
 5874 
 5875 // For specific pipelines, eg A53, define the stages of that pipeline
 5876 //pipe_desc(ISS, EX1, EX2, WR);
 5877 #define ISS S0
 5878 #define EX1 S1
 5879 #define EX2 S2
 5880 #define WR  S3
 5881 
 5882 // Integer ALU reg operation
 5883 pipeline %{
 5884 
 5885 attributes %{
 5886   // ARM instructions are of fixed length
 5887   fixed_size_instructions;        // Fixed size instructions TODO does
 5888   max_instructions_per_bundle = 2;   // A53 = 2, A57 = 4
 5889   // ARM instructions come in 32-bit word units
 5890   instruction_unit_size = 4;         // An instruction is 4 bytes long
 5891   instruction_fetch_unit_size = 64;  // The processor fetches one line
 5892   instruction_fetch_units = 1;       // of 64 bytes
 5893 
 5894   // List of nop instructions
 5895   nops( MachNop );
 5896 %}
 5897 
 5898 // We don&#39;t use an actual pipeline model so don&#39;t care about resources
 5899 // or description. we do use pipeline classes to introduce fixed
 5900 // latencies
 5901 
 5902 //----------RESOURCES----------------------------------------------------------
 5903 // Resources are the functional units available to the machine
 5904 
 5905 resources( INS0, INS1, INS01 = INS0 | INS1,
 5906            ALU0, ALU1, ALU = ALU0 | ALU1,
 5907            MAC,
 5908            DIV,
 5909            BRANCH,
 5910            LDST,
 5911            NEON_FP);
 5912 
 5913 //----------PIPELINE DESCRIPTION-----------------------------------------------
 5914 // Pipeline Description specifies the stages in the machine&#39;s pipeline
 5915 
 5916 // Define the pipeline as a generic 6 stage pipeline
 5917 pipe_desc(S0, S1, S2, S3, S4, S5);
 5918 
 5919 //----------PIPELINE CLASSES---------------------------------------------------
 5920 // Pipeline Classes describe the stages in which input and output are
 5921 // referenced by the hardware pipeline.
 5922 
 5923 pipe_class fp_dop_reg_reg_s(vRegF dst, vRegF src1, vRegF src2)
 5924 %{
 5925   single_instruction;
 5926   src1   : S1(read);
 5927   src2   : S2(read);
 5928   dst    : S5(write);
 5929   INS01  : ISS;
 5930   NEON_FP : S5;
 5931 %}
 5932 
 5933 pipe_class fp_dop_reg_reg_d(vRegD dst, vRegD src1, vRegD src2)
 5934 %{
 5935   single_instruction;
 5936   src1   : S1(read);
 5937   src2   : S2(read);
 5938   dst    : S5(write);
 5939   INS01  : ISS;
 5940   NEON_FP : S5;
 5941 %}
 5942 
 5943 pipe_class fp_uop_s(vRegF dst, vRegF src)
 5944 %{
 5945   single_instruction;
 5946   src    : S1(read);
 5947   dst    : S5(write);
 5948   INS01  : ISS;
 5949   NEON_FP : S5;
 5950 %}
 5951 
 5952 pipe_class fp_uop_d(vRegD dst, vRegD src)
 5953 %{
 5954   single_instruction;
 5955   src    : S1(read);
 5956   dst    : S5(write);
 5957   INS01  : ISS;
 5958   NEON_FP : S5;
 5959 %}
 5960 
 5961 pipe_class fp_d2f(vRegF dst, vRegD src)
 5962 %{
 5963   single_instruction;
 5964   src    : S1(read);
 5965   dst    : S5(write);
 5966   INS01  : ISS;
 5967   NEON_FP : S5;
 5968 %}
 5969 
 5970 pipe_class fp_f2d(vRegD dst, vRegF src)
 5971 %{
 5972   single_instruction;
 5973   src    : S1(read);
 5974   dst    : S5(write);
 5975   INS01  : ISS;
 5976   NEON_FP : S5;
 5977 %}
 5978 
 5979 pipe_class fp_f2i(iRegINoSp dst, vRegF src)
 5980 %{
 5981   single_instruction;
 5982   src    : S1(read);
 5983   dst    : S5(write);
 5984   INS01  : ISS;
 5985   NEON_FP : S5;
 5986 %}
 5987 
 5988 pipe_class fp_f2l(iRegLNoSp dst, vRegF src)
 5989 %{
 5990   single_instruction;
 5991   src    : S1(read);
 5992   dst    : S5(write);
 5993   INS01  : ISS;
 5994   NEON_FP : S5;
 5995 %}
 5996 
 5997 pipe_class fp_i2f(vRegF dst, iRegIorL2I src)
 5998 %{
 5999   single_instruction;
 6000   src    : S1(read);
 6001   dst    : S5(write);
 6002   INS01  : ISS;
 6003   NEON_FP : S5;
 6004 %}
 6005 
 6006 pipe_class fp_l2f(vRegF dst, iRegL src)
 6007 %{
 6008   single_instruction;
 6009   src    : S1(read);
 6010   dst    : S5(write);
 6011   INS01  : ISS;
 6012   NEON_FP : S5;
 6013 %}
 6014 
 6015 pipe_class fp_d2i(iRegINoSp dst, vRegD src)
 6016 %{
 6017   single_instruction;
 6018   src    : S1(read);
 6019   dst    : S5(write);
 6020   INS01  : ISS;
 6021   NEON_FP : S5;
 6022 %}
 6023 
 6024 pipe_class fp_d2l(iRegLNoSp dst, vRegD src)
 6025 %{
 6026   single_instruction;
 6027   src    : S1(read);
 6028   dst    : S5(write);
 6029   INS01  : ISS;
 6030   NEON_FP : S5;
 6031 %}
 6032 
 6033 pipe_class fp_i2d(vRegD dst, iRegIorL2I src)
 6034 %{
 6035   single_instruction;
 6036   src    : S1(read);
 6037   dst    : S5(write);
 6038   INS01  : ISS;
 6039   NEON_FP : S5;
 6040 %}
 6041 
 6042 pipe_class fp_l2d(vRegD dst, iRegIorL2I src)
 6043 %{
 6044   single_instruction;
 6045   src    : S1(read);
 6046   dst    : S5(write);
 6047   INS01  : ISS;
 6048   NEON_FP : S5;
 6049 %}
 6050 
 6051 pipe_class fp_div_s(vRegF dst, vRegF src1, vRegF src2)
 6052 %{
 6053   single_instruction;
 6054   src1   : S1(read);
 6055   src2   : S2(read);
 6056   dst    : S5(write);
 6057   INS0   : ISS;
 6058   NEON_FP : S5;
 6059 %}
 6060 
 6061 pipe_class fp_div_d(vRegD dst, vRegD src1, vRegD src2)
 6062 %{
 6063   single_instruction;
 6064   src1   : S1(read);
 6065   src2   : S2(read);
 6066   dst    : S5(write);
 6067   INS0   : ISS;
 6068   NEON_FP : S5;
 6069 %}
 6070 
 6071 pipe_class fp_cond_reg_reg_s(vRegF dst, vRegF src1, vRegF src2, rFlagsReg cr)
 6072 %{
 6073   single_instruction;
 6074   cr     : S1(read);
 6075   src1   : S1(read);
 6076   src2   : S1(read);
 6077   dst    : S3(write);
 6078   INS01  : ISS;
 6079   NEON_FP : S3;
 6080 %}
 6081 
 6082 pipe_class fp_cond_reg_reg_d(vRegD dst, vRegD src1, vRegD src2, rFlagsReg cr)
 6083 %{
 6084   single_instruction;
 6085   cr     : S1(read);
 6086   src1   : S1(read);
 6087   src2   : S1(read);
 6088   dst    : S3(write);
 6089   INS01  : ISS;
 6090   NEON_FP : S3;
 6091 %}
 6092 
 6093 pipe_class fp_imm_s(vRegF dst)
 6094 %{
 6095   single_instruction;
 6096   dst    : S3(write);
 6097   INS01  : ISS;
 6098   NEON_FP : S3;
 6099 %}
 6100 
 6101 pipe_class fp_imm_d(vRegD dst)
 6102 %{
 6103   single_instruction;
 6104   dst    : S3(write);
 6105   INS01  : ISS;
 6106   NEON_FP : S3;
 6107 %}
 6108 
 6109 pipe_class fp_load_constant_s(vRegF dst)
 6110 %{
 6111   single_instruction;
 6112   dst    : S4(write);
 6113   INS01  : ISS;
 6114   NEON_FP : S4;
 6115 %}
 6116 
 6117 pipe_class fp_load_constant_d(vRegD dst)
 6118 %{
 6119   single_instruction;
 6120   dst    : S4(write);
 6121   INS01  : ISS;
 6122   NEON_FP : S4;
 6123 %}
 6124 
 6125 pipe_class vmul64(vecD dst, vecD src1, vecD src2)
 6126 %{
 6127   single_instruction;
 6128   dst    : S5(write);
 6129   src1   : S1(read);
 6130   src2   : S1(read);
 6131   INS01  : ISS;
 6132   NEON_FP : S5;
 6133 %}
 6134 
 6135 pipe_class vmul128(vecX dst, vecX src1, vecX src2)
 6136 %{
 6137   single_instruction;
 6138   dst    : S5(write);
 6139   src1   : S1(read);
 6140   src2   : S1(read);
 6141   INS0   : ISS;
 6142   NEON_FP : S5;
 6143 %}
 6144 
 6145 pipe_class vmla64(vecD dst, vecD src1, vecD src2)
 6146 %{
 6147   single_instruction;
 6148   dst    : S5(write);
 6149   src1   : S1(read);
 6150   src2   : S1(read);
 6151   dst    : S1(read);
 6152   INS01  : ISS;
 6153   NEON_FP : S5;
 6154 %}
 6155 
 6156 pipe_class vmla128(vecX dst, vecX src1, vecX src2)
 6157 %{
 6158   single_instruction;
 6159   dst    : S5(write);
 6160   src1   : S1(read);
 6161   src2   : S1(read);
 6162   dst    : S1(read);
 6163   INS0   : ISS;
 6164   NEON_FP : S5;
 6165 %}
 6166 
 6167 pipe_class vdop64(vecD dst, vecD src1, vecD src2)
 6168 %{
 6169   single_instruction;
 6170   dst    : S4(write);
 6171   src1   : S2(read);
 6172   src2   : S2(read);
 6173   INS01  : ISS;
 6174   NEON_FP : S4;
 6175 %}
 6176 
 6177 pipe_class vdop128(vecX dst, vecX src1, vecX src2)
 6178 %{
 6179   single_instruction;
 6180   dst    : S4(write);
 6181   src1   : S2(read);
 6182   src2   : S2(read);
 6183   INS0   : ISS;
 6184   NEON_FP : S4;
 6185 %}
 6186 
 6187 pipe_class vlogical64(vecD dst, vecD src1, vecD src2)
 6188 %{
 6189   single_instruction;
 6190   dst    : S3(write);
 6191   src1   : S2(read);
 6192   src2   : S2(read);
 6193   INS01  : ISS;
 6194   NEON_FP : S3;
 6195 %}
 6196 
 6197 pipe_class vlogical128(vecX dst, vecX src1, vecX src2)
 6198 %{
 6199   single_instruction;
 6200   dst    : S3(write);
 6201   src1   : S2(read);
 6202   src2   : S2(read);
 6203   INS0   : ISS;
 6204   NEON_FP : S3;
 6205 %}
 6206 
 6207 pipe_class vshift64(vecD dst, vecD src, vecX shift)
 6208 %{
 6209   single_instruction;
 6210   dst    : S3(write);
 6211   src    : S1(read);
 6212   shift  : S1(read);
 6213   INS01  : ISS;
 6214   NEON_FP : S3;
 6215 %}
 6216 
 6217 pipe_class vshift128(vecX dst, vecX src, vecX shift)
 6218 %{
 6219   single_instruction;
 6220   dst    : S3(write);
 6221   src    : S1(read);
 6222   shift  : S1(read);
 6223   INS0   : ISS;
 6224   NEON_FP : S3;
 6225 %}
 6226 
 6227 pipe_class vshift64_imm(vecD dst, vecD src, immI shift)
 6228 %{
 6229   single_instruction;
 6230   dst    : S3(write);
 6231   src    : S1(read);
 6232   INS01  : ISS;
 6233   NEON_FP : S3;
 6234 %}
 6235 
 6236 pipe_class vshift128_imm(vecX dst, vecX src, immI shift)
 6237 %{
 6238   single_instruction;
 6239   dst    : S3(write);
 6240   src    : S1(read);
 6241   INS0   : ISS;
 6242   NEON_FP : S3;
 6243 %}
 6244 
 6245 pipe_class vdop_fp64(vecD dst, vecD src1, vecD src2)
 6246 %{
 6247   single_instruction;
 6248   dst    : S5(write);
 6249   src1   : S1(read);
 6250   src2   : S1(read);
 6251   INS01  : ISS;
 6252   NEON_FP : S5;
 6253 %}
 6254 
 6255 pipe_class vdop_fp128(vecX dst, vecX src1, vecX src2)
 6256 %{
 6257   single_instruction;
 6258   dst    : S5(write);
 6259   src1   : S1(read);
 6260   src2   : S1(read);
 6261   INS0   : ISS;
 6262   NEON_FP : S5;
 6263 %}
 6264 
 6265 pipe_class vmuldiv_fp64(vecD dst, vecD src1, vecD src2)
 6266 %{
 6267   single_instruction;
 6268   dst    : S5(write);
 6269   src1   : S1(read);
 6270   src2   : S1(read);
 6271   INS0   : ISS;
 6272   NEON_FP : S5;
 6273 %}
 6274 
 6275 pipe_class vmuldiv_fp128(vecX dst, vecX src1, vecX src2)
 6276 %{
 6277   single_instruction;
 6278   dst    : S5(write);
 6279   src1   : S1(read);
 6280   src2   : S1(read);
 6281   INS0   : ISS;
 6282   NEON_FP : S5;
 6283 %}
 6284 
 6285 pipe_class vsqrt_fp128(vecX dst, vecX src)
 6286 %{
 6287   single_instruction;
 6288   dst    : S5(write);
 6289   src    : S1(read);
 6290   INS0   : ISS;
 6291   NEON_FP : S5;
 6292 %}
 6293 
 6294 pipe_class vunop_fp64(vecD dst, vecD src)
 6295 %{
 6296   single_instruction;
 6297   dst    : S5(write);
 6298   src    : S1(read);
 6299   INS01  : ISS;
 6300   NEON_FP : S5;
 6301 %}
 6302 
 6303 pipe_class vunop_fp128(vecX dst, vecX src)
 6304 %{
 6305   single_instruction;
 6306   dst    : S5(write);
 6307   src    : S1(read);
 6308   INS0   : ISS;
 6309   NEON_FP : S5;
 6310 %}
 6311 
 6312 pipe_class vdup_reg_reg64(vecD dst, iRegI src)
 6313 %{
 6314   single_instruction;
 6315   dst    : S3(write);
 6316   src    : S1(read);
 6317   INS01  : ISS;
 6318   NEON_FP : S3;
 6319 %}
 6320 
 6321 pipe_class vdup_reg_reg128(vecX dst, iRegI src)
 6322 %{
 6323   single_instruction;
 6324   dst    : S3(write);
 6325   src    : S1(read);
 6326   INS01  : ISS;
 6327   NEON_FP : S3;
 6328 %}
 6329 
 6330 pipe_class vdup_reg_freg64(vecD dst, vRegF src)
 6331 %{
 6332   single_instruction;
 6333   dst    : S3(write);
 6334   src    : S1(read);
 6335   INS01  : ISS;
 6336   NEON_FP : S3;
 6337 %}
 6338 
 6339 pipe_class vdup_reg_freg128(vecX dst, vRegF src)
 6340 %{
 6341   single_instruction;
 6342   dst    : S3(write);
 6343   src    : S1(read);
 6344   INS01  : ISS;
 6345   NEON_FP : S3;
 6346 %}
 6347 
 6348 pipe_class vdup_reg_dreg128(vecX dst, vRegD src)
 6349 %{
 6350   single_instruction;
 6351   dst    : S3(write);
 6352   src    : S1(read);
 6353   INS01  : ISS;
 6354   NEON_FP : S3;
 6355 %}
 6356 
 6357 pipe_class vmovi_reg_imm64(vecD dst)
 6358 %{
 6359   single_instruction;
 6360   dst    : S3(write);
 6361   INS01  : ISS;
 6362   NEON_FP : S3;
 6363 %}
 6364 
 6365 pipe_class vmovi_reg_imm128(vecX dst)
 6366 %{
 6367   single_instruction;
 6368   dst    : S3(write);
 6369   INS0   : ISS;
 6370   NEON_FP : S3;
 6371 %}
 6372 
 6373 pipe_class vload_reg_mem64(vecD dst, vmem8 mem)
 6374 %{
 6375   single_instruction;
 6376   dst    : S5(write);
 6377   mem    : ISS(read);
 6378   INS01  : ISS;
 6379   NEON_FP : S3;
 6380 %}
 6381 
 6382 pipe_class vload_reg_mem128(vecX dst, vmem16 mem)
 6383 %{
 6384   single_instruction;
 6385   dst    : S5(write);
 6386   mem    : ISS(read);
 6387   INS01  : ISS;
 6388   NEON_FP : S3;
 6389 %}
 6390 
 6391 pipe_class vstore_reg_mem64(vecD src, vmem8 mem)
 6392 %{
 6393   single_instruction;
 6394   mem    : ISS(read);
 6395   src    : S2(read);
 6396   INS01  : ISS;
 6397   NEON_FP : S3;
 6398 %}
 6399 
 6400 pipe_class vstore_reg_mem128(vecD src, vmem16 mem)
 6401 %{
 6402   single_instruction;
 6403   mem    : ISS(read);
 6404   src    : S2(read);
 6405   INS01  : ISS;
 6406   NEON_FP : S3;
 6407 %}
 6408 
 6409 //------- Integer ALU operations --------------------------
 6410 
 6411 // Integer ALU reg-reg operation
 6412 // Operands needed in EX1, result generated in EX2
 6413 // Eg.  ADD     x0, x1, x2
 6414 pipe_class ialu_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6415 %{
 6416   single_instruction;
 6417   dst    : EX2(write);
 6418   src1   : EX1(read);
 6419   src2   : EX1(read);
 6420   INS01  : ISS; // Dual issue as instruction 0 or 1
 6421   ALU    : EX2;
 6422 %}
 6423 
 6424 // Integer ALU reg-reg operation with constant shift
 6425 // Shifted register must be available in LATE_ISS instead of EX1
 6426 // Eg.  ADD     x0, x1, x2, LSL #2
 6427 pipe_class ialu_reg_reg_shift(iRegI dst, iRegI src1, iRegI src2, immI shift)
 6428 %{
 6429   single_instruction;
 6430   dst    : EX2(write);
 6431   src1   : EX1(read);
 6432   src2   : ISS(read);
 6433   INS01  : ISS;
 6434   ALU    : EX2;
 6435 %}
 6436 
 6437 // Integer ALU reg operation with constant shift
 6438 // Eg.  LSL     x0, x1, #shift
 6439 pipe_class ialu_reg_shift(iRegI dst, iRegI src1)
 6440 %{
 6441   single_instruction;
 6442   dst    : EX2(write);
 6443   src1   : ISS(read);
 6444   INS01  : ISS;
 6445   ALU    : EX2;
 6446 %}
 6447 
 6448 // Integer ALU reg-reg operation with variable shift
 6449 // Both operands must be available in LATE_ISS instead of EX1
 6450 // Result is available in EX1 instead of EX2
 6451 // Eg.  LSLV    x0, x1, x2
 6452 pipe_class ialu_reg_reg_vshift(iRegI dst, iRegI src1, iRegI src2)
 6453 %{
 6454   single_instruction;
 6455   dst    : EX1(write);
 6456   src1   : ISS(read);
 6457   src2   : ISS(read);
 6458   INS01  : ISS;
 6459   ALU    : EX1;
 6460 %}
 6461 
 6462 // Integer ALU reg-reg operation with extract
 6463 // As for _vshift above, but result generated in EX2
 6464 // Eg.  EXTR    x0, x1, x2, #N
 6465 pipe_class ialu_reg_reg_extr(iRegI dst, iRegI src1, iRegI src2)
 6466 %{
 6467   single_instruction;
 6468   dst    : EX2(write);
 6469   src1   : ISS(read);
 6470   src2   : ISS(read);
 6471   INS1   : ISS; // Can only dual issue as Instruction 1
 6472   ALU    : EX1;
 6473 %}
 6474 
 6475 // Integer ALU reg operation
 6476 // Eg.  NEG     x0, x1
 6477 pipe_class ialu_reg(iRegI dst, iRegI src)
 6478 %{
 6479   single_instruction;
 6480   dst    : EX2(write);
 6481   src    : EX1(read);
 6482   INS01  : ISS;
 6483   ALU    : EX2;
 6484 %}
 6485 
 6486 // Integer ALU reg mmediate operation
 6487 // Eg.  ADD     x0, x1, #N
 6488 pipe_class ialu_reg_imm(iRegI dst, iRegI src1)
 6489 %{
 6490   single_instruction;
 6491   dst    : EX2(write);
 6492   src1   : EX1(read);
 6493   INS01  : ISS;
 6494   ALU    : EX2;
 6495 %}
 6496 
 6497 // Integer ALU immediate operation (no source operands)
 6498 // Eg.  MOV     x0, #N
 6499 pipe_class ialu_imm(iRegI dst)
 6500 %{
 6501   single_instruction;
 6502   dst    : EX1(write);
 6503   INS01  : ISS;
 6504   ALU    : EX1;
 6505 %}
 6506 
 6507 //------- Compare operation -------------------------------
 6508 
 6509 // Compare reg-reg
 6510 // Eg.  CMP     x0, x1
 6511 pipe_class icmp_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
 6512 %{
 6513   single_instruction;
 6514 //  fixed_latency(16);
 6515   cr     : EX2(write);
 6516   op1    : EX1(read);
 6517   op2    : EX1(read);
 6518   INS01  : ISS;
 6519   ALU    : EX2;
 6520 %}
 6521 
 6522 // Compare reg-reg
 6523 // Eg.  CMP     x0, #N
 6524 pipe_class icmp_reg_imm(rFlagsReg cr, iRegI op1)
 6525 %{
 6526   single_instruction;
 6527 //  fixed_latency(16);
 6528   cr     : EX2(write);
 6529   op1    : EX1(read);
 6530   INS01  : ISS;
 6531   ALU    : EX2;
 6532 %}
 6533 
 6534 //------- Conditional instructions ------------------------
 6535 
 6536 // Conditional no operands
 6537 // Eg.  CSINC   x0, zr, zr, &lt;cond&gt;
 6538 pipe_class icond_none(iRegI dst, rFlagsReg cr)
 6539 %{
 6540   single_instruction;
 6541   cr     : EX1(read);
 6542   dst    : EX2(write);
 6543   INS01  : ISS;
 6544   ALU    : EX2;
 6545 %}
 6546 
 6547 // Conditional 2 operand
 6548 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6549 pipe_class icond_reg_reg(iRegI dst, iRegI src1, iRegI src2, rFlagsReg cr)
 6550 %{
 6551   single_instruction;
 6552   cr     : EX1(read);
 6553   src1   : EX1(read);
 6554   src2   : EX1(read);
 6555   dst    : EX2(write);
 6556   INS01  : ISS;
 6557   ALU    : EX2;
 6558 %}
 6559 
 6560 // Conditional 2 operand
 6561 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6562 pipe_class icond_reg(iRegI dst, iRegI src, rFlagsReg cr)
 6563 %{
 6564   single_instruction;
 6565   cr     : EX1(read);
 6566   src    : EX1(read);
 6567   dst    : EX2(write);
 6568   INS01  : ISS;
 6569   ALU    : EX2;
 6570 %}
 6571 
 6572 //------- Multiply pipeline operations --------------------
 6573 
 6574 // Multiply reg-reg
 6575 // Eg.  MUL     w0, w1, w2
 6576 pipe_class imul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6577 %{
 6578   single_instruction;
 6579   dst    : WR(write);
 6580   src1   : ISS(read);
 6581   src2   : ISS(read);
 6582   INS01  : ISS;
 6583   MAC    : WR;
 6584 %}
 6585 
 6586 // Multiply accumulate
 6587 // Eg.  MADD    w0, w1, w2, w3
 6588 pipe_class imac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6589 %{
 6590   single_instruction;
 6591   dst    : WR(write);
 6592   src1   : ISS(read);
 6593   src2   : ISS(read);
 6594   src3   : ISS(read);
 6595   INS01  : ISS;
 6596   MAC    : WR;
 6597 %}
 6598 
 6599 // Eg.  MUL     w0, w1, w2
 6600 pipe_class lmul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6601 %{
 6602   single_instruction;
 6603   fixed_latency(3); // Maximum latency for 64 bit mul
 6604   dst    : WR(write);
 6605   src1   : ISS(read);
 6606   src2   : ISS(read);
 6607   INS01  : ISS;
 6608   MAC    : WR;
 6609 %}
 6610 
 6611 // Multiply accumulate
 6612 // Eg.  MADD    w0, w1, w2, w3
 6613 pipe_class lmac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6614 %{
 6615   single_instruction;
 6616   fixed_latency(3); // Maximum latency for 64 bit mul
 6617   dst    : WR(write);
 6618   src1   : ISS(read);
 6619   src2   : ISS(read);
 6620   src3   : ISS(read);
 6621   INS01  : ISS;
 6622   MAC    : WR;
 6623 %}
 6624 
 6625 //------- Divide pipeline operations --------------------
 6626 
 6627 // Eg.  SDIV    w0, w1, w2
 6628 pipe_class idiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6629 %{
 6630   single_instruction;
 6631   fixed_latency(8); // Maximum latency for 32 bit divide
 6632   dst    : WR(write);
 6633   src1   : ISS(read);
 6634   src2   : ISS(read);
 6635   INS0   : ISS; // Can only dual issue as instruction 0
 6636   DIV    : WR;
 6637 %}
 6638 
 6639 // Eg.  SDIV    x0, x1, x2
 6640 pipe_class ldiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6641 %{
 6642   single_instruction;
 6643   fixed_latency(16); // Maximum latency for 64 bit divide
 6644   dst    : WR(write);
 6645   src1   : ISS(read);
 6646   src2   : ISS(read);
 6647   INS0   : ISS; // Can only dual issue as instruction 0
 6648   DIV    : WR;
 6649 %}
 6650 
 6651 //------- Load pipeline operations ------------------------
 6652 
 6653 // Load - prefetch
 6654 // Eg.  PFRM    &lt;mem&gt;
 6655 pipe_class iload_prefetch(memory mem)
 6656 %{
 6657   single_instruction;
 6658   mem    : ISS(read);
 6659   INS01  : ISS;
 6660   LDST   : WR;
 6661 %}
 6662 
 6663 // Load - reg, mem
 6664 // Eg.  LDR     x0, &lt;mem&gt;
 6665 pipe_class iload_reg_mem(iRegI dst, memory mem)
 6666 %{
 6667   single_instruction;
 6668   dst    : WR(write);
 6669   mem    : ISS(read);
 6670   INS01  : ISS;
 6671   LDST   : WR;
 6672 %}
 6673 
 6674 // Load - reg, reg
 6675 // Eg.  LDR     x0, [sp, x1]
 6676 pipe_class iload_reg_reg(iRegI dst, iRegI src)
 6677 %{
 6678   single_instruction;
 6679   dst    : WR(write);
 6680   src    : ISS(read);
 6681   INS01  : ISS;
 6682   LDST   : WR;
 6683 %}
 6684 
 6685 //------- Store pipeline operations -----------------------
 6686 
 6687 // Store - zr, mem
 6688 // Eg.  STR     zr, &lt;mem&gt;
 6689 pipe_class istore_mem(memory mem)
 6690 %{
 6691   single_instruction;
 6692   mem    : ISS(read);
 6693   INS01  : ISS;
 6694   LDST   : WR;
 6695 %}
 6696 
 6697 // Store - reg, mem
 6698 // Eg.  STR     x0, &lt;mem&gt;
 6699 pipe_class istore_reg_mem(iRegI src, memory mem)
 6700 %{
 6701   single_instruction;
 6702   mem    : ISS(read);
 6703   src    : EX2(read);
 6704   INS01  : ISS;
 6705   LDST   : WR;
 6706 %}
 6707 
 6708 // Store - reg, reg
 6709 // Eg. STR      x0, [sp, x1]
 6710 pipe_class istore_reg_reg(iRegI dst, iRegI src)
 6711 %{
 6712   single_instruction;
 6713   dst    : ISS(read);
 6714   src    : EX2(read);
 6715   INS01  : ISS;
 6716   LDST   : WR;
 6717 %}
 6718 
 6719 //------- Store pipeline operations -----------------------
 6720 
 6721 // Branch
 6722 pipe_class pipe_branch()
 6723 %{
 6724   single_instruction;
 6725   INS01  : ISS;
 6726   BRANCH : EX1;
 6727 %}
 6728 
 6729 // Conditional branch
 6730 pipe_class pipe_branch_cond(rFlagsReg cr)
 6731 %{
 6732   single_instruction;
 6733   cr     : EX1(read);
 6734   INS01  : ISS;
 6735   BRANCH : EX1;
 6736 %}
 6737 
 6738 // Compare &amp; Branch
 6739 // EG.  CBZ/CBNZ
 6740 pipe_class pipe_cmp_branch(iRegI op1)
 6741 %{
 6742   single_instruction;
 6743   op1    : EX1(read);
 6744   INS01  : ISS;
 6745   BRANCH : EX1;
 6746 %}
 6747 
 6748 //------- Synchronisation operations ----------------------
 6749 
 6750 // Any operation requiring serialization.
 6751 // EG.  DMB/Atomic Ops/Load Acquire/Str Release
 6752 pipe_class pipe_serial()
 6753 %{
 6754   single_instruction;
 6755   force_serialization;
 6756   fixed_latency(16);
 6757   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6758   LDST   : WR;
 6759 %}
 6760 
 6761 // Generic big/slow expanded idiom - also serialized
 6762 pipe_class pipe_slow()
 6763 %{
 6764   instruction_count(10);
 6765   multiple_bundles;
 6766   force_serialization;
 6767   fixed_latency(16);
 6768   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6769   LDST   : WR;
 6770 %}
 6771 
 6772 // Empty pipeline class
 6773 pipe_class pipe_class_empty()
 6774 %{
 6775   single_instruction;
 6776   fixed_latency(0);
 6777 %}
 6778 
 6779 // Default pipeline class.
 6780 pipe_class pipe_class_default()
 6781 %{
 6782   single_instruction;
 6783   fixed_latency(2);
 6784 %}
 6785 
 6786 // Pipeline class for compares.
 6787 pipe_class pipe_class_compare()
 6788 %{
 6789   single_instruction;
 6790   fixed_latency(16);
 6791 %}
 6792 
 6793 // Pipeline class for memory operations.
 6794 pipe_class pipe_class_memory()
 6795 %{
 6796   single_instruction;
 6797   fixed_latency(16);
 6798 %}
 6799 
 6800 // Pipeline class for call.
 6801 pipe_class pipe_class_call()
 6802 %{
 6803   single_instruction;
 6804   fixed_latency(100);
 6805 %}
 6806 
 6807 // Define the class for the Nop node.
 6808 define %{
 6809    MachNop = pipe_class_empty;
 6810 %}
 6811 
 6812 %}
 6813 //----------INSTRUCTIONS-------------------------------------------------------
 6814 //
 6815 // match      -- States which machine-independent subtree may be replaced
 6816 //               by this instruction.
 6817 // ins_cost   -- The estimated cost of this instruction is used by instruction
 6818 //               selection to identify a minimum cost tree of machine
 6819 //               instructions that matches a tree of machine-independent
 6820 //               instructions.
 6821 // format     -- A string providing the disassembly for this instruction.
 6822 //               The value of an instruction&#39;s operand may be inserted
 6823 //               by referring to it with a &#39;$&#39; prefix.
 6824 // opcode     -- Three instruction opcodes may be provided.  These are referred
 6825 //               to within an encode class as $primary, $secondary, and $tertiary
 6826 //               rrspectively.  The primary opcode is commonly used to
 6827 //               indicate the type of machine instruction, while secondary
 6828 //               and tertiary are often used for prefix options or addressing
 6829 //               modes.
 6830 // ins_encode -- A list of encode classes with parameters. The encode class
 6831 //               name must have been defined in an &#39;enc_class&#39; specification
 6832 //               in the encode section of the architecture description.
 6833 
 6834 // ============================================================================
 6835 // Memory (Load/Store) Instructions
 6836 
 6837 // Load Instructions
 6838 
 6839 // Load Byte (8 bit signed)
 6840 instruct loadB(iRegINoSp dst, memory1 mem)
 6841 %{
 6842   match(Set dst (LoadB mem));
 6843   predicate(!needs_acquiring_load(n));
 6844 
 6845   ins_cost(4 * INSN_COST);
 6846   format %{ &quot;ldrsbw  $dst, $mem\t# byte&quot; %}
 6847 
 6848   ins_encode(aarch64_enc_ldrsbw(dst, mem));
 6849 
 6850   ins_pipe(iload_reg_mem);
 6851 %}
 6852 
 6853 // Load Byte (8 bit signed) into long
 6854 instruct loadB2L(iRegLNoSp dst, memory1 mem)
 6855 %{
 6856   match(Set dst (ConvI2L (LoadB mem)));
 6857   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6858 
 6859   ins_cost(4 * INSN_COST);
 6860   format %{ &quot;ldrsb  $dst, $mem\t# byte&quot; %}
 6861 
 6862   ins_encode(aarch64_enc_ldrsb(dst, mem));
 6863 
 6864   ins_pipe(iload_reg_mem);
 6865 %}
 6866 
 6867 // Load Byte (8 bit unsigned)
 6868 instruct loadUB(iRegINoSp dst, memory1 mem)
 6869 %{
 6870   match(Set dst (LoadUB mem));
 6871   predicate(!needs_acquiring_load(n));
 6872 
 6873   ins_cost(4 * INSN_COST);
 6874   format %{ &quot;ldrbw  $dst, $mem\t# byte&quot; %}
 6875 
 6876   ins_encode(aarch64_enc_ldrb(dst, mem));
 6877 
 6878   ins_pipe(iload_reg_mem);
 6879 %}
 6880 
 6881 // Load Byte (8 bit unsigned) into long
 6882 instruct loadUB2L(iRegLNoSp dst, memory1 mem)
 6883 %{
 6884   match(Set dst (ConvI2L (LoadUB mem)));
 6885   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6886 
 6887   ins_cost(4 * INSN_COST);
 6888   format %{ &quot;ldrb  $dst, $mem\t# byte&quot; %}
 6889 
 6890   ins_encode(aarch64_enc_ldrb(dst, mem));
 6891 
 6892   ins_pipe(iload_reg_mem);
 6893 %}
 6894 
 6895 // Load Short (16 bit signed)
 6896 instruct loadS(iRegINoSp dst, memory2 mem)
 6897 %{
 6898   match(Set dst (LoadS mem));
 6899   predicate(!needs_acquiring_load(n));
 6900 
 6901   ins_cost(4 * INSN_COST);
 6902   format %{ &quot;ldrshw  $dst, $mem\t# short&quot; %}
 6903 
 6904   ins_encode(aarch64_enc_ldrshw(dst, mem));
 6905 
 6906   ins_pipe(iload_reg_mem);
 6907 %}
 6908 
 6909 // Load Short (16 bit signed) into long
 6910 instruct loadS2L(iRegLNoSp dst, memory2 mem)
 6911 %{
 6912   match(Set dst (ConvI2L (LoadS mem)));
 6913   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6914 
 6915   ins_cost(4 * INSN_COST);
 6916   format %{ &quot;ldrsh  $dst, $mem\t# short&quot; %}
 6917 
 6918   ins_encode(aarch64_enc_ldrsh(dst, mem));
 6919 
 6920   ins_pipe(iload_reg_mem);
 6921 %}
 6922 
 6923 // Load Char (16 bit unsigned)
 6924 instruct loadUS(iRegINoSp dst, memory2 mem)
 6925 %{
 6926   match(Set dst (LoadUS mem));
 6927   predicate(!needs_acquiring_load(n));
 6928 
 6929   ins_cost(4 * INSN_COST);
 6930   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6931 
 6932   ins_encode(aarch64_enc_ldrh(dst, mem));
 6933 
 6934   ins_pipe(iload_reg_mem);
 6935 %}
 6936 
 6937 // Load Short/Char (16 bit unsigned) into long
 6938 instruct loadUS2L(iRegLNoSp dst, memory2 mem)
 6939 %{
 6940   match(Set dst (ConvI2L (LoadUS mem)));
 6941   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6942 
 6943   ins_cost(4 * INSN_COST);
 6944   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6945 
 6946   ins_encode(aarch64_enc_ldrh(dst, mem));
 6947 
 6948   ins_pipe(iload_reg_mem);
 6949 %}
 6950 
 6951 // Load Integer (32 bit signed)
 6952 instruct loadI(iRegINoSp dst, memory4 mem)
 6953 %{
 6954   match(Set dst (LoadI mem));
 6955   predicate(!needs_acquiring_load(n));
 6956 
 6957   ins_cost(4 * INSN_COST);
 6958   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6959 
 6960   ins_encode(aarch64_enc_ldrw(dst, mem));
 6961 
 6962   ins_pipe(iload_reg_mem);
 6963 %}
 6964 
 6965 // Load Integer (32 bit signed) into long
 6966 instruct loadI2L(iRegLNoSp dst, memory4 mem)
 6967 %{
 6968   match(Set dst (ConvI2L (LoadI mem)));
 6969   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6970 
 6971   ins_cost(4 * INSN_COST);
 6972   format %{ &quot;ldrsw  $dst, $mem\t# int&quot; %}
 6973 
 6974   ins_encode(aarch64_enc_ldrsw(dst, mem));
 6975 
 6976   ins_pipe(iload_reg_mem);
 6977 %}
 6978 
 6979 // Load Integer (32 bit unsigned) into long
 6980 instruct loadUI2L(iRegLNoSp dst, memory4 mem, immL_32bits mask)
 6981 %{
 6982   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 6983   predicate(!needs_acquiring_load(n-&gt;in(1)-&gt;in(1)-&gt;as_Load()));
 6984 
 6985   ins_cost(4 * INSN_COST);
 6986   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6987 
 6988   ins_encode(aarch64_enc_ldrw(dst, mem));
 6989 
 6990   ins_pipe(iload_reg_mem);
 6991 %}
 6992 
 6993 // Load Long (64 bit signed)
 6994 instruct loadL(iRegLNoSp dst, memory8 mem)
 6995 %{
 6996   match(Set dst (LoadL mem));
 6997   predicate(!needs_acquiring_load(n));
 6998 
 6999   ins_cost(4 * INSN_COST);
 7000   format %{ &quot;ldr  $dst, $mem\t# int&quot; %}
 7001 
 7002   ins_encode(aarch64_enc_ldr(dst, mem));
 7003 
 7004   ins_pipe(iload_reg_mem);
 7005 %}
 7006 
 7007 // Load Range
 7008 instruct loadRange(iRegINoSp dst, memory4 mem)
 7009 %{
 7010   match(Set dst (LoadRange mem));
 7011 
 7012   ins_cost(4 * INSN_COST);
 7013   format %{ &quot;ldrw  $dst, $mem\t# range&quot; %}
 7014 
 7015   ins_encode(aarch64_enc_ldrw(dst, mem));
 7016 
 7017   ins_pipe(iload_reg_mem);
 7018 %}
 7019 
 7020 // Load Pointer
 7021 instruct loadP(iRegPNoSp dst, memory8 mem)
 7022 %{
 7023   match(Set dst (LoadP mem));
 7024   predicate(!needs_acquiring_load(n) &amp;&amp; (n-&gt;as_Load()-&gt;barrier_data() == 0));
 7025 
 7026   ins_cost(4 * INSN_COST);
 7027   format %{ &quot;ldr  $dst, $mem\t# ptr&quot; %}
 7028 
 7029   ins_encode(aarch64_enc_ldr(dst, mem));
 7030 
 7031   ins_pipe(iload_reg_mem);
 7032 %}
 7033 
 7034 // Load Compressed Pointer
 7035 instruct loadN(iRegNNoSp dst, memory4 mem)
 7036 %{
 7037   match(Set dst (LoadN mem));
 7038   predicate(!needs_acquiring_load(n));
 7039 
 7040   ins_cost(4 * INSN_COST);
 7041   format %{ &quot;ldrw  $dst, $mem\t# compressed ptr&quot; %}
 7042 
 7043   ins_encode(aarch64_enc_ldrw(dst, mem));
 7044 
 7045   ins_pipe(iload_reg_mem);
 7046 %}
 7047 
 7048 // Load Klass Pointer
 7049 instruct loadKlass(iRegPNoSp dst, memory8 mem)
 7050 %{
 7051   match(Set dst (LoadKlass mem));
 7052   predicate(!needs_acquiring_load(n));
 7053 
 7054   ins_cost(4 * INSN_COST);
 7055   format %{ &quot;ldr  $dst, $mem\t# class&quot; %}
 7056 
 7057   ins_encode(aarch64_enc_ldr(dst, mem));
 7058 
 7059   ins_pipe(iload_reg_mem);
 7060 %}
 7061 
 7062 // Load Narrow Klass Pointer
 7063 instruct loadNKlass(iRegNNoSp dst, memory4 mem)
 7064 %{
 7065   match(Set dst (LoadNKlass mem));
 7066   predicate(!needs_acquiring_load(n));
 7067 
 7068   ins_cost(4 * INSN_COST);
 7069   format %{ &quot;ldrw  $dst, $mem\t# compressed class ptr&quot; %}
 7070 
 7071   ins_encode(aarch64_enc_ldrw(dst, mem));
 7072 
 7073   ins_pipe(iload_reg_mem);
 7074 %}
 7075 
 7076 // Load Float
 7077 instruct loadF(vRegF dst, memory4 mem)
 7078 %{
 7079   match(Set dst (LoadF mem));
 7080   predicate(!needs_acquiring_load(n));
 7081 
 7082   ins_cost(4 * INSN_COST);
 7083   format %{ &quot;ldrs  $dst, $mem\t# float&quot; %}
 7084 
 7085   ins_encode( aarch64_enc_ldrs(dst, mem) );
 7086 
 7087   ins_pipe(pipe_class_memory);
 7088 %}
 7089 
 7090 // Load Double
 7091 instruct loadD(vRegD dst, memory8 mem)
 7092 %{
 7093   match(Set dst (LoadD mem));
 7094   predicate(!needs_acquiring_load(n));
 7095 
 7096   ins_cost(4 * INSN_COST);
 7097   format %{ &quot;ldrd  $dst, $mem\t# double&quot; %}
 7098 
 7099   ins_encode( aarch64_enc_ldrd(dst, mem) );
 7100 
 7101   ins_pipe(pipe_class_memory);
 7102 %}
 7103 
 7104 
 7105 // Load Int Constant
 7106 instruct loadConI(iRegINoSp dst, immI src)
 7107 %{
 7108   match(Set dst src);
 7109 
 7110   ins_cost(INSN_COST);
 7111   format %{ &quot;mov $dst, $src\t# int&quot; %}
 7112 
 7113   ins_encode( aarch64_enc_movw_imm(dst, src) );
 7114 
 7115   ins_pipe(ialu_imm);
 7116 %}
 7117 
 7118 // Load Long Constant
 7119 instruct loadConL(iRegLNoSp dst, immL src)
 7120 %{
 7121   match(Set dst src);
 7122 
 7123   ins_cost(INSN_COST);
 7124   format %{ &quot;mov $dst, $src\t# long&quot; %}
 7125 
 7126   ins_encode( aarch64_enc_mov_imm(dst, src) );
 7127 
 7128   ins_pipe(ialu_imm);
 7129 %}
 7130 
 7131 // Load Pointer Constant
 7132 
 7133 instruct loadConP(iRegPNoSp dst, immP con)
 7134 %{
 7135   match(Set dst con);
 7136 
 7137   ins_cost(INSN_COST * 4);
 7138   format %{
 7139     &quot;mov  $dst, $con\t# ptr\n\t&quot;
 7140   %}
 7141 
 7142   ins_encode(aarch64_enc_mov_p(dst, con));
 7143 
 7144   ins_pipe(ialu_imm);
 7145 %}
 7146 
 7147 // Load Null Pointer Constant
 7148 
 7149 instruct loadConP0(iRegPNoSp dst, immP0 con)
 7150 %{
 7151   match(Set dst con);
 7152 
 7153   ins_cost(INSN_COST);
 7154   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7155 
 7156   ins_encode(aarch64_enc_mov_p0(dst, con));
 7157 
 7158   ins_pipe(ialu_imm);
 7159 %}
 7160 
 7161 // Load Pointer Constant One
 7162 
 7163 instruct loadConP1(iRegPNoSp dst, immP_1 con)
 7164 %{
 7165   match(Set dst con);
 7166 
 7167   ins_cost(INSN_COST);
 7168   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7169 
 7170   ins_encode(aarch64_enc_mov_p1(dst, con));
 7171 
 7172   ins_pipe(ialu_imm);
 7173 %}
 7174 
 7175 // Load Byte Map Base Constant
 7176 
 7177 instruct loadByteMapBase(iRegPNoSp dst, immByteMapBase con)
 7178 %{
 7179   match(Set dst con);
 7180 
 7181   ins_cost(INSN_COST);
 7182   format %{ &quot;adr  $dst, $con\t# Byte Map Base&quot; %}
 7183 
 7184   ins_encode(aarch64_enc_mov_byte_map_base(dst, con));
 7185 
 7186   ins_pipe(ialu_imm);
 7187 %}
 7188 
 7189 // Load Narrow Pointer Constant
 7190 
 7191 instruct loadConN(iRegNNoSp dst, immN con)
 7192 %{
 7193   match(Set dst con);
 7194 
 7195   ins_cost(INSN_COST * 4);
 7196   format %{ &quot;mov  $dst, $con\t# compressed ptr&quot; %}
 7197 
 7198   ins_encode(aarch64_enc_mov_n(dst, con));
 7199 
 7200   ins_pipe(ialu_imm);
 7201 %}
 7202 
 7203 // Load Narrow Null Pointer Constant
 7204 
 7205 instruct loadConN0(iRegNNoSp dst, immN0 con)
 7206 %{
 7207   match(Set dst con);
 7208 
 7209   ins_cost(INSN_COST);
 7210   format %{ &quot;mov  $dst, $con\t# compressed NULL ptr&quot; %}
 7211 
 7212   ins_encode(aarch64_enc_mov_n0(dst, con));
 7213 
 7214   ins_pipe(ialu_imm);
 7215 %}
 7216 
 7217 // Load Narrow Klass Constant
 7218 
 7219 instruct loadConNKlass(iRegNNoSp dst, immNKlass con)
 7220 %{
 7221   match(Set dst con);
 7222 
 7223   ins_cost(INSN_COST);
 7224   format %{ &quot;mov  $dst, $con\t# compressed klass ptr&quot; %}
 7225 
 7226   ins_encode(aarch64_enc_mov_nk(dst, con));
 7227 
 7228   ins_pipe(ialu_imm);
 7229 %}
 7230 
 7231 // Load Packed Float Constant
 7232 
 7233 instruct loadConF_packed(vRegF dst, immFPacked con) %{
 7234   match(Set dst con);
 7235   ins_cost(INSN_COST * 4);
 7236   format %{ &quot;fmovs  $dst, $con&quot;%}
 7237   ins_encode %{
 7238     __ fmovs(as_FloatRegister($dst$$reg), (double)$con$$constant);
 7239   %}
 7240 
 7241   ins_pipe(fp_imm_s);
 7242 %}
 7243 
 7244 // Load Float Constant
 7245 
 7246 instruct loadConF(vRegF dst, immF con) %{
 7247   match(Set dst con);
 7248 
 7249   ins_cost(INSN_COST * 4);
 7250 
 7251   format %{
 7252     &quot;ldrs $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7253   %}
 7254 
 7255   ins_encode %{
 7256     __ ldrs(as_FloatRegister($dst$$reg), $constantaddress($con));
 7257   %}
 7258 
 7259   ins_pipe(fp_load_constant_s);
 7260 %}
 7261 
 7262 // Load Packed Double Constant
 7263 
 7264 instruct loadConD_packed(vRegD dst, immDPacked con) %{
 7265   match(Set dst con);
 7266   ins_cost(INSN_COST);
 7267   format %{ &quot;fmovd  $dst, $con&quot;%}
 7268   ins_encode %{
 7269     __ fmovd(as_FloatRegister($dst$$reg), $con$$constant);
 7270   %}
 7271 
 7272   ins_pipe(fp_imm_d);
 7273 %}
 7274 
 7275 // Load Double Constant
 7276 
 7277 instruct loadConD(vRegD dst, immD con) %{
 7278   match(Set dst con);
 7279 
 7280   ins_cost(INSN_COST * 5);
 7281   format %{
 7282     &quot;ldrd $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7283   %}
 7284 
 7285   ins_encode %{
 7286     __ ldrd(as_FloatRegister($dst$$reg), $constantaddress($con));
 7287   %}
 7288 
 7289   ins_pipe(fp_load_constant_d);
 7290 %}
 7291 
 7292 // Store Instructions
 7293 
 7294 // Store CMS card-mark Immediate
 7295 instruct storeimmCM0(immI0 zero, memory1 mem)
 7296 %{
 7297   match(Set mem (StoreCM mem zero));
 7298 
 7299   ins_cost(INSN_COST);
 7300   format %{ &quot;storestore (elided)\n\t&quot;
 7301             &quot;strb zr, $mem\t# byte&quot; %}
 7302 
 7303   ins_encode(aarch64_enc_strb0(mem));
 7304 
 7305   ins_pipe(istore_mem);
 7306 %}
 7307 
 7308 // Store CMS card-mark Immediate with intervening StoreStore
 7309 // needed when using CMS with no conditional card marking
 7310 instruct storeimmCM0_ordered(immI0 zero, memory1 mem)
 7311 %{
 7312   match(Set mem (StoreCM mem zero));
 7313 
 7314   ins_cost(INSN_COST * 2);
 7315   format %{ &quot;storestore\n\t&quot;
 7316             &quot;dmb ishst&quot;
 7317             &quot;\n\tstrb zr, $mem\t# byte&quot; %}
 7318 
 7319   ins_encode(aarch64_enc_strb0_ordered(mem));
 7320 
 7321   ins_pipe(istore_mem);
 7322 %}
 7323 
 7324 // Store Byte
 7325 instruct storeB(iRegIorL2I src, memory1 mem)
 7326 %{
 7327   match(Set mem (StoreB mem src));
 7328   predicate(!needs_releasing_store(n));
 7329 
 7330   ins_cost(INSN_COST);
 7331   format %{ &quot;strb  $src, $mem\t# byte&quot; %}
 7332 
 7333   ins_encode(aarch64_enc_strb(src, mem));
 7334 
 7335   ins_pipe(istore_reg_mem);
 7336 %}
 7337 
 7338 
 7339 instruct storeimmB0(immI0 zero, memory1 mem)
 7340 %{
 7341   match(Set mem (StoreB mem zero));
 7342   predicate(!needs_releasing_store(n));
 7343 
 7344   ins_cost(INSN_COST);
 7345   format %{ &quot;strb rscractch2, $mem\t# byte&quot; %}
 7346 
 7347   ins_encode(aarch64_enc_strb0(mem));
 7348 
 7349   ins_pipe(istore_mem);
 7350 %}
 7351 
 7352 // Store Char/Short
 7353 instruct storeC(iRegIorL2I src, memory2 mem)
 7354 %{
 7355   match(Set mem (StoreC mem src));
 7356   predicate(!needs_releasing_store(n));
 7357 
 7358   ins_cost(INSN_COST);
 7359   format %{ &quot;strh  $src, $mem\t# short&quot; %}
 7360 
 7361   ins_encode(aarch64_enc_strh(src, mem));
 7362 
 7363   ins_pipe(istore_reg_mem);
 7364 %}
 7365 
 7366 instruct storeimmC0(immI0 zero, memory2 mem)
 7367 %{
 7368   match(Set mem (StoreC mem zero));
 7369   predicate(!needs_releasing_store(n));
 7370 
 7371   ins_cost(INSN_COST);
 7372   format %{ &quot;strh  zr, $mem\t# short&quot; %}
 7373 
 7374   ins_encode(aarch64_enc_strh0(mem));
 7375 
 7376   ins_pipe(istore_mem);
 7377 %}
 7378 
 7379 // Store Integer
 7380 
 7381 instruct storeI(iRegIorL2I src, memory4 mem)
 7382 %{
 7383   match(Set mem(StoreI mem src));
 7384   predicate(!needs_releasing_store(n));
 7385 
 7386   ins_cost(INSN_COST);
 7387   format %{ &quot;strw  $src, $mem\t# int&quot; %}
 7388 
 7389   ins_encode(aarch64_enc_strw(src, mem));
 7390 
 7391   ins_pipe(istore_reg_mem);
 7392 %}
 7393 
 7394 instruct storeimmI0(immI0 zero, memory4 mem)
 7395 %{
 7396   match(Set mem(StoreI mem zero));
 7397   predicate(!needs_releasing_store(n));
 7398 
 7399   ins_cost(INSN_COST);
 7400   format %{ &quot;strw  zr, $mem\t# int&quot; %}
 7401 
 7402   ins_encode(aarch64_enc_strw0(mem));
 7403 
 7404   ins_pipe(istore_mem);
 7405 %}
 7406 
 7407 // Store Long (64 bit signed)
 7408 instruct storeL(iRegL src, memory8 mem)
 7409 %{
 7410   match(Set mem (StoreL mem src));
 7411   predicate(!needs_releasing_store(n));
 7412 
 7413   ins_cost(INSN_COST);
 7414   format %{ &quot;str  $src, $mem\t# int&quot; %}
 7415 
 7416   ins_encode(aarch64_enc_str(src, mem));
 7417 
 7418   ins_pipe(istore_reg_mem);
 7419 %}
 7420 
 7421 // Store Long (64 bit signed)
 7422 instruct storeimmL0(immL0 zero, memory8 mem)
 7423 %{
 7424   match(Set mem (StoreL mem zero));
 7425   predicate(!needs_releasing_store(n));
 7426 
 7427   ins_cost(INSN_COST);
 7428   format %{ &quot;str  zr, $mem\t# int&quot; %}
 7429 
 7430   ins_encode(aarch64_enc_str0(mem));
 7431 
 7432   ins_pipe(istore_mem);
 7433 %}
 7434 
 7435 // Store Pointer
 7436 instruct storeP(iRegP src, memory8 mem)
 7437 %{
 7438   match(Set mem (StoreP mem src));
 7439   predicate(!needs_releasing_store(n));
 7440 
 7441   ins_cost(INSN_COST);
 7442   format %{ &quot;str  $src, $mem\t# ptr&quot; %}
 7443 
 7444   ins_encode(aarch64_enc_str(src, mem));
 7445 
 7446   ins_pipe(istore_reg_mem);
 7447 %}
 7448 
 7449 // Store Pointer
 7450 instruct storeimmP0(immP0 zero, memory8 mem)
 7451 %{
 7452   match(Set mem (StoreP mem zero));
 7453   predicate(!needs_releasing_store(n));
 7454 
 7455   ins_cost(INSN_COST);
 7456   format %{ &quot;str zr, $mem\t# ptr&quot; %}
 7457 
 7458   ins_encode(aarch64_enc_str0(mem));
 7459 
 7460   ins_pipe(istore_mem);
 7461 %}
 7462 
 7463 // Store Compressed Pointer
 7464 instruct storeN(iRegN src, memory4 mem)
 7465 %{
 7466   match(Set mem (StoreN mem src));
 7467   predicate(!needs_releasing_store(n));
 7468 
 7469   ins_cost(INSN_COST);
 7470   format %{ &quot;strw  $src, $mem\t# compressed ptr&quot; %}
 7471 
 7472   ins_encode(aarch64_enc_strw(src, mem));
 7473 
 7474   ins_pipe(istore_reg_mem);
 7475 %}
 7476 
 7477 instruct storeImmN0(immN0 zero, memory4 mem)
 7478 %{
 7479   match(Set mem (StoreN mem zero));
 7480   predicate(!needs_releasing_store(n));
 7481 
 7482   ins_cost(INSN_COST);
 7483   format %{ &quot;strw  zr, $mem\t# compressed ptr&quot; %}
 7484 
 7485   ins_encode(aarch64_enc_strw0(mem));
 7486 
 7487   ins_pipe(istore_mem);
 7488 %}
 7489 
 7490 // Store Float
 7491 instruct storeF(vRegF src, memory4 mem)
 7492 %{
 7493   match(Set mem (StoreF mem src));
 7494   predicate(!needs_releasing_store(n));
 7495 
 7496   ins_cost(INSN_COST);
 7497   format %{ &quot;strs  $src, $mem\t# float&quot; %}
 7498 
 7499   ins_encode( aarch64_enc_strs(src, mem) );
 7500 
 7501   ins_pipe(pipe_class_memory);
 7502 %}
 7503 
 7504 // TODO
 7505 // implement storeImmF0 and storeFImmPacked
 7506 
 7507 // Store Double
 7508 instruct storeD(vRegD src, memory8 mem)
 7509 %{
 7510   match(Set mem (StoreD mem src));
 7511   predicate(!needs_releasing_store(n));
 7512 
 7513   ins_cost(INSN_COST);
 7514   format %{ &quot;strd  $src, $mem\t# double&quot; %}
 7515 
 7516   ins_encode( aarch64_enc_strd(src, mem) );
 7517 
 7518   ins_pipe(pipe_class_memory);
 7519 %}
 7520 
 7521 // Store Compressed Klass Pointer
 7522 instruct storeNKlass(iRegN src, memory4 mem)
 7523 %{
 7524   predicate(!needs_releasing_store(n));
 7525   match(Set mem (StoreNKlass mem src));
 7526 
 7527   ins_cost(INSN_COST);
 7528   format %{ &quot;strw  $src, $mem\t# compressed klass ptr&quot; %}
 7529 
 7530   ins_encode(aarch64_enc_strw(src, mem));
 7531 
 7532   ins_pipe(istore_reg_mem);
 7533 %}
 7534 
 7535 // TODO
 7536 // implement storeImmD0 and storeDImmPacked
 7537 
 7538 // prefetch instructions
 7539 // Must be safe to execute with invalid address (cannot fault).
 7540 
 7541 instruct prefetchalloc( memory8 mem ) %{
 7542   match(PrefetchAllocation mem);
 7543 
 7544   ins_cost(INSN_COST);
 7545   format %{ &quot;prfm $mem, PSTL1KEEP\t# Prefetch into level 1 cache write keep&quot; %}
 7546 
 7547   ins_encode( aarch64_enc_prefetchw(mem) );
 7548 
 7549   ins_pipe(iload_prefetch);
 7550 %}
 7551 
 7552 //  ---------------- volatile loads and stores ----------------
 7553 
 7554 // Load Byte (8 bit signed)
 7555 instruct loadB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7556 %{
 7557   match(Set dst (LoadB mem));
 7558 
 7559   ins_cost(VOLATILE_REF_COST);
 7560   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7561 
 7562   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7563 
 7564   ins_pipe(pipe_serial);
 7565 %}
 7566 
 7567 // Load Byte (8 bit signed) into long
 7568 instruct loadB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7569 %{
 7570   match(Set dst (ConvI2L (LoadB mem)));
 7571 
 7572   ins_cost(VOLATILE_REF_COST);
 7573   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7574 
 7575   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7576 
 7577   ins_pipe(pipe_serial);
 7578 %}
 7579 
 7580 // Load Byte (8 bit unsigned)
 7581 instruct loadUB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7582 %{
 7583   match(Set dst (LoadUB mem));
 7584 
 7585   ins_cost(VOLATILE_REF_COST);
 7586   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7587 
 7588   ins_encode(aarch64_enc_ldarb(dst, mem));
 7589 
 7590   ins_pipe(pipe_serial);
 7591 %}
 7592 
 7593 // Load Byte (8 bit unsigned) into long
 7594 instruct loadUB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7595 %{
 7596   match(Set dst (ConvI2L (LoadUB mem)));
 7597 
 7598   ins_cost(VOLATILE_REF_COST);
 7599   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7600 
 7601   ins_encode(aarch64_enc_ldarb(dst, mem));
 7602 
 7603   ins_pipe(pipe_serial);
 7604 %}
 7605 
 7606 // Load Short (16 bit signed)
 7607 instruct loadS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7608 %{
 7609   match(Set dst (LoadS mem));
 7610 
 7611   ins_cost(VOLATILE_REF_COST);
 7612   format %{ &quot;ldarshw  $dst, $mem\t# short&quot; %}
 7613 
 7614   ins_encode(aarch64_enc_ldarshw(dst, mem));
 7615 
 7616   ins_pipe(pipe_serial);
 7617 %}
 7618 
 7619 instruct loadUS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7620 %{
 7621   match(Set dst (LoadUS mem));
 7622 
 7623   ins_cost(VOLATILE_REF_COST);
 7624   format %{ &quot;ldarhw  $dst, $mem\t# short&quot; %}
 7625 
 7626   ins_encode(aarch64_enc_ldarhw(dst, mem));
 7627 
 7628   ins_pipe(pipe_serial);
 7629 %}
 7630 
 7631 // Load Short/Char (16 bit unsigned) into long
 7632 instruct loadUS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7633 %{
 7634   match(Set dst (ConvI2L (LoadUS mem)));
 7635 
 7636   ins_cost(VOLATILE_REF_COST);
 7637   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7638 
 7639   ins_encode(aarch64_enc_ldarh(dst, mem));
 7640 
 7641   ins_pipe(pipe_serial);
 7642 %}
 7643 
 7644 // Load Short/Char (16 bit signed) into long
 7645 instruct loadS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7646 %{
 7647   match(Set dst (ConvI2L (LoadS mem)));
 7648 
 7649   ins_cost(VOLATILE_REF_COST);
 7650   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7651 
 7652   ins_encode(aarch64_enc_ldarsh(dst, mem));
 7653 
 7654   ins_pipe(pipe_serial);
 7655 %}
 7656 
 7657 // Load Integer (32 bit signed)
 7658 instruct loadI_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7659 %{
 7660   match(Set dst (LoadI mem));
 7661 
 7662   ins_cost(VOLATILE_REF_COST);
 7663   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7664 
 7665   ins_encode(aarch64_enc_ldarw(dst, mem));
 7666 
 7667   ins_pipe(pipe_serial);
 7668 %}
 7669 
 7670 // Load Integer (32 bit unsigned) into long
 7671 instruct loadUI2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem, immL_32bits mask)
 7672 %{
 7673   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 7674 
 7675   ins_cost(VOLATILE_REF_COST);
 7676   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7677 
 7678   ins_encode(aarch64_enc_ldarw(dst, mem));
 7679 
 7680   ins_pipe(pipe_serial);
 7681 %}
 7682 
 7683 // Load Long (64 bit signed)
 7684 instruct loadL_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7685 %{
 7686   match(Set dst (LoadL mem));
 7687 
 7688   ins_cost(VOLATILE_REF_COST);
 7689   format %{ &quot;ldar  $dst, $mem\t# int&quot; %}
 7690 
 7691   ins_encode(aarch64_enc_ldar(dst, mem));
 7692 
 7693   ins_pipe(pipe_serial);
 7694 %}
 7695 
 7696 // Load Pointer
 7697 instruct loadP_volatile(iRegPNoSp dst, /* sync_memory*/indirect mem)
 7698 %{
 7699   match(Set dst (LoadP mem));
 7700   predicate(n-&gt;as_Load()-&gt;barrier_data() == 0);
 7701 
 7702   ins_cost(VOLATILE_REF_COST);
 7703   format %{ &quot;ldar  $dst, $mem\t# ptr&quot; %}
 7704 
 7705   ins_encode(aarch64_enc_ldar(dst, mem));
 7706 
 7707   ins_pipe(pipe_serial);
 7708 %}
 7709 
 7710 // Load Compressed Pointer
 7711 instruct loadN_volatile(iRegNNoSp dst, /* sync_memory*/indirect mem)
 7712 %{
 7713   match(Set dst (LoadN mem));
 7714 
 7715   ins_cost(VOLATILE_REF_COST);
 7716   format %{ &quot;ldarw  $dst, $mem\t# compressed ptr&quot; %}
 7717 
 7718   ins_encode(aarch64_enc_ldarw(dst, mem));
 7719 
 7720   ins_pipe(pipe_serial);
 7721 %}
 7722 
 7723 // Load Float
 7724 instruct loadF_volatile(vRegF dst, /* sync_memory*/indirect mem)
 7725 %{
 7726   match(Set dst (LoadF mem));
 7727 
 7728   ins_cost(VOLATILE_REF_COST);
 7729   format %{ &quot;ldars  $dst, $mem\t# float&quot; %}
 7730 
 7731   ins_encode( aarch64_enc_fldars(dst, mem) );
 7732 
 7733   ins_pipe(pipe_serial);
 7734 %}
 7735 
 7736 // Load Double
 7737 instruct loadD_volatile(vRegD dst, /* sync_memory*/indirect mem)
 7738 %{
 7739   match(Set dst (LoadD mem));
 7740 
 7741   ins_cost(VOLATILE_REF_COST);
 7742   format %{ &quot;ldard  $dst, $mem\t# double&quot; %}
 7743 
 7744   ins_encode( aarch64_enc_fldard(dst, mem) );
 7745 
 7746   ins_pipe(pipe_serial);
 7747 %}
 7748 
 7749 // Store Byte
 7750 instruct storeB_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7751 %{
 7752   match(Set mem (StoreB mem src));
 7753 
 7754   ins_cost(VOLATILE_REF_COST);
 7755   format %{ &quot;stlrb  $src, $mem\t# byte&quot; %}
 7756 
 7757   ins_encode(aarch64_enc_stlrb(src, mem));
 7758 
 7759   ins_pipe(pipe_class_memory);
 7760 %}
 7761 
 7762 // Store Char/Short
 7763 instruct storeC_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7764 %{
 7765   match(Set mem (StoreC mem src));
 7766 
 7767   ins_cost(VOLATILE_REF_COST);
 7768   format %{ &quot;stlrh  $src, $mem\t# short&quot; %}
 7769 
 7770   ins_encode(aarch64_enc_stlrh(src, mem));
 7771 
 7772   ins_pipe(pipe_class_memory);
 7773 %}
 7774 
 7775 // Store Integer
 7776 
 7777 instruct storeI_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7778 %{
 7779   match(Set mem(StoreI mem src));
 7780 
 7781   ins_cost(VOLATILE_REF_COST);
 7782   format %{ &quot;stlrw  $src, $mem\t# int&quot; %}
 7783 
 7784   ins_encode(aarch64_enc_stlrw(src, mem));
 7785 
 7786   ins_pipe(pipe_class_memory);
 7787 %}
 7788 
 7789 // Store Long (64 bit signed)
 7790 instruct storeL_volatile(iRegL src, /* sync_memory*/indirect mem)
 7791 %{
 7792   match(Set mem (StoreL mem src));
 7793 
 7794   ins_cost(VOLATILE_REF_COST);
 7795   format %{ &quot;stlr  $src, $mem\t# int&quot; %}
 7796 
 7797   ins_encode(aarch64_enc_stlr(src, mem));
 7798 
 7799   ins_pipe(pipe_class_memory);
 7800 %}
 7801 
 7802 // Store Pointer
 7803 instruct storeP_volatile(iRegP src, /* sync_memory*/indirect mem)
 7804 %{
 7805   match(Set mem (StoreP mem src));
 7806 
 7807   ins_cost(VOLATILE_REF_COST);
 7808   format %{ &quot;stlr  $src, $mem\t# ptr&quot; %}
 7809 
 7810   ins_encode(aarch64_enc_stlr(src, mem));
 7811 
 7812   ins_pipe(pipe_class_memory);
 7813 %}
 7814 
 7815 // Store Compressed Pointer
 7816 instruct storeN_volatile(iRegN src, /* sync_memory*/indirect mem)
 7817 %{
 7818   match(Set mem (StoreN mem src));
 7819 
 7820   ins_cost(VOLATILE_REF_COST);
 7821   format %{ &quot;stlrw  $src, $mem\t# compressed ptr&quot; %}
 7822 
 7823   ins_encode(aarch64_enc_stlrw(src, mem));
 7824 
 7825   ins_pipe(pipe_class_memory);
 7826 %}
 7827 
 7828 // Store Float
 7829 instruct storeF_volatile(vRegF src, /* sync_memory*/indirect mem)
 7830 %{
 7831   match(Set mem (StoreF mem src));
 7832 
 7833   ins_cost(VOLATILE_REF_COST);
 7834   format %{ &quot;stlrs  $src, $mem\t# float&quot; %}
 7835 
 7836   ins_encode( aarch64_enc_fstlrs(src, mem) );
 7837 
 7838   ins_pipe(pipe_class_memory);
 7839 %}
 7840 
 7841 // TODO
 7842 // implement storeImmF0 and storeFImmPacked
 7843 
 7844 // Store Double
 7845 instruct storeD_volatile(vRegD src, /* sync_memory*/indirect mem)
 7846 %{
 7847   match(Set mem (StoreD mem src));
 7848 
 7849   ins_cost(VOLATILE_REF_COST);
 7850   format %{ &quot;stlrd  $src, $mem\t# double&quot; %}
 7851 
 7852   ins_encode( aarch64_enc_fstlrd(src, mem) );
 7853 
 7854   ins_pipe(pipe_class_memory);
 7855 %}
 7856 
 7857 //  ---------------- end of volatile loads and stores ----------------
 7858 
 7859 instruct cacheWB(indirect addr)
 7860 %{
 7861   predicate(VM_Version::supports_data_cache_line_flush());
 7862   match(CacheWB addr);
 7863 
 7864   ins_cost(100);
 7865   format %{&quot;cache wb $addr&quot; %}
 7866   ins_encode %{
 7867     assert($addr-&gt;index_position() &lt; 0, &quot;should be&quot;);
 7868     assert($addr$$disp == 0, &quot;should be&quot;);
 7869     __ cache_wb(Address($addr$$base$$Register, 0));
 7870   %}
 7871   ins_pipe(pipe_slow); // XXX
 7872 %}
 7873 
 7874 instruct cacheWBPreSync()
 7875 %{
 7876   predicate(VM_Version::supports_data_cache_line_flush());
 7877   match(CacheWBPreSync);
 7878 
 7879   ins_cost(100);
 7880   format %{&quot;cache wb presync&quot; %}
 7881   ins_encode %{
 7882     __ cache_wbsync(true);
 7883   %}
 7884   ins_pipe(pipe_slow); // XXX
 7885 %}
 7886 
 7887 instruct cacheWBPostSync()
 7888 %{
 7889   predicate(VM_Version::supports_data_cache_line_flush());
 7890   match(CacheWBPostSync);
 7891 
 7892   ins_cost(100);
 7893   format %{&quot;cache wb postsync&quot; %}
 7894   ins_encode %{
 7895     __ cache_wbsync(false);
 7896   %}
 7897   ins_pipe(pipe_slow); // XXX
 7898 %}
 7899 
 7900 // ============================================================================
 7901 // BSWAP Instructions
 7902 
 7903 instruct bytes_reverse_int(iRegINoSp dst, iRegIorL2I src) %{
 7904   match(Set dst (ReverseBytesI src));
 7905 
 7906   ins_cost(INSN_COST);
 7907   format %{ &quot;revw  $dst, $src&quot; %}
 7908 
 7909   ins_encode %{
 7910     __ revw(as_Register($dst$$reg), as_Register($src$$reg));
 7911   %}
 7912 
 7913   ins_pipe(ialu_reg);
 7914 %}
 7915 
 7916 instruct bytes_reverse_long(iRegLNoSp dst, iRegL src) %{
 7917   match(Set dst (ReverseBytesL src));
 7918 
 7919   ins_cost(INSN_COST);
 7920   format %{ &quot;rev  $dst, $src&quot; %}
 7921 
 7922   ins_encode %{
 7923     __ rev(as_Register($dst$$reg), as_Register($src$$reg));
 7924   %}
 7925 
 7926   ins_pipe(ialu_reg);
 7927 %}
 7928 
 7929 instruct bytes_reverse_unsigned_short(iRegINoSp dst, iRegIorL2I src) %{
 7930   match(Set dst (ReverseBytesUS src));
 7931 
 7932   ins_cost(INSN_COST);
 7933   format %{ &quot;rev16w  $dst, $src&quot; %}
 7934 
 7935   ins_encode %{
 7936     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7937   %}
 7938 
 7939   ins_pipe(ialu_reg);
 7940 %}
 7941 
 7942 instruct bytes_reverse_short(iRegINoSp dst, iRegIorL2I src) %{
 7943   match(Set dst (ReverseBytesS src));
 7944 
 7945   ins_cost(INSN_COST);
 7946   format %{ &quot;rev16w  $dst, $src\n\t&quot;
 7947             &quot;sbfmw $dst, $dst, #0, #15&quot; %}
 7948 
 7949   ins_encode %{
 7950     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7951     __ sbfmw(as_Register($dst$$reg), as_Register($dst$$reg), 0U, 15U);
 7952   %}
 7953 
 7954   ins_pipe(ialu_reg);
 7955 %}
 7956 
 7957 // ============================================================================
 7958 // Zero Count Instructions
 7959 
 7960 instruct countLeadingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 7961   match(Set dst (CountLeadingZerosI src));
 7962 
 7963   ins_cost(INSN_COST);
 7964   format %{ &quot;clzw  $dst, $src&quot; %}
 7965   ins_encode %{
 7966     __ clzw(as_Register($dst$$reg), as_Register($src$$reg));
 7967   %}
 7968 
 7969   ins_pipe(ialu_reg);
 7970 %}
 7971 
 7972 instruct countLeadingZerosL(iRegINoSp dst, iRegL src) %{
 7973   match(Set dst (CountLeadingZerosL src));
 7974 
 7975   ins_cost(INSN_COST);
 7976   format %{ &quot;clz   $dst, $src&quot; %}
 7977   ins_encode %{
 7978     __ clz(as_Register($dst$$reg), as_Register($src$$reg));
 7979   %}
 7980 
 7981   ins_pipe(ialu_reg);
 7982 %}
 7983 
 7984 instruct countTrailingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 7985   match(Set dst (CountTrailingZerosI src));
 7986 
 7987   ins_cost(INSN_COST * 2);
 7988   format %{ &quot;rbitw  $dst, $src\n\t&quot;
 7989             &quot;clzw   $dst, $dst&quot; %}
 7990   ins_encode %{
 7991     __ rbitw(as_Register($dst$$reg), as_Register($src$$reg));
 7992     __ clzw(as_Register($dst$$reg), as_Register($dst$$reg));
 7993   %}
 7994 
 7995   ins_pipe(ialu_reg);
 7996 %}
 7997 
 7998 instruct countTrailingZerosL(iRegINoSp dst, iRegL src) %{
 7999   match(Set dst (CountTrailingZerosL src));
 8000 
 8001   ins_cost(INSN_COST * 2);
 8002   format %{ &quot;rbit   $dst, $src\n\t&quot;
 8003             &quot;clz    $dst, $dst&quot; %}
 8004   ins_encode %{
 8005     __ rbit(as_Register($dst$$reg), as_Register($src$$reg));
 8006     __ clz(as_Register($dst$$reg), as_Register($dst$$reg));
 8007   %}
 8008 
 8009   ins_pipe(ialu_reg);
 8010 %}
 8011 
 8012 //---------- Population Count Instructions -------------------------------------
 8013 //
 8014 
 8015 instruct popCountI(iRegINoSp dst, iRegIorL2I src, vRegF tmp) %{
 8016   predicate(UsePopCountInstruction);
 8017   match(Set dst (PopCountI src));
 8018   effect(TEMP tmp);
 8019   ins_cost(INSN_COST * 13);
 8020 
 8021   format %{ &quot;movw   $src, $src\n\t&quot;
 8022             &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8023             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8024             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8025             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8026   ins_encode %{
 8027     __ movw($src$$Register, $src$$Register); // ensure top 32 bits 0
 8028     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8029     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8030     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8031     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8032   %}
 8033 
 8034   ins_pipe(pipe_class_default);
 8035 %}
 8036 
 8037 instruct popCountI_mem(iRegINoSp dst, memory4 mem, vRegF tmp) %{
 8038   predicate(UsePopCountInstruction);
 8039   match(Set dst (PopCountI (LoadI mem)));
 8040   effect(TEMP tmp);
 8041   ins_cost(INSN_COST * 13);
 8042 
 8043   format %{ &quot;ldrs   $tmp, $mem\n\t&quot;
 8044             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8045             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8046             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8047   ins_encode %{
 8048     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8049     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, tmp_reg, $mem-&gt;opcode(),
 8050               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 8051     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8052     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8053     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8054   %}
 8055 
 8056   ins_pipe(pipe_class_default);
 8057 %}
 8058 
 8059 // Note: Long.bitCount(long) returns an int.
 8060 instruct popCountL(iRegINoSp dst, iRegL src, vRegD tmp) %{
 8061   predicate(UsePopCountInstruction);
 8062   match(Set dst (PopCountL src));
 8063   effect(TEMP tmp);
 8064   ins_cost(INSN_COST * 13);
 8065 
 8066   format %{ &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8067             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8068             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8069             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8070   ins_encode %{
 8071     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8072     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8073     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8074     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8075   %}
 8076 
 8077   ins_pipe(pipe_class_default);
 8078 %}
 8079 
 8080 instruct popCountL_mem(iRegINoSp dst, memory8 mem, vRegD tmp) %{
 8081   predicate(UsePopCountInstruction);
 8082   match(Set dst (PopCountL (LoadL mem)));
 8083   effect(TEMP tmp);
 8084   ins_cost(INSN_COST * 13);
 8085 
 8086   format %{ &quot;ldrd   $tmp, $mem\n\t&quot;
 8087             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8088             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8089             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8090   ins_encode %{
 8091     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8092     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, tmp_reg, $mem-&gt;opcode(),
 8093               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 8094     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8095     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8096     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8097   %}
 8098 
 8099   ins_pipe(pipe_class_default);
 8100 %}
 8101 
 8102 // ============================================================================
 8103 // MemBar Instruction
 8104 
 8105 instruct load_fence() %{
 8106   match(LoadFence);
 8107   ins_cost(VOLATILE_REF_COST);
 8108 
 8109   format %{ &quot;load_fence&quot; %}
 8110 
 8111   ins_encode %{
 8112     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8113   %}
 8114   ins_pipe(pipe_serial);
 8115 %}
 8116 
 8117 instruct unnecessary_membar_acquire() %{
 8118   predicate(unnecessary_acquire(n));
 8119   match(MemBarAcquire);
 8120   ins_cost(0);
 8121 
 8122   format %{ &quot;membar_acquire (elided)&quot; %}
 8123 
 8124   ins_encode %{
 8125     __ block_comment(&quot;membar_acquire (elided)&quot;);
 8126   %}
 8127 
 8128   ins_pipe(pipe_class_empty);
 8129 %}
 8130 
 8131 instruct membar_acquire() %{
 8132   match(MemBarAcquire);
 8133   ins_cost(VOLATILE_REF_COST);
 8134 
 8135   format %{ &quot;membar_acquire\n\t&quot;
 8136             &quot;dmb ish&quot; %}
 8137 
 8138   ins_encode %{
 8139     __ block_comment(&quot;membar_acquire&quot;);
 8140     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8141   %}
 8142 
 8143   ins_pipe(pipe_serial);
 8144 %}
 8145 
 8146 
 8147 instruct membar_acquire_lock() %{
 8148   match(MemBarAcquireLock);
 8149   ins_cost(VOLATILE_REF_COST);
 8150 
 8151   format %{ &quot;membar_acquire_lock (elided)&quot; %}
 8152 
 8153   ins_encode %{
 8154     __ block_comment(&quot;membar_acquire_lock (elided)&quot;);
 8155   %}
 8156 
 8157   ins_pipe(pipe_serial);
 8158 %}
 8159 
 8160 instruct store_fence() %{
 8161   match(StoreFence);
 8162   ins_cost(VOLATILE_REF_COST);
 8163 
 8164   format %{ &quot;store_fence&quot; %}
 8165 
 8166   ins_encode %{
 8167     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8168   %}
 8169   ins_pipe(pipe_serial);
 8170 %}
 8171 
 8172 instruct unnecessary_membar_release() %{
 8173   predicate(unnecessary_release(n));
 8174   match(MemBarRelease);
 8175   ins_cost(0);
 8176 
 8177   format %{ &quot;membar_release (elided)&quot; %}
 8178 
 8179   ins_encode %{
 8180     __ block_comment(&quot;membar_release (elided)&quot;);
 8181   %}
 8182   ins_pipe(pipe_serial);
 8183 %}
 8184 
 8185 instruct membar_release() %{
 8186   match(MemBarRelease);
 8187   ins_cost(VOLATILE_REF_COST);
 8188 
 8189   format %{ &quot;membar_release\n\t&quot;
 8190             &quot;dmb ish&quot; %}
 8191 
 8192   ins_encode %{
 8193     __ block_comment(&quot;membar_release&quot;);
 8194     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8195   %}
 8196   ins_pipe(pipe_serial);
 8197 %}
 8198 
 8199 instruct membar_storestore() %{
 8200   match(MemBarStoreStore);
 8201   ins_cost(VOLATILE_REF_COST);
 8202 
 8203   format %{ &quot;MEMBAR-store-store&quot; %}
 8204 
 8205   ins_encode %{
 8206     __ membar(Assembler::StoreStore);
 8207   %}
 8208   ins_pipe(pipe_serial);
 8209 %}
 8210 
 8211 instruct membar_release_lock() %{
 8212   match(MemBarReleaseLock);
 8213   ins_cost(VOLATILE_REF_COST);
 8214 
 8215   format %{ &quot;membar_release_lock (elided)&quot; %}
 8216 
 8217   ins_encode %{
 8218     __ block_comment(&quot;membar_release_lock (elided)&quot;);
 8219   %}
 8220 
 8221   ins_pipe(pipe_serial);
 8222 %}
 8223 
 8224 instruct unnecessary_membar_volatile() %{
 8225   predicate(unnecessary_volatile(n));
 8226   match(MemBarVolatile);
 8227   ins_cost(0);
 8228 
 8229   format %{ &quot;membar_volatile (elided)&quot; %}
 8230 
 8231   ins_encode %{
 8232     __ block_comment(&quot;membar_volatile (elided)&quot;);
 8233   %}
 8234 
 8235   ins_pipe(pipe_serial);
 8236 %}
 8237 
 8238 instruct membar_volatile() %{
 8239   match(MemBarVolatile);
 8240   ins_cost(VOLATILE_REF_COST*100);
 8241 
 8242   format %{ &quot;membar_volatile\n\t&quot;
 8243              &quot;dmb ish&quot;%}
 8244 
 8245   ins_encode %{
 8246     __ block_comment(&quot;membar_volatile&quot;);
 8247     __ membar(Assembler::StoreLoad);
 8248   %}
 8249 
 8250   ins_pipe(pipe_serial);
 8251 %}
 8252 
 8253 // ============================================================================
 8254 // Cast/Convert Instructions
 8255 
 8256 instruct castX2P(iRegPNoSp dst, iRegL src) %{
 8257   match(Set dst (CastX2P src));
 8258 
 8259   ins_cost(INSN_COST);
 8260   format %{ &quot;mov $dst, $src\t# long -&gt; ptr&quot; %}
 8261 
 8262   ins_encode %{
 8263     if ($dst$$reg != $src$$reg) {
 8264       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8265     }
 8266   %}
 8267 
 8268   ins_pipe(ialu_reg);
 8269 %}
 8270 
 8271 instruct castP2X(iRegLNoSp dst, iRegP src) %{
 8272   match(Set dst (CastP2X src));
 8273 
 8274   ins_cost(INSN_COST);
 8275   format %{ &quot;mov $dst, $src\t# ptr -&gt; long&quot; %}
 8276 
 8277   ins_encode %{
 8278     if ($dst$$reg != $src$$reg) {
 8279       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8280     }
 8281   %}
 8282 
 8283   ins_pipe(ialu_reg);
 8284 %}
 8285 
 8286 // Convert oop into int for vectors alignment masking
 8287 instruct convP2I(iRegINoSp dst, iRegP src) %{
 8288   match(Set dst (ConvL2I (CastP2X src)));
 8289 
 8290   ins_cost(INSN_COST);
 8291   format %{ &quot;movw $dst, $src\t# ptr -&gt; int&quot; %}
 8292   ins_encode %{
 8293     __ movw($dst$$Register, $src$$Register);
 8294   %}
 8295 
 8296   ins_pipe(ialu_reg);
 8297 %}
 8298 
 8299 // Convert compressed oop into int for vectors alignment masking
 8300 // in case of 32bit oops (heap &lt; 4Gb).
 8301 instruct convN2I(iRegINoSp dst, iRegN src)
 8302 %{
 8303   predicate(CompressedOops::shift() == 0);
 8304   match(Set dst (ConvL2I (CastP2X (DecodeN src))));
 8305 
 8306   ins_cost(INSN_COST);
 8307   format %{ &quot;mov dst, $src\t# compressed ptr -&gt; int&quot; %}
 8308   ins_encode %{
 8309     __ movw($dst$$Register, $src$$Register);
 8310   %}
 8311 
 8312   ins_pipe(ialu_reg);
 8313 %}
 8314 
 8315 
 8316 // Convert oop pointer into compressed form
 8317 instruct encodeHeapOop(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8318   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() != TypePtr::NotNull);
 8319   match(Set dst (EncodeP src));
 8320   effect(KILL cr);
 8321   ins_cost(INSN_COST * 3);
 8322   format %{ &quot;encode_heap_oop $dst, $src&quot; %}
 8323   ins_encode %{
 8324     Register s = $src$$Register;
 8325     Register d = $dst$$Register;
 8326     __ encode_heap_oop(d, s);
 8327   %}
 8328   ins_pipe(ialu_reg);
 8329 %}
 8330 
 8331 instruct encodeHeapOop_not_null(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8332   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() == TypePtr::NotNull);
 8333   match(Set dst (EncodeP src));
 8334   ins_cost(INSN_COST * 3);
 8335   format %{ &quot;encode_heap_oop_not_null $dst, $src&quot; %}
 8336   ins_encode %{
 8337     __ encode_heap_oop_not_null($dst$$Register, $src$$Register);
 8338   %}
 8339   ins_pipe(ialu_reg);
 8340 %}
 8341 
 8342 instruct decodeHeapOop(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8343   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::NotNull &amp;&amp;
 8344             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::Constant);
 8345   match(Set dst (DecodeN src));
 8346   ins_cost(INSN_COST * 3);
 8347   format %{ &quot;decode_heap_oop $dst, $src&quot; %}
 8348   ins_encode %{
 8349     Register s = $src$$Register;
 8350     Register d = $dst$$Register;
 8351     __ decode_heap_oop(d, s);
 8352   %}
 8353   ins_pipe(ialu_reg);
 8354 %}
 8355 
 8356 instruct decodeHeapOop_not_null(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8357   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::NotNull ||
 8358             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::Constant);
 8359   match(Set dst (DecodeN src));
 8360   ins_cost(INSN_COST * 3);
 8361   format %{ &quot;decode_heap_oop_not_null $dst, $src&quot; %}
 8362   ins_encode %{
 8363     Register s = $src$$Register;
 8364     Register d = $dst$$Register;
 8365     __ decode_heap_oop_not_null(d, s);
 8366   %}
 8367   ins_pipe(ialu_reg);
 8368 %}
 8369 
 8370 // n.b. AArch64 implementations of encode_klass_not_null and
 8371 // decode_klass_not_null do not modify the flags register so, unlike
 8372 // Intel, we don&#39;t kill CR as a side effect here
 8373 
 8374 instruct encodeKlass_not_null(iRegNNoSp dst, iRegP src) %{
 8375   match(Set dst (EncodePKlass src));
 8376 
 8377   ins_cost(INSN_COST * 3);
 8378   format %{ &quot;encode_klass_not_null $dst,$src&quot; %}
 8379 
 8380   ins_encode %{
 8381     Register src_reg = as_Register($src$$reg);
 8382     Register dst_reg = as_Register($dst$$reg);
 8383     __ encode_klass_not_null(dst_reg, src_reg);
 8384   %}
 8385 
 8386    ins_pipe(ialu_reg);
 8387 %}
 8388 
 8389 instruct decodeKlass_not_null(iRegPNoSp dst, iRegN src) %{
 8390   match(Set dst (DecodeNKlass src));
 8391 
 8392   ins_cost(INSN_COST * 3);
 8393   format %{ &quot;decode_klass_not_null $dst,$src&quot; %}
 8394 
 8395   ins_encode %{
 8396     Register src_reg = as_Register($src$$reg);
 8397     Register dst_reg = as_Register($dst$$reg);
 8398     if (dst_reg != src_reg) {
 8399       __ decode_klass_not_null(dst_reg, src_reg);
 8400     } else {
 8401       __ decode_klass_not_null(dst_reg);
 8402     }
 8403   %}
 8404 
 8405    ins_pipe(ialu_reg);
 8406 %}
 8407 
 8408 instruct checkCastPP(iRegPNoSp dst)
 8409 %{
 8410   match(Set dst (CheckCastPP dst));
 8411 
 8412   size(0);
 8413   format %{ &quot;# checkcastPP of $dst&quot; %}
 8414   ins_encode(/* empty encoding */);
 8415   ins_pipe(pipe_class_empty);
 8416 %}
 8417 
 8418 instruct castPP(iRegPNoSp dst)
 8419 %{
 8420   match(Set dst (CastPP dst));
 8421 
 8422   size(0);
 8423   format %{ &quot;# castPP of $dst&quot; %}
 8424   ins_encode(/* empty encoding */);
 8425   ins_pipe(pipe_class_empty);
 8426 %}
 8427 
 8428 instruct castII(iRegI dst)
 8429 %{
 8430   match(Set dst (CastII dst));
 8431 
 8432   size(0);
 8433   format %{ &quot;# castII of $dst&quot; %}
 8434   ins_encode(/* empty encoding */);
 8435   ins_cost(0);
 8436   ins_pipe(pipe_class_empty);
 8437 %}
 8438 
 8439 // ============================================================================
 8440 // Atomic operation instructions
 8441 //
 8442 // Intel and SPARC both implement Ideal Node LoadPLocked and
 8443 // Store{PIL}Conditional instructions using a normal load for the
 8444 // LoadPLocked and a CAS for the Store{PIL}Conditional.
 8445 //
 8446 // The ideal code appears only to use LoadPLocked/StorePLocked as a
 8447 // pair to lock object allocations from Eden space when not using
 8448 // TLABs.
 8449 //
 8450 // There does not appear to be a Load{IL}Locked Ideal Node and the
 8451 // Ideal code appears to use Store{IL}Conditional as an alias for CAS
 8452 // and to use StoreIConditional only for 32-bit and StoreLConditional
 8453 // only for 64-bit.
 8454 //
 8455 // We implement LoadPLocked and StorePLocked instructions using,
 8456 // respectively the AArch64 hw load-exclusive and store-conditional
 8457 // instructions. Whereas we must implement each of
 8458 // Store{IL}Conditional using a CAS which employs a pair of
 8459 // instructions comprising a load-exclusive followed by a
 8460 // store-conditional.
 8461 
 8462 
 8463 // Locked-load (linked load) of the current heap-top
 8464 // used when updating the eden heap top
 8465 // implemented using ldaxr on AArch64
 8466 
 8467 instruct loadPLocked(iRegPNoSp dst, indirect mem)
 8468 %{
 8469   match(Set dst (LoadPLocked mem));
 8470 
 8471   ins_cost(VOLATILE_REF_COST);
 8472 
 8473   format %{ &quot;ldaxr $dst, $mem\t# ptr linked acquire&quot; %}
 8474 
 8475   ins_encode(aarch64_enc_ldaxr(dst, mem));
 8476 
 8477   ins_pipe(pipe_serial);
 8478 %}
 8479 
 8480 // Conditional-store of the updated heap-top.
 8481 // Used during allocation of the shared heap.
 8482 // Sets flag (EQ) on success.
 8483 // implemented using stlxr on AArch64.
 8484 
 8485 instruct storePConditional(memory8 heap_top_ptr, iRegP oldval, iRegP newval, rFlagsReg cr)
 8486 %{
 8487   match(Set cr (StorePConditional heap_top_ptr (Binary oldval newval)));
 8488 
 8489   ins_cost(VOLATILE_REF_COST);
 8490 
 8491  // TODO
 8492  // do we need to do a store-conditional release or can we just use a
 8493  // plain store-conditional?
 8494 
 8495   format %{
 8496     &quot;stlxr rscratch1, $newval, $heap_top_ptr\t# ptr cond release&quot;
 8497     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8498   %}
 8499 
 8500   ins_encode(aarch64_enc_stlxr(newval, heap_top_ptr));
 8501 
 8502   ins_pipe(pipe_serial);
 8503 %}
 8504 
 8505 
 8506 // storeLConditional is used by PhaseMacroExpand::expand_lock_node
 8507 // when attempting to rebias a lock towards the current thread.  We
 8508 // must use the acquire form of cmpxchg in order to guarantee acquire
 8509 // semantics in this case.
 8510 instruct storeLConditional(indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr)
 8511 %{
 8512   match(Set cr (StoreLConditional mem (Binary oldval newval)));
 8513 
 8514   ins_cost(VOLATILE_REF_COST);
 8515 
 8516   format %{
 8517     &quot;cmpxchg rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8518     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8519   %}
 8520 
 8521   ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval));
 8522 
 8523   ins_pipe(pipe_slow);
 8524 %}
 8525 
 8526 // storeIConditional also has acquire semantics, for no better reason
 8527 // than matching storeLConditional.  At the time of writing this
 8528 // comment storeIConditional was not used anywhere by AArch64.
 8529 instruct storeIConditional(indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr)
 8530 %{
 8531   match(Set cr (StoreIConditional mem (Binary oldval newval)));
 8532 
 8533   ins_cost(VOLATILE_REF_COST);
 8534 
 8535   format %{
 8536     &quot;cmpxchgw rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8537     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8538   %}
 8539 
 8540   ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval));
 8541 
 8542   ins_pipe(pipe_slow);
 8543 %}
 8544 
 8545 // standard CompareAndSwapX when we are using barriers
 8546 // these have higher priority than the rules selected by a predicate
 8547 
 8548 // XXX No flag versions for CompareAndSwap{I,L,P,N} because matcher
 8549 // can&#39;t match them
 8550 
 8551 instruct compareAndSwapB(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8552 
 8553   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8554   ins_cost(2 * VOLATILE_REF_COST);
 8555 
 8556   effect(KILL cr);
 8557 
 8558   format %{
 8559     &quot;cmpxchgb $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8560     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8561   %}
 8562 
 8563   ins_encode(aarch64_enc_cmpxchgb(mem, oldval, newval),
 8564             aarch64_enc_cset_eq(res));
 8565 
 8566   ins_pipe(pipe_slow);
 8567 %}
 8568 
 8569 instruct compareAndSwapS(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8570 
 8571   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8572   ins_cost(2 * VOLATILE_REF_COST);
 8573 
 8574   effect(KILL cr);
 8575 
 8576   format %{
 8577     &quot;cmpxchgs $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8578     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8579   %}
 8580 
 8581   ins_encode(aarch64_enc_cmpxchgs(mem, oldval, newval),
 8582             aarch64_enc_cset_eq(res));
 8583 
 8584   ins_pipe(pipe_slow);
 8585 %}
 8586 
 8587 instruct compareAndSwapI(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8588 
 8589   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8590   ins_cost(2 * VOLATILE_REF_COST);
 8591 
 8592   effect(KILL cr);
 8593 
 8594  format %{
 8595     &quot;cmpxchgw $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8596     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8597  %}
 8598 
 8599  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8600             aarch64_enc_cset_eq(res));
 8601 
 8602   ins_pipe(pipe_slow);
 8603 %}
 8604 
 8605 instruct compareAndSwapL(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8606 
 8607   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8608   ins_cost(2 * VOLATILE_REF_COST);
 8609 
 8610   effect(KILL cr);
 8611 
 8612  format %{
 8613     &quot;cmpxchg $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8614     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8615  %}
 8616 
 8617  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8618             aarch64_enc_cset_eq(res));
 8619 
 8620   ins_pipe(pipe_slow);
 8621 %}
 8622 
 8623 instruct compareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8624 
 8625   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8626   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8627   ins_cost(2 * VOLATILE_REF_COST);
 8628 
 8629   effect(KILL cr);
 8630 
 8631  format %{
 8632     &quot;cmpxchg $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8633     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8634  %}
 8635 
 8636  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8637             aarch64_enc_cset_eq(res));
 8638 
 8639   ins_pipe(pipe_slow);
 8640 %}
 8641 
 8642 instruct compareAndSwapN(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8643 
 8644   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8645   ins_cost(2 * VOLATILE_REF_COST);
 8646 
 8647   effect(KILL cr);
 8648 
 8649  format %{
 8650     &quot;cmpxchgw $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8651     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8652  %}
 8653 
 8654  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8655             aarch64_enc_cset_eq(res));
 8656 
 8657   ins_pipe(pipe_slow);
 8658 %}
 8659 
 8660 // alternative CompareAndSwapX when we are eliding barriers
 8661 
 8662 instruct compareAndSwapBAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8663 
 8664   predicate(needs_acquiring_load_exclusive(n));
 8665   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8666   ins_cost(VOLATILE_REF_COST);
 8667 
 8668   effect(KILL cr);
 8669 
 8670   format %{
 8671     &quot;cmpxchgb_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8672     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8673   %}
 8674 
 8675   ins_encode(aarch64_enc_cmpxchgb_acq(mem, oldval, newval),
 8676             aarch64_enc_cset_eq(res));
 8677 
 8678   ins_pipe(pipe_slow);
 8679 %}
 8680 
 8681 instruct compareAndSwapSAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8682 
 8683   predicate(needs_acquiring_load_exclusive(n));
 8684   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8685   ins_cost(VOLATILE_REF_COST);
 8686 
 8687   effect(KILL cr);
 8688 
 8689   format %{
 8690     &quot;cmpxchgs_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8691     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8692   %}
 8693 
 8694   ins_encode(aarch64_enc_cmpxchgs_acq(mem, oldval, newval),
 8695             aarch64_enc_cset_eq(res));
 8696 
 8697   ins_pipe(pipe_slow);
 8698 %}
 8699 
 8700 instruct compareAndSwapIAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8701 
 8702   predicate(needs_acquiring_load_exclusive(n));
 8703   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8704   ins_cost(VOLATILE_REF_COST);
 8705 
 8706   effect(KILL cr);
 8707 
 8708  format %{
 8709     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8710     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8711  %}
 8712 
 8713  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8714             aarch64_enc_cset_eq(res));
 8715 
 8716   ins_pipe(pipe_slow);
 8717 %}
 8718 
 8719 instruct compareAndSwapLAcq(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8720 
 8721   predicate(needs_acquiring_load_exclusive(n));
 8722   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8723   ins_cost(VOLATILE_REF_COST);
 8724 
 8725   effect(KILL cr);
 8726 
 8727  format %{
 8728     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8729     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8730  %}
 8731 
 8732  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8733             aarch64_enc_cset_eq(res));
 8734 
 8735   ins_pipe(pipe_slow);
 8736 %}
 8737 
 8738 instruct compareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8739 
 8740   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 8741   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8742   ins_cost(VOLATILE_REF_COST);
 8743 
 8744   effect(KILL cr);
 8745 
 8746  format %{
 8747     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8748     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8749  %}
 8750 
 8751  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8752             aarch64_enc_cset_eq(res));
 8753 
 8754   ins_pipe(pipe_slow);
 8755 %}
 8756 
 8757 instruct compareAndSwapNAcq(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8758 
 8759   predicate(needs_acquiring_load_exclusive(n));
 8760   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8761   ins_cost(VOLATILE_REF_COST);
 8762 
 8763   effect(KILL cr);
 8764 
 8765  format %{
 8766     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8767     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8768  %}
 8769 
 8770  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8771             aarch64_enc_cset_eq(res));
 8772 
 8773   ins_pipe(pipe_slow);
 8774 %}
 8775 
 8776 
 8777 // ---------------------------------------------------------------------
 8778 
 8779 
 8780 // BEGIN This section of the file is automatically generated. Do not edit --------------
 8781 
 8782 // Sundry CAS operations.  Note that release is always true,
 8783 // regardless of the memory ordering of the CAS.  This is because we
 8784 // need the volatile case to be sequentially consistent but there is
 8785 // no trailing StoreLoad barrier emitted by C2.  Unfortunately we
 8786 // can&#39;t check the type of memory ordering here, so we always emit a
 8787 // STLXR.
 8788 
 8789 // This section is generated from aarch64_ad_cas.m4
 8790 
 8791 
 8792 
 8793 instruct compareAndExchangeB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8794   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8795   ins_cost(2 * VOLATILE_REF_COST);
 8796   effect(TEMP_DEF res, KILL cr);
 8797   format %{
 8798     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8799   %}
 8800   ins_encode %{
 8801     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8802                Assembler::byte, /*acquire*/ false, /*release*/ true,
 8803                /*weak*/ false, $res$$Register);
 8804     __ sxtbw($res$$Register, $res$$Register);
 8805   %}
 8806   ins_pipe(pipe_slow);
 8807 %}
 8808 
 8809 instruct compareAndExchangeS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8810   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8811   ins_cost(2 * VOLATILE_REF_COST);
 8812   effect(TEMP_DEF res, KILL cr);
 8813   format %{
 8814     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8815   %}
 8816   ins_encode %{
 8817     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8818                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 8819                /*weak*/ false, $res$$Register);
 8820     __ sxthw($res$$Register, $res$$Register);
 8821   %}
 8822   ins_pipe(pipe_slow);
 8823 %}
 8824 
 8825 instruct compareAndExchangeI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8826   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8827   ins_cost(2 * VOLATILE_REF_COST);
 8828   effect(TEMP_DEF res, KILL cr);
 8829   format %{
 8830     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8831   %}
 8832   ins_encode %{
 8833     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8834                Assembler::word, /*acquire*/ false, /*release*/ true,
 8835                /*weak*/ false, $res$$Register);
 8836   %}
 8837   ins_pipe(pipe_slow);
 8838 %}
 8839 
 8840 instruct compareAndExchangeL(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8841   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8842   ins_cost(2 * VOLATILE_REF_COST);
 8843   effect(TEMP_DEF res, KILL cr);
 8844   format %{
 8845     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8846   %}
 8847   ins_encode %{
 8848     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8849                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8850                /*weak*/ false, $res$$Register);
 8851   %}
 8852   ins_pipe(pipe_slow);
 8853 %}
 8854 
 8855 instruct compareAndExchangeN(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8856   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8857   ins_cost(2 * VOLATILE_REF_COST);
 8858   effect(TEMP_DEF res, KILL cr);
 8859   format %{
 8860     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8861   %}
 8862   ins_encode %{
 8863     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8864                Assembler::word, /*acquire*/ false, /*release*/ true,
 8865                /*weak*/ false, $res$$Register);
 8866   %}
 8867   ins_pipe(pipe_slow);
 8868 %}
 8869 
 8870 instruct compareAndExchangeP(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8871   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8872   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 8873   ins_cost(2 * VOLATILE_REF_COST);
 8874   effect(TEMP_DEF res, KILL cr);
 8875   format %{
 8876     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8877   %}
 8878   ins_encode %{
 8879     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8880                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8881                /*weak*/ false, $res$$Register);
 8882   %}
 8883   ins_pipe(pipe_slow);
 8884 %}
 8885 
 8886 instruct compareAndExchangeBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8887   predicate(needs_acquiring_load_exclusive(n));
 8888   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8889   ins_cost(VOLATILE_REF_COST);
 8890   effect(TEMP_DEF res, KILL cr);
 8891   format %{
 8892     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8893   %}
 8894   ins_encode %{
 8895     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8896                Assembler::byte, /*acquire*/ true, /*release*/ true,
 8897                /*weak*/ false, $res$$Register);
 8898     __ sxtbw($res$$Register, $res$$Register);
 8899   %}
 8900   ins_pipe(pipe_slow);
 8901 %}
 8902 
 8903 instruct compareAndExchangeSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8904   predicate(needs_acquiring_load_exclusive(n));
 8905   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8906   ins_cost(VOLATILE_REF_COST);
 8907   effect(TEMP_DEF res, KILL cr);
 8908   format %{
 8909     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8910   %}
 8911   ins_encode %{
 8912     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8913                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 8914                /*weak*/ false, $res$$Register);
 8915     __ sxthw($res$$Register, $res$$Register);
 8916   %}
 8917   ins_pipe(pipe_slow);
 8918 %}
 8919 
 8920 
 8921 instruct compareAndExchangeIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8922   predicate(needs_acquiring_load_exclusive(n));
 8923   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8924   ins_cost(VOLATILE_REF_COST);
 8925   effect(TEMP_DEF res, KILL cr);
 8926   format %{
 8927     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8928   %}
 8929   ins_encode %{
 8930     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8931                Assembler::word, /*acquire*/ true, /*release*/ true,
 8932                /*weak*/ false, $res$$Register);
 8933   %}
 8934   ins_pipe(pipe_slow);
 8935 %}
 8936 
 8937 instruct compareAndExchangeLAcq(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8938   predicate(needs_acquiring_load_exclusive(n));
 8939   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8940   ins_cost(VOLATILE_REF_COST);
 8941   effect(TEMP_DEF res, KILL cr);
 8942   format %{
 8943     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8944   %}
 8945   ins_encode %{
 8946     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8947                Assembler::xword, /*acquire*/ true, /*release*/ true,
 8948                /*weak*/ false, $res$$Register);
 8949   %}
 8950   ins_pipe(pipe_slow);
 8951 %}
 8952 
 8953 
 8954 instruct compareAndExchangeNAcq(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8955   predicate(needs_acquiring_load_exclusive(n));
 8956   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8957   ins_cost(VOLATILE_REF_COST);
 8958   effect(TEMP_DEF res, KILL cr);
 8959   format %{
 8960     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8961   %}
 8962   ins_encode %{
 8963     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8964                Assembler::word, /*acquire*/ true, /*release*/ true,
 8965                /*weak*/ false, $res$$Register);
 8966   %}
 8967   ins_pipe(pipe_slow);
 8968 %}
 8969 
 8970 instruct compareAndExchangePAcq(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8971   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 8972   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 8973   ins_cost(VOLATILE_REF_COST);
 8974   effect(TEMP_DEF res, KILL cr);
 8975   format %{
 8976     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8977   %}
 8978   ins_encode %{
 8979     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8980                Assembler::xword, /*acquire*/ true, /*release*/ true,
 8981                /*weak*/ false, $res$$Register);
 8982   %}
 8983   ins_pipe(pipe_slow);
 8984 %}
 8985 
 8986 instruct weakCompareAndSwapB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8987   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 8988   ins_cost(2 * VOLATILE_REF_COST);
 8989   effect(KILL cr);
 8990   format %{
 8991     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8992     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8993   %}
 8994   ins_encode %{
 8995     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8996                Assembler::byte, /*acquire*/ false, /*release*/ true,
 8997                /*weak*/ true, noreg);
 8998     __ csetw($res$$Register, Assembler::EQ);
 8999   %}
 9000   ins_pipe(pipe_slow);
 9001 %}
 9002 
 9003 instruct weakCompareAndSwapS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9004   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9005   ins_cost(2 * VOLATILE_REF_COST);
 9006   effect(KILL cr);
 9007   format %{
 9008     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9009     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9010   %}
 9011   ins_encode %{
 9012     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9013                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 9014                /*weak*/ true, noreg);
 9015     __ csetw($res$$Register, Assembler::EQ);
 9016   %}
 9017   ins_pipe(pipe_slow);
 9018 %}
 9019 
 9020 instruct weakCompareAndSwapI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9021   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9022   ins_cost(2 * VOLATILE_REF_COST);
 9023   effect(KILL cr);
 9024   format %{
 9025     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9026     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9027   %}
 9028   ins_encode %{
 9029     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9030                Assembler::word, /*acquire*/ false, /*release*/ true,
 9031                /*weak*/ true, noreg);
 9032     __ csetw($res$$Register, Assembler::EQ);
 9033   %}
 9034   ins_pipe(pipe_slow);
 9035 %}
 9036 
 9037 instruct weakCompareAndSwapL(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9038   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9039   ins_cost(2 * VOLATILE_REF_COST);
 9040   effect(KILL cr);
 9041   format %{
 9042     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9043     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9044   %}
 9045   ins_encode %{
 9046     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9047                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9048                /*weak*/ true, noreg);
 9049     __ csetw($res$$Register, Assembler::EQ);
 9050   %}
 9051   ins_pipe(pipe_slow);
 9052 %}
 9053 
 9054 instruct weakCompareAndSwapN(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9055   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9056   ins_cost(2 * VOLATILE_REF_COST);
 9057   effect(KILL cr);
 9058   format %{
 9059     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9060     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9061   %}
 9062   ins_encode %{
 9063     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9064                Assembler::word, /*acquire*/ false, /*release*/ true,
 9065                /*weak*/ true, noreg);
 9066     __ csetw($res$$Register, Assembler::EQ);
 9067   %}
 9068   ins_pipe(pipe_slow);
 9069 %}
 9070 
 9071 instruct weakCompareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9072   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9073   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9074   ins_cost(2 * VOLATILE_REF_COST);
 9075   effect(KILL cr);
 9076   format %{
 9077     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9078     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9079   %}
 9080   ins_encode %{
 9081     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9082                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9083                /*weak*/ true, noreg);
 9084     __ csetw($res$$Register, Assembler::EQ);
 9085   %}
 9086   ins_pipe(pipe_slow);
 9087 %}
 9088 
 9089 instruct weakCompareAndSwapBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9090   predicate(needs_acquiring_load_exclusive(n));
 9091   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9092   ins_cost(VOLATILE_REF_COST);
 9093   effect(KILL cr);
 9094   format %{
 9095     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9096     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9097   %}
 9098   ins_encode %{
 9099     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9100                Assembler::byte, /*acquire*/ true, /*release*/ true,
 9101                /*weak*/ true, noreg);
 9102     __ csetw($res$$Register, Assembler::EQ);
 9103   %}
 9104   ins_pipe(pipe_slow);
 9105 %}
 9106 
 9107 instruct weakCompareAndSwapSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9108   predicate(needs_acquiring_load_exclusive(n));
 9109   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9110   ins_cost(VOLATILE_REF_COST);
 9111   effect(KILL cr);
 9112   format %{
 9113     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9114     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9115   %}
 9116   ins_encode %{
 9117     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9118                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 9119                /*weak*/ true, noreg);
 9120     __ csetw($res$$Register, Assembler::EQ);
 9121   %}
 9122   ins_pipe(pipe_slow);
 9123 %}
 9124 
 9125 instruct weakCompareAndSwapIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9126   predicate(needs_acquiring_load_exclusive(n));
 9127   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9128   ins_cost(VOLATILE_REF_COST);
 9129   effect(KILL cr);
 9130   format %{
 9131     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9132     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9133   %}
 9134   ins_encode %{
 9135     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9136                Assembler::word, /*acquire*/ true, /*release*/ true,
 9137                /*weak*/ true, noreg);
 9138     __ csetw($res$$Register, Assembler::EQ);
 9139   %}
 9140   ins_pipe(pipe_slow);
 9141 %}
 9142 
 9143 instruct weakCompareAndSwapLAcq(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9144   predicate(needs_acquiring_load_exclusive(n));
 9145   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9146   ins_cost(VOLATILE_REF_COST);
 9147   effect(KILL cr);
 9148   format %{
 9149     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9150     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9151   %}
 9152   ins_encode %{
 9153     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9154                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9155                /*weak*/ true, noreg);
 9156     __ csetw($res$$Register, Assembler::EQ);
 9157   %}
 9158   ins_pipe(pipe_slow);
 9159 %}
 9160 
 9161 instruct weakCompareAndSwapNAcq(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9162   predicate(needs_acquiring_load_exclusive(n));
 9163   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9164   ins_cost(VOLATILE_REF_COST);
 9165   effect(KILL cr);
 9166   format %{
 9167     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9168     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9169   %}
 9170   ins_encode %{
 9171     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9172                Assembler::word, /*acquire*/ true, /*release*/ true,
 9173                /*weak*/ true, noreg);
 9174     __ csetw($res$$Register, Assembler::EQ);
 9175   %}
 9176   ins_pipe(pipe_slow);
 9177 %}
 9178 
 9179 instruct weakCompareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9180   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9181   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9182   ins_cost(VOLATILE_REF_COST);
 9183   effect(KILL cr);
 9184   format %{
 9185     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9186     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9187   %}
 9188   ins_encode %{
 9189     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9190                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9191                /*weak*/ true, noreg);
 9192     __ csetw($res$$Register, Assembler::EQ);
 9193   %}
 9194   ins_pipe(pipe_slow);
 9195 %}
 9196 
 9197 // END This section of the file is automatically generated. Do not edit --------------
 9198 // ---------------------------------------------------------------------
 9199 
 9200 instruct get_and_setI(indirect mem, iRegI newv, iRegINoSp prev) %{
 9201   match(Set prev (GetAndSetI mem newv));
 9202   ins_cost(2 * VOLATILE_REF_COST);
 9203   format %{ &quot;atomic_xchgw  $prev, $newv, [$mem]&quot; %}
 9204   ins_encode %{
 9205     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9206   %}
 9207   ins_pipe(pipe_serial);
 9208 %}
 9209 
 9210 instruct get_and_setL(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9211   match(Set prev (GetAndSetL mem newv));
 9212   ins_cost(2 * VOLATILE_REF_COST);
 9213   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9214   ins_encode %{
 9215     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9216   %}
 9217   ins_pipe(pipe_serial);
 9218 %}
 9219 
 9220 instruct get_and_setN(indirect mem, iRegN newv, iRegINoSp prev) %{
 9221   match(Set prev (GetAndSetN mem newv));
 9222   ins_cost(2 * VOLATILE_REF_COST);
 9223   format %{ &quot;atomic_xchgw $prev, $newv, [$mem]&quot; %}
 9224   ins_encode %{
 9225     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9226   %}
 9227   ins_pipe(pipe_serial);
 9228 %}
 9229 
 9230 instruct get_and_setP(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9231   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9232   match(Set prev (GetAndSetP mem newv));
 9233   ins_cost(2 * VOLATILE_REF_COST);
 9234   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9235   ins_encode %{
 9236     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9237   %}
 9238   ins_pipe(pipe_serial);
 9239 %}
 9240 
 9241 instruct get_and_setIAcq(indirect mem, iRegI newv, iRegINoSp prev) %{
 9242   predicate(needs_acquiring_load_exclusive(n));
 9243   match(Set prev (GetAndSetI mem newv));
 9244   ins_cost(VOLATILE_REF_COST);
 9245   format %{ &quot;atomic_xchgw_acq  $prev, $newv, [$mem]&quot; %}
 9246   ins_encode %{
 9247     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9248   %}
 9249   ins_pipe(pipe_serial);
 9250 %}
 9251 
 9252 instruct get_and_setLAcq(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9253   predicate(needs_acquiring_load_exclusive(n));
 9254   match(Set prev (GetAndSetL mem newv));
 9255   ins_cost(VOLATILE_REF_COST);
 9256   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9257   ins_encode %{
 9258     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9259   %}
 9260   ins_pipe(pipe_serial);
 9261 %}
 9262 
 9263 instruct get_and_setNAcq(indirect mem, iRegN newv, iRegINoSp prev) %{
 9264   predicate(needs_acquiring_load_exclusive(n));
 9265   match(Set prev (GetAndSetN mem newv));
 9266   ins_cost(VOLATILE_REF_COST);
 9267   format %{ &quot;atomic_xchgw_acq $prev, $newv, [$mem]&quot; %}
 9268   ins_encode %{
 9269     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9270   %}
 9271   ins_pipe(pipe_serial);
 9272 %}
 9273 
 9274 instruct get_and_setPAcq(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9275   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9276   match(Set prev (GetAndSetP mem newv));
 9277   ins_cost(VOLATILE_REF_COST);
 9278   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9279   ins_encode %{
 9280     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9281   %}
 9282   ins_pipe(pipe_serial);
 9283 %}
 9284 
 9285 
 9286 instruct get_and_addL(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9287   match(Set newval (GetAndAddL mem incr));
 9288   ins_cost(2 * VOLATILE_REF_COST + 1);
 9289   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9290   ins_encode %{
 9291     __ atomic_add($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9292   %}
 9293   ins_pipe(pipe_serial);
 9294 %}
 9295 
 9296 instruct get_and_addL_no_res(indirect mem, Universe dummy, iRegL incr) %{
 9297   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9298   match(Set dummy (GetAndAddL mem incr));
 9299   ins_cost(2 * VOLATILE_REF_COST);
 9300   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9301   ins_encode %{
 9302     __ atomic_add(noreg, $incr$$Register, as_Register($mem$$base));
 9303   %}
 9304   ins_pipe(pipe_serial);
 9305 %}
 9306 
 9307 instruct get_and_addLi(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9308   match(Set newval (GetAndAddL mem incr));
 9309   ins_cost(2 * VOLATILE_REF_COST + 1);
 9310   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9311   ins_encode %{
 9312     __ atomic_add($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9313   %}
 9314   ins_pipe(pipe_serial);
 9315 %}
 9316 
 9317 instruct get_and_addLi_no_res(indirect mem, Universe dummy, immLAddSub incr) %{
 9318   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9319   match(Set dummy (GetAndAddL mem incr));
 9320   ins_cost(2 * VOLATILE_REF_COST);
 9321   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9322   ins_encode %{
 9323     __ atomic_add(noreg, $incr$$constant, as_Register($mem$$base));
 9324   %}
 9325   ins_pipe(pipe_serial);
 9326 %}
 9327 
 9328 instruct get_and_addI(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9329   match(Set newval (GetAndAddI mem incr));
 9330   ins_cost(2 * VOLATILE_REF_COST + 1);
 9331   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9332   ins_encode %{
 9333     __ atomic_addw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9334   %}
 9335   ins_pipe(pipe_serial);
 9336 %}
 9337 
 9338 instruct get_and_addI_no_res(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9339   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9340   match(Set dummy (GetAndAddI mem incr));
 9341   ins_cost(2 * VOLATILE_REF_COST);
 9342   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9343   ins_encode %{
 9344     __ atomic_addw(noreg, $incr$$Register, as_Register($mem$$base));
 9345   %}
 9346   ins_pipe(pipe_serial);
 9347 %}
 9348 
 9349 instruct get_and_addIi(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9350   match(Set newval (GetAndAddI mem incr));
 9351   ins_cost(2 * VOLATILE_REF_COST + 1);
 9352   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9353   ins_encode %{
 9354     __ atomic_addw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9355   %}
 9356   ins_pipe(pipe_serial);
 9357 %}
 9358 
 9359 instruct get_and_addIi_no_res(indirect mem, Universe dummy, immIAddSub incr) %{
 9360   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9361   match(Set dummy (GetAndAddI mem incr));
 9362   ins_cost(2 * VOLATILE_REF_COST);
 9363   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9364   ins_encode %{
 9365     __ atomic_addw(noreg, $incr$$constant, as_Register($mem$$base));
 9366   %}
 9367   ins_pipe(pipe_serial);
 9368 %}
 9369 
 9370 instruct get_and_addLAcq(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9371   predicate(needs_acquiring_load_exclusive(n));
 9372   match(Set newval (GetAndAddL mem incr));
 9373   ins_cost(VOLATILE_REF_COST + 1);
 9374   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9375   ins_encode %{
 9376     __ atomic_addal($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9377   %}
 9378   ins_pipe(pipe_serial);
 9379 %}
 9380 
 9381 instruct get_and_addL_no_resAcq(indirect mem, Universe dummy, iRegL incr) %{
 9382   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9383   match(Set dummy (GetAndAddL mem incr));
 9384   ins_cost(VOLATILE_REF_COST);
 9385   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9386   ins_encode %{
 9387     __ atomic_addal(noreg, $incr$$Register, as_Register($mem$$base));
 9388   %}
 9389   ins_pipe(pipe_serial);
 9390 %}
 9391 
 9392 instruct get_and_addLiAcq(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9393   predicate(needs_acquiring_load_exclusive(n));
 9394   match(Set newval (GetAndAddL mem incr));
 9395   ins_cost(VOLATILE_REF_COST + 1);
 9396   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9397   ins_encode %{
 9398     __ atomic_addal($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9399   %}
 9400   ins_pipe(pipe_serial);
 9401 %}
 9402 
 9403 instruct get_and_addLi_no_resAcq(indirect mem, Universe dummy, immLAddSub incr) %{
 9404   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9405   match(Set dummy (GetAndAddL mem incr));
 9406   ins_cost(VOLATILE_REF_COST);
 9407   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9408   ins_encode %{
 9409     __ atomic_addal(noreg, $incr$$constant, as_Register($mem$$base));
 9410   %}
 9411   ins_pipe(pipe_serial);
 9412 %}
 9413 
 9414 instruct get_and_addIAcq(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9415   predicate(needs_acquiring_load_exclusive(n));
 9416   match(Set newval (GetAndAddI mem incr));
 9417   ins_cost(VOLATILE_REF_COST + 1);
 9418   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9419   ins_encode %{
 9420     __ atomic_addalw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9421   %}
 9422   ins_pipe(pipe_serial);
 9423 %}
 9424 
 9425 instruct get_and_addI_no_resAcq(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9426   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9427   match(Set dummy (GetAndAddI mem incr));
 9428   ins_cost(VOLATILE_REF_COST);
 9429   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9430   ins_encode %{
 9431     __ atomic_addalw(noreg, $incr$$Register, as_Register($mem$$base));
 9432   %}
 9433   ins_pipe(pipe_serial);
 9434 %}
 9435 
 9436 instruct get_and_addIiAcq(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9437   predicate(needs_acquiring_load_exclusive(n));
 9438   match(Set newval (GetAndAddI mem incr));
 9439   ins_cost(VOLATILE_REF_COST + 1);
 9440   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9441   ins_encode %{
 9442     __ atomic_addalw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9443   %}
 9444   ins_pipe(pipe_serial);
 9445 %}
 9446 
 9447 instruct get_and_addIi_no_resAcq(indirect mem, Universe dummy, immIAddSub incr) %{
 9448   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9449   match(Set dummy (GetAndAddI mem incr));
 9450   ins_cost(VOLATILE_REF_COST);
 9451   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9452   ins_encode %{
 9453     __ atomic_addalw(noreg, $incr$$constant, as_Register($mem$$base));
 9454   %}
 9455   ins_pipe(pipe_serial);
 9456 %}
 9457 
 9458 // Manifest a CmpL result in an integer register.
 9459 // (src1 &lt; src2) ? -1 : ((src1 &gt; src2) ? 1 : 0)
 9460 instruct cmpL3_reg_reg(iRegINoSp dst, iRegL src1, iRegL src2, rFlagsReg flags)
 9461 %{
 9462   match(Set dst (CmpL3 src1 src2));
 9463   effect(KILL flags);
 9464 
 9465   ins_cost(INSN_COST * 6);
 9466   format %{
 9467       &quot;cmp $src1, $src2&quot;
 9468       &quot;csetw $dst, ne&quot;
 9469       &quot;cnegw $dst, lt&quot;
 9470   %}
 9471   // format %{ &quot;CmpL3 $dst, $src1, $src2&quot; %}
 9472   ins_encode %{
 9473     __ cmp($src1$$Register, $src2$$Register);
 9474     __ csetw($dst$$Register, Assembler::NE);
 9475     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9476   %}
 9477 
 9478   ins_pipe(pipe_class_default);
 9479 %}
 9480 
 9481 instruct cmpL3_reg_imm(iRegINoSp dst, iRegL src1, immLAddSub src2, rFlagsReg flags)
 9482 %{
 9483   match(Set dst (CmpL3 src1 src2));
 9484   effect(KILL flags);
 9485 
 9486   ins_cost(INSN_COST * 6);
 9487   format %{
 9488       &quot;cmp $src1, $src2&quot;
 9489       &quot;csetw $dst, ne&quot;
 9490       &quot;cnegw $dst, lt&quot;
 9491   %}
 9492   ins_encode %{
 9493     int32_t con = (int32_t)$src2$$constant;
 9494      if (con &lt; 0) {
 9495       __ adds(zr, $src1$$Register, -con);
 9496     } else {
 9497       __ subs(zr, $src1$$Register, con);
 9498     }
 9499     __ csetw($dst$$Register, Assembler::NE);
 9500     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9501   %}
 9502 
 9503   ins_pipe(pipe_class_default);
 9504 %}
 9505 
 9506 // ============================================================================
 9507 // Conditional Move Instructions
 9508 
 9509 // n.b. we have identical rules for both a signed compare op (cmpOp)
 9510 // and an unsigned compare op (cmpOpU). it would be nice if we could
 9511 // define an op class which merged both inputs and use it to type the
 9512 // argument to a single rule. unfortunatelyt his fails because the
 9513 // opclass does not live up to the COND_INTER interface of its
 9514 // component operands. When the generic code tries to negate the
 9515 // operand it ends up running the generci Machoper::negate method
 9516 // which throws a ShouldNotHappen. So, we have to provide two flavours
 9517 // of each rule, one for a cmpOp and a second for a cmpOpU (sigh).
 9518 
 9519 instruct cmovI_reg_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9520   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9521 
 9522   ins_cost(INSN_COST * 2);
 9523   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, int&quot;  %}
 9524 
 9525   ins_encode %{
 9526     __ cselw(as_Register($dst$$reg),
 9527              as_Register($src2$$reg),
 9528              as_Register($src1$$reg),
 9529              (Assembler::Condition)$cmp$$cmpcode);
 9530   %}
 9531 
 9532   ins_pipe(icond_reg_reg);
 9533 %}
 9534 
 9535 instruct cmovUI_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9536   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9537 
 9538   ins_cost(INSN_COST * 2);
 9539   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# unsigned, int&quot;  %}
 9540 
 9541   ins_encode %{
 9542     __ cselw(as_Register($dst$$reg),
 9543              as_Register($src2$$reg),
 9544              as_Register($src1$$reg),
 9545              (Assembler::Condition)$cmp$$cmpcode);
 9546   %}
 9547 
 9548   ins_pipe(icond_reg_reg);
 9549 %}
 9550 
 9551 // special cases where one arg is zero
 9552 
 9553 // n.b. this is selected in preference to the rule above because it
 9554 // avoids loading constant 0 into a source register
 9555 
 9556 // TODO
 9557 // we ought only to be able to cull one of these variants as the ideal
 9558 // transforms ought always to order the zero consistently (to left/right?)
 9559 
 9560 instruct cmovI_zero_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9561   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9562 
 9563   ins_cost(INSN_COST * 2);
 9564   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, int&quot;  %}
 9565 
 9566   ins_encode %{
 9567     __ cselw(as_Register($dst$$reg),
 9568              as_Register($src$$reg),
 9569              zr,
 9570              (Assembler::Condition)$cmp$$cmpcode);
 9571   %}
 9572 
 9573   ins_pipe(icond_reg);
 9574 %}
 9575 
 9576 instruct cmovUI_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9577   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9578 
 9579   ins_cost(INSN_COST * 2);
 9580   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, int&quot;  %}
 9581 
 9582   ins_encode %{
 9583     __ cselw(as_Register($dst$$reg),
 9584              as_Register($src$$reg),
 9585              zr,
 9586              (Assembler::Condition)$cmp$$cmpcode);
 9587   %}
 9588 
 9589   ins_pipe(icond_reg);
 9590 %}
 9591 
 9592 instruct cmovI_reg_zero(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9593   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9594 
 9595   ins_cost(INSN_COST * 2);
 9596   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, int&quot;  %}
 9597 
 9598   ins_encode %{
 9599     __ cselw(as_Register($dst$$reg),
 9600              zr,
 9601              as_Register($src$$reg),
 9602              (Assembler::Condition)$cmp$$cmpcode);
 9603   %}
 9604 
 9605   ins_pipe(icond_reg);
 9606 %}
 9607 
 9608 instruct cmovUI_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9609   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9610 
 9611   ins_cost(INSN_COST * 2);
 9612   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, int&quot;  %}
 9613 
 9614   ins_encode %{
 9615     __ cselw(as_Register($dst$$reg),
 9616              zr,
 9617              as_Register($src$$reg),
 9618              (Assembler::Condition)$cmp$$cmpcode);
 9619   %}
 9620 
 9621   ins_pipe(icond_reg);
 9622 %}
 9623 
 9624 // special case for creating a boolean 0 or 1
 9625 
 9626 // n.b. this is selected in preference to the rule above because it
 9627 // avoids loading constants 0 and 1 into a source register
 9628 
 9629 instruct cmovI_reg_zero_one(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9630   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9631 
 9632   ins_cost(INSN_COST * 2);
 9633   format %{ &quot;csincw $dst, zr, zr $cmp\t# signed, int&quot;  %}
 9634 
 9635   ins_encode %{
 9636     // equivalently
 9637     // cset(as_Register($dst$$reg),
 9638     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9639     __ csincw(as_Register($dst$$reg),
 9640              zr,
 9641              zr,
 9642              (Assembler::Condition)$cmp$$cmpcode);
 9643   %}
 9644 
 9645   ins_pipe(icond_none);
 9646 %}
 9647 
 9648 instruct cmovUI_reg_zero_one(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9649   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9650 
 9651   ins_cost(INSN_COST * 2);
 9652   format %{ &quot;csincw $dst, zr, zr $cmp\t# unsigned, int&quot;  %}
 9653 
 9654   ins_encode %{
 9655     // equivalently
 9656     // cset(as_Register($dst$$reg),
 9657     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9658     __ csincw(as_Register($dst$$reg),
 9659              zr,
 9660              zr,
 9661              (Assembler::Condition)$cmp$$cmpcode);
 9662   %}
 9663 
 9664   ins_pipe(icond_none);
 9665 %}
 9666 
 9667 instruct cmovL_reg_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9668   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9669 
 9670   ins_cost(INSN_COST * 2);
 9671   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, long&quot;  %}
 9672 
 9673   ins_encode %{
 9674     __ csel(as_Register($dst$$reg),
 9675             as_Register($src2$$reg),
 9676             as_Register($src1$$reg),
 9677             (Assembler::Condition)$cmp$$cmpcode);
 9678   %}
 9679 
 9680   ins_pipe(icond_reg_reg);
 9681 %}
 9682 
 9683 instruct cmovUL_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9684   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9685 
 9686   ins_cost(INSN_COST * 2);
 9687   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, long&quot;  %}
 9688 
 9689   ins_encode %{
 9690     __ csel(as_Register($dst$$reg),
 9691             as_Register($src2$$reg),
 9692             as_Register($src1$$reg),
 9693             (Assembler::Condition)$cmp$$cmpcode);
 9694   %}
 9695 
 9696   ins_pipe(icond_reg_reg);
 9697 %}
 9698 
 9699 // special cases where one arg is zero
 9700 
 9701 instruct cmovL_reg_zero(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9702   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9703 
 9704   ins_cost(INSN_COST * 2);
 9705   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, long&quot;  %}
 9706 
 9707   ins_encode %{
 9708     __ csel(as_Register($dst$$reg),
 9709             zr,
 9710             as_Register($src$$reg),
 9711             (Assembler::Condition)$cmp$$cmpcode);
 9712   %}
 9713 
 9714   ins_pipe(icond_reg);
 9715 %}
 9716 
 9717 instruct cmovUL_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9718   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9719 
 9720   ins_cost(INSN_COST * 2);
 9721   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, long&quot;  %}
 9722 
 9723   ins_encode %{
 9724     __ csel(as_Register($dst$$reg),
 9725             zr,
 9726             as_Register($src$$reg),
 9727             (Assembler::Condition)$cmp$$cmpcode);
 9728   %}
 9729 
 9730   ins_pipe(icond_reg);
 9731 %}
 9732 
 9733 instruct cmovL_zero_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9734   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9735 
 9736   ins_cost(INSN_COST * 2);
 9737   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, long&quot;  %}
 9738 
 9739   ins_encode %{
 9740     __ csel(as_Register($dst$$reg),
 9741             as_Register($src$$reg),
 9742             zr,
 9743             (Assembler::Condition)$cmp$$cmpcode);
 9744   %}
 9745 
 9746   ins_pipe(icond_reg);
 9747 %}
 9748 
 9749 instruct cmovUL_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9750   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9751 
 9752   ins_cost(INSN_COST * 2);
 9753   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, long&quot;  %}
 9754 
 9755   ins_encode %{
 9756     __ csel(as_Register($dst$$reg),
 9757             as_Register($src$$reg),
 9758             zr,
 9759             (Assembler::Condition)$cmp$$cmpcode);
 9760   %}
 9761 
 9762   ins_pipe(icond_reg);
 9763 %}
 9764 
 9765 instruct cmovP_reg_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9766   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9767 
 9768   ins_cost(INSN_COST * 2);
 9769   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, ptr&quot;  %}
 9770 
 9771   ins_encode %{
 9772     __ csel(as_Register($dst$$reg),
 9773             as_Register($src2$$reg),
 9774             as_Register($src1$$reg),
 9775             (Assembler::Condition)$cmp$$cmpcode);
 9776   %}
 9777 
 9778   ins_pipe(icond_reg_reg);
 9779 %}
 9780 
 9781 instruct cmovUP_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9782   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9783 
 9784   ins_cost(INSN_COST * 2);
 9785   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, ptr&quot;  %}
 9786 
 9787   ins_encode %{
 9788     __ csel(as_Register($dst$$reg),
 9789             as_Register($src2$$reg),
 9790             as_Register($src1$$reg),
 9791             (Assembler::Condition)$cmp$$cmpcode);
 9792   %}
 9793 
 9794   ins_pipe(icond_reg_reg);
 9795 %}
 9796 
 9797 // special cases where one arg is zero
 9798 
 9799 instruct cmovP_reg_zero(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9800   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9801 
 9802   ins_cost(INSN_COST * 2);
 9803   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, ptr&quot;  %}
 9804 
 9805   ins_encode %{
 9806     __ csel(as_Register($dst$$reg),
 9807             zr,
 9808             as_Register($src$$reg),
 9809             (Assembler::Condition)$cmp$$cmpcode);
 9810   %}
 9811 
 9812   ins_pipe(icond_reg);
 9813 %}
 9814 
 9815 instruct cmovUP_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9816   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9817 
 9818   ins_cost(INSN_COST * 2);
 9819   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, ptr&quot;  %}
 9820 
 9821   ins_encode %{
 9822     __ csel(as_Register($dst$$reg),
 9823             zr,
 9824             as_Register($src$$reg),
 9825             (Assembler::Condition)$cmp$$cmpcode);
 9826   %}
 9827 
 9828   ins_pipe(icond_reg);
 9829 %}
 9830 
 9831 instruct cmovP_zero_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9832   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9833 
 9834   ins_cost(INSN_COST * 2);
 9835   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, ptr&quot;  %}
 9836 
 9837   ins_encode %{
 9838     __ csel(as_Register($dst$$reg),
 9839             as_Register($src$$reg),
 9840             zr,
 9841             (Assembler::Condition)$cmp$$cmpcode);
 9842   %}
 9843 
 9844   ins_pipe(icond_reg);
 9845 %}
 9846 
 9847 instruct cmovUP_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9848   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9849 
 9850   ins_cost(INSN_COST * 2);
 9851   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, ptr&quot;  %}
 9852 
 9853   ins_encode %{
 9854     __ csel(as_Register($dst$$reg),
 9855             as_Register($src$$reg),
 9856             zr,
 9857             (Assembler::Condition)$cmp$$cmpcode);
 9858   %}
 9859 
 9860   ins_pipe(icond_reg);
 9861 %}
 9862 
 9863 instruct cmovN_reg_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9864   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9865 
 9866   ins_cost(INSN_COST * 2);
 9867   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9868 
 9869   ins_encode %{
 9870     __ cselw(as_Register($dst$$reg),
 9871              as_Register($src2$$reg),
 9872              as_Register($src1$$reg),
 9873              (Assembler::Condition)$cmp$$cmpcode);
 9874   %}
 9875 
 9876   ins_pipe(icond_reg_reg);
 9877 %}
 9878 
 9879 instruct cmovUN_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9880   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9881 
 9882   ins_cost(INSN_COST * 2);
 9883   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9884 
 9885   ins_encode %{
 9886     __ cselw(as_Register($dst$$reg),
 9887              as_Register($src2$$reg),
 9888              as_Register($src1$$reg),
 9889              (Assembler::Condition)$cmp$$cmpcode);
 9890   %}
 9891 
 9892   ins_pipe(icond_reg_reg);
 9893 %}
 9894 
 9895 // special cases where one arg is zero
 9896 
 9897 instruct cmovN_reg_zero(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9898   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9899 
 9900   ins_cost(INSN_COST * 2);
 9901   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, compressed ptr&quot;  %}
 9902 
 9903   ins_encode %{
 9904     __ cselw(as_Register($dst$$reg),
 9905              zr,
 9906              as_Register($src$$reg),
 9907              (Assembler::Condition)$cmp$$cmpcode);
 9908   %}
 9909 
 9910   ins_pipe(icond_reg);
 9911 %}
 9912 
 9913 instruct cmovUN_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9914   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9915 
 9916   ins_cost(INSN_COST * 2);
 9917   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, compressed ptr&quot;  %}
 9918 
 9919   ins_encode %{
 9920     __ cselw(as_Register($dst$$reg),
 9921              zr,
 9922              as_Register($src$$reg),
 9923              (Assembler::Condition)$cmp$$cmpcode);
 9924   %}
 9925 
 9926   ins_pipe(icond_reg);
 9927 %}
 9928 
 9929 instruct cmovN_zero_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
 9930   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
 9931 
 9932   ins_cost(INSN_COST * 2);
 9933   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, compressed ptr&quot;  %}
 9934 
 9935   ins_encode %{
 9936     __ cselw(as_Register($dst$$reg),
 9937              as_Register($src$$reg),
 9938              zr,
 9939              (Assembler::Condition)$cmp$$cmpcode);
 9940   %}
 9941 
 9942   ins_pipe(icond_reg);
 9943 %}
 9944 
 9945 instruct cmovUN_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
 9946   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
 9947 
 9948   ins_cost(INSN_COST * 2);
 9949   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, compressed ptr&quot;  %}
 9950 
 9951   ins_encode %{
 9952     __ cselw(as_Register($dst$$reg),
 9953              as_Register($src$$reg),
 9954              zr,
 9955              (Assembler::Condition)$cmp$$cmpcode);
 9956   %}
 9957 
 9958   ins_pipe(icond_reg);
 9959 %}
 9960 
 9961 instruct cmovF_reg(cmpOp cmp, rFlagsReg cr, vRegF dst, vRegF src1,  vRegF src2)
 9962 %{
 9963   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
 9964 
 9965   ins_cost(INSN_COST * 3);
 9966 
 9967   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
 9968   ins_encode %{
 9969     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
 9970     __ fcsels(as_FloatRegister($dst$$reg),
 9971               as_FloatRegister($src2$$reg),
 9972               as_FloatRegister($src1$$reg),
 9973               cond);
 9974   %}
 9975 
 9976   ins_pipe(fp_cond_reg_reg_s);
 9977 %}
 9978 
 9979 instruct cmovUF_reg(cmpOpU cmp, rFlagsRegU cr, vRegF dst, vRegF src1,  vRegF src2)
 9980 %{
 9981   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
 9982 
 9983   ins_cost(INSN_COST * 3);
 9984 
 9985   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
 9986   ins_encode %{
 9987     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
 9988     __ fcsels(as_FloatRegister($dst$$reg),
 9989               as_FloatRegister($src2$$reg),
 9990               as_FloatRegister($src1$$reg),
 9991               cond);
 9992   %}
 9993 
 9994   ins_pipe(fp_cond_reg_reg_s);
 9995 %}
 9996 
 9997 instruct cmovD_reg(cmpOp cmp, rFlagsReg cr, vRegD dst, vRegD src1,  vRegD src2)
 9998 %{
 9999   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10000 
10001   ins_cost(INSN_COST * 3);
10002 
10003   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10004   ins_encode %{
10005     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10006     __ fcseld(as_FloatRegister($dst$$reg),
10007               as_FloatRegister($src2$$reg),
10008               as_FloatRegister($src1$$reg),
10009               cond);
10010   %}
10011 
10012   ins_pipe(fp_cond_reg_reg_d);
10013 %}
10014 
10015 instruct cmovUD_reg(cmpOpU cmp, rFlagsRegU cr, vRegD dst, vRegD src1,  vRegD src2)
10016 %{
10017   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10018 
10019   ins_cost(INSN_COST * 3);
10020 
10021   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10022   ins_encode %{
10023     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10024     __ fcseld(as_FloatRegister($dst$$reg),
10025               as_FloatRegister($src2$$reg),
10026               as_FloatRegister($src1$$reg),
10027               cond);
10028   %}
10029 
10030   ins_pipe(fp_cond_reg_reg_d);
10031 %}
10032 
10033 // ============================================================================
10034 // Arithmetic Instructions
10035 //
10036 
10037 // Integer Addition
10038 
10039 // TODO
10040 // these currently employ operations which do not set CR and hence are
10041 // not flagged as killing CR but we would like to isolate the cases
10042 // where we want to set flags from those where we don&#39;t. need to work
10043 // out how to do that.
10044 
10045 instruct addI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10046   match(Set dst (AddI src1 src2));
10047 
10048   ins_cost(INSN_COST);
10049   format %{ &quot;addw  $dst, $src1, $src2&quot; %}
10050 
10051   ins_encode %{
10052     __ addw(as_Register($dst$$reg),
10053             as_Register($src1$$reg),
10054             as_Register($src2$$reg));
10055   %}
10056 
10057   ins_pipe(ialu_reg_reg);
10058 %}
10059 
10060 instruct addI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10061   match(Set dst (AddI src1 src2));
10062 
10063   ins_cost(INSN_COST);
10064   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10065 
10066   // use opcode to indicate that this is an add not a sub
10067   opcode(0x0);
10068 
10069   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10070 
10071   ins_pipe(ialu_reg_imm);
10072 %}
10073 
10074 instruct addI_reg_imm_i2l(iRegINoSp dst, iRegL src1, immIAddSub src2) %{
10075   match(Set dst (AddI (ConvL2I src1) src2));
10076 
10077   ins_cost(INSN_COST);
10078   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10079 
10080   // use opcode to indicate that this is an add not a sub
10081   opcode(0x0);
10082 
10083   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10084 
10085   ins_pipe(ialu_reg_imm);
10086 %}
10087 
10088 // Pointer Addition
10089 instruct addP_reg_reg(iRegPNoSp dst, iRegP src1, iRegL src2) %{
10090   match(Set dst (AddP src1 src2));
10091 
10092   ins_cost(INSN_COST);
10093   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10094 
10095   ins_encode %{
10096     __ add(as_Register($dst$$reg),
10097            as_Register($src1$$reg),
10098            as_Register($src2$$reg));
10099   %}
10100 
10101   ins_pipe(ialu_reg_reg);
10102 %}
10103 
10104 instruct addP_reg_reg_ext(iRegPNoSp dst, iRegP src1, iRegIorL2I src2) %{
10105   match(Set dst (AddP src1 (ConvI2L src2)));
10106 
10107   ins_cost(1.9 * INSN_COST);
10108   format %{ &quot;add $dst, $src1, $src2, sxtw\t# ptr&quot; %}
10109 
10110   ins_encode %{
10111     __ add(as_Register($dst$$reg),
10112            as_Register($src1$$reg),
10113            as_Register($src2$$reg), ext::sxtw);
10114   %}
10115 
10116   ins_pipe(ialu_reg_reg);
10117 %}
10118 
10119 instruct addP_reg_reg_lsl(iRegPNoSp dst, iRegP src1, iRegL src2, immIScale scale) %{
10120   match(Set dst (AddP src1 (LShiftL src2 scale)));
10121 
10122   ins_cost(1.9 * INSN_COST);
10123   format %{ &quot;add $dst, $src1, $src2, LShiftL $scale\t# ptr&quot; %}
10124 
10125   ins_encode %{
10126     __ lea(as_Register($dst$$reg),
10127            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10128                    Address::lsl($scale$$constant)));
10129   %}
10130 
10131   ins_pipe(ialu_reg_reg_shift);
10132 %}
10133 
10134 instruct addP_reg_reg_ext_shift(iRegPNoSp dst, iRegP src1, iRegIorL2I src2, immIScale scale) %{
10135   match(Set dst (AddP src1 (LShiftL (ConvI2L src2) scale)));
10136 
10137   ins_cost(1.9 * INSN_COST);
10138   format %{ &quot;add $dst, $src1, $src2, I2L $scale\t# ptr&quot; %}
10139 
10140   ins_encode %{
10141     __ lea(as_Register($dst$$reg),
10142            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10143                    Address::sxtw($scale$$constant)));
10144   %}
10145 
10146   ins_pipe(ialu_reg_reg_shift);
10147 %}
10148 
10149 instruct lshift_ext(iRegLNoSp dst, iRegIorL2I src, immI scale, rFlagsReg cr) %{
10150   match(Set dst (LShiftL (ConvI2L src) scale));
10151 
10152   ins_cost(INSN_COST);
10153   format %{ &quot;sbfiz $dst, $src, $scale &amp; 63, -$scale &amp; 63\t&quot; %}
10154 
10155   ins_encode %{
10156     __ sbfiz(as_Register($dst$$reg),
10157           as_Register($src$$reg),
10158           $scale$$constant &amp; 63, MIN2(32, (int)((-$scale$$constant) &amp; 63)));
10159   %}
10160 
10161   ins_pipe(ialu_reg_shift);
10162 %}
10163 
10164 // Pointer Immediate Addition
10165 // n.b. this needs to be more expensive than using an indirect memory
10166 // operand
10167 instruct addP_reg_imm(iRegPNoSp dst, iRegP src1, immLAddSub src2) %{
10168   match(Set dst (AddP src1 src2));
10169 
10170   ins_cost(INSN_COST);
10171   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10172 
10173   // use opcode to indicate that this is an add not a sub
10174   opcode(0x0);
10175 
10176   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10177 
10178   ins_pipe(ialu_reg_imm);
10179 %}
10180 
10181 // Long Addition
10182 instruct addL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10183 
10184   match(Set dst (AddL src1 src2));
10185 
10186   ins_cost(INSN_COST);
10187   format %{ &quot;add  $dst, $src1, $src2&quot; %}
10188 
10189   ins_encode %{
10190     __ add(as_Register($dst$$reg),
10191            as_Register($src1$$reg),
10192            as_Register($src2$$reg));
10193   %}
10194 
10195   ins_pipe(ialu_reg_reg);
10196 %}
10197 
10198 // No constant pool entries requiredLong Immediate Addition.
10199 instruct addL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10200   match(Set dst (AddL src1 src2));
10201 
10202   ins_cost(INSN_COST);
10203   format %{ &quot;add $dst, $src1, $src2&quot; %}
10204 
10205   // use opcode to indicate that this is an add not a sub
10206   opcode(0x0);
10207 
10208   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10209 
10210   ins_pipe(ialu_reg_imm);
10211 %}
10212 
10213 // Integer Subtraction
10214 instruct subI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10215   match(Set dst (SubI src1 src2));
10216 
10217   ins_cost(INSN_COST);
10218   format %{ &quot;subw  $dst, $src1, $src2&quot; %}
10219 
10220   ins_encode %{
10221     __ subw(as_Register($dst$$reg),
10222             as_Register($src1$$reg),
10223             as_Register($src2$$reg));
10224   %}
10225 
10226   ins_pipe(ialu_reg_reg);
10227 %}
10228 
10229 // Immediate Subtraction
10230 instruct subI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10231   match(Set dst (SubI src1 src2));
10232 
10233   ins_cost(INSN_COST);
10234   format %{ &quot;subw $dst, $src1, $src2&quot; %}
10235 
10236   // use opcode to indicate that this is a sub not an add
10237   opcode(0x1);
10238 
10239   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10240 
10241   ins_pipe(ialu_reg_imm);
10242 %}
10243 
10244 // Long Subtraction
10245 instruct subL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10246 
10247   match(Set dst (SubL src1 src2));
10248 
10249   ins_cost(INSN_COST);
10250   format %{ &quot;sub  $dst, $src1, $src2&quot; %}
10251 
10252   ins_encode %{
10253     __ sub(as_Register($dst$$reg),
10254            as_Register($src1$$reg),
10255            as_Register($src2$$reg));
10256   %}
10257 
10258   ins_pipe(ialu_reg_reg);
10259 %}
10260 
10261 // No constant pool entries requiredLong Immediate Subtraction.
10262 instruct subL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10263   match(Set dst (SubL src1 src2));
10264 
10265   ins_cost(INSN_COST);
10266   format %{ &quot;sub$dst, $src1, $src2&quot; %}
10267 
10268   // use opcode to indicate that this is a sub not an add
10269   opcode(0x1);
10270 
10271   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10272 
10273   ins_pipe(ialu_reg_imm);
10274 %}
10275 
10276 // Integer Negation (special case for sub)
10277 
10278 instruct negI_reg(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr) %{
10279   match(Set dst (SubI zero src));
10280 
10281   ins_cost(INSN_COST);
10282   format %{ &quot;negw $dst, $src\t# int&quot; %}
10283 
10284   ins_encode %{
10285     __ negw(as_Register($dst$$reg),
10286             as_Register($src$$reg));
10287   %}
10288 
10289   ins_pipe(ialu_reg);
10290 %}
10291 
10292 // Long Negation
10293 
10294 instruct negL_reg(iRegLNoSp dst, iRegL src, immL0 zero, rFlagsReg cr) %{
10295   match(Set dst (SubL zero src));
10296 
10297   ins_cost(INSN_COST);
10298   format %{ &quot;neg $dst, $src\t# long&quot; %}
10299 
10300   ins_encode %{
10301     __ neg(as_Register($dst$$reg),
10302            as_Register($src$$reg));
10303   %}
10304 
10305   ins_pipe(ialu_reg);
10306 %}
10307 
10308 // Integer Multiply
10309 
10310 instruct mulI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10311   match(Set dst (MulI src1 src2));
10312 
10313   ins_cost(INSN_COST * 3);
10314   format %{ &quot;mulw  $dst, $src1, $src2&quot; %}
10315 
10316   ins_encode %{
10317     __ mulw(as_Register($dst$$reg),
10318             as_Register($src1$$reg),
10319             as_Register($src2$$reg));
10320   %}
10321 
10322   ins_pipe(imul_reg_reg);
10323 %}
10324 
10325 instruct smulI(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10326   match(Set dst (MulL (ConvI2L src1) (ConvI2L src2)));
10327 
10328   ins_cost(INSN_COST * 3);
10329   format %{ &quot;smull  $dst, $src1, $src2&quot; %}
10330 
10331   ins_encode %{
10332     __ smull(as_Register($dst$$reg),
10333              as_Register($src1$$reg),
10334              as_Register($src2$$reg));
10335   %}
10336 
10337   ins_pipe(imul_reg_reg);
10338 %}
10339 
10340 // Long Multiply
10341 
10342 instruct mulL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10343   match(Set dst (MulL src1 src2));
10344 
10345   ins_cost(INSN_COST * 5);
10346   format %{ &quot;mul  $dst, $src1, $src2&quot; %}
10347 
10348   ins_encode %{
10349     __ mul(as_Register($dst$$reg),
10350            as_Register($src1$$reg),
10351            as_Register($src2$$reg));
10352   %}
10353 
10354   ins_pipe(lmul_reg_reg);
10355 %}
10356 
10357 instruct mulHiL_rReg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr)
10358 %{
10359   match(Set dst (MulHiL src1 src2));
10360 
10361   ins_cost(INSN_COST * 7);
10362   format %{ &quot;smulh   $dst, $src1, $src2, \t# mulhi&quot; %}
10363 
10364   ins_encode %{
10365     __ smulh(as_Register($dst$$reg),
10366              as_Register($src1$$reg),
10367              as_Register($src2$$reg));
10368   %}
10369 
10370   ins_pipe(lmul_reg_reg);
10371 %}
10372 
10373 // Combined Integer Multiply &amp; Add/Sub
10374 
10375 instruct maddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10376   match(Set dst (AddI src3 (MulI src1 src2)));
10377 
10378   ins_cost(INSN_COST * 3);
10379   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10380 
10381   ins_encode %{
10382     __ maddw(as_Register($dst$$reg),
10383              as_Register($src1$$reg),
10384              as_Register($src2$$reg),
10385              as_Register($src3$$reg));
10386   %}
10387 
10388   ins_pipe(imac_reg_reg);
10389 %}
10390 
10391 instruct msubI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10392   match(Set dst (SubI src3 (MulI src1 src2)));
10393 
10394   ins_cost(INSN_COST * 3);
10395   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10396 
10397   ins_encode %{
10398     __ msubw(as_Register($dst$$reg),
10399              as_Register($src1$$reg),
10400              as_Register($src2$$reg),
10401              as_Register($src3$$reg));
10402   %}
10403 
10404   ins_pipe(imac_reg_reg);
10405 %}
10406 
10407 // Combined Integer Multiply &amp; Neg
10408 
10409 instruct mnegI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI0 zero) %{
10410   match(Set dst (MulI (SubI zero src1) src2));
10411   match(Set dst (MulI src1 (SubI zero src2)));
10412 
10413   ins_cost(INSN_COST * 3);
10414   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10415 
10416   ins_encode %{
10417     __ mnegw(as_Register($dst$$reg),
10418              as_Register($src1$$reg),
10419              as_Register($src2$$reg));
10420   %}
10421 
10422   ins_pipe(imac_reg_reg);
10423 %}
10424 
10425 // Combined Long Multiply &amp; Add/Sub
10426 
10427 instruct maddL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10428   match(Set dst (AddL src3 (MulL src1 src2)));
10429 
10430   ins_cost(INSN_COST * 5);
10431   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10432 
10433   ins_encode %{
10434     __ madd(as_Register($dst$$reg),
10435             as_Register($src1$$reg),
10436             as_Register($src2$$reg),
10437             as_Register($src3$$reg));
10438   %}
10439 
10440   ins_pipe(lmac_reg_reg);
10441 %}
10442 
10443 instruct msubL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10444   match(Set dst (SubL src3 (MulL src1 src2)));
10445 
10446   ins_cost(INSN_COST * 5);
10447   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10448 
10449   ins_encode %{
10450     __ msub(as_Register($dst$$reg),
10451             as_Register($src1$$reg),
10452             as_Register($src2$$reg),
10453             as_Register($src3$$reg));
10454   %}
10455 
10456   ins_pipe(lmac_reg_reg);
10457 %}
10458 
10459 // Combined Long Multiply &amp; Neg
10460 
10461 instruct mnegL(iRegLNoSp dst, iRegL src1, iRegL src2, immL0 zero) %{
10462   match(Set dst (MulL (SubL zero src1) src2));
10463   match(Set dst (MulL src1 (SubL zero src2)));
10464 
10465   ins_cost(INSN_COST * 5);
10466   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10467 
10468   ins_encode %{
10469     __ mneg(as_Register($dst$$reg),
10470             as_Register($src1$$reg),
10471             as_Register($src2$$reg));
10472   %}
10473 
10474   ins_pipe(lmac_reg_reg);
10475 %}
10476 
10477 // Combine Integer Signed Multiply &amp; Add/Sub/Neg Long
10478 
10479 instruct smaddL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10480   match(Set dst (AddL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10481 
10482   ins_cost(INSN_COST * 3);
10483   format %{ &quot;smaddl  $dst, $src1, $src2, $src3&quot; %}
10484 
10485   ins_encode %{
10486     __ smaddl(as_Register($dst$$reg),
10487               as_Register($src1$$reg),
10488               as_Register($src2$$reg),
10489               as_Register($src3$$reg));
10490   %}
10491 
10492   ins_pipe(imac_reg_reg);
10493 %}
10494 
10495 instruct smsubL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10496   match(Set dst (SubL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10497 
10498   ins_cost(INSN_COST * 3);
10499   format %{ &quot;smsubl  $dst, $src1, $src2, $src3&quot; %}
10500 
10501   ins_encode %{
10502     __ smsubl(as_Register($dst$$reg),
10503               as_Register($src1$$reg),
10504               as_Register($src2$$reg),
10505               as_Register($src3$$reg));
10506   %}
10507 
10508   ins_pipe(imac_reg_reg);
10509 %}
10510 
10511 instruct smnegL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, immL0 zero) %{
10512   match(Set dst (MulL (SubL zero (ConvI2L src1)) (ConvI2L src2)));
10513   match(Set dst (MulL (ConvI2L src1) (SubL zero (ConvI2L src2))));
10514 
10515   ins_cost(INSN_COST * 3);
10516   format %{ &quot;smnegl  $dst, $src1, $src2&quot; %}
10517 
10518   ins_encode %{
10519     __ smnegl(as_Register($dst$$reg),
10520               as_Register($src1$$reg),
10521               as_Register($src2$$reg));
10522   %}
10523 
10524   ins_pipe(imac_reg_reg);
10525 %}
10526 
10527 // Combined Multiply-Add Shorts into Integer (dst = src1 * src2 + src3 * src4)
10528 
10529 instruct muladdS2I(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3, iRegIorL2I src4) %{
10530   match(Set dst (MulAddS2I (Binary src1 src2) (Binary src3 src4)));
10531 
10532   ins_cost(INSN_COST * 5);
10533   format %{ &quot;mulw  rscratch1, $src1, $src2\n\t&quot;
10534             &quot;maddw $dst, $src3, $src4, rscratch1&quot; %}
10535 
10536   ins_encode %{
10537     __ mulw(rscratch1, as_Register($src1$$reg), as_Register($src2$$reg));
10538     __ maddw(as_Register($dst$$reg), as_Register($src3$$reg), as_Register($src4$$reg), rscratch1); %}
10539 
10540   ins_pipe(imac_reg_reg);
10541 %}
10542 
10543 // Integer Divide
10544 
10545 instruct divI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10546   match(Set dst (DivI src1 src2));
10547 
10548   ins_cost(INSN_COST * 19);
10549   format %{ &quot;sdivw  $dst, $src1, $src2&quot; %}
10550 
10551   ins_encode(aarch64_enc_divw(dst, src1, src2));
10552   ins_pipe(idiv_reg_reg);
10553 %}
10554 
10555 // Long Divide
10556 
10557 instruct divL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10558   match(Set dst (DivL src1 src2));
10559 
10560   ins_cost(INSN_COST * 35);
10561   format %{ &quot;sdiv   $dst, $src1, $src2&quot; %}
10562 
10563   ins_encode(aarch64_enc_div(dst, src1, src2));
10564   ins_pipe(ldiv_reg_reg);
10565 %}
10566 
10567 // Integer Remainder
10568 
10569 instruct modI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10570   match(Set dst (ModI src1 src2));
10571 
10572   ins_cost(INSN_COST * 22);
10573   format %{ &quot;sdivw  rscratch1, $src1, $src2\n\t&quot;
10574             &quot;msubw($dst, rscratch1, $src2, $src1&quot; %}
10575 
10576   ins_encode(aarch64_enc_modw(dst, src1, src2));
10577   ins_pipe(idiv_reg_reg);
10578 %}
10579 
10580 // Long Remainder
10581 
10582 instruct modL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10583   match(Set dst (ModL src1 src2));
10584 
10585   ins_cost(INSN_COST * 38);
10586   format %{ &quot;sdiv   rscratch1, $src1, $src2\n&quot;
10587             &quot;msub($dst, rscratch1, $src2, $src1&quot; %}
10588 
10589   ins_encode(aarch64_enc_mod(dst, src1, src2));
10590   ins_pipe(ldiv_reg_reg);
10591 %}
10592 
10593 // Integer Shifts
10594 
10595 // Shift Left Register
10596 instruct lShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10597   match(Set dst (LShiftI src1 src2));
10598 
10599   ins_cost(INSN_COST * 2);
10600   format %{ &quot;lslvw  $dst, $src1, $src2&quot; %}
10601 
10602   ins_encode %{
10603     __ lslvw(as_Register($dst$$reg),
10604              as_Register($src1$$reg),
10605              as_Register($src2$$reg));
10606   %}
10607 
10608   ins_pipe(ialu_reg_reg_vshift);
10609 %}
10610 
10611 // Shift Left Immediate
10612 instruct lShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10613   match(Set dst (LShiftI src1 src2));
10614 
10615   ins_cost(INSN_COST);
10616   format %{ &quot;lslw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10617 
10618   ins_encode %{
10619     __ lslw(as_Register($dst$$reg),
10620             as_Register($src1$$reg),
10621             $src2$$constant &amp; 0x1f);
10622   %}
10623 
10624   ins_pipe(ialu_reg_shift);
10625 %}
10626 
10627 // Shift Right Logical Register
10628 instruct urShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10629   match(Set dst (URShiftI src1 src2));
10630 
10631   ins_cost(INSN_COST * 2);
10632   format %{ &quot;lsrvw  $dst, $src1, $src2&quot; %}
10633 
10634   ins_encode %{
10635     __ lsrvw(as_Register($dst$$reg),
10636              as_Register($src1$$reg),
10637              as_Register($src2$$reg));
10638   %}
10639 
10640   ins_pipe(ialu_reg_reg_vshift);
10641 %}
10642 
10643 // Shift Right Logical Immediate
10644 instruct urShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10645   match(Set dst (URShiftI src1 src2));
10646 
10647   ins_cost(INSN_COST);
10648   format %{ &quot;lsrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10649 
10650   ins_encode %{
10651     __ lsrw(as_Register($dst$$reg),
10652             as_Register($src1$$reg),
10653             $src2$$constant &amp; 0x1f);
10654   %}
10655 
10656   ins_pipe(ialu_reg_shift);
10657 %}
10658 
10659 // Shift Right Arithmetic Register
10660 instruct rShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10661   match(Set dst (RShiftI src1 src2));
10662 
10663   ins_cost(INSN_COST * 2);
10664   format %{ &quot;asrvw  $dst, $src1, $src2&quot; %}
10665 
10666   ins_encode %{
10667     __ asrvw(as_Register($dst$$reg),
10668              as_Register($src1$$reg),
10669              as_Register($src2$$reg));
10670   %}
10671 
10672   ins_pipe(ialu_reg_reg_vshift);
10673 %}
10674 
10675 // Shift Right Arithmetic Immediate
10676 instruct rShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10677   match(Set dst (RShiftI src1 src2));
10678 
10679   ins_cost(INSN_COST);
10680   format %{ &quot;asrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10681 
10682   ins_encode %{
10683     __ asrw(as_Register($dst$$reg),
10684             as_Register($src1$$reg),
10685             $src2$$constant &amp; 0x1f);
10686   %}
10687 
10688   ins_pipe(ialu_reg_shift);
10689 %}
10690 
10691 // Combined Int Mask and Right Shift (using UBFM)
10692 // TODO
10693 
10694 // Long Shifts
10695 
10696 // Shift Left Register
10697 instruct lShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10698   match(Set dst (LShiftL src1 src2));
10699 
10700   ins_cost(INSN_COST * 2);
10701   format %{ &quot;lslv  $dst, $src1, $src2&quot; %}
10702 
10703   ins_encode %{
10704     __ lslv(as_Register($dst$$reg),
10705             as_Register($src1$$reg),
10706             as_Register($src2$$reg));
10707   %}
10708 
10709   ins_pipe(ialu_reg_reg_vshift);
10710 %}
10711 
10712 // Shift Left Immediate
10713 instruct lShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10714   match(Set dst (LShiftL src1 src2));
10715 
10716   ins_cost(INSN_COST);
10717   format %{ &quot;lsl $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10718 
10719   ins_encode %{
10720     __ lsl(as_Register($dst$$reg),
10721             as_Register($src1$$reg),
10722             $src2$$constant &amp; 0x3f);
10723   %}
10724 
10725   ins_pipe(ialu_reg_shift);
10726 %}
10727 
10728 // Shift Right Logical Register
10729 instruct urShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10730   match(Set dst (URShiftL src1 src2));
10731 
10732   ins_cost(INSN_COST * 2);
10733   format %{ &quot;lsrv  $dst, $src1, $src2&quot; %}
10734 
10735   ins_encode %{
10736     __ lsrv(as_Register($dst$$reg),
10737             as_Register($src1$$reg),
10738             as_Register($src2$$reg));
10739   %}
10740 
10741   ins_pipe(ialu_reg_reg_vshift);
10742 %}
10743 
10744 // Shift Right Logical Immediate
10745 instruct urShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10746   match(Set dst (URShiftL src1 src2));
10747 
10748   ins_cost(INSN_COST);
10749   format %{ &quot;lsr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10750 
10751   ins_encode %{
10752     __ lsr(as_Register($dst$$reg),
10753            as_Register($src1$$reg),
10754            $src2$$constant &amp; 0x3f);
10755   %}
10756 
10757   ins_pipe(ialu_reg_shift);
10758 %}
10759 
10760 // A special-case pattern for card table stores.
10761 instruct urShiftP_reg_imm(iRegLNoSp dst, iRegP src1, immI src2) %{
10762   match(Set dst (URShiftL (CastP2X src1) src2));
10763 
10764   ins_cost(INSN_COST);
10765   format %{ &quot;lsr $dst, p2x($src1), ($src2 &amp; 0x3f)&quot; %}
10766 
10767   ins_encode %{
10768     __ lsr(as_Register($dst$$reg),
10769            as_Register($src1$$reg),
10770            $src2$$constant &amp; 0x3f);
10771   %}
10772 
10773   ins_pipe(ialu_reg_shift);
10774 %}
10775 
10776 // Shift Right Arithmetic Register
10777 instruct rShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10778   match(Set dst (RShiftL src1 src2));
10779 
10780   ins_cost(INSN_COST * 2);
10781   format %{ &quot;asrv  $dst, $src1, $src2&quot; %}
10782 
10783   ins_encode %{
10784     __ asrv(as_Register($dst$$reg),
10785             as_Register($src1$$reg),
10786             as_Register($src2$$reg));
10787   %}
10788 
10789   ins_pipe(ialu_reg_reg_vshift);
10790 %}
10791 
10792 // Shift Right Arithmetic Immediate
10793 instruct rShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10794   match(Set dst (RShiftL src1 src2));
10795 
10796   ins_cost(INSN_COST);
10797   format %{ &quot;asr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10798 
10799   ins_encode %{
10800     __ asr(as_Register($dst$$reg),
10801            as_Register($src1$$reg),
10802            $src2$$constant &amp; 0x3f);
10803   %}
10804 
10805   ins_pipe(ialu_reg_shift);
10806 %}
10807 
10808 // BEGIN This section of the file is automatically generated. Do not edit --------------
10809 
10810 
10811 // This pattern is automatically generated from aarch64_ad.m4
10812 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
10813 instruct regL_not_reg(iRegLNoSp dst,
10814                          iRegL src1, immL_M1 m1,
10815                          rFlagsReg cr) %{
10816   match(Set dst (XorL src1 m1));
10817   ins_cost(INSN_COST);
10818   format %{ &quot;eon  $dst, $src1, zr&quot; %}
10819 
10820   ins_encode %{
10821     __ eon(as_Register($dst$$reg),
10822               as_Register($src1$$reg),
10823               zr,
10824               Assembler::LSL, 0);
10825   %}
10826 
10827   ins_pipe(ialu_reg);
10828 %}
10829 
10830 // This pattern is automatically generated from aarch64_ad.m4
10831 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
10832 instruct regI_not_reg(iRegINoSp dst,
10833                          iRegIorL2I src1, immI_M1 m1,
10834                          rFlagsReg cr) %{
10835   match(Set dst (XorI src1 m1));
10836   ins_cost(INSN_COST);
10837   format %{ &quot;eonw  $dst, $src1, zr&quot; %}
10838 
10839   ins_encode %{
10840     __ eonw(as_Register($dst$$reg),
10841               as_Register($src1$$reg),
10842               zr,
10843               Assembler::LSL, 0);
10844   %}
10845 
10846   ins_pipe(ialu_reg);
10847 %}
10848 
10849 // This pattern is automatically generated from aarch64_ad.m4
10850 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
10851 instruct AndI_reg_not_reg(iRegINoSp dst,
10852                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10853                          rFlagsReg cr) %{
10854   match(Set dst (AndI src1 (XorI src2 m1)));
10855   ins_cost(INSN_COST);
10856   format %{ &quot;bicw  $dst, $src1, $src2&quot; %}
10857 
10858   ins_encode %{
10859     __ bicw(as_Register($dst$$reg),
10860               as_Register($src1$$reg),
10861               as_Register($src2$$reg),
10862               Assembler::LSL, 0);
10863   %}
10864 
10865   ins_pipe(ialu_reg_reg);
10866 %}
10867 
10868 // This pattern is automatically generated from aarch64_ad.m4
10869 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
10870 instruct AndL_reg_not_reg(iRegLNoSp dst,
10871                          iRegL src1, iRegL src2, immL_M1 m1,
10872                          rFlagsReg cr) %{
10873   match(Set dst (AndL src1 (XorL src2 m1)));
10874   ins_cost(INSN_COST);
10875   format %{ &quot;bic  $dst, $src1, $src2&quot; %}
10876 
10877   ins_encode %{
10878     __ bic(as_Register($dst$$reg),
10879               as_Register($src1$$reg),
10880               as_Register($src2$$reg),
10881               Assembler::LSL, 0);
10882   %}
10883 
10884   ins_pipe(ialu_reg_reg);
10885 %}
10886 
10887 // This pattern is automatically generated from aarch64_ad.m4
10888 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
10889 instruct OrI_reg_not_reg(iRegINoSp dst,
10890                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10891                          rFlagsReg cr) %{
10892   match(Set dst (OrI src1 (XorI src2 m1)));
10893   ins_cost(INSN_COST);
10894   format %{ &quot;ornw  $dst, $src1, $src2&quot; %}
10895 
10896   ins_encode %{
10897     __ ornw(as_Register($dst$$reg),
10898               as_Register($src1$$reg),
10899               as_Register($src2$$reg),
10900               Assembler::LSL, 0);
10901   %}
10902 
10903   ins_pipe(ialu_reg_reg);
10904 %}
10905 
10906 // This pattern is automatically generated from aarch64_ad.m4
10907 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
10908 instruct OrL_reg_not_reg(iRegLNoSp dst,
10909                          iRegL src1, iRegL src2, immL_M1 m1,
10910                          rFlagsReg cr) %{
10911   match(Set dst (OrL src1 (XorL src2 m1)));
10912   ins_cost(INSN_COST);
10913   format %{ &quot;orn  $dst, $src1, $src2&quot; %}
10914 
10915   ins_encode %{
10916     __ orn(as_Register($dst$$reg),
10917               as_Register($src1$$reg),
10918               as_Register($src2$$reg),
10919               Assembler::LSL, 0);
10920   %}
10921 
10922   ins_pipe(ialu_reg_reg);
10923 %}
10924 
10925 // This pattern is automatically generated from aarch64_ad.m4
10926 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
10927 instruct XorI_reg_not_reg(iRegINoSp dst,
10928                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10929                          rFlagsReg cr) %{
10930   match(Set dst (XorI m1 (XorI src2 src1)));
10931   ins_cost(INSN_COST);
10932   format %{ &quot;eonw  $dst, $src1, $src2&quot; %}
10933 
10934   ins_encode %{
10935     __ eonw(as_Register($dst$$reg),
10936               as_Register($src1$$reg),
10937               as_Register($src2$$reg),
10938               Assembler::LSL, 0);
10939   %}
10940 
10941   ins_pipe(ialu_reg_reg);
10942 %}
10943 
10944 // This pattern is automatically generated from aarch64_ad.m4
10945 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
10946 instruct XorL_reg_not_reg(iRegLNoSp dst,
10947                          iRegL src1, iRegL src2, immL_M1 m1,
10948                          rFlagsReg cr) %{
10949   match(Set dst (XorL m1 (XorL src2 src1)));
10950   ins_cost(INSN_COST);
10951   format %{ &quot;eon  $dst, $src1, $src2&quot; %}
10952 
10953   ins_encode %{
10954     __ eon(as_Register($dst$$reg),
10955               as_Register($src1$$reg),
10956               as_Register($src2$$reg),
10957               Assembler::LSL, 0);
10958   %}
10959 
10960   ins_pipe(ialu_reg_reg);
10961 %}
10962 
10963 // This pattern is automatically generated from aarch64_ad.m4
10964 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
10965 instruct AndI_reg_URShift_not_reg(iRegINoSp dst,
10966                          iRegIorL2I src1, iRegIorL2I src2,
10967                          immI src3, immI_M1 src4, rFlagsReg cr) %{
10968   match(Set dst (AndI src1 (XorI(URShiftI src2 src3) src4)));
10969   ins_cost(1.9 * INSN_COST);
10970   format %{ &quot;bicw  $dst, $src1, $src2, LSR $src3&quot; %}
10971 
10972   ins_encode %{
10973     __ bicw(as_Register($dst$$reg),
10974               as_Register($src1$$reg),
10975               as_Register($src2$$reg),
10976               Assembler::LSR,
10977               $src3$$constant &amp; 0x1f);
10978   %}
10979 
10980   ins_pipe(ialu_reg_reg_shift);
10981 %}
10982 
10983 // This pattern is automatically generated from aarch64_ad.m4
10984 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
10985 instruct AndL_reg_URShift_not_reg(iRegLNoSp dst,
10986                          iRegL src1, iRegL src2,
10987                          immI src3, immL_M1 src4, rFlagsReg cr) %{
10988   match(Set dst (AndL src1 (XorL(URShiftL src2 src3) src4)));
10989   ins_cost(1.9 * INSN_COST);
10990   format %{ &quot;bic  $dst, $src1, $src2, LSR $src3&quot; %}
10991 
10992   ins_encode %{
10993     __ bic(as_Register($dst$$reg),
10994               as_Register($src1$$reg),
10995               as_Register($src2$$reg),
10996               Assembler::LSR,
10997               $src3$$constant &amp; 0x3f);
10998   %}
10999 
11000   ins_pipe(ialu_reg_reg_shift);
11001 %}
11002 
11003 // This pattern is automatically generated from aarch64_ad.m4
11004 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11005 instruct AndI_reg_RShift_not_reg(iRegINoSp dst,
11006                          iRegIorL2I src1, iRegIorL2I src2,
11007                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11008   match(Set dst (AndI src1 (XorI(RShiftI src2 src3) src4)));
11009   ins_cost(1.9 * INSN_COST);
11010   format %{ &quot;bicw  $dst, $src1, $src2, ASR $src3&quot; %}
11011 
11012   ins_encode %{
11013     __ bicw(as_Register($dst$$reg),
11014               as_Register($src1$$reg),
11015               as_Register($src2$$reg),
11016               Assembler::ASR,
11017               $src3$$constant &amp; 0x1f);
11018   %}
11019 
11020   ins_pipe(ialu_reg_reg_shift);
11021 %}
11022 
11023 // This pattern is automatically generated from aarch64_ad.m4
11024 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11025 instruct AndL_reg_RShift_not_reg(iRegLNoSp dst,
11026                          iRegL src1, iRegL src2,
11027                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11028   match(Set dst (AndL src1 (XorL(RShiftL src2 src3) src4)));
11029   ins_cost(1.9 * INSN_COST);
11030   format %{ &quot;bic  $dst, $src1, $src2, ASR $src3&quot; %}
11031 
11032   ins_encode %{
11033     __ bic(as_Register($dst$$reg),
11034               as_Register($src1$$reg),
11035               as_Register($src2$$reg),
11036               Assembler::ASR,
11037               $src3$$constant &amp; 0x3f);
11038   %}
11039 
11040   ins_pipe(ialu_reg_reg_shift);
11041 %}
11042 
11043 // This pattern is automatically generated from aarch64_ad.m4
11044 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11045 instruct AndI_reg_LShift_not_reg(iRegINoSp dst,
11046                          iRegIorL2I src1, iRegIorL2I src2,
11047                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11048   match(Set dst (AndI src1 (XorI(LShiftI src2 src3) src4)));
11049   ins_cost(1.9 * INSN_COST);
11050   format %{ &quot;bicw  $dst, $src1, $src2, LSL $src3&quot; %}
11051 
11052   ins_encode %{
11053     __ bicw(as_Register($dst$$reg),
11054               as_Register($src1$$reg),
11055               as_Register($src2$$reg),
11056               Assembler::LSL,
11057               $src3$$constant &amp; 0x1f);
11058   %}
11059 
11060   ins_pipe(ialu_reg_reg_shift);
11061 %}
11062 
11063 // This pattern is automatically generated from aarch64_ad.m4
11064 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11065 instruct AndL_reg_LShift_not_reg(iRegLNoSp dst,
11066                          iRegL src1, iRegL src2,
11067                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11068   match(Set dst (AndL src1 (XorL(LShiftL src2 src3) src4)));
11069   ins_cost(1.9 * INSN_COST);
11070   format %{ &quot;bic  $dst, $src1, $src2, LSL $src3&quot; %}
11071 
11072   ins_encode %{
11073     __ bic(as_Register($dst$$reg),
11074               as_Register($src1$$reg),
11075               as_Register($src2$$reg),
11076               Assembler::LSL,
11077               $src3$$constant &amp; 0x3f);
11078   %}
11079 
11080   ins_pipe(ialu_reg_reg_shift);
11081 %}
11082 
11083 // This pattern is automatically generated from aarch64_ad.m4
11084 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11085 instruct XorI_reg_URShift_not_reg(iRegINoSp dst,
11086                          iRegIorL2I src1, iRegIorL2I src2,
11087                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11088   match(Set dst (XorI src4 (XorI(URShiftI src2 src3) src1)));
11089   ins_cost(1.9 * INSN_COST);
11090   format %{ &quot;eonw  $dst, $src1, $src2, LSR $src3&quot; %}
11091 
11092   ins_encode %{
11093     __ eonw(as_Register($dst$$reg),
11094               as_Register($src1$$reg),
11095               as_Register($src2$$reg),
11096               Assembler::LSR,
11097               $src3$$constant &amp; 0x1f);
11098   %}
11099 
11100   ins_pipe(ialu_reg_reg_shift);
11101 %}
11102 
11103 // This pattern is automatically generated from aarch64_ad.m4
11104 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11105 instruct XorL_reg_URShift_not_reg(iRegLNoSp dst,
11106                          iRegL src1, iRegL src2,
11107                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11108   match(Set dst (XorL src4 (XorL(URShiftL src2 src3) src1)));
11109   ins_cost(1.9 * INSN_COST);
11110   format %{ &quot;eon  $dst, $src1, $src2, LSR $src3&quot; %}
11111 
11112   ins_encode %{
11113     __ eon(as_Register($dst$$reg),
11114               as_Register($src1$$reg),
11115               as_Register($src2$$reg),
11116               Assembler::LSR,
11117               $src3$$constant &amp; 0x3f);
11118   %}
11119 
11120   ins_pipe(ialu_reg_reg_shift);
11121 %}
11122 
11123 // This pattern is automatically generated from aarch64_ad.m4
11124 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11125 instruct XorI_reg_RShift_not_reg(iRegINoSp dst,
11126                          iRegIorL2I src1, iRegIorL2I src2,
11127                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11128   match(Set dst (XorI src4 (XorI(RShiftI src2 src3) src1)));
11129   ins_cost(1.9 * INSN_COST);
11130   format %{ &quot;eonw  $dst, $src1, $src2, ASR $src3&quot; %}
11131 
11132   ins_encode %{
11133     __ eonw(as_Register($dst$$reg),
11134               as_Register($src1$$reg),
11135               as_Register($src2$$reg),
11136               Assembler::ASR,
11137               $src3$$constant &amp; 0x1f);
11138   %}
11139 
11140   ins_pipe(ialu_reg_reg_shift);
11141 %}
11142 
11143 // This pattern is automatically generated from aarch64_ad.m4
11144 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11145 instruct XorL_reg_RShift_not_reg(iRegLNoSp dst,
11146                          iRegL src1, iRegL src2,
11147                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11148   match(Set dst (XorL src4 (XorL(RShiftL src2 src3) src1)));
11149   ins_cost(1.9 * INSN_COST);
11150   format %{ &quot;eon  $dst, $src1, $src2, ASR $src3&quot; %}
11151 
11152   ins_encode %{
11153     __ eon(as_Register($dst$$reg),
11154               as_Register($src1$$reg),
11155               as_Register($src2$$reg),
11156               Assembler::ASR,
11157               $src3$$constant &amp; 0x3f);
11158   %}
11159 
11160   ins_pipe(ialu_reg_reg_shift);
11161 %}
11162 
11163 // This pattern is automatically generated from aarch64_ad.m4
11164 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11165 instruct XorI_reg_LShift_not_reg(iRegINoSp dst,
11166                          iRegIorL2I src1, iRegIorL2I src2,
11167                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11168   match(Set dst (XorI src4 (XorI(LShiftI src2 src3) src1)));
11169   ins_cost(1.9 * INSN_COST);
11170   format %{ &quot;eonw  $dst, $src1, $src2, LSL $src3&quot; %}
11171 
11172   ins_encode %{
11173     __ eonw(as_Register($dst$$reg),
11174               as_Register($src1$$reg),
11175               as_Register($src2$$reg),
11176               Assembler::LSL,
11177               $src3$$constant &amp; 0x1f);
11178   %}
11179 
11180   ins_pipe(ialu_reg_reg_shift);
11181 %}
11182 
11183 // This pattern is automatically generated from aarch64_ad.m4
11184 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11185 instruct XorL_reg_LShift_not_reg(iRegLNoSp dst,
11186                          iRegL src1, iRegL src2,
11187                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11188   match(Set dst (XorL src4 (XorL(LShiftL src2 src3) src1)));
11189   ins_cost(1.9 * INSN_COST);
11190   format %{ &quot;eon  $dst, $src1, $src2, LSL $src3&quot; %}
11191 
11192   ins_encode %{
11193     __ eon(as_Register($dst$$reg),
11194               as_Register($src1$$reg),
11195               as_Register($src2$$reg),
11196               Assembler::LSL,
11197               $src3$$constant &amp; 0x3f);
11198   %}
11199 
11200   ins_pipe(ialu_reg_reg_shift);
11201 %}
11202 
11203 // This pattern is automatically generated from aarch64_ad.m4
11204 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11205 instruct OrI_reg_URShift_not_reg(iRegINoSp dst,
11206                          iRegIorL2I src1, iRegIorL2I src2,
11207                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11208   match(Set dst (OrI src1 (XorI(URShiftI src2 src3) src4)));
11209   ins_cost(1.9 * INSN_COST);
11210   format %{ &quot;ornw  $dst, $src1, $src2, LSR $src3&quot; %}
11211 
11212   ins_encode %{
11213     __ ornw(as_Register($dst$$reg),
11214               as_Register($src1$$reg),
11215               as_Register($src2$$reg),
11216               Assembler::LSR,
11217               $src3$$constant &amp; 0x1f);
11218   %}
11219 
11220   ins_pipe(ialu_reg_reg_shift);
11221 %}
11222 
11223 // This pattern is automatically generated from aarch64_ad.m4
11224 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11225 instruct OrL_reg_URShift_not_reg(iRegLNoSp dst,
11226                          iRegL src1, iRegL src2,
11227                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11228   match(Set dst (OrL src1 (XorL(URShiftL src2 src3) src4)));
11229   ins_cost(1.9 * INSN_COST);
11230   format %{ &quot;orn  $dst, $src1, $src2, LSR $src3&quot; %}
11231 
11232   ins_encode %{
11233     __ orn(as_Register($dst$$reg),
11234               as_Register($src1$$reg),
11235               as_Register($src2$$reg),
11236               Assembler::LSR,
11237               $src3$$constant &amp; 0x3f);
11238   %}
11239 
11240   ins_pipe(ialu_reg_reg_shift);
11241 %}
11242 
11243 // This pattern is automatically generated from aarch64_ad.m4
11244 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11245 instruct OrI_reg_RShift_not_reg(iRegINoSp dst,
11246                          iRegIorL2I src1, iRegIorL2I src2,
11247                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11248   match(Set dst (OrI src1 (XorI(RShiftI src2 src3) src4)));
11249   ins_cost(1.9 * INSN_COST);
11250   format %{ &quot;ornw  $dst, $src1, $src2, ASR $src3&quot; %}
11251 
11252   ins_encode %{
11253     __ ornw(as_Register($dst$$reg),
11254               as_Register($src1$$reg),
11255               as_Register($src2$$reg),
11256               Assembler::ASR,
11257               $src3$$constant &amp; 0x1f);
11258   %}
11259 
11260   ins_pipe(ialu_reg_reg_shift);
11261 %}
11262 
11263 // This pattern is automatically generated from aarch64_ad.m4
11264 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11265 instruct OrL_reg_RShift_not_reg(iRegLNoSp dst,
11266                          iRegL src1, iRegL src2,
11267                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11268   match(Set dst (OrL src1 (XorL(RShiftL src2 src3) src4)));
11269   ins_cost(1.9 * INSN_COST);
11270   format %{ &quot;orn  $dst, $src1, $src2, ASR $src3&quot; %}
11271 
11272   ins_encode %{
11273     __ orn(as_Register($dst$$reg),
11274               as_Register($src1$$reg),
11275               as_Register($src2$$reg),
11276               Assembler::ASR,
11277               $src3$$constant &amp; 0x3f);
11278   %}
11279 
11280   ins_pipe(ialu_reg_reg_shift);
11281 %}
11282 
11283 // This pattern is automatically generated from aarch64_ad.m4
11284 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11285 instruct OrI_reg_LShift_not_reg(iRegINoSp dst,
11286                          iRegIorL2I src1, iRegIorL2I src2,
11287                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11288   match(Set dst (OrI src1 (XorI(LShiftI src2 src3) src4)));
11289   ins_cost(1.9 * INSN_COST);
11290   format %{ &quot;ornw  $dst, $src1, $src2, LSL $src3&quot; %}
11291 
11292   ins_encode %{
11293     __ ornw(as_Register($dst$$reg),
11294               as_Register($src1$$reg),
11295               as_Register($src2$$reg),
11296               Assembler::LSL,
11297               $src3$$constant &amp; 0x1f);
11298   %}
11299 
11300   ins_pipe(ialu_reg_reg_shift);
11301 %}
11302 
11303 // This pattern is automatically generated from aarch64_ad.m4
11304 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11305 instruct OrL_reg_LShift_not_reg(iRegLNoSp dst,
11306                          iRegL src1, iRegL src2,
11307                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11308   match(Set dst (OrL src1 (XorL(LShiftL src2 src3) src4)));
11309   ins_cost(1.9 * INSN_COST);
11310   format %{ &quot;orn  $dst, $src1, $src2, LSL $src3&quot; %}
11311 
11312   ins_encode %{
11313     __ orn(as_Register($dst$$reg),
11314               as_Register($src1$$reg),
11315               as_Register($src2$$reg),
11316               Assembler::LSL,
11317               $src3$$constant &amp; 0x3f);
11318   %}
11319 
11320   ins_pipe(ialu_reg_reg_shift);
11321 %}
11322 
11323 // This pattern is automatically generated from aarch64_ad.m4
11324 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11325 instruct AndI_reg_URShift_reg(iRegINoSp dst,
11326                          iRegIorL2I src1, iRegIorL2I src2,
11327                          immI src3, rFlagsReg cr) %{
11328   match(Set dst (AndI src1 (URShiftI src2 src3)));
11329 
11330   ins_cost(1.9 * INSN_COST);
11331   format %{ &quot;andw  $dst, $src1, $src2, LSR $src3&quot; %}
11332 
11333   ins_encode %{
11334     __ andw(as_Register($dst$$reg),
11335               as_Register($src1$$reg),
11336               as_Register($src2$$reg),
11337               Assembler::LSR,
11338               $src3$$constant &amp; 0x1f);
11339   %}
11340 
11341   ins_pipe(ialu_reg_reg_shift);
11342 %}
11343 
11344 // This pattern is automatically generated from aarch64_ad.m4
11345 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11346 instruct AndL_reg_URShift_reg(iRegLNoSp dst,
11347                          iRegL src1, iRegL src2,
11348                          immI src3, rFlagsReg cr) %{
11349   match(Set dst (AndL src1 (URShiftL src2 src3)));
11350 
11351   ins_cost(1.9 * INSN_COST);
11352   format %{ &quot;andr  $dst, $src1, $src2, LSR $src3&quot; %}
11353 
11354   ins_encode %{
11355     __ andr(as_Register($dst$$reg),
11356               as_Register($src1$$reg),
11357               as_Register($src2$$reg),
11358               Assembler::LSR,
11359               $src3$$constant &amp; 0x3f);
11360   %}
11361 
11362   ins_pipe(ialu_reg_reg_shift);
11363 %}
11364 
11365 // This pattern is automatically generated from aarch64_ad.m4
11366 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11367 instruct AndI_reg_RShift_reg(iRegINoSp dst,
11368                          iRegIorL2I src1, iRegIorL2I src2,
11369                          immI src3, rFlagsReg cr) %{
11370   match(Set dst (AndI src1 (RShiftI src2 src3)));
11371 
11372   ins_cost(1.9 * INSN_COST);
11373   format %{ &quot;andw  $dst, $src1, $src2, ASR $src3&quot; %}
11374 
11375   ins_encode %{
11376     __ andw(as_Register($dst$$reg),
11377               as_Register($src1$$reg),
11378               as_Register($src2$$reg),
11379               Assembler::ASR,
11380               $src3$$constant &amp; 0x1f);
11381   %}
11382 
11383   ins_pipe(ialu_reg_reg_shift);
11384 %}
11385 
11386 // This pattern is automatically generated from aarch64_ad.m4
11387 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11388 instruct AndL_reg_RShift_reg(iRegLNoSp dst,
11389                          iRegL src1, iRegL src2,
11390                          immI src3, rFlagsReg cr) %{
11391   match(Set dst (AndL src1 (RShiftL src2 src3)));
11392 
11393   ins_cost(1.9 * INSN_COST);
11394   format %{ &quot;andr  $dst, $src1, $src2, ASR $src3&quot; %}
11395 
11396   ins_encode %{
11397     __ andr(as_Register($dst$$reg),
11398               as_Register($src1$$reg),
11399               as_Register($src2$$reg),
11400               Assembler::ASR,
11401               $src3$$constant &amp; 0x3f);
11402   %}
11403 
11404   ins_pipe(ialu_reg_reg_shift);
11405 %}
11406 
11407 // This pattern is automatically generated from aarch64_ad.m4
11408 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11409 instruct AndI_reg_LShift_reg(iRegINoSp dst,
11410                          iRegIorL2I src1, iRegIorL2I src2,
11411                          immI src3, rFlagsReg cr) %{
11412   match(Set dst (AndI src1 (LShiftI src2 src3)));
11413 
11414   ins_cost(1.9 * INSN_COST);
11415   format %{ &quot;andw  $dst, $src1, $src2, LSL $src3&quot; %}
11416 
11417   ins_encode %{
11418     __ andw(as_Register($dst$$reg),
11419               as_Register($src1$$reg),
11420               as_Register($src2$$reg),
11421               Assembler::LSL,
11422               $src3$$constant &amp; 0x1f);
11423   %}
11424 
11425   ins_pipe(ialu_reg_reg_shift);
11426 %}
11427 
11428 // This pattern is automatically generated from aarch64_ad.m4
11429 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11430 instruct AndL_reg_LShift_reg(iRegLNoSp dst,
11431                          iRegL src1, iRegL src2,
11432                          immI src3, rFlagsReg cr) %{
11433   match(Set dst (AndL src1 (LShiftL src2 src3)));
11434 
11435   ins_cost(1.9 * INSN_COST);
11436   format %{ &quot;andr  $dst, $src1, $src2, LSL $src3&quot; %}
11437 
11438   ins_encode %{
11439     __ andr(as_Register($dst$$reg),
11440               as_Register($src1$$reg),
11441               as_Register($src2$$reg),
11442               Assembler::LSL,
11443               $src3$$constant &amp; 0x3f);
11444   %}
11445 
11446   ins_pipe(ialu_reg_reg_shift);
11447 %}
11448 
11449 // This pattern is automatically generated from aarch64_ad.m4
11450 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11451 instruct XorI_reg_URShift_reg(iRegINoSp dst,
11452                          iRegIorL2I src1, iRegIorL2I src2,
11453                          immI src3, rFlagsReg cr) %{
11454   match(Set dst (XorI src1 (URShiftI src2 src3)));
11455 
11456   ins_cost(1.9 * INSN_COST);
11457   format %{ &quot;eorw  $dst, $src1, $src2, LSR $src3&quot; %}
11458 
11459   ins_encode %{
11460     __ eorw(as_Register($dst$$reg),
11461               as_Register($src1$$reg),
11462               as_Register($src2$$reg),
11463               Assembler::LSR,
11464               $src3$$constant &amp; 0x1f);
11465   %}
11466 
11467   ins_pipe(ialu_reg_reg_shift);
11468 %}
11469 
11470 // This pattern is automatically generated from aarch64_ad.m4
11471 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11472 instruct XorL_reg_URShift_reg(iRegLNoSp dst,
11473                          iRegL src1, iRegL src2,
11474                          immI src3, rFlagsReg cr) %{
11475   match(Set dst (XorL src1 (URShiftL src2 src3)));
11476 
11477   ins_cost(1.9 * INSN_COST);
11478   format %{ &quot;eor  $dst, $src1, $src2, LSR $src3&quot; %}
11479 
11480   ins_encode %{
11481     __ eor(as_Register($dst$$reg),
11482               as_Register($src1$$reg),
11483               as_Register($src2$$reg),
11484               Assembler::LSR,
11485               $src3$$constant &amp; 0x3f);
11486   %}
11487 
11488   ins_pipe(ialu_reg_reg_shift);
11489 %}
11490 
11491 // This pattern is automatically generated from aarch64_ad.m4
11492 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11493 instruct XorI_reg_RShift_reg(iRegINoSp dst,
11494                          iRegIorL2I src1, iRegIorL2I src2,
11495                          immI src3, rFlagsReg cr) %{
11496   match(Set dst (XorI src1 (RShiftI src2 src3)));
11497 
11498   ins_cost(1.9 * INSN_COST);
11499   format %{ &quot;eorw  $dst, $src1, $src2, ASR $src3&quot; %}
11500 
11501   ins_encode %{
11502     __ eorw(as_Register($dst$$reg),
11503               as_Register($src1$$reg),
11504               as_Register($src2$$reg),
11505               Assembler::ASR,
11506               $src3$$constant &amp; 0x1f);
11507   %}
11508 
11509   ins_pipe(ialu_reg_reg_shift);
11510 %}
11511 
11512 // This pattern is automatically generated from aarch64_ad.m4
11513 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11514 instruct XorL_reg_RShift_reg(iRegLNoSp dst,
11515                          iRegL src1, iRegL src2,
11516                          immI src3, rFlagsReg cr) %{
11517   match(Set dst (XorL src1 (RShiftL src2 src3)));
11518 
11519   ins_cost(1.9 * INSN_COST);
11520   format %{ &quot;eor  $dst, $src1, $src2, ASR $src3&quot; %}
11521 
11522   ins_encode %{
11523     __ eor(as_Register($dst$$reg),
11524               as_Register($src1$$reg),
11525               as_Register($src2$$reg),
11526               Assembler::ASR,
11527               $src3$$constant &amp; 0x3f);
11528   %}
11529 
11530   ins_pipe(ialu_reg_reg_shift);
11531 %}
11532 
11533 // This pattern is automatically generated from aarch64_ad.m4
11534 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11535 instruct XorI_reg_LShift_reg(iRegINoSp dst,
11536                          iRegIorL2I src1, iRegIorL2I src2,
11537                          immI src3, rFlagsReg cr) %{
11538   match(Set dst (XorI src1 (LShiftI src2 src3)));
11539 
11540   ins_cost(1.9 * INSN_COST);
11541   format %{ &quot;eorw  $dst, $src1, $src2, LSL $src3&quot; %}
11542 
11543   ins_encode %{
11544     __ eorw(as_Register($dst$$reg),
11545               as_Register($src1$$reg),
11546               as_Register($src2$$reg),
11547               Assembler::LSL,
11548               $src3$$constant &amp; 0x1f);
11549   %}
11550 
11551   ins_pipe(ialu_reg_reg_shift);
11552 %}
11553 
11554 // This pattern is automatically generated from aarch64_ad.m4
11555 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11556 instruct XorL_reg_LShift_reg(iRegLNoSp dst,
11557                          iRegL src1, iRegL src2,
11558                          immI src3, rFlagsReg cr) %{
11559   match(Set dst (XorL src1 (LShiftL src2 src3)));
11560 
11561   ins_cost(1.9 * INSN_COST);
11562   format %{ &quot;eor  $dst, $src1, $src2, LSL $src3&quot; %}
11563 
11564   ins_encode %{
11565     __ eor(as_Register($dst$$reg),
11566               as_Register($src1$$reg),
11567               as_Register($src2$$reg),
11568               Assembler::LSL,
11569               $src3$$constant &amp; 0x3f);
11570   %}
11571 
11572   ins_pipe(ialu_reg_reg_shift);
11573 %}
11574 
11575 // This pattern is automatically generated from aarch64_ad.m4
11576 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11577 instruct OrI_reg_URShift_reg(iRegINoSp dst,
11578                          iRegIorL2I src1, iRegIorL2I src2,
11579                          immI src3, rFlagsReg cr) %{
11580   match(Set dst (OrI src1 (URShiftI src2 src3)));
11581 
11582   ins_cost(1.9 * INSN_COST);
11583   format %{ &quot;orrw  $dst, $src1, $src2, LSR $src3&quot; %}
11584 
11585   ins_encode %{
11586     __ orrw(as_Register($dst$$reg),
11587               as_Register($src1$$reg),
11588               as_Register($src2$$reg),
11589               Assembler::LSR,
11590               $src3$$constant &amp; 0x1f);
11591   %}
11592 
11593   ins_pipe(ialu_reg_reg_shift);
11594 %}
11595 
11596 // This pattern is automatically generated from aarch64_ad.m4
11597 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11598 instruct OrL_reg_URShift_reg(iRegLNoSp dst,
11599                          iRegL src1, iRegL src2,
11600                          immI src3, rFlagsReg cr) %{
11601   match(Set dst (OrL src1 (URShiftL src2 src3)));
11602 
11603   ins_cost(1.9 * INSN_COST);
11604   format %{ &quot;orr  $dst, $src1, $src2, LSR $src3&quot; %}
11605 
11606   ins_encode %{
11607     __ orr(as_Register($dst$$reg),
11608               as_Register($src1$$reg),
11609               as_Register($src2$$reg),
11610               Assembler::LSR,
11611               $src3$$constant &amp; 0x3f);
11612   %}
11613 
11614   ins_pipe(ialu_reg_reg_shift);
11615 %}
11616 
11617 // This pattern is automatically generated from aarch64_ad.m4
11618 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11619 instruct OrI_reg_RShift_reg(iRegINoSp dst,
11620                          iRegIorL2I src1, iRegIorL2I src2,
11621                          immI src3, rFlagsReg cr) %{
11622   match(Set dst (OrI src1 (RShiftI src2 src3)));
11623 
11624   ins_cost(1.9 * INSN_COST);
11625   format %{ &quot;orrw  $dst, $src1, $src2, ASR $src3&quot; %}
11626 
11627   ins_encode %{
11628     __ orrw(as_Register($dst$$reg),
11629               as_Register($src1$$reg),
11630               as_Register($src2$$reg),
11631               Assembler::ASR,
11632               $src3$$constant &amp; 0x1f);
11633   %}
11634 
11635   ins_pipe(ialu_reg_reg_shift);
11636 %}
11637 
11638 // This pattern is automatically generated from aarch64_ad.m4
11639 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11640 instruct OrL_reg_RShift_reg(iRegLNoSp dst,
11641                          iRegL src1, iRegL src2,
11642                          immI src3, rFlagsReg cr) %{
11643   match(Set dst (OrL src1 (RShiftL src2 src3)));
11644 
11645   ins_cost(1.9 * INSN_COST);
11646   format %{ &quot;orr  $dst, $src1, $src2, ASR $src3&quot; %}
11647 
11648   ins_encode %{
11649     __ orr(as_Register($dst$$reg),
11650               as_Register($src1$$reg),
11651               as_Register($src2$$reg),
11652               Assembler::ASR,
11653               $src3$$constant &amp; 0x3f);
11654   %}
11655 
11656   ins_pipe(ialu_reg_reg_shift);
11657 %}
11658 
11659 // This pattern is automatically generated from aarch64_ad.m4
11660 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11661 instruct OrI_reg_LShift_reg(iRegINoSp dst,
11662                          iRegIorL2I src1, iRegIorL2I src2,
11663                          immI src3, rFlagsReg cr) %{
11664   match(Set dst (OrI src1 (LShiftI src2 src3)));
11665 
11666   ins_cost(1.9 * INSN_COST);
11667   format %{ &quot;orrw  $dst, $src1, $src2, LSL $src3&quot; %}
11668 
11669   ins_encode %{
11670     __ orrw(as_Register($dst$$reg),
11671               as_Register($src1$$reg),
11672               as_Register($src2$$reg),
11673               Assembler::LSL,
11674               $src3$$constant &amp; 0x1f);
11675   %}
11676 
11677   ins_pipe(ialu_reg_reg_shift);
11678 %}
11679 
11680 // This pattern is automatically generated from aarch64_ad.m4
11681 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11682 instruct OrL_reg_LShift_reg(iRegLNoSp dst,
11683                          iRegL src1, iRegL src2,
11684                          immI src3, rFlagsReg cr) %{
11685   match(Set dst (OrL src1 (LShiftL src2 src3)));
11686 
11687   ins_cost(1.9 * INSN_COST);
11688   format %{ &quot;orr  $dst, $src1, $src2, LSL $src3&quot; %}
11689 
11690   ins_encode %{
11691     __ orr(as_Register($dst$$reg),
11692               as_Register($src1$$reg),
11693               as_Register($src2$$reg),
11694               Assembler::LSL,
11695               $src3$$constant &amp; 0x3f);
11696   %}
11697 
11698   ins_pipe(ialu_reg_reg_shift);
11699 %}
11700 
11701 // This pattern is automatically generated from aarch64_ad.m4
11702 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11703 instruct AddI_reg_URShift_reg(iRegINoSp dst,
11704                          iRegIorL2I src1, iRegIorL2I src2,
11705                          immI src3, rFlagsReg cr) %{
11706   match(Set dst (AddI src1 (URShiftI src2 src3)));
11707 
11708   ins_cost(1.9 * INSN_COST);
11709   format %{ &quot;addw  $dst, $src1, $src2, LSR $src3&quot; %}
11710 
11711   ins_encode %{
11712     __ addw(as_Register($dst$$reg),
11713               as_Register($src1$$reg),
11714               as_Register($src2$$reg),
11715               Assembler::LSR,
11716               $src3$$constant &amp; 0x1f);
11717   %}
11718 
11719   ins_pipe(ialu_reg_reg_shift);
11720 %}
11721 
11722 // This pattern is automatically generated from aarch64_ad.m4
11723 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11724 instruct AddL_reg_URShift_reg(iRegLNoSp dst,
11725                          iRegL src1, iRegL src2,
11726                          immI src3, rFlagsReg cr) %{
11727   match(Set dst (AddL src1 (URShiftL src2 src3)));
11728 
11729   ins_cost(1.9 * INSN_COST);
11730   format %{ &quot;add  $dst, $src1, $src2, LSR $src3&quot; %}
11731 
11732   ins_encode %{
11733     __ add(as_Register($dst$$reg),
11734               as_Register($src1$$reg),
11735               as_Register($src2$$reg),
11736               Assembler::LSR,
11737               $src3$$constant &amp; 0x3f);
11738   %}
11739 
11740   ins_pipe(ialu_reg_reg_shift);
11741 %}
11742 
11743 // This pattern is automatically generated from aarch64_ad.m4
11744 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11745 instruct AddI_reg_RShift_reg(iRegINoSp dst,
11746                          iRegIorL2I src1, iRegIorL2I src2,
11747                          immI src3, rFlagsReg cr) %{
11748   match(Set dst (AddI src1 (RShiftI src2 src3)));
11749 
11750   ins_cost(1.9 * INSN_COST);
11751   format %{ &quot;addw  $dst, $src1, $src2, ASR $src3&quot; %}
11752 
11753   ins_encode %{
11754     __ addw(as_Register($dst$$reg),
11755               as_Register($src1$$reg),
11756               as_Register($src2$$reg),
11757               Assembler::ASR,
11758               $src3$$constant &amp; 0x1f);
11759   %}
11760 
11761   ins_pipe(ialu_reg_reg_shift);
11762 %}
11763 
11764 // This pattern is automatically generated from aarch64_ad.m4
11765 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11766 instruct AddL_reg_RShift_reg(iRegLNoSp dst,
11767                          iRegL src1, iRegL src2,
11768                          immI src3, rFlagsReg cr) %{
11769   match(Set dst (AddL src1 (RShiftL src2 src3)));
11770 
11771   ins_cost(1.9 * INSN_COST);
11772   format %{ &quot;add  $dst, $src1, $src2, ASR $src3&quot; %}
11773 
11774   ins_encode %{
11775     __ add(as_Register($dst$$reg),
11776               as_Register($src1$$reg),
11777               as_Register($src2$$reg),
11778               Assembler::ASR,
11779               $src3$$constant &amp; 0x3f);
11780   %}
11781 
11782   ins_pipe(ialu_reg_reg_shift);
11783 %}
11784 
11785 // This pattern is automatically generated from aarch64_ad.m4
11786 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11787 instruct AddI_reg_LShift_reg(iRegINoSp dst,
11788                          iRegIorL2I src1, iRegIorL2I src2,
11789                          immI src3, rFlagsReg cr) %{
11790   match(Set dst (AddI src1 (LShiftI src2 src3)));
11791 
11792   ins_cost(1.9 * INSN_COST);
11793   format %{ &quot;addw  $dst, $src1, $src2, LSL $src3&quot; %}
11794 
11795   ins_encode %{
11796     __ addw(as_Register($dst$$reg),
11797               as_Register($src1$$reg),
11798               as_Register($src2$$reg),
11799               Assembler::LSL,
11800               $src3$$constant &amp; 0x1f);
11801   %}
11802 
11803   ins_pipe(ialu_reg_reg_shift);
11804 %}
11805 
11806 // This pattern is automatically generated from aarch64_ad.m4
11807 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11808 instruct AddL_reg_LShift_reg(iRegLNoSp dst,
11809                          iRegL src1, iRegL src2,
11810                          immI src3, rFlagsReg cr) %{
11811   match(Set dst (AddL src1 (LShiftL src2 src3)));
11812 
11813   ins_cost(1.9 * INSN_COST);
11814   format %{ &quot;add  $dst, $src1, $src2, LSL $src3&quot; %}
11815 
11816   ins_encode %{
11817     __ add(as_Register($dst$$reg),
11818               as_Register($src1$$reg),
11819               as_Register($src2$$reg),
11820               Assembler::LSL,
11821               $src3$$constant &amp; 0x3f);
11822   %}
11823 
11824   ins_pipe(ialu_reg_reg_shift);
11825 %}
11826 
11827 // This pattern is automatically generated from aarch64_ad.m4
11828 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11829 instruct SubI_reg_URShift_reg(iRegINoSp dst,
11830                          iRegIorL2I src1, iRegIorL2I src2,
11831                          immI src3, rFlagsReg cr) %{
11832   match(Set dst (SubI src1 (URShiftI src2 src3)));
11833 
11834   ins_cost(1.9 * INSN_COST);
11835   format %{ &quot;subw  $dst, $src1, $src2, LSR $src3&quot; %}
11836 
11837   ins_encode %{
11838     __ subw(as_Register($dst$$reg),
11839               as_Register($src1$$reg),
11840               as_Register($src2$$reg),
11841               Assembler::LSR,
11842               $src3$$constant &amp; 0x1f);
11843   %}
11844 
11845   ins_pipe(ialu_reg_reg_shift);
11846 %}
11847 
11848 // This pattern is automatically generated from aarch64_ad.m4
11849 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11850 instruct SubL_reg_URShift_reg(iRegLNoSp dst,
11851                          iRegL src1, iRegL src2,
11852                          immI src3, rFlagsReg cr) %{
11853   match(Set dst (SubL src1 (URShiftL src2 src3)));
11854 
11855   ins_cost(1.9 * INSN_COST);
11856   format %{ &quot;sub  $dst, $src1, $src2, LSR $src3&quot; %}
11857 
11858   ins_encode %{
11859     __ sub(as_Register($dst$$reg),
11860               as_Register($src1$$reg),
11861               as_Register($src2$$reg),
11862               Assembler::LSR,
11863               $src3$$constant &amp; 0x3f);
11864   %}
11865 
11866   ins_pipe(ialu_reg_reg_shift);
11867 %}
11868 
11869 // This pattern is automatically generated from aarch64_ad.m4
11870 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11871 instruct SubI_reg_RShift_reg(iRegINoSp dst,
11872                          iRegIorL2I src1, iRegIorL2I src2,
11873                          immI src3, rFlagsReg cr) %{
11874   match(Set dst (SubI src1 (RShiftI src2 src3)));
11875 
11876   ins_cost(1.9 * INSN_COST);
11877   format %{ &quot;subw  $dst, $src1, $src2, ASR $src3&quot; %}
11878 
11879   ins_encode %{
11880     __ subw(as_Register($dst$$reg),
11881               as_Register($src1$$reg),
11882               as_Register($src2$$reg),
11883               Assembler::ASR,
11884               $src3$$constant &amp; 0x1f);
11885   %}
11886 
11887   ins_pipe(ialu_reg_reg_shift);
11888 %}
11889 
11890 // This pattern is automatically generated from aarch64_ad.m4
11891 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11892 instruct SubL_reg_RShift_reg(iRegLNoSp dst,
11893                          iRegL src1, iRegL src2,
11894                          immI src3, rFlagsReg cr) %{
11895   match(Set dst (SubL src1 (RShiftL src2 src3)));
11896 
11897   ins_cost(1.9 * INSN_COST);
11898   format %{ &quot;sub  $dst, $src1, $src2, ASR $src3&quot; %}
11899 
11900   ins_encode %{
11901     __ sub(as_Register($dst$$reg),
11902               as_Register($src1$$reg),
11903               as_Register($src2$$reg),
11904               Assembler::ASR,
11905               $src3$$constant &amp; 0x3f);
11906   %}
11907 
11908   ins_pipe(ialu_reg_reg_shift);
11909 %}
11910 
11911 // This pattern is automatically generated from aarch64_ad.m4
11912 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11913 instruct SubI_reg_LShift_reg(iRegINoSp dst,
11914                          iRegIorL2I src1, iRegIorL2I src2,
11915                          immI src3, rFlagsReg cr) %{
11916   match(Set dst (SubI src1 (LShiftI src2 src3)));
11917 
11918   ins_cost(1.9 * INSN_COST);
11919   format %{ &quot;subw  $dst, $src1, $src2, LSL $src3&quot; %}
11920 
11921   ins_encode %{
11922     __ subw(as_Register($dst$$reg),
11923               as_Register($src1$$reg),
11924               as_Register($src2$$reg),
11925               Assembler::LSL,
11926               $src3$$constant &amp; 0x1f);
11927   %}
11928 
11929   ins_pipe(ialu_reg_reg_shift);
11930 %}
11931 
11932 // This pattern is automatically generated from aarch64_ad.m4
11933 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11934 instruct SubL_reg_LShift_reg(iRegLNoSp dst,
11935                          iRegL src1, iRegL src2,
11936                          immI src3, rFlagsReg cr) %{
11937   match(Set dst (SubL src1 (LShiftL src2 src3)));
11938 
11939   ins_cost(1.9 * INSN_COST);
11940   format %{ &quot;sub  $dst, $src1, $src2, LSL $src3&quot; %}
11941 
11942   ins_encode %{
11943     __ sub(as_Register($dst$$reg),
11944               as_Register($src1$$reg),
11945               as_Register($src2$$reg),
11946               Assembler::LSL,
11947               $src3$$constant &amp; 0x3f);
11948   %}
11949 
11950   ins_pipe(ialu_reg_reg_shift);
11951 %}
11952 
11953  
11954 // This pattern is automatically generated from aarch64_ad.m4
11955 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11956 
11957 // Shift Left followed by Shift Right.
11958 // This idiom is used by the compiler for the i2b bytecode etc.
11959 instruct sbfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11960 %{
11961   match(Set dst (RShiftL (LShiftL src lshift_count) rshift_count));
11962   ins_cost(INSN_COST * 2);
11963   format %{ &quot;sbfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11964   ins_encode %{
11965     int lshift = $lshift_count$$constant &amp; 63;
11966     int rshift = $rshift_count$$constant &amp; 63;
11967     int s = 63 - lshift;
11968     int r = (rshift - lshift) &amp; 63;
11969     __ sbfm(as_Register($dst$$reg),
11970             as_Register($src$$reg),
11971             r, s);
11972   %}
11973 
11974   ins_pipe(ialu_reg_shift);
11975 %}
11976 
11977 // This pattern is automatically generated from aarch64_ad.m4
11978 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11979 
11980 // Shift Left followed by Shift Right.
11981 // This idiom is used by the compiler for the i2b bytecode etc.
11982 instruct sbfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11983 %{
11984   match(Set dst (RShiftI (LShiftI src lshift_count) rshift_count));
11985   ins_cost(INSN_COST * 2);
11986   format %{ &quot;sbfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
11987   ins_encode %{
11988     int lshift = $lshift_count$$constant &amp; 31;
11989     int rshift = $rshift_count$$constant &amp; 31;
11990     int s = 31 - lshift;
11991     int r = (rshift - lshift) &amp; 31;
11992     __ sbfmw(as_Register($dst$$reg),
11993             as_Register($src$$reg),
11994             r, s);
11995   %}
11996 
11997   ins_pipe(ialu_reg_shift);
11998 %}
11999 
12000 // This pattern is automatically generated from aarch64_ad.m4
12001 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12002 
12003 // Shift Left followed by Shift Right.
12004 // This idiom is used by the compiler for the i2b bytecode etc.
12005 instruct ubfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
12006 %{
12007   match(Set dst (URShiftL (LShiftL src lshift_count) rshift_count));
12008   ins_cost(INSN_COST * 2);
12009   format %{ &quot;ubfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
12010   ins_encode %{
12011     int lshift = $lshift_count$$constant &amp; 63;
12012     int rshift = $rshift_count$$constant &amp; 63;
12013     int s = 63 - lshift;
12014     int r = (rshift - lshift) &amp; 63;
12015     __ ubfm(as_Register($dst$$reg),
12016             as_Register($src$$reg),
12017             r, s);
12018   %}
12019 
12020   ins_pipe(ialu_reg_shift);
12021 %}
12022 
12023 // This pattern is automatically generated from aarch64_ad.m4
12024 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12025 
12026 // Shift Left followed by Shift Right.
12027 // This idiom is used by the compiler for the i2b bytecode etc.
12028 instruct ubfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
12029 %{
12030   match(Set dst (URShiftI (LShiftI src lshift_count) rshift_count));
12031   ins_cost(INSN_COST * 2);
12032   format %{ &quot;ubfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
12033   ins_encode %{
12034     int lshift = $lshift_count$$constant &amp; 31;
12035     int rshift = $rshift_count$$constant &amp; 31;
12036     int s = 31 - lshift;
12037     int r = (rshift - lshift) &amp; 31;
12038     __ ubfmw(as_Register($dst$$reg),
12039             as_Register($src$$reg),
12040             r, s);
12041   %}
12042 
12043   ins_pipe(ialu_reg_shift);
12044 %}
12045 
12046 // Bitfield extract with shift &amp; mask
12047 
12048 // This pattern is automatically generated from aarch64_ad.m4
12049 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12050 instruct ubfxwI(iRegINoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
12051 %{
12052   match(Set dst (AndI (URShiftI src rshift) mask));
12053   // Make sure we are not going to exceed what ubfxw can do.
12054   predicate((exact_log2(n-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12055 
12056   ins_cost(INSN_COST);
12057   format %{ &quot;ubfxw $dst, $src, $rshift, $mask&quot; %}
12058   ins_encode %{
12059     int rshift = $rshift$$constant &amp; 31;
12060     intptr_t mask = $mask$$constant;
12061     int width = exact_log2(mask+1);
12062     __ ubfxw(as_Register($dst$$reg),
12063             as_Register($src$$reg), rshift, width);
12064   %}
12065   ins_pipe(ialu_reg_shift);
12066 %}
12067 
12068 // This pattern is automatically generated from aarch64_ad.m4
12069 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12070 instruct ubfxL(iRegLNoSp dst, iRegL src, immI rshift, immL_bitmask mask)
12071 %{
12072   match(Set dst (AndL (URShiftL src rshift) mask));
12073   // Make sure we are not going to exceed what ubfx can do.
12074   predicate((exact_log2_long(n-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12075 
12076   ins_cost(INSN_COST);
12077   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12078   ins_encode %{
12079     int rshift = $rshift$$constant &amp; 63;
12080     intptr_t mask = $mask$$constant;
12081     int width = exact_log2_long(mask+1);
12082     __ ubfx(as_Register($dst$$reg),
12083             as_Register($src$$reg), rshift, width);
12084   %}
12085   ins_pipe(ialu_reg_shift);
12086 %}
12087 
12088 
12089 // This pattern is automatically generated from aarch64_ad.m4
12090 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12091 
12092 // We can use ubfx when extending an And with a mask when we know mask
12093 // is positive.  We know that because immI_bitmask guarantees it.
12094 instruct ubfxIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
12095 %{
12096   match(Set dst (ConvI2L (AndI (URShiftI src rshift) mask)));
12097   // Make sure we are not going to exceed what ubfxw can do.
12098   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12099 
12100   ins_cost(INSN_COST * 2);
12101   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12102   ins_encode %{
12103     int rshift = $rshift$$constant &amp; 31;
12104     intptr_t mask = $mask$$constant;
12105     int width = exact_log2(mask+1);
12106     __ ubfx(as_Register($dst$$reg),
12107             as_Register($src$$reg), rshift, width);
12108   %}
12109   ins_pipe(ialu_reg_shift);
12110 %}
12111 
12112 
12113 // This pattern is automatically generated from aarch64_ad.m4
12114 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12115 
12116 // We can use ubfiz when masking by a positive number and then left shifting the result.
12117 // We know that the mask is positive because immI_bitmask guarantees it.
12118 instruct ubfizwI(iRegINoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12119 %{
12120   match(Set dst (LShiftI (AndI src mask) lshift));
12121   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12122 
12123   ins_cost(INSN_COST);
12124   format %{ &quot;ubfizw $dst, $src, $lshift, $mask&quot; %}
12125   ins_encode %{
12126     int lshift = $lshift$$constant &amp; 31;
12127     intptr_t mask = $mask$$constant;
12128     int width = exact_log2(mask+1);
12129     __ ubfizw(as_Register($dst$$reg),
12130           as_Register($src$$reg), lshift, width);
12131   %}
12132   ins_pipe(ialu_reg_shift);
12133 %}
12134 
12135 // This pattern is automatically generated from aarch64_ad.m4
12136 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12137 
12138 // We can use ubfiz when masking by a positive number and then left shifting the result.
12139 // We know that the mask is positive because immL_bitmask guarantees it.
12140 instruct ubfizL(iRegLNoSp dst, iRegL src, immI lshift, immL_bitmask mask)
12141 %{
12142   match(Set dst (LShiftL (AndL src mask) lshift));
12143   predicate((exact_log2_long(n-&gt;in(1)-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12144 
12145   ins_cost(INSN_COST);
12146   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12147   ins_encode %{
12148     int lshift = $lshift$$constant &amp; 63;
12149     intptr_t mask = $mask$$constant;
12150     int width = exact_log2_long(mask+1);
12151     __ ubfiz(as_Register($dst$$reg),
12152           as_Register($src$$reg), lshift, width);
12153   %}
12154   ins_pipe(ialu_reg_shift);
12155 %}
12156 
12157 
12158 // This pattern is automatically generated from aarch64_ad.m4
12159 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12160 
12161 // If there is a convert I to L block between and AndI and a LShiftL, we can also match ubfiz
12162 instruct ubfizIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12163 %{
12164   match(Set dst (LShiftL (ConvI2L (AndI src mask)) lshift));
12165   predicate((exact_log2(n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12166 
12167   ins_cost(INSN_COST);
12168   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12169   ins_encode %{
12170     int lshift = $lshift$$constant &amp; 63;
12171     intptr_t mask = $mask$$constant;
12172     int width = exact_log2(mask+1);
12173     __ ubfiz(as_Register($dst$$reg),
12174              as_Register($src$$reg), lshift, width);
12175   %}
12176   ins_pipe(ialu_reg_shift);
12177 %}
12178 
12179 
12180 // Rotations 
12181 // This pattern is automatically generated from aarch64_ad.m4
12182 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12183 instruct extrOrL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12184 %{
12185   match(Set dst (OrL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12186   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12187 
12188   ins_cost(INSN_COST);
12189   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12190 
12191   ins_encode %{
12192     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12193             $rshift$$constant &amp; 63);
12194   %}
12195   ins_pipe(ialu_reg_reg_extr);
12196 %}
12197 
12198 
12199 // This pattern is automatically generated from aarch64_ad.m4
12200 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12201 instruct extrOrI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12202 %{
12203   match(Set dst (OrI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12204   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12205 
12206   ins_cost(INSN_COST);
12207   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12208 
12209   ins_encode %{
12210     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12211             $rshift$$constant &amp; 31);
12212   %}
12213   ins_pipe(ialu_reg_reg_extr);
12214 %}
12215 
12216 
12217 // This pattern is automatically generated from aarch64_ad.m4
12218 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12219 instruct extrAddL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12220 %{
12221   match(Set dst (AddL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12222   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12223 
12224   ins_cost(INSN_COST);
12225   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12226 
12227   ins_encode %{
12228     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12229             $rshift$$constant &amp; 63);
12230   %}
12231   ins_pipe(ialu_reg_reg_extr);
12232 %}
12233 
12234 
12235 // This pattern is automatically generated from aarch64_ad.m4
12236 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12237 instruct extrAddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12238 %{
12239   match(Set dst (AddI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12240   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12241 
12242   ins_cost(INSN_COST);
12243   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12244 
12245   ins_encode %{
12246     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12247             $rshift$$constant &amp; 31);
12248   %}
12249   ins_pipe(ialu_reg_reg_extr);
12250 %}
12251 
12252 
12253 // This pattern is automatically generated from aarch64_ad.m4
12254 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12255 
12256 // rol expander
12257 instruct rolL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12258 %{
12259   effect(DEF dst, USE src, USE shift);
12260 
12261   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12262   ins_cost(INSN_COST * 3);
12263   ins_encode %{
12264     __ subw(rscratch1, zr, as_Register($shift$$reg));
12265     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12266             rscratch1);
12267     %}
12268   ins_pipe(ialu_reg_reg_vshift);
12269 %}
12270 
12271 // This pattern is automatically generated from aarch64_ad.m4
12272 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12273 
12274 // rol expander
12275 instruct rolI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12276 %{
12277   effect(DEF dst, USE src, USE shift);
12278 
12279   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12280   ins_cost(INSN_COST * 3);
12281   ins_encode %{
12282     __ subw(rscratch1, zr, as_Register($shift$$reg));
12283     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12284             rscratch1);
12285     %}
12286   ins_pipe(ialu_reg_reg_vshift);
12287 %}
12288 
12289 // This pattern is automatically generated from aarch64_ad.m4
12290 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12291 instruct rolL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12292 %{
12293   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c_64 shift))));
12294 
12295   expand %{
12296     rolL_rReg(dst, src, shift, cr);
12297   %}
12298 %}
12299 
12300 // This pattern is automatically generated from aarch64_ad.m4
12301 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12302 instruct rolL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12303 %{
12304   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c0 shift))));
12305 
12306   expand %{
12307     rolL_rReg(dst, src, shift, cr);
12308   %}
12309 %}
12310 
12311 // This pattern is automatically generated from aarch64_ad.m4
12312 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12313 instruct rolI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12314 %{
12315   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c_32 shift))));
12316 
12317   expand %{
12318     rolI_rReg(dst, src, shift, cr);
12319   %}
12320 %}
12321 
12322 // This pattern is automatically generated from aarch64_ad.m4
12323 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12324 instruct rolI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12325 %{
12326   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c0 shift))));
12327 
12328   expand %{
12329     rolI_rReg(dst, src, shift, cr);
12330   %}
12331 %}
12332 
12333 // This pattern is automatically generated from aarch64_ad.m4
12334 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12335 
12336 // ror expander
12337 instruct rorL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12338 %{
12339   effect(DEF dst, USE src, USE shift);
12340 
12341   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12342   ins_cost(INSN_COST);
12343   ins_encode %{
12344     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12345             as_Register($shift$$reg));
12346     %}
12347   ins_pipe(ialu_reg_reg_vshift);
12348 %}
12349 
12350 // This pattern is automatically generated from aarch64_ad.m4
12351 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12352 
12353 // ror expander
12354 instruct rorI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12355 %{
12356   effect(DEF dst, USE src, USE shift);
12357 
12358   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12359   ins_cost(INSN_COST);
12360   ins_encode %{
12361     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12362             as_Register($shift$$reg));
12363     %}
12364   ins_pipe(ialu_reg_reg_vshift);
12365 %}
12366 
12367 // This pattern is automatically generated from aarch64_ad.m4
12368 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12369 instruct rorL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12370 %{
12371   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c_64 shift))));
12372 
12373   expand %{
12374     rorL_rReg(dst, src, shift, cr);
12375   %}
12376 %}
12377 
12378 // This pattern is automatically generated from aarch64_ad.m4
12379 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12380 instruct rorL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12381 %{
12382   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c0 shift))));
12383 
12384   expand %{
12385     rorL_rReg(dst, src, shift, cr);
12386   %}
12387 %}
12388 
12389 // This pattern is automatically generated from aarch64_ad.m4
12390 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12391 instruct rorI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12392 %{
12393   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c_32 shift))));
12394 
12395   expand %{
12396     rorI_rReg(dst, src, shift, cr);
12397   %}
12398 %}
12399 
12400 // This pattern is automatically generated from aarch64_ad.m4
12401 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12402 instruct rorI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12403 %{
12404   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c0 shift))));
12405 
12406   expand %{
12407     rorI_rReg(dst, src, shift, cr);
12408   %}
12409 %}
12410 
12411 
12412 // Add/subtract (extended)
12413 
12414 // This pattern is automatically generated from aarch64_ad.m4
12415 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12416 instruct AddExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12417 %{
12418   match(Set dst (AddL src1 (ConvI2L src2)));
12419   ins_cost(INSN_COST);
12420   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12421 
12422    ins_encode %{
12423      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12424             as_Register($src2$$reg), ext::sxtw);
12425    %}
12426   ins_pipe(ialu_reg_reg);
12427 %}
12428 
12429 // This pattern is automatically generated from aarch64_ad.m4
12430 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12431 instruct SubExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12432 %{
12433   match(Set dst (SubL src1 (ConvI2L src2)));
12434   ins_cost(INSN_COST);
12435   format %{ &quot;sub  $dst, $src1, $src2, sxtw&quot; %}
12436 
12437    ins_encode %{
12438      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12439             as_Register($src2$$reg), ext::sxtw);
12440    %}
12441   ins_pipe(ialu_reg_reg);
12442 %}
12443 
12444 // This pattern is automatically generated from aarch64_ad.m4
12445 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12446 instruct AddExtI_sxth(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_16 lshift, immI_16 rshift, rFlagsReg cr)
12447 %{
12448   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12449   ins_cost(INSN_COST);
12450   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12451 
12452    ins_encode %{
12453      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12454             as_Register($src2$$reg), ext::sxth);
12455    %}
12456   ins_pipe(ialu_reg_reg);
12457 %}
12458 
12459 // This pattern is automatically generated from aarch64_ad.m4
12460 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12461 instruct AddExtI_sxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12462 %{
12463   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12464   ins_cost(INSN_COST);
12465   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12466 
12467    ins_encode %{
12468      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12469             as_Register($src2$$reg), ext::sxtb);
12470    %}
12471   ins_pipe(ialu_reg_reg);
12472 %}
12473 
12474 // This pattern is automatically generated from aarch64_ad.m4
12475 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12476 instruct AddExtI_uxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12477 %{
12478   match(Set dst (AddI src1 (URShiftI (LShiftI src2 lshift) rshift)));
12479   ins_cost(INSN_COST);
12480   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12481 
12482    ins_encode %{
12483      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12484             as_Register($src2$$reg), ext::uxtb);
12485    %}
12486   ins_pipe(ialu_reg_reg);
12487 %}
12488 
12489 // This pattern is automatically generated from aarch64_ad.m4
12490 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12491 instruct AddExtL_sxth(iRegLNoSp dst, iRegL src1, iRegL src2, immI_48 lshift, immI_48 rshift, rFlagsReg cr)
12492 %{
12493   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12494   ins_cost(INSN_COST);
12495   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12496 
12497    ins_encode %{
12498      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12499             as_Register($src2$$reg), ext::sxth);
12500    %}
12501   ins_pipe(ialu_reg_reg);
12502 %}
12503 
12504 // This pattern is automatically generated from aarch64_ad.m4
12505 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12506 instruct AddExtL_sxtw(iRegLNoSp dst, iRegL src1, iRegL src2, immI_32 lshift, immI_32 rshift, rFlagsReg cr)
12507 %{
12508   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12509   ins_cost(INSN_COST);
12510   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12511 
12512    ins_encode %{
12513      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12514             as_Register($src2$$reg), ext::sxtw);
12515    %}
12516   ins_pipe(ialu_reg_reg);
12517 %}
12518 
12519 // This pattern is automatically generated from aarch64_ad.m4
12520 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12521 instruct AddExtL_sxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12522 %{
12523   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12524   ins_cost(INSN_COST);
12525   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12526 
12527    ins_encode %{
12528      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12529             as_Register($src2$$reg), ext::sxtb);
12530    %}
12531   ins_pipe(ialu_reg_reg);
12532 %}
12533 
12534 // This pattern is automatically generated from aarch64_ad.m4
12535 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12536 instruct AddExtL_uxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12537 %{
12538   match(Set dst (AddL src1 (URShiftL (LShiftL src2 lshift) rshift)));
12539   ins_cost(INSN_COST);
12540   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12541 
12542    ins_encode %{
12543      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12544             as_Register($src2$$reg), ext::uxtb);
12545    %}
12546   ins_pipe(ialu_reg_reg);
12547 %}
12548 
12549 // This pattern is automatically generated from aarch64_ad.m4
12550 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12551 instruct AddExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12552 %{
12553   match(Set dst (AddI src1 (AndI src2 mask)));
12554   ins_cost(INSN_COST);
12555   format %{ &quot;addw  $dst, $src1, $src2, uxtb&quot; %}
12556 
12557    ins_encode %{
12558      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12559             as_Register($src2$$reg), ext::uxtb);
12560    %}
12561   ins_pipe(ialu_reg_reg);
12562 %}
12563 
12564 // This pattern is automatically generated from aarch64_ad.m4
12565 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12566 instruct AddExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12567 %{
12568   match(Set dst (AddI src1 (AndI src2 mask)));
12569   ins_cost(INSN_COST);
12570   format %{ &quot;addw  $dst, $src1, $src2, uxth&quot; %}
12571 
12572    ins_encode %{
12573      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12574             as_Register($src2$$reg), ext::uxth);
12575    %}
12576   ins_pipe(ialu_reg_reg);
12577 %}
12578 
12579 // This pattern is automatically generated from aarch64_ad.m4
12580 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12581 instruct AddExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12582 %{
12583   match(Set dst (AddL src1 (AndL src2 mask)));
12584   ins_cost(INSN_COST);
12585   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12586 
12587    ins_encode %{
12588      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12589             as_Register($src2$$reg), ext::uxtb);
12590    %}
12591   ins_pipe(ialu_reg_reg);
12592 %}
12593 
12594 // This pattern is automatically generated from aarch64_ad.m4
12595 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12596 instruct AddExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12597 %{
12598   match(Set dst (AddL src1 (AndL src2 mask)));
12599   ins_cost(INSN_COST);
12600   format %{ &quot;add  $dst, $src1, $src2, uxth&quot; %}
12601 
12602    ins_encode %{
12603      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12604             as_Register($src2$$reg), ext::uxth);
12605    %}
12606   ins_pipe(ialu_reg_reg);
12607 %}
12608 
12609 // This pattern is automatically generated from aarch64_ad.m4
12610 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12611 instruct AddExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12612 %{
12613   match(Set dst (AddL src1 (AndL src2 mask)));
12614   ins_cost(INSN_COST);
12615   format %{ &quot;add  $dst, $src1, $src2, uxtw&quot; %}
12616 
12617    ins_encode %{
12618      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12619             as_Register($src2$$reg), ext::uxtw);
12620    %}
12621   ins_pipe(ialu_reg_reg);
12622 %}
12623 
12624 // This pattern is automatically generated from aarch64_ad.m4
12625 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12626 instruct SubExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12627 %{
12628   match(Set dst (SubI src1 (AndI src2 mask)));
12629   ins_cost(INSN_COST);
12630   format %{ &quot;subw  $dst, $src1, $src2, uxtb&quot; %}
12631 
12632    ins_encode %{
12633      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12634             as_Register($src2$$reg), ext::uxtb);
12635    %}
12636   ins_pipe(ialu_reg_reg);
12637 %}
12638 
12639 // This pattern is automatically generated from aarch64_ad.m4
12640 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12641 instruct SubExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12642 %{
12643   match(Set dst (SubI src1 (AndI src2 mask)));
12644   ins_cost(INSN_COST);
12645   format %{ &quot;subw  $dst, $src1, $src2, uxth&quot; %}
12646 
12647    ins_encode %{
12648      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12649             as_Register($src2$$reg), ext::uxth);
12650    %}
12651   ins_pipe(ialu_reg_reg);
12652 %}
12653 
12654 // This pattern is automatically generated from aarch64_ad.m4
12655 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12656 instruct SubExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12657 %{
12658   match(Set dst (SubL src1 (AndL src2 mask)));
12659   ins_cost(INSN_COST);
12660   format %{ &quot;sub  $dst, $src1, $src2, uxtb&quot; %}
12661 
12662    ins_encode %{
12663      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12664             as_Register($src2$$reg), ext::uxtb);
12665    %}
12666   ins_pipe(ialu_reg_reg);
12667 %}
12668 
12669 // This pattern is automatically generated from aarch64_ad.m4
12670 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12671 instruct SubExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12672 %{
12673   match(Set dst (SubL src1 (AndL src2 mask)));
12674   ins_cost(INSN_COST);
12675   format %{ &quot;sub  $dst, $src1, $src2, uxth&quot; %}
12676 
12677    ins_encode %{
12678      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12679             as_Register($src2$$reg), ext::uxth);
12680    %}
12681   ins_pipe(ialu_reg_reg);
12682 %}
12683 
12684 // This pattern is automatically generated from aarch64_ad.m4
12685 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12686 instruct SubExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12687 %{
12688   match(Set dst (SubL src1 (AndL src2 mask)));
12689   ins_cost(INSN_COST);
12690   format %{ &quot;sub  $dst, $src1, $src2, uxtw&quot; %}
12691 
12692    ins_encode %{
12693      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12694             as_Register($src2$$reg), ext::uxtw);
12695    %}
12696   ins_pipe(ialu_reg_reg);
12697 %}
12698 
12699 
12700 // This pattern is automatically generated from aarch64_ad.m4
12701 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12702 instruct AddExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12703 %{
12704   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12705   ins_cost(1.9 * INSN_COST);
12706   format %{ &quot;add  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12707 
12708    ins_encode %{
12709      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12710             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12711    %}
12712   ins_pipe(ialu_reg_reg_shift);
12713 %}
12714 
12715 // This pattern is automatically generated from aarch64_ad.m4
12716 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12717 instruct AddExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12718 %{
12719   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12720   ins_cost(1.9 * INSN_COST);
12721   format %{ &quot;add  $dst, $src1, $src2, sxth #lshift2&quot; %}
12722 
12723    ins_encode %{
12724      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12725             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12726    %}
12727   ins_pipe(ialu_reg_reg_shift);
12728 %}
12729 
12730 // This pattern is automatically generated from aarch64_ad.m4
12731 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12732 instruct AddExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12733 %{
12734   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12735   ins_cost(1.9 * INSN_COST);
12736   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12737 
12738    ins_encode %{
12739      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12740             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12741    %}
12742   ins_pipe(ialu_reg_reg_shift);
12743 %}
12744 
12745 // This pattern is automatically generated from aarch64_ad.m4
12746 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12747 instruct SubExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12748 %{
12749   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12750   ins_cost(1.9 * INSN_COST);
12751   format %{ &quot;sub  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12752 
12753    ins_encode %{
12754      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12755             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12756    %}
12757   ins_pipe(ialu_reg_reg_shift);
12758 %}
12759 
12760 // This pattern is automatically generated from aarch64_ad.m4
12761 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12762 instruct SubExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12763 %{
12764   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12765   ins_cost(1.9 * INSN_COST);
12766   format %{ &quot;sub  $dst, $src1, $src2, sxth #lshift2&quot; %}
12767 
12768    ins_encode %{
12769      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12770             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12771    %}
12772   ins_pipe(ialu_reg_reg_shift);
12773 %}
12774 
12775 // This pattern is automatically generated from aarch64_ad.m4
12776 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12777 instruct SubExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12778 %{
12779   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12780   ins_cost(1.9 * INSN_COST);
12781   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12782 
12783    ins_encode %{
12784      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12785             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12786    %}
12787   ins_pipe(ialu_reg_reg_shift);
12788 %}
12789 
12790 // This pattern is automatically generated from aarch64_ad.m4
12791 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12792 instruct AddExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12793 %{
12794   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12795   ins_cost(1.9 * INSN_COST);
12796   format %{ &quot;addw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12797 
12798    ins_encode %{
12799      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12800             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12801    %}
12802   ins_pipe(ialu_reg_reg_shift);
12803 %}
12804 
12805 // This pattern is automatically generated from aarch64_ad.m4
12806 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12807 instruct AddExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12808 %{
12809   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12810   ins_cost(1.9 * INSN_COST);
12811   format %{ &quot;addw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12812 
12813    ins_encode %{
12814      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12815             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12816    %}
12817   ins_pipe(ialu_reg_reg_shift);
12818 %}
12819 
12820 // This pattern is automatically generated from aarch64_ad.m4
12821 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12822 instruct SubExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12823 %{
12824   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12825   ins_cost(1.9 * INSN_COST);
12826   format %{ &quot;subw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12827 
12828    ins_encode %{
12829      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12830             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12831    %}
12832   ins_pipe(ialu_reg_reg_shift);
12833 %}
12834 
12835 // This pattern is automatically generated from aarch64_ad.m4
12836 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12837 instruct SubExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12838 %{
12839   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12840   ins_cost(1.9 * INSN_COST);
12841   format %{ &quot;subw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12842 
12843    ins_encode %{
12844      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12845             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12846    %}
12847   ins_pipe(ialu_reg_reg_shift);
12848 %}
12849 
12850 // This pattern is automatically generated from aarch64_ad.m4
12851 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12852 instruct AddExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12853 %{
12854   match(Set dst (AddL src1 (LShiftL (ConvI2L src2) lshift)));
12855   ins_cost(1.9 * INSN_COST);
12856   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift&quot; %}
12857 
12858    ins_encode %{
12859      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12860             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12861    %}
12862   ins_pipe(ialu_reg_reg_shift);
12863 %}
12864 
12865 // This pattern is automatically generated from aarch64_ad.m4
12866 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12867 instruct SubExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12868 %{
12869   match(Set dst (SubL src1 (LShiftL (ConvI2L src2) lshift)));
12870   ins_cost(1.9 * INSN_COST);
12871   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift&quot; %}
12872 
12873    ins_encode %{
12874      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12875             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12876    %}
12877   ins_pipe(ialu_reg_reg_shift);
12878 %}
12879 
12880 // This pattern is automatically generated from aarch64_ad.m4
12881 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12882 instruct AddExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12883 %{
12884   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12885   ins_cost(1.9 * INSN_COST);
12886   format %{ &quot;add  $dst, $src1, $src2, uxtb #lshift&quot; %}
12887 
12888    ins_encode %{
12889      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12890             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12891    %}
12892   ins_pipe(ialu_reg_reg_shift);
12893 %}
12894 
12895 // This pattern is automatically generated from aarch64_ad.m4
12896 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12897 instruct AddExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12898 %{
12899   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12900   ins_cost(1.9 * INSN_COST);
12901   format %{ &quot;add  $dst, $src1, $src2, uxth #lshift&quot; %}
12902 
12903    ins_encode %{
12904      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12905             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12906    %}
12907   ins_pipe(ialu_reg_reg_shift);
12908 %}
12909 
12910 // This pattern is automatically generated from aarch64_ad.m4
12911 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12912 instruct AddExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12913 %{
12914   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12915   ins_cost(1.9 * INSN_COST);
12916   format %{ &quot;add  $dst, $src1, $src2, uxtw #lshift&quot; %}
12917 
12918    ins_encode %{
12919      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12920             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12921    %}
12922   ins_pipe(ialu_reg_reg_shift);
12923 %}
12924 
12925 // This pattern is automatically generated from aarch64_ad.m4
12926 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12927 instruct SubExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12928 %{
12929   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12930   ins_cost(1.9 * INSN_COST);
12931   format %{ &quot;sub  $dst, $src1, $src2, uxtb #lshift&quot; %}
12932 
12933    ins_encode %{
12934      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12935             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12936    %}
12937   ins_pipe(ialu_reg_reg_shift);
12938 %}
12939 
12940 // This pattern is automatically generated from aarch64_ad.m4
12941 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12942 instruct SubExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12943 %{
12944   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12945   ins_cost(1.9 * INSN_COST);
12946   format %{ &quot;sub  $dst, $src1, $src2, uxth #lshift&quot; %}
12947 
12948    ins_encode %{
12949      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12950             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12951    %}
12952   ins_pipe(ialu_reg_reg_shift);
12953 %}
12954 
12955 // This pattern is automatically generated from aarch64_ad.m4
12956 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12957 instruct SubExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12958 %{
12959   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12960   ins_cost(1.9 * INSN_COST);
12961   format %{ &quot;sub  $dst, $src1, $src2, uxtw #lshift&quot; %}
12962 
12963    ins_encode %{
12964      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12965             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12966    %}
12967   ins_pipe(ialu_reg_reg_shift);
12968 %}
12969 
12970 // This pattern is automatically generated from aarch64_ad.m4
12971 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12972 instruct AddExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12973 %{
12974   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12975   ins_cost(1.9 * INSN_COST);
12976   format %{ &quot;addw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12977 
12978    ins_encode %{
12979      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12980             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12981    %}
12982   ins_pipe(ialu_reg_reg_shift);
12983 %}
12984 
12985 // This pattern is automatically generated from aarch64_ad.m4
12986 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12987 instruct AddExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12988 %{
12989   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12990   ins_cost(1.9 * INSN_COST);
12991   format %{ &quot;addw  $dst, $src1, $src2, uxth #lshift&quot; %}
12992 
12993    ins_encode %{
12994      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12995             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12996    %}
12997   ins_pipe(ialu_reg_reg_shift);
12998 %}
12999 
13000 // This pattern is automatically generated from aarch64_ad.m4
13001 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
13002 instruct SubExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
13003 %{
13004   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
13005   ins_cost(1.9 * INSN_COST);
13006   format %{ &quot;subw  $dst, $src1, $src2, uxtb #lshift&quot; %}
13007 
13008    ins_encode %{
13009      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
13010             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
13011    %}
13012   ins_pipe(ialu_reg_reg_shift);
13013 %}
13014 
13015 // This pattern is automatically generated from aarch64_ad.m4
13016 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
13017 instruct SubExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
13018 %{
13019   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
13020   ins_cost(1.9 * INSN_COST);
13021   format %{ &quot;subw  $dst, $src1, $src2, uxth #lshift&quot; %}
13022 
13023    ins_encode %{
13024      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
13025             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
13026    %}
13027   ins_pipe(ialu_reg_reg_shift);
13028 %}
13029 
13030 
13031 
13032 // END This section of the file is automatically generated. Do not edit --------------
13033 
13034 
13035 // ============================================================================
13036 // Floating Point Arithmetic Instructions
13037 
13038 instruct addF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13039   match(Set dst (AddF src1 src2));
13040 
13041   ins_cost(INSN_COST * 5);
13042   format %{ &quot;fadds   $dst, $src1, $src2&quot; %}
13043 
13044   ins_encode %{
13045     __ fadds(as_FloatRegister($dst$$reg),
13046              as_FloatRegister($src1$$reg),
13047              as_FloatRegister($src2$$reg));
13048   %}
13049 
13050   ins_pipe(fp_dop_reg_reg_s);
13051 %}
13052 
13053 instruct addD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13054   match(Set dst (AddD src1 src2));
13055 
13056   ins_cost(INSN_COST * 5);
13057   format %{ &quot;faddd   $dst, $src1, $src2&quot; %}
13058 
13059   ins_encode %{
13060     __ faddd(as_FloatRegister($dst$$reg),
13061              as_FloatRegister($src1$$reg),
13062              as_FloatRegister($src2$$reg));
13063   %}
13064 
13065   ins_pipe(fp_dop_reg_reg_d);
13066 %}
13067 
13068 instruct subF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13069   match(Set dst (SubF src1 src2));
13070 
13071   ins_cost(INSN_COST * 5);
13072   format %{ &quot;fsubs   $dst, $src1, $src2&quot; %}
13073 
13074   ins_encode %{
13075     __ fsubs(as_FloatRegister($dst$$reg),
13076              as_FloatRegister($src1$$reg),
13077              as_FloatRegister($src2$$reg));
13078   %}
13079 
13080   ins_pipe(fp_dop_reg_reg_s);
13081 %}
13082 
13083 instruct subD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13084   match(Set dst (SubD src1 src2));
13085 
13086   ins_cost(INSN_COST * 5);
13087   format %{ &quot;fsubd   $dst, $src1, $src2&quot; %}
13088 
13089   ins_encode %{
13090     __ fsubd(as_FloatRegister($dst$$reg),
13091              as_FloatRegister($src1$$reg),
13092              as_FloatRegister($src2$$reg));
13093   %}
13094 
13095   ins_pipe(fp_dop_reg_reg_d);
13096 %}
13097 
13098 instruct mulF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13099   match(Set dst (MulF src1 src2));
13100 
13101   ins_cost(INSN_COST * 6);
13102   format %{ &quot;fmuls   $dst, $src1, $src2&quot; %}
13103 
13104   ins_encode %{
13105     __ fmuls(as_FloatRegister($dst$$reg),
13106              as_FloatRegister($src1$$reg),
13107              as_FloatRegister($src2$$reg));
13108   %}
13109 
13110   ins_pipe(fp_dop_reg_reg_s);
13111 %}
13112 
13113 instruct mulD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13114   match(Set dst (MulD src1 src2));
13115 
13116   ins_cost(INSN_COST * 6);
13117   format %{ &quot;fmuld   $dst, $src1, $src2&quot; %}
13118 
13119   ins_encode %{
13120     __ fmuld(as_FloatRegister($dst$$reg),
13121              as_FloatRegister($src1$$reg),
13122              as_FloatRegister($src2$$reg));
13123   %}
13124 
13125   ins_pipe(fp_dop_reg_reg_d);
13126 %}
13127 
13128 // src1 * src2 + src3
13129 instruct maddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
13130   predicate(UseFMA);
13131   match(Set dst (FmaF src3 (Binary src1 src2)));
13132 
13133   format %{ &quot;fmadds   $dst, $src1, $src2, $src3&quot; %}
13134 
13135   ins_encode %{
13136     __ fmadds(as_FloatRegister($dst$$reg),
13137              as_FloatRegister($src1$$reg),
13138              as_FloatRegister($src2$$reg),
13139              as_FloatRegister($src3$$reg));
13140   %}
13141 
13142   ins_pipe(pipe_class_default);
13143 %}
13144 
13145 // src1 * src2 + src3
13146 instruct maddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13147   predicate(UseFMA);
13148   match(Set dst (FmaD src3 (Binary src1 src2)));
13149 
13150   format %{ &quot;fmaddd   $dst, $src1, $src2, $src3&quot; %}
13151 
13152   ins_encode %{
13153     __ fmaddd(as_FloatRegister($dst$$reg),
13154              as_FloatRegister($src1$$reg),
13155              as_FloatRegister($src2$$reg),
13156              as_FloatRegister($src3$$reg));
13157   %}
13158 
13159   ins_pipe(pipe_class_default);
13160 %}
13161 
13162 // -src1 * src2 + src3
13163 instruct msubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
13164   predicate(UseFMA);
13165   match(Set dst (FmaF src3 (Binary (NegF src1) src2)));
13166   match(Set dst (FmaF src3 (Binary src1 (NegF src2))));
13167 
13168   format %{ &quot;fmsubs   $dst, $src1, $src2, $src3&quot; %}
13169 
13170   ins_encode %{
13171     __ fmsubs(as_FloatRegister($dst$$reg),
13172               as_FloatRegister($src1$$reg),
13173               as_FloatRegister($src2$$reg),
13174               as_FloatRegister($src3$$reg));
13175   %}
13176 
13177   ins_pipe(pipe_class_default);
13178 %}
13179 
13180 // -src1 * src2 + src3
13181 instruct msubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13182   predicate(UseFMA);
13183   match(Set dst (FmaD src3 (Binary (NegD src1) src2)));
13184   match(Set dst (FmaD src3 (Binary src1 (NegD src2))));
13185 
13186   format %{ &quot;fmsubd   $dst, $src1, $src2, $src3&quot; %}
13187 
13188   ins_encode %{
13189     __ fmsubd(as_FloatRegister($dst$$reg),
13190               as_FloatRegister($src1$$reg),
13191               as_FloatRegister($src2$$reg),
13192               as_FloatRegister($src3$$reg));
13193   %}
13194 
13195   ins_pipe(pipe_class_default);
13196 %}
13197 
13198 // -src1 * src2 - src3
13199 instruct mnaddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
13200   predicate(UseFMA);
13201   match(Set dst (FmaF (NegF src3) (Binary (NegF src1) src2)));
13202   match(Set dst (FmaF (NegF src3) (Binary src1 (NegF src2))));
13203 
13204   format %{ &quot;fnmadds  $dst, $src1, $src2, $src3&quot; %}
13205 
13206   ins_encode %{
13207     __ fnmadds(as_FloatRegister($dst$$reg),
13208                as_FloatRegister($src1$$reg),
13209                as_FloatRegister($src2$$reg),
13210                as_FloatRegister($src3$$reg));
13211   %}
13212 
13213   ins_pipe(pipe_class_default);
13214 %}
13215 
13216 // -src1 * src2 - src3
13217 instruct mnaddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13218   predicate(UseFMA);
13219   match(Set dst (FmaD (NegD src3) (Binary (NegD src1) src2)));
13220   match(Set dst (FmaD (NegD src3) (Binary src1 (NegD src2))));
13221 
13222   format %{ &quot;fnmaddd   $dst, $src1, $src2, $src3&quot; %}
13223 
13224   ins_encode %{
13225     __ fnmaddd(as_FloatRegister($dst$$reg),
13226                as_FloatRegister($src1$$reg),
13227                as_FloatRegister($src2$$reg),
13228                as_FloatRegister($src3$$reg));
13229   %}
13230 
13231   ins_pipe(pipe_class_default);
13232 %}
13233 
13234 // src1 * src2 - src3
13235 instruct mnsubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3, immF0 zero) %{
13236   predicate(UseFMA);
13237   match(Set dst (FmaF (NegF src3) (Binary src1 src2)));
13238 
13239   format %{ &quot;fnmsubs  $dst, $src1, $src2, $src3&quot; %}
13240 
13241   ins_encode %{
13242     __ fnmsubs(as_FloatRegister($dst$$reg),
13243                as_FloatRegister($src1$$reg),
13244                as_FloatRegister($src2$$reg),
13245                as_FloatRegister($src3$$reg));
13246   %}
13247 
13248   ins_pipe(pipe_class_default);
13249 %}
13250 
13251 // src1 * src2 - src3
13252 instruct mnsubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3, immD0 zero) %{
13253   predicate(UseFMA);
13254   match(Set dst (FmaD (NegD src3) (Binary src1 src2)));
13255 
13256   format %{ &quot;fnmsubd   $dst, $src1, $src2, $src3&quot; %}
13257 
13258   ins_encode %{
13259   // n.b. insn name should be fnmsubd
13260     __ fnmsub(as_FloatRegister($dst$$reg),
13261               as_FloatRegister($src1$$reg),
13262               as_FloatRegister($src2$$reg),
13263               as_FloatRegister($src3$$reg));
13264   %}
13265 
13266   ins_pipe(pipe_class_default);
13267 %}
13268 
13269 
13270 // Math.max(FF)F
13271 instruct maxF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13272   match(Set dst (MaxF src1 src2));
13273 
13274   format %{ &quot;fmaxs   $dst, $src1, $src2&quot; %}
13275   ins_encode %{
13276     __ fmaxs(as_FloatRegister($dst$$reg),
13277              as_FloatRegister($src1$$reg),
13278              as_FloatRegister($src2$$reg));
13279   %}
13280 
13281   ins_pipe(fp_dop_reg_reg_s);
13282 %}
13283 
13284 // Math.min(FF)F
13285 instruct minF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13286   match(Set dst (MinF src1 src2));
13287 
13288   format %{ &quot;fmins   $dst, $src1, $src2&quot; %}
13289   ins_encode %{
13290     __ fmins(as_FloatRegister($dst$$reg),
13291              as_FloatRegister($src1$$reg),
13292              as_FloatRegister($src2$$reg));
13293   %}
13294 
13295   ins_pipe(fp_dop_reg_reg_s);
13296 %}
13297 
13298 // Math.max(DD)D
13299 instruct maxD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13300   match(Set dst (MaxD src1 src2));
13301 
13302   format %{ &quot;fmaxd   $dst, $src1, $src2&quot; %}
13303   ins_encode %{
13304     __ fmaxd(as_FloatRegister($dst$$reg),
13305              as_FloatRegister($src1$$reg),
13306              as_FloatRegister($src2$$reg));
13307   %}
13308 
13309   ins_pipe(fp_dop_reg_reg_d);
13310 %}
13311 
13312 // Math.min(DD)D
13313 instruct minD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13314   match(Set dst (MinD src1 src2));
13315 
13316   format %{ &quot;fmind   $dst, $src1, $src2&quot; %}
13317   ins_encode %{
13318     __ fmind(as_FloatRegister($dst$$reg),
13319              as_FloatRegister($src1$$reg),
13320              as_FloatRegister($src2$$reg));
13321   %}
13322 
13323   ins_pipe(fp_dop_reg_reg_d);
13324 %}
13325 
13326 
13327 instruct divF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13328   match(Set dst (DivF src1  src2));
13329 
13330   ins_cost(INSN_COST * 18);
13331   format %{ &quot;fdivs   $dst, $src1, $src2&quot; %}
13332 
13333   ins_encode %{
13334     __ fdivs(as_FloatRegister($dst$$reg),
13335              as_FloatRegister($src1$$reg),
13336              as_FloatRegister($src2$$reg));
13337   %}
13338 
13339   ins_pipe(fp_div_s);
13340 %}
13341 
13342 instruct divD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13343   match(Set dst (DivD src1  src2));
13344 
13345   ins_cost(INSN_COST * 32);
13346   format %{ &quot;fdivd   $dst, $src1, $src2&quot; %}
13347 
13348   ins_encode %{
13349     __ fdivd(as_FloatRegister($dst$$reg),
13350              as_FloatRegister($src1$$reg),
13351              as_FloatRegister($src2$$reg));
13352   %}
13353 
13354   ins_pipe(fp_div_d);
13355 %}
13356 
13357 instruct negF_reg_reg(vRegF dst, vRegF src) %{
13358   match(Set dst (NegF src));
13359 
13360   ins_cost(INSN_COST * 3);
13361   format %{ &quot;fneg   $dst, $src&quot; %}
13362 
13363   ins_encode %{
13364     __ fnegs(as_FloatRegister($dst$$reg),
13365              as_FloatRegister($src$$reg));
13366   %}
13367 
13368   ins_pipe(fp_uop_s);
13369 %}
13370 
13371 instruct negD_reg_reg(vRegD dst, vRegD src) %{
13372   match(Set dst (NegD src));
13373 
13374   ins_cost(INSN_COST * 3);
13375   format %{ &quot;fnegd   $dst, $src&quot; %}
13376 
13377   ins_encode %{
13378     __ fnegd(as_FloatRegister($dst$$reg),
13379              as_FloatRegister($src$$reg));
13380   %}
13381 
13382   ins_pipe(fp_uop_d);
13383 %}
13384 
13385 instruct absI_reg(iRegINoSp dst, iRegIorL2I src, rFlagsReg cr)
13386 %{
13387   match(Set dst (AbsI src));
13388 
13389   effect(KILL cr);
13390   ins_cost(INSN_COST * 2);
13391   format %{ &quot;cmpw  $src, zr\n\t&quot;
13392             &quot;cnegw $dst, $src, Assembler::LT\t# int abs&quot;
13393   %}
13394 
13395   ins_encode %{
13396     __ cmpw(as_Register($src$$reg), zr);
13397     __ cnegw(as_Register($dst$$reg), as_Register($src$$reg), Assembler::LT);
13398   %}
13399   ins_pipe(pipe_class_default);
13400 %}
13401 
13402 instruct absL_reg(iRegLNoSp dst, iRegL src, rFlagsReg cr)
13403 %{
13404   match(Set dst (AbsL src));
13405 
13406   effect(KILL cr);
13407   ins_cost(INSN_COST * 2);
13408   format %{ &quot;cmp  $src, zr\n\t&quot;
13409             &quot;cneg $dst, $src, Assembler::LT\t# long abs&quot;
13410   %}
13411 
13412   ins_encode %{
13413     __ cmp(as_Register($src$$reg), zr);
13414     __ cneg(as_Register($dst$$reg), as_Register($src$$reg), Assembler::LT);
13415   %}
13416   ins_pipe(pipe_class_default);
13417 %}
13418 
13419 instruct absF_reg(vRegF dst, vRegF src) %{
13420   match(Set dst (AbsF src));
13421 
13422   ins_cost(INSN_COST * 3);
13423   format %{ &quot;fabss   $dst, $src&quot; %}
13424   ins_encode %{
13425     __ fabss(as_FloatRegister($dst$$reg),
13426              as_FloatRegister($src$$reg));
13427   %}
13428 
13429   ins_pipe(fp_uop_s);
13430 %}
13431 
13432 instruct absD_reg(vRegD dst, vRegD src) %{
13433   match(Set dst (AbsD src));
13434 
13435   ins_cost(INSN_COST * 3);
13436   format %{ &quot;fabsd   $dst, $src&quot; %}
13437   ins_encode %{
13438     __ fabsd(as_FloatRegister($dst$$reg),
13439              as_FloatRegister($src$$reg));
13440   %}
13441 
13442   ins_pipe(fp_uop_d);
13443 %}
13444 
13445 instruct sqrtD_reg(vRegD dst, vRegD src) %{
13446   match(Set dst (SqrtD src));
13447 
13448   ins_cost(INSN_COST * 50);
13449   format %{ &quot;fsqrtd  $dst, $src&quot; %}
13450   ins_encode %{
13451     __ fsqrtd(as_FloatRegister($dst$$reg),
13452              as_FloatRegister($src$$reg));
13453   %}
13454 
13455   ins_pipe(fp_div_s);
13456 %}
13457 
13458 instruct sqrtF_reg(vRegF dst, vRegF src) %{
13459   match(Set dst (SqrtF src));
13460 
13461   ins_cost(INSN_COST * 50);
13462   format %{ &quot;fsqrts  $dst, $src&quot; %}
13463   ins_encode %{
13464     __ fsqrts(as_FloatRegister($dst$$reg),
13465              as_FloatRegister($src$$reg));
13466   %}
13467 
13468   ins_pipe(fp_div_d);
13469 %}
13470 
13471 // Math.rint, floor, ceil
13472 instruct roundD_reg(vRegD dst, vRegD src, immI rmode) %{
13473   match(Set dst (RoundDoubleMode src rmode));
13474   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
13475   ins_encode %{
13476     switch ($rmode$$constant) {
13477       case RoundDoubleModeNode::rmode_rint:
13478         __ frintnd(as_FloatRegister($dst$$reg),
13479                    as_FloatRegister($src$$reg));
13480         break;
13481       case RoundDoubleModeNode::rmode_floor:
13482         __ frintmd(as_FloatRegister($dst$$reg),
13483                    as_FloatRegister($src$$reg));
13484         break;
13485       case RoundDoubleModeNode::rmode_ceil:
13486         __ frintpd(as_FloatRegister($dst$$reg),
13487                    as_FloatRegister($src$$reg));
13488         break;
13489     }
13490   %}
13491   ins_pipe(fp_uop_d);
13492 %}
13493 
13494 // ============================================================================
13495 // Logical Instructions
13496 
13497 // Integer Logical Instructions
13498 
13499 // And Instructions
13500 
13501 
13502 instruct andI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, rFlagsReg cr) %{
13503   match(Set dst (AndI src1 src2));
13504 
13505   format %{ &quot;andw  $dst, $src1, $src2\t# int&quot; %}
13506 
13507   ins_cost(INSN_COST);
13508   ins_encode %{
13509     __ andw(as_Register($dst$$reg),
13510             as_Register($src1$$reg),
13511             as_Register($src2$$reg));
13512   %}
13513 
13514   ins_pipe(ialu_reg_reg);
13515 %}
13516 
13517 instruct andI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2, rFlagsReg cr) %{
13518   match(Set dst (AndI src1 src2));
13519 
13520   format %{ &quot;andsw  $dst, $src1, $src2\t# int&quot; %}
13521 
13522   ins_cost(INSN_COST);
13523   ins_encode %{
13524     __ andw(as_Register($dst$$reg),
13525             as_Register($src1$$reg),
13526             (uint64_t)($src2$$constant));
13527   %}
13528 
13529   ins_pipe(ialu_reg_imm);
13530 %}
13531 
13532 // Or Instructions
13533 
13534 instruct orI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13535   match(Set dst (OrI src1 src2));
13536 
13537   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13538 
13539   ins_cost(INSN_COST);
13540   ins_encode %{
13541     __ orrw(as_Register($dst$$reg),
13542             as_Register($src1$$reg),
13543             as_Register($src2$$reg));
13544   %}
13545 
13546   ins_pipe(ialu_reg_reg);
13547 %}
13548 
13549 instruct orI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13550   match(Set dst (OrI src1 src2));
13551 
13552   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13553 
13554   ins_cost(INSN_COST);
13555   ins_encode %{
13556     __ orrw(as_Register($dst$$reg),
13557             as_Register($src1$$reg),
13558             (uint64_t)($src2$$constant));
13559   %}
13560 
13561   ins_pipe(ialu_reg_imm);
13562 %}
13563 
13564 // Xor Instructions
13565 
13566 instruct xorI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13567   match(Set dst (XorI src1 src2));
13568 
13569   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13570 
13571   ins_cost(INSN_COST);
13572   ins_encode %{
13573     __ eorw(as_Register($dst$$reg),
13574             as_Register($src1$$reg),
13575             as_Register($src2$$reg));
13576   %}
13577 
13578   ins_pipe(ialu_reg_reg);
13579 %}
13580 
13581 instruct xorI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13582   match(Set dst (XorI src1 src2));
13583 
13584   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13585 
13586   ins_cost(INSN_COST);
13587   ins_encode %{
13588     __ eorw(as_Register($dst$$reg),
13589             as_Register($src1$$reg),
13590             (uint64_t)($src2$$constant));
13591   %}
13592 
13593   ins_pipe(ialu_reg_imm);
13594 %}
13595 
13596 // Long Logical Instructions
13597 // TODO
13598 
13599 instruct andL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr) %{
13600   match(Set dst (AndL src1 src2));
13601 
13602   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13603 
13604   ins_cost(INSN_COST);
13605   ins_encode %{
13606     __ andr(as_Register($dst$$reg),
13607             as_Register($src1$$reg),
13608             as_Register($src2$$reg));
13609   %}
13610 
13611   ins_pipe(ialu_reg_reg);
13612 %}
13613 
13614 instruct andL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2, rFlagsReg cr) %{
13615   match(Set dst (AndL src1 src2));
13616 
13617   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13618 
13619   ins_cost(INSN_COST);
13620   ins_encode %{
13621     __ andr(as_Register($dst$$reg),
13622             as_Register($src1$$reg),
13623             (uint64_t)($src2$$constant));
13624   %}
13625 
13626   ins_pipe(ialu_reg_imm);
13627 %}
13628 
13629 // Or Instructions
13630 
13631 instruct orL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13632   match(Set dst (OrL src1 src2));
13633 
13634   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13635 
13636   ins_cost(INSN_COST);
13637   ins_encode %{
13638     __ orr(as_Register($dst$$reg),
13639            as_Register($src1$$reg),
13640            as_Register($src2$$reg));
13641   %}
13642 
13643   ins_pipe(ialu_reg_reg);
13644 %}
13645 
13646 instruct orL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13647   match(Set dst (OrL src1 src2));
13648 
13649   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13650 
13651   ins_cost(INSN_COST);
13652   ins_encode %{
13653     __ orr(as_Register($dst$$reg),
13654            as_Register($src1$$reg),
13655            (uint64_t)($src2$$constant));
13656   %}
13657 
13658   ins_pipe(ialu_reg_imm);
13659 %}
13660 
13661 // Xor Instructions
13662 
13663 instruct xorL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13664   match(Set dst (XorL src1 src2));
13665 
13666   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13667 
13668   ins_cost(INSN_COST);
13669   ins_encode %{
13670     __ eor(as_Register($dst$$reg),
13671            as_Register($src1$$reg),
13672            as_Register($src2$$reg));
13673   %}
13674 
13675   ins_pipe(ialu_reg_reg);
13676 %}
13677 
13678 instruct xorL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13679   match(Set dst (XorL src1 src2));
13680 
13681   ins_cost(INSN_COST);
13682   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13683 
13684   ins_encode %{
13685     __ eor(as_Register($dst$$reg),
13686            as_Register($src1$$reg),
13687            (uint64_t)($src2$$constant));
13688   %}
13689 
13690   ins_pipe(ialu_reg_imm);
13691 %}
13692 
13693 instruct convI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src)
13694 %{
13695   match(Set dst (ConvI2L src));
13696 
13697   ins_cost(INSN_COST);
13698   format %{ &quot;sxtw  $dst, $src\t# i2l&quot; %}
13699   ins_encode %{
13700     __ sbfm($dst$$Register, $src$$Register, 0, 31);
13701   %}
13702   ins_pipe(ialu_reg_shift);
13703 %}
13704 
13705 // this pattern occurs in bigmath arithmetic
13706 instruct convUI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src, immL_32bits mask)
13707 %{
13708   match(Set dst (AndL (ConvI2L src) mask));
13709 
13710   ins_cost(INSN_COST);
13711   format %{ &quot;ubfm  $dst, $src, 0, 31\t# ui2l&quot; %}
13712   ins_encode %{
13713     __ ubfm($dst$$Register, $src$$Register, 0, 31);
13714   %}
13715 
13716   ins_pipe(ialu_reg_shift);
13717 %}
13718 
13719 instruct convL2I_reg(iRegINoSp dst, iRegL src) %{
13720   match(Set dst (ConvL2I src));
13721 
13722   ins_cost(INSN_COST);
13723   format %{ &quot;movw  $dst, $src \t// l2i&quot; %}
13724 
13725   ins_encode %{
13726     __ movw(as_Register($dst$$reg), as_Register($src$$reg));
13727   %}
13728 
13729   ins_pipe(ialu_reg);
13730 %}
13731 
13732 instruct convI2B(iRegINoSp dst, iRegIorL2I src, rFlagsReg cr)
13733 %{
13734   match(Set dst (Conv2B src));
13735   effect(KILL cr);
13736 
13737   format %{
13738     &quot;cmpw $src, zr\n\t&quot;
13739     &quot;cset $dst, ne&quot;
13740   %}
13741 
13742   ins_encode %{
13743     __ cmpw(as_Register($src$$reg), zr);
13744     __ cset(as_Register($dst$$reg), Assembler::NE);
13745   %}
13746 
13747   ins_pipe(ialu_reg);
13748 %}
13749 
13750 instruct convP2B(iRegINoSp dst, iRegP src, rFlagsReg cr)
13751 %{
13752   match(Set dst (Conv2B src));
13753   effect(KILL cr);
13754 
13755   format %{
13756     &quot;cmp  $src, zr\n\t&quot;
13757     &quot;cset $dst, ne&quot;
13758   %}
13759 
13760   ins_encode %{
13761     __ cmp(as_Register($src$$reg), zr);
13762     __ cset(as_Register($dst$$reg), Assembler::NE);
13763   %}
13764 
13765   ins_pipe(ialu_reg);
13766 %}
13767 
13768 instruct convD2F_reg(vRegF dst, vRegD src) %{
13769   match(Set dst (ConvD2F src));
13770 
13771   ins_cost(INSN_COST * 5);
13772   format %{ &quot;fcvtd  $dst, $src \t// d2f&quot; %}
13773 
13774   ins_encode %{
13775     __ fcvtd(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13776   %}
13777 
13778   ins_pipe(fp_d2f);
13779 %}
13780 
13781 instruct convF2D_reg(vRegD dst, vRegF src) %{
13782   match(Set dst (ConvF2D src));
13783 
13784   ins_cost(INSN_COST * 5);
13785   format %{ &quot;fcvts  $dst, $src \t// f2d&quot; %}
13786 
13787   ins_encode %{
13788     __ fcvts(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13789   %}
13790 
13791   ins_pipe(fp_f2d);
13792 %}
13793 
13794 instruct convF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13795   match(Set dst (ConvF2I src));
13796 
13797   ins_cost(INSN_COST * 5);
13798   format %{ &quot;fcvtzsw  $dst, $src \t// f2i&quot; %}
13799 
13800   ins_encode %{
13801     __ fcvtzsw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13802   %}
13803 
13804   ins_pipe(fp_f2i);
13805 %}
13806 
13807 instruct convF2L_reg_reg(iRegLNoSp dst, vRegF src) %{
13808   match(Set dst (ConvF2L src));
13809 
13810   ins_cost(INSN_COST * 5);
13811   format %{ &quot;fcvtzs  $dst, $src \t// f2l&quot; %}
13812 
13813   ins_encode %{
13814     __ fcvtzs(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13815   %}
13816 
13817   ins_pipe(fp_f2l);
13818 %}
13819 
13820 instruct convI2F_reg_reg(vRegF dst, iRegIorL2I src) %{
13821   match(Set dst (ConvI2F src));
13822 
13823   ins_cost(INSN_COST * 5);
13824   format %{ &quot;scvtfws  $dst, $src \t// i2f&quot; %}
13825 
13826   ins_encode %{
13827     __ scvtfws(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13828   %}
13829 
13830   ins_pipe(fp_i2f);
13831 %}
13832 
13833 instruct convL2F_reg_reg(vRegF dst, iRegL src) %{
13834   match(Set dst (ConvL2F src));
13835 
13836   ins_cost(INSN_COST * 5);
13837   format %{ &quot;scvtfs  $dst, $src \t// l2f&quot; %}
13838 
13839   ins_encode %{
13840     __ scvtfs(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13841   %}
13842 
13843   ins_pipe(fp_l2f);
13844 %}
13845 
13846 instruct convD2I_reg_reg(iRegINoSp dst, vRegD src) %{
13847   match(Set dst (ConvD2I src));
13848 
13849   ins_cost(INSN_COST * 5);
13850   format %{ &quot;fcvtzdw  $dst, $src \t// d2i&quot; %}
13851 
13852   ins_encode %{
13853     __ fcvtzdw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13854   %}
13855 
13856   ins_pipe(fp_d2i);
13857 %}
13858 
13859 instruct convD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13860   match(Set dst (ConvD2L src));
13861 
13862   ins_cost(INSN_COST * 5);
13863   format %{ &quot;fcvtzd  $dst, $src \t// d2l&quot; %}
13864 
13865   ins_encode %{
13866     __ fcvtzd(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13867   %}
13868 
13869   ins_pipe(fp_d2l);
13870 %}
13871 
13872 instruct convI2D_reg_reg(vRegD dst, iRegIorL2I src) %{
13873   match(Set dst (ConvI2D src));
13874 
13875   ins_cost(INSN_COST * 5);
13876   format %{ &quot;scvtfwd  $dst, $src \t// i2d&quot; %}
13877 
13878   ins_encode %{
13879     __ scvtfwd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13880   %}
13881 
13882   ins_pipe(fp_i2d);
13883 %}
13884 
13885 instruct convL2D_reg_reg(vRegD dst, iRegL src) %{
13886   match(Set dst (ConvL2D src));
13887 
13888   ins_cost(INSN_COST * 5);
13889   format %{ &quot;scvtfd  $dst, $src \t// l2d&quot; %}
13890 
13891   ins_encode %{
13892     __ scvtfd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13893   %}
13894 
13895   ins_pipe(fp_l2d);
13896 %}
13897 
13898 // stack &lt;-&gt; reg and reg &lt;-&gt; reg shuffles with no conversion
13899 
13900 instruct MoveF2I_stack_reg(iRegINoSp dst, stackSlotF src) %{
13901 
13902   match(Set dst (MoveF2I src));
13903 
13904   effect(DEF dst, USE src);
13905 
13906   ins_cost(4 * INSN_COST);
13907 
13908   format %{ &quot;ldrw $dst, $src\t# MoveF2I_stack_reg&quot; %}
13909 
13910   ins_encode %{
13911     __ ldrw($dst$$Register, Address(sp, $src$$disp));
13912   %}
13913 
13914   ins_pipe(iload_reg_reg);
13915 
13916 %}
13917 
13918 instruct MoveI2F_stack_reg(vRegF dst, stackSlotI src) %{
13919 
13920   match(Set dst (MoveI2F src));
13921 
13922   effect(DEF dst, USE src);
13923 
13924   ins_cost(4 * INSN_COST);
13925 
13926   format %{ &quot;ldrs $dst, $src\t# MoveI2F_stack_reg&quot; %}
13927 
13928   ins_encode %{
13929     __ ldrs(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13930   %}
13931 
13932   ins_pipe(pipe_class_memory);
13933 
13934 %}
13935 
13936 instruct MoveD2L_stack_reg(iRegLNoSp dst, stackSlotD src) %{
13937 
13938   match(Set dst (MoveD2L src));
13939 
13940   effect(DEF dst, USE src);
13941 
13942   ins_cost(4 * INSN_COST);
13943 
13944   format %{ &quot;ldr $dst, $src\t# MoveD2L_stack_reg&quot; %}
13945 
13946   ins_encode %{
13947     __ ldr($dst$$Register, Address(sp, $src$$disp));
13948   %}
13949 
13950   ins_pipe(iload_reg_reg);
13951 
13952 %}
13953 
13954 instruct MoveL2D_stack_reg(vRegD dst, stackSlotL src) %{
13955 
13956   match(Set dst (MoveL2D src));
13957 
13958   effect(DEF dst, USE src);
13959 
13960   ins_cost(4 * INSN_COST);
13961 
13962   format %{ &quot;ldrd $dst, $src\t# MoveL2D_stack_reg&quot; %}
13963 
13964   ins_encode %{
13965     __ ldrd(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13966   %}
13967 
13968   ins_pipe(pipe_class_memory);
13969 
13970 %}
13971 
13972 instruct MoveF2I_reg_stack(stackSlotI dst, vRegF src) %{
13973 
13974   match(Set dst (MoveF2I src));
13975 
13976   effect(DEF dst, USE src);
13977 
13978   ins_cost(INSN_COST);
13979 
13980   format %{ &quot;strs $src, $dst\t# MoveF2I_reg_stack&quot; %}
13981 
13982   ins_encode %{
13983     __ strs(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13984   %}
13985 
13986   ins_pipe(pipe_class_memory);
13987 
13988 %}
13989 
13990 instruct MoveI2F_reg_stack(stackSlotF dst, iRegI src) %{
13991 
13992   match(Set dst (MoveI2F src));
13993 
13994   effect(DEF dst, USE src);
13995 
13996   ins_cost(INSN_COST);
13997 
13998   format %{ &quot;strw $src, $dst\t# MoveI2F_reg_stack&quot; %}
13999 
14000   ins_encode %{
14001     __ strw($src$$Register, Address(sp, $dst$$disp));
14002   %}
14003 
14004   ins_pipe(istore_reg_reg);
14005 
14006 %}
14007 
14008 instruct MoveD2L_reg_stack(stackSlotL dst, vRegD src) %{
14009 
14010   match(Set dst (MoveD2L src));
14011 
14012   effect(DEF dst, USE src);
14013 
14014   ins_cost(INSN_COST);
14015 
14016   format %{ &quot;strd $dst, $src\t# MoveD2L_reg_stack&quot; %}
14017 
14018   ins_encode %{
14019     __ strd(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
14020   %}
14021 
14022   ins_pipe(pipe_class_memory);
14023 
14024 %}
14025 
14026 instruct MoveL2D_reg_stack(stackSlotD dst, iRegL src) %{
14027 
14028   match(Set dst (MoveL2D src));
14029 
14030   effect(DEF dst, USE src);
14031 
14032   ins_cost(INSN_COST);
14033 
14034   format %{ &quot;str $src, $dst\t# MoveL2D_reg_stack&quot; %}
14035 
14036   ins_encode %{
14037     __ str($src$$Register, Address(sp, $dst$$disp));
14038   %}
14039 
14040   ins_pipe(istore_reg_reg);
14041 
14042 %}
14043 
14044 instruct MoveF2I_reg_reg(iRegINoSp dst, vRegF src) %{
14045 
14046   match(Set dst (MoveF2I src));
14047 
14048   effect(DEF dst, USE src);
14049 
14050   ins_cost(INSN_COST);
14051 
14052   format %{ &quot;fmovs $dst, $src\t# MoveF2I_reg_reg&quot; %}
14053 
14054   ins_encode %{
14055     __ fmovs($dst$$Register, as_FloatRegister($src$$reg));
14056   %}
14057 
14058   ins_pipe(fp_f2i);
14059 
14060 %}
14061 
14062 instruct MoveI2F_reg_reg(vRegF dst, iRegI src) %{
14063 
14064   match(Set dst (MoveI2F src));
14065 
14066   effect(DEF dst, USE src);
14067 
14068   ins_cost(INSN_COST);
14069 
14070   format %{ &quot;fmovs $dst, $src\t# MoveI2F_reg_reg&quot; %}
14071 
14072   ins_encode %{
14073     __ fmovs(as_FloatRegister($dst$$reg), $src$$Register);
14074   %}
14075 
14076   ins_pipe(fp_i2f);
14077 
14078 %}
14079 
14080 instruct MoveD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
14081 
14082   match(Set dst (MoveD2L src));
14083 
14084   effect(DEF dst, USE src);
14085 
14086   ins_cost(INSN_COST);
14087 
14088   format %{ &quot;fmovd $dst, $src\t# MoveD2L_reg_reg&quot; %}
14089 
14090   ins_encode %{
14091     __ fmovd($dst$$Register, as_FloatRegister($src$$reg));
14092   %}
14093 
14094   ins_pipe(fp_d2l);
14095 
14096 %}
14097 
14098 instruct MoveL2D_reg_reg(vRegD dst, iRegL src) %{
14099 
14100   match(Set dst (MoveL2D src));
14101 
14102   effect(DEF dst, USE src);
14103 
14104   ins_cost(INSN_COST);
14105 
14106   format %{ &quot;fmovd $dst, $src\t# MoveL2D_reg_reg&quot; %}
14107 
14108   ins_encode %{
14109     __ fmovd(as_FloatRegister($dst$$reg), $src$$Register);
14110   %}
14111 
14112   ins_pipe(fp_l2d);
14113 
14114 %}
14115 
14116 // ============================================================================
14117 // clearing of an array
14118 
14119 instruct clearArray_reg_reg(iRegL_R11 cnt, iRegP_R10 base, Universe dummy, rFlagsReg cr)
14120 %{
14121   match(Set dummy (ClearArray cnt base));
14122   effect(USE_KILL cnt, USE_KILL base, KILL cr);
14123 
14124   ins_cost(4 * INSN_COST);
14125   format %{ &quot;ClearArray $cnt, $base&quot; %}
14126 
14127   ins_encode %{
14128     __ zero_words($base$$Register, $cnt$$Register);
14129   %}
14130 
14131   ins_pipe(pipe_class_memory);
14132 %}
14133 
14134 instruct clearArray_imm_reg(immL cnt, iRegP_R10 base, Universe dummy, rFlagsReg cr)
14135 %{
14136   predicate((uint64_t)n-&gt;in(2)-&gt;get_long()
14137             &lt; (uint64_t)(BlockZeroingLowLimit &gt;&gt; LogBytesPerWord));
14138   match(Set dummy (ClearArray cnt base));
14139   effect(USE_KILL base);
14140 
14141   ins_cost(4 * INSN_COST);
14142   format %{ &quot;ClearArray $cnt, $base&quot; %}
14143 
14144   ins_encode %{
14145     __ zero_words($base$$Register, (uint64_t)$cnt$$constant);
14146   %}
14147 
14148   ins_pipe(pipe_class_memory);
14149 %}
14150 
14151 // ============================================================================
14152 // Overflow Math Instructions
14153 
14154 instruct overflowAddI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14155 %{
14156   match(Set cr (OverflowAddI op1 op2));
14157 
14158   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
14159   ins_cost(INSN_COST);
14160   ins_encode %{
14161     __ cmnw($op1$$Register, $op2$$Register);
14162   %}
14163 
14164   ins_pipe(icmp_reg_reg);
14165 %}
14166 
14167 instruct overflowAddI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
14168 %{
14169   match(Set cr (OverflowAddI op1 op2));
14170 
14171   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
14172   ins_cost(INSN_COST);
14173   ins_encode %{
14174     __ cmnw($op1$$Register, $op2$$constant);
14175   %}
14176 
14177   ins_pipe(icmp_reg_imm);
14178 %}
14179 
14180 instruct overflowAddL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14181 %{
14182   match(Set cr (OverflowAddL op1 op2));
14183 
14184   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
14185   ins_cost(INSN_COST);
14186   ins_encode %{
14187     __ cmn($op1$$Register, $op2$$Register);
14188   %}
14189 
14190   ins_pipe(icmp_reg_reg);
14191 %}
14192 
14193 instruct overflowAddL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
14194 %{
14195   match(Set cr (OverflowAddL op1 op2));
14196 
14197   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
14198   ins_cost(INSN_COST);
14199   ins_encode %{
14200     __ cmn($op1$$Register, $op2$$constant);
14201   %}
14202 
14203   ins_pipe(icmp_reg_imm);
14204 %}
14205 
14206 instruct overflowSubI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14207 %{
14208   match(Set cr (OverflowSubI op1 op2));
14209 
14210   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
14211   ins_cost(INSN_COST);
14212   ins_encode %{
14213     __ cmpw($op1$$Register, $op2$$Register);
14214   %}
14215 
14216   ins_pipe(icmp_reg_reg);
14217 %}
14218 
14219 instruct overflowSubI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
14220 %{
14221   match(Set cr (OverflowSubI op1 op2));
14222 
14223   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
14224   ins_cost(INSN_COST);
14225   ins_encode %{
14226     __ cmpw($op1$$Register, $op2$$constant);
14227   %}
14228 
14229   ins_pipe(icmp_reg_imm);
14230 %}
14231 
14232 instruct overflowSubL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14233 %{
14234   match(Set cr (OverflowSubL op1 op2));
14235 
14236   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
14237   ins_cost(INSN_COST);
14238   ins_encode %{
14239     __ cmp($op1$$Register, $op2$$Register);
14240   %}
14241 
14242   ins_pipe(icmp_reg_reg);
14243 %}
14244 
14245 instruct overflowSubL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
14246 %{
14247   match(Set cr (OverflowSubL op1 op2));
14248 
14249   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
14250   ins_cost(INSN_COST);
14251   ins_encode %{
14252     __ subs(zr, $op1$$Register, $op2$$constant);
14253   %}
14254 
14255   ins_pipe(icmp_reg_imm);
14256 %}
14257 
14258 instruct overflowNegI_reg(rFlagsReg cr, immI0 zero, iRegIorL2I op1)
14259 %{
14260   match(Set cr (OverflowSubI zero op1));
14261 
14262   format %{ &quot;cmpw  zr, $op1\t# overflow check int&quot; %}
14263   ins_cost(INSN_COST);
14264   ins_encode %{
14265     __ cmpw(zr, $op1$$Register);
14266   %}
14267 
14268   ins_pipe(icmp_reg_imm);
14269 %}
14270 
14271 instruct overflowNegL_reg(rFlagsReg cr, immI0 zero, iRegL op1)
14272 %{
14273   match(Set cr (OverflowSubL zero op1));
14274 
14275   format %{ &quot;cmp   zr, $op1\t# overflow check long&quot; %}
14276   ins_cost(INSN_COST);
14277   ins_encode %{
14278     __ cmp(zr, $op1$$Register);
14279   %}
14280 
14281   ins_pipe(icmp_reg_imm);
14282 %}
14283 
14284 instruct overflowMulI_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14285 %{
14286   match(Set cr (OverflowMulI op1 op2));
14287 
14288   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14289             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14290             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14291             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14292             &quot;cmpw  rscratch1, #1&quot; %}
14293   ins_cost(5 * INSN_COST);
14294   ins_encode %{
14295     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14296     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14297     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14298     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14299     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14300   %}
14301 
14302   ins_pipe(pipe_slow);
14303 %}
14304 
14305 instruct overflowMulI_reg_branch(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, label labl, rFlagsReg cr)
14306 %{
14307   match(If cmp (OverflowMulI op1 op2));
14308   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14309             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14310   effect(USE labl, KILL cr);
14311 
14312   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14313             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14314             &quot;b$cmp   $labl&quot; %}
14315   ins_cost(3 * INSN_COST); // Branch is rare so treat as INSN_COST
14316   ins_encode %{
14317     Label* L = $labl$$label;
14318     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14319     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14320     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14321     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14322   %}
14323 
14324   ins_pipe(pipe_serial);
14325 %}
14326 
14327 instruct overflowMulL_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14328 %{
14329   match(Set cr (OverflowMulL op1 op2));
14330 
14331   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14332             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14333             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14334             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14335             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14336             &quot;cmpw  rscratch1, #1&quot; %}
14337   ins_cost(6 * INSN_COST);
14338   ins_encode %{
14339     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14340     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14341     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14342     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14343     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14344     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14345   %}
14346 
14347   ins_pipe(pipe_slow);
14348 %}
14349 
14350 instruct overflowMulL_reg_branch(cmpOp cmp, iRegL op1, iRegL op2, label labl, rFlagsReg cr)
14351 %{
14352   match(If cmp (OverflowMulL op1 op2));
14353   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14354             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14355   effect(USE labl, KILL cr);
14356 
14357   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14358             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14359             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14360             &quot;b$cmp $labl&quot; %}
14361   ins_cost(4 * INSN_COST); // Branch is rare so treat as INSN_COST
14362   ins_encode %{
14363     Label* L = $labl$$label;
14364     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14365     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14366     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14367     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14368     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14369   %}
14370 
14371   ins_pipe(pipe_serial);
14372 %}
14373 
14374 // ============================================================================
14375 // Compare Instructions
14376 
14377 instruct compI_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
14378 %{
14379   match(Set cr (CmpI op1 op2));
14380 
14381   effect(DEF cr, USE op1, USE op2);
14382 
14383   ins_cost(INSN_COST);
14384   format %{ &quot;cmpw  $op1, $op2&quot; %}
14385 
14386   ins_encode(aarch64_enc_cmpw(op1, op2));
14387 
14388   ins_pipe(icmp_reg_reg);
14389 %}
14390 
14391 instruct compI_reg_immI0(rFlagsReg cr, iRegI op1, immI0 zero)
14392 %{
14393   match(Set cr (CmpI op1 zero));
14394 
14395   effect(DEF cr, USE op1);
14396 
14397   ins_cost(INSN_COST);
14398   format %{ &quot;cmpw $op1, 0&quot; %}
14399 
14400   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14401 
14402   ins_pipe(icmp_reg_imm);
14403 %}
14404 
14405 instruct compI_reg_immIAddSub(rFlagsReg cr, iRegI op1, immIAddSub op2)
14406 %{
14407   match(Set cr (CmpI op1 op2));
14408 
14409   effect(DEF cr, USE op1);
14410 
14411   ins_cost(INSN_COST);
14412   format %{ &quot;cmpw  $op1, $op2&quot; %}
14413 
14414   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14415 
14416   ins_pipe(icmp_reg_imm);
14417 %}
14418 
14419 instruct compI_reg_immI(rFlagsReg cr, iRegI op1, immI op2)
14420 %{
14421   match(Set cr (CmpI op1 op2));
14422 
14423   effect(DEF cr, USE op1);
14424 
14425   ins_cost(INSN_COST * 2);
14426   format %{ &quot;cmpw  $op1, $op2&quot; %}
14427 
14428   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14429 
14430   ins_pipe(icmp_reg_imm);
14431 %}
14432 
14433 // Unsigned compare Instructions; really, same as signed compare
14434 // except it should only be used to feed an If or a CMovI which takes a
14435 // cmpOpU.
14436 
14437 instruct compU_reg_reg(rFlagsRegU cr, iRegI op1, iRegI op2)
14438 %{
14439   match(Set cr (CmpU op1 op2));
14440 
14441   effect(DEF cr, USE op1, USE op2);
14442 
14443   ins_cost(INSN_COST);
14444   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14445 
14446   ins_encode(aarch64_enc_cmpw(op1, op2));
14447 
14448   ins_pipe(icmp_reg_reg);
14449 %}
14450 
14451 instruct compU_reg_immI0(rFlagsRegU cr, iRegI op1, immI0 zero)
14452 %{
14453   match(Set cr (CmpU op1 zero));
14454 
14455   effect(DEF cr, USE op1);
14456 
14457   ins_cost(INSN_COST);
14458   format %{ &quot;cmpw $op1, #0\t# unsigned&quot; %}
14459 
14460   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14461 
14462   ins_pipe(icmp_reg_imm);
14463 %}
14464 
14465 instruct compU_reg_immIAddSub(rFlagsRegU cr, iRegI op1, immIAddSub op2)
14466 %{
14467   match(Set cr (CmpU op1 op2));
14468 
14469   effect(DEF cr, USE op1);
14470 
14471   ins_cost(INSN_COST);
14472   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14473 
14474   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14475 
14476   ins_pipe(icmp_reg_imm);
14477 %}
14478 
14479 instruct compU_reg_immI(rFlagsRegU cr, iRegI op1, immI op2)
14480 %{
14481   match(Set cr (CmpU op1 op2));
14482 
14483   effect(DEF cr, USE op1);
14484 
14485   ins_cost(INSN_COST * 2);
14486   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14487 
14488   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14489 
14490   ins_pipe(icmp_reg_imm);
14491 %}
14492 
14493 instruct compL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14494 %{
14495   match(Set cr (CmpL op1 op2));
14496 
14497   effect(DEF cr, USE op1, USE op2);
14498 
14499   ins_cost(INSN_COST);
14500   format %{ &quot;cmp  $op1, $op2&quot; %}
14501 
14502   ins_encode(aarch64_enc_cmp(op1, op2));
14503 
14504   ins_pipe(icmp_reg_reg);
14505 %}
14506 
14507 instruct compL_reg_immL0(rFlagsReg cr, iRegL op1, immL0 zero)
14508 %{
14509   match(Set cr (CmpL op1 zero));
14510 
14511   effect(DEF cr, USE op1);
14512 
14513   ins_cost(INSN_COST);
14514   format %{ &quot;tst  $op1&quot; %}
14515 
14516   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14517 
14518   ins_pipe(icmp_reg_imm);
14519 %}
14520 
14521 instruct compL_reg_immLAddSub(rFlagsReg cr, iRegL op1, immLAddSub op2)
14522 %{
14523   match(Set cr (CmpL op1 op2));
14524 
14525   effect(DEF cr, USE op1);
14526 
14527   ins_cost(INSN_COST);
14528   format %{ &quot;cmp  $op1, $op2&quot; %}
14529 
14530   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14531 
14532   ins_pipe(icmp_reg_imm);
14533 %}
14534 
14535 instruct compL_reg_immL(rFlagsReg cr, iRegL op1, immL op2)
14536 %{
14537   match(Set cr (CmpL op1 op2));
14538 
14539   effect(DEF cr, USE op1);
14540 
14541   ins_cost(INSN_COST * 2);
14542   format %{ &quot;cmp  $op1, $op2&quot; %}
14543 
14544   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14545 
14546   ins_pipe(icmp_reg_imm);
14547 %}
14548 
14549 instruct compUL_reg_reg(rFlagsRegU cr, iRegL op1, iRegL op2)
14550 %{
14551   match(Set cr (CmpUL op1 op2));
14552 
14553   effect(DEF cr, USE op1, USE op2);
14554 
14555   ins_cost(INSN_COST);
14556   format %{ &quot;cmp  $op1, $op2&quot; %}
14557 
14558   ins_encode(aarch64_enc_cmp(op1, op2));
14559 
14560   ins_pipe(icmp_reg_reg);
14561 %}
14562 
14563 instruct compUL_reg_immL0(rFlagsRegU cr, iRegL op1, immL0 zero)
14564 %{
14565   match(Set cr (CmpUL op1 zero));
14566 
14567   effect(DEF cr, USE op1);
14568 
14569   ins_cost(INSN_COST);
14570   format %{ &quot;tst  $op1&quot; %}
14571 
14572   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14573 
14574   ins_pipe(icmp_reg_imm);
14575 %}
14576 
14577 instruct compUL_reg_immLAddSub(rFlagsRegU cr, iRegL op1, immLAddSub op2)
14578 %{
14579   match(Set cr (CmpUL op1 op2));
14580 
14581   effect(DEF cr, USE op1);
14582 
14583   ins_cost(INSN_COST);
14584   format %{ &quot;cmp  $op1, $op2&quot; %}
14585 
14586   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14587 
14588   ins_pipe(icmp_reg_imm);
14589 %}
14590 
14591 instruct compUL_reg_immL(rFlagsRegU cr, iRegL op1, immL op2)
14592 %{
14593   match(Set cr (CmpUL op1 op2));
14594 
14595   effect(DEF cr, USE op1);
14596 
14597   ins_cost(INSN_COST * 2);
14598   format %{ &quot;cmp  $op1, $op2&quot; %}
14599 
14600   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14601 
14602   ins_pipe(icmp_reg_imm);
14603 %}
14604 
14605 instruct compP_reg_reg(rFlagsRegU cr, iRegP op1, iRegP op2)
14606 %{
14607   match(Set cr (CmpP op1 op2));
14608 
14609   effect(DEF cr, USE op1, USE op2);
14610 
14611   ins_cost(INSN_COST);
14612   format %{ &quot;cmp  $op1, $op2\t // ptr&quot; %}
14613 
14614   ins_encode(aarch64_enc_cmpp(op1, op2));
14615 
14616   ins_pipe(icmp_reg_reg);
14617 %}
14618 
14619 instruct compN_reg_reg(rFlagsRegU cr, iRegN op1, iRegN op2)
14620 %{
14621   match(Set cr (CmpN op1 op2));
14622 
14623   effect(DEF cr, USE op1, USE op2);
14624 
14625   ins_cost(INSN_COST);
14626   format %{ &quot;cmp  $op1, $op2\t // compressed ptr&quot; %}
14627 
14628   ins_encode(aarch64_enc_cmpn(op1, op2));
14629 
14630   ins_pipe(icmp_reg_reg);
14631 %}
14632 
14633 instruct testP_reg(rFlagsRegU cr, iRegP op1, immP0 zero)
14634 %{
14635   match(Set cr (CmpP op1 zero));
14636 
14637   effect(DEF cr, USE op1, USE zero);
14638 
14639   ins_cost(INSN_COST);
14640   format %{ &quot;cmp  $op1, 0\t // ptr&quot; %}
14641 
14642   ins_encode(aarch64_enc_testp(op1));
14643 
14644   ins_pipe(icmp_reg_imm);
14645 %}
14646 
14647 instruct testN_reg(rFlagsRegU cr, iRegN op1, immN0 zero)
14648 %{
14649   match(Set cr (CmpN op1 zero));
14650 
14651   effect(DEF cr, USE op1, USE zero);
14652 
14653   ins_cost(INSN_COST);
14654   format %{ &quot;cmp  $op1, 0\t // compressed ptr&quot; %}
14655 
14656   ins_encode(aarch64_enc_testn(op1));
14657 
14658   ins_pipe(icmp_reg_imm);
14659 %}
14660 
14661 // FP comparisons
14662 //
14663 // n.b. CmpF/CmpD set a normal flags reg which then gets compared
14664 // using normal cmpOp. See declaration of rFlagsReg for details.
14665 
14666 instruct compF_reg_reg(rFlagsReg cr, vRegF src1, vRegF src2)
14667 %{
14668   match(Set cr (CmpF src1 src2));
14669 
14670   ins_cost(3 * INSN_COST);
14671   format %{ &quot;fcmps $src1, $src2&quot; %}
14672 
14673   ins_encode %{
14674     __ fcmps(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14675   %}
14676 
14677   ins_pipe(pipe_class_compare);
14678 %}
14679 
14680 instruct compF_reg_zero(rFlagsReg cr, vRegF src1, immF0 src2)
14681 %{
14682   match(Set cr (CmpF src1 src2));
14683 
14684   ins_cost(3 * INSN_COST);
14685   format %{ &quot;fcmps $src1, 0.0&quot; %}
14686 
14687   ins_encode %{
14688     __ fcmps(as_FloatRegister($src1$$reg), 0.0);
14689   %}
14690 
14691   ins_pipe(pipe_class_compare);
14692 %}
14693 // FROM HERE
14694 
14695 instruct compD_reg_reg(rFlagsReg cr, vRegD src1, vRegD src2)
14696 %{
14697   match(Set cr (CmpD src1 src2));
14698 
14699   ins_cost(3 * INSN_COST);
14700   format %{ &quot;fcmpd $src1, $src2&quot; %}
14701 
14702   ins_encode %{
14703     __ fcmpd(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14704   %}
14705 
14706   ins_pipe(pipe_class_compare);
14707 %}
14708 
14709 instruct compD_reg_zero(rFlagsReg cr, vRegD src1, immD0 src2)
14710 %{
14711   match(Set cr (CmpD src1 src2));
14712 
14713   ins_cost(3 * INSN_COST);
14714   format %{ &quot;fcmpd $src1, 0.0&quot; %}
14715 
14716   ins_encode %{
14717     __ fcmpd(as_FloatRegister($src1$$reg), 0.0);
14718   %}
14719 
14720   ins_pipe(pipe_class_compare);
14721 %}
14722 
14723 instruct compF3_reg_reg(iRegINoSp dst, vRegF src1, vRegF src2, rFlagsReg cr)
14724 %{
14725   match(Set dst (CmpF3 src1 src2));
14726   effect(KILL cr);
14727 
14728   ins_cost(5 * INSN_COST);
14729   format %{ &quot;fcmps $src1, $src2\n\t&quot;
14730             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14731             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14732   %}
14733 
14734   ins_encode %{
14735     Label done;
14736     FloatRegister s1 = as_FloatRegister($src1$$reg);
14737     FloatRegister s2 = as_FloatRegister($src2$$reg);
14738     Register d = as_Register($dst$$reg);
14739     __ fcmps(s1, s2);
14740     // installs 0 if EQ else -1
14741     __ csinvw(d, zr, zr, Assembler::EQ);
14742     // keeps -1 if less or unordered else installs 1
14743     __ csnegw(d, d, d, Assembler::LT);
14744     __ bind(done);
14745   %}
14746 
14747   ins_pipe(pipe_class_default);
14748 
14749 %}
14750 
14751 instruct compD3_reg_reg(iRegINoSp dst, vRegD src1, vRegD src2, rFlagsReg cr)
14752 %{
14753   match(Set dst (CmpD3 src1 src2));
14754   effect(KILL cr);
14755 
14756   ins_cost(5 * INSN_COST);
14757   format %{ &quot;fcmpd $src1, $src2\n\t&quot;
14758             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14759             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14760   %}
14761 
14762   ins_encode %{
14763     Label done;
14764     FloatRegister s1 = as_FloatRegister($src1$$reg);
14765     FloatRegister s2 = as_FloatRegister($src2$$reg);
14766     Register d = as_Register($dst$$reg);
14767     __ fcmpd(s1, s2);
14768     // installs 0 if EQ else -1
14769     __ csinvw(d, zr, zr, Assembler::EQ);
14770     // keeps -1 if less or unordered else installs 1
14771     __ csnegw(d, d, d, Assembler::LT);
14772     __ bind(done);
14773   %}
14774   ins_pipe(pipe_class_default);
14775 
14776 %}
14777 
14778 instruct compF3_reg_immF0(iRegINoSp dst, vRegF src1, immF0 zero, rFlagsReg cr)
14779 %{
14780   match(Set dst (CmpF3 src1 zero));
14781   effect(KILL cr);
14782 
14783   ins_cost(5 * INSN_COST);
14784   format %{ &quot;fcmps $src1, 0.0\n\t&quot;
14785             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14786             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14787   %}
14788 
14789   ins_encode %{
14790     Label done;
14791     FloatRegister s1 = as_FloatRegister($src1$$reg);
14792     Register d = as_Register($dst$$reg);
14793     __ fcmps(s1, 0.0);
14794     // installs 0 if EQ else -1
14795     __ csinvw(d, zr, zr, Assembler::EQ);
14796     // keeps -1 if less or unordered else installs 1
14797     __ csnegw(d, d, d, Assembler::LT);
14798     __ bind(done);
14799   %}
14800 
14801   ins_pipe(pipe_class_default);
14802 
14803 %}
14804 
14805 instruct compD3_reg_immD0(iRegINoSp dst, vRegD src1, immD0 zero, rFlagsReg cr)
14806 %{
14807   match(Set dst (CmpD3 src1 zero));
14808   effect(KILL cr);
14809 
14810   ins_cost(5 * INSN_COST);
14811   format %{ &quot;fcmpd $src1, 0.0\n\t&quot;
14812             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14813             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14814   %}
14815 
14816   ins_encode %{
14817     Label done;
14818     FloatRegister s1 = as_FloatRegister($src1$$reg);
14819     Register d = as_Register($dst$$reg);
14820     __ fcmpd(s1, 0.0);
14821     // installs 0 if EQ else -1
14822     __ csinvw(d, zr, zr, Assembler::EQ);
14823     // keeps -1 if less or unordered else installs 1
14824     __ csnegw(d, d, d, Assembler::LT);
14825     __ bind(done);
14826   %}
14827   ins_pipe(pipe_class_default);
14828 
14829 %}
14830 
14831 instruct cmpLTMask_reg_reg(iRegINoSp dst, iRegIorL2I p, iRegIorL2I q, rFlagsReg cr)
14832 %{
14833   match(Set dst (CmpLTMask p q));
14834   effect(KILL cr);
14835 
14836   ins_cost(3 * INSN_COST);
14837 
14838   format %{ &quot;cmpw $p, $q\t# cmpLTMask\n\t&quot;
14839             &quot;csetw $dst, lt\n\t&quot;
14840             &quot;subw $dst, zr, $dst&quot;
14841   %}
14842 
14843   ins_encode %{
14844     __ cmpw(as_Register($p$$reg), as_Register($q$$reg));
14845     __ csetw(as_Register($dst$$reg), Assembler::LT);
14846     __ subw(as_Register($dst$$reg), zr, as_Register($dst$$reg));
14847   %}
14848 
14849   ins_pipe(ialu_reg_reg);
14850 %}
14851 
14852 instruct cmpLTMask_reg_zero(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr)
14853 %{
14854   match(Set dst (CmpLTMask src zero));
14855   effect(KILL cr);
14856 
14857   ins_cost(INSN_COST);
14858 
14859   format %{ &quot;asrw $dst, $src, #31\t# cmpLTMask0&quot; %}
14860 
14861   ins_encode %{
14862     __ asrw(as_Register($dst$$reg), as_Register($src$$reg), 31);
14863   %}
14864 
14865   ins_pipe(ialu_reg_shift);
14866 %}
14867 
14868 // ============================================================================
14869 // Max and Min
14870 
14871 instruct cmovI_reg_reg_lt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14872 %{
14873   effect( DEF dst, USE src1, USE src2, USE cr );
14874 
14875   ins_cost(INSN_COST * 2);
14876   format %{ &quot;cselw $dst, $src1, $src2 lt\t&quot;  %}
14877 
14878   ins_encode %{
14879     __ cselw(as_Register($dst$$reg),
14880              as_Register($src1$$reg),
14881              as_Register($src2$$reg),
14882              Assembler::LT);
14883   %}
14884 
14885   ins_pipe(icond_reg_reg);
14886 %}
14887 
14888 instruct minI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14889 %{
14890   match(Set dst (MinI src1 src2));
14891   ins_cost(INSN_COST * 3);
14892 
14893   expand %{
14894     rFlagsReg cr;
14895     compI_reg_reg(cr, src1, src2);
14896     cmovI_reg_reg_lt(dst, src1, src2, cr);
14897   %}
14898 
14899 %}
14900 // FROM HERE
14901 
14902 instruct cmovI_reg_reg_gt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14903 %{
14904   effect( DEF dst, USE src1, USE src2, USE cr );
14905 
14906   ins_cost(INSN_COST * 2);
14907   format %{ &quot;cselw $dst, $src1, $src2 gt\t&quot;  %}
14908 
14909   ins_encode %{
14910     __ cselw(as_Register($dst$$reg),
14911              as_Register($src1$$reg),
14912              as_Register($src2$$reg),
14913              Assembler::GT);
14914   %}
14915 
14916   ins_pipe(icond_reg_reg);
14917 %}
14918 
14919 instruct maxI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14920 %{
14921   match(Set dst (MaxI src1 src2));
14922   ins_cost(INSN_COST * 3);
14923   expand %{
14924     rFlagsReg cr;
14925     compI_reg_reg(cr, src1, src2);
14926     cmovI_reg_reg_gt(dst, src1, src2, cr);
14927   %}
14928 %}
14929 
14930 // ============================================================================
14931 // Branch Instructions
14932 
14933 // Direct Branch.
14934 instruct branch(label lbl)
14935 %{
14936   match(Goto);
14937 
14938   effect(USE lbl);
14939 
14940   ins_cost(BRANCH_COST);
14941   format %{ &quot;b  $lbl&quot; %}
14942 
14943   ins_encode(aarch64_enc_b(lbl));
14944 
14945   ins_pipe(pipe_branch);
14946 %}
14947 
14948 // Conditional Near Branch
14949 instruct branchCon(cmpOp cmp, rFlagsReg cr, label lbl)
14950 %{
14951   // Same match rule as `branchConFar&#39;.
14952   match(If cmp cr);
14953 
14954   effect(USE lbl);
14955 
14956   ins_cost(BRANCH_COST);
14957   // If set to 1 this indicates that the current instruction is a
14958   // short variant of a long branch. This avoids using this
14959   // instruction in first-pass matching. It will then only be used in
14960   // the `Shorten_branches&#39; pass.
14961   // ins_short_branch(1);
14962   format %{ &quot;b$cmp  $lbl&quot; %}
14963 
14964   ins_encode(aarch64_enc_br_con(cmp, lbl));
14965 
14966   ins_pipe(pipe_branch_cond);
14967 %}
14968 
14969 // Conditional Near Branch Unsigned
14970 instruct branchConU(cmpOpU cmp, rFlagsRegU cr, label lbl)
14971 %{
14972   // Same match rule as `branchConFar&#39;.
14973   match(If cmp cr);
14974 
14975   effect(USE lbl);
14976 
14977   ins_cost(BRANCH_COST);
14978   // If set to 1 this indicates that the current instruction is a
14979   // short variant of a long branch. This avoids using this
14980   // instruction in first-pass matching. It will then only be used in
14981   // the `Shorten_branches&#39; pass.
14982   // ins_short_branch(1);
14983   format %{ &quot;b$cmp  $lbl\t# unsigned&quot; %}
14984 
14985   ins_encode(aarch64_enc_br_conU(cmp, lbl));
14986 
14987   ins_pipe(pipe_branch_cond);
14988 %}
14989 
14990 // Make use of CBZ and CBNZ.  These instructions, as well as being
14991 // shorter than (cmp; branch), have the additional benefit of not
14992 // killing the flags.
14993 
14994 instruct cmpI_imm0_branch(cmpOpEqNe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsReg cr) %{
14995   match(If cmp (CmpI op1 op2));
14996   effect(USE labl);
14997 
14998   ins_cost(BRANCH_COST);
14999   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
15000   ins_encode %{
15001     Label* L = $labl$$label;
15002     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15003     if (cond == Assembler::EQ)
15004       __ cbzw($op1$$Register, *L);
15005     else
15006       __ cbnzw($op1$$Register, *L);
15007   %}
15008   ins_pipe(pipe_cmp_branch);
15009 %}
15010 
15011 instruct cmpL_imm0_branch(cmpOpEqNe cmp, iRegL op1, immL0 op2, label labl, rFlagsReg cr) %{
15012   match(If cmp (CmpL op1 op2));
15013   effect(USE labl);
15014 
15015   ins_cost(BRANCH_COST);
15016   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
15017   ins_encode %{
15018     Label* L = $labl$$label;
15019     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15020     if (cond == Assembler::EQ)
15021       __ cbz($op1$$Register, *L);
15022     else
15023       __ cbnz($op1$$Register, *L);
15024   %}
15025   ins_pipe(pipe_cmp_branch);
15026 %}
15027 
15028 instruct cmpP_imm0_branch(cmpOpEqNe cmp, iRegP op1, immP0 op2, label labl, rFlagsReg cr) %{
15029   match(If cmp (CmpP op1 op2));
15030   effect(USE labl);
15031 
15032   ins_cost(BRANCH_COST);
15033   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
15034   ins_encode %{
15035     Label* L = $labl$$label;
15036     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15037     if (cond == Assembler::EQ)
15038       __ cbz($op1$$Register, *L);
15039     else
15040       __ cbnz($op1$$Register, *L);
15041   %}
15042   ins_pipe(pipe_cmp_branch);
15043 %}
15044 
15045 instruct cmpN_imm0_branch(cmpOpEqNe cmp, iRegN op1, immN0 op2, label labl, rFlagsReg cr) %{
15046   match(If cmp (CmpN op1 op2));
15047   effect(USE labl);
15048 
15049   ins_cost(BRANCH_COST);
15050   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
15051   ins_encode %{
15052     Label* L = $labl$$label;
15053     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15054     if (cond == Assembler::EQ)
15055       __ cbzw($op1$$Register, *L);
15056     else
15057       __ cbnzw($op1$$Register, *L);
15058   %}
15059   ins_pipe(pipe_cmp_branch);
15060 %}
15061 
15062 instruct cmpP_narrowOop_imm0_branch(cmpOpEqNe cmp, iRegN oop, immP0 zero, label labl, rFlagsReg cr) %{
15063   match(If cmp (CmpP (DecodeN oop) zero));
15064   effect(USE labl);
15065 
15066   ins_cost(BRANCH_COST);
15067   format %{ &quot;cb$cmp   $oop, $labl&quot; %}
15068   ins_encode %{
15069     Label* L = $labl$$label;
15070     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15071     if (cond == Assembler::EQ)
15072       __ cbzw($oop$$Register, *L);
15073     else
15074       __ cbnzw($oop$$Register, *L);
15075   %}
15076   ins_pipe(pipe_cmp_branch);
15077 %}
15078 
15079 instruct cmpUI_imm0_branch(cmpOpUEqNeLtGe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsRegU cr) %{
15080   match(If cmp (CmpU op1 op2));
15081   effect(USE labl);
15082 
15083   ins_cost(BRANCH_COST);
15084   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
15085   ins_encode %{
15086     Label* L = $labl$$label;
15087     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15088     if (cond == Assembler::EQ || cond == Assembler::LS)
15089       __ cbzw($op1$$Register, *L);
15090     else
15091       __ cbnzw($op1$$Register, *L);
15092   %}
15093   ins_pipe(pipe_cmp_branch);
15094 %}
15095 
15096 instruct cmpUL_imm0_branch(cmpOpUEqNeLtGe cmp, iRegL op1, immL0 op2, label labl, rFlagsRegU cr) %{
15097   match(If cmp (CmpUL op1 op2));
15098   effect(USE labl);
15099 
15100   ins_cost(BRANCH_COST);
15101   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
15102   ins_encode %{
15103     Label* L = $labl$$label;
15104     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15105     if (cond == Assembler::EQ || cond == Assembler::LS)
15106       __ cbz($op1$$Register, *L);
15107     else
15108       __ cbnz($op1$$Register, *L);
15109   %}
15110   ins_pipe(pipe_cmp_branch);
15111 %}
15112 
15113 // Test bit and Branch
15114 
15115 // Patterns for short (&lt; 32KiB) variants
15116 instruct cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
15117   match(If cmp (CmpL op1 op2));
15118   effect(USE labl);
15119 
15120   ins_cost(BRANCH_COST);
15121   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
15122   ins_encode %{
15123     Label* L = $labl$$label;
15124     Assembler::Condition cond =
15125       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
15126     __ tbr(cond, $op1$$Register, 63, *L);
15127   %}
15128   ins_pipe(pipe_cmp_branch);
15129   ins_short_branch(1);
15130 %}
15131 
15132 instruct cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
15133   match(If cmp (CmpI op1 op2));
15134   effect(USE labl);
15135 
15136   ins_cost(BRANCH_COST);
15137   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
15138   ins_encode %{
15139     Label* L = $labl$$label;
15140     Assembler::Condition cond =
15141       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
15142     __ tbr(cond, $op1$$Register, 31, *L);
15143   %}
15144   ins_pipe(pipe_cmp_branch);
15145   ins_short_branch(1);
15146 %}
15147 
15148 instruct cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
15149   match(If cmp (CmpL (AndL op1 op2) op3));
15150   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15151   effect(USE labl);
15152 
15153   ins_cost(BRANCH_COST);
15154   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15155   ins_encode %{
15156     Label* L = $labl$$label;
15157     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15158     int bit = exact_log2_long($op2$$constant);
15159     __ tbr(cond, $op1$$Register, bit, *L);
15160   %}
15161   ins_pipe(pipe_cmp_branch);
15162   ins_short_branch(1);
15163 %}
15164 
15165 instruct cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
15166   match(If cmp (CmpI (AndI op1 op2) op3));
15167   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15168   effect(USE labl);
15169 
15170   ins_cost(BRANCH_COST);
15171   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15172   ins_encode %{
15173     Label* L = $labl$$label;
15174     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15175     int bit = exact_log2((juint)$op2$$constant);
15176     __ tbr(cond, $op1$$Register, bit, *L);
15177   %}
15178   ins_pipe(pipe_cmp_branch);
15179   ins_short_branch(1);
15180 %}
15181 
15182 // And far variants
15183 instruct far_cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
15184   match(If cmp (CmpL op1 op2));
15185   effect(USE labl);
15186 
15187   ins_cost(BRANCH_COST);
15188   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
15189   ins_encode %{
15190     Label* L = $labl$$label;
15191     Assembler::Condition cond =
15192       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
15193     __ tbr(cond, $op1$$Register, 63, *L, /*far*/true);
15194   %}
15195   ins_pipe(pipe_cmp_branch);
15196 %}
15197 
15198 instruct far_cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
15199   match(If cmp (CmpI op1 op2));
15200   effect(USE labl);
15201 
15202   ins_cost(BRANCH_COST);
15203   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
15204   ins_encode %{
15205     Label* L = $labl$$label;
15206     Assembler::Condition cond =
15207       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
15208     __ tbr(cond, $op1$$Register, 31, *L, /*far*/true);
15209   %}
15210   ins_pipe(pipe_cmp_branch);
15211 %}
15212 
15213 instruct far_cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
15214   match(If cmp (CmpL (AndL op1 op2) op3));
15215   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15216   effect(USE labl);
15217 
15218   ins_cost(BRANCH_COST);
15219   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15220   ins_encode %{
15221     Label* L = $labl$$label;
15222     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15223     int bit = exact_log2_long($op2$$constant);
15224     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15225   %}
15226   ins_pipe(pipe_cmp_branch);
15227 %}
15228 
15229 instruct far_cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
15230   match(If cmp (CmpI (AndI op1 op2) op3));
15231   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15232   effect(USE labl);
15233 
15234   ins_cost(BRANCH_COST);
15235   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15236   ins_encode %{
15237     Label* L = $labl$$label;
15238     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15239     int bit = exact_log2((juint)$op2$$constant);
15240     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15241   %}
15242   ins_pipe(pipe_cmp_branch);
15243 %}
15244 
15245 // Test bits
15246 
15247 instruct cmpL_and(cmpOp cmp, iRegL op1, immL op2, immL0 op3, rFlagsReg cr) %{
15248   match(Set cr (CmpL (AndL op1 op2) op3));
15249   predicate(Assembler::operand_valid_for_logical_immediate
15250             (/*is_32*/false, n-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15251 
15252   ins_cost(INSN_COST);
15253   format %{ &quot;tst $op1, $op2 # long&quot; %}
15254   ins_encode %{
15255     __ tst($op1$$Register, $op2$$constant);
15256   %}
15257   ins_pipe(ialu_reg_reg);
15258 %}
15259 
15260 instruct cmpI_and(cmpOp cmp, iRegIorL2I op1, immI op2, immI0 op3, rFlagsReg cr) %{
15261   match(Set cr (CmpI (AndI op1 op2) op3));
15262   predicate(Assembler::operand_valid_for_logical_immediate
15263             (/*is_32*/true, n-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15264 
15265   ins_cost(INSN_COST);
15266   format %{ &quot;tst $op1, $op2 # int&quot; %}
15267   ins_encode %{
15268     __ tstw($op1$$Register, $op2$$constant);
15269   %}
15270   ins_pipe(ialu_reg_reg);
15271 %}
15272 
15273 instruct cmpL_and_reg(cmpOp cmp, iRegL op1, iRegL op2, immL0 op3, rFlagsReg cr) %{
15274   match(Set cr (CmpL (AndL op1 op2) op3));
15275 
15276   ins_cost(INSN_COST);
15277   format %{ &quot;tst $op1, $op2 # long&quot; %}
15278   ins_encode %{
15279     __ tst($op1$$Register, $op2$$Register);
15280   %}
15281   ins_pipe(ialu_reg_reg);
15282 %}
15283 
15284 instruct cmpI_and_reg(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, immI0 op3, rFlagsReg cr) %{
15285   match(Set cr (CmpI (AndI op1 op2) op3));
15286 
15287   ins_cost(INSN_COST);
15288   format %{ &quot;tstw $op1, $op2 # int&quot; %}
15289   ins_encode %{
15290     __ tstw($op1$$Register, $op2$$Register);
15291   %}
15292   ins_pipe(ialu_reg_reg);
15293 %}
15294 
15295 
15296 // Conditional Far Branch
15297 // Conditional Far Branch Unsigned
15298 // TODO: fixme
15299 
15300 // counted loop end branch near
15301 instruct branchLoopEnd(cmpOp cmp, rFlagsReg cr, label lbl)
15302 %{
15303   match(CountedLoopEnd cmp cr);
15304 
15305   effect(USE lbl);
15306 
15307   ins_cost(BRANCH_COST);
15308   // short variant.
15309   // ins_short_branch(1);
15310   format %{ &quot;b$cmp $lbl \t// counted loop end&quot; %}
15311 
15312   ins_encode(aarch64_enc_br_con(cmp, lbl));
15313 
15314   ins_pipe(pipe_branch);
15315 %}
15316 
15317 // counted loop end branch near Unsigned
15318 instruct branchLoopEndU(cmpOpU cmp, rFlagsRegU cr, label lbl)
15319 %{
15320   match(CountedLoopEnd cmp cr);
15321 
15322   effect(USE lbl);
15323 
15324   ins_cost(BRANCH_COST);
15325   // short variant.
15326   // ins_short_branch(1);
15327   format %{ &quot;b$cmp $lbl \t// counted loop end unsigned&quot; %}
15328 
15329   ins_encode(aarch64_enc_br_conU(cmp, lbl));
15330 
15331   ins_pipe(pipe_branch);
15332 %}
15333 
15334 // counted loop end branch far
15335 // counted loop end branch far unsigned
15336 // TODO: fixme
15337 
15338 // ============================================================================
15339 // inlined locking and unlocking
15340 
15341 instruct cmpFastLock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15342 %{
15343   match(Set cr (FastLock object box));
15344   effect(TEMP tmp, TEMP tmp2);
15345 
15346   // TODO
15347   // identify correct cost
15348   ins_cost(5 * INSN_COST);
15349   format %{ &quot;fastlock $object,$box\t! kills $tmp,$tmp2&quot; %}
15350 
15351   ins_encode(aarch64_enc_fast_lock(object, box, tmp, tmp2));
15352 
15353   ins_pipe(pipe_serial);
15354 %}
15355 
15356 instruct cmpFastUnlock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15357 %{
15358   match(Set cr (FastUnlock object box));
15359   effect(TEMP tmp, TEMP tmp2);
15360 
15361   ins_cost(5 * INSN_COST);
15362   format %{ &quot;fastunlock $object,$box\t! kills $tmp, $tmp2&quot; %}
15363 
15364   ins_encode(aarch64_enc_fast_unlock(object, box, tmp, tmp2));
15365 
15366   ins_pipe(pipe_serial);
15367 %}
15368 
15369 
15370 // ============================================================================
15371 // Safepoint Instructions
15372 
15373 // TODO
15374 // provide a near and far version of this code
15375 
15376 instruct safePoint(rFlagsReg cr, iRegP poll)
15377 %{
15378   match(SafePoint poll);
15379   effect(KILL cr);
15380 
15381   format %{
15382     &quot;ldrw zr, [$poll]\t# Safepoint: poll for GC&quot;
15383   %}
15384   ins_encode %{
15385     __ read_polling_page(as_Register($poll$$reg), relocInfo::poll_type);
15386   %}
15387   ins_pipe(pipe_serial); // ins_pipe(iload_reg_mem);
15388 %}
15389 
15390 
15391 // ============================================================================
15392 // Procedure Call/Return Instructions
15393 
15394 // Call Java Static Instruction
15395 
15396 instruct CallStaticJavaDirect(method meth)
15397 %{
15398   match(CallStaticJava);
15399 
15400   effect(USE meth);
15401 
15402   ins_cost(CALL_COST);
15403 
15404   format %{ &quot;call,static $meth \t// ==&gt; &quot; %}
15405 
15406   ins_encode( aarch64_enc_java_static_call(meth),
15407               aarch64_enc_call_epilog );
15408 
15409   ins_pipe(pipe_class_call);
15410 %}
15411 
15412 // TO HERE
15413 
15414 // Call Java Dynamic Instruction
15415 instruct CallDynamicJavaDirect(method meth)
15416 %{
15417   match(CallDynamicJava);
15418 
15419   effect(USE meth);
15420 
15421   ins_cost(CALL_COST);
15422 
15423   format %{ &quot;CALL,dynamic $meth \t// ==&gt; &quot; %}
15424 
15425   ins_encode( aarch64_enc_java_dynamic_call(meth),
15426                aarch64_enc_call_epilog );
15427 
15428   ins_pipe(pipe_class_call);
15429 %}
15430 
15431 // Call Runtime Instruction
15432 
15433 instruct CallRuntimeDirect(method meth)
15434 %{
15435   match(CallRuntime);
15436 
15437   effect(USE meth);
15438 
15439   ins_cost(CALL_COST);
15440 
15441   format %{ &quot;CALL, runtime $meth&quot; %}
15442 
15443   ins_encode( aarch64_enc_java_to_runtime(meth) );
15444 
15445   ins_pipe(pipe_class_call);
15446 %}
15447 
15448 // Call Runtime Instruction
15449 
15450 instruct CallLeafDirect(method meth)
15451 %{
15452   match(CallLeaf);
15453 
15454   effect(USE meth);
15455 
15456   ins_cost(CALL_COST);
15457 
15458   format %{ &quot;CALL, runtime leaf $meth&quot; %}
15459 
15460   ins_encode( aarch64_enc_java_to_runtime(meth) );
15461 
15462   ins_pipe(pipe_class_call);
15463 %}
15464 
15465 // Call Runtime Instruction
15466 
15467 instruct CallLeafNoFPDirect(method meth)
15468 %{
15469   match(CallLeafNoFP);
15470 
15471   effect(USE meth);
15472 
15473   ins_cost(CALL_COST);
15474 
15475   format %{ &quot;CALL, runtime leaf nofp $meth&quot; %}
15476 
15477   ins_encode( aarch64_enc_java_to_runtime(meth) );
15478 
15479   ins_pipe(pipe_class_call);
15480 %}
15481 
15482 // Tail Call; Jump from runtime stub to Java code.
15483 // Also known as an &#39;interprocedural jump&#39;.
15484 // Target of jump will eventually return to caller.
15485 // TailJump below removes the return address.
15486 instruct TailCalljmpInd(iRegPNoSp jump_target, inline_cache_RegP method_oop)
15487 %{
15488   match(TailCall jump_target method_oop);
15489 
15490   ins_cost(CALL_COST);
15491 
15492   format %{ &quot;br $jump_target\t# $method_oop holds method oop&quot; %}
15493 
15494   ins_encode(aarch64_enc_tail_call(jump_target));
15495 
15496   ins_pipe(pipe_class_call);
15497 %}
15498 
15499 instruct TailjmpInd(iRegPNoSp jump_target, iRegP_R0 ex_oop)
15500 %{
15501   match(TailJump jump_target ex_oop);
15502 
15503   ins_cost(CALL_COST);
15504 
15505   format %{ &quot;br $jump_target\t# $ex_oop holds exception oop&quot; %}
15506 
15507   ins_encode(aarch64_enc_tail_jmp(jump_target));
15508 
15509   ins_pipe(pipe_class_call);
15510 %}
15511 
15512 // Create exception oop: created by stack-crawling runtime code.
15513 // Created exception is now available to this handler, and is setup
15514 // just prior to jumping to this handler. No code emitted.
15515 // TODO check
15516 // should ex_oop be in r0? intel uses rax, ppc cannot use r0 so uses rarg1
15517 instruct CreateException(iRegP_R0 ex_oop)
15518 %{
15519   match(Set ex_oop (CreateEx));
15520 
15521   format %{ &quot; -- \t// exception oop; no code emitted&quot; %}
15522 
15523   size(0);
15524 
15525   ins_encode( /*empty*/ );
15526 
15527   ins_pipe(pipe_class_empty);
15528 %}
15529 
15530 // Rethrow exception: The exception oop will come in the first
15531 // argument position. Then JUMP (not call) to the rethrow stub code.
15532 instruct RethrowException() %{
15533   match(Rethrow);
15534   ins_cost(CALL_COST);
15535 
15536   format %{ &quot;b rethrow_stub&quot; %}
15537 
15538   ins_encode( aarch64_enc_rethrow() );
15539 
15540   ins_pipe(pipe_class_call);
15541 %}
15542 
15543 
15544 // Return Instruction
15545 // epilog node loads ret address into lr as part of frame pop
15546 instruct Ret()
15547 %{
15548   match(Return);
15549 
15550   format %{ &quot;ret\t// return register&quot; %}
15551 
15552   ins_encode( aarch64_enc_ret() );
15553 
15554   ins_pipe(pipe_branch);
15555 %}
15556 
15557 // Die now.
15558 instruct ShouldNotReachHere() %{
15559   match(Halt);
15560 
15561   ins_cost(CALL_COST);
15562   format %{ &quot;ShouldNotReachHere&quot; %}
15563 
15564   ins_encode %{
15565     if (is_reachable()) {
15566       __ stop(_halt_reason);
15567     }
15568   %}
15569 
15570   ins_pipe(pipe_class_default);
15571 %}
15572 
15573 // ============================================================================
15574 // Partial Subtype Check
15575 //
15576 // superklass array for an instance of the superklass.  Set a hidden
15577 // internal cache on a hit (cache is checked with exposed code in
15578 // gen_subtype_check()).  Return NZ for a miss or zero for a hit.  The
15579 // encoding ALSO sets flags.
15580 
15581 instruct partialSubtypeCheck(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, rFlagsReg cr)
15582 %{
15583   match(Set result (PartialSubtypeCheck sub super));
15584   effect(KILL cr, KILL temp);
15585 
15586   ins_cost(1100);  // slightly larger than the next version
15587   format %{ &quot;partialSubtypeCheck $result, $sub, $super&quot; %}
15588 
15589   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15590 
15591   opcode(0x1); // Force zero of result reg on hit
15592 
15593   ins_pipe(pipe_class_memory);
15594 %}
15595 
15596 instruct partialSubtypeCheckVsZero(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, immP0 zero, rFlagsReg cr)
15597 %{
15598   match(Set cr (CmpP (PartialSubtypeCheck sub super) zero));
15599   effect(KILL temp, KILL result);
15600 
15601   ins_cost(1100);  // slightly larger than the next version
15602   format %{ &quot;partialSubtypeCheck $result, $sub, $super == 0&quot; %}
15603 
15604   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15605 
15606   opcode(0x0); // Don&#39;t zero result reg on hit
15607 
15608   ins_pipe(pipe_class_memory);
15609 %}
15610 
15611 instruct string_compareU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15612                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15613 %{
15614   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15615   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15616   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15617 
15618   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15619   ins_encode %{
15620     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15621     __ string_compare($str1$$Register, $str2$$Register,
15622                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15623                       $tmp1$$Register, $tmp2$$Register,
15624                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::UU);
15625   %}
15626   ins_pipe(pipe_class_memory);
15627 %}
15628 
15629 instruct string_compareL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15630                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15631 %{
15632   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15633   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15634   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15635 
15636   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15637   ins_encode %{
15638     __ string_compare($str1$$Register, $str2$$Register,
15639                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15640                       $tmp1$$Register, $tmp2$$Register,
15641                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::LL);
15642   %}
15643   ins_pipe(pipe_class_memory);
15644 %}
15645 
15646 instruct string_compareUL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15647                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15648                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15649 %{
15650   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15651   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15652   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15653          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15654 
15655   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15656   ins_encode %{
15657     __ string_compare($str1$$Register, $str2$$Register,
15658                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15659                       $tmp1$$Register, $tmp2$$Register,
15660                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15661                       $vtmp3$$FloatRegister, StrIntrinsicNode::UL);
15662   %}
15663   ins_pipe(pipe_class_memory);
15664 %}
15665 
15666 instruct string_compareLU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15667                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15668                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15669 %{
15670   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LU);
15671   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15672   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15673          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15674 
15675   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15676   ins_encode %{
15677     __ string_compare($str1$$Register, $str2$$Register,
15678                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15679                       $tmp1$$Register, $tmp2$$Register,
15680                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15681                       $vtmp3$$FloatRegister,StrIntrinsicNode::LU);
15682   %}
15683   ins_pipe(pipe_class_memory);
15684 %}
15685 
15686 instruct string_indexofUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15687        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15688        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15689 %{
15690   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15691   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15692   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15693          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15694   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UU)&quot; %}
15695 
15696   ins_encode %{
15697     __ string_indexof($str1$$Register, $str2$$Register,
15698                       $cnt1$$Register, $cnt2$$Register,
15699                       $tmp1$$Register, $tmp2$$Register,
15700                       $tmp3$$Register, $tmp4$$Register,
15701                       $tmp5$$Register, $tmp6$$Register,
15702                       -1, $result$$Register, StrIntrinsicNode::UU);
15703   %}
15704   ins_pipe(pipe_class_memory);
15705 %}
15706 
15707 instruct string_indexofLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15708        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15709        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15710 %{
15711   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15712   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15713   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15714          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15715   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (LL)&quot; %}
15716 
15717   ins_encode %{
15718     __ string_indexof($str1$$Register, $str2$$Register,
15719                       $cnt1$$Register, $cnt2$$Register,
15720                       $tmp1$$Register, $tmp2$$Register,
15721                       $tmp3$$Register, $tmp4$$Register,
15722                       $tmp5$$Register, $tmp6$$Register,
15723                       -1, $result$$Register, StrIntrinsicNode::LL);
15724   %}
15725   ins_pipe(pipe_class_memory);
15726 %}
15727 
15728 instruct string_indexofUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15729        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15730        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15731 %{
15732   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15733   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15734   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15735          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15736   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UL)&quot; %}
15737 
15738   ins_encode %{
15739     __ string_indexof($str1$$Register, $str2$$Register,
15740                       $cnt1$$Register, $cnt2$$Register,
15741                       $tmp1$$Register, $tmp2$$Register,
15742                       $tmp3$$Register, $tmp4$$Register,
15743                       $tmp5$$Register, $tmp6$$Register,
15744                       -1, $result$$Register, StrIntrinsicNode::UL);
15745   %}
15746   ins_pipe(pipe_class_memory);
15747 %}
15748 
15749 instruct string_indexof_conUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15750                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15751                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15752 %{
15753   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15754   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15755   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15756          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15757   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UU)&quot; %}
15758 
15759   ins_encode %{
15760     int icnt2 = (int)$int_cnt2$$constant;
15761     __ string_indexof($str1$$Register, $str2$$Register,
15762                       $cnt1$$Register, zr,
15763                       $tmp1$$Register, $tmp2$$Register,
15764                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15765                       icnt2, $result$$Register, StrIntrinsicNode::UU);
15766   %}
15767   ins_pipe(pipe_class_memory);
15768 %}
15769 
15770 instruct string_indexof_conLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15771                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15772                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15773 %{
15774   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15775   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15776   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15777          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15778   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (LL)&quot; %}
15779 
15780   ins_encode %{
15781     int icnt2 = (int)$int_cnt2$$constant;
15782     __ string_indexof($str1$$Register, $str2$$Register,
15783                       $cnt1$$Register, zr,
15784                       $tmp1$$Register, $tmp2$$Register,
15785                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15786                       icnt2, $result$$Register, StrIntrinsicNode::LL);
15787   %}
15788   ins_pipe(pipe_class_memory);
15789 %}
15790 
15791 instruct string_indexof_conUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15792                  immI_1 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15793                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15794 %{
15795   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15796   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15797   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15798          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15799   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UL)&quot; %}
15800 
15801   ins_encode %{
15802     int icnt2 = (int)$int_cnt2$$constant;
15803     __ string_indexof($str1$$Register, $str2$$Register,
15804                       $cnt1$$Register, zr,
15805                       $tmp1$$Register, $tmp2$$Register,
15806                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15807                       icnt2, $result$$Register, StrIntrinsicNode::UL);
15808   %}
15809   ins_pipe(pipe_class_memory);
15810 %}
15811 
15812 instruct string_indexofU_char(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,
15813                               iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15814                               iRegINoSp tmp3, rFlagsReg cr)
15815 %{
15816   match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));
15817   effect(USE_KILL str1, USE_KILL cnt1, USE_KILL ch,
15818          TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15819 
15820   format %{ &quot;String IndexOf char[] $str1,$cnt1,$ch -&gt; $result&quot; %}
15821 
15822   ins_encode %{
15823     __ string_indexof_char($str1$$Register, $cnt1$$Register, $ch$$Register,
15824                            $result$$Register, $tmp1$$Register, $tmp2$$Register,
15825                            $tmp3$$Register);
15826   %}
15827   ins_pipe(pipe_class_memory);
15828 %}
15829 
15830 instruct string_equalsL(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15831                         iRegI_R0 result, rFlagsReg cr)
15832 %{
15833   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15834   match(Set result (StrEquals (Binary str1 str2) cnt));
15835   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15836 
15837   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15838   ins_encode %{
15839     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15840     __ string_equals($str1$$Register, $str2$$Register,
15841                      $result$$Register, $cnt$$Register, 1);
15842   %}
15843   ins_pipe(pipe_class_memory);
15844 %}
15845 
15846 instruct string_equalsU(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15847                         iRegI_R0 result, rFlagsReg cr)
15848 %{
15849   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15850   match(Set result (StrEquals (Binary str1 str2) cnt));
15851   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15852 
15853   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15854   ins_encode %{
15855     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15856     __ string_equals($str1$$Register, $str2$$Register,
15857                      $result$$Register, $cnt$$Register, 2);
15858   %}
15859   ins_pipe(pipe_class_memory);
15860 %}
15861 
15862 instruct array_equalsB(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15863                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15864                        iRegP_R10 tmp, rFlagsReg cr)
15865 %{
15866   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15867   match(Set result (AryEq ary1 ary2));
15868   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15869 
15870   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15871   ins_encode %{
15872     __ arrays_equals($ary1$$Register, $ary2$$Register,
15873                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15874                      $result$$Register, $tmp$$Register, 1);
15875     %}
15876   ins_pipe(pipe_class_memory);
15877 %}
15878 
15879 instruct array_equalsC(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15880                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15881                        iRegP_R10 tmp, rFlagsReg cr)
15882 %{
15883   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15884   match(Set result (AryEq ary1 ary2));
15885   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15886 
15887   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15888   ins_encode %{
15889     __ arrays_equals($ary1$$Register, $ary2$$Register,
15890                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15891                      $result$$Register, $tmp$$Register, 2);
15892   %}
15893   ins_pipe(pipe_class_memory);
15894 %}
15895 
15896 instruct has_negatives(iRegP_R1 ary1, iRegI_R2 len, iRegI_R0 result, rFlagsReg cr)
15897 %{
15898   match(Set result (HasNegatives ary1 len));
15899   effect(USE_KILL ary1, USE_KILL len, KILL cr);
15900   format %{ &quot;has negatives byte[] $ary1,$len -&gt; $result&quot; %}
15901   ins_encode %{
15902     __ has_negatives($ary1$$Register, $len$$Register, $result$$Register);
15903   %}
15904   ins_pipe( pipe_slow );
15905 %}
15906 
15907 // fast char[] to byte[] compression
15908 instruct string_compress(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15909                          vRegD_V0 tmp1, vRegD_V1 tmp2,
15910                          vRegD_V2 tmp3, vRegD_V3 tmp4,
15911                          iRegI_R0 result, rFlagsReg cr)
15912 %{
15913   match(Set result (StrCompressedCopy src (Binary dst len)));
15914   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15915 
15916   format %{ &quot;String Compress $src,$dst -&gt; $result    // KILL R1, R2, R3, R4&quot; %}
15917   ins_encode %{
15918     __ char_array_compress($src$$Register, $dst$$Register, $len$$Register,
15919                            $tmp1$$FloatRegister, $tmp2$$FloatRegister,
15920                            $tmp3$$FloatRegister, $tmp4$$FloatRegister,
15921                            $result$$Register);
15922   %}
15923   ins_pipe( pipe_slow );
15924 %}
15925 
15926 // fast byte[] to char[] inflation
15927 instruct string_inflate(Universe dummy, iRegP_R0 src, iRegP_R1 dst, iRegI_R2 len,
15928                         vRegD_V0 tmp1, vRegD_V1 tmp2, vRegD_V2 tmp3, iRegP_R3 tmp4, rFlagsReg cr)
15929 %{
15930   match(Set dummy (StrInflatedCopy src (Binary dst len)));
15931   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15932 
15933   format %{ &quot;String Inflate $src,$dst    // KILL $tmp1, $tmp2&quot; %}
15934   ins_encode %{
15935     __ byte_array_inflate($src$$Register, $dst$$Register, $len$$Register,
15936                           $tmp1$$FloatRegister, $tmp2$$FloatRegister, $tmp3$$FloatRegister, $tmp4$$Register);
15937   %}
15938   ins_pipe(pipe_class_memory);
15939 %}
15940 
15941 // encode char[] to byte[] in ISO_8859_1
15942 instruct encode_iso_array(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15943                           vRegD_V0 Vtmp1, vRegD_V1 Vtmp2,
15944                           vRegD_V2 Vtmp3, vRegD_V3 Vtmp4,
15945                           iRegI_R0 result, rFlagsReg cr)
15946 %{
15947   match(Set result (EncodeISOArray src (Binary dst len)));
15948   effect(USE_KILL src, USE_KILL dst, USE_KILL len,
15949          KILL Vtmp1, KILL Vtmp2, KILL Vtmp3, KILL Vtmp4, KILL cr);
15950 
15951   format %{ &quot;Encode array $src,$dst,$len -&gt; $result&quot; %}
15952   ins_encode %{
15953     __ encode_iso_array($src$$Register, $dst$$Register, $len$$Register,
15954          $result$$Register, $Vtmp1$$FloatRegister,  $Vtmp2$$FloatRegister,
15955          $Vtmp3$$FloatRegister,  $Vtmp4$$FloatRegister);
15956   %}
15957   ins_pipe( pipe_class_memory );
15958 %}
15959 
15960 // ============================================================================
15961 // This name is KNOWN by the ADLC and cannot be changed.
15962 // The ADLC forces a &#39;TypeRawPtr::BOTTOM&#39; output type
15963 // for this guy.
15964 instruct tlsLoadP(thread_RegP dst)
15965 %{
15966   match(Set dst (ThreadLocal));
15967 
15968   ins_cost(0);
15969 
15970   format %{ &quot; -- \t// $dst=Thread::current(), empty&quot; %}
15971 
15972   size(0);
15973 
15974   ins_encode( /*empty*/ );
15975 
15976   ins_pipe(pipe_class_empty);
15977 %}
15978 
15979 // ====================VECTOR INSTRUCTIONS=====================================
15980 
15981 // Load vector (32 bits)
15982 instruct loadV4(vecD dst, vmem4 mem)
15983 %{
15984   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 4);
15985   match(Set dst (LoadVector mem));
15986   ins_cost(4 * INSN_COST);
15987   format %{ &quot;ldrs   $dst,$mem\t# vector (32 bits)&quot; %}
15988   ins_encode( aarch64_enc_ldrvS(dst, mem) );
15989   ins_pipe(vload_reg_mem64);
15990 %}
15991 
15992 // Load vector (64 bits)
15993 instruct loadV8(vecD dst, vmem8 mem)
15994 %{
15995   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 8);
15996   match(Set dst (LoadVector mem));
15997   ins_cost(4 * INSN_COST);
15998   format %{ &quot;ldrd   $dst,$mem\t# vector (64 bits)&quot; %}
15999   ins_encode( aarch64_enc_ldrvD(dst, mem) );
16000   ins_pipe(vload_reg_mem64);
16001 %}
16002 
16003 // Load Vector (128 bits)
16004 instruct loadV16(vecX dst, vmem16 mem)
16005 %{
16006   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 16);
16007   match(Set dst (LoadVector mem));
16008   ins_cost(4 * INSN_COST);
16009   format %{ &quot;ldrq   $dst,$mem\t# vector (128 bits)&quot; %}
16010   ins_encode( aarch64_enc_ldrvQ(dst, mem) );
16011   ins_pipe(vload_reg_mem128);
16012 %}
16013 
16014 // Store Vector (32 bits)
16015 instruct storeV4(vecD src, vmem4 mem)
16016 %{
16017   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 4);
16018   match(Set mem (StoreVector mem src));
16019   ins_cost(4 * INSN_COST);
16020   format %{ &quot;strs   $mem,$src\t# vector (32 bits)&quot; %}
16021   ins_encode( aarch64_enc_strvS(src, mem) );
16022   ins_pipe(vstore_reg_mem64);
16023 %}
16024 
16025 // Store Vector (64 bits)
16026 instruct storeV8(vecD src, vmem8 mem)
16027 %{
16028   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 8);
16029   match(Set mem (StoreVector mem src));
16030   ins_cost(4 * INSN_COST);
16031   format %{ &quot;strd   $mem,$src\t# vector (64 bits)&quot; %}
16032   ins_encode( aarch64_enc_strvD(src, mem) );
16033   ins_pipe(vstore_reg_mem64);
16034 %}
16035 
16036 // Store Vector (128 bits)
16037 instruct storeV16(vecX src, vmem16 mem)
16038 %{
16039   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 16);
16040   match(Set mem (StoreVector mem src));
16041   ins_cost(4 * INSN_COST);
16042   format %{ &quot;strq   $mem,$src\t# vector (128 bits)&quot; %}
16043   ins_encode( aarch64_enc_strvQ(src, mem) );
16044   ins_pipe(vstore_reg_mem128);
16045 %}
16046 
16047 instruct replicate8B(vecD dst, iRegIorL2I src)
16048 %{
16049   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16050             n-&gt;as_Vector()-&gt;length() == 8);
16051   match(Set dst (ReplicateB src));
16052   ins_cost(INSN_COST);
16053   format %{ &quot;dup  $dst, $src\t# vector (8B)&quot; %}
16054   ins_encode %{
16055     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($src$$reg));
16056   %}
16057   ins_pipe(vdup_reg_reg64);
16058 %}
16059 
16060 instruct replicate16B(vecX dst, iRegIorL2I src)
16061 %{
16062   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16063   match(Set dst (ReplicateB src));
16064   ins_cost(INSN_COST);
16065   format %{ &quot;dup  $dst, $src\t# vector (16B)&quot; %}
16066   ins_encode %{
16067     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($src$$reg));
16068   %}
16069   ins_pipe(vdup_reg_reg128);
16070 %}
16071 
16072 instruct replicate8B_imm(vecD dst, immI con)
16073 %{
16074   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16075             n-&gt;as_Vector()-&gt;length() == 8);
16076   match(Set dst (ReplicateB con));
16077   ins_cost(INSN_COST);
16078   format %{ &quot;movi  $dst, $con\t# vector(8B)&quot; %}
16079   ins_encode %{
16080     __ mov(as_FloatRegister($dst$$reg), __ T8B, $con$$constant &amp; 0xff);
16081   %}
16082   ins_pipe(vmovi_reg_imm64);
16083 %}
16084 
16085 instruct replicate16B_imm(vecX dst, immI con)
16086 %{
16087   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16088   match(Set dst (ReplicateB con));
16089   ins_cost(INSN_COST);
16090   format %{ &quot;movi  $dst, $con\t# vector(16B)&quot; %}
16091   ins_encode %{
16092     __ mov(as_FloatRegister($dst$$reg), __ T16B, $con$$constant &amp; 0xff);
16093   %}
16094   ins_pipe(vmovi_reg_imm128);
16095 %}
16096 
16097 instruct replicate4S(vecD dst, iRegIorL2I src)
16098 %{
16099   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16100             n-&gt;as_Vector()-&gt;length() == 4);
16101   match(Set dst (ReplicateS src));
16102   ins_cost(INSN_COST);
16103   format %{ &quot;dup  $dst, $src\t# vector (4S)&quot; %}
16104   ins_encode %{
16105     __ dup(as_FloatRegister($dst$$reg), __ T4H, as_Register($src$$reg));
16106   %}
16107   ins_pipe(vdup_reg_reg64);
16108 %}
16109 
16110 instruct replicate8S(vecX dst, iRegIorL2I src)
16111 %{
16112   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16113   match(Set dst (ReplicateS src));
16114   ins_cost(INSN_COST);
16115   format %{ &quot;dup  $dst, $src\t# vector (8S)&quot; %}
16116   ins_encode %{
16117     __ dup(as_FloatRegister($dst$$reg), __ T8H, as_Register($src$$reg));
16118   %}
16119   ins_pipe(vdup_reg_reg128);
16120 %}
16121 
16122 instruct replicate4S_imm(vecD dst, immI con)
16123 %{
16124   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16125             n-&gt;as_Vector()-&gt;length() == 4);
16126   match(Set dst (ReplicateS con));
16127   ins_cost(INSN_COST);
16128   format %{ &quot;movi  $dst, $con\t# vector(4H)&quot; %}
16129   ins_encode %{
16130     __ mov(as_FloatRegister($dst$$reg), __ T4H, $con$$constant &amp; 0xffff);
16131   %}
16132   ins_pipe(vmovi_reg_imm64);
16133 %}
16134 
16135 instruct replicate8S_imm(vecX dst, immI con)
16136 %{
16137   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16138   match(Set dst (ReplicateS con));
16139   ins_cost(INSN_COST);
16140   format %{ &quot;movi  $dst, $con\t# vector(8H)&quot; %}
16141   ins_encode %{
16142     __ mov(as_FloatRegister($dst$$reg), __ T8H, $con$$constant &amp; 0xffff);
16143   %}
16144   ins_pipe(vmovi_reg_imm128);
16145 %}
16146 
16147 instruct replicate2I(vecD dst, iRegIorL2I src)
16148 %{
16149   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16150   match(Set dst (ReplicateI src));
16151   ins_cost(INSN_COST);
16152   format %{ &quot;dup  $dst, $src\t# vector (2I)&quot; %}
16153   ins_encode %{
16154     __ dup(as_FloatRegister($dst$$reg), __ T2S, as_Register($src$$reg));
16155   %}
16156   ins_pipe(vdup_reg_reg64);
16157 %}
16158 
16159 instruct replicate4I(vecX dst, iRegIorL2I src)
16160 %{
16161   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16162   match(Set dst (ReplicateI src));
16163   ins_cost(INSN_COST);
16164   format %{ &quot;dup  $dst, $src\t# vector (4I)&quot; %}
16165   ins_encode %{
16166     __ dup(as_FloatRegister($dst$$reg), __ T4S, as_Register($src$$reg));
16167   %}
16168   ins_pipe(vdup_reg_reg128);
16169 %}
16170 
16171 instruct replicate2I_imm(vecD dst, immI con)
16172 %{
16173   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16174   match(Set dst (ReplicateI con));
16175   ins_cost(INSN_COST);
16176   format %{ &quot;movi  $dst, $con\t# vector(2I)&quot; %}
16177   ins_encode %{
16178     __ mov(as_FloatRegister($dst$$reg), __ T2S, $con$$constant);
16179   %}
16180   ins_pipe(vmovi_reg_imm64);
16181 %}
16182 
16183 instruct replicate4I_imm(vecX dst, immI con)
16184 %{
16185   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16186   match(Set dst (ReplicateI con));
16187   ins_cost(INSN_COST);
16188   format %{ &quot;movi  $dst, $con\t# vector(4I)&quot; %}
16189   ins_encode %{
16190     __ mov(as_FloatRegister($dst$$reg), __ T4S, $con$$constant);
16191   %}
16192   ins_pipe(vmovi_reg_imm128);
16193 %}
16194 
16195 instruct replicate2L(vecX dst, iRegL src)
16196 %{
16197   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16198   match(Set dst (ReplicateL src));
16199   ins_cost(INSN_COST);
16200   format %{ &quot;dup  $dst, $src\t# vector (2L)&quot; %}
16201   ins_encode %{
16202     __ dup(as_FloatRegister($dst$$reg), __ T2D, as_Register($src$$reg));
16203   %}
16204   ins_pipe(vdup_reg_reg128);
16205 %}
16206 
16207 instruct replicate2L_zero(vecX dst, immI0 zero)
16208 %{
16209   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16210   match(Set dst (ReplicateI zero));
16211   ins_cost(INSN_COST);
16212   format %{ &quot;movi  $dst, $zero\t# vector(4I)&quot; %}
16213   ins_encode %{
16214     __ eor(as_FloatRegister($dst$$reg), __ T16B,
16215            as_FloatRegister($dst$$reg),
16216            as_FloatRegister($dst$$reg));
16217   %}
16218   ins_pipe(vmovi_reg_imm128);
16219 %}
16220 
16221 instruct replicate2F(vecD dst, vRegF src)
16222 %{
16223   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16224   match(Set dst (ReplicateF src));
16225   ins_cost(INSN_COST);
16226   format %{ &quot;dup  $dst, $src\t# vector (2F)&quot; %}
16227   ins_encode %{
16228     __ dup(as_FloatRegister($dst$$reg), __ T2S,
16229            as_FloatRegister($src$$reg));
16230   %}
16231   ins_pipe(vdup_reg_freg64);
16232 %}
16233 
16234 instruct replicate4F(vecX dst, vRegF src)
16235 %{
16236   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16237   match(Set dst (ReplicateF src));
16238   ins_cost(INSN_COST);
16239   format %{ &quot;dup  $dst, $src\t# vector (4F)&quot; %}
16240   ins_encode %{
16241     __ dup(as_FloatRegister($dst$$reg), __ T4S,
16242            as_FloatRegister($src$$reg));
16243   %}
16244   ins_pipe(vdup_reg_freg128);
16245 %}
16246 
16247 instruct replicate2D(vecX dst, vRegD src)
16248 %{
16249   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16250   match(Set dst (ReplicateD src));
16251   ins_cost(INSN_COST);
16252   format %{ &quot;dup  $dst, $src\t# vector (2D)&quot; %}
16253   ins_encode %{
16254     __ dup(as_FloatRegister($dst$$reg), __ T2D,
16255            as_FloatRegister($src$$reg));
16256   %}
16257   ins_pipe(vdup_reg_dreg128);
16258 %}
16259 
16260 // ====================REDUCTION ARITHMETIC====================================
16261 
16262 instruct reduce_add2I(iRegINoSp dst, iRegIorL2I isrc, vecD vsrc, iRegINoSp tmp, iRegINoSp tmp2)
16263 %{
16264   match(Set dst (AddReductionVI isrc vsrc));
16265   ins_cost(INSN_COST);
16266   effect(TEMP tmp, TEMP tmp2);
16267   format %{ &quot;umov  $tmp, $vsrc, S, 0\n\t&quot;
16268             &quot;umov  $tmp2, $vsrc, S, 1\n\t&quot;
16269             &quot;addw  $tmp, $isrc, $tmp\n\t&quot;
16270             &quot;addw  $dst, $tmp, $tmp2\t# add reduction2I&quot;
16271   %}
16272   ins_encode %{
16273     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 0);
16274     __ umov($tmp2$$Register, as_FloatRegister($vsrc$$reg), __ S, 1);
16275     __ addw($tmp$$Register, $isrc$$Register, $tmp$$Register);
16276     __ addw($dst$$Register, $tmp$$Register, $tmp2$$Register);
16277   %}
16278   ins_pipe(pipe_class_default);
16279 %}
16280 
16281 instruct reduce_add4I(iRegINoSp dst, iRegIorL2I isrc, vecX vsrc, vecX vtmp, iRegINoSp itmp)
16282 %{
16283   match(Set dst (AddReductionVI isrc vsrc));
16284   ins_cost(INSN_COST);
16285   effect(TEMP vtmp, TEMP itmp);
16286   format %{ &quot;addv  $vtmp, T4S, $vsrc\n\t&quot;
16287             &quot;umov  $itmp, $vtmp, S, 0\n\t&quot;
16288             &quot;addw  $dst, $itmp, $isrc\t# add reduction4I&quot;
16289   %}
16290   ins_encode %{
16291     __ addv(as_FloatRegister($vtmp$$reg), __ T4S,
16292             as_FloatRegister($vsrc$$reg));
16293     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 0);
16294     __ addw($dst$$Register, $itmp$$Register, $isrc$$Register);
16295   %}
16296   ins_pipe(pipe_class_default);
16297 %}
16298 
16299 instruct reduce_mul2I(iRegINoSp dst, iRegIorL2I isrc, vecD vsrc, iRegINoSp tmp)
16300 %{
16301   match(Set dst (MulReductionVI isrc vsrc));
16302   ins_cost(INSN_COST);
16303   effect(TEMP tmp, TEMP dst);
16304   format %{ &quot;umov  $tmp, $vsrc, S, 0\n\t&quot;
16305             &quot;mul   $dst, $tmp, $isrc\n\t&quot;
16306             &quot;umov  $tmp, $vsrc, S, 1\n\t&quot;
16307             &quot;mul   $dst, $tmp, $dst\t# mul reduction2I&quot;
16308   %}
16309   ins_encode %{
16310     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 0);
16311     __ mul($dst$$Register, $tmp$$Register, $isrc$$Register);
16312     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 1);
16313     __ mul($dst$$Register, $tmp$$Register, $dst$$Register);
16314   %}
16315   ins_pipe(pipe_class_default);
16316 %}
16317 
16318 instruct reduce_mul4I(iRegINoSp dst, iRegIorL2I isrc, vecX vsrc, vecX vtmp, iRegINoSp itmp)
16319 %{
16320   match(Set dst (MulReductionVI isrc vsrc));
16321   ins_cost(INSN_COST);
16322   effect(TEMP vtmp, TEMP itmp, TEMP dst);
16323   format %{ &quot;ins   $vtmp, D, $vsrc, 0, 1\n\t&quot;
16324             &quot;mulv  $vtmp, T2S, $vtmp, $vsrc\n\t&quot;
16325             &quot;umov  $itmp, $vtmp, S, 0\n\t&quot;
16326             &quot;mul   $dst, $itmp, $isrc\n\t&quot;
16327             &quot;umov  $itmp, $vtmp, S, 1\n\t&quot;
16328             &quot;mul   $dst, $itmp, $dst\t# mul reduction4I&quot;
16329   %}
16330   ins_encode %{
16331     __ ins(as_FloatRegister($vtmp$$reg), __ D,
16332            as_FloatRegister($vsrc$$reg), 0, 1);
16333     __ mulv(as_FloatRegister($vtmp$$reg), __ T2S,
16334             as_FloatRegister($vtmp$$reg), as_FloatRegister($vsrc$$reg));
16335     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 0);
16336     __ mul($dst$$Register, $itmp$$Register, $isrc$$Register);
16337     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 1);
16338     __ mul($dst$$Register, $itmp$$Register, $dst$$Register);
16339   %}
16340   ins_pipe(pipe_class_default);
16341 %}
16342 
16343 instruct reduce_add2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp)
16344 %{
16345   match(Set dst (AddReductionVF fsrc vsrc));
16346   ins_cost(INSN_COST);
16347   effect(TEMP tmp, TEMP dst);
16348   format %{ &quot;fadds $dst, $fsrc, $vsrc\n\t&quot;
16349             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16350             &quot;fadds $dst, $dst, $tmp\t# add reduction2F&quot;
16351   %}
16352   ins_encode %{
16353     __ fadds(as_FloatRegister($dst$$reg),
16354              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16355     __ ins(as_FloatRegister($tmp$$reg), __ S,
16356            as_FloatRegister($vsrc$$reg), 0, 1);
16357     __ fadds(as_FloatRegister($dst$$reg),
16358              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16359   %}
16360   ins_pipe(pipe_class_default);
16361 %}
16362 
16363 instruct reduce_add4F(vRegF dst, vRegF fsrc, vecX vsrc, vecX tmp)
16364 %{
16365   match(Set dst (AddReductionVF fsrc vsrc));
16366   ins_cost(INSN_COST);
16367   effect(TEMP tmp, TEMP dst);
16368   format %{ &quot;fadds $dst, $fsrc, $vsrc\n\t&quot;
16369             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16370             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16371             &quot;ins   $tmp, S, $vsrc, 0, 2\n\t&quot;
16372             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16373             &quot;ins   $tmp, S, $vsrc, 0, 3\n\t&quot;
16374             &quot;fadds $dst, $dst, $tmp\t# add reduction4F&quot;
16375   %}
16376   ins_encode %{
16377     __ fadds(as_FloatRegister($dst$$reg),
16378              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16379     __ ins(as_FloatRegister($tmp$$reg), __ S,
16380            as_FloatRegister($vsrc$$reg), 0, 1);
16381     __ fadds(as_FloatRegister($dst$$reg),
16382              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16383     __ ins(as_FloatRegister($tmp$$reg), __ S,
16384            as_FloatRegister($vsrc$$reg), 0, 2);
16385     __ fadds(as_FloatRegister($dst$$reg),
16386              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16387     __ ins(as_FloatRegister($tmp$$reg), __ S,
16388            as_FloatRegister($vsrc$$reg), 0, 3);
16389     __ fadds(as_FloatRegister($dst$$reg),
16390              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16391   %}
16392   ins_pipe(pipe_class_default);
16393 %}
16394 
16395 instruct reduce_mul2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp)
16396 %{
16397   match(Set dst (MulReductionVF fsrc vsrc));
16398   ins_cost(INSN_COST);
16399   effect(TEMP tmp, TEMP dst);
16400   format %{ &quot;fmuls $dst, $fsrc, $vsrc\n\t&quot;
16401             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16402             &quot;fmuls $dst, $dst, $tmp\t# mul reduction2F&quot;
16403   %}
16404   ins_encode %{
16405     __ fmuls(as_FloatRegister($dst$$reg),
16406              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16407     __ ins(as_FloatRegister($tmp$$reg), __ S,
16408            as_FloatRegister($vsrc$$reg), 0, 1);
16409     __ fmuls(as_FloatRegister($dst$$reg),
16410              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16411   %}
16412   ins_pipe(pipe_class_default);
16413 %}
16414 
16415 instruct reduce_mul4F(vRegF dst, vRegF fsrc, vecX vsrc, vecX tmp)
16416 %{
16417   match(Set dst (MulReductionVF fsrc vsrc));
16418   ins_cost(INSN_COST);
16419   effect(TEMP tmp, TEMP dst);
16420   format %{ &quot;fmuls $dst, $fsrc, $vsrc\n\t&quot;
16421             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16422             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16423             &quot;ins   $tmp, S, $vsrc, 0, 2\n\t&quot;
16424             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16425             &quot;ins   $tmp, S, $vsrc, 0, 3\n\t&quot;
16426             &quot;fmuls $dst, $dst, $tmp\t# mul reduction4F&quot;
16427   %}
16428   ins_encode %{
16429     __ fmuls(as_FloatRegister($dst$$reg),
16430              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16431     __ ins(as_FloatRegister($tmp$$reg), __ S,
16432            as_FloatRegister($vsrc$$reg), 0, 1);
16433     __ fmuls(as_FloatRegister($dst$$reg),
16434              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16435     __ ins(as_FloatRegister($tmp$$reg), __ S,
16436            as_FloatRegister($vsrc$$reg), 0, 2);
16437     __ fmuls(as_FloatRegister($dst$$reg),
16438              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16439     __ ins(as_FloatRegister($tmp$$reg), __ S,
16440            as_FloatRegister($vsrc$$reg), 0, 3);
16441     __ fmuls(as_FloatRegister($dst$$reg),
16442              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16443   %}
16444   ins_pipe(pipe_class_default);
16445 %}
16446 
16447 instruct reduce_add2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp)
16448 %{
16449   match(Set dst (AddReductionVD dsrc vsrc));
16450   ins_cost(INSN_COST);
16451   effect(TEMP tmp, TEMP dst);
16452   format %{ &quot;faddd $dst, $dsrc, $vsrc\n\t&quot;
16453             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16454             &quot;faddd $dst, $dst, $tmp\t# add reduction2D&quot;
16455   %}
16456   ins_encode %{
16457     __ faddd(as_FloatRegister($dst$$reg),
16458              as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16459     __ ins(as_FloatRegister($tmp$$reg), __ D,
16460            as_FloatRegister($vsrc$$reg), 0, 1);
16461     __ faddd(as_FloatRegister($dst$$reg),
16462              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16463   %}
16464   ins_pipe(pipe_class_default);
16465 %}
16466 
16467 instruct reduce_mul2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp)
16468 %{
16469   match(Set dst (MulReductionVD dsrc vsrc));
16470   ins_cost(INSN_COST);
16471   effect(TEMP tmp, TEMP dst);
16472   format %{ &quot;fmuld $dst, $dsrc, $vsrc\n\t&quot;
16473             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16474             &quot;fmuld $dst, $dst, $tmp\t# mul reduction2D&quot;
16475   %}
16476   ins_encode %{
16477     __ fmuld(as_FloatRegister($dst$$reg),
16478              as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16479     __ ins(as_FloatRegister($tmp$$reg), __ D,
16480            as_FloatRegister($vsrc$$reg), 0, 1);
16481     __ fmuld(as_FloatRegister($dst$$reg),
16482              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16483   %}
16484   ins_pipe(pipe_class_default);
16485 %}
16486 
16487 instruct reduce_max2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp) %{
16488   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16489   match(Set dst (MaxReductionV fsrc vsrc));
16490   ins_cost(INSN_COST);
16491   effect(TEMP_DEF dst, TEMP tmp);
16492   format %{ &quot;fmaxs $dst, $fsrc, $vsrc\n\t&quot;
16493             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16494             &quot;fmaxs $dst, $dst, $tmp\t# max reduction2F&quot; %}
16495   ins_encode %{
16496     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16497     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($vsrc$$reg), 0, 1);
16498     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16499   %}
16500   ins_pipe(pipe_class_default);
16501 %}
16502 
16503 instruct reduce_max4F(vRegF dst, vRegF fsrc, vecX vsrc) %{
16504   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16505   match(Set dst (MaxReductionV fsrc vsrc));
16506   ins_cost(INSN_COST);
16507   effect(TEMP_DEF dst);
16508   format %{ &quot;fmaxv $dst, T4S, $vsrc\n\t&quot;
16509             &quot;fmaxs $dst, $dst, $fsrc\t# max reduction4F&quot; %}
16510   ins_encode %{
16511     __ fmaxv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($vsrc$$reg));
16512     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));
16513   %}
16514   ins_pipe(pipe_class_default);
16515 %}
16516 
16517 instruct reduce_max2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp) %{
16518   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16519   match(Set dst (MaxReductionV dsrc vsrc));
16520   ins_cost(INSN_COST);
16521   effect(TEMP_DEF dst, TEMP tmp);
16522   format %{ &quot;fmaxd $dst, $dsrc, $vsrc\n\t&quot;
16523             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16524             &quot;fmaxd $dst, $dst, $tmp\t# max reduction2D&quot; %}
16525   ins_encode %{
16526     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16527     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($vsrc$$reg), 0, 1);
16528     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16529   %}
16530   ins_pipe(pipe_class_default);
16531 %}
16532 
16533 instruct reduce_min2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp) %{
16534   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16535   match(Set dst (MinReductionV fsrc vsrc));
16536   ins_cost(INSN_COST);
16537   effect(TEMP_DEF dst, TEMP tmp);
16538   format %{ &quot;fmins $dst, $fsrc, $vsrc\n\t&quot;
16539             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16540             &quot;fmins $dst, $dst, $tmp\t# min reduction2F&quot; %}
16541   ins_encode %{
16542     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16543     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($vsrc$$reg), 0, 1);
16544     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16545   %}
16546   ins_pipe(pipe_class_default);
16547 %}
16548 
16549 instruct reduce_min4F(vRegF dst, vRegF fsrc, vecX vsrc) %{
16550   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16551   match(Set dst (MinReductionV fsrc vsrc));
16552   ins_cost(INSN_COST);
16553   effect(TEMP_DEF dst);
16554   format %{ &quot;fminv $dst, T4S, $vsrc\n\t&quot;
16555             &quot;fmins $dst, $dst, $fsrc\t# min reduction4F&quot; %}
16556   ins_encode %{
16557     __ fminv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($vsrc$$reg));
16558     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));
16559   %}
16560   ins_pipe(pipe_class_default);
16561 %}
16562 
16563 instruct reduce_min2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp) %{
16564   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16565   match(Set dst (MinReductionV dsrc vsrc));
16566   ins_cost(INSN_COST);
16567   effect(TEMP_DEF dst, TEMP tmp);
16568   format %{ &quot;fmind $dst, $dsrc, $vsrc\n\t&quot;
16569             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16570             &quot;fmind $dst, $dst, $tmp\t# min reduction2D&quot; %}
16571   ins_encode %{
16572     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16573     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($vsrc$$reg), 0, 1);
16574     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16575   %}
16576   ins_pipe(pipe_class_default);
16577 %}
16578 
16579 // ====================VECTOR ARITHMETIC=======================================
16580 
16581 // --------------------------------- ADD --------------------------------------
16582 
16583 instruct vadd8B(vecD dst, vecD src1, vecD src2)
16584 %{
16585   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16586             n-&gt;as_Vector()-&gt;length() == 8);
16587   match(Set dst (AddVB src1 src2));
16588   ins_cost(INSN_COST);
16589   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16590   ins_encode %{
16591     __ addv(as_FloatRegister($dst$$reg), __ T8B,
16592             as_FloatRegister($src1$$reg),
16593             as_FloatRegister($src2$$reg));
16594   %}
16595   ins_pipe(vdop64);
16596 %}
16597 
16598 instruct vadd16B(vecX dst, vecX src1, vecX src2)
16599 %{
16600   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16601   match(Set dst (AddVB src1 src2));
16602   ins_cost(INSN_COST);
16603   format %{ &quot;addv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16604   ins_encode %{
16605     __ addv(as_FloatRegister($dst$$reg), __ T16B,
16606             as_FloatRegister($src1$$reg),
16607             as_FloatRegister($src2$$reg));
16608   %}
16609   ins_pipe(vdop128);
16610 %}
16611 
16612 instruct vadd4S(vecD dst, vecD src1, vecD src2)
16613 %{
16614   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16615             n-&gt;as_Vector()-&gt;length() == 4);
16616   match(Set dst (AddVS src1 src2));
16617   ins_cost(INSN_COST);
16618   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16619   ins_encode %{
16620     __ addv(as_FloatRegister($dst$$reg), __ T4H,
16621             as_FloatRegister($src1$$reg),
16622             as_FloatRegister($src2$$reg));
16623   %}
16624   ins_pipe(vdop64);
16625 %}
16626 
16627 instruct vadd8S(vecX dst, vecX src1, vecX src2)
16628 %{
16629   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16630   match(Set dst (AddVS src1 src2));
16631   ins_cost(INSN_COST);
16632   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16633   ins_encode %{
16634     __ addv(as_FloatRegister($dst$$reg), __ T8H,
16635             as_FloatRegister($src1$$reg),
16636             as_FloatRegister($src2$$reg));
16637   %}
16638   ins_pipe(vdop128);
16639 %}
16640 
16641 instruct vadd2I(vecD dst, vecD src1, vecD src2)
16642 %{
16643   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16644   match(Set dst (AddVI src1 src2));
16645   ins_cost(INSN_COST);
16646   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16647   ins_encode %{
16648     __ addv(as_FloatRegister($dst$$reg), __ T2S,
16649             as_FloatRegister($src1$$reg),
16650             as_FloatRegister($src2$$reg));
16651   %}
16652   ins_pipe(vdop64);
16653 %}
16654 
16655 instruct vadd4I(vecX dst, vecX src1, vecX src2)
16656 %{
16657   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16658   match(Set dst (AddVI src1 src2));
16659   ins_cost(INSN_COST);
16660   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16661   ins_encode %{
16662     __ addv(as_FloatRegister($dst$$reg), __ T4S,
16663             as_FloatRegister($src1$$reg),
16664             as_FloatRegister($src2$$reg));
16665   %}
16666   ins_pipe(vdop128);
16667 %}
16668 
16669 instruct vadd2L(vecX dst, vecX src1, vecX src2)
16670 %{
16671   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16672   match(Set dst (AddVL src1 src2));
16673   ins_cost(INSN_COST);
16674   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16675   ins_encode %{
16676     __ addv(as_FloatRegister($dst$$reg), __ T2D,
16677             as_FloatRegister($src1$$reg),
16678             as_FloatRegister($src2$$reg));
16679   %}
16680   ins_pipe(vdop128);
16681 %}
16682 
16683 instruct vadd2F(vecD dst, vecD src1, vecD src2)
16684 %{
16685   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16686   match(Set dst (AddVF src1 src2));
16687   ins_cost(INSN_COST);
16688   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2S)&quot; %}
16689   ins_encode %{
16690     __ fadd(as_FloatRegister($dst$$reg), __ T2S,
16691             as_FloatRegister($src1$$reg),
16692             as_FloatRegister($src2$$reg));
16693   %}
16694   ins_pipe(vdop_fp64);
16695 %}
16696 
16697 instruct vadd4F(vecX dst, vecX src1, vecX src2)
16698 %{
16699   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16700   match(Set dst (AddVF src1 src2));
16701   ins_cost(INSN_COST);
16702   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (4S)&quot; %}
16703   ins_encode %{
16704     __ fadd(as_FloatRegister($dst$$reg), __ T4S,
16705             as_FloatRegister($src1$$reg),
16706             as_FloatRegister($src2$$reg));
16707   %}
16708   ins_pipe(vdop_fp128);
16709 %}
16710 
16711 instruct vadd2D(vecX dst, vecX src1, vecX src2)
16712 %{
16713   match(Set dst (AddVD src1 src2));
16714   ins_cost(INSN_COST);
16715   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2D)&quot; %}
16716   ins_encode %{
16717     __ fadd(as_FloatRegister($dst$$reg), __ T2D,
16718             as_FloatRegister($src1$$reg),
16719             as_FloatRegister($src2$$reg));
16720   %}
16721   ins_pipe(vdop_fp128);
16722 %}
16723 
16724 // --------------------------------- SUB --------------------------------------
16725 
16726 instruct vsub8B(vecD dst, vecD src1, vecD src2)
16727 %{
16728   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16729             n-&gt;as_Vector()-&gt;length() == 8);
16730   match(Set dst (SubVB src1 src2));
16731   ins_cost(INSN_COST);
16732   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16733   ins_encode %{
16734     __ subv(as_FloatRegister($dst$$reg), __ T8B,
16735             as_FloatRegister($src1$$reg),
16736             as_FloatRegister($src2$$reg));
16737   %}
16738   ins_pipe(vdop64);
16739 %}
16740 
16741 instruct vsub16B(vecX dst, vecX src1, vecX src2)
16742 %{
16743   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16744   match(Set dst (SubVB src1 src2));
16745   ins_cost(INSN_COST);
16746   format %{ &quot;subv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16747   ins_encode %{
16748     __ subv(as_FloatRegister($dst$$reg), __ T16B,
16749             as_FloatRegister($src1$$reg),
16750             as_FloatRegister($src2$$reg));
16751   %}
16752   ins_pipe(vdop128);
16753 %}
16754 
16755 instruct vsub4S(vecD dst, vecD src1, vecD src2)
16756 %{
16757   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16758             n-&gt;as_Vector()-&gt;length() == 4);
16759   match(Set dst (SubVS src1 src2));
16760   ins_cost(INSN_COST);
16761   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16762   ins_encode %{
16763     __ subv(as_FloatRegister($dst$$reg), __ T4H,
16764             as_FloatRegister($src1$$reg),
16765             as_FloatRegister($src2$$reg));
16766   %}
16767   ins_pipe(vdop64);
16768 %}
16769 
16770 instruct vsub8S(vecX dst, vecX src1, vecX src2)
16771 %{
16772   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16773   match(Set dst (SubVS src1 src2));
16774   ins_cost(INSN_COST);
16775   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16776   ins_encode %{
16777     __ subv(as_FloatRegister($dst$$reg), __ T8H,
16778             as_FloatRegister($src1$$reg),
16779             as_FloatRegister($src2$$reg));
16780   %}
16781   ins_pipe(vdop128);
16782 %}
16783 
16784 instruct vsub2I(vecD dst, vecD src1, vecD src2)
16785 %{
16786   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16787   match(Set dst (SubVI src1 src2));
16788   ins_cost(INSN_COST);
16789   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16790   ins_encode %{
16791     __ subv(as_FloatRegister($dst$$reg), __ T2S,
16792             as_FloatRegister($src1$$reg),
16793             as_FloatRegister($src2$$reg));
16794   %}
16795   ins_pipe(vdop64);
16796 %}
16797 
16798 instruct vsub4I(vecX dst, vecX src1, vecX src2)
16799 %{
16800   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16801   match(Set dst (SubVI src1 src2));
16802   ins_cost(INSN_COST);
16803   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16804   ins_encode %{
16805     __ subv(as_FloatRegister($dst$$reg), __ T4S,
16806             as_FloatRegister($src1$$reg),
16807             as_FloatRegister($src2$$reg));
16808   %}
16809   ins_pipe(vdop128);
16810 %}
16811 
16812 instruct vsub2L(vecX dst, vecX src1, vecX src2)
16813 %{
16814   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16815   match(Set dst (SubVL src1 src2));
16816   ins_cost(INSN_COST);
16817   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16818   ins_encode %{
16819     __ subv(as_FloatRegister($dst$$reg), __ T2D,
16820             as_FloatRegister($src1$$reg),
16821             as_FloatRegister($src2$$reg));
16822   %}
16823   ins_pipe(vdop128);
16824 %}
16825 
16826 instruct vsub2F(vecD dst, vecD src1, vecD src2)
16827 %{
16828   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16829   match(Set dst (SubVF src1 src2));
16830   ins_cost(INSN_COST);
16831   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2S)&quot; %}
16832   ins_encode %{
16833     __ fsub(as_FloatRegister($dst$$reg), __ T2S,
16834             as_FloatRegister($src1$$reg),
16835             as_FloatRegister($src2$$reg));
16836   %}
16837   ins_pipe(vdop_fp64);
16838 %}
16839 
16840 instruct vsub4F(vecX dst, vecX src1, vecX src2)
16841 %{
16842   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16843   match(Set dst (SubVF src1 src2));
16844   ins_cost(INSN_COST);
16845   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (4S)&quot; %}
16846   ins_encode %{
16847     __ fsub(as_FloatRegister($dst$$reg), __ T4S,
16848             as_FloatRegister($src1$$reg),
16849             as_FloatRegister($src2$$reg));
16850   %}
16851   ins_pipe(vdop_fp128);
16852 %}
16853 
16854 instruct vsub2D(vecX dst, vecX src1, vecX src2)
16855 %{
16856   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16857   match(Set dst (SubVD src1 src2));
16858   ins_cost(INSN_COST);
16859   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2D)&quot; %}
16860   ins_encode %{
16861     __ fsub(as_FloatRegister($dst$$reg), __ T2D,
16862             as_FloatRegister($src1$$reg),
16863             as_FloatRegister($src2$$reg));
16864   %}
16865   ins_pipe(vdop_fp128);
16866 %}
16867 
16868 // --------------------------------- MUL --------------------------------------
16869 
16870 instruct vmul8B(vecD dst, vecD src1, vecD src2)
16871 %{
16872   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16873             n-&gt;as_Vector()-&gt;length() == 8);
16874   match(Set dst (MulVB src1 src2));
16875   ins_cost(INSN_COST);
16876   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16877   ins_encode %{
16878     __ mulv(as_FloatRegister($dst$$reg), __ T8B,
16879             as_FloatRegister($src1$$reg),
16880             as_FloatRegister($src2$$reg));
16881   %}
16882   ins_pipe(vmul64);
16883 %}
16884 
16885 instruct vmul16B(vecX dst, vecX src1, vecX src2)
16886 %{
16887   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16888   match(Set dst (MulVB src1 src2));
16889   ins_cost(INSN_COST);
16890   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16891   ins_encode %{
16892     __ mulv(as_FloatRegister($dst$$reg), __ T16B,
16893             as_FloatRegister($src1$$reg),
16894             as_FloatRegister($src2$$reg));
16895   %}
16896   ins_pipe(vmul128);
16897 %}
16898 
16899 instruct vmul4S(vecD dst, vecD src1, vecD src2)
16900 %{
16901   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16902             n-&gt;as_Vector()-&gt;length() == 4);
16903   match(Set dst (MulVS src1 src2));
16904   ins_cost(INSN_COST);
16905   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16906   ins_encode %{
16907     __ mulv(as_FloatRegister($dst$$reg), __ T4H,
16908             as_FloatRegister($src1$$reg),
16909             as_FloatRegister($src2$$reg));
16910   %}
16911   ins_pipe(vmul64);
16912 %}
16913 
16914 instruct vmul8S(vecX dst, vecX src1, vecX src2)
16915 %{
16916   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16917   match(Set dst (MulVS src1 src2));
16918   ins_cost(INSN_COST);
16919   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16920   ins_encode %{
16921     __ mulv(as_FloatRegister($dst$$reg), __ T8H,
16922             as_FloatRegister($src1$$reg),
16923             as_FloatRegister($src2$$reg));
16924   %}
16925   ins_pipe(vmul128);
16926 %}
16927 
16928 instruct vmul2I(vecD dst, vecD src1, vecD src2)
16929 %{
16930   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16931   match(Set dst (MulVI src1 src2));
16932   ins_cost(INSN_COST);
16933   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16934   ins_encode %{
16935     __ mulv(as_FloatRegister($dst$$reg), __ T2S,
16936             as_FloatRegister($src1$$reg),
16937             as_FloatRegister($src2$$reg));
16938   %}
16939   ins_pipe(vmul64);
16940 %}
16941 
16942 instruct vmul4I(vecX dst, vecX src1, vecX src2)
16943 %{
16944   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16945   match(Set dst (MulVI src1 src2));
16946   ins_cost(INSN_COST);
16947   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16948   ins_encode %{
16949     __ mulv(as_FloatRegister($dst$$reg), __ T4S,
16950             as_FloatRegister($src1$$reg),
16951             as_FloatRegister($src2$$reg));
16952   %}
16953   ins_pipe(vmul128);
16954 %}
16955 
16956 instruct vmul2F(vecD dst, vecD src1, vecD src2)
16957 %{
16958   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16959   match(Set dst (MulVF src1 src2));
16960   ins_cost(INSN_COST);
16961   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2S)&quot; %}
16962   ins_encode %{
16963     __ fmul(as_FloatRegister($dst$$reg), __ T2S,
16964             as_FloatRegister($src1$$reg),
16965             as_FloatRegister($src2$$reg));
16966   %}
16967   ins_pipe(vmuldiv_fp64);
16968 %}
16969 
16970 instruct vmul4F(vecX dst, vecX src1, vecX src2)
16971 %{
16972   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16973   match(Set dst (MulVF src1 src2));
16974   ins_cost(INSN_COST);
16975   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (4S)&quot; %}
16976   ins_encode %{
16977     __ fmul(as_FloatRegister($dst$$reg), __ T4S,
16978             as_FloatRegister($src1$$reg),
16979             as_FloatRegister($src2$$reg));
16980   %}
16981   ins_pipe(vmuldiv_fp128);
16982 %}
16983 
16984 instruct vmul2D(vecX dst, vecX src1, vecX src2)
16985 %{
16986   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16987   match(Set dst (MulVD src1 src2));
16988   ins_cost(INSN_COST);
16989   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2D)&quot; %}
16990   ins_encode %{
16991     __ fmul(as_FloatRegister($dst$$reg), __ T2D,
16992             as_FloatRegister($src1$$reg),
16993             as_FloatRegister($src2$$reg));
16994   %}
16995   ins_pipe(vmuldiv_fp128);
16996 %}
16997 
16998 // --------------------------------- MLA --------------------------------------
16999 
17000 instruct vmla4S(vecD dst, vecD src1, vecD src2)
17001 %{
17002   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17003             n-&gt;as_Vector()-&gt;length() == 4);
17004   match(Set dst (AddVS dst (MulVS src1 src2)));
17005   ins_cost(INSN_COST);
17006   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4H)&quot; %}
17007   ins_encode %{
17008     __ mlav(as_FloatRegister($dst$$reg), __ T4H,
17009             as_FloatRegister($src1$$reg),
17010             as_FloatRegister($src2$$reg));
17011   %}
17012   ins_pipe(vmla64);
17013 %}
17014 
17015 instruct vmla8S(vecX dst, vecX src1, vecX src2)
17016 %{
17017   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17018   match(Set dst (AddVS dst (MulVS src1 src2)));
17019   ins_cost(INSN_COST);
17020   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (8H)&quot; %}
17021   ins_encode %{
17022     __ mlav(as_FloatRegister($dst$$reg), __ T8H,
17023             as_FloatRegister($src1$$reg),
17024             as_FloatRegister($src2$$reg));
17025   %}
17026   ins_pipe(vmla128);
17027 %}
17028 
17029 instruct vmla2I(vecD dst, vecD src1, vecD src2)
17030 %{
17031   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17032   match(Set dst (AddVI dst (MulVI src1 src2)));
17033   ins_cost(INSN_COST);
17034   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (2S)&quot; %}
17035   ins_encode %{
17036     __ mlav(as_FloatRegister($dst$$reg), __ T2S,
17037             as_FloatRegister($src1$$reg),
17038             as_FloatRegister($src2$$reg));
17039   %}
17040   ins_pipe(vmla64);
17041 %}
17042 
17043 instruct vmla4I(vecX dst, vecX src1, vecX src2)
17044 %{
17045   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17046   match(Set dst (AddVI dst (MulVI src1 src2)));
17047   ins_cost(INSN_COST);
17048   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4S)&quot; %}
17049   ins_encode %{
17050     __ mlav(as_FloatRegister($dst$$reg), __ T4S,
17051             as_FloatRegister($src1$$reg),
17052             as_FloatRegister($src2$$reg));
17053   %}
17054   ins_pipe(vmla128);
17055 %}
17056 
17057 // dst + src1 * src2
17058 instruct vmla2F(vecD dst, vecD src1, vecD src2) %{
17059   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
17060   match(Set dst (FmaVF  dst (Binary src1 src2)));
17061   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2S)&quot; %}
17062   ins_cost(INSN_COST);
17063   ins_encode %{
17064     __ fmla(as_FloatRegister($dst$$reg), __ T2S,
17065             as_FloatRegister($src1$$reg),
17066             as_FloatRegister($src2$$reg));
17067   %}
17068   ins_pipe(vmuldiv_fp64);
17069 %}
17070 
17071 // dst + src1 * src2
17072 instruct vmla4F(vecX dst, vecX src1, vecX src2) %{
17073   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
17074   match(Set dst (FmaVF  dst (Binary src1 src2)));
17075   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (4S)&quot; %}
17076   ins_cost(INSN_COST);
17077   ins_encode %{
17078     __ fmla(as_FloatRegister($dst$$reg), __ T4S,
17079             as_FloatRegister($src1$$reg),
17080             as_FloatRegister($src2$$reg));
17081   %}
17082   ins_pipe(vmuldiv_fp128);
17083 %}
17084 
17085 // dst + src1 * src2
17086 instruct vmla2D(vecX dst, vecX src1, vecX src2) %{
17087   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
17088   match(Set dst (FmaVD  dst (Binary src1 src2)));
17089   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2D)&quot; %}
17090   ins_cost(INSN_COST);
17091   ins_encode %{
17092     __ fmla(as_FloatRegister($dst$$reg), __ T2D,
17093             as_FloatRegister($src1$$reg),
17094             as_FloatRegister($src2$$reg));
17095   %}
17096   ins_pipe(vmuldiv_fp128);
17097 %}
17098 
17099 // --------------------------------- MLS --------------------------------------
17100 
17101 instruct vmls4S(vecD dst, vecD src1, vecD src2)
17102 %{
17103   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17104             n-&gt;as_Vector()-&gt;length() == 4);
17105   match(Set dst (SubVS dst (MulVS src1 src2)));
17106   ins_cost(INSN_COST);
17107   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4H)&quot; %}
17108   ins_encode %{
17109     __ mlsv(as_FloatRegister($dst$$reg), __ T4H,
17110             as_FloatRegister($src1$$reg),
17111             as_FloatRegister($src2$$reg));
17112   %}
17113   ins_pipe(vmla64);
17114 %}
17115 
17116 instruct vmls8S(vecX dst, vecX src1, vecX src2)
17117 %{
17118   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17119   match(Set dst (SubVS dst (MulVS src1 src2)));
17120   ins_cost(INSN_COST);
17121   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (8H)&quot; %}
17122   ins_encode %{
17123     __ mlsv(as_FloatRegister($dst$$reg), __ T8H,
17124             as_FloatRegister($src1$$reg),
17125             as_FloatRegister($src2$$reg));
17126   %}
17127   ins_pipe(vmla128);
17128 %}
17129 
17130 instruct vmls2I(vecD dst, vecD src1, vecD src2)
17131 %{
17132   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17133   match(Set dst (SubVI dst (MulVI src1 src2)));
17134   ins_cost(INSN_COST);
17135   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (2S)&quot; %}
17136   ins_encode %{
17137     __ mlsv(as_FloatRegister($dst$$reg), __ T2S,
17138             as_FloatRegister($src1$$reg),
17139             as_FloatRegister($src2$$reg));
17140   %}
17141   ins_pipe(vmla64);
17142 %}
17143 
17144 instruct vmls4I(vecX dst, vecX src1, vecX src2)
17145 %{
17146   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17147   match(Set dst (SubVI dst (MulVI src1 src2)));
17148   ins_cost(INSN_COST);
17149   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4S)&quot; %}
17150   ins_encode %{
17151     __ mlsv(as_FloatRegister($dst$$reg), __ T4S,
17152             as_FloatRegister($src1$$reg),
17153             as_FloatRegister($src2$$reg));
17154   %}
17155   ins_pipe(vmla128);
17156 %}
17157 
17158 // dst - src1 * src2
17159 instruct vmls2F(vecD dst, vecD src1, vecD src2) %{
17160   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
17161   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
17162   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
17163   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2S)&quot; %}
17164   ins_cost(INSN_COST);
17165   ins_encode %{
17166     __ fmls(as_FloatRegister($dst$$reg), __ T2S,
17167             as_FloatRegister($src1$$reg),
17168             as_FloatRegister($src2$$reg));
17169   %}
17170   ins_pipe(vmuldiv_fp64);
17171 %}
17172 
17173 // dst - src1 * src2
17174 instruct vmls4F(vecX dst, vecX src1, vecX src2) %{
17175   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
17176   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
17177   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
17178   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (4S)&quot; %}
17179   ins_cost(INSN_COST);
17180   ins_encode %{
17181     __ fmls(as_FloatRegister($dst$$reg), __ T4S,
17182             as_FloatRegister($src1$$reg),
17183             as_FloatRegister($src2$$reg));
17184   %}
17185   ins_pipe(vmuldiv_fp128);
17186 %}
17187 
17188 // dst - src1 * src2
17189 instruct vmls2D(vecX dst, vecX src1, vecX src2) %{
17190   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
17191   match(Set dst (FmaVD  dst (Binary (NegVD src1) src2)));
17192   match(Set dst (FmaVD  dst (Binary src1 (NegVD src2))));
17193   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2D)&quot; %}
17194   ins_cost(INSN_COST);
17195   ins_encode %{
17196     __ fmls(as_FloatRegister($dst$$reg), __ T2D,
17197             as_FloatRegister($src1$$reg),
17198             as_FloatRegister($src2$$reg));
17199   %}
17200   ins_pipe(vmuldiv_fp128);
17201 %}
17202 
17203 // --------------- Vector Multiply-Add Shorts into Integer --------------------
17204 
17205 instruct vmuladdS2I(vecX dst, vecX src1, vecX src2, vecX tmp) %{
17206   predicate(n-&gt;in(1)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_SHORT);
17207   match(Set dst (MulAddVS2VI src1 src2));
17208   ins_cost(INSN_COST);
17209   effect(TEMP_DEF dst, TEMP tmp);
17210   format %{ &quot;smullv  $tmp, $src1, $src2\t# vector (4H)\n\t&quot;
17211             &quot;smullv  $dst, $src1, $src2\t# vector (8H)\n\t&quot;
17212             &quot;addpv   $dst, $tmp, $dst\t# vector (4S)\n\t&quot; %}
17213   ins_encode %{
17214     __ smullv(as_FloatRegister($tmp$$reg), __ T4H,
17215               as_FloatRegister($src1$$reg),
17216               as_FloatRegister($src2$$reg));
17217     __ smullv(as_FloatRegister($dst$$reg), __ T8H,
17218               as_FloatRegister($src1$$reg),
17219               as_FloatRegister($src2$$reg));
17220     __ addpv(as_FloatRegister($dst$$reg), __ T4S,
17221              as_FloatRegister($tmp$$reg),
17222              as_FloatRegister($dst$$reg));
17223   %}
17224   ins_pipe(vmuldiv_fp128);
17225 %}
17226 
17227 // --------------------------------- DIV --------------------------------------
17228 
17229 instruct vdiv2F(vecD dst, vecD src1, vecD src2)
17230 %{
17231   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17232   match(Set dst (DivVF src1 src2));
17233   ins_cost(INSN_COST);
17234   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2S)&quot; %}
17235   ins_encode %{
17236     __ fdiv(as_FloatRegister($dst$$reg), __ T2S,
17237             as_FloatRegister($src1$$reg),
17238             as_FloatRegister($src2$$reg));
17239   %}
17240   ins_pipe(vmuldiv_fp64);
17241 %}
17242 
17243 instruct vdiv4F(vecX dst, vecX src1, vecX src2)
17244 %{
17245   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17246   match(Set dst (DivVF src1 src2));
17247   ins_cost(INSN_COST);
17248   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (4S)&quot; %}
17249   ins_encode %{
17250     __ fdiv(as_FloatRegister($dst$$reg), __ T4S,
17251             as_FloatRegister($src1$$reg),
17252             as_FloatRegister($src2$$reg));
17253   %}
17254   ins_pipe(vmuldiv_fp128);
17255 %}
17256 
17257 instruct vdiv2D(vecX dst, vecX src1, vecX src2)
17258 %{
17259   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17260   match(Set dst (DivVD src1 src2));
17261   ins_cost(INSN_COST);
17262   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2D)&quot; %}
17263   ins_encode %{
17264     __ fdiv(as_FloatRegister($dst$$reg), __ T2D,
17265             as_FloatRegister($src1$$reg),
17266             as_FloatRegister($src2$$reg));
17267   %}
17268   ins_pipe(vmuldiv_fp128);
17269 %}
17270 
17271 // --------------------------------- SQRT -------------------------------------
17272 
17273 instruct vsqrt2F(vecD dst, vecD src)
17274 %{
17275   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17276   match(Set dst (SqrtVF src));
17277   format %{ &quot;fsqrt  $dst, $src\t# vector (2F)&quot; %}
17278   ins_encode %{
17279     __ fsqrt(as_FloatRegister($dst$$reg), __ T2S, as_FloatRegister($src$$reg));
17280   %}
17281   ins_pipe(vunop_fp64);
17282 %}
17283 
17284 instruct vsqrt4F(vecX dst, vecX src)
17285 %{
17286   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17287   match(Set dst (SqrtVF src));
17288   format %{ &quot;fsqrt  $dst, $src\t# vector (4F)&quot; %}
17289   ins_encode %{
17290     __ fsqrt(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src$$reg));
17291   %}
17292   ins_pipe(vsqrt_fp128);
17293 %}
17294 
17295 instruct vsqrt2D(vecX dst, vecX src)
17296 %{
17297   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17298   match(Set dst (SqrtVD src));
17299   format %{ &quot;fsqrt  $dst, $src\t# vector (2D)&quot; %}
17300   ins_encode %{
17301     __ fsqrt(as_FloatRegister($dst$$reg), __ T2D,
17302              as_FloatRegister($src$$reg));
17303   %}
17304   ins_pipe(vsqrt_fp128);
17305 %}
17306 
17307 // --------------------------------- ABS --------------------------------------
17308 
17309 instruct vabs8B(vecD dst, vecD src)
17310 %{
17311   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17312             n-&gt;as_Vector()-&gt;length() == 8);
17313   match(Set dst (AbsVB src));
17314   ins_cost(INSN_COST);
17315   format %{ &quot;abs  $dst, $src\t# vector (8B)&quot; %}
17316   ins_encode %{
17317     __ absr(as_FloatRegister($dst$$reg), __ T8B, as_FloatRegister($src$$reg));
17318   %}
17319   ins_pipe(vlogical64);
17320 %}
17321 
17322 instruct vabs16B(vecX dst, vecX src)
17323 %{
17324   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17325   match(Set dst (AbsVB src));
17326   ins_cost(INSN_COST);
17327   format %{ &quot;abs  $dst, $src\t# vector (16B)&quot; %}
17328   ins_encode %{
17329     __ absr(as_FloatRegister($dst$$reg), __ T16B, as_FloatRegister($src$$reg));
17330   %}
17331   ins_pipe(vlogical128);
17332 %}
17333 
17334 instruct vabs4S(vecD dst, vecD src)
17335 %{
17336   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17337   match(Set dst (AbsVS src));
17338   ins_cost(INSN_COST);
17339   format %{ &quot;abs  $dst, $src\t# vector (4H)&quot; %}
17340   ins_encode %{
17341     __ absr(as_FloatRegister($dst$$reg), __ T4H, as_FloatRegister($src$$reg));
17342   %}
17343   ins_pipe(vlogical64);
17344 %}
17345 
17346 instruct vabs8S(vecX dst, vecX src)
17347 %{
17348   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17349   match(Set dst (AbsVS src));
17350   ins_cost(INSN_COST);
17351   format %{ &quot;abs  $dst, $src\t# vector (8H)&quot; %}
17352   ins_encode %{
17353     __ absr(as_FloatRegister($dst$$reg), __ T8H, as_FloatRegister($src$$reg));
17354   %}
17355   ins_pipe(vlogical128);
17356 %}
17357 
17358 instruct vabs2I(vecD dst, vecD src)
17359 %{
17360   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17361   match(Set dst (AbsVI src));
17362   ins_cost(INSN_COST);
17363   format %{ &quot;abs  $dst, $src\t# vector (2S)&quot; %}
17364   ins_encode %{
17365     __ absr(as_FloatRegister($dst$$reg), __ T2S, as_FloatRegister($src$$reg));
17366   %}
17367   ins_pipe(vlogical64);
17368 %}
17369 
17370 instruct vabs4I(vecX dst, vecX src)
17371 %{
17372   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17373   match(Set dst (AbsVI src));
17374   ins_cost(INSN_COST);
17375   format %{ &quot;abs  $dst, $src\t# vector (4S)&quot; %}
17376   ins_encode %{
17377     __ absr(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src$$reg));
17378   %}
17379   ins_pipe(vlogical128);
17380 %}
17381 
17382 instruct vabs2L(vecX dst, vecX src)
17383 %{
17384   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17385   match(Set dst (AbsVL src));
17386   ins_cost(INSN_COST);
17387   format %{ &quot;abs  $dst, $src\t# vector (2D)&quot; %}
17388   ins_encode %{
17389     __ absr(as_FloatRegister($dst$$reg), __ T2D, as_FloatRegister($src$$reg));
17390   %}
17391   ins_pipe(vlogical128);
17392 %}
17393 
17394 instruct vabs2F(vecD dst, vecD src)
17395 %{
17396   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17397   match(Set dst (AbsVF src));
17398   ins_cost(INSN_COST * 3);
17399   format %{ &quot;fabs  $dst,$src\t# vector (2S)&quot; %}
17400   ins_encode %{
17401     __ fabs(as_FloatRegister($dst$$reg), __ T2S,
17402             as_FloatRegister($src$$reg));
17403   %}
17404   ins_pipe(vunop_fp64);
17405 %}
17406 
17407 instruct vabs4F(vecX dst, vecX src)
17408 %{
17409   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17410   match(Set dst (AbsVF src));
17411   ins_cost(INSN_COST * 3);
17412   format %{ &quot;fabs  $dst,$src\t# vector (4S)&quot; %}
17413   ins_encode %{
17414     __ fabs(as_FloatRegister($dst$$reg), __ T4S,
17415             as_FloatRegister($src$$reg));
17416   %}
17417   ins_pipe(vunop_fp128);
17418 %}
17419 
17420 instruct vabs2D(vecX dst, vecX src)
17421 %{
17422   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17423   match(Set dst (AbsVD src));
17424   ins_cost(INSN_COST * 3);
17425   format %{ &quot;fabs  $dst,$src\t# vector (2D)&quot; %}
17426   ins_encode %{
17427     __ fabs(as_FloatRegister($dst$$reg), __ T2D,
17428             as_FloatRegister($src$$reg));
17429   %}
17430   ins_pipe(vunop_fp128);
17431 %}
17432 
17433 // --------------------------------- NEG --------------------------------------
17434 
17435 instruct vneg2F(vecD dst, vecD src)
17436 %{
17437   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17438   match(Set dst (NegVF src));
17439   ins_cost(INSN_COST * 3);
17440   format %{ &quot;fneg  $dst,$src\t# vector (2S)&quot; %}
17441   ins_encode %{
17442     __ fneg(as_FloatRegister($dst$$reg), __ T2S,
17443             as_FloatRegister($src$$reg));
17444   %}
17445   ins_pipe(vunop_fp64);
17446 %}
17447 
17448 instruct vneg4F(vecX dst, vecX src)
17449 %{
17450   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17451   match(Set dst (NegVF src));
17452   ins_cost(INSN_COST * 3);
17453   format %{ &quot;fneg  $dst,$src\t# vector (4S)&quot; %}
17454   ins_encode %{
17455     __ fneg(as_FloatRegister($dst$$reg), __ T4S,
17456             as_FloatRegister($src$$reg));
17457   %}
17458   ins_pipe(vunop_fp128);
17459 %}
17460 
17461 instruct vneg2D(vecX dst, vecX src)
17462 %{
17463   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17464   match(Set dst (NegVD src));
17465   ins_cost(INSN_COST * 3);
17466   format %{ &quot;fneg  $dst,$src\t# vector (2D)&quot; %}
17467   ins_encode %{
17468     __ fneg(as_FloatRegister($dst$$reg), __ T2D,
17469             as_FloatRegister($src$$reg));
17470   %}
17471   ins_pipe(vunop_fp128);
17472 %}
17473 
17474 // --------------------------------- AND --------------------------------------
17475 
17476 instruct vand8B(vecD dst, vecD src1, vecD src2)
17477 %{
17478   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17479             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17480   match(Set dst (AndV src1 src2));
17481   ins_cost(INSN_COST);
17482   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17483   ins_encode %{
17484     __ andr(as_FloatRegister($dst$$reg), __ T8B,
17485             as_FloatRegister($src1$$reg),
17486             as_FloatRegister($src2$$reg));
17487   %}
17488   ins_pipe(vlogical64);
17489 %}
17490 
17491 instruct vand16B(vecX dst, vecX src1, vecX src2)
17492 %{
17493   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17494   match(Set dst (AndV src1 src2));
17495   ins_cost(INSN_COST);
17496   format %{ &quot;and  $dst,$src1,$src2\t# vector (16B)&quot; %}
17497   ins_encode %{
17498     __ andr(as_FloatRegister($dst$$reg), __ T16B,
17499             as_FloatRegister($src1$$reg),
17500             as_FloatRegister($src2$$reg));
17501   %}
17502   ins_pipe(vlogical128);
17503 %}
17504 
17505 // --------------------------------- OR ---------------------------------------
17506 
17507 instruct vor8B(vecD dst, vecD src1, vecD src2)
17508 %{
17509   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17510             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17511   match(Set dst (OrV src1 src2));
17512   ins_cost(INSN_COST);
17513   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17514   ins_encode %{
17515     __ orr(as_FloatRegister($dst$$reg), __ T8B,
17516             as_FloatRegister($src1$$reg),
17517             as_FloatRegister($src2$$reg));
17518   %}
17519   ins_pipe(vlogical64);
17520 %}
17521 
17522 instruct vor16B(vecX dst, vecX src1, vecX src2)
17523 %{
17524   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17525   match(Set dst (OrV src1 src2));
17526   ins_cost(INSN_COST);
17527   format %{ &quot;orr  $dst,$src1,$src2\t# vector (16B)&quot; %}
17528   ins_encode %{
17529     __ orr(as_FloatRegister($dst$$reg), __ T16B,
17530             as_FloatRegister($src1$$reg),
17531             as_FloatRegister($src2$$reg));
17532   %}
17533   ins_pipe(vlogical128);
17534 %}
17535 
17536 // --------------------------------- XOR --------------------------------------
17537 
17538 instruct vxor8B(vecD dst, vecD src1, vecD src2)
17539 %{
17540   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17541             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17542   match(Set dst (XorV src1 src2));
17543   ins_cost(INSN_COST);
17544   format %{ &quot;xor  $dst,$src1,$src2\t# vector (8B)&quot; %}
17545   ins_encode %{
17546     __ eor(as_FloatRegister($dst$$reg), __ T8B,
17547             as_FloatRegister($src1$$reg),
17548             as_FloatRegister($src2$$reg));
17549   %}
17550   ins_pipe(vlogical64);
17551 %}
17552 
17553 instruct vxor16B(vecX dst, vecX src1, vecX src2)
17554 %{
17555   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17556   match(Set dst (XorV src1 src2));
17557   ins_cost(INSN_COST);
17558   format %{ &quot;xor  $dst,$src1,$src2\t# vector (16B)&quot; %}
17559   ins_encode %{
17560     __ eor(as_FloatRegister($dst$$reg), __ T16B,
17561             as_FloatRegister($src1$$reg),
17562             as_FloatRegister($src2$$reg));
17563   %}
17564   ins_pipe(vlogical128);
17565 %}
17566 
17567 // ------------------------------ Shift ---------------------------------------
17568 instruct vshiftcnt8B(vecD dst, iRegIorL2I cnt) %{
17569   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17570   match(Set dst (LShiftCntV cnt));
17571   match(Set dst (RShiftCntV cnt));
17572   format %{ &quot;dup  $dst, $cnt\t# shift count vector (8B)&quot; %}
17573   ins_encode %{
17574     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($cnt$$reg));
17575   %}
17576   ins_pipe(vdup_reg_reg64);
17577 %}
17578 
17579 instruct vshiftcnt16B(vecX dst, iRegIorL2I cnt) %{
17580   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17581   match(Set dst (LShiftCntV cnt));
17582   match(Set dst (RShiftCntV cnt));
17583   format %{ &quot;dup  $dst, $cnt\t# shift count vector (16B)&quot; %}
17584   ins_encode %{
17585     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($cnt$$reg));
17586   %}
17587   ins_pipe(vdup_reg_reg128);
17588 %}
17589 
17590 instruct vsll8B(vecD dst, vecD src, vecD shift) %{
17591   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17592             n-&gt;as_Vector()-&gt;length() == 8);
17593   match(Set dst (LShiftVB src shift));
17594   ins_cost(INSN_COST);
17595   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8B)&quot; %}
17596   ins_encode %{
17597     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17598             as_FloatRegister($src$$reg),
17599             as_FloatRegister($shift$$reg));
17600   %}
17601   ins_pipe(vshift64);
17602 %}
17603 
17604 instruct vsll16B(vecX dst, vecX src, vecX shift) %{
17605   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17606   match(Set dst (LShiftVB src shift));
17607   ins_cost(INSN_COST);
17608   format %{ &quot;sshl  $dst,$src,$shift\t# vector (16B)&quot; %}
17609   ins_encode %{
17610     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17611             as_FloatRegister($src$$reg),
17612             as_FloatRegister($shift$$reg));
17613   %}
17614   ins_pipe(vshift128);
17615 %}
17616 
17617 // Right shifts with vector shift count on aarch64 SIMD are implemented
17618 // as left shift by negative shift count.
17619 // There are two cases for vector shift count.
17620 //
17621 // Case 1: The vector shift count is from replication.
17622 //        |            |
17623 //    LoadVector  RShiftCntV
17624 //        |       /
17625 //     RShiftVI
17626 // Note: In inner loop, multiple neg instructions are used, which can be
17627 // moved to outer loop and merge into one neg instruction.
17628 //
17629 // Case 2: The vector shift count is from loading.
17630 // This case isn&#39;t supported by middle-end now. But it&#39;s supported by
17631 // panama/vectorIntrinsics(JEP 338: Vector API).
17632 //        |            |
17633 //    LoadVector  LoadVector
17634 //        |       /
17635 //     RShiftVI
17636 //
17637 
17638 instruct vsra8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17639   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17640             n-&gt;as_Vector()-&gt;length() == 8);
17641   match(Set dst (RShiftVB src shift));
17642   ins_cost(INSN_COST);
17643   effect(TEMP tmp);
17644   format %{ &quot;negr  $tmp,$shift\t&quot;
17645             &quot;sshl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17646   ins_encode %{
17647     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17648             as_FloatRegister($shift$$reg));
17649     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17650             as_FloatRegister($src$$reg),
17651             as_FloatRegister($tmp$$reg));
17652   %}
17653   ins_pipe(vshift64);
17654 %}
17655 
17656 instruct vsra16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17657   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17658   match(Set dst (RShiftVB src shift));
17659   ins_cost(INSN_COST);
17660   effect(TEMP tmp);
17661   format %{ &quot;negr  $tmp,$shift\t&quot;
17662             &quot;sshl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17663   ins_encode %{
17664     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17665             as_FloatRegister($shift$$reg));
17666     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17667             as_FloatRegister($src$$reg),
17668             as_FloatRegister($tmp$$reg));
17669   %}
17670   ins_pipe(vshift128);
17671 %}
17672 
17673 instruct vsrl8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17674   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17675             n-&gt;as_Vector()-&gt;length() == 8);
17676   match(Set dst (URShiftVB src shift));
17677   ins_cost(INSN_COST);
17678   effect(TEMP tmp);
17679   format %{ &quot;negr  $tmp,$shift\t&quot;
17680             &quot;ushl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17681   ins_encode %{
17682     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17683             as_FloatRegister($shift$$reg));
17684     __ ushl(as_FloatRegister($dst$$reg), __ T8B,
17685             as_FloatRegister($src$$reg),
17686             as_FloatRegister($tmp$$reg));
17687   %}
17688   ins_pipe(vshift64);
17689 %}
17690 
17691 instruct vsrl16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17692   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17693   match(Set dst (URShiftVB src shift));
17694   ins_cost(INSN_COST);
17695   effect(TEMP tmp);
17696   format %{ &quot;negr  $tmp,$shift\t&quot;
17697             &quot;ushl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17698   ins_encode %{
17699     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17700             as_FloatRegister($shift$$reg));
17701     __ ushl(as_FloatRegister($dst$$reg), __ T16B,
17702             as_FloatRegister($src$$reg),
17703             as_FloatRegister($tmp$$reg));
17704   %}
17705   ins_pipe(vshift128);
17706 %}
17707 
17708 instruct vsll8B_imm(vecD dst, vecD src, immI shift) %{
17709   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17710             n-&gt;as_Vector()-&gt;length() == 8);
17711   match(Set dst (LShiftVB src (LShiftCntV shift)));
17712   ins_cost(INSN_COST);
17713   format %{ &quot;shl    $dst, $src, $shift\t# vector (8B)&quot; %}
17714   ins_encode %{
17715     int sh = (int)$shift$$constant;
17716     if (sh &gt;= 8) {
17717       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17718              as_FloatRegister($src$$reg),
17719              as_FloatRegister($src$$reg));
17720     } else {
17721       __ shl(as_FloatRegister($dst$$reg), __ T8B,
17722              as_FloatRegister($src$$reg), sh);
17723     }
17724   %}
17725   ins_pipe(vshift64_imm);
17726 %}
17727 
17728 instruct vsll16B_imm(vecX dst, vecX src, immI shift) %{
17729   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17730   match(Set dst (LShiftVB src (LShiftCntV shift)));
17731   ins_cost(INSN_COST);
17732   format %{ &quot;shl    $dst, $src, $shift\t# vector (16B)&quot; %}
17733   ins_encode %{
17734     int sh = (int)$shift$$constant;
17735     if (sh &gt;= 8) {
17736       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17737              as_FloatRegister($src$$reg),
17738              as_FloatRegister($src$$reg));
17739     } else {
17740       __ shl(as_FloatRegister($dst$$reg), __ T16B,
17741              as_FloatRegister($src$$reg), sh);
17742     }
17743   %}
17744   ins_pipe(vshift128_imm);
17745 %}
17746 
17747 instruct vsra8B_imm(vecD dst, vecD src, immI shift) %{
17748   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17749             n-&gt;as_Vector()-&gt;length() == 8);
17750   match(Set dst (RShiftVB src (RShiftCntV shift)));
17751   ins_cost(INSN_COST);
17752   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8B)&quot; %}
17753   ins_encode %{
17754     int sh = (int)$shift$$constant;
17755     if (sh &gt;= 8) sh = 7;
17756     __ sshr(as_FloatRegister($dst$$reg), __ T8B,
17757            as_FloatRegister($src$$reg), sh);
17758   %}
17759   ins_pipe(vshift64_imm);
17760 %}
17761 
17762 instruct vsra16B_imm(vecX dst, vecX src, immI shift) %{
17763   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17764   match(Set dst (RShiftVB src (RShiftCntV shift)));
17765   ins_cost(INSN_COST);
17766   format %{ &quot;sshr    $dst, $src, $shift\t# vector (16B)&quot; %}
17767   ins_encode %{
17768     int sh = (int)$shift$$constant;
17769     if (sh &gt;= 8) sh = 7;
17770     __ sshr(as_FloatRegister($dst$$reg), __ T16B,
17771            as_FloatRegister($src$$reg), sh);
17772   %}
17773   ins_pipe(vshift128_imm);
17774 %}
17775 
17776 instruct vsrl8B_imm(vecD dst, vecD src, immI shift) %{
17777   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17778             n-&gt;as_Vector()-&gt;length() == 8);
17779   match(Set dst (URShiftVB src (RShiftCntV shift)));
17780   ins_cost(INSN_COST);
17781   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8B)&quot; %}
17782   ins_encode %{
17783     int sh = (int)$shift$$constant;
17784     if (sh &gt;= 8) {
17785       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17786              as_FloatRegister($src$$reg),
17787              as_FloatRegister($src$$reg));
17788     } else {
17789       __ ushr(as_FloatRegister($dst$$reg), __ T8B,
17790              as_FloatRegister($src$$reg), sh);
17791     }
17792   %}
17793   ins_pipe(vshift64_imm);
17794 %}
17795 
17796 instruct vsrl16B_imm(vecX dst, vecX src, immI shift) %{
17797   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17798   match(Set dst (URShiftVB src (RShiftCntV shift)));
17799   ins_cost(INSN_COST);
17800   format %{ &quot;ushr    $dst, $src, $shift\t# vector (16B)&quot; %}
17801   ins_encode %{
17802     int sh = (int)$shift$$constant;
17803     if (sh &gt;= 8) {
17804       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17805              as_FloatRegister($src$$reg),
17806              as_FloatRegister($src$$reg));
17807     } else {
17808       __ ushr(as_FloatRegister($dst$$reg), __ T16B,
17809              as_FloatRegister($src$$reg), sh);
17810     }
17811   %}
17812   ins_pipe(vshift128_imm);
17813 %}
17814 
17815 instruct vsll4S(vecD dst, vecD src, vecD shift) %{
17816   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17817             n-&gt;as_Vector()-&gt;length() == 4);
17818   match(Set dst (LShiftVS src shift));
17819   ins_cost(INSN_COST);
17820   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4H)&quot; %}
17821   ins_encode %{
17822     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17823             as_FloatRegister($src$$reg),
17824             as_FloatRegister($shift$$reg));
17825   %}
17826   ins_pipe(vshift64);
17827 %}
17828 
17829 instruct vsll8S(vecX dst, vecX src, vecX shift) %{
17830   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17831   match(Set dst (LShiftVS src shift));
17832   ins_cost(INSN_COST);
17833   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8H)&quot; %}
17834   ins_encode %{
17835     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17836             as_FloatRegister($src$$reg),
17837             as_FloatRegister($shift$$reg));
17838   %}
17839   ins_pipe(vshift128);
17840 %}
17841 
17842 instruct vsra4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17843   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17844             n-&gt;as_Vector()-&gt;length() == 4);
17845   match(Set dst (RShiftVS src shift));
17846   ins_cost(INSN_COST);
17847   effect(TEMP tmp);
17848   format %{ &quot;negr  $tmp,$shift\t&quot;
17849             &quot;sshl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17850   ins_encode %{
17851     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17852             as_FloatRegister($shift$$reg));
17853     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17854             as_FloatRegister($src$$reg),
17855             as_FloatRegister($tmp$$reg));
17856   %}
17857   ins_pipe(vshift64);
17858 %}
17859 
17860 instruct vsra8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17861   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17862   match(Set dst (RShiftVS src shift));
17863   ins_cost(INSN_COST);
17864   effect(TEMP tmp);
17865   format %{ &quot;negr  $tmp,$shift\t&quot;
17866             &quot;sshl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17867   ins_encode %{
17868     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17869             as_FloatRegister($shift$$reg));
17870     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17871             as_FloatRegister($src$$reg),
17872             as_FloatRegister($tmp$$reg));
17873   %}
17874   ins_pipe(vshift128);
17875 %}
17876 
17877 instruct vsrl4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17878   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17879             n-&gt;as_Vector()-&gt;length() == 4);
17880   match(Set dst (URShiftVS src shift));
17881   ins_cost(INSN_COST);
17882   effect(TEMP tmp);
17883   format %{ &quot;negr  $tmp,$shift\t&quot;
17884             &quot;ushl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17885   ins_encode %{
17886     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17887             as_FloatRegister($shift$$reg));
17888     __ ushl(as_FloatRegister($dst$$reg), __ T4H,
17889             as_FloatRegister($src$$reg),
17890             as_FloatRegister($tmp$$reg));
17891   %}
17892   ins_pipe(vshift64);
17893 %}
17894 
17895 instruct vsrl8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17896   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17897   match(Set dst (URShiftVS src shift));
17898   ins_cost(INSN_COST);
17899   effect(TEMP tmp);
17900   format %{ &quot;negr  $tmp,$shift\t&quot;
17901             &quot;ushl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17902   ins_encode %{
17903     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17904             as_FloatRegister($shift$$reg));
17905     __ ushl(as_FloatRegister($dst$$reg), __ T8H,
17906             as_FloatRegister($src$$reg),
17907             as_FloatRegister($tmp$$reg));
17908   %}
17909   ins_pipe(vshift128);
17910 %}
17911 
17912 instruct vsll4S_imm(vecD dst, vecD src, immI shift) %{
17913   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17914             n-&gt;as_Vector()-&gt;length() == 4);
17915   match(Set dst (LShiftVS src (LShiftCntV shift)));
17916   ins_cost(INSN_COST);
17917   format %{ &quot;shl    $dst, $src, $shift\t# vector (4H)&quot; %}
17918   ins_encode %{
17919     int sh = (int)$shift$$constant;
17920     if (sh &gt;= 16) {
17921       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17922              as_FloatRegister($src$$reg),
17923              as_FloatRegister($src$$reg));
17924     } else {
17925       __ shl(as_FloatRegister($dst$$reg), __ T4H,
17926              as_FloatRegister($src$$reg), sh);
17927     }
17928   %}
17929   ins_pipe(vshift64_imm);
17930 %}
17931 
17932 instruct vsll8S_imm(vecX dst, vecX src, immI shift) %{
17933   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17934   match(Set dst (LShiftVS src (LShiftCntV shift)));
17935   ins_cost(INSN_COST);
17936   format %{ &quot;shl    $dst, $src, $shift\t# vector (8H)&quot; %}
17937   ins_encode %{
17938     int sh = (int)$shift$$constant;
17939     if (sh &gt;= 16) {
17940       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17941              as_FloatRegister($src$$reg),
17942              as_FloatRegister($src$$reg));
17943     } else {
17944       __ shl(as_FloatRegister($dst$$reg), __ T8H,
17945              as_FloatRegister($src$$reg), sh);
17946     }
17947   %}
17948   ins_pipe(vshift128_imm);
17949 %}
17950 
17951 instruct vsra4S_imm(vecD dst, vecD src, immI shift) %{
17952   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17953             n-&gt;as_Vector()-&gt;length() == 4);
17954   match(Set dst (RShiftVS src (RShiftCntV shift)));
17955   ins_cost(INSN_COST);
17956   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4H)&quot; %}
17957   ins_encode %{
17958     int sh = (int)$shift$$constant;
17959     if (sh &gt;= 16) sh = 15;
17960     __ sshr(as_FloatRegister($dst$$reg), __ T4H,
17961            as_FloatRegister($src$$reg), sh);
17962   %}
17963   ins_pipe(vshift64_imm);
17964 %}
17965 
17966 instruct vsra8S_imm(vecX dst, vecX src, immI shift) %{
17967   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17968   match(Set dst (RShiftVS src (RShiftCntV shift)));
17969   ins_cost(INSN_COST);
17970   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8H)&quot; %}
17971   ins_encode %{
17972     int sh = (int)$shift$$constant;
17973     if (sh &gt;= 16) sh = 15;
17974     __ sshr(as_FloatRegister($dst$$reg), __ T8H,
17975            as_FloatRegister($src$$reg), sh);
17976   %}
17977   ins_pipe(vshift128_imm);
17978 %}
17979 
17980 instruct vsrl4S_imm(vecD dst, vecD src, immI shift) %{
17981   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17982             n-&gt;as_Vector()-&gt;length() == 4);
17983   match(Set dst (URShiftVS src (RShiftCntV shift)));
17984   ins_cost(INSN_COST);
17985   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4H)&quot; %}
17986   ins_encode %{
17987     int sh = (int)$shift$$constant;
17988     if (sh &gt;= 16) {
17989       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17990              as_FloatRegister($src$$reg),
17991              as_FloatRegister($src$$reg));
17992     } else {
17993       __ ushr(as_FloatRegister($dst$$reg), __ T4H,
17994              as_FloatRegister($src$$reg), sh);
17995     }
17996   %}
17997   ins_pipe(vshift64_imm);
17998 %}
17999 
18000 instruct vsrl8S_imm(vecX dst, vecX src, immI shift) %{
18001   predicate(n-&gt;as_Vector()-&gt;length() == 8);
18002   match(Set dst (URShiftVS src (RShiftCntV shift)));
18003   ins_cost(INSN_COST);
18004   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8H)&quot; %}
18005   ins_encode %{
18006     int sh = (int)$shift$$constant;
18007     if (sh &gt;= 16) {
18008       __ eor(as_FloatRegister($dst$$reg), __ T16B,
18009              as_FloatRegister($src$$reg),
18010              as_FloatRegister($src$$reg));
18011     } else {
18012       __ ushr(as_FloatRegister($dst$$reg), __ T8H,
18013              as_FloatRegister($src$$reg), sh);
18014     }
18015   %}
18016   ins_pipe(vshift128_imm);
18017 %}
18018 
18019 instruct vsll2I(vecD dst, vecD src, vecD shift) %{
18020   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18021   match(Set dst (LShiftVI src shift));
18022   ins_cost(INSN_COST);
18023   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2S)&quot; %}
18024   ins_encode %{
18025     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
18026             as_FloatRegister($src$$reg),
18027             as_FloatRegister($shift$$reg));
18028   %}
18029   ins_pipe(vshift64);
18030 %}
18031 
18032 instruct vsll4I(vecX dst, vecX src, vecX shift) %{
18033   predicate(n-&gt;as_Vector()-&gt;length() == 4);
18034   match(Set dst (LShiftVI src shift));
18035   ins_cost(INSN_COST);
18036   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4S)&quot; %}
18037   ins_encode %{
18038     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
18039             as_FloatRegister($src$$reg),
18040             as_FloatRegister($shift$$reg));
18041   %}
18042   ins_pipe(vshift128);
18043 %}
18044 
18045 instruct vsra2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
18046   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18047   match(Set dst (RShiftVI src shift));
18048   ins_cost(INSN_COST);
18049   effect(TEMP tmp);
18050   format %{ &quot;negr  $tmp,$shift\t&quot;
18051             &quot;sshl  $dst,$src,$tmp\t# vector (2S)&quot; %}
18052   ins_encode %{
18053     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
18054             as_FloatRegister($shift$$reg));
18055     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
18056             as_FloatRegister($src$$reg),
18057             as_FloatRegister($tmp$$reg));
18058   %}
18059   ins_pipe(vshift64);
18060 %}
18061 
18062 instruct vsra4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
18063   predicate(n-&gt;as_Vector()-&gt;length() == 4);
18064   match(Set dst (RShiftVI src shift));
18065   ins_cost(INSN_COST);
18066   effect(TEMP tmp);
18067   format %{ &quot;negr  $tmp,$shift\t&quot;
18068             &quot;sshl  $dst,$src,$tmp\t# vector (4S)&quot; %}
18069   ins_encode %{
18070     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
18071             as_FloatRegister($shift$$reg));
18072     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
18073             as_FloatRegister($src$$reg),
18074             as_FloatRegister($tmp$$reg));
18075   %}
18076   ins_pipe(vshift128);
18077 %}
18078 
18079 instruct vsrl2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
18080   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18081   match(Set dst (URShiftVI src shift));
18082   ins_cost(INSN_COST);
18083   effect(TEMP tmp);
18084   format %{ &quot;negr  $tmp,$shift\t&quot;
18085             &quot;ushl  $dst,$src,$tmp\t# vector (2S)&quot; %}
18086   ins_encode %{
18087     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
18088             as_FloatRegister($shift$$reg));
18089     __ ushl(as_FloatRegister($dst$$reg), __ T2S,
18090             as_FloatRegister($src$$reg),
18091             as_FloatRegister($tmp$$reg));
18092   %}
18093   ins_pipe(vshift64);
18094 %}
18095 
18096 instruct vsrl4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
18097   predicate(n-&gt;as_Vector()-&gt;length() == 4);
18098   match(Set dst (URShiftVI src shift));
18099   ins_cost(INSN_COST);
18100   effect(TEMP tmp);
18101   format %{ &quot;negr  $tmp,$shift\t&quot;
18102             &quot;ushl  $dst,$src,$tmp\t# vector (4S)&quot; %}
18103   ins_encode %{
18104     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
18105             as_FloatRegister($shift$$reg));
18106     __ ushl(as_FloatRegister($dst$$reg), __ T4S,
18107             as_FloatRegister($src$$reg),
18108             as_FloatRegister($tmp$$reg));
18109   %}
18110   ins_pipe(vshift128);
18111 %}
18112 
18113 instruct vsll2I_imm(vecD dst, vecD src, immI shift) %{
18114   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18115   match(Set dst (LShiftVI src (LShiftCntV shift)));
18116   ins_cost(INSN_COST);
18117   format %{ &quot;shl    $dst, $src, $shift\t# vector (2S)&quot; %}
18118   ins_encode %{
18119     __ shl(as_FloatRegister($dst$$reg), __ T2S,
18120            as_FloatRegister($src$$reg),
18121            (int)$shift$$constant);
18122   %}
18123   ins_pipe(vshift64_imm);
18124 %}
18125 
18126 instruct vsll4I_imm(vecX dst, vecX src, immI shift) %{
18127   predicate(n-&gt;as_Vector()-&gt;length() == 4);
18128   match(Set dst (LShiftVI src (LShiftCntV shift)));
18129   ins_cost(INSN_COST);
18130   format %{ &quot;shl    $dst, $src, $shift\t# vector (4S)&quot; %}
18131   ins_encode %{
18132     __ shl(as_FloatRegister($dst$$reg), __ T4S,
18133            as_FloatRegister($src$$reg),
18134            (int)$shift$$constant);
18135   %}
18136   ins_pipe(vshift128_imm);
18137 %}
18138 
18139 instruct vsra2I_imm(vecD dst, vecD src, immI shift) %{
18140   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18141   match(Set dst (RShiftVI src (RShiftCntV shift)));
18142   ins_cost(INSN_COST);
18143   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2S)&quot; %}
18144   ins_encode %{
18145     __ sshr(as_FloatRegister($dst$$reg), __ T2S,
18146             as_FloatRegister($src$$reg),
18147             (int)$shift$$constant);
18148   %}
18149   ins_pipe(vshift64_imm);
18150 %}
18151 
18152 instruct vsra4I_imm(vecX dst, vecX src, immI shift) %{
18153   predicate(n-&gt;as_Vector()-&gt;length() == 4);
18154   match(Set dst (RShiftVI src (RShiftCntV shift)));
18155   ins_cost(INSN_COST);
18156   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4S)&quot; %}
18157   ins_encode %{
18158     __ sshr(as_FloatRegister($dst$$reg), __ T4S,
18159             as_FloatRegister($src$$reg),
18160             (int)$shift$$constant);
18161   %}
18162   ins_pipe(vshift128_imm);
18163 %}
18164 
18165 instruct vsrl2I_imm(vecD dst, vecD src, immI shift) %{
18166   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18167   match(Set dst (URShiftVI src (RShiftCntV shift)));
18168   ins_cost(INSN_COST);
18169   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2S)&quot; %}
18170   ins_encode %{
18171     __ ushr(as_FloatRegister($dst$$reg), __ T2S,
18172             as_FloatRegister($src$$reg),
18173             (int)$shift$$constant);
18174   %}
18175   ins_pipe(vshift64_imm);
18176 %}
18177 
18178 instruct vsrl4I_imm(vecX dst, vecX src, immI shift) %{
18179   predicate(n-&gt;as_Vector()-&gt;length() == 4);
18180   match(Set dst (URShiftVI src (RShiftCntV shift)));
18181   ins_cost(INSN_COST);
18182   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4S)&quot; %}
18183   ins_encode %{
18184     __ ushr(as_FloatRegister($dst$$reg), __ T4S,
18185             as_FloatRegister($src$$reg),
18186             (int)$shift$$constant);
18187   %}
18188   ins_pipe(vshift128_imm);
18189 %}
18190 
18191 instruct vsll2L(vecX dst, vecX src, vecX shift) %{
18192   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18193   match(Set dst (LShiftVL src shift));
18194   ins_cost(INSN_COST);
18195   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2D)&quot; %}
18196   ins_encode %{
18197     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
18198             as_FloatRegister($src$$reg),
18199             as_FloatRegister($shift$$reg));
18200   %}
18201   ins_pipe(vshift128);
18202 %}
18203 
18204 instruct vsra2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
18205   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18206   match(Set dst (RShiftVL src shift));
18207   ins_cost(INSN_COST);
18208   effect(TEMP tmp);
18209   format %{ &quot;negr  $tmp,$shift\t&quot;
18210             &quot;sshl  $dst,$src,$tmp\t# vector (2D)&quot; %}
18211   ins_encode %{
18212     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
18213             as_FloatRegister($shift$$reg));
18214     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
18215             as_FloatRegister($src$$reg),
18216             as_FloatRegister($tmp$$reg));
18217   %}
18218   ins_pipe(vshift128);
18219 %}
18220 
18221 instruct vsrl2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
18222   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18223   match(Set dst (URShiftVL src shift));
18224   ins_cost(INSN_COST);
18225   effect(TEMP tmp);
18226   format %{ &quot;negr  $tmp,$shift\t&quot;
18227             &quot;ushl  $dst,$src,$tmp\t# vector (2D)&quot; %}
18228   ins_encode %{
18229     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
18230             as_FloatRegister($shift$$reg));
18231     __ ushl(as_FloatRegister($dst$$reg), __ T2D,
18232             as_FloatRegister($src$$reg),
18233             as_FloatRegister($tmp$$reg));
18234   %}
18235   ins_pipe(vshift128);
18236 %}
18237 
18238 instruct vsll2L_imm(vecX dst, vecX src, immI shift) %{
18239   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18240   match(Set dst (LShiftVL src (LShiftCntV shift)));
18241   ins_cost(INSN_COST);
18242   format %{ &quot;shl    $dst, $src, $shift\t# vector (2D)&quot; %}
18243   ins_encode %{
18244     __ shl(as_FloatRegister($dst$$reg), __ T2D,
18245            as_FloatRegister($src$$reg),
18246            (int)$shift$$constant);
18247   %}
18248   ins_pipe(vshift128_imm);
18249 %}
18250 
18251 instruct vsra2L_imm(vecX dst, vecX src, immI shift) %{
18252   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18253   match(Set dst (RShiftVL src (RShiftCntV shift)));
18254   ins_cost(INSN_COST);
18255   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2D)&quot; %}
18256   ins_encode %{
18257     __ sshr(as_FloatRegister($dst$$reg), __ T2D,
18258             as_FloatRegister($src$$reg),
18259             (int)$shift$$constant);
18260   %}
18261   ins_pipe(vshift128_imm);
18262 %}
18263 
18264 instruct vsrl2L_imm(vecX dst, vecX src, immI shift) %{
18265   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18266   match(Set dst (URShiftVL src (RShiftCntV shift)));
18267   ins_cost(INSN_COST);
18268   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2D)&quot; %}
18269   ins_encode %{
18270     __ ushr(as_FloatRegister($dst$$reg), __ T2D,
18271             as_FloatRegister($src$$reg),
18272             (int)$shift$$constant);
18273   %}
18274   ins_pipe(vshift128_imm);
18275 %}
18276 
18277 instruct vmax2F(vecD dst, vecD src1, vecD src2)
18278 %{
18279   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18280   match(Set dst (MaxV src1 src2));
18281   ins_cost(INSN_COST);
18282   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2F)&quot; %}
18283   ins_encode %{
18284     __ fmax(as_FloatRegister($dst$$reg), __ T2S,
18285             as_FloatRegister($src1$$reg),
18286             as_FloatRegister($src2$$reg));
18287   %}
18288   ins_pipe(vdop_fp64);
18289 %}
18290 
18291 instruct vmax4F(vecX dst, vecX src1, vecX src2)
18292 %{
18293   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18294   match(Set dst (MaxV src1 src2));
18295   ins_cost(INSN_COST);
18296   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (4S)&quot; %}
18297   ins_encode %{
18298     __ fmax(as_FloatRegister($dst$$reg), __ T4S,
18299             as_FloatRegister($src1$$reg),
18300             as_FloatRegister($src2$$reg));
18301   %}
18302   ins_pipe(vdop_fp128);
18303 %}
18304 
18305 instruct vmax2D(vecX dst, vecX src1, vecX src2)
18306 %{
18307   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18308   match(Set dst (MaxV src1 src2));
18309   ins_cost(INSN_COST);
18310   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2D)&quot; %}
18311   ins_encode %{
18312     __ fmax(as_FloatRegister($dst$$reg), __ T2D,
18313             as_FloatRegister($src1$$reg),
18314             as_FloatRegister($src2$$reg));
18315   %}
18316   ins_pipe(vdop_fp128);
18317 %}
18318 
18319 instruct vmin2F(vecD dst, vecD src1, vecD src2)
18320 %{
18321   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18322   match(Set dst (MinV src1 src2));
18323   ins_cost(INSN_COST);
18324   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2F)&quot; %}
18325   ins_encode %{
18326     __ fmin(as_FloatRegister($dst$$reg), __ T2S,
18327             as_FloatRegister($src1$$reg),
18328             as_FloatRegister($src2$$reg));
18329   %}
18330   ins_pipe(vdop_fp64);
18331 %}
18332 
18333 instruct vmin4F(vecX dst, vecX src1, vecX src2)
18334 %{
18335   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18336   match(Set dst (MinV src1 src2));
18337   ins_cost(INSN_COST);
18338   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (4S)&quot; %}
18339   ins_encode %{
18340     __ fmin(as_FloatRegister($dst$$reg), __ T4S,
18341             as_FloatRegister($src1$$reg),
18342             as_FloatRegister($src2$$reg));
18343   %}
18344   ins_pipe(vdop_fp128);
18345 %}
18346 
18347 instruct vmin2D(vecX dst, vecX src1, vecX src2)
18348 %{
18349   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18350   match(Set dst (MinV src1 src2));
18351   ins_cost(INSN_COST);
18352   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2D)&quot; %}
18353   ins_encode %{
18354     __ fmin(as_FloatRegister($dst$$reg), __ T2D,
18355             as_FloatRegister($src1$$reg),
18356             as_FloatRegister($src2$$reg));
18357   %}
18358   ins_pipe(vdop_fp128);
18359 %}
18360 
18361 instruct vround2D_reg(vecX dst, vecX src, immI rmode) %{
18362   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18363   match(Set dst (RoundDoubleModeV src rmode));
18364   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
18365   ins_encode %{
18366     switch ($rmode$$constant) {
18367       case RoundDoubleModeNode::rmode_rint:
18368         __ frintn(as_FloatRegister($dst$$reg), __ T2D,
18369                   as_FloatRegister($src$$reg));
18370         break;
18371       case RoundDoubleModeNode::rmode_floor:
18372         __ frintm(as_FloatRegister($dst$$reg), __ T2D,
18373                   as_FloatRegister($src$$reg));
18374         break;
18375       case RoundDoubleModeNode::rmode_ceil:
18376         __ frintp(as_FloatRegister($dst$$reg), __ T2D,
18377                   as_FloatRegister($src$$reg));
18378         break;
18379     }
18380   %}
18381   ins_pipe(vdop_fp128);
18382 %}
18383 
18384 instruct vpopcount4I(vecX dst, vecX src) %{
18385   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
18386   match(Set dst (PopCountVI src));
18387   format %{
18388     &quot;cnt     $dst, $src\t# vector (16B)\n\t&quot;
18389     &quot;uaddlp  $dst, $dst\t# vector (16B)\n\t&quot;
18390     &quot;uaddlp  $dst, $dst\t# vector (8H)&quot;
18391   %}
18392   ins_encode %{
18393      __ cnt(as_FloatRegister($dst$$reg), __ T16B,
18394             as_FloatRegister($src$$reg));
18395      __ uaddlp(as_FloatRegister($dst$$reg), __ T16B,
18396                as_FloatRegister($dst$$reg));
18397      __ uaddlp(as_FloatRegister($dst$$reg), __ T8H,
18398                as_FloatRegister($dst$$reg));
18399   %}
18400   ins_pipe(pipe_class_default);
18401 %}
18402 
18403 instruct vpopcount2I(vecD dst, vecD src) %{
18404   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
18405   match(Set dst (PopCountVI src));
18406   format %{
18407     &quot;cnt     $dst, $src\t# vector (8B)\n\t&quot;
18408     &quot;uaddlp  $dst, $dst\t# vector (8B)\n\t&quot;
18409     &quot;uaddlp  $dst, $dst\t# vector (4H)&quot;
18410   %}
18411   ins_encode %{
18412      __ cnt(as_FloatRegister($dst$$reg), __ T8B,
18413             as_FloatRegister($src$$reg));
18414      __ uaddlp(as_FloatRegister($dst$$reg), __ T8B,
18415                as_FloatRegister($dst$$reg));
18416      __ uaddlp(as_FloatRegister($dst$$reg), __ T4H,
18417                as_FloatRegister($dst$$reg));
18418   %}
18419   ins_pipe(pipe_class_default);
18420 %}
18421 
18422 //----------PEEPHOLE RULES-----------------------------------------------------
18423 // These must follow all instruction definitions as they use the names
18424 // defined in the instructions definitions.
18425 //
18426 // peepmatch ( root_instr_name [preceding_instruction]* );
18427 //
18428 // peepconstraint %{
18429 // (instruction_number.operand_name relational_op instruction_number.operand_name
18430 //  [, ...] );
18431 // // instruction numbers are zero-based using left to right order in peepmatch
18432 //
18433 // peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
18434 // // provide an instruction_number.operand_name for each operand that appears
18435 // // in the replacement instruction&#39;s match rule
18436 //
18437 // ---------VM FLAGS---------------------------------------------------------
18438 //
18439 // All peephole optimizations can be turned off using -XX:-OptoPeephole
18440 //
18441 // Each peephole rule is given an identifying number starting with zero and
18442 // increasing by one in the order seen by the parser.  An individual peephole
18443 // can be enabled, and all others disabled, by using -XX:OptoPeepholeAt=#
18444 // on the command-line.
18445 //
18446 // ---------CURRENT LIMITATIONS----------------------------------------------
18447 //
18448 // Only match adjacent instructions in same basic block
18449 // Only equality constraints
18450 // Only constraints between operands, not (0.dest_reg == RAX_enc)
18451 // Only one replacement instruction
18452 //
18453 // ---------EXAMPLE----------------------------------------------------------
18454 //
18455 // // pertinent parts of existing instructions in architecture description
18456 // instruct movI(iRegINoSp dst, iRegI src)
18457 // %{
18458 //   match(Set dst (CopyI src));
18459 // %}
18460 //
18461 // instruct incI_iReg(iRegINoSp dst, immI1 src, rFlagsReg cr)
18462 // %{
18463 //   match(Set dst (AddI dst src));
18464 //   effect(KILL cr);
18465 // %}
18466 //
18467 // // Change (inc mov) to lea
18468 // peephole %{
18469 //   // increment preceeded by register-register move
18470 //   peepmatch ( incI_iReg movI );
18471 //   // require that the destination register of the increment
18472 //   // match the destination register of the move
18473 //   peepconstraint ( 0.dst == 1.dst );
18474 //   // construct a replacement instruction that sets
18475 //   // the destination to ( move&#39;s source register + one )
18476 //   peepreplace ( leaI_iReg_immI( 0.dst 1.src 0.src ) );
18477 // %}
18478 //
18479 
18480 // Implementation no longer uses movX instructions since
18481 // machine-independent system no longer uses CopyX nodes.
18482 //
18483 // peephole
18484 // %{
18485 //   peepmatch (incI_iReg movI);
18486 //   peepconstraint (0.dst == 1.dst);
18487 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18488 // %}
18489 
18490 // peephole
18491 // %{
18492 //   peepmatch (decI_iReg movI);
18493 //   peepconstraint (0.dst == 1.dst);
18494 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18495 // %}
18496 
18497 // peephole
18498 // %{
18499 //   peepmatch (addI_iReg_imm movI);
18500 //   peepconstraint (0.dst == 1.dst);
18501 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18502 // %}
18503 
18504 // peephole
18505 // %{
18506 //   peepmatch (incL_iReg movL);
18507 //   peepconstraint (0.dst == 1.dst);
18508 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18509 // %}
18510 
18511 // peephole
18512 // %{
18513 //   peepmatch (decL_iReg movL);
18514 //   peepconstraint (0.dst == 1.dst);
18515 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18516 // %}
18517 
18518 // peephole
18519 // %{
18520 //   peepmatch (addL_iReg_imm movL);
18521 //   peepconstraint (0.dst == 1.dst);
18522 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18523 // %}
18524 
18525 // peephole
18526 // %{
18527 //   peepmatch (addP_iReg_imm movP);
18528 //   peepconstraint (0.dst == 1.dst);
18529 //   peepreplace (leaP_iReg_imm(0.dst 1.src 0.src));
18530 // %}
18531 
18532 // // Change load of spilled value to only a spill
18533 // instruct storeI(memory mem, iRegI src)
18534 // %{
18535 //   match(Set mem (StoreI mem src));
18536 // %}
18537 //
18538 // instruct loadI(iRegINoSp dst, memory mem)
18539 // %{
18540 //   match(Set dst (LoadI mem));
18541 // %}
18542 //
18543 
18544 //----------SMARTSPILL RULES---------------------------------------------------
18545 // These must follow all instruction definitions as they use the names
18546 // defined in the instructions definitions.
18547 
18548 // Local Variables:
18549 // mode: c++
18550 // End:
    </pre>
  </body>
</html>