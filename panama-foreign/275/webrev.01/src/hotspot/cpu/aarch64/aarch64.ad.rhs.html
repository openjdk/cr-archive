<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/cpu/aarch64/aarch64.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>    1 //
    2 // Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.
    3 // Copyright (c) 2014, 2020, Red Hat, Inc. All rights reserved.
    4 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    5 //
    6 // This code is free software; you can redistribute it and/or modify it
    7 // under the terms of the GNU General Public License version 2 only, as
    8 // published by the Free Software Foundation.
    9 //
   10 // This code is distributed in the hope that it will be useful, but WITHOUT
   11 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   12 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   13 // version 2 for more details (a copy is included in the LICENSE file that
   14 // accompanied this code).
   15 //
   16 // You should have received a copy of the GNU General Public License version
   17 // 2 along with this work; if not, write to the Free Software Foundation,
   18 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   19 //
   20 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   21 // or visit www.oracle.com if you need additional information or have any
   22 // questions.
   23 //
   24 //
   25 
   26 // AArch64 Architecture Description File
   27 
   28 //----------REGISTER DEFINITION BLOCK------------------------------------------
   29 // This information is used by the matcher and the register allocator to
   30 // describe individual registers and classes of registers within the target
   31 // archtecture.
   32 
   33 register %{
   34 //----------Architecture Description Register Definitions----------------------
   35 // General Registers
   36 // &quot;reg_def&quot;  name ( register save type, C convention save type,
   37 //                   ideal register type, encoding );
   38 // Register Save Types:
   39 //
   40 // NS  = No-Save:       The register allocator assumes that these registers
   41 //                      can be used without saving upon entry to the method, &amp;
   42 //                      that they do not need to be saved at call sites.
   43 //
   44 // SOC = Save-On-Call:  The register allocator assumes that these registers
   45 //                      can be used without saving upon entry to the method,
   46 //                      but that they must be saved at call sites.
   47 //
   48 // SOE = Save-On-Entry: The register allocator assumes that these registers
   49 //                      must be saved before using them upon entry to the
   50 //                      method, but they do not need to be saved at call
   51 //                      sites.
   52 //
   53 // AS  = Always-Save:   The register allocator assumes that these registers
   54 //                      must be saved before using them upon entry to the
   55 //                      method, &amp; that they must be saved at call sites.
   56 //
   57 // Ideal Register Type is used to determine how to save &amp; restore a
   58 // register.  Op_RegI will get spilled with LoadI/StoreI, Op_RegP will get
   59 // spilled with LoadP/StoreP.  If the register supports both, use Op_RegI.
   60 //
   61 // The encoding number is the actual bit-pattern placed into the opcodes.
   62 
   63 // We must define the 64 bit int registers in two 32 bit halves, the
   64 // real lower register and a virtual upper half register. upper halves
   65 // are used by the register allocator but are not actually supplied as
   66 // operands to memory ops.
   67 //
   68 // follow the C1 compiler in making registers
   69 //
   70 //   r0-r7,r10-r26 volatile (caller save)
   71 //   r27-r32 system (no save, no allocate)
   72 //   r8-r9 invisible to the allocator (so we can use them as scratch regs)
   73 //
   74 // as regards Java usage. we don&#39;t use any callee save registers
   75 // because this makes it difficult to de-optimise a frame (see comment
   76 // in x86 implementation of Deoptimization::unwind_callee_save_values)
   77 //
   78 
   79 // General Registers
   80 
   81 reg_def R0      ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()         );
   82 reg_def R0_H    ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()-&gt;next() );
   83 reg_def R1      ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()         );
   84 reg_def R1_H    ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()-&gt;next() );
   85 reg_def R2      ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()         );
   86 reg_def R2_H    ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()-&gt;next() );
   87 reg_def R3      ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()         );
   88 reg_def R3_H    ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()-&gt;next() );
   89 reg_def R4      ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()         );
   90 reg_def R4_H    ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()-&gt;next() );
   91 reg_def R5      ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()         );
   92 reg_def R5_H    ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()-&gt;next() );
   93 reg_def R6      ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()         );
   94 reg_def R6_H    ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()-&gt;next() );
   95 reg_def R7      ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()         );
   96 reg_def R7_H    ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()-&gt;next() );
   97 reg_def R10     ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()        );
   98 reg_def R10_H   ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()-&gt;next());
   99 reg_def R11     ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()        );
  100 reg_def R11_H   ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()-&gt;next());
  101 reg_def R12     ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()        );
  102 reg_def R12_H   ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()-&gt;next());
  103 reg_def R13     ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()        );
  104 reg_def R13_H   ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()-&gt;next());
  105 reg_def R14     ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()        );
  106 reg_def R14_H   ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()-&gt;next());
  107 reg_def R15     ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()        );
  108 reg_def R15_H   ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()-&gt;next());
  109 reg_def R16     ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()        );
  110 reg_def R16_H   ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()-&gt;next());
  111 reg_def R17     ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()        );
  112 reg_def R17_H   ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()-&gt;next());
  113 reg_def R18     ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()        );
  114 reg_def R18_H   ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()-&gt;next());
  115 reg_def R19     ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()        );
  116 reg_def R19_H   ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()-&gt;next());
  117 reg_def R20     ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()        ); // caller esp
  118 reg_def R20_H   ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()-&gt;next());
  119 reg_def R21     ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()        );
  120 reg_def R21_H   ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()-&gt;next());
  121 reg_def R22     ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()        );
  122 reg_def R22_H   ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()-&gt;next());
  123 reg_def R23     ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()        );
  124 reg_def R23_H   ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()-&gt;next());
  125 reg_def R24     ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()        );
  126 reg_def R24_H   ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()-&gt;next());
  127 reg_def R25     ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()        );
  128 reg_def R25_H   ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()-&gt;next());
  129 reg_def R26     ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()        );
  130 reg_def R26_H   ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()-&gt;next());
  131 reg_def R27     ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()        ); // heapbase
  132 reg_def R27_H   ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()-&gt;next());
  133 reg_def R28     (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()        ); // thread
  134 reg_def R28_H   (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()-&gt;next());
  135 reg_def R29     (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()        ); // fp
  136 reg_def R29_H   (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()-&gt;next());
  137 reg_def R30     (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()        ); // lr
  138 reg_def R30_H   (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()-&gt;next());
  139 reg_def R31     (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()     ); // sp
  140 reg_def R31_H   (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()-&gt;next());
  141 
  142 // ----------------------------
  143 // Float/Double Registers
  144 // ----------------------------
  145 
  146 // Double Registers
  147 
  148 // The rules of ADL require that double registers be defined in pairs.
  149 // Each pair must be two 32-bit values, but not necessarily a pair of
  150 // single float registers. In each pair, ADLC-assigned register numbers
  151 // must be adjacent, with the lower number even. Finally, when the
  152 // CPU stores such a register pair to memory, the word associated with
  153 // the lower ADLC-assigned number must be stored to the lower address.
  154 
  155 // AArch64 has 32 floating-point registers. Each can store a vector of
  156 // single or double precision floating-point values up to 8 * 32
  157 // floats, 4 * 64 bit floats or 2 * 128 bit floats.  We currently only
  158 // use the first float or double element of the vector.
  159 
  160 // for Java use float registers v0-v15 are always save on call whereas
  161 // the platform ABI treats v8-v15 as callee save). float registers
  162 // v16-v31 are SOC as per the platform spec
  163 
  164   reg_def V0   ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()          );
  165   reg_def V0_H ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next()  );
  166   reg_def V0_J ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(2) );
  167   reg_def V0_K ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(3) );
  168 
  169   reg_def V1   ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()          );
  170   reg_def V1_H ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next()  );
  171   reg_def V1_J ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(2) );
  172   reg_def V1_K ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(3) );
  173 
  174   reg_def V2   ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()          );
  175   reg_def V2_H ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next()  );
  176   reg_def V2_J ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(2) );
  177   reg_def V2_K ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(3) );
  178 
  179   reg_def V3   ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()          );
  180   reg_def V3_H ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next()  );
  181   reg_def V3_J ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(2) );
  182   reg_def V3_K ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(3) );
  183 
  184   reg_def V4   ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()          );
  185   reg_def V4_H ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next()  );
  186   reg_def V4_J ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(2) );
  187   reg_def V4_K ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(3) );
  188 
  189   reg_def V5   ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()          );
  190   reg_def V5_H ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next()  );
  191   reg_def V5_J ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(2) );
  192   reg_def V5_K ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(3) );
  193 
  194   reg_def V6   ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()          );
  195   reg_def V6_H ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next()  );
  196   reg_def V6_J ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(2) );
  197   reg_def V6_K ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(3) );
  198 
  199   reg_def V7   ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()          );
  200   reg_def V7_H ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next()  );
  201   reg_def V7_J ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(2) );
  202   reg_def V7_K ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(3) );
  203 
  204   reg_def V8   ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()          );
  205   reg_def V8_H ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next()  );
  206   reg_def V8_J ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(2) );
  207   reg_def V8_K ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(3) );
  208 
  209   reg_def V9   ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()          );
  210   reg_def V9_H ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next()  );
  211   reg_def V9_J ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(2) );
  212   reg_def V9_K ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(3) );
  213 
  214   reg_def V10  ( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()         );
  215   reg_def V10_H( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next() );
  216   reg_def V10_J( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(2));
  217   reg_def V10_K( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(3));
  218 
  219   reg_def V11  ( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()         );
  220   reg_def V11_H( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next() );
  221   reg_def V11_J( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(2));
  222   reg_def V11_K( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(3));
  223 
  224   reg_def V12  ( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()         );
  225   reg_def V12_H( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next() );
  226   reg_def V12_J( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(2));
  227   reg_def V12_K( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(3));
  228 
  229   reg_def V13  ( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()         );
  230   reg_def V13_H( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next() );
  231   reg_def V13_J( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(2));
  232   reg_def V13_K( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(3));
  233 
  234   reg_def V14  ( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()         );
  235   reg_def V14_H( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next() );
  236   reg_def V14_J( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(2));
  237   reg_def V14_K( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(3));
  238 
  239   reg_def V15  ( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()         );
  240   reg_def V15_H( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next() );
  241   reg_def V15_J( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(2));
  242   reg_def V15_K( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(3));
  243 
  244   reg_def V16  ( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()         );
  245   reg_def V16_H( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next() );
  246   reg_def V16_J( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(2));
  247   reg_def V16_K( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(3));
  248 
  249   reg_def V17  ( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()         );
  250   reg_def V17_H( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next() );
  251   reg_def V17_J( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(2));
  252   reg_def V17_K( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(3));
  253 
  254   reg_def V18  ( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()         );
  255   reg_def V18_H( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next() );
  256   reg_def V18_J( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(2));
  257   reg_def V18_K( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(3));
  258 
  259   reg_def V19  ( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()         );
  260   reg_def V19_H( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next() );
  261   reg_def V19_J( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(2));
  262   reg_def V19_K( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(3));
  263 
  264   reg_def V20  ( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()         );
  265   reg_def V20_H( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next() );
  266   reg_def V20_J( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(2));
  267   reg_def V20_K( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(3));
  268 
  269   reg_def V21  ( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()         );
  270   reg_def V21_H( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next() );
  271   reg_def V21_J( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(2));
  272   reg_def V21_K( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(3));
  273 
  274   reg_def V22  ( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()         );
  275   reg_def V22_H( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next() );
  276   reg_def V22_J( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(2));
  277   reg_def V22_K( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(3));
  278 
  279   reg_def V23  ( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()         );
  280   reg_def V23_H( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next() );
  281   reg_def V23_J( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(2));
  282   reg_def V23_K( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(3));
  283 
  284   reg_def V24  ( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()         );
  285   reg_def V24_H( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next() );
  286   reg_def V24_J( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(2));
  287   reg_def V24_K( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(3));
  288 
  289   reg_def V25  ( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()         );
  290   reg_def V25_H( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next() );
  291   reg_def V25_J( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(2));
  292   reg_def V25_K( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(3));
  293 
  294   reg_def V26  ( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()         );
  295   reg_def V26_H( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next() );
  296   reg_def V26_J( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(2));
  297   reg_def V26_K( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(3));
  298 
  299   reg_def V27  ( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()         );
  300   reg_def V27_H( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next() );
  301   reg_def V27_J( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(2));
  302   reg_def V27_K( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(3));
  303 
  304   reg_def V28  ( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()         );
  305   reg_def V28_H( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next() );
  306   reg_def V28_J( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(2));
  307   reg_def V28_K( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(3));
  308 
  309   reg_def V29  ( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()         );
  310   reg_def V29_H( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next() );
  311   reg_def V29_J( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(2));
  312   reg_def V29_K( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(3));
  313 
  314   reg_def V30  ( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()         );
  315   reg_def V30_H( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next() );
  316   reg_def V30_J( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(2));
  317   reg_def V30_K( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(3));
  318 
  319   reg_def V31  ( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()         );
  320   reg_def V31_H( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next() );
  321   reg_def V31_J( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(2));
  322   reg_def V31_K( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(3));
  323 
  324 // ----------------------------
  325 // Special Registers
  326 // ----------------------------
  327 
  328 // the AArch64 CSPR status flag register is not directly acessible as
  329 // instruction operand. the FPSR status flag register is a system
  330 // register which can be written/read using MSR/MRS but again does not
  331 // appear as an operand (a code identifying the FSPR occurs as an
  332 // immediate value in the instruction).
  333 
  334 reg_def RFLAGS(SOC, SOC, 0, 32, VMRegImpl::Bad());
  335 
  336 
  337 // Specify priority of register selection within phases of register
  338 // allocation.  Highest priority is first.  A useful heuristic is to
  339 // give registers a low priority when they are required by machine
  340 // instructions, like EAX and EDX on I486, and choose no-save registers
  341 // before save-on-call, &amp; save-on-call before save-on-entry.  Registers
  342 // which participate in fixed calling sequences should come last.
  343 // Registers which are used as pairs must fall on an even boundary.
  344 
  345 alloc_class chunk0(
  346     // volatiles
  347     R10, R10_H,
  348     R11, R11_H,
  349     R12, R12_H,
  350     R13, R13_H,
  351     R14, R14_H,
  352     R15, R15_H,
  353     R16, R16_H,
  354     R17, R17_H,
  355     R18, R18_H,
  356 
  357     // arg registers
  358     R0, R0_H,
  359     R1, R1_H,
  360     R2, R2_H,
  361     R3, R3_H,
  362     R4, R4_H,
  363     R5, R5_H,
  364     R6, R6_H,
  365     R7, R7_H,
  366 
  367     // non-volatiles
  368     R19, R19_H,
  369     R20, R20_H,
  370     R21, R21_H,
  371     R22, R22_H,
  372     R23, R23_H,
  373     R24, R24_H,
  374     R25, R25_H,
  375     R26, R26_H,
  376 
  377     // non-allocatable registers
  378 
  379     R27, R27_H, // heapbase
  380     R28, R28_H, // thread
  381     R29, R29_H, // fp
  382     R30, R30_H, // lr
  383     R31, R31_H, // sp
  384 );
  385 
  386 alloc_class chunk1(
  387 
  388     // no save
  389     V16, V16_H, V16_J, V16_K,
  390     V17, V17_H, V17_J, V17_K,
  391     V18, V18_H, V18_J, V18_K,
  392     V19, V19_H, V19_J, V19_K,
  393     V20, V20_H, V20_J, V20_K,
  394     V21, V21_H, V21_J, V21_K,
  395     V22, V22_H, V22_J, V22_K,
  396     V23, V23_H, V23_J, V23_K,
  397     V24, V24_H, V24_J, V24_K,
  398     V25, V25_H, V25_J, V25_K,
  399     V26, V26_H, V26_J, V26_K,
  400     V27, V27_H, V27_J, V27_K,
  401     V28, V28_H, V28_J, V28_K,
  402     V29, V29_H, V29_J, V29_K,
  403     V30, V30_H, V30_J, V30_K,
  404     V31, V31_H, V31_J, V31_K,
  405 
  406     // arg registers
  407     V0, V0_H, V0_J, V0_K,
  408     V1, V1_H, V1_J, V1_K,
  409     V2, V2_H, V2_J, V2_K,
  410     V3, V3_H, V3_J, V3_K,
  411     V4, V4_H, V4_J, V4_K,
  412     V5, V5_H, V5_J, V5_K,
  413     V6, V6_H, V6_J, V6_K,
  414     V7, V7_H, V7_J, V7_K,
  415 
  416     // non-volatiles
  417     V8, V8_H, V8_J, V8_K,
  418     V9, V9_H, V9_J, V9_K,
  419     V10, V10_H, V10_J, V10_K,
  420     V11, V11_H, V11_J, V11_K,
  421     V12, V12_H, V12_J, V12_K,
  422     V13, V13_H, V13_J, V13_K,
  423     V14, V14_H, V14_J, V14_K,
  424     V15, V15_H, V15_J, V15_K,
  425 );
  426 
  427 alloc_class chunk2(RFLAGS);
  428 
  429 //----------Architecture Description Register Classes--------------------------
  430 // Several register classes are automatically defined based upon information in
  431 // this architecture description.
  432 // 1) reg_class inline_cache_reg           ( /* as def&#39;d in frame section */ )
  433 // 2) reg_class compiler_method_oop_reg    ( /* as def&#39;d in frame section */ )
  434 // 2) reg_class interpreter_method_oop_reg ( /* as def&#39;d in frame section */ )
  435 // 3) reg_class stack_slots( /* one chunk of stack-based &quot;registers&quot; */ )
  436 //
  437 
  438 // Class for all 32 bit general purpose registers
  439 reg_class all_reg32(
  440     R0,
  441     R1,
  442     R2,
  443     R3,
  444     R4,
  445     R5,
  446     R6,
  447     R7,
  448     R10,
  449     R11,
  450     R12,
  451     R13,
  452     R14,
  453     R15,
  454     R16,
  455     R17,
  456     R18,
  457     R19,
  458     R20,
  459     R21,
  460     R22,
  461     R23,
  462     R24,
  463     R25,
  464     R26,
  465     R27,
  466     R28,
  467     R29,
  468     R30,
  469     R31
  470 );
  471 
  472 
  473 // Class for all 32 bit integer registers (excluding SP which
  474 // will never be used as an integer register)
  475 reg_class any_reg32 %{
  476   return _ANY_REG32_mask;
  477 %}
  478 
  479 // Singleton class for R0 int register
  480 reg_class int_r0_reg(R0);
  481 
  482 // Singleton class for R2 int register
  483 reg_class int_r2_reg(R2);
  484 
  485 // Singleton class for R3 int register
  486 reg_class int_r3_reg(R3);
  487 
  488 // Singleton class for R4 int register
  489 reg_class int_r4_reg(R4);
  490 
  491 // Singleton class for R31 int register
  492 reg_class int_r31_reg(R31);
  493 
  494 // Class for all 64 bit general purpose registers
  495 reg_class all_reg(
  496     R0, R0_H,
  497     R1, R1_H,
  498     R2, R2_H,
  499     R3, R3_H,
  500     R4, R4_H,
  501     R5, R5_H,
  502     R6, R6_H,
  503     R7, R7_H,
  504     R10, R10_H,
  505     R11, R11_H,
  506     R12, R12_H,
  507     R13, R13_H,
  508     R14, R14_H,
  509     R15, R15_H,
  510     R16, R16_H,
  511     R17, R17_H,
  512     R18, R18_H,
  513     R19, R19_H,
  514     R20, R20_H,
  515     R21, R21_H,
  516     R22, R22_H,
  517     R23, R23_H,
  518     R24, R24_H,
  519     R25, R25_H,
  520     R26, R26_H,
  521     R27, R27_H,
  522     R28, R28_H,
  523     R29, R29_H,
  524     R30, R30_H,
  525     R31, R31_H
  526 );
  527 
  528 // Class for all long integer registers (including SP)
  529 reg_class any_reg %{
  530   return _ANY_REG_mask;
  531 %}
  532 
  533 // Class for non-allocatable 32 bit registers
  534 reg_class non_allocatable_reg32(
  535     R28,                        // thread
  536     R30,                        // lr
  537     R31                         // sp
  538 );
  539 
  540 // Class for non-allocatable 64 bit registers
  541 reg_class non_allocatable_reg(
  542     R28, R28_H,                 // thread
  543     R30, R30_H,                 // lr
  544     R31, R31_H                  // sp
  545 );
  546 
  547 // Class for all non-special integer registers
  548 reg_class no_special_reg32 %{
  549   return _NO_SPECIAL_REG32_mask;
  550 %}
  551 
  552 // Class for all non-special long integer registers
  553 reg_class no_special_reg %{
  554   return _NO_SPECIAL_REG_mask;
  555 %}
  556 
  557 // Class for 64 bit register r0
  558 reg_class r0_reg(
  559     R0, R0_H
  560 );
  561 
  562 // Class for 64 bit register r1
  563 reg_class r1_reg(
  564     R1, R1_H
  565 );
  566 
  567 // Class for 64 bit register r2
  568 reg_class r2_reg(
  569     R2, R2_H
  570 );
  571 
  572 // Class for 64 bit register r3
  573 reg_class r3_reg(
  574     R3, R3_H
  575 );
  576 
  577 // Class for 64 bit register r4
  578 reg_class r4_reg(
  579     R4, R4_H
  580 );
  581 
  582 // Class for 64 bit register r5
  583 reg_class r5_reg(
  584     R5, R5_H
  585 );
  586 
  587 // Class for 64 bit register r10
  588 reg_class r10_reg(
  589     R10, R10_H
  590 );
  591 
  592 // Class for 64 bit register r11
  593 reg_class r11_reg(
  594     R11, R11_H
  595 );
  596 
  597 // Class for method register
  598 reg_class method_reg(
  599     R12, R12_H
  600 );
  601 
  602 // Class for heapbase register
  603 reg_class heapbase_reg(
  604     R27, R27_H
  605 );
  606 
  607 // Class for thread register
  608 reg_class thread_reg(
  609     R28, R28_H
  610 );
  611 
  612 // Class for frame pointer register
  613 reg_class fp_reg(
  614     R29, R29_H
  615 );
  616 
  617 // Class for link register
  618 reg_class lr_reg(
  619     R30, R30_H
  620 );
  621 
  622 // Class for long sp register
  623 reg_class sp_reg(
  624   R31, R31_H
  625 );
  626 
  627 // Class for all pointer registers
  628 reg_class ptr_reg %{
  629   return _PTR_REG_mask;
  630 %}
  631 
  632 // Class for all non_special pointer registers
  633 reg_class no_special_ptr_reg %{
  634   return _NO_SPECIAL_PTR_REG_mask;
  635 %}
  636 
  637 // Class for all float registers
  638 reg_class float_reg(
  639     V0,
  640     V1,
  641     V2,
  642     V3,
  643     V4,
  644     V5,
  645     V6,
  646     V7,
  647     V8,
  648     V9,
  649     V10,
  650     V11,
  651     V12,
  652     V13,
  653     V14,
  654     V15,
  655     V16,
  656     V17,
  657     V18,
  658     V19,
  659     V20,
  660     V21,
  661     V22,
  662     V23,
  663     V24,
  664     V25,
  665     V26,
  666     V27,
  667     V28,
  668     V29,
  669     V30,
  670     V31
  671 );
  672 
  673 // Double precision float registers have virtual `high halves&#39; that
  674 // are needed by the allocator.
  675 // Class for all double registers
  676 reg_class double_reg(
  677     V0, V0_H,
  678     V1, V1_H,
  679     V2, V2_H,
  680     V3, V3_H,
  681     V4, V4_H,
  682     V5, V5_H,
  683     V6, V6_H,
  684     V7, V7_H,
  685     V8, V8_H,
  686     V9, V9_H,
  687     V10, V10_H,
  688     V11, V11_H,
  689     V12, V12_H,
  690     V13, V13_H,
  691     V14, V14_H,
  692     V15, V15_H,
  693     V16, V16_H,
  694     V17, V17_H,
  695     V18, V18_H,
  696     V19, V19_H,
  697     V20, V20_H,
  698     V21, V21_H,
  699     V22, V22_H,
  700     V23, V23_H,
  701     V24, V24_H,
  702     V25, V25_H,
  703     V26, V26_H,
  704     V27, V27_H,
  705     V28, V28_H,
  706     V29, V29_H,
  707     V30, V30_H,
  708     V31, V31_H
  709 );
  710 
  711 // Class for all 64bit vector registers
  712 reg_class vectord_reg(
  713     V0, V0_H,
  714     V1, V1_H,
  715     V2, V2_H,
  716     V3, V3_H,
  717     V4, V4_H,
  718     V5, V5_H,
  719     V6, V6_H,
  720     V7, V7_H,
  721     V8, V8_H,
  722     V9, V9_H,
  723     V10, V10_H,
  724     V11, V11_H,
  725     V12, V12_H,
  726     V13, V13_H,
  727     V14, V14_H,
  728     V15, V15_H,
  729     V16, V16_H,
  730     V17, V17_H,
  731     V18, V18_H,
  732     V19, V19_H,
  733     V20, V20_H,
  734     V21, V21_H,
  735     V22, V22_H,
  736     V23, V23_H,
  737     V24, V24_H,
  738     V25, V25_H,
  739     V26, V26_H,
  740     V27, V27_H,
  741     V28, V28_H,
  742     V29, V29_H,
  743     V30, V30_H,
  744     V31, V31_H
  745 );
  746 
  747 // Class for all 128bit vector registers
  748 reg_class vectorx_reg(
  749     V0, V0_H, V0_J, V0_K,
  750     V1, V1_H, V1_J, V1_K,
  751     V2, V2_H, V2_J, V2_K,
  752     V3, V3_H, V3_J, V3_K,
  753     V4, V4_H, V4_J, V4_K,
  754     V5, V5_H, V5_J, V5_K,
  755     V6, V6_H, V6_J, V6_K,
  756     V7, V7_H, V7_J, V7_K,
  757     V8, V8_H, V8_J, V8_K,
  758     V9, V9_H, V9_J, V9_K,
  759     V10, V10_H, V10_J, V10_K,
  760     V11, V11_H, V11_J, V11_K,
  761     V12, V12_H, V12_J, V12_K,
  762     V13, V13_H, V13_J, V13_K,
  763     V14, V14_H, V14_J, V14_K,
  764     V15, V15_H, V15_J, V15_K,
  765     V16, V16_H, V16_J, V16_K,
  766     V17, V17_H, V17_J, V17_K,
  767     V18, V18_H, V18_J, V18_K,
  768     V19, V19_H, V19_J, V19_K,
  769     V20, V20_H, V20_J, V20_K,
  770     V21, V21_H, V21_J, V21_K,
  771     V22, V22_H, V22_J, V22_K,
  772     V23, V23_H, V23_J, V23_K,
  773     V24, V24_H, V24_J, V24_K,
  774     V25, V25_H, V25_J, V25_K,
  775     V26, V26_H, V26_J, V26_K,
  776     V27, V27_H, V27_J, V27_K,
  777     V28, V28_H, V28_J, V28_K,
  778     V29, V29_H, V29_J, V29_K,
  779     V30, V30_H, V30_J, V30_K,
  780     V31, V31_H, V31_J, V31_K
  781 );
  782 
  783 // Class for 128 bit register v0
  784 reg_class v0_reg(
  785     V0, V0_H
  786 );
  787 
  788 // Class for 128 bit register v1
  789 reg_class v1_reg(
  790     V1, V1_H
  791 );
  792 
  793 // Class for 128 bit register v2
  794 reg_class v2_reg(
  795     V2, V2_H
  796 );
  797 
  798 // Class for 128 bit register v3
  799 reg_class v3_reg(
  800     V3, V3_H
  801 );
  802 
  803 // Class for 128 bit register v4
  804 reg_class v4_reg(
  805     V4, V4_H
  806 );
  807 
  808 // Class for 128 bit register v5
  809 reg_class v5_reg(
  810     V5, V5_H
  811 );
  812 
  813 // Class for 128 bit register v6
  814 reg_class v6_reg(
  815     V6, V6_H
  816 );
  817 
  818 // Class for 128 bit register v7
  819 reg_class v7_reg(
  820     V7, V7_H
  821 );
  822 
  823 // Class for 128 bit register v8
  824 reg_class v8_reg(
  825     V8, V8_H
  826 );
  827 
  828 // Class for 128 bit register v9
  829 reg_class v9_reg(
  830     V9, V9_H
  831 );
  832 
  833 // Class for 128 bit register v10
  834 reg_class v10_reg(
  835     V10, V10_H
  836 );
  837 
  838 // Class for 128 bit register v11
  839 reg_class v11_reg(
  840     V11, V11_H
  841 );
  842 
  843 // Class for 128 bit register v12
  844 reg_class v12_reg(
  845     V12, V12_H
  846 );
  847 
  848 // Class for 128 bit register v13
  849 reg_class v13_reg(
  850     V13, V13_H
  851 );
  852 
  853 // Class for 128 bit register v14
  854 reg_class v14_reg(
  855     V14, V14_H
  856 );
  857 
  858 // Class for 128 bit register v15
  859 reg_class v15_reg(
  860     V15, V15_H
  861 );
  862 
  863 // Class for 128 bit register v16
  864 reg_class v16_reg(
  865     V16, V16_H
  866 );
  867 
  868 // Class for 128 bit register v17
  869 reg_class v17_reg(
  870     V17, V17_H
  871 );
  872 
  873 // Class for 128 bit register v18
  874 reg_class v18_reg(
  875     V18, V18_H
  876 );
  877 
  878 // Class for 128 bit register v19
  879 reg_class v19_reg(
  880     V19, V19_H
  881 );
  882 
  883 // Class for 128 bit register v20
  884 reg_class v20_reg(
  885     V20, V20_H
  886 );
  887 
  888 // Class for 128 bit register v21
  889 reg_class v21_reg(
  890     V21, V21_H
  891 );
  892 
  893 // Class for 128 bit register v22
  894 reg_class v22_reg(
  895     V22, V22_H
  896 );
  897 
  898 // Class for 128 bit register v23
  899 reg_class v23_reg(
  900     V23, V23_H
  901 );
  902 
  903 // Class for 128 bit register v24
  904 reg_class v24_reg(
  905     V24, V24_H
  906 );
  907 
  908 // Class for 128 bit register v25
  909 reg_class v25_reg(
  910     V25, V25_H
  911 );
  912 
  913 // Class for 128 bit register v26
  914 reg_class v26_reg(
  915     V26, V26_H
  916 );
  917 
  918 // Class for 128 bit register v27
  919 reg_class v27_reg(
  920     V27, V27_H
  921 );
  922 
  923 // Class for 128 bit register v28
  924 reg_class v28_reg(
  925     V28, V28_H
  926 );
  927 
  928 // Class for 128 bit register v29
  929 reg_class v29_reg(
  930     V29, V29_H
  931 );
  932 
  933 // Class for 128 bit register v30
  934 reg_class v30_reg(
  935     V30, V30_H
  936 );
  937 
  938 // Class for 128 bit register v31
  939 reg_class v31_reg(
  940     V31, V31_H
  941 );
  942 
  943 // Singleton class for condition codes
  944 reg_class int_flags(RFLAGS);
  945 
  946 %}
  947 
  948 //----------DEFINITION BLOCK---------------------------------------------------
  949 // Define name --&gt; value mappings to inform the ADLC of an integer valued name
  950 // Current support includes integer values in the range [0, 0x7FFFFFFF]
  951 // Format:
  952 //        int_def  &lt;name&gt;         ( &lt;int_value&gt;, &lt;expression&gt;);
  953 // Generated Code in ad_&lt;arch&gt;.hpp
  954 //        #define  &lt;name&gt;   (&lt;expression&gt;)
  955 //        // value == &lt;int_value&gt;
  956 // Generated code in ad_&lt;arch&gt;.cpp adlc_verification()
  957 //        assert( &lt;name&gt; == &lt;int_value&gt;, &quot;Expect (&lt;expression&gt;) to equal &lt;int_value&gt;&quot;);
  958 //
  959 
  960 // we follow the ppc-aix port in using a simple cost model which ranks
  961 // register operations as cheap, memory ops as more expensive and
  962 // branches as most expensive. the first two have a low as well as a
  963 // normal cost. huge cost appears to be a way of saying don&#39;t do
  964 // something
  965 
  966 definitions %{
  967   // The default cost (of a register move instruction).
  968   int_def INSN_COST            (    100,     100);
  969   int_def BRANCH_COST          (    200,     2 * INSN_COST);
  970   int_def CALL_COST            (    200,     2 * INSN_COST);
  971   int_def VOLATILE_REF_COST    (   1000,     10 * INSN_COST);
  972 %}
  973 
  974 
  975 //----------SOURCE BLOCK-------------------------------------------------------
  976 // This is a block of C++ code which provides values, functions, and
  977 // definitions necessary in the rest of the architecture description
  978 
  979 source_hpp %{
  980 
  981 #include &quot;asm/macroAssembler.hpp&quot;
  982 #include &quot;gc/shared/cardTable.hpp&quot;
  983 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;
  984 #include &quot;gc/shared/collectedHeap.hpp&quot;
  985 #include &quot;opto/addnode.hpp&quot;
  986 #include &quot;opto/convertnode.hpp&quot;
  987 
  988 extern RegMask _ANY_REG32_mask;
  989 extern RegMask _ANY_REG_mask;
  990 extern RegMask _PTR_REG_mask;
  991 extern RegMask _NO_SPECIAL_REG32_mask;
  992 extern RegMask _NO_SPECIAL_REG_mask;
  993 extern RegMask _NO_SPECIAL_PTR_REG_mask;
  994 
  995 class CallStubImpl {
  996 
  997   //--------------------------------------------------------------
  998   //---&lt;  Used for optimization in Compile::shorten_branches  &gt;---
  999   //--------------------------------------------------------------
 1000 
 1001  public:
 1002   // Size of call trampoline stub.
 1003   static uint size_call_trampoline() {
 1004     return 0; // no call trampolines on this platform
 1005   }
 1006 
 1007   // number of relocations needed by a call trampoline stub
 1008   static uint reloc_call_trampoline() {
 1009     return 0; // no call trampolines on this platform
 1010   }
 1011 };
 1012 
 1013 class HandlerImpl {
 1014 
 1015  public:
 1016 
 1017   static int emit_exception_handler(CodeBuffer &amp;cbuf);
 1018   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
 1019 
 1020   static uint size_exception_handler() {
 1021     return MacroAssembler::far_branch_size();
 1022   }
 1023 
 1024   static uint size_deopt_handler() {
 1025     // count one adr and one far branch instruction
 1026     return 4 * NativeInstruction::instruction_size;
 1027   }
 1028 };
 1029 
 1030 class Node::PD {
 1031 public:
 1032   enum NodeFlags {
 1033     _last_flag = Node::_last_flag
 1034   };
 1035 };
 1036 
 1037  bool is_CAS(int opcode, bool maybe_volatile);
 1038 
 1039   // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1040 
 1041   bool unnecessary_acquire(const Node *barrier);
 1042   bool needs_acquiring_load(const Node *load);
 1043 
 1044   // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1045 
 1046   bool unnecessary_release(const Node *barrier);
 1047   bool unnecessary_volatile(const Node *barrier);
 1048   bool needs_releasing_store(const Node *store);
 1049 
 1050   // predicate controlling translation of CompareAndSwapX
 1051   bool needs_acquiring_load_exclusive(const Node *load);
 1052 
 1053   // predicate controlling addressing modes
 1054   bool size_fits_all_mem_uses(AddPNode* addp, int shift);
 1055 %}
 1056 
 1057 source %{
 1058 
 1059   // Derived RegMask with conditionally allocatable registers
 1060 
 1061   void PhaseOutput::pd_perform_mach_node_analysis() {
 1062   }
 1063 
 1064   int MachNode::pd_alignment_required() const {
 1065     return 1;
 1066   }
 1067 
 1068   int MachNode::compute_padding(int current_offset) const {
 1069     return 0;
 1070   }
 1071 
 1072   RegMask _ANY_REG32_mask;
 1073   RegMask _ANY_REG_mask;
 1074   RegMask _PTR_REG_mask;
 1075   RegMask _NO_SPECIAL_REG32_mask;
 1076   RegMask _NO_SPECIAL_REG_mask;
 1077   RegMask _NO_SPECIAL_PTR_REG_mask;
 1078 
 1079   void reg_mask_init() {
 1080     // We derive below RegMask(s) from the ones which are auto-generated from
 1081     // adlc register classes to make AArch64 rheapbase (r27) and rfp (r29)
 1082     // registers conditionally reserved.
 1083 
 1084     _ANY_REG32_mask = _ALL_REG32_mask;
 1085     _ANY_REG32_mask.Remove(OptoReg::as_OptoReg(r31_sp-&gt;as_VMReg()));
 1086 
 1087     _ANY_REG_mask = _ALL_REG_mask;
 1088 
 1089     _PTR_REG_mask = _ALL_REG_mask;
 1090 
 1091     _NO_SPECIAL_REG32_mask = _ALL_REG32_mask;
 1092     _NO_SPECIAL_REG32_mask.SUBTRACT(_NON_ALLOCATABLE_REG32_mask);
 1093 
 1094     _NO_SPECIAL_REG_mask = _ALL_REG_mask;
 1095     _NO_SPECIAL_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1096 
 1097     _NO_SPECIAL_PTR_REG_mask = _ALL_REG_mask;
 1098     _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1099 
 1100     // r27 is not allocatable when compressed oops is on and heapbase is not
 1101     // zero, compressed klass pointers doesn&#39;t use r27 after JDK-8234794
 1102     if (UseCompressedOops &amp;&amp; (CompressedOops::ptrs_base() != NULL || UseAOT)) {
 1103       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r27-&gt;as_VMReg()));
 1104       _NO_SPECIAL_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1105       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1106     }
 1107 
 1108     // r29 is not allocatable when PreserveFramePointer is on
 1109     if (PreserveFramePointer) {
 1110       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r29-&gt;as_VMReg()));
 1111       _NO_SPECIAL_REG_mask.SUBTRACT(_FP_REG_mask);
 1112       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_FP_REG_mask);
 1113     }
 1114   }
 1115 
 1116   // Optimizaton of volatile gets and puts
 1117   // -------------------------------------
 1118   //
 1119   // AArch64 has ldar&lt;x&gt; and stlr&lt;x&gt; instructions which we can safely
 1120   // use to implement volatile reads and writes. For a volatile read
 1121   // we simply need
 1122   //
 1123   //   ldar&lt;x&gt;
 1124   //
 1125   // and for a volatile write we need
 1126   //
 1127   //   stlr&lt;x&gt;
 1128   //
 1129   // Alternatively, we can implement them by pairing a normal
 1130   // load/store with a memory barrier. For a volatile read we need
 1131   //
 1132   //   ldr&lt;x&gt;
 1133   //   dmb ishld
 1134   //
 1135   // for a volatile write
 1136   //
 1137   //   dmb ish
 1138   //   str&lt;x&gt;
 1139   //   dmb ish
 1140   //
 1141   // We can also use ldaxr and stlxr to implement compare and swap CAS
 1142   // sequences. These are normally translated to an instruction
 1143   // sequence like the following
 1144   //
 1145   //   dmb      ish
 1146   // retry:
 1147   //   ldxr&lt;x&gt;   rval raddr
 1148   //   cmp       rval rold
 1149   //   b.ne done
 1150   //   stlxr&lt;x&gt;  rval, rnew, rold
 1151   //   cbnz      rval retry
 1152   // done:
 1153   //   cset      r0, eq
 1154   //   dmb ishld
 1155   //
 1156   // Note that the exclusive store is already using an stlxr
 1157   // instruction. That is required to ensure visibility to other
 1158   // threads of the exclusive write (assuming it succeeds) before that
 1159   // of any subsequent writes.
 1160   //
 1161   // The following instruction sequence is an improvement on the above
 1162   //
 1163   // retry:
 1164   //   ldaxr&lt;x&gt;  rval raddr
 1165   //   cmp       rval rold
 1166   //   b.ne done
 1167   //   stlxr&lt;x&gt;  rval, rnew, rold
 1168   //   cbnz      rval retry
 1169   // done:
 1170   //   cset      r0, eq
 1171   //
 1172   // We don&#39;t need the leading dmb ish since the stlxr guarantees
 1173   // visibility of prior writes in the case that the swap is
 1174   // successful. Crucially we don&#39;t have to worry about the case where
 1175   // the swap is not successful since no valid program should be
 1176   // relying on visibility of prior changes by the attempting thread
 1177   // in the case where the CAS fails.
 1178   //
 1179   // Similarly, we don&#39;t need the trailing dmb ishld if we substitute
 1180   // an ldaxr instruction since that will provide all the guarantees we
 1181   // require regarding observation of changes made by other threads
 1182   // before any change to the CAS address observed by the load.
 1183   //
 1184   // In order to generate the desired instruction sequence we need to
 1185   // be able to identify specific &#39;signature&#39; ideal graph node
 1186   // sequences which i) occur as a translation of a volatile reads or
 1187   // writes or CAS operations and ii) do not occur through any other
 1188   // translation or graph transformation. We can then provide
 1189   // alternative aldc matching rules which translate these node
 1190   // sequences to the desired machine code sequences. Selection of the
 1191   // alternative rules can be implemented by predicates which identify
 1192   // the relevant node sequences.
 1193   //
 1194   // The ideal graph generator translates a volatile read to the node
 1195   // sequence
 1196   //
 1197   //   LoadX[mo_acquire]
 1198   //   MemBarAcquire
 1199   //
 1200   // As a special case when using the compressed oops optimization we
 1201   // may also see this variant
 1202   //
 1203   //   LoadN[mo_acquire]
 1204   //   DecodeN
 1205   //   MemBarAcquire
 1206   //
 1207   // A volatile write is translated to the node sequence
 1208   //
 1209   //   MemBarRelease
 1210   //   StoreX[mo_release] {CardMark}-optional
 1211   //   MemBarVolatile
 1212   //
 1213   // n.b. the above node patterns are generated with a strict
 1214   // &#39;signature&#39; configuration of input and output dependencies (see
 1215   // the predicates below for exact details). The card mark may be as
 1216   // simple as a few extra nodes or, in a few GC configurations, may
 1217   // include more complex control flow between the leading and
 1218   // trailing memory barriers. However, whatever the card mark
 1219   // configuration these signatures are unique to translated volatile
 1220   // reads/stores -- they will not appear as a result of any other
 1221   // bytecode translation or inlining nor as a consequence of
 1222   // optimizing transforms.
 1223   //
 1224   // We also want to catch inlined unsafe volatile gets and puts and
 1225   // be able to implement them using either ldar&lt;x&gt;/stlr&lt;x&gt; or some
 1226   // combination of ldr&lt;x&gt;/stlr&lt;x&gt; and dmb instructions.
 1227   //
 1228   // Inlined unsafe volatiles puts manifest as a minor variant of the
 1229   // normal volatile put node sequence containing an extra cpuorder
 1230   // membar
 1231   //
 1232   //   MemBarRelease
 1233   //   MemBarCPUOrder
 1234   //   StoreX[mo_release] {CardMark}-optional
 1235   //   MemBarCPUOrder
 1236   //   MemBarVolatile
 1237   //
 1238   // n.b. as an aside, a cpuorder membar is not itself subject to
 1239   // matching and translation by adlc rules.  However, the rule
 1240   // predicates need to detect its presence in order to correctly
 1241   // select the desired adlc rules.
 1242   //
 1243   // Inlined unsafe volatile gets manifest as a slightly different
 1244   // node sequence to a normal volatile get because of the
 1245   // introduction of some CPUOrder memory barriers to bracket the
 1246   // Load. However, but the same basic skeleton of a LoadX feeding a
 1247   // MemBarAcquire, possibly thorugh an optional DecodeN, is still
 1248   // present
 1249   //
 1250   //   MemBarCPUOrder
 1251   //        ||       \\
 1252   //   MemBarCPUOrder LoadX[mo_acquire]
 1253   //        ||            |
 1254   //        ||       {DecodeN} optional
 1255   //        ||       /
 1256   //     MemBarAcquire
 1257   //
 1258   // In this case the acquire membar does not directly depend on the
 1259   // load. However, we can be sure that the load is generated from an
 1260   // inlined unsafe volatile get if we see it dependent on this unique
 1261   // sequence of membar nodes. Similarly, given an acquire membar we
 1262   // can know that it was added because of an inlined unsafe volatile
 1263   // get if it is fed and feeds a cpuorder membar and if its feed
 1264   // membar also feeds an acquiring load.
 1265   //
 1266   // Finally an inlined (Unsafe) CAS operation is translated to the
 1267   // following ideal graph
 1268   //
 1269   //   MemBarRelease
 1270   //   MemBarCPUOrder
 1271   //   CompareAndSwapX {CardMark}-optional
 1272   //   MemBarCPUOrder
 1273   //   MemBarAcquire
 1274   //
 1275   // So, where we can identify these volatile read and write
 1276   // signatures we can choose to plant either of the above two code
 1277   // sequences. For a volatile read we can simply plant a normal
 1278   // ldr&lt;x&gt; and translate the MemBarAcquire to a dmb. However, we can
 1279   // also choose to inhibit translation of the MemBarAcquire and
 1280   // inhibit planting of the ldr&lt;x&gt;, instead planting an ldar&lt;x&gt;.
 1281   //
 1282   // When we recognise a volatile store signature we can choose to
 1283   // plant at a dmb ish as a translation for the MemBarRelease, a
 1284   // normal str&lt;x&gt; and then a dmb ish for the MemBarVolatile.
 1285   // Alternatively, we can inhibit translation of the MemBarRelease
 1286   // and MemBarVolatile and instead plant a simple stlr&lt;x&gt;
 1287   // instruction.
 1288   //
 1289   // when we recognise a CAS signature we can choose to plant a dmb
 1290   // ish as a translation for the MemBarRelease, the conventional
 1291   // macro-instruction sequence for the CompareAndSwap node (which
 1292   // uses ldxr&lt;x&gt;) and then a dmb ishld for the MemBarAcquire.
 1293   // Alternatively, we can elide generation of the dmb instructions
 1294   // and plant the alternative CompareAndSwap macro-instruction
 1295   // sequence (which uses ldaxr&lt;x&gt;).
 1296   //
 1297   // Of course, the above only applies when we see these signature
 1298   // configurations. We still want to plant dmb instructions in any
 1299   // other cases where we may see a MemBarAcquire, MemBarRelease or
 1300   // MemBarVolatile. For example, at the end of a constructor which
 1301   // writes final/volatile fields we will see a MemBarRelease
 1302   // instruction and this needs a &#39;dmb ish&#39; lest we risk the
 1303   // constructed object being visible without making the
 1304   // final/volatile field writes visible.
 1305   //
 1306   // n.b. the translation rules below which rely on detection of the
 1307   // volatile signatures and insert ldar&lt;x&gt; or stlr&lt;x&gt; are failsafe.
 1308   // If we see anything other than the signature configurations we
 1309   // always just translate the loads and stores to ldr&lt;x&gt; and str&lt;x&gt;
 1310   // and translate acquire, release and volatile membars to the
 1311   // relevant dmb instructions.
 1312   //
 1313 
 1314   // is_CAS(int opcode, bool maybe_volatile)
 1315   //
 1316   // return true if opcode is one of the possible CompareAndSwapX
 1317   // values otherwise false.
 1318 
 1319   bool is_CAS(int opcode, bool maybe_volatile)
 1320   {
 1321     switch(opcode) {
 1322       // We handle these
 1323     case Op_CompareAndSwapI:
 1324     case Op_CompareAndSwapL:
 1325     case Op_CompareAndSwapP:
 1326     case Op_CompareAndSwapN:
 1327     case Op_ShenandoahCompareAndSwapP:
 1328     case Op_ShenandoahCompareAndSwapN:
 1329     case Op_CompareAndSwapB:
 1330     case Op_CompareAndSwapS:
 1331     case Op_GetAndSetI:
 1332     case Op_GetAndSetL:
 1333     case Op_GetAndSetP:
 1334     case Op_GetAndSetN:
 1335     case Op_GetAndAddI:
 1336     case Op_GetAndAddL:
 1337       return true;
 1338     case Op_CompareAndExchangeI:
 1339     case Op_CompareAndExchangeN:
 1340     case Op_CompareAndExchangeB:
 1341     case Op_CompareAndExchangeS:
 1342     case Op_CompareAndExchangeL:
 1343     case Op_CompareAndExchangeP:
 1344     case Op_WeakCompareAndSwapB:
 1345     case Op_WeakCompareAndSwapS:
 1346     case Op_WeakCompareAndSwapI:
 1347     case Op_WeakCompareAndSwapL:
 1348     case Op_WeakCompareAndSwapP:
 1349     case Op_WeakCompareAndSwapN:
 1350     case Op_ShenandoahWeakCompareAndSwapP:
 1351     case Op_ShenandoahWeakCompareAndSwapN:
 1352     case Op_ShenandoahCompareAndExchangeP:
 1353     case Op_ShenandoahCompareAndExchangeN:
 1354       return maybe_volatile;
 1355     default:
 1356       return false;
 1357     }
 1358   }
 1359 
 1360   // helper to determine the maximum number of Phi nodes we may need to
 1361   // traverse when searching from a card mark membar for the merge mem
 1362   // feeding a trailing membar or vice versa
 1363 
 1364 // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt;
 1365 
 1366 bool unnecessary_acquire(const Node *barrier)
 1367 {
 1368   assert(barrier-&gt;is_MemBar(), &quot;expecting a membar&quot;);
 1369 
 1370   MemBarNode* mb = barrier-&gt;as_MemBar();
 1371 
 1372   if (mb-&gt;trailing_load()) {
 1373     return true;
 1374   }
 1375 
 1376   if (mb-&gt;trailing_load_store()) {
 1377     Node* load_store = mb-&gt;in(MemBarNode::Precedent);
 1378     assert(load_store-&gt;is_LoadStore(), &quot;unexpected graph shape&quot;);
 1379     return is_CAS(load_store-&gt;Opcode(), true);
 1380   }
 1381 
 1382   return false;
 1383 }
 1384 
 1385 bool needs_acquiring_load(const Node *n)
 1386 {
 1387   assert(n-&gt;is_Load(), &quot;expecting a load&quot;);
 1388   LoadNode *ld = n-&gt;as_Load();
 1389   return ld-&gt;is_acquire();
 1390 }
 1391 
 1392 bool unnecessary_release(const Node *n)
 1393 {
 1394   assert((n-&gt;is_MemBar() &amp;&amp;
 1395           n-&gt;Opcode() == Op_MemBarRelease),
 1396          &quot;expecting a release membar&quot;);
 1397 
 1398   MemBarNode *barrier = n-&gt;as_MemBar();
 1399   if (!barrier-&gt;leading()) {
 1400     return false;
 1401   } else {
 1402     Node* trailing = barrier-&gt;trailing_membar();
 1403     MemBarNode* trailing_mb = trailing-&gt;as_MemBar();
 1404     assert(trailing_mb-&gt;trailing(), &quot;Not a trailing membar?&quot;);
 1405     assert(trailing_mb-&gt;leading_membar() == n, &quot;inconsistent leading/trailing membars&quot;);
 1406 
 1407     Node* mem = trailing_mb-&gt;in(MemBarNode::Precedent);
 1408     if (mem-&gt;is_Store()) {
 1409       assert(mem-&gt;as_Store()-&gt;is_release(), &quot;&quot;);
 1410       assert(trailing_mb-&gt;Opcode() == Op_MemBarVolatile, &quot;&quot;);
 1411       return true;
 1412     } else {
 1413       assert(mem-&gt;is_LoadStore(), &quot;&quot;);
 1414       assert(trailing_mb-&gt;Opcode() == Op_MemBarAcquire, &quot;&quot;);
 1415       return is_CAS(mem-&gt;Opcode(), true);
 1416     }
 1417   }
 1418   return false;
 1419 }
 1420 
 1421 bool unnecessary_volatile(const Node *n)
 1422 {
 1423   // assert n-&gt;is_MemBar();
 1424   MemBarNode *mbvol = n-&gt;as_MemBar();
 1425 
 1426   bool release = mbvol-&gt;trailing_store();
 1427   assert(!release || (mbvol-&gt;in(MemBarNode::Precedent)-&gt;is_Store() &amp;&amp; mbvol-&gt;in(MemBarNode::Precedent)-&gt;as_Store()-&gt;is_release()), &quot;&quot;);
 1428 #ifdef ASSERT
 1429   if (release) {
 1430     Node* leading = mbvol-&gt;leading_membar();
 1431     assert(leading-&gt;Opcode() == Op_MemBarRelease, &quot;&quot;);
 1432     assert(leading-&gt;as_MemBar()-&gt;leading_store(), &quot;&quot;);
 1433     assert(leading-&gt;as_MemBar()-&gt;trailing_membar() == mbvol, &quot;&quot;);
 1434   }
 1435 #endif
 1436 
 1437   return release;
 1438 }
 1439 
 1440 // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt;
 1441 
 1442 bool needs_releasing_store(const Node *n)
 1443 {
 1444   // assert n-&gt;is_Store();
 1445   StoreNode *st = n-&gt;as_Store();
 1446   return st-&gt;trailing_membar() != NULL;
 1447 }
 1448 
 1449 // predicate controlling translation of CAS
 1450 //
 1451 // returns true if CAS needs to use an acquiring load otherwise false
 1452 
 1453 bool needs_acquiring_load_exclusive(const Node *n)
 1454 {
 1455   assert(is_CAS(n-&gt;Opcode(), true), &quot;expecting a compare and swap&quot;);
 1456   LoadStoreNode* ldst = n-&gt;as_LoadStore();
 1457   if (is_CAS(n-&gt;Opcode(), false)) {
 1458     assert(ldst-&gt;trailing_membar() != NULL, &quot;expected trailing membar&quot;);
 1459   } else {
 1460     return ldst-&gt;trailing_membar() != NULL;
 1461   }
 1462 
 1463   // so we can just return true here
 1464   return true;
 1465 }
 1466 
 1467 #define __ _masm.
 1468 
 1469 // advance declarations for helper functions to convert register
 1470 // indices to register objects
 1471 
 1472 // the ad file has to provide implementations of certain methods
 1473 // expected by the generic code
 1474 //
 1475 // REQUIRED FUNCTIONALITY
 1476 
 1477 //=============================================================================
 1478 
 1479 // !!!!! Special hack to get all types of calls to specify the byte offset
 1480 //       from the start of the call to the point where the return address
 1481 //       will point.
 1482 
 1483 int MachCallStaticJavaNode::ret_addr_offset()
 1484 {
 1485   // call should be a simple bl
 1486   int off = 4;
 1487   return off;
 1488 }
 1489 
 1490 int MachCallDynamicJavaNode::ret_addr_offset()
 1491 {
 1492   return 16; // movz, movk, movk, bl
 1493 }
 1494 
 1495 int MachCallRuntimeNode::ret_addr_offset() {
 1496   // for generated stubs the call will be
 1497   //   far_call(addr)
 1498   // for real runtime callouts it will be six instructions
 1499   // see aarch64_enc_java_to_runtime
 1500   //   adr(rscratch2, retaddr)
 1501   //   lea(rscratch1, RuntimeAddress(addr)
 1502   //   stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)))
 1503   //   blr(rscratch1)
 1504   CodeBlob *cb = CodeCache::find_blob(_entry_point);
 1505   if (cb) {
 1506     return MacroAssembler::far_branch_size();
 1507   } else {
 1508     return 6 * NativeInstruction::instruction_size;
 1509   }
 1510 }
 1511 
 1512 int MachCallNativeNode::ret_addr_offset() {
 1513   ShouldNotReachHere();
 1514   return -1;
 1515 }
 1516 
 1517 // Indicate if the safepoint node needs the polling page as an input
 1518 
 1519 // the shared code plants the oop data at the start of the generated
 1520 // code for the safepoint node and that needs ot be at the load
 1521 // instruction itself. so we cannot plant a mov of the safepoint poll
 1522 // address followed by a load. setting this to true means the mov is
 1523 // scheduled as a prior instruction. that&#39;s better for scheduling
 1524 // anyway.
 1525 
 1526 bool SafePointNode::needs_polling_address_input()
 1527 {
 1528   return true;
 1529 }
 1530 
 1531 //=============================================================================
 1532 
 1533 #ifndef PRODUCT
 1534 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1535   st-&gt;print(&quot;BREAKPOINT&quot;);
 1536 }
 1537 #endif
 1538 
 1539 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1540   C2_MacroAssembler _masm(&amp;cbuf);
 1541   __ brk(0);
 1542 }
 1543 
 1544 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
 1545   return MachNode::size(ra_);
 1546 }
 1547 
 1548 //=============================================================================
 1549 
 1550 #ifndef PRODUCT
 1551   void MachNopNode::format(PhaseRegAlloc*, outputStream* st) const {
 1552     st-&gt;print(&quot;nop \t# %d bytes pad for loops and calls&quot;, _count);
 1553   }
 1554 #endif
 1555 
 1556   void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc*) const {
 1557     C2_MacroAssembler _masm(&amp;cbuf);
 1558     for (int i = 0; i &lt; _count; i++) {
 1559       __ nop();
 1560     }
 1561   }
 1562 
 1563   uint MachNopNode::size(PhaseRegAlloc*) const {
 1564     return _count * NativeInstruction::instruction_size;
 1565   }
 1566 
 1567 //=============================================================================
 1568 const RegMask&amp; MachConstantBaseNode::_out_RegMask = RegMask::Empty;
 1569 
 1570 int ConstantTable::calculate_table_base_offset() const {
 1571   return 0;  // absolute addressing, no offset
 1572 }
 1573 
 1574 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
 1575 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1576   ShouldNotReachHere();
 1577 }
 1578 
 1579 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1580   // Empty encoding
 1581 }
 1582 
 1583 uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
 1584   return 0;
 1585 }
 1586 
 1587 #ifndef PRODUCT
 1588 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1589   st-&gt;print(&quot;-- \t// MachConstantBaseNode (empty encoding)&quot;);
 1590 }
 1591 #endif
 1592 
 1593 #ifndef PRODUCT
 1594 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1595   Compile* C = ra_-&gt;C;
 1596 
 1597   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1598 
 1599   if (C-&gt;output()-&gt;need_stack_bang(framesize))
 1600     st-&gt;print(&quot;# stack bang size=%d\n\t&quot;, framesize);
 1601 
 1602   if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1603     st-&gt;print(&quot;sub  sp, sp, #%d\n\t&quot;, framesize);
 1604     st-&gt;print(&quot;stp  rfp, lr, [sp, #%d]&quot;, framesize - 2 * wordSize);
 1605     if (PreserveFramePointer) st-&gt;print(&quot;\n\tadd  rfp, sp, #%d&quot;, framesize - 2 * wordSize);
 1606   } else {
 1607     st-&gt;print(&quot;stp  lr, rfp, [sp, #%d]!\n\t&quot;, -(2 * wordSize));
 1608     if (PreserveFramePointer) st-&gt;print(&quot;mov  rfp, sp\n\t&quot;);
 1609     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1610     st-&gt;print(&quot;sub  sp, sp, rscratch1&quot;);
 1611   }
 1612   if (C-&gt;stub_function() == NULL &amp;&amp; BarrierSet::barrier_set()-&gt;barrier_set_nmethod() != NULL) {
 1613     st-&gt;print(&quot;\n\t&quot;);
 1614     st-&gt;print(&quot;ldr  rscratch1, [guard]\n\t&quot;);
 1615     st-&gt;print(&quot;dmb ishld\n\t&quot;);
 1616     st-&gt;print(&quot;ldr  rscratch2, [rthread, #thread_disarmed_offset]\n\t&quot;);
 1617     st-&gt;print(&quot;cmp  rscratch1, rscratch2\n\t&quot;);
 1618     st-&gt;print(&quot;b.eq skip&quot;);
 1619     st-&gt;print(&quot;\n\t&quot;);
 1620     st-&gt;print(&quot;blr #nmethod_entry_barrier_stub\n\t&quot;);
 1621     st-&gt;print(&quot;b skip\n\t&quot;);
 1622     st-&gt;print(&quot;guard: int\n\t&quot;);
 1623     st-&gt;print(&quot;\n\t&quot;);
 1624     st-&gt;print(&quot;skip:\n\t&quot;);
 1625   }
 1626 }
 1627 #endif
 1628 
 1629 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1630   Compile* C = ra_-&gt;C;
 1631   C2_MacroAssembler _masm(&amp;cbuf);
 1632 
 1633   // n.b. frame size includes space for return pc and rfp
 1634   const int framesize = C-&gt;output()-&gt;frame_size_in_bytes();
 1635   assert(framesize%(2*wordSize) == 0, &quot;must preserve 2*wordSize alignment&quot;);
 1636 
 1637   // insert a nop at the start of the prolog so we can patch in a
 1638   // branch if we need to invalidate the method later
 1639   __ nop();
 1640 
 1641   if (C-&gt;clinit_barrier_on_entry()) {
 1642     assert(!C-&gt;method()-&gt;holder()-&gt;is_not_initialized(), &quot;initialization should have been started&quot;);
 1643 
 1644     Label L_skip_barrier;
 1645 
 1646     __ mov_metadata(rscratch2, C-&gt;method()-&gt;holder()-&gt;constant_encoding());
 1647     __ clinit_barrier(rscratch2, rscratch1, &amp;L_skip_barrier);
 1648     __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));
 1649     __ bind(L_skip_barrier);
 1650   }
 1651 
 1652   int bangsize = C-&gt;output()-&gt;bang_size_in_bytes();
 1653   if (C-&gt;output()-&gt;need_stack_bang(bangsize) &amp;&amp; UseStackBanging)
 1654     __ generate_stack_overflow_check(bangsize);
 1655 
 1656   __ build_frame(framesize);
 1657 
 1658   if (C-&gt;stub_function() == NULL) {
 1659     BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
 1660     bs-&gt;nmethod_entry_barrier(&amp;_masm);
 1661   }
 1662 
 1663   if (VerifyStackAtCalls) {
 1664     Unimplemented();
 1665   }
 1666 
 1667   C-&gt;output()-&gt;set_frame_complete(cbuf.insts_size());
 1668 
 1669   if (C-&gt;has_mach_constant_base_node()) {
 1670     // NOTE: We set the table base offset here because users might be
 1671     // emitted before MachConstantBaseNode.
 1672     ConstantTable&amp; constant_table = C-&gt;output()-&gt;constant_table();
 1673     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
 1674   }
 1675 }
 1676 
 1677 uint MachPrologNode::size(PhaseRegAlloc* ra_) const
 1678 {
 1679   return MachNode::size(ra_); // too many variables; just compute it
 1680                               // the hard way
 1681 }
 1682 
 1683 int MachPrologNode::reloc() const
 1684 {
 1685   return 0;
 1686 }
 1687 
 1688 //=============================================================================
 1689 
 1690 #ifndef PRODUCT
 1691 void MachEpilogNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1692   Compile* C = ra_-&gt;C;
 1693   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1694 
 1695   st-&gt;print(&quot;# pop frame %d\n\t&quot;,framesize);
 1696 
 1697   if (framesize == 0) {
 1698     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1699   } else if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1700     st-&gt;print(&quot;ldp  lr, rfp, [sp,#%d]\n\t&quot;, framesize - 2 * wordSize);
 1701     st-&gt;print(&quot;add  sp, sp, #%d\n\t&quot;, framesize);
 1702   } else {
 1703     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1704     st-&gt;print(&quot;add  sp, sp, rscratch1\n\t&quot;);
 1705     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1706   }
 1707 
 1708   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1709     st-&gt;print(&quot;# touch polling page\n\t&quot;);
 1710     st-&gt;print(&quot;ldr rscratch1, [rthread],#polling_page_offset\n\t&quot;);
 1711     st-&gt;print(&quot;ldr zr, [rscratch1]&quot;);
 1712   }
 1713 }
 1714 #endif
 1715 
 1716 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1717   Compile* C = ra_-&gt;C;
 1718   C2_MacroAssembler _masm(&amp;cbuf);
 1719   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1720 
 1721   __ remove_frame(framesize);
 1722 
 1723   if (StackReservedPages &gt; 0 &amp;&amp; C-&gt;has_reserved_stack_access()) {
 1724     __ reserved_stack_check();
 1725   }
 1726 
 1727   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1728     __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);
 1729   }
 1730 }
 1731 
 1732 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
 1733   // Variable size. Determine dynamically.
 1734   return MachNode::size(ra_);
 1735 }
 1736 
 1737 int MachEpilogNode::reloc() const {
 1738   // Return number of relocatable values contained in this instruction.
 1739   return 1; // 1 for polling page.
 1740 }
 1741 
 1742 const Pipeline * MachEpilogNode::pipeline() const {
 1743   return MachNode::pipeline_class();
 1744 }
 1745 
 1746 //=============================================================================
 1747 
 1748 // Figure out which register class each belongs in: rc_int, rc_float or
 1749 // rc_stack.
 1750 enum RC { rc_bad, rc_int, rc_float, rc_stack };
 1751 
 1752 static enum RC rc_class(OptoReg::Name reg) {
 1753 
 1754   if (reg == OptoReg::Bad) {
 1755     return rc_bad;
 1756   }
 1757 
 1758   // we have 30 int registers * 2 halves
 1759   // (rscratch1 and rscratch2 are omitted)
 1760   int slots_of_int_registers = RegisterImpl::max_slots_per_register * (RegisterImpl::number_of_registers - 2);
 1761 
 1762   if (reg &lt; slots_of_int_registers) {
 1763     return rc_int;
 1764   }
 1765 
 1766   // we have 32 float register * 4 halves
 1767   if (reg &lt; slots_of_int_registers + FloatRegisterImpl::max_slots_per_register * FloatRegisterImpl::number_of_registers) {
 1768     return rc_float;
 1769   }
 1770 
 1771   // Between float regs &amp; stack is the flags regs.
 1772   assert(OptoReg::is_stack(reg), &quot;blow up if spilling flags&quot;);
 1773 
 1774   return rc_stack;
 1775 }
 1776 
 1777 uint MachSpillCopyNode::implementation(CodeBuffer *cbuf, PhaseRegAlloc *ra_, bool do_size, outputStream *st) const {
 1778   Compile* C = ra_-&gt;C;
 1779 
 1780   // Get registers to move.
 1781   OptoReg::Name src_hi = ra_-&gt;get_reg_second(in(1));
 1782   OptoReg::Name src_lo = ra_-&gt;get_reg_first(in(1));
 1783   OptoReg::Name dst_hi = ra_-&gt;get_reg_second(this);
 1784   OptoReg::Name dst_lo = ra_-&gt;get_reg_first(this);
 1785 
 1786   enum RC src_hi_rc = rc_class(src_hi);
 1787   enum RC src_lo_rc = rc_class(src_lo);
 1788   enum RC dst_hi_rc = rc_class(dst_hi);
 1789   enum RC dst_lo_rc = rc_class(dst_lo);
 1790 
 1791   assert(src_lo != OptoReg::Bad &amp;&amp; dst_lo != OptoReg::Bad, &quot;must move at least 1 register&quot;);
 1792 
 1793   if (src_hi != OptoReg::Bad) {
 1794     assert((src_lo&amp;1)==0 &amp;&amp; src_lo+1==src_hi &amp;&amp;
 1795            (dst_lo&amp;1)==0 &amp;&amp; dst_lo+1==dst_hi,
 1796            &quot;expected aligned-adjacent pairs&quot;);
 1797   }
 1798 
 1799   if (src_lo == dst_lo &amp;&amp; src_hi == dst_hi) {
 1800     return 0;            // Self copy, no move.
 1801   }
 1802 
 1803   bool is64 = (src_lo &amp; 1) == 0 &amp;&amp; src_lo + 1 == src_hi &amp;&amp;
 1804               (dst_lo &amp; 1) == 0 &amp;&amp; dst_lo + 1 == dst_hi;
 1805   int src_offset = ra_-&gt;reg2offset(src_lo);
 1806   int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1807 
 1808   if (bottom_type()-&gt;isa_vect() != NULL) {
 1809     uint ireg = ideal_reg();
 1810     assert(ireg == Op_VecD || ireg == Op_VecX, &quot;must be 64 bit or 128 bit vector&quot;);
 1811     if (cbuf) {
 1812       C2_MacroAssembler _masm(cbuf);
 1813       assert((src_lo_rc != rc_int &amp;&amp; dst_lo_rc != rc_int), &quot;sanity&quot;);
 1814       if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1815         // stack-&gt;stack
 1816         assert((src_offset &amp; 7) == 0 &amp;&amp; (dst_offset &amp; 7) == 0, &quot;unaligned stack offset&quot;);
 1817         if (ireg == Op_VecD) {
 1818           __ unspill(rscratch1, true, src_offset);
 1819           __ spill(rscratch1, true, dst_offset);
 1820         } else {
 1821           __ spill_copy128(src_offset, dst_offset);
 1822         }
 1823       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_float) {
 1824         __ mov(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1825                ireg == Op_VecD ? __ T8B : __ T16B,
 1826                as_FloatRegister(Matcher::_regEncode[src_lo]));
 1827       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_stack) {
 1828         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1829                        ireg == Op_VecD ? __ D : __ Q,
 1830                        ra_-&gt;reg2offset(dst_lo));
 1831       } else if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_float) {
 1832         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1833                        ireg == Op_VecD ? __ D : __ Q,
 1834                        ra_-&gt;reg2offset(src_lo));
 1835       } else {
 1836         ShouldNotReachHere();
 1837       }
 1838     }
 1839   } else if (cbuf) {
 1840     C2_MacroAssembler _masm(cbuf);
 1841     switch (src_lo_rc) {
 1842     case rc_int:
 1843       if (dst_lo_rc == rc_int) {  // gpr --&gt; gpr copy
 1844         if (is64) {
 1845             __ mov(as_Register(Matcher::_regEncode[dst_lo]),
 1846                    as_Register(Matcher::_regEncode[src_lo]));
 1847         } else {
 1848             C2_MacroAssembler _masm(cbuf);
 1849             __ movw(as_Register(Matcher::_regEncode[dst_lo]),
 1850                     as_Register(Matcher::_regEncode[src_lo]));
 1851         }
 1852       } else if (dst_lo_rc == rc_float) { // gpr --&gt; fpr copy
 1853         if (is64) {
 1854             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1855                      as_Register(Matcher::_regEncode[src_lo]));
 1856         } else {
 1857             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1858                      as_Register(Matcher::_regEncode[src_lo]));
 1859         }
 1860       } else {                    // gpr --&gt; stack spill
 1861         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1862         __ spill(as_Register(Matcher::_regEncode[src_lo]), is64, dst_offset);
 1863       }
 1864       break;
 1865     case rc_float:
 1866       if (dst_lo_rc == rc_int) {  // fpr --&gt; gpr copy
 1867         if (is64) {
 1868             __ fmovd(as_Register(Matcher::_regEncode[dst_lo]),
 1869                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1870         } else {
 1871             __ fmovs(as_Register(Matcher::_regEncode[dst_lo]),
 1872                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1873         }
 1874       } else if (dst_lo_rc == rc_float) { // fpr --&gt; fpr copy
 1875           if (cbuf) {
 1876             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1877                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1878         } else {
 1879             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1880                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1881         }
 1882       } else {                    // fpr --&gt; stack spill
 1883         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1884         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1885                  is64 ? __ D : __ S, dst_offset);
 1886       }
 1887       break;
 1888     case rc_stack:
 1889       if (dst_lo_rc == rc_int) {  // stack --&gt; gpr load
 1890         __ unspill(as_Register(Matcher::_regEncode[dst_lo]), is64, src_offset);
 1891       } else if (dst_lo_rc == rc_float) { // stack --&gt; fpr load
 1892         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1893                    is64 ? __ D : __ S, src_offset);
 1894       } else {                    // stack --&gt; stack copy
 1895         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1896         __ unspill(rscratch1, is64, src_offset);
 1897         __ spill(rscratch1, is64, dst_offset);
 1898       }
 1899       break;
 1900     default:
 1901       assert(false, &quot;bad rc_class for spill&quot;);
 1902       ShouldNotReachHere();
 1903     }
 1904   }
 1905 
 1906   if (st) {
 1907     st-&gt;print(&quot;spill &quot;);
 1908     if (src_lo_rc == rc_stack) {
 1909       st-&gt;print(&quot;[sp, #%d] -&gt; &quot;, ra_-&gt;reg2offset(src_lo));
 1910     } else {
 1911       st-&gt;print(&quot;%s -&gt; &quot;, Matcher::regName[src_lo]);
 1912     }
 1913     if (dst_lo_rc == rc_stack) {
 1914       st-&gt;print(&quot;[sp, #%d]&quot;, ra_-&gt;reg2offset(dst_lo));
 1915     } else {
 1916       st-&gt;print(&quot;%s&quot;, Matcher::regName[dst_lo]);
 1917     }
 1918     if (bottom_type()-&gt;isa_vect() != NULL) {
 1919       st-&gt;print(&quot;\t# vector spill size = %d&quot;, ideal_reg()==Op_VecD ? 64:128);
 1920     } else {
 1921       st-&gt;print(&quot;\t# spill size = %d&quot;, is64 ? 64:32);
 1922     }
 1923   }
 1924 
 1925   return 0;
 1926 
 1927 }
 1928 
 1929 #ifndef PRODUCT
 1930 void MachSpillCopyNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1931   if (!ra_)
 1932     st-&gt;print(&quot;N%d = SpillCopy(N%d)&quot;, _idx, in(1)-&gt;_idx);
 1933   else
 1934     implementation(NULL, ra_, false, st);
 1935 }
 1936 #endif
 1937 
 1938 void MachSpillCopyNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1939   implementation(&amp;cbuf, ra_, false, NULL);
 1940 }
 1941 
 1942 uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
 1943   return MachNode::size(ra_);
 1944 }
 1945 
 1946 //=============================================================================
 1947 
 1948 #ifndef PRODUCT
 1949 void BoxLockNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1950   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1951   int reg = ra_-&gt;get_reg_first(this);
 1952   st-&gt;print(&quot;add %s, rsp, #%d]\t# box lock&quot;,
 1953             Matcher::regName[reg], offset);
 1954 }
 1955 #endif
 1956 
 1957 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1958   C2_MacroAssembler _masm(&amp;cbuf);
 1959 
 1960   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1961   int reg    = ra_-&gt;get_encode(this);
 1962 
 1963   // This add will handle any 24-bit signed offset. 24 bits allows an
 1964   // 8 megabyte stack frame.
 1965   __ add(as_Register(reg), sp, offset);
 1966 }
 1967 
 1968 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 1969   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_).
 1970   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1971 
 1972   if (Assembler::operand_valid_for_add_sub_immediate(offset)) {
 1973     return NativeInstruction::instruction_size;
 1974   } else {
 1975     return 2 * NativeInstruction::instruction_size;
 1976   }
 1977 }
 1978 
 1979 //=============================================================================
 1980 
 1981 #ifndef PRODUCT
 1982 void MachUEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 1983 {
 1984   st-&gt;print_cr(&quot;# MachUEPNode&quot;);
 1985   if (UseCompressedClassPointers) {
 1986     st-&gt;print_cr(&quot;\tldrw rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1987     if (CompressedKlassPointers::shift() != 0) {
 1988       st-&gt;print_cr(&quot;\tdecode_klass_not_null rscratch1, rscratch1&quot;);
 1989     }
 1990   } else {
 1991    st-&gt;print_cr(&quot;\tldr rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1992   }
 1993   st-&gt;print_cr(&quot;\tcmp r0, rscratch1\t # Inline cache check&quot;);
 1994   st-&gt;print_cr(&quot;\tbne, SharedRuntime::_ic_miss_stub&quot;);
 1995 }
 1996 #endif
 1997 
 1998 void MachUEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 1999 {
 2000   // This is the unverified entry point.
 2001   C2_MacroAssembler _masm(&amp;cbuf);
 2002 
 2003   __ cmp_klass(j_rarg0, rscratch2, rscratch1);
 2004   Label skip;
 2005   // TODO
 2006   // can we avoid this skip and still use a reloc?
 2007   __ br(Assembler::EQ, skip);
 2008   __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 2009   __ bind(skip);
 2010 }
 2011 
 2012 uint MachUEPNode::size(PhaseRegAlloc* ra_) const
 2013 {
 2014   return MachNode::size(ra_);
 2015 }
 2016 
 2017 // REQUIRED EMIT CODE
 2018 
 2019 //=============================================================================
 2020 
 2021 // Emit exception handler code.
 2022 int HandlerImpl::emit_exception_handler(CodeBuffer&amp; cbuf)
 2023 {
 2024   // mov rscratch1 #exception_blob_entry_point
 2025   // br rscratch1
 2026   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2027   // That&#39;s why we must use the macroassembler to generate a handler.
 2028   C2_MacroAssembler _masm(&amp;cbuf);
 2029   address base = __ start_a_stub(size_exception_handler());
 2030   if (base == NULL) {
 2031     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2032     return 0;  // CodeBuffer::expand failed
 2033   }
 2034   int offset = __ offset();
 2035   __ far_jump(RuntimeAddress(OptoRuntime::exception_blob()-&gt;entry_point()));
 2036   assert(__ offset() - offset &lt;= (int) size_exception_handler(), &quot;overflow&quot;);
 2037   __ end_a_stub();
 2038   return offset;
 2039 }
 2040 
 2041 // Emit deopt handler code.
 2042 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf)
 2043 {
 2044   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2045   // That&#39;s why we must use the macroassembler to generate a handler.
 2046   C2_MacroAssembler _masm(&amp;cbuf);
 2047   address base = __ start_a_stub(size_deopt_handler());
 2048   if (base == NULL) {
 2049     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2050     return 0;  // CodeBuffer::expand failed
 2051   }
 2052   int offset = __ offset();
 2053 
 2054   __ adr(lr, __ pc());
 2055   __ far_jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 2056 
 2057   assert(__ offset() - offset &lt;= (int) size_deopt_handler(), &quot;overflow&quot;);
 2058   __ end_a_stub();
 2059   return offset;
 2060 }
 2061 
 2062 // REQUIRED MATCHER CODE
 2063 
 2064 //=============================================================================
 2065 
 2066 const bool Matcher::match_rule_supported(int opcode) {
 2067   if (!has_match_rule(opcode))
 2068     return false;
 2069 
 2070   bool ret_value = true;
 2071   switch (opcode) {
 2072     case Op_CacheWB:
 2073     case Op_CacheWBPreSync:
 2074     case Op_CacheWBPostSync:
 2075       if (!VM_Version::supports_data_cache_line_flush()) {
 2076         ret_value = false;
 2077       }
 2078       break;
 2079   }
 2080 
 2081   return ret_value; // Per default match rules are supported.
 2082 }
 2083 
 2084 // Identify extra cases that we might want to provide match rules for vector nodes and
 2085 // other intrinsics guarded with vector length (vlen) and element type (bt).
 2086 const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {
 2087   if (!match_rule_supported(opcode)) {
 2088     return false;
 2089   }
 2090 
 2091   // Special cases which require vector length
 2092   switch (opcode) {
 2093     case Op_MulAddVS2VI: {
 2094       if (vlen != 4) {
 2095         return false;
 2096       }
 2097       break;
 2098     }
 2099   }
 2100 
 2101   return true; // Per default match rules are supported.
 2102 }
 2103 
 2104 const bool Matcher::has_predicated_vectors(void) {
 2105   return false;
 2106 }
 2107 
 2108 const int Matcher::float_pressure(int default_pressure_threshold) {
 2109   return default_pressure_threshold;
 2110 }
 2111 
 2112 int Matcher::regnum_to_fpu_offset(int regnum)
 2113 {
 2114   Unimplemented();
 2115   return 0;
 2116 }
 2117 
 2118 // Is this branch offset short enough that a short branch can be used?
 2119 //
 2120 // NOTE: If the platform does not provide any short branch variants, then
 2121 //       this method should return false for offset 0.
 2122 bool Matcher::is_short_branch_offset(int rule, int br_size, int offset) {
 2123   // The passed offset is relative to address of the branch.
 2124 
 2125   return (-32768 &lt;= offset &amp;&amp; offset &lt; 32768);
 2126 }
 2127 
 2128 const bool Matcher::isSimpleConstant64(jlong value) {
 2129   // Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.
 2130   // Probably always true, even if a temp register is required.
 2131   return true;
 2132 }
 2133 
 2134 // true just means we have fast l2f conversion
 2135 const bool Matcher::convL2FSupported(void) {
 2136   return true;
 2137 }
 2138 
 2139 // Vector width in bytes.
 2140 const int Matcher::vector_width_in_bytes(BasicType bt) {
 2141   int size = MIN2(16,(int)MaxVectorSize);
 2142   // Minimum 2 values in vector
 2143   if (size &lt; 2*type2aelembytes(bt)) size = 0;
 2144   // But never &lt; 4
 2145   if (size &lt; 4) size = 0;
 2146   return size;
 2147 }
 2148 
 2149 // Limits on vector size (number of elements) loaded into vector.
 2150 const int Matcher::max_vector_size(const BasicType bt) {
 2151   return vector_width_in_bytes(bt)/type2aelembytes(bt);
 2152 }
 2153 const int Matcher::min_vector_size(const BasicType bt) {
 2154 //  For the moment limit the vector size to 8 bytes
 2155     int size = 8 / type2aelembytes(bt);
 2156     if (size &lt; 2) size = 2;
 2157     return size;
 2158 }
 2159 
 2160 // Vector ideal reg.
 2161 const uint Matcher::vector_ideal_reg(int len) {
 2162   switch(len) {
 2163     case  8: return Op_VecD;
 2164     case 16: return Op_VecX;
 2165   }
 2166   ShouldNotReachHere();
 2167   return 0;
 2168 }
 2169 
 2170 // AES support not yet implemented
 2171 const bool Matcher::pass_original_key_for_aes() {
 2172   return false;
 2173 }
 2174 
 2175 // aarch64 supports misaligned vectors store/load.
 2176 const bool Matcher::misaligned_vectors_ok() {
 2177   return true;
 2178 }
 2179 
 2180 // false =&gt; size gets scaled to BytesPerLong, ok.
 2181 const bool Matcher::init_array_count_is_in_bytes = false;
 2182 
 2183 // Use conditional move (CMOVL)
 2184 const int Matcher::long_cmove_cost() {
 2185   // long cmoves are no more expensive than int cmoves
 2186   return 0;
 2187 }
 2188 
 2189 const int Matcher::float_cmove_cost() {
 2190   // float cmoves are no more expensive than int cmoves
 2191   return 0;
 2192 }
 2193 
 2194 // Does the CPU require late expand (see block.cpp for description of late expand)?
 2195 const bool Matcher::require_postalloc_expand = false;
 2196 
 2197 // Do we need to mask the count passed to shift instructions or does
 2198 // the cpu only look at the lower 5/6 bits anyway?
 2199 const bool Matcher::need_masked_shift_count = false;
 2200 
 2201 // No support for generic vector operands.
 2202 const bool Matcher::supports_generic_vector_operands  = false;
 2203 
 2204 MachOper* Matcher::pd_specialize_generic_vector_operand(MachOper* original_opnd, uint ideal_reg, bool is_temp) {
 2205   ShouldNotReachHere(); // generic vector operands not supported
 2206   return NULL;
 2207 }
 2208 
 2209 bool Matcher::is_generic_reg2reg_move(MachNode* m) {
 2210   ShouldNotReachHere();  // generic vector operands not supported
 2211   return false;
 2212 }
 2213 
 2214 bool Matcher::is_generic_vector(MachOper* opnd)  {
 2215   ShouldNotReachHere();  // generic vector operands not supported
 2216   return false;
 2217 }
 2218 
 2219 // This affects two different things:
 2220 //  - how Decode nodes are matched
 2221 //  - how ImplicitNullCheck opportunities are recognized
 2222 // If true, the matcher will try to remove all Decodes and match them
 2223 // (as operands) into nodes. NullChecks are not prepared to deal with
 2224 // Decodes by final_graph_reshaping().
 2225 // If false, final_graph_reshaping() forces the decode behind the Cmp
 2226 // for a NullCheck. The matcher matches the Decode node into a register.
 2227 // Implicit_null_check optimization moves the Decode along with the
 2228 // memory operation back up before the NullCheck.
 2229 bool Matcher::narrow_oop_use_complex_address() {
 2230   return CompressedOops::shift() == 0;
 2231 }
 2232 
 2233 bool Matcher::narrow_klass_use_complex_address() {
 2234 // TODO
 2235 // decide whether we need to set this to true
 2236   return false;
 2237 }
 2238 
 2239 bool Matcher::const_oop_prefer_decode() {
 2240   // Prefer ConN+DecodeN over ConP in simple compressed oops mode.
 2241   return CompressedOops::base() == NULL;
 2242 }
 2243 
 2244 bool Matcher::const_klass_prefer_decode() {
 2245   // Prefer ConNKlass+DecodeNKlass over ConP in simple compressed klass mode.
 2246   return CompressedKlassPointers::base() == NULL;
 2247 }
 2248 
 2249 // Is it better to copy float constants, or load them directly from
 2250 // memory?  Intel can load a float constant from a direct address,
 2251 // requiring no extra registers.  Most RISCs will have to materialize
 2252 // an address into a register first, so they would do better to copy
 2253 // the constant from stack.
 2254 const bool Matcher::rematerialize_float_constants = false;
 2255 
 2256 // If CPU can load and store mis-aligned doubles directly then no
 2257 // fixup is needed.  Else we split the double into 2 integer pieces
 2258 // and move it piece-by-piece.  Only happens when passing doubles into
 2259 // C code as the Java calling convention forces doubles to be aligned.
 2260 const bool Matcher::misaligned_doubles_ok = true;
 2261 
 2262 // No-op on amd64
 2263 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 2264   Unimplemented();
 2265 }
 2266 
 2267 // Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.
 2268 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 2269 
 2270 // Are floats converted to double when stored to stack during
 2271 // deoptimization?
 2272 bool Matcher::float_in_double() { return false; }
 2273 
 2274 // Do ints take an entire long register or just half?
 2275 // The relevant question is how the int is callee-saved:
 2276 // the whole long is written but de-opt&#39;ing will have to extract
 2277 // the relevant 32 bits.
 2278 const bool Matcher::int_in_long = true;
 2279 
 2280 // Return whether or not this register is ever used as an argument.
 2281 // This function is used on startup to build the trampoline stubs in
 2282 // generateOptoStub.  Registers not mentioned will be killed by the VM
 2283 // call in the trampoline, and arguments in those registers not be
 2284 // available to the callee.
 2285 bool Matcher::can_be_java_arg(int reg)
 2286 {
 2287   return
 2288     reg ==  R0_num || reg == R0_H_num ||
 2289     reg ==  R1_num || reg == R1_H_num ||
 2290     reg ==  R2_num || reg == R2_H_num ||
 2291     reg ==  R3_num || reg == R3_H_num ||
 2292     reg ==  R4_num || reg == R4_H_num ||
 2293     reg ==  R5_num || reg == R5_H_num ||
 2294     reg ==  R6_num || reg == R6_H_num ||
 2295     reg ==  R7_num || reg == R7_H_num ||
 2296     reg ==  V0_num || reg == V0_H_num ||
 2297     reg ==  V1_num || reg == V1_H_num ||
 2298     reg ==  V2_num || reg == V2_H_num ||
 2299     reg ==  V3_num || reg == V3_H_num ||
 2300     reg ==  V4_num || reg == V4_H_num ||
 2301     reg ==  V5_num || reg == V5_H_num ||
 2302     reg ==  V6_num || reg == V6_H_num ||
 2303     reg ==  V7_num || reg == V7_H_num;
 2304 }
 2305 
 2306 bool Matcher::is_spillable_arg(int reg)
 2307 {
 2308   return can_be_java_arg(reg);
 2309 }
 2310 
 2311 bool Matcher::use_asm_for_ldiv_by_con(jlong divisor) {
 2312   return false;
 2313 }
 2314 
 2315 RegMask Matcher::divI_proj_mask() {
 2316   ShouldNotReachHere();
 2317   return RegMask();
 2318 }
 2319 
 2320 // Register for MODI projection of divmodI.
 2321 RegMask Matcher::modI_proj_mask() {
 2322   ShouldNotReachHere();
 2323   return RegMask();
 2324 }
 2325 
 2326 // Register for DIVL projection of divmodL.
 2327 RegMask Matcher::divL_proj_mask() {
 2328   ShouldNotReachHere();
 2329   return RegMask();
 2330 }
 2331 
 2332 // Register for MODL projection of divmodL.
 2333 RegMask Matcher::modL_proj_mask() {
 2334   ShouldNotReachHere();
 2335   return RegMask();
 2336 }
 2337 
 2338 const RegMask Matcher::method_handle_invoke_SP_save_mask() {
 2339   return FP_REG_mask();
 2340 }
 2341 
 2342 bool size_fits_all_mem_uses(AddPNode* addp, int shift) {
 2343   for (DUIterator_Fast imax, i = addp-&gt;fast_outs(imax); i &lt; imax; i++) {
 2344     Node* u = addp-&gt;fast_out(i);
 2345     if (u-&gt;is_Mem()) {
 2346       int opsize = u-&gt;as_Mem()-&gt;memory_size();
 2347       assert(opsize &gt; 0, &quot;unexpected memory operand size&quot;);
 2348       if (u-&gt;as_Mem()-&gt;memory_size() != (1&lt;&lt;shift)) {
 2349         return false;
 2350       }
 2351     }
 2352   }
 2353   return true;
 2354 }
 2355 
 2356 const bool Matcher::convi2l_type_required = false;
 2357 
 2358 // Should the matcher clone input &#39;m&#39; of node &#39;n&#39;?
 2359 bool Matcher::pd_clone_node(Node* n, Node* m, Matcher::MStack&amp; mstack) {
 2360   if (is_vshift_con_pattern(n, m)) { // ShiftV src (ShiftCntV con)
 2361     mstack.push(m, Visit);           // m = ShiftCntV
 2362     return true;
 2363   }
 2364   return false;
 2365 }
 2366 
 2367 // Should the Matcher clone shifts on addressing modes, expecting them
 2368 // to be subsumed into complex addressing expressions or compute them
 2369 // into registers?
 2370 bool Matcher::pd_clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
 2371   if (clone_base_plus_offset_address(m, mstack, address_visited)) {
 2372     return true;
 2373   }
 2374 
 2375   Node *off = m-&gt;in(AddPNode::Offset);
 2376   if (off-&gt;Opcode() == Op_LShiftL &amp;&amp; off-&gt;in(2)-&gt;is_Con() &amp;&amp;
 2377       size_fits_all_mem_uses(m, off-&gt;in(2)-&gt;get_int()) &amp;&amp;
 2378       // Are there other uses besides address expressions?
 2379       !is_visited(off)) {
 2380     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2381     mstack.push(off-&gt;in(2), Visit);
 2382     Node *conv = off-&gt;in(1);
 2383     if (conv-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2384         // Are there other uses besides address expressions?
 2385         !is_visited(conv)) {
 2386       address_visited.set(conv-&gt;_idx); // Flag as address_visited
 2387       mstack.push(conv-&gt;in(1), Pre_Visit);
 2388     } else {
 2389       mstack.push(conv, Pre_Visit);
 2390     }
 2391     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2392     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2393     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2394     return true;
 2395   } else if (off-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2396              // Are there other uses besides address expressions?
 2397              !is_visited(off)) {
 2398     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2399     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2400     mstack.push(off-&gt;in(1), Pre_Visit);
 2401     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2402     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2403     return true;
 2404   }
 2405   return false;
 2406 }
 2407 
 2408 void Compile::reshape_address(AddPNode* addp) {
 2409 }
 2410 
 2411 
 2412 #define MOV_VOLATILE(REG, BASE, INDEX, SCALE, DISP, SCRATCH, INSN)      \
 2413   C2_MacroAssembler _masm(&amp;cbuf);                                       \
 2414   {                                                                     \
 2415     guarantee(INDEX == -1, &quot;mode not permitted for volatile&quot;);          \
 2416     guarantee(DISP == 0, &quot;mode not permitted for volatile&quot;);            \
 2417     guarantee(SCALE == 0, &quot;mode not permitted for volatile&quot;);           \
 2418     __ INSN(REG, as_Register(BASE));                                    \
 2419   }
 2420 
 2421 
 2422 static Address mem2address(int opcode, Register base, int index, int size, int disp)
 2423   {
 2424     Address::extend scale;
 2425 
 2426     // Hooboy, this is fugly.  We need a way to communicate to the
 2427     // encoder that the index needs to be sign extended, so we have to
 2428     // enumerate all the cases.
 2429     switch (opcode) {
 2430     case INDINDEXSCALEDI2L:
 2431     case INDINDEXSCALEDI2LN:
 2432     case INDINDEXI2L:
 2433     case INDINDEXI2LN:
 2434       scale = Address::sxtw(size);
 2435       break;
 2436     default:
 2437       scale = Address::lsl(size);
 2438     }
 2439 
 2440     if (index == -1) {
 2441       return Address(base, disp);
 2442     } else {
 2443       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2444       return Address(base, as_Register(index), scale);
 2445     }
 2446   }
 2447 
 2448 
 2449 typedef void (MacroAssembler::* mem_insn)(Register Rt, const Address &amp;adr);
 2450 typedef void (MacroAssembler::* mem_insn2)(Register Rt, Register adr);
 2451 typedef void (MacroAssembler::* mem_float_insn)(FloatRegister Rt, const Address &amp;adr);
 2452 typedef void (MacroAssembler::* mem_vector_insn)(FloatRegister Rt,
 2453                                   MacroAssembler::SIMD_RegVariant T, const Address &amp;adr);
 2454 
 2455   // Used for all non-volatile memory accesses.  The use of
 2456   // $mem-&gt;opcode() to discover whether this pattern uses sign-extended
 2457   // offsets is something of a kludge.
 2458   static void loadStore(C2_MacroAssembler masm, mem_insn insn,
 2459                         Register reg, int opcode,
 2460                         Register base, int index, int scale, int disp,
 2461                         int size_in_memory)
 2462   {
 2463     Address addr = mem2address(opcode, base, index, scale, disp);
 2464     if (addr.getMode() == Address::base_plus_offset) {
 2465       /* If we get an out-of-range offset it is a bug in the compiler,
 2466          so we assert here. */
 2467       assert(Address::offset_ok_for_immed(addr.offset(), exact_log2(size_in_memory)),
 2468              &quot;c2 compiler bug&quot;);
 2469       /* Fix up any out-of-range offsets. */
 2470       assert_different_registers(rscratch1, base);
 2471       assert_different_registers(rscratch1, reg);
 2472       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2473     }
 2474     (masm.*insn)(reg, addr);
 2475   }
 2476 
 2477   static void loadStore(C2_MacroAssembler masm, mem_float_insn insn,
 2478                         FloatRegister reg, int opcode,
 2479                         Register base, int index, int size, int disp,
 2480                         int size_in_memory)
 2481   {
 2482     Address::extend scale;
 2483 
 2484     switch (opcode) {
 2485     case INDINDEXSCALEDI2L:
 2486     case INDINDEXSCALEDI2LN:
 2487       scale = Address::sxtw(size);
 2488       break;
 2489     default:
 2490       scale = Address::lsl(size);
 2491     }
 2492 
 2493     if (index == -1) {
 2494       /* If we get an out-of-range offset it is a bug in the compiler,
 2495          so we assert here. */
 2496       assert(Address::offset_ok_for_immed(disp, exact_log2(size_in_memory)), &quot;c2 compiler bug&quot;);
 2497       /* Fix up any out-of-range offsets. */
 2498       assert_different_registers(rscratch1, base);
 2499       Address addr = Address(base, disp);
 2500       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2501       (masm.*insn)(reg, addr);
 2502     } else {
 2503       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2504       (masm.*insn)(reg, Address(base, as_Register(index), scale));
 2505     }
 2506   }
 2507 
 2508   static void loadStore(C2_MacroAssembler masm, mem_vector_insn insn,
 2509                         FloatRegister reg, MacroAssembler::SIMD_RegVariant T,
 2510                         int opcode, Register base, int index, int size, int disp)
 2511   {
 2512     if (index == -1) {
 2513       (masm.*insn)(reg, T, Address(base, disp));
 2514     } else {
 2515       assert(disp == 0, &quot;unsupported address mode&quot;);
 2516       (masm.*insn)(reg, T, Address(base, as_Register(index), Address::lsl(size)));
 2517     }
 2518   }
 2519 
 2520 %}
 2521 
 2522 
 2523 
 2524 //----------ENCODING BLOCK-----------------------------------------------------
 2525 // This block specifies the encoding classes used by the compiler to
 2526 // output byte streams.  Encoding classes are parameterized macros
 2527 // used by Machine Instruction Nodes in order to generate the bit
 2528 // encoding of the instruction.  Operands specify their base encoding
 2529 // interface with the interface keyword.  There are currently
 2530 // supported four interfaces, REG_INTER, CONST_INTER, MEMORY_INTER, &amp;
 2531 // COND_INTER.  REG_INTER causes an operand to generate a function
 2532 // which returns its register number when queried.  CONST_INTER causes
 2533 // an operand to generate a function which returns the value of the
 2534 // constant when queried.  MEMORY_INTER causes an operand to generate
 2535 // four functions which return the Base Register, the Index Register,
 2536 // the Scale Value, and the Offset Value of the operand when queried.
 2537 // COND_INTER causes an operand to generate six functions which return
 2538 // the encoding code (ie - encoding bits for the instruction)
 2539 // associated with each basic boolean condition for a conditional
 2540 // instruction.
 2541 //
 2542 // Instructions specify two basic values for encoding.  Again, a
 2543 // function is available to check if the constant displacement is an
 2544 // oop. They use the ins_encode keyword to specify their encoding
 2545 // classes (which must be a sequence of enc_class names, and their
 2546 // parameters, specified in the encoding block), and they use the
 2547 // opcode keyword to specify, in order, their primary, secondary, and
 2548 // tertiary opcode.  Only the opcode sections which a particular
 2549 // instruction needs for encoding need to be specified.
 2550 encode %{
 2551   // Build emit functions for each basic byte or larger field in the
 2552   // intel encoding scheme (opcode, rm, sib, immediate), and call them
 2553   // from C++ code in the enc_class source block.  Emit functions will
 2554   // live in the main source block for now.  In future, we can
 2555   // generalize this by adding a syntax that specifies the sizes of
 2556   // fields in an order, so that the adlc can build the emit functions
 2557   // automagically
 2558 
 2559   // catch all for unimplemented encodings
 2560   enc_class enc_unimplemented %{
 2561     C2_MacroAssembler _masm(&amp;cbuf);
 2562     __ unimplemented(&quot;C2 catch all&quot;);
 2563   %}
 2564 
 2565   // BEGIN Non-volatile memory access
 2566 
 2567   // This encoding class is generated automatically from ad_encode.m4.
 2568   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2569   enc_class aarch64_enc_ldrsbw(iRegI dst, memory1 mem) %{
 2570     Register dst_reg = as_Register($dst$$reg);
 2571     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsbw, dst_reg, $mem-&gt;opcode(),
 2572                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2573   %}
 2574 
 2575   // This encoding class is generated automatically from ad_encode.m4.
 2576   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2577   enc_class aarch64_enc_ldrsb(iRegI dst, memory1 mem) %{
 2578     Register dst_reg = as_Register($dst$$reg);
 2579     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsb, dst_reg, $mem-&gt;opcode(),
 2580                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2581   %}
 2582 
 2583   // This encoding class is generated automatically from ad_encode.m4.
 2584   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2585   enc_class aarch64_enc_ldrb(iRegI dst, memory1 mem) %{
 2586     Register dst_reg = as_Register($dst$$reg);
 2587     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2588                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2589   %}
 2590 
 2591   // This encoding class is generated automatically from ad_encode.m4.
 2592   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2593   enc_class aarch64_enc_ldrb(iRegL dst, memory1 mem) %{
 2594     Register dst_reg = as_Register($dst$$reg);
 2595     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2596                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2597   %}
 2598 
 2599   // This encoding class is generated automatically from ad_encode.m4.
 2600   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2601   enc_class aarch64_enc_ldrshw(iRegI dst, memory2 mem) %{
 2602     Register dst_reg = as_Register($dst$$reg);
 2603     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrshw, dst_reg, $mem-&gt;opcode(),
 2604                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2605   %}
 2606 
 2607   // This encoding class is generated automatically from ad_encode.m4.
 2608   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2609   enc_class aarch64_enc_ldrsh(iRegI dst, memory2 mem) %{
 2610     Register dst_reg = as_Register($dst$$reg);
 2611     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsh, dst_reg, $mem-&gt;opcode(),
 2612                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2613   %}
 2614 
 2615   // This encoding class is generated automatically from ad_encode.m4.
 2616   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2617   enc_class aarch64_enc_ldrh(iRegI dst, memory2 mem) %{
 2618     Register dst_reg = as_Register($dst$$reg);
 2619     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2620                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2621   %}
 2622 
 2623   // This encoding class is generated automatically from ad_encode.m4.
 2624   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2625   enc_class aarch64_enc_ldrh(iRegL dst, memory2 mem) %{
 2626     Register dst_reg = as_Register($dst$$reg);
 2627     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2628                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2629   %}
 2630 
 2631   // This encoding class is generated automatically from ad_encode.m4.
 2632   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2633   enc_class aarch64_enc_ldrw(iRegI dst, memory4 mem) %{
 2634     Register dst_reg = as_Register($dst$$reg);
 2635     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2636                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2637   %}
 2638 
 2639   // This encoding class is generated automatically from ad_encode.m4.
 2640   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2641   enc_class aarch64_enc_ldrw(iRegL dst, memory4 mem) %{
 2642     Register dst_reg = as_Register($dst$$reg);
 2643     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2644                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2645   %}
 2646 
 2647   // This encoding class is generated automatically from ad_encode.m4.
 2648   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2649   enc_class aarch64_enc_ldrsw(iRegL dst, memory4 mem) %{
 2650     Register dst_reg = as_Register($dst$$reg);
 2651     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsw, dst_reg, $mem-&gt;opcode(),
 2652                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2653   %}
 2654 
 2655   // This encoding class is generated automatically from ad_encode.m4.
 2656   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2657   enc_class aarch64_enc_ldr(iRegL dst, memory8 mem) %{
 2658     Register dst_reg = as_Register($dst$$reg);
 2659     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, $mem-&gt;opcode(),
 2660                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2661   %}
 2662 
 2663   // This encoding class is generated automatically from ad_encode.m4.
 2664   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2665   enc_class aarch64_enc_ldrs(vRegF dst, memory4 mem) %{
 2666     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2667     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, dst_reg, $mem-&gt;opcode(),
 2668                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2669   %}
 2670 
 2671   // This encoding class is generated automatically from ad_encode.m4.
 2672   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2673   enc_class aarch64_enc_ldrd(vRegD dst, memory8 mem) %{
 2674     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2675     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, dst_reg, $mem-&gt;opcode(),
 2676                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2677   %}
 2678 
 2679   // This encoding class is generated automatically from ad_encode.m4.
 2680   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2681   enc_class aarch64_enc_strb(iRegI src, memory1 mem) %{
 2682     Register src_reg = as_Register($src$$reg);
 2683     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strb, src_reg, $mem-&gt;opcode(),
 2684                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2685   %}
 2686 
 2687   // This encoding class is generated automatically from ad_encode.m4.
 2688   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2689   enc_class aarch64_enc_strb0(memory1 mem) %{
 2690     C2_MacroAssembler _masm(&amp;cbuf);
 2691     loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2692                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2693   %}
 2694 
 2695   // This encoding class is generated automatically from ad_encode.m4.
 2696   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2697   enc_class aarch64_enc_strh(iRegI src, memory2 mem) %{
 2698     Register src_reg = as_Register($src$$reg);
 2699     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strh, src_reg, $mem-&gt;opcode(),
 2700                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2701   %}
 2702 
 2703   // This encoding class is generated automatically from ad_encode.m4.
 2704   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2705   enc_class aarch64_enc_strh0(memory2 mem) %{
 2706     C2_MacroAssembler _masm(&amp;cbuf);
 2707     loadStore(_masm, &amp;MacroAssembler::strh, zr, $mem-&gt;opcode(),
 2708                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2709   %}
 2710 
 2711   // This encoding class is generated automatically from ad_encode.m4.
 2712   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2713   enc_class aarch64_enc_strw(iRegI src, memory4 mem) %{
 2714     Register src_reg = as_Register($src$$reg);
 2715     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strw, src_reg, $mem-&gt;opcode(),
 2716                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2717   %}
 2718 
 2719   // This encoding class is generated automatically from ad_encode.m4.
 2720   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2721   enc_class aarch64_enc_strw0(memory4 mem) %{
 2722     C2_MacroAssembler _masm(&amp;cbuf);
 2723     loadStore(_masm, &amp;MacroAssembler::strw, zr, $mem-&gt;opcode(),
 2724                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2725   %}
 2726 
 2727   // This encoding class is generated automatically from ad_encode.m4.
 2728   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2729   enc_class aarch64_enc_str(iRegL src, memory8 mem) %{
 2730     Register src_reg = as_Register($src$$reg);
 2731     // we sometimes get asked to store the stack pointer into the
 2732     // current thread -- we cannot do that directly on AArch64
 2733     if (src_reg == r31_sp) {
 2734       C2_MacroAssembler _masm(&amp;cbuf);
 2735       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2736       __ mov(rscratch2, sp);
 2737       src_reg = rscratch2;
 2738     }
 2739     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, $mem-&gt;opcode(),
 2740                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2741   %}
 2742 
 2743   // This encoding class is generated automatically from ad_encode.m4.
 2744   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2745   enc_class aarch64_enc_str0(memory8 mem) %{
 2746     C2_MacroAssembler _masm(&amp;cbuf);
 2747     loadStore(_masm, &amp;MacroAssembler::str, zr, $mem-&gt;opcode(),
 2748                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2749   %}
 2750 
 2751   // This encoding class is generated automatically from ad_encode.m4.
 2752   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2753   enc_class aarch64_enc_strs(vRegF src, memory4 mem) %{
 2754     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2755     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strs, src_reg, $mem-&gt;opcode(),
 2756                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2757   %}
 2758 
 2759   // This encoding class is generated automatically from ad_encode.m4.
 2760   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2761   enc_class aarch64_enc_strd(vRegD src, memory8 mem) %{
 2762     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2763     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strd, src_reg, $mem-&gt;opcode(),
 2764                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2765   %}
 2766 
 2767   // This encoding class is generated automatically from ad_encode.m4.
 2768   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2769   enc_class aarch64_enc_strw_immn(immN src, memory1 mem) %{
 2770     C2_MacroAssembler _masm(&amp;cbuf);
 2771     address con = (address)$src$$constant;
 2772     // need to do this the hard way until we can manage relocs
 2773     // for 32 bit constants
 2774     __ movoop(rscratch2, (jobject)con);
 2775     if (con) __ encode_heap_oop_not_null(rscratch2);
 2776     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2777                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2778   %}
 2779 
 2780   // This encoding class is generated automatically from ad_encode.m4.
 2781   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2782   enc_class aarch64_enc_strw_immnk(immN src, memory4 mem) %{
 2783     C2_MacroAssembler _masm(&amp;cbuf);
 2784     address con = (address)$src$$constant;
 2785     // need to do this the hard way until we can manage relocs
 2786     // for 32 bit constants
 2787     __ movoop(rscratch2, (jobject)con);
 2788     __ encode_klass_not_null(rscratch2);
 2789     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2790                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2791   %}
 2792 
 2793   // This encoding class is generated automatically from ad_encode.m4.
 2794   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2795   enc_class aarch64_enc_strb0_ordered(memory4 mem) %{
 2796       C2_MacroAssembler _masm(&amp;cbuf);
 2797       __ membar(Assembler::StoreStore);
 2798       loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2799                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2800   %}
 2801 
 2802   // END Non-volatile memory access
 2803 
 2804   // Vector loads and stores
 2805   enc_class aarch64_enc_ldrvS(vecD dst, memory mem) %{
 2806     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2807     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::S,
 2808        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2809   %}
 2810 
 2811   enc_class aarch64_enc_ldrvD(vecD dst, memory mem) %{
 2812     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2813     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::D,
 2814        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2815   %}
 2816 
 2817   enc_class aarch64_enc_ldrvQ(vecX dst, memory mem) %{
 2818     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2819     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::Q,
 2820        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2821   %}
 2822 
 2823   enc_class aarch64_enc_strvS(vecD src, memory mem) %{
 2824     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2825     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::S,
 2826        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2827   %}
 2828 
 2829   enc_class aarch64_enc_strvD(vecD src, memory mem) %{
 2830     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2831     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::D,
 2832        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2833   %}
 2834 
 2835   enc_class aarch64_enc_strvQ(vecX src, memory mem) %{
 2836     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2837     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::Q,
 2838        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2839   %}
 2840 
 2841   // volatile loads and stores
 2842 
 2843   enc_class aarch64_enc_stlrb(iRegI src, memory mem) %{
 2844     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2845                  rscratch1, stlrb);
 2846   %}
 2847 
 2848   enc_class aarch64_enc_stlrh(iRegI src, memory mem) %{
 2849     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2850                  rscratch1, stlrh);
 2851   %}
 2852 
 2853   enc_class aarch64_enc_stlrw(iRegI src, memory mem) %{
 2854     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2855                  rscratch1, stlrw);
 2856   %}
 2857 
 2858 
 2859   enc_class aarch64_enc_ldarsbw(iRegI dst, memory mem) %{
 2860     Register dst_reg = as_Register($dst$$reg);
 2861     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2862              rscratch1, ldarb);
 2863     __ sxtbw(dst_reg, dst_reg);
 2864   %}
 2865 
 2866   enc_class aarch64_enc_ldarsb(iRegL dst, memory mem) %{
 2867     Register dst_reg = as_Register($dst$$reg);
 2868     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2869              rscratch1, ldarb);
 2870     __ sxtb(dst_reg, dst_reg);
 2871   %}
 2872 
 2873   enc_class aarch64_enc_ldarbw(iRegI dst, memory mem) %{
 2874     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2875              rscratch1, ldarb);
 2876   %}
 2877 
 2878   enc_class aarch64_enc_ldarb(iRegL dst, memory mem) %{
 2879     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2880              rscratch1, ldarb);
 2881   %}
 2882 
 2883   enc_class aarch64_enc_ldarshw(iRegI dst, memory mem) %{
 2884     Register dst_reg = as_Register($dst$$reg);
 2885     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2886              rscratch1, ldarh);
 2887     __ sxthw(dst_reg, dst_reg);
 2888   %}
 2889 
 2890   enc_class aarch64_enc_ldarsh(iRegL dst, memory mem) %{
 2891     Register dst_reg = as_Register($dst$$reg);
 2892     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2893              rscratch1, ldarh);
 2894     __ sxth(dst_reg, dst_reg);
 2895   %}
 2896 
 2897   enc_class aarch64_enc_ldarhw(iRegI dst, memory mem) %{
 2898     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2899              rscratch1, ldarh);
 2900   %}
 2901 
 2902   enc_class aarch64_enc_ldarh(iRegL dst, memory mem) %{
 2903     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2904              rscratch1, ldarh);
 2905   %}
 2906 
 2907   enc_class aarch64_enc_ldarw(iRegI dst, memory mem) %{
 2908     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2909              rscratch1, ldarw);
 2910   %}
 2911 
 2912   enc_class aarch64_enc_ldarw(iRegL dst, memory mem) %{
 2913     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2914              rscratch1, ldarw);
 2915   %}
 2916 
 2917   enc_class aarch64_enc_ldar(iRegL dst, memory mem) %{
 2918     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2919              rscratch1, ldar);
 2920   %}
 2921 
 2922   enc_class aarch64_enc_fldars(vRegF dst, memory mem) %{
 2923     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2924              rscratch1, ldarw);
 2925     __ fmovs(as_FloatRegister($dst$$reg), rscratch1);
 2926   %}
 2927 
 2928   enc_class aarch64_enc_fldard(vRegD dst, memory mem) %{
 2929     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2930              rscratch1, ldar);
 2931     __ fmovd(as_FloatRegister($dst$$reg), rscratch1);
 2932   %}
 2933 
 2934   enc_class aarch64_enc_stlr(iRegL src, memory mem) %{
 2935     Register src_reg = as_Register($src$$reg);
 2936     // we sometimes get asked to store the stack pointer into the
 2937     // current thread -- we cannot do that directly on AArch64
 2938     if (src_reg == r31_sp) {
 2939       C2_MacroAssembler _masm(&amp;cbuf);
 2940       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2941       __ mov(rscratch2, sp);
 2942       src_reg = rscratch2;
 2943     }
 2944     MOV_VOLATILE(src_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2945                  rscratch1, stlr);
 2946   %}
 2947 
 2948   enc_class aarch64_enc_fstlrs(vRegF src, memory mem) %{
 2949     {
 2950       C2_MacroAssembler _masm(&amp;cbuf);
 2951       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2952       __ fmovs(rscratch2, src_reg);
 2953     }
 2954     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2955                  rscratch1, stlrw);
 2956   %}
 2957 
 2958   enc_class aarch64_enc_fstlrd(vRegD src, memory mem) %{
 2959     {
 2960       C2_MacroAssembler _masm(&amp;cbuf);
 2961       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2962       __ fmovd(rscratch2, src_reg);
 2963     }
 2964     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2965                  rscratch1, stlr);
 2966   %}
 2967 
 2968   // synchronized read/update encodings
 2969 
 2970   enc_class aarch64_enc_ldaxr(iRegL dst, memory8 mem) %{
 2971     C2_MacroAssembler _masm(&amp;cbuf);
 2972     Register dst_reg = as_Register($dst$$reg);
 2973     Register base = as_Register($mem$$base);
 2974     int index = $mem$$index;
 2975     int scale = $mem$$scale;
 2976     int disp = $mem$$disp;
 2977     if (index == -1) {
 2978        if (disp != 0) {
 2979         __ lea(rscratch1, Address(base, disp));
 2980         __ ldaxr(dst_reg, rscratch1);
 2981       } else {
 2982         // TODO
 2983         // should we ever get anything other than this case?
 2984         __ ldaxr(dst_reg, base);
 2985       }
 2986     } else {
 2987       Register index_reg = as_Register(index);
 2988       if (disp == 0) {
 2989         __ lea(rscratch1, Address(base, index_reg, Address::lsl(scale)));
 2990         __ ldaxr(dst_reg, rscratch1);
 2991       } else {
 2992         __ lea(rscratch1, Address(base, disp));
 2993         __ lea(rscratch1, Address(rscratch1, index_reg, Address::lsl(scale)));
 2994         __ ldaxr(dst_reg, rscratch1);
 2995       }
 2996     }
 2997   %}
 2998 
 2999   enc_class aarch64_enc_stlxr(iRegLNoSp src, memory8 mem) %{
 3000     C2_MacroAssembler _masm(&amp;cbuf);
 3001     Register src_reg = as_Register($src$$reg);
 3002     Register base = as_Register($mem$$base);
 3003     int index = $mem$$index;
 3004     int scale = $mem$$scale;
 3005     int disp = $mem$$disp;
 3006     if (index == -1) {
 3007        if (disp != 0) {
 3008         __ lea(rscratch2, Address(base, disp));
 3009         __ stlxr(rscratch1, src_reg, rscratch2);
 3010       } else {
 3011         // TODO
 3012         // should we ever get anything other than this case?
 3013         __ stlxr(rscratch1, src_reg, base);
 3014       }
 3015     } else {
 3016       Register index_reg = as_Register(index);
 3017       if (disp == 0) {
 3018         __ lea(rscratch2, Address(base, index_reg, Address::lsl(scale)));
 3019         __ stlxr(rscratch1, src_reg, rscratch2);
 3020       } else {
 3021         __ lea(rscratch2, Address(base, disp));
 3022         __ lea(rscratch2, Address(rscratch2, index_reg, Address::lsl(scale)));
 3023         __ stlxr(rscratch1, src_reg, rscratch2);
 3024       }
 3025     }
 3026     __ cmpw(rscratch1, zr);
 3027   %}
 3028 
 3029   enc_class aarch64_enc_cmpxchg(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3030     C2_MacroAssembler _masm(&amp;cbuf);
 3031     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3032     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3033                Assembler::xword, /*acquire*/ false, /*release*/ true,
 3034                /*weak*/ false, noreg);
 3035   %}
 3036 
 3037   enc_class aarch64_enc_cmpxchgw(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3038     C2_MacroAssembler _masm(&amp;cbuf);
 3039     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3040     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3041                Assembler::word, /*acquire*/ false, /*release*/ true,
 3042                /*weak*/ false, noreg);
 3043   %}
 3044 
 3045   enc_class aarch64_enc_cmpxchgs(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3046     C2_MacroAssembler _masm(&amp;cbuf);
 3047     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3048     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3049                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 3050                /*weak*/ false, noreg);
 3051   %}
 3052 
 3053   enc_class aarch64_enc_cmpxchgb(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3054     C2_MacroAssembler _masm(&amp;cbuf);
 3055     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3056     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3057                Assembler::byte, /*acquire*/ false, /*release*/ true,
 3058                /*weak*/ false, noreg);
 3059   %}
 3060 
 3061 
 3062   // The only difference between aarch64_enc_cmpxchg and
 3063   // aarch64_enc_cmpxchg_acq is that we use load-acquire in the
 3064   // CompareAndSwap sequence to serve as a barrier on acquiring a
 3065   // lock.
 3066   enc_class aarch64_enc_cmpxchg_acq(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3067     C2_MacroAssembler _masm(&amp;cbuf);
 3068     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3069     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3070                Assembler::xword, /*acquire*/ true, /*release*/ true,
 3071                /*weak*/ false, noreg);
 3072   %}
 3073 
 3074   enc_class aarch64_enc_cmpxchgw_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3075     C2_MacroAssembler _masm(&amp;cbuf);
 3076     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3077     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3078                Assembler::word, /*acquire*/ true, /*release*/ true,
 3079                /*weak*/ false, noreg);
 3080   %}
 3081 
 3082   enc_class aarch64_enc_cmpxchgs_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3083     C2_MacroAssembler _masm(&amp;cbuf);
 3084     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3085     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3086                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 3087                /*weak*/ false, noreg);
 3088   %}
 3089 
 3090   enc_class aarch64_enc_cmpxchgb_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3091     C2_MacroAssembler _masm(&amp;cbuf);
 3092     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3093     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3094                Assembler::byte, /*acquire*/ true, /*release*/ true,
 3095                /*weak*/ false, noreg);
 3096   %}
 3097 
 3098   // auxiliary used for CompareAndSwapX to set result register
 3099   enc_class aarch64_enc_cset_eq(iRegINoSp res) %{
 3100     C2_MacroAssembler _masm(&amp;cbuf);
 3101     Register res_reg = as_Register($res$$reg);
 3102     __ cset(res_reg, Assembler::EQ);
 3103   %}
 3104 
 3105   // prefetch encodings
 3106 
 3107   enc_class aarch64_enc_prefetchw(memory mem) %{
 3108     C2_MacroAssembler _masm(&amp;cbuf);
 3109     Register base = as_Register($mem$$base);
 3110     int index = $mem$$index;
 3111     int scale = $mem$$scale;
 3112     int disp = $mem$$disp;
 3113     if (index == -1) {
 3114       __ prfm(Address(base, disp), PSTL1KEEP);
 3115     } else {
 3116       Register index_reg = as_Register(index);
 3117       if (disp == 0) {
 3118         __ prfm(Address(base, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3119       } else {
 3120         __ lea(rscratch1, Address(base, disp));
 3121 	__ prfm(Address(rscratch1, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3122       }
 3123     }
 3124   %}
 3125 
 3126   /// mov envcodings
 3127 
 3128   enc_class aarch64_enc_movw_imm(iRegI dst, immI src) %{
 3129     C2_MacroAssembler _masm(&amp;cbuf);
 3130     uint32_t con = (uint32_t)$src$$constant;
 3131     Register dst_reg = as_Register($dst$$reg);
 3132     if (con == 0) {
 3133       __ movw(dst_reg, zr);
 3134     } else {
 3135       __ movw(dst_reg, con);
 3136     }
 3137   %}
 3138 
 3139   enc_class aarch64_enc_mov_imm(iRegL dst, immL src) %{
 3140     C2_MacroAssembler _masm(&amp;cbuf);
 3141     Register dst_reg = as_Register($dst$$reg);
 3142     uint64_t con = (uint64_t)$src$$constant;
 3143     if (con == 0) {
 3144       __ mov(dst_reg, zr);
 3145     } else {
 3146       __ mov(dst_reg, con);
 3147     }
 3148   %}
 3149 
 3150   enc_class aarch64_enc_mov_p(iRegP dst, immP src) %{
 3151     C2_MacroAssembler _masm(&amp;cbuf);
 3152     Register dst_reg = as_Register($dst$$reg);
 3153     address con = (address)$src$$constant;
 3154     if (con == NULL || con == (address)1) {
 3155       ShouldNotReachHere();
 3156     } else {
 3157       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3158       if (rtype == relocInfo::oop_type) {
 3159         __ movoop(dst_reg, (jobject)con, /*immediate*/true);
 3160       } else if (rtype == relocInfo::metadata_type) {
 3161         __ mov_metadata(dst_reg, (Metadata*)con);
 3162       } else {
 3163         assert(rtype == relocInfo::none, &quot;unexpected reloc type&quot;);
 3164         if (con &lt; (address)(uintptr_t)os::vm_page_size()) {
 3165           __ mov(dst_reg, con);
 3166         } else {
 3167           uintptr_t offset;
 3168           __ adrp(dst_reg, con, offset);
 3169           __ add(dst_reg, dst_reg, offset);
 3170         }
 3171       }
 3172     }
 3173   %}
 3174 
 3175   enc_class aarch64_enc_mov_p0(iRegP dst, immP0 src) %{
 3176     C2_MacroAssembler _masm(&amp;cbuf);
 3177     Register dst_reg = as_Register($dst$$reg);
 3178     __ mov(dst_reg, zr);
 3179   %}
 3180 
 3181   enc_class aarch64_enc_mov_p1(iRegP dst, immP_1 src) %{
 3182     C2_MacroAssembler _masm(&amp;cbuf);
 3183     Register dst_reg = as_Register($dst$$reg);
 3184     __ mov(dst_reg, (uint64_t)1);
 3185   %}
 3186 
 3187   enc_class aarch64_enc_mov_byte_map_base(iRegP dst, immByteMapBase src) %{
 3188     C2_MacroAssembler _masm(&amp;cbuf);
 3189     __ load_byte_map_base($dst$$Register);
 3190   %}
 3191 
 3192   enc_class aarch64_enc_mov_n(iRegN dst, immN src) %{
 3193     C2_MacroAssembler _masm(&amp;cbuf);
 3194     Register dst_reg = as_Register($dst$$reg);
 3195     address con = (address)$src$$constant;
 3196     if (con == NULL) {
 3197       ShouldNotReachHere();
 3198     } else {
 3199       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3200       assert(rtype == relocInfo::oop_type, &quot;unexpected reloc type&quot;);
 3201       __ set_narrow_oop(dst_reg, (jobject)con);
 3202     }
 3203   %}
 3204 
 3205   enc_class aarch64_enc_mov_n0(iRegN dst, immN0 src) %{
 3206     C2_MacroAssembler _masm(&amp;cbuf);
 3207     Register dst_reg = as_Register($dst$$reg);
 3208     __ mov(dst_reg, zr);
 3209   %}
 3210 
 3211   enc_class aarch64_enc_mov_nk(iRegN dst, immNKlass src) %{
 3212     C2_MacroAssembler _masm(&amp;cbuf);
 3213     Register dst_reg = as_Register($dst$$reg);
 3214     address con = (address)$src$$constant;
 3215     if (con == NULL) {
 3216       ShouldNotReachHere();
 3217     } else {
 3218       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3219       assert(rtype == relocInfo::metadata_type, &quot;unexpected reloc type&quot;);
 3220       __ set_narrow_klass(dst_reg, (Klass *)con);
 3221     }
 3222   %}
 3223 
 3224   // arithmetic encodings
 3225 
 3226   enc_class aarch64_enc_addsubw_imm(iRegI dst, iRegI src1, immIAddSub src2) %{
 3227     C2_MacroAssembler _masm(&amp;cbuf);
 3228     Register dst_reg = as_Register($dst$$reg);
 3229     Register src_reg = as_Register($src1$$reg);
 3230     int32_t con = (int32_t)$src2$$constant;
 3231     // add has primary == 0, subtract has primary == 1
 3232     if ($primary) { con = -con; }
 3233     if (con &lt; 0) {
 3234       __ subw(dst_reg, src_reg, -con);
 3235     } else {
 3236       __ addw(dst_reg, src_reg, con);
 3237     }
 3238   %}
 3239 
 3240   enc_class aarch64_enc_addsub_imm(iRegL dst, iRegL src1, immLAddSub src2) %{
 3241     C2_MacroAssembler _masm(&amp;cbuf);
 3242     Register dst_reg = as_Register($dst$$reg);
 3243     Register src_reg = as_Register($src1$$reg);
 3244     int32_t con = (int32_t)$src2$$constant;
 3245     // add has primary == 0, subtract has primary == 1
 3246     if ($primary) { con = -con; }
 3247     if (con &lt; 0) {
 3248       __ sub(dst_reg, src_reg, -con);
 3249     } else {
 3250       __ add(dst_reg, src_reg, con);
 3251     }
 3252   %}
 3253 
 3254   enc_class aarch64_enc_divw(iRegI dst, iRegI src1, iRegI src2) %{
 3255     C2_MacroAssembler _masm(&amp;cbuf);
 3256    Register dst_reg = as_Register($dst$$reg);
 3257    Register src1_reg = as_Register($src1$$reg);
 3258    Register src2_reg = as_Register($src2$$reg);
 3259     __ corrected_idivl(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3260   %}
 3261 
 3262   enc_class aarch64_enc_div(iRegI dst, iRegI src1, iRegI src2) %{
 3263     C2_MacroAssembler _masm(&amp;cbuf);
 3264    Register dst_reg = as_Register($dst$$reg);
 3265    Register src1_reg = as_Register($src1$$reg);
 3266    Register src2_reg = as_Register($src2$$reg);
 3267     __ corrected_idivq(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3268   %}
 3269 
 3270   enc_class aarch64_enc_modw(iRegI dst, iRegI src1, iRegI src2) %{
 3271     C2_MacroAssembler _masm(&amp;cbuf);
 3272    Register dst_reg = as_Register($dst$$reg);
 3273    Register src1_reg = as_Register($src1$$reg);
 3274    Register src2_reg = as_Register($src2$$reg);
 3275     __ corrected_idivl(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3276   %}
 3277 
 3278   enc_class aarch64_enc_mod(iRegI dst, iRegI src1, iRegI src2) %{
 3279     C2_MacroAssembler _masm(&amp;cbuf);
 3280    Register dst_reg = as_Register($dst$$reg);
 3281    Register src1_reg = as_Register($src1$$reg);
 3282    Register src2_reg = as_Register($src2$$reg);
 3283     __ corrected_idivq(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3284   %}
 3285 
 3286   // compare instruction encodings
 3287 
 3288   enc_class aarch64_enc_cmpw(iRegI src1, iRegI src2) %{
 3289     C2_MacroAssembler _masm(&amp;cbuf);
 3290     Register reg1 = as_Register($src1$$reg);
 3291     Register reg2 = as_Register($src2$$reg);
 3292     __ cmpw(reg1, reg2);
 3293   %}
 3294 
 3295   enc_class aarch64_enc_cmpw_imm_addsub(iRegI src1, immIAddSub src2) %{
 3296     C2_MacroAssembler _masm(&amp;cbuf);
 3297     Register reg = as_Register($src1$$reg);
 3298     int32_t val = $src2$$constant;
 3299     if (val &gt;= 0) {
 3300       __ subsw(zr, reg, val);
 3301     } else {
 3302       __ addsw(zr, reg, -val);
 3303     }
 3304   %}
 3305 
 3306   enc_class aarch64_enc_cmpw_imm(iRegI src1, immI src2) %{
 3307     C2_MacroAssembler _masm(&amp;cbuf);
 3308     Register reg1 = as_Register($src1$$reg);
 3309     uint32_t val = (uint32_t)$src2$$constant;
 3310     __ movw(rscratch1, val);
 3311     __ cmpw(reg1, rscratch1);
 3312   %}
 3313 
 3314   enc_class aarch64_enc_cmp(iRegL src1, iRegL src2) %{
 3315     C2_MacroAssembler _masm(&amp;cbuf);
 3316     Register reg1 = as_Register($src1$$reg);
 3317     Register reg2 = as_Register($src2$$reg);
 3318     __ cmp(reg1, reg2);
 3319   %}
 3320 
 3321   enc_class aarch64_enc_cmp_imm_addsub(iRegL src1, immL12 src2) %{
 3322     C2_MacroAssembler _masm(&amp;cbuf);
 3323     Register reg = as_Register($src1$$reg);
 3324     int64_t val = $src2$$constant;
 3325     if (val &gt;= 0) {
 3326       __ subs(zr, reg, val);
 3327     } else if (val != -val) {
 3328       __ adds(zr, reg, -val);
 3329     } else {
 3330     // aargh, Long.MIN_VALUE is a special case
 3331       __ orr(rscratch1, zr, (uint64_t)val);
 3332       __ subs(zr, reg, rscratch1);
 3333     }
 3334   %}
 3335 
 3336   enc_class aarch64_enc_cmp_imm(iRegL src1, immL src2) %{
 3337     C2_MacroAssembler _masm(&amp;cbuf);
 3338     Register reg1 = as_Register($src1$$reg);
 3339     uint64_t val = (uint64_t)$src2$$constant;
 3340     __ mov(rscratch1, val);
 3341     __ cmp(reg1, rscratch1);
 3342   %}
 3343 
 3344   enc_class aarch64_enc_cmpp(iRegP src1, iRegP src2) %{
 3345     C2_MacroAssembler _masm(&amp;cbuf);
 3346     Register reg1 = as_Register($src1$$reg);
 3347     Register reg2 = as_Register($src2$$reg);
 3348     __ cmp(reg1, reg2);
 3349   %}
 3350 
 3351   enc_class aarch64_enc_cmpn(iRegN src1, iRegN src2) %{
 3352     C2_MacroAssembler _masm(&amp;cbuf);
 3353     Register reg1 = as_Register($src1$$reg);
 3354     Register reg2 = as_Register($src2$$reg);
 3355     __ cmpw(reg1, reg2);
 3356   %}
 3357 
 3358   enc_class aarch64_enc_testp(iRegP src) %{
 3359     C2_MacroAssembler _masm(&amp;cbuf);
 3360     Register reg = as_Register($src$$reg);
 3361     __ cmp(reg, zr);
 3362   %}
 3363 
 3364   enc_class aarch64_enc_testn(iRegN src) %{
 3365     C2_MacroAssembler _masm(&amp;cbuf);
 3366     Register reg = as_Register($src$$reg);
 3367     __ cmpw(reg, zr);
 3368   %}
 3369 
 3370   enc_class aarch64_enc_b(label lbl) %{
 3371     C2_MacroAssembler _masm(&amp;cbuf);
 3372     Label *L = $lbl$$label;
 3373     __ b(*L);
 3374   %}
 3375 
 3376   enc_class aarch64_enc_br_con(cmpOp cmp, label lbl) %{
 3377     C2_MacroAssembler _masm(&amp;cbuf);
 3378     Label *L = $lbl$$label;
 3379     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3380   %}
 3381 
 3382   enc_class aarch64_enc_br_conU(cmpOpU cmp, label lbl) %{
 3383     C2_MacroAssembler _masm(&amp;cbuf);
 3384     Label *L = $lbl$$label;
 3385     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3386   %}
 3387 
 3388   enc_class aarch64_enc_partial_subtype_check(iRegP sub, iRegP super, iRegP temp, iRegP result)
 3389   %{
 3390      Register sub_reg = as_Register($sub$$reg);
 3391      Register super_reg = as_Register($super$$reg);
 3392      Register temp_reg = as_Register($temp$$reg);
 3393      Register result_reg = as_Register($result$$reg);
 3394 
 3395      Label miss;
 3396      C2_MacroAssembler _masm(&amp;cbuf);
 3397      __ check_klass_subtype_slow_path(sub_reg, super_reg, temp_reg, result_reg,
 3398                                      NULL, &amp;miss,
 3399                                      /*set_cond_codes:*/ true);
 3400      if ($primary) {
 3401        __ mov(result_reg, zr);
 3402      }
 3403      __ bind(miss);
 3404   %}
 3405 
 3406   enc_class aarch64_enc_java_static_call(method meth) %{
 3407     C2_MacroAssembler _masm(&amp;cbuf);
 3408 
 3409     address addr = (address)$meth$$method;
 3410     address call;
 3411     if (!_method) {
 3412       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
 3413       call = __ trampoline_call(Address(addr, relocInfo::runtime_call_type), &amp;cbuf);
 3414     } else {
 3415       int method_index = resolved_method_index(cbuf);
 3416       RelocationHolder rspec = _optimized_virtual ? opt_virtual_call_Relocation::spec(method_index)
 3417                                                   : static_call_Relocation::spec(method_index);
 3418       call = __ trampoline_call(Address(addr, rspec), &amp;cbuf);
 3419 
 3420       // Emit stub for static call
 3421       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 3422       if (stub == NULL) {
 3423         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3424         return;
 3425       }
 3426     }
 3427     if (call == NULL) {
 3428       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3429       return;
 3430     }
 3431   %}
 3432 
 3433   enc_class aarch64_enc_java_dynamic_call(method meth) %{
 3434     C2_MacroAssembler _masm(&amp;cbuf);
 3435     int method_index = resolved_method_index(cbuf);
 3436     address call = __ ic_call((address)$meth$$method, method_index);
 3437     if (call == NULL) {
 3438       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3439       return;
 3440     }
 3441   %}
 3442 
 3443   enc_class aarch64_enc_call_epilog() %{
 3444     C2_MacroAssembler _masm(&amp;cbuf);
 3445     if (VerifyStackAtCalls) {
 3446       // Check that stack depth is unchanged: find majik cookie on stack
 3447       __ call_Unimplemented();
 3448     }
 3449   %}
 3450 
 3451   enc_class aarch64_enc_java_to_runtime(method meth) %{
 3452     C2_MacroAssembler _masm(&amp;cbuf);
 3453 
 3454     // some calls to generated routines (arraycopy code) are scheduled
 3455     // by C2 as runtime calls. if so we can call them using a br (they
 3456     // will be in a reachable segment) otherwise we have to use a blr
 3457     // which loads the absolute address into a register.
 3458     address entry = (address)$meth$$method;
 3459     CodeBlob *cb = CodeCache::find_blob(entry);
 3460     if (cb) {
 3461       address call = __ trampoline_call(Address(entry, relocInfo::runtime_call_type));
 3462       if (call == NULL) {
 3463         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3464         return;
 3465       }
 3466     } else {
 3467       Label retaddr;
 3468       __ adr(rscratch2, retaddr);
 3469       __ lea(rscratch1, RuntimeAddress(entry));
 3470       // Leave a breadcrumb for JavaFrameAnchor::capture_last_Java_pc()
 3471       __ stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)));
 3472       __ blr(rscratch1);
 3473       __ bind(retaddr);
 3474       __ add(sp, sp, 2 * wordSize);
 3475     }
 3476   %}
 3477 
 3478   enc_class aarch64_enc_rethrow() %{
 3479     C2_MacroAssembler _masm(&amp;cbuf);
 3480     __ far_jump(RuntimeAddress(OptoRuntime::rethrow_stub()));
 3481   %}
 3482 
 3483   enc_class aarch64_enc_ret() %{
 3484     C2_MacroAssembler _masm(&amp;cbuf);
 3485     __ ret(lr);
 3486   %}
 3487 
 3488   enc_class aarch64_enc_tail_call(iRegP jump_target) %{
 3489     C2_MacroAssembler _masm(&amp;cbuf);
 3490     Register target_reg = as_Register($jump_target$$reg);
 3491     __ br(target_reg);
 3492   %}
 3493 
 3494   enc_class aarch64_enc_tail_jmp(iRegP jump_target) %{
 3495     C2_MacroAssembler _masm(&amp;cbuf);
 3496     Register target_reg = as_Register($jump_target$$reg);
 3497     // exception oop should be in r0
 3498     // ret addr has been popped into lr
 3499     // callee expects it in r3
 3500     __ mov(r3, lr);
 3501     __ br(target_reg);
 3502   %}
 3503 
 3504   enc_class aarch64_enc_fast_lock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3505     C2_MacroAssembler _masm(&amp;cbuf);
 3506     Register oop = as_Register($object$$reg);
 3507     Register box = as_Register($box$$reg);
 3508     Register disp_hdr = as_Register($tmp$$reg);
 3509     Register tmp = as_Register($tmp2$$reg);
 3510     Label cont;
 3511     Label object_has_monitor;
 3512     Label cas_failed;
 3513 
 3514     assert_different_registers(oop, box, tmp, disp_hdr);
 3515 
 3516     // Load markWord from object into displaced_header.
 3517     __ ldr(disp_hdr, Address(oop, oopDesc::mark_offset_in_bytes()));
 3518 
 3519     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3520       __ biased_locking_enter(box, oop, disp_hdr, tmp, true, cont);
 3521     }
 3522 
 3523     // Check for existing monitor
 3524     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3525 
 3526     // Set tmp to be (markWord of object | UNLOCK_VALUE).
 3527     __ orr(tmp, disp_hdr, markWord::unlocked_value);
 3528 
 3529     // Initialize the box. (Must happen before we update the object mark!)
 3530     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3531 
 3532     // Compare object markWord with an unlocked value (tmp) and if
 3533     // equal exchange the stack address of our box with object markWord.
 3534     // On failure disp_hdr contains the possibly locked markWord.
 3535     __ cmpxchg(oop, tmp, box, Assembler::xword, /*acquire*/ true,
 3536                /*release*/ true, /*weak*/ false, disp_hdr);
 3537     __ br(Assembler::EQ, cont);
 3538 
 3539     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3540 
 3541     // If the compare-and-exchange succeeded, then we found an unlocked
 3542     // object, will have now locked it will continue at label cont
 3543 
 3544     __ bind(cas_failed);
 3545     // We did not see an unlocked object so try the fast recursive case.
 3546 
 3547     // Check if the owner is self by comparing the value in the
 3548     // markWord of object (disp_hdr) with the stack pointer.
 3549     __ mov(rscratch1, sp);
 3550     __ sub(disp_hdr, disp_hdr, rscratch1);
 3551     __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));
 3552     // If condition is true we are cont and hence we can store 0 as the
 3553     // displaced header in the box, which indicates that it is a recursive lock.
 3554     __ ands(tmp/*==0?*/, disp_hdr, tmp);   // Sets flags for result
 3555     __ str(tmp/*==0, perhaps*/, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3556 
 3557     __ b(cont);
 3558 
 3559     // Handle existing monitor.
 3560     __ bind(object_has_monitor);
 3561 
 3562     // The object&#39;s monitor m is unlocked iff m-&gt;owner == NULL,
 3563     // otherwise m-&gt;owner may contain a thread or a stack address.
 3564     //
 3565     // Try to CAS m-&gt;owner from NULL to current thread.
 3566     __ add(tmp, disp_hdr, (ObjectMonitor::owner_offset_in_bytes()-markWord::monitor_value));
 3567     __ cmpxchg(tmp, zr, rthread, Assembler::xword, /*acquire*/ true,
 3568                /*release*/ true, /*weak*/ false, noreg); // Sets flags for result
 3569 
 3570     // Store a non-null value into the box to avoid looking like a re-entrant
 3571     // lock. The fast-path monitor unlock code checks for
 3572     // markWord::monitor_value so use markWord::unused_mark which has the
 3573     // relevant bit set, and also matches ObjectSynchronizer::enter.
 3574     __ mov(tmp, (address)markWord::unused_mark().value());
 3575     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3576 
 3577     __ bind(cont);
 3578     // flag == EQ indicates success
 3579     // flag == NE indicates failure
 3580   %}
 3581 
 3582   enc_class aarch64_enc_fast_unlock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3583     C2_MacroAssembler _masm(&amp;cbuf);
 3584     Register oop = as_Register($object$$reg);
 3585     Register box = as_Register($box$$reg);
 3586     Register disp_hdr = as_Register($tmp$$reg);
 3587     Register tmp = as_Register($tmp2$$reg);
 3588     Label cont;
 3589     Label object_has_monitor;
 3590 
 3591     assert_different_registers(oop, box, tmp, disp_hdr);
 3592 
 3593     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3594       __ biased_locking_exit(oop, tmp, cont);
 3595     }
 3596 
 3597     // Find the lock address and load the displaced header from the stack.
 3598     __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3599 
 3600     // If the displaced header is 0, we have a recursive unlock.
 3601     __ cmp(disp_hdr, zr);
 3602     __ br(Assembler::EQ, cont);
 3603 
 3604     // Handle existing monitor.
 3605     __ ldr(tmp, Address(oop, oopDesc::mark_offset_in_bytes()));
 3606     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3607 
 3608     // Check if it is still a light weight lock, this is is true if we
 3609     // see the stack address of the basicLock in the markWord of the
 3610     // object.
 3611 
 3612     __ cmpxchg(oop, box, disp_hdr, Assembler::xword, /*acquire*/ false,
 3613                /*release*/ true, /*weak*/ false, tmp);
 3614     __ b(cont);
 3615 
 3616     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3617 
 3618     // Handle existing monitor.
 3619     __ bind(object_has_monitor);
 3620     STATIC_ASSERT(markWord::monitor_value &lt;= INT_MAX);
 3621     __ add(tmp, tmp, -(int)markWord::monitor_value); // monitor
 3622     __ ldr(rscratch1, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3623     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::recursions_offset_in_bytes()));
 3624     __ eor(rscratch1, rscratch1, rthread); // Will be 0 if we are the owner.
 3625     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if there are 0 recursions
 3626     __ cmp(rscratch1, zr); // Sets flags for result
 3627     __ br(Assembler::NE, cont);
 3628 
 3629     __ ldr(rscratch1, Address(tmp, ObjectMonitor::EntryList_offset_in_bytes()));
 3630     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::cxq_offset_in_bytes()));
 3631     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if both are 0.
 3632     __ cmp(rscratch1, zr); // Sets flags for result
 3633     __ cbnz(rscratch1, cont);
 3634     // need a release store here
 3635     __ lea(tmp, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3636     __ stlr(zr, tmp); // set unowned
 3637 
 3638     __ bind(cont);
 3639     // flag == EQ indicates success
 3640     // flag == NE indicates failure
 3641   %}
 3642 
 3643 %}
 3644 
 3645 //----------FRAME--------------------------------------------------------------
 3646 // Definition of frame structure and management information.
 3647 //
 3648 //  S T A C K   L A Y O U T    Allocators stack-slot number
 3649 //                             |   (to get allocators register number
 3650 //  G  Owned by    |        |  v    add OptoReg::stack0())
 3651 //  r   CALLER     |        |
 3652 //  o     |        +--------+      pad to even-align allocators stack-slot
 3653 //  w     V        |  pad0  |        numbers; owned by CALLER
 3654 //  t   -----------+--------+----&gt; Matcher::_in_arg_limit, unaligned
 3655 //  h     ^        |   in   |  5
 3656 //        |        |  args  |  4   Holes in incoming args owned by SELF
 3657 //  |     |        |        |  3
 3658 //  |     |        +--------+
 3659 //  V     |        | old out|      Empty on Intel, window on Sparc
 3660 //        |    old |preserve|      Must be even aligned.
 3661 //        |     SP-+--------+----&gt; Matcher::_old_SP, even aligned
 3662 //        |        |   in   |  3   area for Intel ret address
 3663 //     Owned by    |preserve|      Empty on Sparc.
 3664 //       SELF      +--------+
 3665 //        |        |  pad2  |  2   pad to align old SP
 3666 //        |        +--------+  1
 3667 //        |        | locks  |  0
 3668 //        |        +--------+----&gt; OptoReg::stack0(), even aligned
 3669 //        |        |  pad1  | 11   pad to align new SP
 3670 //        |        +--------+
 3671 //        |        |        | 10
 3672 //        |        | spills |  9   spills
 3673 //        V        |        |  8   (pad0 slot for callee)
 3674 //      -----------+--------+----&gt; Matcher::_out_arg_limit, unaligned
 3675 //        ^        |  out   |  7
 3676 //        |        |  args  |  6   Holes in outgoing args owned by CALLEE
 3677 //     Owned by    +--------+
 3678 //      CALLEE     | new out|  6   Empty on Intel, window on Sparc
 3679 //        |    new |preserve|      Must be even-aligned.
 3680 //        |     SP-+--------+----&gt; Matcher::_new_SP, even aligned
 3681 //        |        |        |
 3682 //
 3683 // Note 1: Only region 8-11 is determined by the allocator.  Region 0-5 is
 3684 //         known from SELF&#39;s arguments and the Java calling convention.
 3685 //         Region 6-7 is determined per call site.
 3686 // Note 2: If the calling convention leaves holes in the incoming argument
 3687 //         area, those holes are owned by SELF.  Holes in the outgoing area
 3688 //         are owned by the CALLEE.  Holes should not be nessecary in the
 3689 //         incoming area, as the Java calling convention is completely under
 3690 //         the control of the AD file.  Doubles can be sorted and packed to
 3691 //         avoid holes.  Holes in the outgoing arguments may be nessecary for
 3692 //         varargs C calling conventions.
 3693 // Note 3: Region 0-3 is even aligned, with pad2 as needed.  Region 3-5 is
 3694 //         even aligned with pad0 as needed.
 3695 //         Region 6 is even aligned.  Region 6-7 is NOT even aligned;
 3696 //           (the latter is true on Intel but is it false on AArch64?)
 3697 //         region 6-11 is even aligned; it may be padded out more so that
 3698 //         the region from SP to FP meets the minimum stack alignment.
 3699 // Note 4: For I2C adapters, the incoming FP may not meet the minimum stack
 3700 //         alignment.  Region 11, pad1, may be dynamically extended so that
 3701 //         SP meets the minimum alignment.
 3702 
 3703 frame %{
 3704   // What direction does stack grow in (assumed to be same for C &amp; Java)
 3705   stack_direction(TOWARDS_LOW);
 3706 
 3707   // These three registers define part of the calling convention
 3708   // between compiled code and the interpreter.
 3709 
<a name="1" id="anc1"></a><span class="line-modified"> 3710   // Inline Cache Register or Method for I2C.</span>
 3711   inline_cache_reg(R12);
 3712 
 3713   // Method Oop Register when calling interpreter.
 3714   interpreter_method_oop_reg(R12);
 3715 
 3716   // Number of stack slots consumed by locking an object
 3717   sync_stack_slots(2);
 3718 
 3719   // Compiled code&#39;s Frame Pointer
 3720   frame_pointer(R31);
 3721 
 3722   // Interpreter stores its frame pointer in a register which is
 3723   // stored to the stack by I2CAdaptors.
 3724   // I2CAdaptors convert from interpreted java to compiled java.
 3725   interpreter_frame_pointer(R29);
 3726 
 3727   // Stack alignment requirement
 3728   stack_alignment(StackAlignmentInBytes); // Alignment size in bytes (128-bit -&gt; 16 bytes)
 3729 
 3730   // Number of stack slots between incoming argument block and the start of
 3731   // a new frame.  The PROLOG must add this many slots to the stack.  The
 3732   // EPILOG must remove this many slots. aarch64 needs two slots for
 3733   // return address and fp.
 3734   // TODO think this is correct but check
 3735   in_preserve_stack_slots(4);
 3736 
 3737   // Number of outgoing stack slots killed above the out_preserve_stack_slots
 3738   // for calls to C.  Supports the var-args backing area for register parms.
 3739   varargs_C_out_slots_killed(frame::arg_reg_save_area_bytes/BytesPerInt);
 3740 
 3741   // The after-PROLOG location of the return address.  Location of
 3742   // return address specifies a type (REG or STACK) and a number
 3743   // representing the register number (i.e. - use a register name) or
 3744   // stack slot.
 3745   // Ret Addr is on stack in slot 0 if no locks or verification or alignment.
 3746   // Otherwise, it is above the locks and verification slot and alignment word
 3747   // TODO this may well be correct but need to check why that - 2 is there
 3748   // ppc port uses 0 but we definitely need to allow for fixed_slots
 3749   // which folds in the space used for monitors
 3750   return_addr(STACK - 2 +
 3751               align_up((Compile::current()-&gt;in_preserve_stack_slots() +
 3752                         Compile::current()-&gt;fixed_slots()),
 3753                        stack_alignment_in_slots()));
 3754 
 3755   // Body of function which returns an integer array locating
 3756   // arguments either in registers or in stack slots.  Passed an array
 3757   // of ideal registers called &quot;sig&quot; and a &quot;length&quot; count.  Stack-slot
 3758   // offsets are based on outgoing arguments, i.e. a CALLER setting up
 3759   // arguments for a CALLEE.  Incoming stack arguments are
 3760   // automatically biased by the preserve_stack_slots field above.
 3761 
 3762   calling_convention
 3763   %{
 3764     // No difference between ingoing/outgoing just pass false
 3765     SharedRuntime::java_calling_convention(sig_bt, regs, length, false);
 3766   %}
 3767 
 3768   c_calling_convention
 3769   %{
 3770     // This is obviously always outgoing
 3771     (void) SharedRuntime::c_calling_convention(sig_bt, regs, NULL, length);
 3772   %}
 3773 
 3774   // Location of compiled Java return values.  Same as C for now.
 3775   return_value
 3776   %{
 3777     // TODO do we allow ideal_reg == Op_RegN???
 3778     assert(ideal_reg &gt;= Op_RegI &amp;&amp; ideal_reg &lt;= Op_RegL,
 3779            &quot;only return normal values&quot;);
 3780 
 3781     static const int lo[Op_RegL + 1] = { // enum name
 3782       0,                                 // Op_Node
 3783       0,                                 // Op_Set
 3784       R0_num,                            // Op_RegN
 3785       R0_num,                            // Op_RegI
 3786       R0_num,                            // Op_RegP
 3787       V0_num,                            // Op_RegF
 3788       V0_num,                            // Op_RegD
 3789       R0_num                             // Op_RegL
 3790     };
 3791 
 3792     static const int hi[Op_RegL + 1] = { // enum name
 3793       0,                                 // Op_Node
 3794       0,                                 // Op_Set
 3795       OptoReg::Bad,                      // Op_RegN
 3796       OptoReg::Bad,                      // Op_RegI
 3797       R0_H_num,                          // Op_RegP
 3798       OptoReg::Bad,                      // Op_RegF
 3799       V0_H_num,                          // Op_RegD
 3800       R0_H_num                           // Op_RegL
 3801     };
 3802 
 3803     return OptoRegPair(hi[ideal_reg], lo[ideal_reg]);
 3804   %}
 3805 %}
 3806 
 3807 //----------ATTRIBUTES---------------------------------------------------------
 3808 //----------Operand Attributes-------------------------------------------------
 3809 op_attrib op_cost(1);        // Required cost attribute
 3810 
 3811 //----------Instruction Attributes---------------------------------------------
 3812 ins_attrib ins_cost(INSN_COST); // Required cost attribute
 3813 ins_attrib ins_size(32);        // Required size attribute (in bits)
 3814 ins_attrib ins_short_branch(0); // Required flag: is this instruction
 3815                                 // a non-matching short branch variant
 3816                                 // of some long branch?
 3817 ins_attrib ins_alignment(4);    // Required alignment attribute (must
 3818                                 // be a power of 2) specifies the
 3819                                 // alignment that some part of the
 3820                                 // instruction (not necessarily the
 3821                                 // start) requires.  If &gt; 1, a
 3822                                 // compute_padding() function must be
 3823                                 // provided for the instruction
 3824 
 3825 //----------OPERANDS-----------------------------------------------------------
 3826 // Operand definitions must precede instruction definitions for correct parsing
 3827 // in the ADLC because operands constitute user defined types which are used in
 3828 // instruction definitions.
 3829 
 3830 //----------Simple Operands----------------------------------------------------
 3831 
 3832 // Integer operands 32 bit
 3833 // 32 bit immediate
 3834 operand immI()
 3835 %{
 3836   match(ConI);
 3837 
 3838   op_cost(0);
 3839   format %{ %}
 3840   interface(CONST_INTER);
 3841 %}
 3842 
 3843 // 32 bit zero
 3844 operand immI0()
 3845 %{
 3846   predicate(n-&gt;get_int() == 0);
 3847   match(ConI);
 3848 
 3849   op_cost(0);
 3850   format %{ %}
 3851   interface(CONST_INTER);
 3852 %}
 3853 
 3854 // 32 bit unit increment
 3855 operand immI_1()
 3856 %{
 3857   predicate(n-&gt;get_int() == 1);
 3858   match(ConI);
 3859 
 3860   op_cost(0);
 3861   format %{ %}
 3862   interface(CONST_INTER);
 3863 %}
 3864 
 3865 // 32 bit unit decrement
 3866 operand immI_M1()
 3867 %{
 3868   predicate(n-&gt;get_int() == -1);
 3869   match(ConI);
 3870 
 3871   op_cost(0);
 3872   format %{ %}
 3873   interface(CONST_INTER);
 3874 %}
 3875 
 3876 // Shift values for add/sub extension shift
 3877 operand immIExt()
 3878 %{
 3879   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 4));
 3880   match(ConI);
 3881 
 3882   op_cost(0);
 3883   format %{ %}
 3884   interface(CONST_INTER);
 3885 %}
 3886 
 3887 operand immI_le_4()
 3888 %{
 3889   predicate(n-&gt;get_int() &lt;= 4);
 3890   match(ConI);
 3891 
 3892   op_cost(0);
 3893   format %{ %}
 3894   interface(CONST_INTER);
 3895 %}
 3896 
 3897 operand immI_31()
 3898 %{
 3899   predicate(n-&gt;get_int() == 31);
 3900   match(ConI);
 3901 
 3902   op_cost(0);
 3903   format %{ %}
 3904   interface(CONST_INTER);
 3905 %}
 3906 
 3907 operand immI_8()
 3908 %{
 3909   predicate(n-&gt;get_int() == 8);
 3910   match(ConI);
 3911 
 3912   op_cost(0);
 3913   format %{ %}
 3914   interface(CONST_INTER);
 3915 %}
 3916 
 3917 operand immI_16()
 3918 %{
 3919   predicate(n-&gt;get_int() == 16);
 3920   match(ConI);
 3921 
 3922   op_cost(0);
 3923   format %{ %}
 3924   interface(CONST_INTER);
 3925 %}
 3926 
 3927 operand immI_24()
 3928 %{
 3929   predicate(n-&gt;get_int() == 24);
 3930   match(ConI);
 3931 
 3932   op_cost(0);
 3933   format %{ %}
 3934   interface(CONST_INTER);
 3935 %}
 3936 
 3937 operand immI_32()
 3938 %{
 3939   predicate(n-&gt;get_int() == 32);
 3940   match(ConI);
 3941 
 3942   op_cost(0);
 3943   format %{ %}
 3944   interface(CONST_INTER);
 3945 %}
 3946 
 3947 operand immI_48()
 3948 %{
 3949   predicate(n-&gt;get_int() == 48);
 3950   match(ConI);
 3951 
 3952   op_cost(0);
 3953   format %{ %}
 3954   interface(CONST_INTER);
 3955 %}
 3956 
 3957 operand immI_56()
 3958 %{
 3959   predicate(n-&gt;get_int() == 56);
 3960   match(ConI);
 3961 
 3962   op_cost(0);
 3963   format %{ %}
 3964   interface(CONST_INTER);
 3965 %}
 3966 
 3967 operand immI_63()
 3968 %{
 3969   predicate(n-&gt;get_int() == 63);
 3970   match(ConI);
 3971 
 3972   op_cost(0);
 3973   format %{ %}
 3974   interface(CONST_INTER);
 3975 %}
 3976 
 3977 operand immI_64()
 3978 %{
 3979   predicate(n-&gt;get_int() == 64);
 3980   match(ConI);
 3981 
 3982   op_cost(0);
 3983   format %{ %}
 3984   interface(CONST_INTER);
 3985 %}
 3986 
 3987 operand immI_255()
 3988 %{
 3989   predicate(n-&gt;get_int() == 255);
 3990   match(ConI);
 3991 
 3992   op_cost(0);
 3993   format %{ %}
 3994   interface(CONST_INTER);
 3995 %}
 3996 
 3997 operand immI_65535()
 3998 %{
 3999   predicate(n-&gt;get_int() == 65535);
 4000   match(ConI);
 4001 
 4002   op_cost(0);
 4003   format %{ %}
 4004   interface(CONST_INTER);
 4005 %}
 4006 
 4007 operand immL_255()
 4008 %{
 4009   predicate(n-&gt;get_long() == 255L);
 4010   match(ConL);
 4011 
 4012   op_cost(0);
 4013   format %{ %}
 4014   interface(CONST_INTER);
 4015 %}
 4016 
 4017 operand immL_65535()
 4018 %{
 4019   predicate(n-&gt;get_long() == 65535L);
 4020   match(ConL);
 4021 
 4022   op_cost(0);
 4023   format %{ %}
 4024   interface(CONST_INTER);
 4025 %}
 4026 
 4027 operand immL_4294967295()
 4028 %{
 4029   predicate(n-&gt;get_long() == 4294967295L);
 4030   match(ConL);
 4031 
 4032   op_cost(0);
 4033   format %{ %}
 4034   interface(CONST_INTER);
 4035 %}
 4036 
 4037 operand immL_bitmask()
 4038 %{
 4039   predicate((n-&gt;get_long() != 0)
 4040             &amp;&amp; ((n-&gt;get_long() &amp; 0xc000000000000000l) == 0)
 4041             &amp;&amp; is_power_of_2(n-&gt;get_long() + 1));
 4042   match(ConL);
 4043 
 4044   op_cost(0);
 4045   format %{ %}
 4046   interface(CONST_INTER);
 4047 %}
 4048 
 4049 operand immI_bitmask()
 4050 %{
 4051   predicate((n-&gt;get_int() != 0)
 4052             &amp;&amp; ((n-&gt;get_int() &amp; 0xc0000000) == 0)
 4053             &amp;&amp; is_power_of_2(n-&gt;get_int() + 1));
 4054   match(ConI);
 4055 
 4056   op_cost(0);
 4057   format %{ %}
 4058   interface(CONST_INTER);
 4059 %}
 4060 
<a name="2" id="anc2"></a><span class="line-added"> 4061 operand immL_positive_bitmaskI()</span>
<span class="line-added"> 4062 %{</span>
<span class="line-added"> 4063   predicate((n-&gt;get_long() != 0)</span>
<span class="line-added"> 4064             &amp;&amp; ((julong)n-&gt;get_long() &lt; 0x80000000ULL)</span>
<span class="line-added"> 4065             &amp;&amp; is_power_of_2(n-&gt;get_long() + 1));</span>
<span class="line-added"> 4066   match(ConL);</span>
<span class="line-added"> 4067 </span>
<span class="line-added"> 4068   op_cost(0);</span>
<span class="line-added"> 4069   format %{ %}</span>
<span class="line-added"> 4070   interface(CONST_INTER);</span>
<span class="line-added"> 4071 %}</span>
<span class="line-added"> 4072 </span>
 4073 // Scale values for scaled offset addressing modes (up to long but not quad)
 4074 operand immIScale()
 4075 %{
 4076   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 3));
 4077   match(ConI);
 4078 
 4079   op_cost(0);
 4080   format %{ %}
 4081   interface(CONST_INTER);
 4082 %}
 4083 
 4084 // 26 bit signed offset -- for pc-relative branches
 4085 operand immI26()
 4086 %{
 4087   predicate(((-(1 &lt;&lt; 25)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 25)));
 4088   match(ConI);
 4089 
 4090   op_cost(0);
 4091   format %{ %}
 4092   interface(CONST_INTER);
 4093 %}
 4094 
 4095 // 19 bit signed offset -- for pc-relative loads
 4096 operand immI19()
 4097 %{
 4098   predicate(((-(1 &lt;&lt; 18)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 18)));
 4099   match(ConI);
 4100 
 4101   op_cost(0);
 4102   format %{ %}
 4103   interface(CONST_INTER);
 4104 %}
 4105 
 4106 // 12 bit unsigned offset -- for base plus immediate loads
 4107 operand immIU12()
 4108 %{
 4109   predicate((0 &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 12)));
 4110   match(ConI);
 4111 
 4112   op_cost(0);
 4113   format %{ %}
 4114   interface(CONST_INTER);
 4115 %}
 4116 
 4117 operand immLU12()
 4118 %{
 4119   predicate((0 &lt;= n-&gt;get_long()) &amp;&amp; (n-&gt;get_long() &lt; (1 &lt;&lt; 12)));
 4120   match(ConL);
 4121 
 4122   op_cost(0);
 4123   format %{ %}
 4124   interface(CONST_INTER);
 4125 %}
 4126 
 4127 // Offset for scaled or unscaled immediate loads and stores
 4128 operand immIOffset()
 4129 %{
 4130   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4131   match(ConI);
 4132 
 4133   op_cost(0);
 4134   format %{ %}
 4135   interface(CONST_INTER);
 4136 %}
 4137 
 4138 operand immIOffset1()
 4139 %{
 4140   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4141   match(ConI);
 4142 
 4143   op_cost(0);
 4144   format %{ %}
 4145   interface(CONST_INTER);
 4146 %}
 4147 
 4148 operand immIOffset2()
 4149 %{
 4150   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 1));
 4151   match(ConI);
 4152 
 4153   op_cost(0);
 4154   format %{ %}
 4155   interface(CONST_INTER);
 4156 %}
 4157 
 4158 operand immIOffset4()
 4159 %{
 4160   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 2));
 4161   match(ConI);
 4162 
 4163   op_cost(0);
 4164   format %{ %}
 4165   interface(CONST_INTER);
 4166 %}
 4167 
 4168 operand immIOffset8()
 4169 %{
 4170   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 3));
 4171   match(ConI);
 4172 
 4173   op_cost(0);
 4174   format %{ %}
 4175   interface(CONST_INTER);
 4176 %}
 4177 
 4178 operand immIOffset16()
 4179 %{
 4180   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 4));
 4181   match(ConI);
 4182 
 4183   op_cost(0);
 4184   format %{ %}
 4185   interface(CONST_INTER);
 4186 %}
 4187 
 4188 operand immLoffset()
 4189 %{
 4190   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4191   match(ConL);
 4192 
 4193   op_cost(0);
 4194   format %{ %}
 4195   interface(CONST_INTER);
 4196 %}
 4197 
 4198 operand immLoffset1()
 4199 %{
 4200   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4201   match(ConL);
 4202 
 4203   op_cost(0);
 4204   format %{ %}
 4205   interface(CONST_INTER);
 4206 %}
 4207 
 4208 operand immLoffset2()
 4209 %{
 4210   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 1));
 4211   match(ConL);
 4212 
 4213   op_cost(0);
 4214   format %{ %}
 4215   interface(CONST_INTER);
 4216 %}
 4217 
 4218 operand immLoffset4()
 4219 %{
 4220   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 2));
 4221   match(ConL);
 4222 
 4223   op_cost(0);
 4224   format %{ %}
 4225   interface(CONST_INTER);
 4226 %}
 4227 
 4228 operand immLoffset8()
 4229 %{
 4230   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 3));
 4231   match(ConL);
 4232 
 4233   op_cost(0);
 4234   format %{ %}
 4235   interface(CONST_INTER);
 4236 %}
 4237 
 4238 operand immLoffset16()
 4239 %{
 4240   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 4));
 4241   match(ConL);
 4242 
 4243   op_cost(0);
 4244   format %{ %}
 4245   interface(CONST_INTER);
 4246 %}
 4247 
 4248 // 32 bit integer valid for add sub immediate
 4249 operand immIAddSub()
 4250 %{
 4251   predicate(Assembler::operand_valid_for_add_sub_immediate((int64_t)n-&gt;get_int()));
 4252   match(ConI);
 4253   op_cost(0);
 4254   format %{ %}
 4255   interface(CONST_INTER);
 4256 %}
 4257 
 4258 // 32 bit unsigned integer valid for logical immediate
 4259 // TODO -- check this is right when e.g the mask is 0x80000000
 4260 operand immILog()
 4261 %{
 4262   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/true, (uint64_t)n-&gt;get_int()));
 4263   match(ConI);
 4264 
 4265   op_cost(0);
 4266   format %{ %}
 4267   interface(CONST_INTER);
 4268 %}
 4269 
 4270 // Integer operands 64 bit
 4271 // 64 bit immediate
 4272 operand immL()
 4273 %{
 4274   match(ConL);
 4275 
 4276   op_cost(0);
 4277   format %{ %}
 4278   interface(CONST_INTER);
 4279 %}
 4280 
 4281 // 64 bit zero
 4282 operand immL0()
 4283 %{
 4284   predicate(n-&gt;get_long() == 0);
 4285   match(ConL);
 4286 
 4287   op_cost(0);
 4288   format %{ %}
 4289   interface(CONST_INTER);
 4290 %}
 4291 
 4292 // 64 bit unit increment
 4293 operand immL_1()
 4294 %{
 4295   predicate(n-&gt;get_long() == 1);
 4296   match(ConL);
 4297 
 4298   op_cost(0);
 4299   format %{ %}
 4300   interface(CONST_INTER);
 4301 %}
 4302 
 4303 // 64 bit unit decrement
 4304 operand immL_M1()
 4305 %{
 4306   predicate(n-&gt;get_long() == -1);
 4307   match(ConL);
 4308 
 4309   op_cost(0);
 4310   format %{ %}
 4311   interface(CONST_INTER);
 4312 %}
 4313 
 4314 // 32 bit offset of pc in thread anchor
 4315 
 4316 operand immL_pc_off()
 4317 %{
 4318   predicate(n-&gt;get_long() == in_bytes(JavaThread::frame_anchor_offset()) +
 4319                              in_bytes(JavaFrameAnchor::last_Java_pc_offset()));
 4320   match(ConL);
 4321 
 4322   op_cost(0);
 4323   format %{ %}
 4324   interface(CONST_INTER);
 4325 %}
 4326 
 4327 // 64 bit integer valid for add sub immediate
 4328 operand immLAddSub()
 4329 %{
 4330   predicate(Assembler::operand_valid_for_add_sub_immediate(n-&gt;get_long()));
 4331   match(ConL);
 4332   op_cost(0);
 4333   format %{ %}
 4334   interface(CONST_INTER);
 4335 %}
 4336 
 4337 // 64 bit integer valid for logical immediate
 4338 operand immLLog()
 4339 %{
 4340   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/false, (uint64_t)n-&gt;get_long()));
 4341   match(ConL);
 4342   op_cost(0);
 4343   format %{ %}
 4344   interface(CONST_INTER);
 4345 %}
 4346 
 4347 // Long Immediate: low 32-bit mask
 4348 operand immL_32bits()
 4349 %{
 4350   predicate(n-&gt;get_long() == 0xFFFFFFFFL);
 4351   match(ConL);
 4352   op_cost(0);
 4353   format %{ %}
 4354   interface(CONST_INTER);
 4355 %}
 4356 
 4357 // Pointer operands
 4358 // Pointer Immediate
 4359 operand immP()
 4360 %{
 4361   match(ConP);
 4362 
 4363   op_cost(0);
 4364   format %{ %}
 4365   interface(CONST_INTER);
 4366 %}
 4367 
 4368 // NULL Pointer Immediate
 4369 operand immP0()
 4370 %{
 4371   predicate(n-&gt;get_ptr() == 0);
 4372   match(ConP);
 4373 
 4374   op_cost(0);
 4375   format %{ %}
 4376   interface(CONST_INTER);
 4377 %}
 4378 
 4379 // Pointer Immediate One
 4380 // this is used in object initialization (initial object header)
 4381 operand immP_1()
 4382 %{
 4383   predicate(n-&gt;get_ptr() == 1);
 4384   match(ConP);
 4385 
 4386   op_cost(0);
 4387   format %{ %}
 4388   interface(CONST_INTER);
 4389 %}
 4390 
 4391 // Card Table Byte Map Base
 4392 operand immByteMapBase()
 4393 %{
 4394   // Get base of card map
 4395   predicate(BarrierSet::barrier_set()-&gt;is_a(BarrierSet::CardTableBarrierSet) &amp;&amp;
 4396             (CardTable::CardValue*)n-&gt;get_ptr() == ((CardTableBarrierSet*)(BarrierSet::barrier_set()))-&gt;card_table()-&gt;byte_map_base());
 4397   match(ConP);
 4398 
 4399   op_cost(0);
 4400   format %{ %}
 4401   interface(CONST_INTER);
 4402 %}
 4403 
 4404 // Pointer Immediate Minus One
 4405 // this is used when we want to write the current PC to the thread anchor
 4406 operand immP_M1()
 4407 %{
 4408   predicate(n-&gt;get_ptr() == -1);
 4409   match(ConP);
 4410 
 4411   op_cost(0);
 4412   format %{ %}
 4413   interface(CONST_INTER);
 4414 %}
 4415 
 4416 // Pointer Immediate Minus Two
 4417 // this is used when we want to write the current PC to the thread anchor
 4418 operand immP_M2()
 4419 %{
 4420   predicate(n-&gt;get_ptr() == -2);
 4421   match(ConP);
 4422 
 4423   op_cost(0);
 4424   format %{ %}
 4425   interface(CONST_INTER);
 4426 %}
 4427 
 4428 // Float and Double operands
 4429 // Double Immediate
 4430 operand immD()
 4431 %{
 4432   match(ConD);
 4433   op_cost(0);
 4434   format %{ %}
 4435   interface(CONST_INTER);
 4436 %}
 4437 
 4438 // Double Immediate: +0.0d
 4439 operand immD0()
 4440 %{
 4441   predicate(jlong_cast(n-&gt;getd()) == 0);
 4442   match(ConD);
 4443 
 4444   op_cost(0);
 4445   format %{ %}
 4446   interface(CONST_INTER);
 4447 %}
 4448 
 4449 // constant &#39;double +0.0&#39;.
 4450 operand immDPacked()
 4451 %{
 4452   predicate(Assembler::operand_valid_for_float_immediate(n-&gt;getd()));
 4453   match(ConD);
 4454   op_cost(0);
 4455   format %{ %}
 4456   interface(CONST_INTER);
 4457 %}
 4458 
 4459 // Float Immediate
 4460 operand immF()
 4461 %{
 4462   match(ConF);
 4463   op_cost(0);
 4464   format %{ %}
 4465   interface(CONST_INTER);
 4466 %}
 4467 
 4468 // Float Immediate: +0.0f.
 4469 operand immF0()
 4470 %{
 4471   predicate(jint_cast(n-&gt;getf()) == 0);
 4472   match(ConF);
 4473 
 4474   op_cost(0);
 4475   format %{ %}
 4476   interface(CONST_INTER);
 4477 %}
 4478 
 4479 //
 4480 operand immFPacked()
 4481 %{
 4482   predicate(Assembler::operand_valid_for_float_immediate((double)n-&gt;getf()));
 4483   match(ConF);
 4484   op_cost(0);
 4485   format %{ %}
 4486   interface(CONST_INTER);
 4487 %}
 4488 
 4489 // Narrow pointer operands
 4490 // Narrow Pointer Immediate
 4491 operand immN()
 4492 %{
 4493   match(ConN);
 4494 
 4495   op_cost(0);
 4496   format %{ %}
 4497   interface(CONST_INTER);
 4498 %}
 4499 
 4500 // Narrow NULL Pointer Immediate
 4501 operand immN0()
 4502 %{
 4503   predicate(n-&gt;get_narrowcon() == 0);
 4504   match(ConN);
 4505 
 4506   op_cost(0);
 4507   format %{ %}
 4508   interface(CONST_INTER);
 4509 %}
 4510 
 4511 operand immNKlass()
 4512 %{
 4513   match(ConNKlass);
 4514 
 4515   op_cost(0);
 4516   format %{ %}
 4517   interface(CONST_INTER);
 4518 %}
 4519 
 4520 // Integer 32 bit Register Operands
 4521 // Integer 32 bitRegister (excludes SP)
 4522 operand iRegI()
 4523 %{
 4524   constraint(ALLOC_IN_RC(any_reg32));
 4525   match(RegI);
 4526   match(iRegINoSp);
 4527   op_cost(0);
 4528   format %{ %}
 4529   interface(REG_INTER);
 4530 %}
 4531 
 4532 // Integer 32 bit Register not Special
 4533 operand iRegINoSp()
 4534 %{
 4535   constraint(ALLOC_IN_RC(no_special_reg32));
 4536   match(RegI);
 4537   op_cost(0);
 4538   format %{ %}
 4539   interface(REG_INTER);
 4540 %}
 4541 
 4542 // Integer 64 bit Register Operands
 4543 // Integer 64 bit Register (includes SP)
 4544 operand iRegL()
 4545 %{
 4546   constraint(ALLOC_IN_RC(any_reg));
 4547   match(RegL);
 4548   match(iRegLNoSp);
 4549   op_cost(0);
 4550   format %{ %}
 4551   interface(REG_INTER);
 4552 %}
 4553 
 4554 // Integer 64 bit Register not Special
 4555 operand iRegLNoSp()
 4556 %{
 4557   constraint(ALLOC_IN_RC(no_special_reg));
 4558   match(RegL);
 4559   match(iRegL_R0);
 4560   format %{ %}
 4561   interface(REG_INTER);
 4562 %}
 4563 
 4564 // Pointer Register Operands
 4565 // Pointer Register
 4566 operand iRegP()
 4567 %{
 4568   constraint(ALLOC_IN_RC(ptr_reg));
 4569   match(RegP);
 4570   match(iRegPNoSp);
 4571   match(iRegP_R0);
 4572   //match(iRegP_R2);
 4573   //match(iRegP_R4);
 4574   //match(iRegP_R5);
 4575   match(thread_RegP);
 4576   op_cost(0);
 4577   format %{ %}
 4578   interface(REG_INTER);
 4579 %}
 4580 
 4581 // Pointer 64 bit Register not Special
 4582 operand iRegPNoSp()
 4583 %{
 4584   constraint(ALLOC_IN_RC(no_special_ptr_reg));
 4585   match(RegP);
 4586   // match(iRegP);
 4587   // match(iRegP_R0);
 4588   // match(iRegP_R2);
 4589   // match(iRegP_R4);
 4590   // match(iRegP_R5);
 4591   // match(thread_RegP);
 4592   op_cost(0);
 4593   format %{ %}
 4594   interface(REG_INTER);
 4595 %}
 4596 
 4597 // Pointer 64 bit Register R0 only
 4598 operand iRegP_R0()
 4599 %{
 4600   constraint(ALLOC_IN_RC(r0_reg));
 4601   match(RegP);
 4602   // match(iRegP);
 4603   match(iRegPNoSp);
 4604   op_cost(0);
 4605   format %{ %}
 4606   interface(REG_INTER);
 4607 %}
 4608 
 4609 // Pointer 64 bit Register R1 only
 4610 operand iRegP_R1()
 4611 %{
 4612   constraint(ALLOC_IN_RC(r1_reg));
 4613   match(RegP);
 4614   // match(iRegP);
 4615   match(iRegPNoSp);
 4616   op_cost(0);
 4617   format %{ %}
 4618   interface(REG_INTER);
 4619 %}
 4620 
 4621 // Pointer 64 bit Register R2 only
 4622 operand iRegP_R2()
 4623 %{
 4624   constraint(ALLOC_IN_RC(r2_reg));
 4625   match(RegP);
 4626   // match(iRegP);
 4627   match(iRegPNoSp);
 4628   op_cost(0);
 4629   format %{ %}
 4630   interface(REG_INTER);
 4631 %}
 4632 
 4633 // Pointer 64 bit Register R3 only
 4634 operand iRegP_R3()
 4635 %{
 4636   constraint(ALLOC_IN_RC(r3_reg));
 4637   match(RegP);
 4638   // match(iRegP);
 4639   match(iRegPNoSp);
 4640   op_cost(0);
 4641   format %{ %}
 4642   interface(REG_INTER);
 4643 %}
 4644 
 4645 // Pointer 64 bit Register R4 only
 4646 operand iRegP_R4()
 4647 %{
 4648   constraint(ALLOC_IN_RC(r4_reg));
 4649   match(RegP);
 4650   // match(iRegP);
 4651   match(iRegPNoSp);
 4652   op_cost(0);
 4653   format %{ %}
 4654   interface(REG_INTER);
 4655 %}
 4656 
 4657 // Pointer 64 bit Register R5 only
 4658 operand iRegP_R5()
 4659 %{
 4660   constraint(ALLOC_IN_RC(r5_reg));
 4661   match(RegP);
 4662   // match(iRegP);
 4663   match(iRegPNoSp);
 4664   op_cost(0);
 4665   format %{ %}
 4666   interface(REG_INTER);
 4667 %}
 4668 
 4669 // Pointer 64 bit Register R10 only
 4670 operand iRegP_R10()
 4671 %{
 4672   constraint(ALLOC_IN_RC(r10_reg));
 4673   match(RegP);
 4674   // match(iRegP);
 4675   match(iRegPNoSp);
 4676   op_cost(0);
 4677   format %{ %}
 4678   interface(REG_INTER);
 4679 %}
 4680 
 4681 // Long 64 bit Register R0 only
 4682 operand iRegL_R0()
 4683 %{
 4684   constraint(ALLOC_IN_RC(r0_reg));
 4685   match(RegL);
 4686   match(iRegLNoSp);
 4687   op_cost(0);
 4688   format %{ %}
 4689   interface(REG_INTER);
 4690 %}
 4691 
 4692 // Long 64 bit Register R2 only
 4693 operand iRegL_R2()
 4694 %{
 4695   constraint(ALLOC_IN_RC(r2_reg));
 4696   match(RegL);
 4697   match(iRegLNoSp);
 4698   op_cost(0);
 4699   format %{ %}
 4700   interface(REG_INTER);
 4701 %}
 4702 
 4703 // Long 64 bit Register R3 only
 4704 operand iRegL_R3()
 4705 %{
 4706   constraint(ALLOC_IN_RC(r3_reg));
 4707   match(RegL);
 4708   match(iRegLNoSp);
 4709   op_cost(0);
 4710   format %{ %}
 4711   interface(REG_INTER);
 4712 %}
 4713 
 4714 // Long 64 bit Register R11 only
 4715 operand iRegL_R11()
 4716 %{
 4717   constraint(ALLOC_IN_RC(r11_reg));
 4718   match(RegL);
 4719   match(iRegLNoSp);
 4720   op_cost(0);
 4721   format %{ %}
 4722   interface(REG_INTER);
 4723 %}
 4724 
 4725 // Pointer 64 bit Register FP only
 4726 operand iRegP_FP()
 4727 %{
 4728   constraint(ALLOC_IN_RC(fp_reg));
 4729   match(RegP);
 4730   // match(iRegP);
 4731   op_cost(0);
 4732   format %{ %}
 4733   interface(REG_INTER);
 4734 %}
 4735 
 4736 // Register R0 only
 4737 operand iRegI_R0()
 4738 %{
 4739   constraint(ALLOC_IN_RC(int_r0_reg));
 4740   match(RegI);
 4741   match(iRegINoSp);
 4742   op_cost(0);
 4743   format %{ %}
 4744   interface(REG_INTER);
 4745 %}
 4746 
 4747 // Register R2 only
 4748 operand iRegI_R2()
 4749 %{
 4750   constraint(ALLOC_IN_RC(int_r2_reg));
 4751   match(RegI);
 4752   match(iRegINoSp);
 4753   op_cost(0);
 4754   format %{ %}
 4755   interface(REG_INTER);
 4756 %}
 4757 
 4758 // Register R3 only
 4759 operand iRegI_R3()
 4760 %{
 4761   constraint(ALLOC_IN_RC(int_r3_reg));
 4762   match(RegI);
 4763   match(iRegINoSp);
 4764   op_cost(0);
 4765   format %{ %}
 4766   interface(REG_INTER);
 4767 %}
 4768 
 4769 
 4770 // Register R4 only
 4771 operand iRegI_R4()
 4772 %{
 4773   constraint(ALLOC_IN_RC(int_r4_reg));
 4774   match(RegI);
 4775   match(iRegINoSp);
 4776   op_cost(0);
 4777   format %{ %}
 4778   interface(REG_INTER);
 4779 %}
 4780 
 4781 
 4782 // Pointer Register Operands
 4783 // Narrow Pointer Register
 4784 operand iRegN()
 4785 %{
 4786   constraint(ALLOC_IN_RC(any_reg32));
 4787   match(RegN);
 4788   match(iRegNNoSp);
 4789   op_cost(0);
 4790   format %{ %}
 4791   interface(REG_INTER);
 4792 %}
 4793 
 4794 operand iRegN_R0()
 4795 %{
 4796   constraint(ALLOC_IN_RC(r0_reg));
 4797   match(iRegN);
 4798   op_cost(0);
 4799   format %{ %}
 4800   interface(REG_INTER);
 4801 %}
 4802 
 4803 operand iRegN_R2()
 4804 %{
 4805   constraint(ALLOC_IN_RC(r2_reg));
 4806   match(iRegN);
 4807   op_cost(0);
 4808   format %{ %}
 4809   interface(REG_INTER);
 4810 %}
 4811 
 4812 operand iRegN_R3()
 4813 %{
 4814   constraint(ALLOC_IN_RC(r3_reg));
 4815   match(iRegN);
 4816   op_cost(0);
 4817   format %{ %}
 4818   interface(REG_INTER);
 4819 %}
 4820 
 4821 // Integer 64 bit Register not Special
 4822 operand iRegNNoSp()
 4823 %{
 4824   constraint(ALLOC_IN_RC(no_special_reg32));
 4825   match(RegN);
 4826   op_cost(0);
 4827   format %{ %}
 4828   interface(REG_INTER);
 4829 %}
 4830 
 4831 // heap base register -- used for encoding immN0
 4832 
 4833 operand iRegIHeapbase()
 4834 %{
 4835   constraint(ALLOC_IN_RC(heapbase_reg));
 4836   match(RegI);
 4837   op_cost(0);
 4838   format %{ %}
 4839   interface(REG_INTER);
 4840 %}
 4841 
 4842 // Float Register
 4843 // Float register operands
 4844 operand vRegF()
 4845 %{
 4846   constraint(ALLOC_IN_RC(float_reg));
 4847   match(RegF);
 4848 
 4849   op_cost(0);
 4850   format %{ %}
 4851   interface(REG_INTER);
 4852 %}
 4853 
 4854 // Double Register
 4855 // Double register operands
 4856 operand vRegD()
 4857 %{
 4858   constraint(ALLOC_IN_RC(double_reg));
 4859   match(RegD);
 4860 
 4861   op_cost(0);
 4862   format %{ %}
 4863   interface(REG_INTER);
 4864 %}
 4865 
 4866 operand vecD()
 4867 %{
 4868   constraint(ALLOC_IN_RC(vectord_reg));
 4869   match(VecD);
 4870 
 4871   op_cost(0);
 4872   format %{ %}
 4873   interface(REG_INTER);
 4874 %}
 4875 
 4876 operand vecX()
 4877 %{
 4878   constraint(ALLOC_IN_RC(vectorx_reg));
 4879   match(VecX);
 4880 
 4881   op_cost(0);
 4882   format %{ %}
 4883   interface(REG_INTER);
 4884 %}
 4885 
 4886 operand vRegD_V0()
 4887 %{
 4888   constraint(ALLOC_IN_RC(v0_reg));
 4889   match(RegD);
 4890   op_cost(0);
 4891   format %{ %}
 4892   interface(REG_INTER);
 4893 %}
 4894 
 4895 operand vRegD_V1()
 4896 %{
 4897   constraint(ALLOC_IN_RC(v1_reg));
 4898   match(RegD);
 4899   op_cost(0);
 4900   format %{ %}
 4901   interface(REG_INTER);
 4902 %}
 4903 
 4904 operand vRegD_V2()
 4905 %{
 4906   constraint(ALLOC_IN_RC(v2_reg));
 4907   match(RegD);
 4908   op_cost(0);
 4909   format %{ %}
 4910   interface(REG_INTER);
 4911 %}
 4912 
 4913 operand vRegD_V3()
 4914 %{
 4915   constraint(ALLOC_IN_RC(v3_reg));
 4916   match(RegD);
 4917   op_cost(0);
 4918   format %{ %}
 4919   interface(REG_INTER);
 4920 %}
 4921 
 4922 operand vRegD_V4()
 4923 %{
 4924   constraint(ALLOC_IN_RC(v4_reg));
 4925   match(RegD);
 4926   op_cost(0);
 4927   format %{ %}
 4928   interface(REG_INTER);
 4929 %}
 4930 
 4931 operand vRegD_V5()
 4932 %{
 4933   constraint(ALLOC_IN_RC(v5_reg));
 4934   match(RegD);
 4935   op_cost(0);
 4936   format %{ %}
 4937   interface(REG_INTER);
 4938 %}
 4939 
 4940 operand vRegD_V6()
 4941 %{
 4942   constraint(ALLOC_IN_RC(v6_reg));
 4943   match(RegD);
 4944   op_cost(0);
 4945   format %{ %}
 4946   interface(REG_INTER);
 4947 %}
 4948 
 4949 operand vRegD_V7()
 4950 %{
 4951   constraint(ALLOC_IN_RC(v7_reg));
 4952   match(RegD);
 4953   op_cost(0);
 4954   format %{ %}
 4955   interface(REG_INTER);
 4956 %}
 4957 
 4958 operand vRegD_V8()
 4959 %{
 4960   constraint(ALLOC_IN_RC(v8_reg));
 4961   match(RegD);
 4962   op_cost(0);
 4963   format %{ %}
 4964   interface(REG_INTER);
 4965 %}
 4966 
 4967 operand vRegD_V9()
 4968 %{
 4969   constraint(ALLOC_IN_RC(v9_reg));
 4970   match(RegD);
 4971   op_cost(0);
 4972   format %{ %}
 4973   interface(REG_INTER);
 4974 %}
 4975 
 4976 operand vRegD_V10()
 4977 %{
 4978   constraint(ALLOC_IN_RC(v10_reg));
 4979   match(RegD);
 4980   op_cost(0);
 4981   format %{ %}
 4982   interface(REG_INTER);
 4983 %}
 4984 
 4985 operand vRegD_V11()
 4986 %{
 4987   constraint(ALLOC_IN_RC(v11_reg));
 4988   match(RegD);
 4989   op_cost(0);
 4990   format %{ %}
 4991   interface(REG_INTER);
 4992 %}
 4993 
 4994 operand vRegD_V12()
 4995 %{
 4996   constraint(ALLOC_IN_RC(v12_reg));
 4997   match(RegD);
 4998   op_cost(0);
 4999   format %{ %}
 5000   interface(REG_INTER);
 5001 %}
 5002 
 5003 operand vRegD_V13()
 5004 %{
 5005   constraint(ALLOC_IN_RC(v13_reg));
 5006   match(RegD);
 5007   op_cost(0);
 5008   format %{ %}
 5009   interface(REG_INTER);
 5010 %}
 5011 
 5012 operand vRegD_V14()
 5013 %{
 5014   constraint(ALLOC_IN_RC(v14_reg));
 5015   match(RegD);
 5016   op_cost(0);
 5017   format %{ %}
 5018   interface(REG_INTER);
 5019 %}
 5020 
 5021 operand vRegD_V15()
 5022 %{
 5023   constraint(ALLOC_IN_RC(v15_reg));
 5024   match(RegD);
 5025   op_cost(0);
 5026   format %{ %}
 5027   interface(REG_INTER);
 5028 %}
 5029 
 5030 operand vRegD_V16()
 5031 %{
 5032   constraint(ALLOC_IN_RC(v16_reg));
 5033   match(RegD);
 5034   op_cost(0);
 5035   format %{ %}
 5036   interface(REG_INTER);
 5037 %}
 5038 
 5039 operand vRegD_V17()
 5040 %{
 5041   constraint(ALLOC_IN_RC(v17_reg));
 5042   match(RegD);
 5043   op_cost(0);
 5044   format %{ %}
 5045   interface(REG_INTER);
 5046 %}
 5047 
 5048 operand vRegD_V18()
 5049 %{
 5050   constraint(ALLOC_IN_RC(v18_reg));
 5051   match(RegD);
 5052   op_cost(0);
 5053   format %{ %}
 5054   interface(REG_INTER);
 5055 %}
 5056 
 5057 operand vRegD_V19()
 5058 %{
 5059   constraint(ALLOC_IN_RC(v19_reg));
 5060   match(RegD);
 5061   op_cost(0);
 5062   format %{ %}
 5063   interface(REG_INTER);
 5064 %}
 5065 
 5066 operand vRegD_V20()
 5067 %{
 5068   constraint(ALLOC_IN_RC(v20_reg));
 5069   match(RegD);
 5070   op_cost(0);
 5071   format %{ %}
 5072   interface(REG_INTER);
 5073 %}
 5074 
 5075 operand vRegD_V21()
 5076 %{
 5077   constraint(ALLOC_IN_RC(v21_reg));
 5078   match(RegD);
 5079   op_cost(0);
 5080   format %{ %}
 5081   interface(REG_INTER);
 5082 %}
 5083 
 5084 operand vRegD_V22()
 5085 %{
 5086   constraint(ALLOC_IN_RC(v22_reg));
 5087   match(RegD);
 5088   op_cost(0);
 5089   format %{ %}
 5090   interface(REG_INTER);
 5091 %}
 5092 
 5093 operand vRegD_V23()
 5094 %{
 5095   constraint(ALLOC_IN_RC(v23_reg));
 5096   match(RegD);
 5097   op_cost(0);
 5098   format %{ %}
 5099   interface(REG_INTER);
 5100 %}
 5101 
 5102 operand vRegD_V24()
 5103 %{
 5104   constraint(ALLOC_IN_RC(v24_reg));
 5105   match(RegD);
 5106   op_cost(0);
 5107   format %{ %}
 5108   interface(REG_INTER);
 5109 %}
 5110 
 5111 operand vRegD_V25()
 5112 %{
 5113   constraint(ALLOC_IN_RC(v25_reg));
 5114   match(RegD);
 5115   op_cost(0);
 5116   format %{ %}
 5117   interface(REG_INTER);
 5118 %}
 5119 
 5120 operand vRegD_V26()
 5121 %{
 5122   constraint(ALLOC_IN_RC(v26_reg));
 5123   match(RegD);
 5124   op_cost(0);
 5125   format %{ %}
 5126   interface(REG_INTER);
 5127 %}
 5128 
 5129 operand vRegD_V27()
 5130 %{
 5131   constraint(ALLOC_IN_RC(v27_reg));
 5132   match(RegD);
 5133   op_cost(0);
 5134   format %{ %}
 5135   interface(REG_INTER);
 5136 %}
 5137 
 5138 operand vRegD_V28()
 5139 %{
 5140   constraint(ALLOC_IN_RC(v28_reg));
 5141   match(RegD);
 5142   op_cost(0);
 5143   format %{ %}
 5144   interface(REG_INTER);
 5145 %}
 5146 
 5147 operand vRegD_V29()
 5148 %{
 5149   constraint(ALLOC_IN_RC(v29_reg));
 5150   match(RegD);
 5151   op_cost(0);
 5152   format %{ %}
 5153   interface(REG_INTER);
 5154 %}
 5155 
 5156 operand vRegD_V30()
 5157 %{
 5158   constraint(ALLOC_IN_RC(v30_reg));
 5159   match(RegD);
 5160   op_cost(0);
 5161   format %{ %}
 5162   interface(REG_INTER);
 5163 %}
 5164 
 5165 operand vRegD_V31()
 5166 %{
 5167   constraint(ALLOC_IN_RC(v31_reg));
 5168   match(RegD);
 5169   op_cost(0);
 5170   format %{ %}
 5171   interface(REG_INTER);
 5172 %}
 5173 
 5174 // Flags register, used as output of signed compare instructions
 5175 
 5176 // note that on AArch64 we also use this register as the output for
 5177 // for floating point compare instructions (CmpF CmpD). this ensures
 5178 // that ordered inequality tests use GT, GE, LT or LE none of which
 5179 // pass through cases where the result is unordered i.e. one or both
 5180 // inputs to the compare is a NaN. this means that the ideal code can
 5181 // replace e.g. a GT with an LE and not end up capturing the NaN case
 5182 // (where the comparison should always fail). EQ and NE tests are
 5183 // always generated in ideal code so that unordered folds into the NE
 5184 // case, matching the behaviour of AArch64 NE.
 5185 //
 5186 // This differs from x86 where the outputs of FP compares use a
 5187 // special FP flags registers and where compares based on this
 5188 // register are distinguished into ordered inequalities (cmpOpUCF) and
 5189 // EQ/NEQ tests (cmpOpUCF2). x86 has to special case the latter tests
 5190 // to explicitly handle the unordered case in branches. x86 also has
 5191 // to include extra CMoveX rules to accept a cmpOpUCF input.
 5192 
 5193 operand rFlagsReg()
 5194 %{
 5195   constraint(ALLOC_IN_RC(int_flags));
 5196   match(RegFlags);
 5197 
 5198   op_cost(0);
 5199   format %{ &quot;RFLAGS&quot; %}
 5200   interface(REG_INTER);
 5201 %}
 5202 
 5203 // Flags register, used as output of unsigned compare instructions
 5204 operand rFlagsRegU()
 5205 %{
 5206   constraint(ALLOC_IN_RC(int_flags));
 5207   match(RegFlags);
 5208 
 5209   op_cost(0);
 5210   format %{ &quot;RFLAGSU&quot; %}
 5211   interface(REG_INTER);
 5212 %}
 5213 
 5214 // Special Registers
 5215 
 5216 // Method Register
 5217 operand inline_cache_RegP(iRegP reg)
 5218 %{
 5219   constraint(ALLOC_IN_RC(method_reg)); // inline_cache_reg
 5220   match(reg);
 5221   match(iRegPNoSp);
 5222   op_cost(0);
 5223   format %{ %}
 5224   interface(REG_INTER);
 5225 %}
 5226 
 5227 operand interpreter_method_oop_RegP(iRegP reg)
 5228 %{
 5229   constraint(ALLOC_IN_RC(method_reg)); // interpreter_method_oop_reg
 5230   match(reg);
 5231   match(iRegPNoSp);
 5232   op_cost(0);
 5233   format %{ %}
 5234   interface(REG_INTER);
 5235 %}
 5236 
 5237 // Thread Register
 5238 operand thread_RegP(iRegP reg)
 5239 %{
 5240   constraint(ALLOC_IN_RC(thread_reg)); // link_reg
 5241   match(reg);
 5242   op_cost(0);
 5243   format %{ %}
 5244   interface(REG_INTER);
 5245 %}
 5246 
 5247 operand lr_RegP(iRegP reg)
 5248 %{
 5249   constraint(ALLOC_IN_RC(lr_reg)); // link_reg
 5250   match(reg);
 5251   op_cost(0);
 5252   format %{ %}
 5253   interface(REG_INTER);
 5254 %}
 5255 
 5256 //----------Memory Operands----------------------------------------------------
 5257 
 5258 operand indirect(iRegP reg)
 5259 %{
 5260   constraint(ALLOC_IN_RC(ptr_reg));
 5261   match(reg);
 5262   op_cost(0);
 5263   format %{ &quot;[$reg]&quot; %}
 5264   interface(MEMORY_INTER) %{
 5265     base($reg);
 5266     index(0xffffffff);
 5267     scale(0x0);
 5268     disp(0x0);
 5269   %}
 5270 %}
 5271 
 5272 operand indIndexScaledI2L(iRegP reg, iRegI ireg, immIScale scale)
 5273 %{
 5274   constraint(ALLOC_IN_RC(ptr_reg));
 5275   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5276   match(AddP reg (LShiftL (ConvI2L ireg) scale));
 5277   op_cost(0);
 5278   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L&quot; %}
 5279   interface(MEMORY_INTER) %{
 5280     base($reg);
 5281     index($ireg);
 5282     scale($scale);
 5283     disp(0x0);
 5284   %}
 5285 %}
 5286 
 5287 operand indIndexScaled(iRegP reg, iRegL lreg, immIScale scale)
 5288 %{
 5289   constraint(ALLOC_IN_RC(ptr_reg));
 5290   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5291   match(AddP reg (LShiftL lreg scale));
 5292   op_cost(0);
 5293   format %{ &quot;$reg, $lreg lsl($scale)&quot; %}
 5294   interface(MEMORY_INTER) %{
 5295     base($reg);
 5296     index($lreg);
 5297     scale($scale);
 5298     disp(0x0);
 5299   %}
 5300 %}
 5301 
 5302 operand indIndexI2L(iRegP reg, iRegI ireg)
 5303 %{
 5304   constraint(ALLOC_IN_RC(ptr_reg));
 5305   match(AddP reg (ConvI2L ireg));
 5306   op_cost(0);
 5307   format %{ &quot;$reg, $ireg, 0, I2L&quot; %}
 5308   interface(MEMORY_INTER) %{
 5309     base($reg);
 5310     index($ireg);
 5311     scale(0x0);
 5312     disp(0x0);
 5313   %}
 5314 %}
 5315 
 5316 operand indIndex(iRegP reg, iRegL lreg)
 5317 %{
 5318   constraint(ALLOC_IN_RC(ptr_reg));
 5319   match(AddP reg lreg);
 5320   op_cost(0);
 5321   format %{ &quot;$reg, $lreg&quot; %}
 5322   interface(MEMORY_INTER) %{
 5323     base($reg);
 5324     index($lreg);
 5325     scale(0x0);
 5326     disp(0x0);
 5327   %}
 5328 %}
 5329 
 5330 operand indOffI(iRegP reg, immIOffset off)
 5331 %{
 5332   constraint(ALLOC_IN_RC(ptr_reg));
 5333   match(AddP reg off);
 5334   op_cost(0);
 5335   format %{ &quot;[$reg, $off]&quot; %}
 5336   interface(MEMORY_INTER) %{
 5337     base($reg);
 5338     index(0xffffffff);
 5339     scale(0x0);
 5340     disp($off);
 5341   %}
 5342 %}
 5343 
 5344 operand indOffI1(iRegP reg, immIOffset1 off)
 5345 %{
 5346   constraint(ALLOC_IN_RC(ptr_reg));
 5347   match(AddP reg off);
 5348   op_cost(0);
 5349   format %{ &quot;[$reg, $off]&quot; %}
 5350   interface(MEMORY_INTER) %{
 5351     base($reg);
 5352     index(0xffffffff);
 5353     scale(0x0);
 5354     disp($off);
 5355   %}
 5356 %}
 5357 
 5358 operand indOffI2(iRegP reg, immIOffset2 off)
 5359 %{
 5360   constraint(ALLOC_IN_RC(ptr_reg));
 5361   match(AddP reg off);
 5362   op_cost(0);
 5363   format %{ &quot;[$reg, $off]&quot; %}
 5364   interface(MEMORY_INTER) %{
 5365     base($reg);
 5366     index(0xffffffff);
 5367     scale(0x0);
 5368     disp($off);
 5369   %}
 5370 %}
 5371 
 5372 operand indOffI4(iRegP reg, immIOffset4 off)
 5373 %{
 5374   constraint(ALLOC_IN_RC(ptr_reg));
 5375   match(AddP reg off);
 5376   op_cost(0);
 5377   format %{ &quot;[$reg, $off]&quot; %}
 5378   interface(MEMORY_INTER) %{
 5379     base($reg);
 5380     index(0xffffffff);
 5381     scale(0x0);
 5382     disp($off);
 5383   %}
 5384 %}
 5385 
 5386 operand indOffI8(iRegP reg, immIOffset8 off)
 5387 %{
 5388   constraint(ALLOC_IN_RC(ptr_reg));
 5389   match(AddP reg off);
 5390   op_cost(0);
 5391   format %{ &quot;[$reg, $off]&quot; %}
 5392   interface(MEMORY_INTER) %{
 5393     base($reg);
 5394     index(0xffffffff);
 5395     scale(0x0);
 5396     disp($off);
 5397   %}
 5398 %}
 5399 
 5400 operand indOffI16(iRegP reg, immIOffset16 off)
 5401 %{
 5402   constraint(ALLOC_IN_RC(ptr_reg));
 5403   match(AddP reg off);
 5404   op_cost(0);
 5405   format %{ &quot;[$reg, $off]&quot; %}
 5406   interface(MEMORY_INTER) %{
 5407     base($reg);
 5408     index(0xffffffff);
 5409     scale(0x0);
 5410     disp($off);
 5411   %}
 5412 %}
 5413 
 5414 operand indOffL(iRegP reg, immLoffset off)
 5415 %{
 5416   constraint(ALLOC_IN_RC(ptr_reg));
 5417   match(AddP reg off);
 5418   op_cost(0);
 5419   format %{ &quot;[$reg, $off]&quot; %}
 5420   interface(MEMORY_INTER) %{
 5421     base($reg);
 5422     index(0xffffffff);
 5423     scale(0x0);
 5424     disp($off);
 5425   %}
 5426 %}
 5427 
 5428 operand indOffL1(iRegP reg, immLoffset1 off)
 5429 %{
 5430   constraint(ALLOC_IN_RC(ptr_reg));
 5431   match(AddP reg off);
 5432   op_cost(0);
 5433   format %{ &quot;[$reg, $off]&quot; %}
 5434   interface(MEMORY_INTER) %{
 5435     base($reg);
 5436     index(0xffffffff);
 5437     scale(0x0);
 5438     disp($off);
 5439   %}
 5440 %}
 5441 
 5442 operand indOffL2(iRegP reg, immLoffset2 off)
 5443 %{
 5444   constraint(ALLOC_IN_RC(ptr_reg));
 5445   match(AddP reg off);
 5446   op_cost(0);
 5447   format %{ &quot;[$reg, $off]&quot; %}
 5448   interface(MEMORY_INTER) %{
 5449     base($reg);
 5450     index(0xffffffff);
 5451     scale(0x0);
 5452     disp($off);
 5453   %}
 5454 %}
 5455 
 5456 operand indOffL4(iRegP reg, immLoffset4 off)
 5457 %{
 5458   constraint(ALLOC_IN_RC(ptr_reg));
 5459   match(AddP reg off);
 5460   op_cost(0);
 5461   format %{ &quot;[$reg, $off]&quot; %}
 5462   interface(MEMORY_INTER) %{
 5463     base($reg);
 5464     index(0xffffffff);
 5465     scale(0x0);
 5466     disp($off);
 5467   %}
 5468 %}
 5469 
 5470 operand indOffL8(iRegP reg, immLoffset8 off)
 5471 %{
 5472   constraint(ALLOC_IN_RC(ptr_reg));
 5473   match(AddP reg off);
 5474   op_cost(0);
 5475   format %{ &quot;[$reg, $off]&quot; %}
 5476   interface(MEMORY_INTER) %{
 5477     base($reg);
 5478     index(0xffffffff);
 5479     scale(0x0);
 5480     disp($off);
 5481   %}
 5482 %}
 5483 
 5484 operand indOffL16(iRegP reg, immLoffset16 off)
 5485 %{
 5486   constraint(ALLOC_IN_RC(ptr_reg));
 5487   match(AddP reg off);
 5488   op_cost(0);
 5489   format %{ &quot;[$reg, $off]&quot; %}
 5490   interface(MEMORY_INTER) %{
 5491     base($reg);
 5492     index(0xffffffff);
 5493     scale(0x0);
 5494     disp($off);
 5495   %}
 5496 %}
 5497 
 5498 operand indirectN(iRegN reg)
 5499 %{
 5500   predicate(CompressedOops::shift() == 0);
 5501   constraint(ALLOC_IN_RC(ptr_reg));
 5502   match(DecodeN reg);
 5503   op_cost(0);
 5504   format %{ &quot;[$reg]\t# narrow&quot; %}
 5505   interface(MEMORY_INTER) %{
 5506     base($reg);
 5507     index(0xffffffff);
 5508     scale(0x0);
 5509     disp(0x0);
 5510   %}
 5511 %}
 5512 
 5513 operand indIndexScaledI2LN(iRegN reg, iRegI ireg, immIScale scale)
 5514 %{
 5515   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5516   constraint(ALLOC_IN_RC(ptr_reg));
 5517   match(AddP (DecodeN reg) (LShiftL (ConvI2L ireg) scale));
 5518   op_cost(0);
 5519   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L\t# narrow&quot; %}
 5520   interface(MEMORY_INTER) %{
 5521     base($reg);
 5522     index($ireg);
 5523     scale($scale);
 5524     disp(0x0);
 5525   %}
 5526 %}
 5527 
 5528 operand indIndexScaledN(iRegN reg, iRegL lreg, immIScale scale)
 5529 %{
 5530   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5531   constraint(ALLOC_IN_RC(ptr_reg));
 5532   match(AddP (DecodeN reg) (LShiftL lreg scale));
 5533   op_cost(0);
 5534   format %{ &quot;$reg, $lreg lsl($scale)\t# narrow&quot; %}
 5535   interface(MEMORY_INTER) %{
 5536     base($reg);
 5537     index($lreg);
 5538     scale($scale);
 5539     disp(0x0);
 5540   %}
 5541 %}
 5542 
 5543 operand indIndexI2LN(iRegN reg, iRegI ireg)
 5544 %{
 5545   predicate(CompressedOops::shift() == 0);
 5546   constraint(ALLOC_IN_RC(ptr_reg));
 5547   match(AddP (DecodeN reg) (ConvI2L ireg));
 5548   op_cost(0);
 5549   format %{ &quot;$reg, $ireg, 0, I2L\t# narrow&quot; %}
 5550   interface(MEMORY_INTER) %{
 5551     base($reg);
 5552     index($ireg);
 5553     scale(0x0);
 5554     disp(0x0);
 5555   %}
 5556 %}
 5557 
 5558 operand indIndexN(iRegN reg, iRegL lreg)
 5559 %{
 5560   predicate(CompressedOops::shift() == 0);
 5561   constraint(ALLOC_IN_RC(ptr_reg));
 5562   match(AddP (DecodeN reg) lreg);
 5563   op_cost(0);
 5564   format %{ &quot;$reg, $lreg\t# narrow&quot; %}
 5565   interface(MEMORY_INTER) %{
 5566     base($reg);
 5567     index($lreg);
 5568     scale(0x0);
 5569     disp(0x0);
 5570   %}
 5571 %}
 5572 
 5573 operand indOffIN(iRegN reg, immIOffset off)
 5574 %{
 5575   predicate(CompressedOops::shift() == 0);
 5576   constraint(ALLOC_IN_RC(ptr_reg));
 5577   match(AddP (DecodeN reg) off);
 5578   op_cost(0);
 5579   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5580   interface(MEMORY_INTER) %{
 5581     base($reg);
 5582     index(0xffffffff);
 5583     scale(0x0);
 5584     disp($off);
 5585   %}
 5586 %}
 5587 
 5588 operand indOffLN(iRegN reg, immLoffset off)
 5589 %{
 5590   predicate(CompressedOops::shift() == 0);
 5591   constraint(ALLOC_IN_RC(ptr_reg));
 5592   match(AddP (DecodeN reg) off);
 5593   op_cost(0);
 5594   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5595   interface(MEMORY_INTER) %{
 5596     base($reg);
 5597     index(0xffffffff);
 5598     scale(0x0);
 5599     disp($off);
 5600   %}
 5601 %}
 5602 
 5603 
 5604 
 5605 // AArch64 opto stubs need to write to the pc slot in the thread anchor
 5606 operand thread_anchor_pc(thread_RegP reg, immL_pc_off off)
 5607 %{
 5608   constraint(ALLOC_IN_RC(ptr_reg));
 5609   match(AddP reg off);
 5610   op_cost(0);
 5611   format %{ &quot;[$reg, $off]&quot; %}
 5612   interface(MEMORY_INTER) %{
 5613     base($reg);
 5614     index(0xffffffff);
 5615     scale(0x0);
 5616     disp($off);
 5617   %}
 5618 %}
 5619 
 5620 //----------Special Memory Operands--------------------------------------------
 5621 // Stack Slot Operand - This operand is used for loading and storing temporary
 5622 //                      values on the stack where a match requires a value to
 5623 //                      flow through memory.
 5624 operand stackSlotP(sRegP reg)
 5625 %{
 5626   constraint(ALLOC_IN_RC(stack_slots));
 5627   op_cost(100);
 5628   // No match rule because this operand is only generated in matching
 5629   // match(RegP);
 5630   format %{ &quot;[$reg]&quot; %}
 5631   interface(MEMORY_INTER) %{
 5632     base(0x1e);  // RSP
 5633     index(0x0);  // No Index
 5634     scale(0x0);  // No Scale
 5635     disp($reg);  // Stack Offset
 5636   %}
 5637 %}
 5638 
 5639 operand stackSlotI(sRegI reg)
 5640 %{
 5641   constraint(ALLOC_IN_RC(stack_slots));
 5642   // No match rule because this operand is only generated in matching
 5643   // match(RegI);
 5644   format %{ &quot;[$reg]&quot; %}
 5645   interface(MEMORY_INTER) %{
 5646     base(0x1e);  // RSP
 5647     index(0x0);  // No Index
 5648     scale(0x0);  // No Scale
 5649     disp($reg);  // Stack Offset
 5650   %}
 5651 %}
 5652 
 5653 operand stackSlotF(sRegF reg)
 5654 %{
 5655   constraint(ALLOC_IN_RC(stack_slots));
 5656   // No match rule because this operand is only generated in matching
 5657   // match(RegF);
 5658   format %{ &quot;[$reg]&quot; %}
 5659   interface(MEMORY_INTER) %{
 5660     base(0x1e);  // RSP
 5661     index(0x0);  // No Index
 5662     scale(0x0);  // No Scale
 5663     disp($reg);  // Stack Offset
 5664   %}
 5665 %}
 5666 
 5667 operand stackSlotD(sRegD reg)
 5668 %{
 5669   constraint(ALLOC_IN_RC(stack_slots));
 5670   // No match rule because this operand is only generated in matching
 5671   // match(RegD);
 5672   format %{ &quot;[$reg]&quot; %}
 5673   interface(MEMORY_INTER) %{
 5674     base(0x1e);  // RSP
 5675     index(0x0);  // No Index
 5676     scale(0x0);  // No Scale
 5677     disp($reg);  // Stack Offset
 5678   %}
 5679 %}
 5680 
 5681 operand stackSlotL(sRegL reg)
 5682 %{
 5683   constraint(ALLOC_IN_RC(stack_slots));
 5684   // No match rule because this operand is only generated in matching
 5685   // match(RegL);
 5686   format %{ &quot;[$reg]&quot; %}
 5687   interface(MEMORY_INTER) %{
 5688     base(0x1e);  // RSP
 5689     index(0x0);  // No Index
 5690     scale(0x0);  // No Scale
 5691     disp($reg);  // Stack Offset
 5692   %}
 5693 %}
 5694 
 5695 // Operands for expressing Control Flow
 5696 // NOTE: Label is a predefined operand which should not be redefined in
 5697 //       the AD file. It is generically handled within the ADLC.
 5698 
 5699 //----------Conditional Branch Operands----------------------------------------
 5700 // Comparison Op  - This is the operation of the comparison, and is limited to
 5701 //                  the following set of codes:
 5702 //                  L (&lt;), LE (&lt;=), G (&gt;), GE (&gt;=), E (==), NE (!=)
 5703 //
 5704 // Other attributes of the comparison, such as unsignedness, are specified
 5705 // by the comparison instruction that sets a condition code flags register.
 5706 // That result is represented by a flags operand whose subtype is appropriate
 5707 // to the unsignedness (etc.) of the comparison.
 5708 //
 5709 // Later, the instruction which matches both the Comparison Op (a Bool) and
 5710 // the flags (produced by the Cmp) specifies the coding of the comparison op
 5711 // by matching a specific subtype of Bool operand below, such as cmpOpU.
 5712 
 5713 // used for signed integral comparisons and fp comparisons
 5714 
 5715 operand cmpOp()
 5716 %{
 5717   match(Bool);
 5718 
 5719   format %{ &quot;&quot; %}
 5720   interface(COND_INTER) %{
 5721     equal(0x0, &quot;eq&quot;);
 5722     not_equal(0x1, &quot;ne&quot;);
 5723     less(0xb, &quot;lt&quot;);
 5724     greater_equal(0xa, &quot;ge&quot;);
 5725     less_equal(0xd, &quot;le&quot;);
 5726     greater(0xc, &quot;gt&quot;);
 5727     overflow(0x6, &quot;vs&quot;);
 5728     no_overflow(0x7, &quot;vc&quot;);
 5729   %}
 5730 %}
 5731 
 5732 // used for unsigned integral comparisons
 5733 
 5734 operand cmpOpU()
 5735 %{
 5736   match(Bool);
 5737 
 5738   format %{ &quot;&quot; %}
 5739   interface(COND_INTER) %{
 5740     equal(0x0, &quot;eq&quot;);
 5741     not_equal(0x1, &quot;ne&quot;);
 5742     less(0x3, &quot;lo&quot;);
 5743     greater_equal(0x2, &quot;hs&quot;);
 5744     less_equal(0x9, &quot;ls&quot;);
 5745     greater(0x8, &quot;hi&quot;);
 5746     overflow(0x6, &quot;vs&quot;);
 5747     no_overflow(0x7, &quot;vc&quot;);
 5748   %}
 5749 %}
 5750 
 5751 // used for certain integral comparisons which can be
 5752 // converted to cbxx or tbxx instructions
 5753 
 5754 operand cmpOpEqNe()
 5755 %{
 5756   match(Bool);
 5757   op_cost(0);
 5758   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5759             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq);
 5760 
 5761   format %{ &quot;&quot; %}
 5762   interface(COND_INTER) %{
 5763     equal(0x0, &quot;eq&quot;);
 5764     not_equal(0x1, &quot;ne&quot;);
 5765     less(0xb, &quot;lt&quot;);
 5766     greater_equal(0xa, &quot;ge&quot;);
 5767     less_equal(0xd, &quot;le&quot;);
 5768     greater(0xc, &quot;gt&quot;);
 5769     overflow(0x6, &quot;vs&quot;);
 5770     no_overflow(0x7, &quot;vc&quot;);
 5771   %}
 5772 %}
 5773 
 5774 // used for certain integral comparisons which can be
 5775 // converted to cbxx or tbxx instructions
 5776 
 5777 operand cmpOpLtGe()
 5778 %{
 5779   match(Bool);
 5780   op_cost(0);
 5781 
 5782   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5783             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5784 
 5785   format %{ &quot;&quot; %}
 5786   interface(COND_INTER) %{
 5787     equal(0x0, &quot;eq&quot;);
 5788     not_equal(0x1, &quot;ne&quot;);
 5789     less(0xb, &quot;lt&quot;);
 5790     greater_equal(0xa, &quot;ge&quot;);
 5791     less_equal(0xd, &quot;le&quot;);
 5792     greater(0xc, &quot;gt&quot;);
 5793     overflow(0x6, &quot;vs&quot;);
 5794     no_overflow(0x7, &quot;vc&quot;);
 5795   %}
 5796 %}
 5797 
 5798 // used for certain unsigned integral comparisons which can be
 5799 // converted to cbxx or tbxx instructions
 5800 
 5801 operand cmpOpUEqNeLtGe()
 5802 %{
 5803   match(Bool);
 5804   op_cost(0);
 5805 
 5806   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq
 5807             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5808             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5809             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5810 
 5811   format %{ &quot;&quot; %}
 5812   interface(COND_INTER) %{
 5813     equal(0x0, &quot;eq&quot;);
 5814     not_equal(0x1, &quot;ne&quot;);
 5815     less(0xb, &quot;lt&quot;);
 5816     greater_equal(0xa, &quot;ge&quot;);
 5817     less_equal(0xd, &quot;le&quot;);
 5818     greater(0xc, &quot;gt&quot;);
 5819     overflow(0x6, &quot;vs&quot;);
 5820     no_overflow(0x7, &quot;vc&quot;);
 5821   %}
 5822 %}
 5823 
 5824 // Special operand allowing long args to int ops to be truncated for free
 5825 
 5826 operand iRegL2I(iRegL reg) %{
 5827 
 5828   op_cost(0);
 5829 
 5830   match(ConvL2I reg);
 5831 
 5832   format %{ &quot;l2i($reg)&quot; %}
 5833 
 5834   interface(REG_INTER)
 5835 %}
 5836 
 5837 opclass vmem4(indirect, indIndex, indOffI4, indOffL4);
 5838 opclass vmem8(indirect, indIndex, indOffI8, indOffL8);
 5839 opclass vmem16(indirect, indIndex, indOffI16, indOffL16);
 5840 
 5841 //----------OPERAND CLASSES----------------------------------------------------
 5842 // Operand Classes are groups of operands that are used as to simplify
 5843 // instruction definitions by not requiring the AD writer to specify
 5844 // separate instructions for every form of operand when the
 5845 // instruction accepts multiple operand types with the same basic
 5846 // encoding and format. The classic case of this is memory operands.
 5847 
 5848 // memory is used to define read/write location for load/store
 5849 // instruction defs. we can turn a memory op into an Address
 5850 
 5851 opclass memory1(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI1, indOffL1,
 5852                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5853 
 5854 opclass memory2(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI2, indOffL2,
 5855                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5856 
 5857 opclass memory4(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI4, indOffL4,
 5858                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5859 
 5860 opclass memory8(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI8, indOffL8,
 5861                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5862 
 5863 // All of the memory operands. For the pipeline description.
 5864 opclass memory(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex,
 5865                indOffI1, indOffL1, indOffI2, indOffL2, indOffI4, indOffL4, indOffI8, indOffL8,
 5866                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5867 
 5868 
 5869 // iRegIorL2I is used for src inputs in rules for 32 bit int (I)
 5870 // operations. it allows the src to be either an iRegI or a (ConvL2I
 5871 // iRegL). in the latter case the l2i normally planted for a ConvL2I
 5872 // can be elided because the 32-bit instruction will just employ the
 5873 // lower 32 bits anyway.
 5874 //
 5875 // n.b. this does not elide all L2I conversions. if the truncated
 5876 // value is consumed by more than one operation then the ConvL2I
 5877 // cannot be bundled into the consuming nodes so an l2i gets planted
 5878 // (actually a movw $dst $src) and the downstream instructions consume
 5879 // the result of the l2i as an iRegI input. That&#39;s a shame since the
 5880 // movw is actually redundant but its not too costly.
 5881 
 5882 opclass iRegIorL2I(iRegI, iRegL2I);
 5883 
 5884 //----------PIPELINE-----------------------------------------------------------
 5885 // Rules which define the behavior of the target architectures pipeline.
 5886 
 5887 // For specific pipelines, eg A53, define the stages of that pipeline
 5888 //pipe_desc(ISS, EX1, EX2, WR);
 5889 #define ISS S0
 5890 #define EX1 S1
 5891 #define EX2 S2
 5892 #define WR  S3
 5893 
 5894 // Integer ALU reg operation
 5895 pipeline %{
 5896 
 5897 attributes %{
 5898   // ARM instructions are of fixed length
 5899   fixed_size_instructions;        // Fixed size instructions TODO does
 5900   max_instructions_per_bundle = 2;   // A53 = 2, A57 = 4
 5901   // ARM instructions come in 32-bit word units
 5902   instruction_unit_size = 4;         // An instruction is 4 bytes long
 5903   instruction_fetch_unit_size = 64;  // The processor fetches one line
 5904   instruction_fetch_units = 1;       // of 64 bytes
 5905 
 5906   // List of nop instructions
 5907   nops( MachNop );
 5908 %}
 5909 
 5910 // We don&#39;t use an actual pipeline model so don&#39;t care about resources
 5911 // or description. we do use pipeline classes to introduce fixed
 5912 // latencies
 5913 
 5914 //----------RESOURCES----------------------------------------------------------
 5915 // Resources are the functional units available to the machine
 5916 
 5917 resources( INS0, INS1, INS01 = INS0 | INS1,
 5918            ALU0, ALU1, ALU = ALU0 | ALU1,
 5919            MAC,
 5920            DIV,
 5921            BRANCH,
 5922            LDST,
 5923            NEON_FP);
 5924 
 5925 //----------PIPELINE DESCRIPTION-----------------------------------------------
 5926 // Pipeline Description specifies the stages in the machine&#39;s pipeline
 5927 
 5928 // Define the pipeline as a generic 6 stage pipeline
 5929 pipe_desc(S0, S1, S2, S3, S4, S5);
 5930 
 5931 //----------PIPELINE CLASSES---------------------------------------------------
 5932 // Pipeline Classes describe the stages in which input and output are
 5933 // referenced by the hardware pipeline.
 5934 
 5935 pipe_class fp_dop_reg_reg_s(vRegF dst, vRegF src1, vRegF src2)
 5936 %{
 5937   single_instruction;
 5938   src1   : S1(read);
 5939   src2   : S2(read);
 5940   dst    : S5(write);
 5941   INS01  : ISS;
 5942   NEON_FP : S5;
 5943 %}
 5944 
 5945 pipe_class fp_dop_reg_reg_d(vRegD dst, vRegD src1, vRegD src2)
 5946 %{
 5947   single_instruction;
 5948   src1   : S1(read);
 5949   src2   : S2(read);
 5950   dst    : S5(write);
 5951   INS01  : ISS;
 5952   NEON_FP : S5;
 5953 %}
 5954 
 5955 pipe_class fp_uop_s(vRegF dst, vRegF src)
 5956 %{
 5957   single_instruction;
 5958   src    : S1(read);
 5959   dst    : S5(write);
 5960   INS01  : ISS;
 5961   NEON_FP : S5;
 5962 %}
 5963 
 5964 pipe_class fp_uop_d(vRegD dst, vRegD src)
 5965 %{
 5966   single_instruction;
 5967   src    : S1(read);
 5968   dst    : S5(write);
 5969   INS01  : ISS;
 5970   NEON_FP : S5;
 5971 %}
 5972 
 5973 pipe_class fp_d2f(vRegF dst, vRegD src)
 5974 %{
 5975   single_instruction;
 5976   src    : S1(read);
 5977   dst    : S5(write);
 5978   INS01  : ISS;
 5979   NEON_FP : S5;
 5980 %}
 5981 
 5982 pipe_class fp_f2d(vRegD dst, vRegF src)
 5983 %{
 5984   single_instruction;
 5985   src    : S1(read);
 5986   dst    : S5(write);
 5987   INS01  : ISS;
 5988   NEON_FP : S5;
 5989 %}
 5990 
 5991 pipe_class fp_f2i(iRegINoSp dst, vRegF src)
 5992 %{
 5993   single_instruction;
 5994   src    : S1(read);
 5995   dst    : S5(write);
 5996   INS01  : ISS;
 5997   NEON_FP : S5;
 5998 %}
 5999 
 6000 pipe_class fp_f2l(iRegLNoSp dst, vRegF src)
 6001 %{
 6002   single_instruction;
 6003   src    : S1(read);
 6004   dst    : S5(write);
 6005   INS01  : ISS;
 6006   NEON_FP : S5;
 6007 %}
 6008 
 6009 pipe_class fp_i2f(vRegF dst, iRegIorL2I src)
 6010 %{
 6011   single_instruction;
 6012   src    : S1(read);
 6013   dst    : S5(write);
 6014   INS01  : ISS;
 6015   NEON_FP : S5;
 6016 %}
 6017 
 6018 pipe_class fp_l2f(vRegF dst, iRegL src)
 6019 %{
 6020   single_instruction;
 6021   src    : S1(read);
 6022   dst    : S5(write);
 6023   INS01  : ISS;
 6024   NEON_FP : S5;
 6025 %}
 6026 
 6027 pipe_class fp_d2i(iRegINoSp dst, vRegD src)
 6028 %{
 6029   single_instruction;
 6030   src    : S1(read);
 6031   dst    : S5(write);
 6032   INS01  : ISS;
 6033   NEON_FP : S5;
 6034 %}
 6035 
 6036 pipe_class fp_d2l(iRegLNoSp dst, vRegD src)
 6037 %{
 6038   single_instruction;
 6039   src    : S1(read);
 6040   dst    : S5(write);
 6041   INS01  : ISS;
 6042   NEON_FP : S5;
 6043 %}
 6044 
 6045 pipe_class fp_i2d(vRegD dst, iRegIorL2I src)
 6046 %{
 6047   single_instruction;
 6048   src    : S1(read);
 6049   dst    : S5(write);
 6050   INS01  : ISS;
 6051   NEON_FP : S5;
 6052 %}
 6053 
 6054 pipe_class fp_l2d(vRegD dst, iRegIorL2I src)
 6055 %{
 6056   single_instruction;
 6057   src    : S1(read);
 6058   dst    : S5(write);
 6059   INS01  : ISS;
 6060   NEON_FP : S5;
 6061 %}
 6062 
 6063 pipe_class fp_div_s(vRegF dst, vRegF src1, vRegF src2)
 6064 %{
 6065   single_instruction;
 6066   src1   : S1(read);
 6067   src2   : S2(read);
 6068   dst    : S5(write);
 6069   INS0   : ISS;
 6070   NEON_FP : S5;
 6071 %}
 6072 
 6073 pipe_class fp_div_d(vRegD dst, vRegD src1, vRegD src2)
 6074 %{
 6075   single_instruction;
 6076   src1   : S1(read);
 6077   src2   : S2(read);
 6078   dst    : S5(write);
 6079   INS0   : ISS;
 6080   NEON_FP : S5;
 6081 %}
 6082 
 6083 pipe_class fp_cond_reg_reg_s(vRegF dst, vRegF src1, vRegF src2, rFlagsReg cr)
 6084 %{
 6085   single_instruction;
 6086   cr     : S1(read);
 6087   src1   : S1(read);
 6088   src2   : S1(read);
 6089   dst    : S3(write);
 6090   INS01  : ISS;
 6091   NEON_FP : S3;
 6092 %}
 6093 
 6094 pipe_class fp_cond_reg_reg_d(vRegD dst, vRegD src1, vRegD src2, rFlagsReg cr)
 6095 %{
 6096   single_instruction;
 6097   cr     : S1(read);
 6098   src1   : S1(read);
 6099   src2   : S1(read);
 6100   dst    : S3(write);
 6101   INS01  : ISS;
 6102   NEON_FP : S3;
 6103 %}
 6104 
 6105 pipe_class fp_imm_s(vRegF dst)
 6106 %{
 6107   single_instruction;
 6108   dst    : S3(write);
 6109   INS01  : ISS;
 6110   NEON_FP : S3;
 6111 %}
 6112 
 6113 pipe_class fp_imm_d(vRegD dst)
 6114 %{
 6115   single_instruction;
 6116   dst    : S3(write);
 6117   INS01  : ISS;
 6118   NEON_FP : S3;
 6119 %}
 6120 
 6121 pipe_class fp_load_constant_s(vRegF dst)
 6122 %{
 6123   single_instruction;
 6124   dst    : S4(write);
 6125   INS01  : ISS;
 6126   NEON_FP : S4;
 6127 %}
 6128 
 6129 pipe_class fp_load_constant_d(vRegD dst)
 6130 %{
 6131   single_instruction;
 6132   dst    : S4(write);
 6133   INS01  : ISS;
 6134   NEON_FP : S4;
 6135 %}
 6136 
 6137 pipe_class vmul64(vecD dst, vecD src1, vecD src2)
 6138 %{
 6139   single_instruction;
 6140   dst    : S5(write);
 6141   src1   : S1(read);
 6142   src2   : S1(read);
 6143   INS01  : ISS;
 6144   NEON_FP : S5;
 6145 %}
 6146 
 6147 pipe_class vmul128(vecX dst, vecX src1, vecX src2)
 6148 %{
 6149   single_instruction;
 6150   dst    : S5(write);
 6151   src1   : S1(read);
 6152   src2   : S1(read);
 6153   INS0   : ISS;
 6154   NEON_FP : S5;
 6155 %}
 6156 
 6157 pipe_class vmla64(vecD dst, vecD src1, vecD src2)
 6158 %{
 6159   single_instruction;
 6160   dst    : S5(write);
 6161   src1   : S1(read);
 6162   src2   : S1(read);
 6163   dst    : S1(read);
 6164   INS01  : ISS;
 6165   NEON_FP : S5;
 6166 %}
 6167 
 6168 pipe_class vmla128(vecX dst, vecX src1, vecX src2)
 6169 %{
 6170   single_instruction;
 6171   dst    : S5(write);
 6172   src1   : S1(read);
 6173   src2   : S1(read);
 6174   dst    : S1(read);
 6175   INS0   : ISS;
 6176   NEON_FP : S5;
 6177 %}
 6178 
 6179 pipe_class vdop64(vecD dst, vecD src1, vecD src2)
 6180 %{
 6181   single_instruction;
 6182   dst    : S4(write);
 6183   src1   : S2(read);
 6184   src2   : S2(read);
 6185   INS01  : ISS;
 6186   NEON_FP : S4;
 6187 %}
 6188 
 6189 pipe_class vdop128(vecX dst, vecX src1, vecX src2)
 6190 %{
 6191   single_instruction;
 6192   dst    : S4(write);
 6193   src1   : S2(read);
 6194   src2   : S2(read);
 6195   INS0   : ISS;
 6196   NEON_FP : S4;
 6197 %}
 6198 
 6199 pipe_class vlogical64(vecD dst, vecD src1, vecD src2)
 6200 %{
 6201   single_instruction;
 6202   dst    : S3(write);
 6203   src1   : S2(read);
 6204   src2   : S2(read);
 6205   INS01  : ISS;
 6206   NEON_FP : S3;
 6207 %}
 6208 
 6209 pipe_class vlogical128(vecX dst, vecX src1, vecX src2)
 6210 %{
 6211   single_instruction;
 6212   dst    : S3(write);
 6213   src1   : S2(read);
 6214   src2   : S2(read);
 6215   INS0   : ISS;
 6216   NEON_FP : S3;
 6217 %}
 6218 
 6219 pipe_class vshift64(vecD dst, vecD src, vecX shift)
 6220 %{
 6221   single_instruction;
 6222   dst    : S3(write);
 6223   src    : S1(read);
 6224   shift  : S1(read);
 6225   INS01  : ISS;
 6226   NEON_FP : S3;
 6227 %}
 6228 
 6229 pipe_class vshift128(vecX dst, vecX src, vecX shift)
 6230 %{
 6231   single_instruction;
 6232   dst    : S3(write);
 6233   src    : S1(read);
 6234   shift  : S1(read);
 6235   INS0   : ISS;
 6236   NEON_FP : S3;
 6237 %}
 6238 
 6239 pipe_class vshift64_imm(vecD dst, vecD src, immI shift)
 6240 %{
 6241   single_instruction;
 6242   dst    : S3(write);
 6243   src    : S1(read);
 6244   INS01  : ISS;
 6245   NEON_FP : S3;
 6246 %}
 6247 
 6248 pipe_class vshift128_imm(vecX dst, vecX src, immI shift)
 6249 %{
 6250   single_instruction;
 6251   dst    : S3(write);
 6252   src    : S1(read);
 6253   INS0   : ISS;
 6254   NEON_FP : S3;
 6255 %}
 6256 
 6257 pipe_class vdop_fp64(vecD dst, vecD src1, vecD src2)
 6258 %{
 6259   single_instruction;
 6260   dst    : S5(write);
 6261   src1   : S1(read);
 6262   src2   : S1(read);
 6263   INS01  : ISS;
 6264   NEON_FP : S5;
 6265 %}
 6266 
 6267 pipe_class vdop_fp128(vecX dst, vecX src1, vecX src2)
 6268 %{
 6269   single_instruction;
 6270   dst    : S5(write);
 6271   src1   : S1(read);
 6272   src2   : S1(read);
 6273   INS0   : ISS;
 6274   NEON_FP : S5;
 6275 %}
 6276 
 6277 pipe_class vmuldiv_fp64(vecD dst, vecD src1, vecD src2)
 6278 %{
 6279   single_instruction;
 6280   dst    : S5(write);
 6281   src1   : S1(read);
 6282   src2   : S1(read);
 6283   INS0   : ISS;
 6284   NEON_FP : S5;
 6285 %}
 6286 
 6287 pipe_class vmuldiv_fp128(vecX dst, vecX src1, vecX src2)
 6288 %{
 6289   single_instruction;
 6290   dst    : S5(write);
 6291   src1   : S1(read);
 6292   src2   : S1(read);
 6293   INS0   : ISS;
 6294   NEON_FP : S5;
 6295 %}
 6296 
 6297 pipe_class vsqrt_fp128(vecX dst, vecX src)
 6298 %{
 6299   single_instruction;
 6300   dst    : S5(write);
 6301   src    : S1(read);
 6302   INS0   : ISS;
 6303   NEON_FP : S5;
 6304 %}
 6305 
 6306 pipe_class vunop_fp64(vecD dst, vecD src)
 6307 %{
 6308   single_instruction;
 6309   dst    : S5(write);
 6310   src    : S1(read);
 6311   INS01  : ISS;
 6312   NEON_FP : S5;
 6313 %}
 6314 
 6315 pipe_class vunop_fp128(vecX dst, vecX src)
 6316 %{
 6317   single_instruction;
 6318   dst    : S5(write);
 6319   src    : S1(read);
 6320   INS0   : ISS;
 6321   NEON_FP : S5;
 6322 %}
 6323 
 6324 pipe_class vdup_reg_reg64(vecD dst, iRegI src)
 6325 %{
 6326   single_instruction;
 6327   dst    : S3(write);
 6328   src    : S1(read);
 6329   INS01  : ISS;
 6330   NEON_FP : S3;
 6331 %}
 6332 
 6333 pipe_class vdup_reg_reg128(vecX dst, iRegI src)
 6334 %{
 6335   single_instruction;
 6336   dst    : S3(write);
 6337   src    : S1(read);
 6338   INS01  : ISS;
 6339   NEON_FP : S3;
 6340 %}
 6341 
 6342 pipe_class vdup_reg_freg64(vecD dst, vRegF src)
 6343 %{
 6344   single_instruction;
 6345   dst    : S3(write);
 6346   src    : S1(read);
 6347   INS01  : ISS;
 6348   NEON_FP : S3;
 6349 %}
 6350 
 6351 pipe_class vdup_reg_freg128(vecX dst, vRegF src)
 6352 %{
 6353   single_instruction;
 6354   dst    : S3(write);
 6355   src    : S1(read);
 6356   INS01  : ISS;
 6357   NEON_FP : S3;
 6358 %}
 6359 
 6360 pipe_class vdup_reg_dreg128(vecX dst, vRegD src)
 6361 %{
 6362   single_instruction;
 6363   dst    : S3(write);
 6364   src    : S1(read);
 6365   INS01  : ISS;
 6366   NEON_FP : S3;
 6367 %}
 6368 
 6369 pipe_class vmovi_reg_imm64(vecD dst)
 6370 %{
 6371   single_instruction;
 6372   dst    : S3(write);
 6373   INS01  : ISS;
 6374   NEON_FP : S3;
 6375 %}
 6376 
 6377 pipe_class vmovi_reg_imm128(vecX dst)
 6378 %{
 6379   single_instruction;
 6380   dst    : S3(write);
 6381   INS0   : ISS;
 6382   NEON_FP : S3;
 6383 %}
 6384 
 6385 pipe_class vload_reg_mem64(vecD dst, vmem8 mem)
 6386 %{
 6387   single_instruction;
 6388   dst    : S5(write);
 6389   mem    : ISS(read);
 6390   INS01  : ISS;
 6391   NEON_FP : S3;
 6392 %}
 6393 
 6394 pipe_class vload_reg_mem128(vecX dst, vmem16 mem)
 6395 %{
 6396   single_instruction;
 6397   dst    : S5(write);
 6398   mem    : ISS(read);
 6399   INS01  : ISS;
 6400   NEON_FP : S3;
 6401 %}
 6402 
 6403 pipe_class vstore_reg_mem64(vecD src, vmem8 mem)
 6404 %{
 6405   single_instruction;
 6406   mem    : ISS(read);
 6407   src    : S2(read);
 6408   INS01  : ISS;
 6409   NEON_FP : S3;
 6410 %}
 6411 
 6412 pipe_class vstore_reg_mem128(vecD src, vmem16 mem)
 6413 %{
 6414   single_instruction;
 6415   mem    : ISS(read);
 6416   src    : S2(read);
 6417   INS01  : ISS;
 6418   NEON_FP : S3;
 6419 %}
 6420 
 6421 //------- Integer ALU operations --------------------------
 6422 
 6423 // Integer ALU reg-reg operation
 6424 // Operands needed in EX1, result generated in EX2
 6425 // Eg.  ADD     x0, x1, x2
 6426 pipe_class ialu_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6427 %{
 6428   single_instruction;
 6429   dst    : EX2(write);
 6430   src1   : EX1(read);
 6431   src2   : EX1(read);
 6432   INS01  : ISS; // Dual issue as instruction 0 or 1
 6433   ALU    : EX2;
 6434 %}
 6435 
 6436 // Integer ALU reg-reg operation with constant shift
 6437 // Shifted register must be available in LATE_ISS instead of EX1
 6438 // Eg.  ADD     x0, x1, x2, LSL #2
 6439 pipe_class ialu_reg_reg_shift(iRegI dst, iRegI src1, iRegI src2, immI shift)
 6440 %{
 6441   single_instruction;
 6442   dst    : EX2(write);
 6443   src1   : EX1(read);
 6444   src2   : ISS(read);
 6445   INS01  : ISS;
 6446   ALU    : EX2;
 6447 %}
 6448 
 6449 // Integer ALU reg operation with constant shift
 6450 // Eg.  LSL     x0, x1, #shift
 6451 pipe_class ialu_reg_shift(iRegI dst, iRegI src1)
 6452 %{
 6453   single_instruction;
 6454   dst    : EX2(write);
 6455   src1   : ISS(read);
 6456   INS01  : ISS;
 6457   ALU    : EX2;
 6458 %}
 6459 
 6460 // Integer ALU reg-reg operation with variable shift
 6461 // Both operands must be available in LATE_ISS instead of EX1
 6462 // Result is available in EX1 instead of EX2
 6463 // Eg.  LSLV    x0, x1, x2
 6464 pipe_class ialu_reg_reg_vshift(iRegI dst, iRegI src1, iRegI src2)
 6465 %{
 6466   single_instruction;
 6467   dst    : EX1(write);
 6468   src1   : ISS(read);
 6469   src2   : ISS(read);
 6470   INS01  : ISS;
 6471   ALU    : EX1;
 6472 %}
 6473 
 6474 // Integer ALU reg-reg operation with extract
 6475 // As for _vshift above, but result generated in EX2
 6476 // Eg.  EXTR    x0, x1, x2, #N
 6477 pipe_class ialu_reg_reg_extr(iRegI dst, iRegI src1, iRegI src2)
 6478 %{
 6479   single_instruction;
 6480   dst    : EX2(write);
 6481   src1   : ISS(read);
 6482   src2   : ISS(read);
 6483   INS1   : ISS; // Can only dual issue as Instruction 1
 6484   ALU    : EX1;
 6485 %}
 6486 
 6487 // Integer ALU reg operation
 6488 // Eg.  NEG     x0, x1
 6489 pipe_class ialu_reg(iRegI dst, iRegI src)
 6490 %{
 6491   single_instruction;
 6492   dst    : EX2(write);
 6493   src    : EX1(read);
 6494   INS01  : ISS;
 6495   ALU    : EX2;
 6496 %}
 6497 
 6498 // Integer ALU reg mmediate operation
 6499 // Eg.  ADD     x0, x1, #N
 6500 pipe_class ialu_reg_imm(iRegI dst, iRegI src1)
 6501 %{
 6502   single_instruction;
 6503   dst    : EX2(write);
 6504   src1   : EX1(read);
 6505   INS01  : ISS;
 6506   ALU    : EX2;
 6507 %}
 6508 
 6509 // Integer ALU immediate operation (no source operands)
 6510 // Eg.  MOV     x0, #N
 6511 pipe_class ialu_imm(iRegI dst)
 6512 %{
 6513   single_instruction;
 6514   dst    : EX1(write);
 6515   INS01  : ISS;
 6516   ALU    : EX1;
 6517 %}
 6518 
 6519 //------- Compare operation -------------------------------
 6520 
 6521 // Compare reg-reg
 6522 // Eg.  CMP     x0, x1
 6523 pipe_class icmp_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
 6524 %{
 6525   single_instruction;
 6526 //  fixed_latency(16);
 6527   cr     : EX2(write);
 6528   op1    : EX1(read);
 6529   op2    : EX1(read);
 6530   INS01  : ISS;
 6531   ALU    : EX2;
 6532 %}
 6533 
 6534 // Compare reg-reg
 6535 // Eg.  CMP     x0, #N
 6536 pipe_class icmp_reg_imm(rFlagsReg cr, iRegI op1)
 6537 %{
 6538   single_instruction;
 6539 //  fixed_latency(16);
 6540   cr     : EX2(write);
 6541   op1    : EX1(read);
 6542   INS01  : ISS;
 6543   ALU    : EX2;
 6544 %}
 6545 
 6546 //------- Conditional instructions ------------------------
 6547 
 6548 // Conditional no operands
 6549 // Eg.  CSINC   x0, zr, zr, &lt;cond&gt;
 6550 pipe_class icond_none(iRegI dst, rFlagsReg cr)
 6551 %{
 6552   single_instruction;
 6553   cr     : EX1(read);
 6554   dst    : EX2(write);
 6555   INS01  : ISS;
 6556   ALU    : EX2;
 6557 %}
 6558 
 6559 // Conditional 2 operand
 6560 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6561 pipe_class icond_reg_reg(iRegI dst, iRegI src1, iRegI src2, rFlagsReg cr)
 6562 %{
 6563   single_instruction;
 6564   cr     : EX1(read);
 6565   src1   : EX1(read);
 6566   src2   : EX1(read);
 6567   dst    : EX2(write);
 6568   INS01  : ISS;
 6569   ALU    : EX2;
 6570 %}
 6571 
 6572 // Conditional 2 operand
 6573 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6574 pipe_class icond_reg(iRegI dst, iRegI src, rFlagsReg cr)
 6575 %{
 6576   single_instruction;
 6577   cr     : EX1(read);
 6578   src    : EX1(read);
 6579   dst    : EX2(write);
 6580   INS01  : ISS;
 6581   ALU    : EX2;
 6582 %}
 6583 
 6584 //------- Multiply pipeline operations --------------------
 6585 
 6586 // Multiply reg-reg
 6587 // Eg.  MUL     w0, w1, w2
 6588 pipe_class imul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6589 %{
 6590   single_instruction;
 6591   dst    : WR(write);
 6592   src1   : ISS(read);
 6593   src2   : ISS(read);
 6594   INS01  : ISS;
 6595   MAC    : WR;
 6596 %}
 6597 
 6598 // Multiply accumulate
 6599 // Eg.  MADD    w0, w1, w2, w3
 6600 pipe_class imac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6601 %{
 6602   single_instruction;
 6603   dst    : WR(write);
 6604   src1   : ISS(read);
 6605   src2   : ISS(read);
 6606   src3   : ISS(read);
 6607   INS01  : ISS;
 6608   MAC    : WR;
 6609 %}
 6610 
 6611 // Eg.  MUL     w0, w1, w2
 6612 pipe_class lmul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6613 %{
 6614   single_instruction;
 6615   fixed_latency(3); // Maximum latency for 64 bit mul
 6616   dst    : WR(write);
 6617   src1   : ISS(read);
 6618   src2   : ISS(read);
 6619   INS01  : ISS;
 6620   MAC    : WR;
 6621 %}
 6622 
 6623 // Multiply accumulate
 6624 // Eg.  MADD    w0, w1, w2, w3
 6625 pipe_class lmac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6626 %{
 6627   single_instruction;
 6628   fixed_latency(3); // Maximum latency for 64 bit mul
 6629   dst    : WR(write);
 6630   src1   : ISS(read);
 6631   src2   : ISS(read);
 6632   src3   : ISS(read);
 6633   INS01  : ISS;
 6634   MAC    : WR;
 6635 %}
 6636 
 6637 //------- Divide pipeline operations --------------------
 6638 
 6639 // Eg.  SDIV    w0, w1, w2
 6640 pipe_class idiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6641 %{
 6642   single_instruction;
 6643   fixed_latency(8); // Maximum latency for 32 bit divide
 6644   dst    : WR(write);
 6645   src1   : ISS(read);
 6646   src2   : ISS(read);
 6647   INS0   : ISS; // Can only dual issue as instruction 0
 6648   DIV    : WR;
 6649 %}
 6650 
 6651 // Eg.  SDIV    x0, x1, x2
 6652 pipe_class ldiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6653 %{
 6654   single_instruction;
 6655   fixed_latency(16); // Maximum latency for 64 bit divide
 6656   dst    : WR(write);
 6657   src1   : ISS(read);
 6658   src2   : ISS(read);
 6659   INS0   : ISS; // Can only dual issue as instruction 0
 6660   DIV    : WR;
 6661 %}
 6662 
 6663 //------- Load pipeline operations ------------------------
 6664 
 6665 // Load - prefetch
 6666 // Eg.  PFRM    &lt;mem&gt;
 6667 pipe_class iload_prefetch(memory mem)
 6668 %{
 6669   single_instruction;
 6670   mem    : ISS(read);
 6671   INS01  : ISS;
 6672   LDST   : WR;
 6673 %}
 6674 
 6675 // Load - reg, mem
 6676 // Eg.  LDR     x0, &lt;mem&gt;
 6677 pipe_class iload_reg_mem(iRegI dst, memory mem)
 6678 %{
 6679   single_instruction;
 6680   dst    : WR(write);
 6681   mem    : ISS(read);
 6682   INS01  : ISS;
 6683   LDST   : WR;
 6684 %}
 6685 
 6686 // Load - reg, reg
 6687 // Eg.  LDR     x0, [sp, x1]
 6688 pipe_class iload_reg_reg(iRegI dst, iRegI src)
 6689 %{
 6690   single_instruction;
 6691   dst    : WR(write);
 6692   src    : ISS(read);
 6693   INS01  : ISS;
 6694   LDST   : WR;
 6695 %}
 6696 
 6697 //------- Store pipeline operations -----------------------
 6698 
 6699 // Store - zr, mem
 6700 // Eg.  STR     zr, &lt;mem&gt;
 6701 pipe_class istore_mem(memory mem)
 6702 %{
 6703   single_instruction;
 6704   mem    : ISS(read);
 6705   INS01  : ISS;
 6706   LDST   : WR;
 6707 %}
 6708 
 6709 // Store - reg, mem
 6710 // Eg.  STR     x0, &lt;mem&gt;
 6711 pipe_class istore_reg_mem(iRegI src, memory mem)
 6712 %{
 6713   single_instruction;
 6714   mem    : ISS(read);
 6715   src    : EX2(read);
 6716   INS01  : ISS;
 6717   LDST   : WR;
 6718 %}
 6719 
 6720 // Store - reg, reg
 6721 // Eg. STR      x0, [sp, x1]
 6722 pipe_class istore_reg_reg(iRegI dst, iRegI src)
 6723 %{
 6724   single_instruction;
 6725   dst    : ISS(read);
 6726   src    : EX2(read);
 6727   INS01  : ISS;
 6728   LDST   : WR;
 6729 %}
 6730 
 6731 //------- Store pipeline operations -----------------------
 6732 
 6733 // Branch
 6734 pipe_class pipe_branch()
 6735 %{
 6736   single_instruction;
 6737   INS01  : ISS;
 6738   BRANCH : EX1;
 6739 %}
 6740 
 6741 // Conditional branch
 6742 pipe_class pipe_branch_cond(rFlagsReg cr)
 6743 %{
 6744   single_instruction;
 6745   cr     : EX1(read);
 6746   INS01  : ISS;
 6747   BRANCH : EX1;
 6748 %}
 6749 
 6750 // Compare &amp; Branch
 6751 // EG.  CBZ/CBNZ
 6752 pipe_class pipe_cmp_branch(iRegI op1)
 6753 %{
 6754   single_instruction;
 6755   op1    : EX1(read);
 6756   INS01  : ISS;
 6757   BRANCH : EX1;
 6758 %}
 6759 
 6760 //------- Synchronisation operations ----------------------
 6761 
 6762 // Any operation requiring serialization.
 6763 // EG.  DMB/Atomic Ops/Load Acquire/Str Release
 6764 pipe_class pipe_serial()
 6765 %{
 6766   single_instruction;
 6767   force_serialization;
 6768   fixed_latency(16);
 6769   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6770   LDST   : WR;
 6771 %}
 6772 
 6773 // Generic big/slow expanded idiom - also serialized
 6774 pipe_class pipe_slow()
 6775 %{
 6776   instruction_count(10);
 6777   multiple_bundles;
 6778   force_serialization;
 6779   fixed_latency(16);
 6780   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6781   LDST   : WR;
 6782 %}
 6783 
 6784 // Empty pipeline class
 6785 pipe_class pipe_class_empty()
 6786 %{
 6787   single_instruction;
 6788   fixed_latency(0);
 6789 %}
 6790 
 6791 // Default pipeline class.
 6792 pipe_class pipe_class_default()
 6793 %{
 6794   single_instruction;
 6795   fixed_latency(2);
 6796 %}
 6797 
 6798 // Pipeline class for compares.
 6799 pipe_class pipe_class_compare()
 6800 %{
 6801   single_instruction;
 6802   fixed_latency(16);
 6803 %}
 6804 
 6805 // Pipeline class for memory operations.
 6806 pipe_class pipe_class_memory()
 6807 %{
 6808   single_instruction;
 6809   fixed_latency(16);
 6810 %}
 6811 
 6812 // Pipeline class for call.
 6813 pipe_class pipe_class_call()
 6814 %{
 6815   single_instruction;
 6816   fixed_latency(100);
 6817 %}
 6818 
 6819 // Define the class for the Nop node.
 6820 define %{
 6821    MachNop = pipe_class_empty;
 6822 %}
 6823 
 6824 %}
 6825 //----------INSTRUCTIONS-------------------------------------------------------
 6826 //
 6827 // match      -- States which machine-independent subtree may be replaced
 6828 //               by this instruction.
 6829 // ins_cost   -- The estimated cost of this instruction is used by instruction
 6830 //               selection to identify a minimum cost tree of machine
 6831 //               instructions that matches a tree of machine-independent
 6832 //               instructions.
 6833 // format     -- A string providing the disassembly for this instruction.
 6834 //               The value of an instruction&#39;s operand may be inserted
 6835 //               by referring to it with a &#39;$&#39; prefix.
 6836 // opcode     -- Three instruction opcodes may be provided.  These are referred
 6837 //               to within an encode class as $primary, $secondary, and $tertiary
 6838 //               rrspectively.  The primary opcode is commonly used to
 6839 //               indicate the type of machine instruction, while secondary
 6840 //               and tertiary are often used for prefix options or addressing
 6841 //               modes.
 6842 // ins_encode -- A list of encode classes with parameters. The encode class
 6843 //               name must have been defined in an &#39;enc_class&#39; specification
 6844 //               in the encode section of the architecture description.
 6845 
 6846 // ============================================================================
 6847 // Memory (Load/Store) Instructions
 6848 
 6849 // Load Instructions
 6850 
 6851 // Load Byte (8 bit signed)
 6852 instruct loadB(iRegINoSp dst, memory1 mem)
 6853 %{
 6854   match(Set dst (LoadB mem));
 6855   predicate(!needs_acquiring_load(n));
 6856 
 6857   ins_cost(4 * INSN_COST);
 6858   format %{ &quot;ldrsbw  $dst, $mem\t# byte&quot; %}
 6859 
 6860   ins_encode(aarch64_enc_ldrsbw(dst, mem));
 6861 
 6862   ins_pipe(iload_reg_mem);
 6863 %}
 6864 
 6865 // Load Byte (8 bit signed) into long
 6866 instruct loadB2L(iRegLNoSp dst, memory1 mem)
 6867 %{
 6868   match(Set dst (ConvI2L (LoadB mem)));
 6869   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6870 
 6871   ins_cost(4 * INSN_COST);
 6872   format %{ &quot;ldrsb  $dst, $mem\t# byte&quot; %}
 6873 
 6874   ins_encode(aarch64_enc_ldrsb(dst, mem));
 6875 
 6876   ins_pipe(iload_reg_mem);
 6877 %}
 6878 
 6879 // Load Byte (8 bit unsigned)
 6880 instruct loadUB(iRegINoSp dst, memory1 mem)
 6881 %{
 6882   match(Set dst (LoadUB mem));
 6883   predicate(!needs_acquiring_load(n));
 6884 
 6885   ins_cost(4 * INSN_COST);
 6886   format %{ &quot;ldrbw  $dst, $mem\t# byte&quot; %}
 6887 
 6888   ins_encode(aarch64_enc_ldrb(dst, mem));
 6889 
 6890   ins_pipe(iload_reg_mem);
 6891 %}
 6892 
 6893 // Load Byte (8 bit unsigned) into long
 6894 instruct loadUB2L(iRegLNoSp dst, memory1 mem)
 6895 %{
 6896   match(Set dst (ConvI2L (LoadUB mem)));
 6897   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6898 
 6899   ins_cost(4 * INSN_COST);
 6900   format %{ &quot;ldrb  $dst, $mem\t# byte&quot; %}
 6901 
 6902   ins_encode(aarch64_enc_ldrb(dst, mem));
 6903 
 6904   ins_pipe(iload_reg_mem);
 6905 %}
 6906 
 6907 // Load Short (16 bit signed)
 6908 instruct loadS(iRegINoSp dst, memory2 mem)
 6909 %{
 6910   match(Set dst (LoadS mem));
 6911   predicate(!needs_acquiring_load(n));
 6912 
 6913   ins_cost(4 * INSN_COST);
 6914   format %{ &quot;ldrshw  $dst, $mem\t# short&quot; %}
 6915 
 6916   ins_encode(aarch64_enc_ldrshw(dst, mem));
 6917 
 6918   ins_pipe(iload_reg_mem);
 6919 %}
 6920 
 6921 // Load Short (16 bit signed) into long
 6922 instruct loadS2L(iRegLNoSp dst, memory2 mem)
 6923 %{
 6924   match(Set dst (ConvI2L (LoadS mem)));
 6925   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6926 
 6927   ins_cost(4 * INSN_COST);
 6928   format %{ &quot;ldrsh  $dst, $mem\t# short&quot; %}
 6929 
 6930   ins_encode(aarch64_enc_ldrsh(dst, mem));
 6931 
 6932   ins_pipe(iload_reg_mem);
 6933 %}
 6934 
 6935 // Load Char (16 bit unsigned)
 6936 instruct loadUS(iRegINoSp dst, memory2 mem)
 6937 %{
 6938   match(Set dst (LoadUS mem));
 6939   predicate(!needs_acquiring_load(n));
 6940 
 6941   ins_cost(4 * INSN_COST);
 6942   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6943 
 6944   ins_encode(aarch64_enc_ldrh(dst, mem));
 6945 
 6946   ins_pipe(iload_reg_mem);
 6947 %}
 6948 
 6949 // Load Short/Char (16 bit unsigned) into long
 6950 instruct loadUS2L(iRegLNoSp dst, memory2 mem)
 6951 %{
 6952   match(Set dst (ConvI2L (LoadUS mem)));
 6953   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6954 
 6955   ins_cost(4 * INSN_COST);
 6956   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6957 
 6958   ins_encode(aarch64_enc_ldrh(dst, mem));
 6959 
 6960   ins_pipe(iload_reg_mem);
 6961 %}
 6962 
 6963 // Load Integer (32 bit signed)
 6964 instruct loadI(iRegINoSp dst, memory4 mem)
 6965 %{
 6966   match(Set dst (LoadI mem));
 6967   predicate(!needs_acquiring_load(n));
 6968 
 6969   ins_cost(4 * INSN_COST);
 6970   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6971 
 6972   ins_encode(aarch64_enc_ldrw(dst, mem));
 6973 
 6974   ins_pipe(iload_reg_mem);
 6975 %}
 6976 
 6977 // Load Integer (32 bit signed) into long
 6978 instruct loadI2L(iRegLNoSp dst, memory4 mem)
 6979 %{
 6980   match(Set dst (ConvI2L (LoadI mem)));
 6981   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6982 
 6983   ins_cost(4 * INSN_COST);
 6984   format %{ &quot;ldrsw  $dst, $mem\t# int&quot; %}
 6985 
 6986   ins_encode(aarch64_enc_ldrsw(dst, mem));
 6987 
 6988   ins_pipe(iload_reg_mem);
 6989 %}
 6990 
 6991 // Load Integer (32 bit unsigned) into long
 6992 instruct loadUI2L(iRegLNoSp dst, memory4 mem, immL_32bits mask)
 6993 %{
 6994   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 6995   predicate(!needs_acquiring_load(n-&gt;in(1)-&gt;in(1)-&gt;as_Load()));
 6996 
 6997   ins_cost(4 * INSN_COST);
 6998   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6999 
 7000   ins_encode(aarch64_enc_ldrw(dst, mem));
 7001 
 7002   ins_pipe(iload_reg_mem);
 7003 %}
 7004 
 7005 // Load Long (64 bit signed)
 7006 instruct loadL(iRegLNoSp dst, memory8 mem)
 7007 %{
 7008   match(Set dst (LoadL mem));
 7009   predicate(!needs_acquiring_load(n));
 7010 
 7011   ins_cost(4 * INSN_COST);
 7012   format %{ &quot;ldr  $dst, $mem\t# int&quot; %}
 7013 
 7014   ins_encode(aarch64_enc_ldr(dst, mem));
 7015 
 7016   ins_pipe(iload_reg_mem);
 7017 %}
 7018 
 7019 // Load Range
 7020 instruct loadRange(iRegINoSp dst, memory4 mem)
 7021 %{
 7022   match(Set dst (LoadRange mem));
 7023 
 7024   ins_cost(4 * INSN_COST);
 7025   format %{ &quot;ldrw  $dst, $mem\t# range&quot; %}
 7026 
 7027   ins_encode(aarch64_enc_ldrw(dst, mem));
 7028 
 7029   ins_pipe(iload_reg_mem);
 7030 %}
 7031 
 7032 // Load Pointer
 7033 instruct loadP(iRegPNoSp dst, memory8 mem)
 7034 %{
 7035   match(Set dst (LoadP mem));
 7036   predicate(!needs_acquiring_load(n) &amp;&amp; (n-&gt;as_Load()-&gt;barrier_data() == 0));
 7037 
 7038   ins_cost(4 * INSN_COST);
 7039   format %{ &quot;ldr  $dst, $mem\t# ptr&quot; %}
 7040 
 7041   ins_encode(aarch64_enc_ldr(dst, mem));
 7042 
 7043   ins_pipe(iload_reg_mem);
 7044 %}
 7045 
 7046 // Load Compressed Pointer
 7047 instruct loadN(iRegNNoSp dst, memory4 mem)
 7048 %{
 7049   match(Set dst (LoadN mem));
 7050   predicate(!needs_acquiring_load(n));
 7051 
 7052   ins_cost(4 * INSN_COST);
 7053   format %{ &quot;ldrw  $dst, $mem\t# compressed ptr&quot; %}
 7054 
 7055   ins_encode(aarch64_enc_ldrw(dst, mem));
 7056 
 7057   ins_pipe(iload_reg_mem);
 7058 %}
 7059 
 7060 // Load Klass Pointer
 7061 instruct loadKlass(iRegPNoSp dst, memory8 mem)
 7062 %{
 7063   match(Set dst (LoadKlass mem));
 7064   predicate(!needs_acquiring_load(n));
 7065 
 7066   ins_cost(4 * INSN_COST);
 7067   format %{ &quot;ldr  $dst, $mem\t# class&quot; %}
 7068 
 7069   ins_encode(aarch64_enc_ldr(dst, mem));
 7070 
 7071   ins_pipe(iload_reg_mem);
 7072 %}
 7073 
 7074 // Load Narrow Klass Pointer
 7075 instruct loadNKlass(iRegNNoSp dst, memory4 mem)
 7076 %{
 7077   match(Set dst (LoadNKlass mem));
 7078   predicate(!needs_acquiring_load(n));
 7079 
 7080   ins_cost(4 * INSN_COST);
 7081   format %{ &quot;ldrw  $dst, $mem\t# compressed class ptr&quot; %}
 7082 
 7083   ins_encode(aarch64_enc_ldrw(dst, mem));
 7084 
 7085   ins_pipe(iload_reg_mem);
 7086 %}
 7087 
 7088 // Load Float
 7089 instruct loadF(vRegF dst, memory4 mem)
 7090 %{
 7091   match(Set dst (LoadF mem));
 7092   predicate(!needs_acquiring_load(n));
 7093 
 7094   ins_cost(4 * INSN_COST);
 7095   format %{ &quot;ldrs  $dst, $mem\t# float&quot; %}
 7096 
 7097   ins_encode( aarch64_enc_ldrs(dst, mem) );
 7098 
 7099   ins_pipe(pipe_class_memory);
 7100 %}
 7101 
 7102 // Load Double
 7103 instruct loadD(vRegD dst, memory8 mem)
 7104 %{
 7105   match(Set dst (LoadD mem));
 7106   predicate(!needs_acquiring_load(n));
 7107 
 7108   ins_cost(4 * INSN_COST);
 7109   format %{ &quot;ldrd  $dst, $mem\t# double&quot; %}
 7110 
 7111   ins_encode( aarch64_enc_ldrd(dst, mem) );
 7112 
 7113   ins_pipe(pipe_class_memory);
 7114 %}
 7115 
 7116 
 7117 // Load Int Constant
 7118 instruct loadConI(iRegINoSp dst, immI src)
 7119 %{
 7120   match(Set dst src);
 7121 
 7122   ins_cost(INSN_COST);
 7123   format %{ &quot;mov $dst, $src\t# int&quot; %}
 7124 
 7125   ins_encode( aarch64_enc_movw_imm(dst, src) );
 7126 
 7127   ins_pipe(ialu_imm);
 7128 %}
 7129 
 7130 // Load Long Constant
 7131 instruct loadConL(iRegLNoSp dst, immL src)
 7132 %{
 7133   match(Set dst src);
 7134 
 7135   ins_cost(INSN_COST);
 7136   format %{ &quot;mov $dst, $src\t# long&quot; %}
 7137 
 7138   ins_encode( aarch64_enc_mov_imm(dst, src) );
 7139 
 7140   ins_pipe(ialu_imm);
 7141 %}
 7142 
 7143 // Load Pointer Constant
 7144 
 7145 instruct loadConP(iRegPNoSp dst, immP con)
 7146 %{
 7147   match(Set dst con);
 7148 
 7149   ins_cost(INSN_COST * 4);
 7150   format %{
 7151     &quot;mov  $dst, $con\t# ptr\n\t&quot;
 7152   %}
 7153 
 7154   ins_encode(aarch64_enc_mov_p(dst, con));
 7155 
 7156   ins_pipe(ialu_imm);
 7157 %}
 7158 
 7159 // Load Null Pointer Constant
 7160 
 7161 instruct loadConP0(iRegPNoSp dst, immP0 con)
 7162 %{
 7163   match(Set dst con);
 7164 
 7165   ins_cost(INSN_COST);
 7166   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7167 
 7168   ins_encode(aarch64_enc_mov_p0(dst, con));
 7169 
 7170   ins_pipe(ialu_imm);
 7171 %}
 7172 
 7173 // Load Pointer Constant One
 7174 
 7175 instruct loadConP1(iRegPNoSp dst, immP_1 con)
 7176 %{
 7177   match(Set dst con);
 7178 
 7179   ins_cost(INSN_COST);
 7180   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7181 
 7182   ins_encode(aarch64_enc_mov_p1(dst, con));
 7183 
 7184   ins_pipe(ialu_imm);
 7185 %}
 7186 
 7187 // Load Byte Map Base Constant
 7188 
 7189 instruct loadByteMapBase(iRegPNoSp dst, immByteMapBase con)
 7190 %{
 7191   match(Set dst con);
 7192 
 7193   ins_cost(INSN_COST);
 7194   format %{ &quot;adr  $dst, $con\t# Byte Map Base&quot; %}
 7195 
 7196   ins_encode(aarch64_enc_mov_byte_map_base(dst, con));
 7197 
 7198   ins_pipe(ialu_imm);
 7199 %}
 7200 
 7201 // Load Narrow Pointer Constant
 7202 
 7203 instruct loadConN(iRegNNoSp dst, immN con)
 7204 %{
 7205   match(Set dst con);
 7206 
 7207   ins_cost(INSN_COST * 4);
 7208   format %{ &quot;mov  $dst, $con\t# compressed ptr&quot; %}
 7209 
 7210   ins_encode(aarch64_enc_mov_n(dst, con));
 7211 
 7212   ins_pipe(ialu_imm);
 7213 %}
 7214 
 7215 // Load Narrow Null Pointer Constant
 7216 
 7217 instruct loadConN0(iRegNNoSp dst, immN0 con)
 7218 %{
 7219   match(Set dst con);
 7220 
 7221   ins_cost(INSN_COST);
 7222   format %{ &quot;mov  $dst, $con\t# compressed NULL ptr&quot; %}
 7223 
 7224   ins_encode(aarch64_enc_mov_n0(dst, con));
 7225 
 7226   ins_pipe(ialu_imm);
 7227 %}
 7228 
 7229 // Load Narrow Klass Constant
 7230 
 7231 instruct loadConNKlass(iRegNNoSp dst, immNKlass con)
 7232 %{
 7233   match(Set dst con);
 7234 
 7235   ins_cost(INSN_COST);
 7236   format %{ &quot;mov  $dst, $con\t# compressed klass ptr&quot; %}
 7237 
 7238   ins_encode(aarch64_enc_mov_nk(dst, con));
 7239 
 7240   ins_pipe(ialu_imm);
 7241 %}
 7242 
 7243 // Load Packed Float Constant
 7244 
 7245 instruct loadConF_packed(vRegF dst, immFPacked con) %{
 7246   match(Set dst con);
 7247   ins_cost(INSN_COST * 4);
 7248   format %{ &quot;fmovs  $dst, $con&quot;%}
 7249   ins_encode %{
 7250     __ fmovs(as_FloatRegister($dst$$reg), (double)$con$$constant);
 7251   %}
 7252 
 7253   ins_pipe(fp_imm_s);
 7254 %}
 7255 
 7256 // Load Float Constant
 7257 
 7258 instruct loadConF(vRegF dst, immF con) %{
 7259   match(Set dst con);
 7260 
 7261   ins_cost(INSN_COST * 4);
 7262 
 7263   format %{
 7264     &quot;ldrs $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7265   %}
 7266 
 7267   ins_encode %{
 7268     __ ldrs(as_FloatRegister($dst$$reg), $constantaddress($con));
 7269   %}
 7270 
 7271   ins_pipe(fp_load_constant_s);
 7272 %}
 7273 
 7274 // Load Packed Double Constant
 7275 
 7276 instruct loadConD_packed(vRegD dst, immDPacked con) %{
 7277   match(Set dst con);
 7278   ins_cost(INSN_COST);
 7279   format %{ &quot;fmovd  $dst, $con&quot;%}
 7280   ins_encode %{
 7281     __ fmovd(as_FloatRegister($dst$$reg), $con$$constant);
 7282   %}
 7283 
 7284   ins_pipe(fp_imm_d);
 7285 %}
 7286 
 7287 // Load Double Constant
 7288 
 7289 instruct loadConD(vRegD dst, immD con) %{
 7290   match(Set dst con);
 7291 
 7292   ins_cost(INSN_COST * 5);
 7293   format %{
 7294     &quot;ldrd $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7295   %}
 7296 
 7297   ins_encode %{
 7298     __ ldrd(as_FloatRegister($dst$$reg), $constantaddress($con));
 7299   %}
 7300 
 7301   ins_pipe(fp_load_constant_d);
 7302 %}
 7303 
 7304 // Store Instructions
 7305 
 7306 // Store CMS card-mark Immediate
 7307 instruct storeimmCM0(immI0 zero, memory1 mem)
 7308 %{
 7309   match(Set mem (StoreCM mem zero));
 7310 
 7311   ins_cost(INSN_COST);
 7312   format %{ &quot;storestore (elided)\n\t&quot;
 7313             &quot;strb zr, $mem\t# byte&quot; %}
 7314 
 7315   ins_encode(aarch64_enc_strb0(mem));
 7316 
 7317   ins_pipe(istore_mem);
 7318 %}
 7319 
 7320 // Store CMS card-mark Immediate with intervening StoreStore
 7321 // needed when using CMS with no conditional card marking
 7322 instruct storeimmCM0_ordered(immI0 zero, memory1 mem)
 7323 %{
 7324   match(Set mem (StoreCM mem zero));
 7325 
 7326   ins_cost(INSN_COST * 2);
 7327   format %{ &quot;storestore\n\t&quot;
 7328             &quot;dmb ishst&quot;
 7329             &quot;\n\tstrb zr, $mem\t# byte&quot; %}
 7330 
 7331   ins_encode(aarch64_enc_strb0_ordered(mem));
 7332 
 7333   ins_pipe(istore_mem);
 7334 %}
 7335 
 7336 // Store Byte
 7337 instruct storeB(iRegIorL2I src, memory1 mem)
 7338 %{
 7339   match(Set mem (StoreB mem src));
 7340   predicate(!needs_releasing_store(n));
 7341 
 7342   ins_cost(INSN_COST);
 7343   format %{ &quot;strb  $src, $mem\t# byte&quot; %}
 7344 
 7345   ins_encode(aarch64_enc_strb(src, mem));
 7346 
 7347   ins_pipe(istore_reg_mem);
 7348 %}
 7349 
 7350 
 7351 instruct storeimmB0(immI0 zero, memory1 mem)
 7352 %{
 7353   match(Set mem (StoreB mem zero));
 7354   predicate(!needs_releasing_store(n));
 7355 
 7356   ins_cost(INSN_COST);
 7357   format %{ &quot;strb rscractch2, $mem\t# byte&quot; %}
 7358 
 7359   ins_encode(aarch64_enc_strb0(mem));
 7360 
 7361   ins_pipe(istore_mem);
 7362 %}
 7363 
 7364 // Store Char/Short
 7365 instruct storeC(iRegIorL2I src, memory2 mem)
 7366 %{
 7367   match(Set mem (StoreC mem src));
 7368   predicate(!needs_releasing_store(n));
 7369 
 7370   ins_cost(INSN_COST);
 7371   format %{ &quot;strh  $src, $mem\t# short&quot; %}
 7372 
 7373   ins_encode(aarch64_enc_strh(src, mem));
 7374 
 7375   ins_pipe(istore_reg_mem);
 7376 %}
 7377 
 7378 instruct storeimmC0(immI0 zero, memory2 mem)
 7379 %{
 7380   match(Set mem (StoreC mem zero));
 7381   predicate(!needs_releasing_store(n));
 7382 
 7383   ins_cost(INSN_COST);
 7384   format %{ &quot;strh  zr, $mem\t# short&quot; %}
 7385 
 7386   ins_encode(aarch64_enc_strh0(mem));
 7387 
 7388   ins_pipe(istore_mem);
 7389 %}
 7390 
 7391 // Store Integer
 7392 
 7393 instruct storeI(iRegIorL2I src, memory4 mem)
 7394 %{
 7395   match(Set mem(StoreI mem src));
 7396   predicate(!needs_releasing_store(n));
 7397 
 7398   ins_cost(INSN_COST);
 7399   format %{ &quot;strw  $src, $mem\t# int&quot; %}
 7400 
 7401   ins_encode(aarch64_enc_strw(src, mem));
 7402 
 7403   ins_pipe(istore_reg_mem);
 7404 %}
 7405 
 7406 instruct storeimmI0(immI0 zero, memory4 mem)
 7407 %{
 7408   match(Set mem(StoreI mem zero));
 7409   predicate(!needs_releasing_store(n));
 7410 
 7411   ins_cost(INSN_COST);
 7412   format %{ &quot;strw  zr, $mem\t# int&quot; %}
 7413 
 7414   ins_encode(aarch64_enc_strw0(mem));
 7415 
 7416   ins_pipe(istore_mem);
 7417 %}
 7418 
 7419 // Store Long (64 bit signed)
 7420 instruct storeL(iRegL src, memory8 mem)
 7421 %{
 7422   match(Set mem (StoreL mem src));
 7423   predicate(!needs_releasing_store(n));
 7424 
 7425   ins_cost(INSN_COST);
 7426   format %{ &quot;str  $src, $mem\t# int&quot; %}
 7427 
 7428   ins_encode(aarch64_enc_str(src, mem));
 7429 
 7430   ins_pipe(istore_reg_mem);
 7431 %}
 7432 
 7433 // Store Long (64 bit signed)
 7434 instruct storeimmL0(immL0 zero, memory8 mem)
 7435 %{
 7436   match(Set mem (StoreL mem zero));
 7437   predicate(!needs_releasing_store(n));
 7438 
 7439   ins_cost(INSN_COST);
 7440   format %{ &quot;str  zr, $mem\t# int&quot; %}
 7441 
 7442   ins_encode(aarch64_enc_str0(mem));
 7443 
 7444   ins_pipe(istore_mem);
 7445 %}
 7446 
 7447 // Store Pointer
 7448 instruct storeP(iRegP src, memory8 mem)
 7449 %{
 7450   match(Set mem (StoreP mem src));
 7451   predicate(!needs_releasing_store(n));
 7452 
 7453   ins_cost(INSN_COST);
 7454   format %{ &quot;str  $src, $mem\t# ptr&quot; %}
 7455 
 7456   ins_encode(aarch64_enc_str(src, mem));
 7457 
 7458   ins_pipe(istore_reg_mem);
 7459 %}
 7460 
 7461 // Store Pointer
 7462 instruct storeimmP0(immP0 zero, memory8 mem)
 7463 %{
 7464   match(Set mem (StoreP mem zero));
 7465   predicate(!needs_releasing_store(n));
 7466 
 7467   ins_cost(INSN_COST);
 7468   format %{ &quot;str zr, $mem\t# ptr&quot; %}
 7469 
 7470   ins_encode(aarch64_enc_str0(mem));
 7471 
 7472   ins_pipe(istore_mem);
 7473 %}
 7474 
 7475 // Store Compressed Pointer
 7476 instruct storeN(iRegN src, memory4 mem)
 7477 %{
 7478   match(Set mem (StoreN mem src));
 7479   predicate(!needs_releasing_store(n));
 7480 
 7481   ins_cost(INSN_COST);
 7482   format %{ &quot;strw  $src, $mem\t# compressed ptr&quot; %}
 7483 
 7484   ins_encode(aarch64_enc_strw(src, mem));
 7485 
 7486   ins_pipe(istore_reg_mem);
 7487 %}
 7488 
 7489 instruct storeImmN0(immN0 zero, memory4 mem)
 7490 %{
 7491   match(Set mem (StoreN mem zero));
 7492   predicate(!needs_releasing_store(n));
 7493 
 7494   ins_cost(INSN_COST);
 7495   format %{ &quot;strw  zr, $mem\t# compressed ptr&quot; %}
 7496 
 7497   ins_encode(aarch64_enc_strw0(mem));
 7498 
 7499   ins_pipe(istore_mem);
 7500 %}
 7501 
 7502 // Store Float
 7503 instruct storeF(vRegF src, memory4 mem)
 7504 %{
 7505   match(Set mem (StoreF mem src));
 7506   predicate(!needs_releasing_store(n));
 7507 
 7508   ins_cost(INSN_COST);
 7509   format %{ &quot;strs  $src, $mem\t# float&quot; %}
 7510 
 7511   ins_encode( aarch64_enc_strs(src, mem) );
 7512 
 7513   ins_pipe(pipe_class_memory);
 7514 %}
 7515 
 7516 // TODO
 7517 // implement storeImmF0 and storeFImmPacked
 7518 
 7519 // Store Double
 7520 instruct storeD(vRegD src, memory8 mem)
 7521 %{
 7522   match(Set mem (StoreD mem src));
 7523   predicate(!needs_releasing_store(n));
 7524 
 7525   ins_cost(INSN_COST);
 7526   format %{ &quot;strd  $src, $mem\t# double&quot; %}
 7527 
 7528   ins_encode( aarch64_enc_strd(src, mem) );
 7529 
 7530   ins_pipe(pipe_class_memory);
 7531 %}
 7532 
 7533 // Store Compressed Klass Pointer
 7534 instruct storeNKlass(iRegN src, memory4 mem)
 7535 %{
 7536   predicate(!needs_releasing_store(n));
 7537   match(Set mem (StoreNKlass mem src));
 7538 
 7539   ins_cost(INSN_COST);
 7540   format %{ &quot;strw  $src, $mem\t# compressed klass ptr&quot; %}
 7541 
 7542   ins_encode(aarch64_enc_strw(src, mem));
 7543 
 7544   ins_pipe(istore_reg_mem);
 7545 %}
 7546 
 7547 // TODO
 7548 // implement storeImmD0 and storeDImmPacked
 7549 
 7550 // prefetch instructions
 7551 // Must be safe to execute with invalid address (cannot fault).
 7552 
 7553 instruct prefetchalloc( memory8 mem ) %{
 7554   match(PrefetchAllocation mem);
 7555 
 7556   ins_cost(INSN_COST);
 7557   format %{ &quot;prfm $mem, PSTL1KEEP\t# Prefetch into level 1 cache write keep&quot; %}
 7558 
 7559   ins_encode( aarch64_enc_prefetchw(mem) );
 7560 
 7561   ins_pipe(iload_prefetch);
 7562 %}
 7563 
 7564 //  ---------------- volatile loads and stores ----------------
 7565 
 7566 // Load Byte (8 bit signed)
 7567 instruct loadB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7568 %{
 7569   match(Set dst (LoadB mem));
 7570 
 7571   ins_cost(VOLATILE_REF_COST);
 7572   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7573 
 7574   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7575 
 7576   ins_pipe(pipe_serial);
 7577 %}
 7578 
 7579 // Load Byte (8 bit signed) into long
 7580 instruct loadB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7581 %{
 7582   match(Set dst (ConvI2L (LoadB mem)));
 7583 
 7584   ins_cost(VOLATILE_REF_COST);
 7585   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7586 
 7587   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7588 
 7589   ins_pipe(pipe_serial);
 7590 %}
 7591 
 7592 // Load Byte (8 bit unsigned)
 7593 instruct loadUB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7594 %{
 7595   match(Set dst (LoadUB mem));
 7596 
 7597   ins_cost(VOLATILE_REF_COST);
 7598   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7599 
 7600   ins_encode(aarch64_enc_ldarb(dst, mem));
 7601 
 7602   ins_pipe(pipe_serial);
 7603 %}
 7604 
 7605 // Load Byte (8 bit unsigned) into long
 7606 instruct loadUB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7607 %{
 7608   match(Set dst (ConvI2L (LoadUB mem)));
 7609 
 7610   ins_cost(VOLATILE_REF_COST);
 7611   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7612 
 7613   ins_encode(aarch64_enc_ldarb(dst, mem));
 7614 
 7615   ins_pipe(pipe_serial);
 7616 %}
 7617 
 7618 // Load Short (16 bit signed)
 7619 instruct loadS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7620 %{
 7621   match(Set dst (LoadS mem));
 7622 
 7623   ins_cost(VOLATILE_REF_COST);
 7624   format %{ &quot;ldarshw  $dst, $mem\t# short&quot; %}
 7625 
 7626   ins_encode(aarch64_enc_ldarshw(dst, mem));
 7627 
 7628   ins_pipe(pipe_serial);
 7629 %}
 7630 
 7631 instruct loadUS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7632 %{
 7633   match(Set dst (LoadUS mem));
 7634 
 7635   ins_cost(VOLATILE_REF_COST);
 7636   format %{ &quot;ldarhw  $dst, $mem\t# short&quot; %}
 7637 
 7638   ins_encode(aarch64_enc_ldarhw(dst, mem));
 7639 
 7640   ins_pipe(pipe_serial);
 7641 %}
 7642 
 7643 // Load Short/Char (16 bit unsigned) into long
 7644 instruct loadUS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7645 %{
 7646   match(Set dst (ConvI2L (LoadUS mem)));
 7647 
 7648   ins_cost(VOLATILE_REF_COST);
 7649   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7650 
 7651   ins_encode(aarch64_enc_ldarh(dst, mem));
 7652 
 7653   ins_pipe(pipe_serial);
 7654 %}
 7655 
 7656 // Load Short/Char (16 bit signed) into long
 7657 instruct loadS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7658 %{
 7659   match(Set dst (ConvI2L (LoadS mem)));
 7660 
 7661   ins_cost(VOLATILE_REF_COST);
 7662   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7663 
 7664   ins_encode(aarch64_enc_ldarsh(dst, mem));
 7665 
 7666   ins_pipe(pipe_serial);
 7667 %}
 7668 
 7669 // Load Integer (32 bit signed)
 7670 instruct loadI_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7671 %{
 7672   match(Set dst (LoadI mem));
 7673 
 7674   ins_cost(VOLATILE_REF_COST);
 7675   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7676 
 7677   ins_encode(aarch64_enc_ldarw(dst, mem));
 7678 
 7679   ins_pipe(pipe_serial);
 7680 %}
 7681 
 7682 // Load Integer (32 bit unsigned) into long
 7683 instruct loadUI2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem, immL_32bits mask)
 7684 %{
 7685   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 7686 
 7687   ins_cost(VOLATILE_REF_COST);
 7688   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7689 
 7690   ins_encode(aarch64_enc_ldarw(dst, mem));
 7691 
 7692   ins_pipe(pipe_serial);
 7693 %}
 7694 
 7695 // Load Long (64 bit signed)
 7696 instruct loadL_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7697 %{
 7698   match(Set dst (LoadL mem));
 7699 
 7700   ins_cost(VOLATILE_REF_COST);
 7701   format %{ &quot;ldar  $dst, $mem\t# int&quot; %}
 7702 
 7703   ins_encode(aarch64_enc_ldar(dst, mem));
 7704 
 7705   ins_pipe(pipe_serial);
 7706 %}
 7707 
 7708 // Load Pointer
 7709 instruct loadP_volatile(iRegPNoSp dst, /* sync_memory*/indirect mem)
 7710 %{
 7711   match(Set dst (LoadP mem));
 7712   predicate(n-&gt;as_Load()-&gt;barrier_data() == 0);
 7713 
 7714   ins_cost(VOLATILE_REF_COST);
 7715   format %{ &quot;ldar  $dst, $mem\t# ptr&quot; %}
 7716 
 7717   ins_encode(aarch64_enc_ldar(dst, mem));
 7718 
 7719   ins_pipe(pipe_serial);
 7720 %}
 7721 
 7722 // Load Compressed Pointer
 7723 instruct loadN_volatile(iRegNNoSp dst, /* sync_memory*/indirect mem)
 7724 %{
 7725   match(Set dst (LoadN mem));
 7726 
 7727   ins_cost(VOLATILE_REF_COST);
 7728   format %{ &quot;ldarw  $dst, $mem\t# compressed ptr&quot; %}
 7729 
 7730   ins_encode(aarch64_enc_ldarw(dst, mem));
 7731 
 7732   ins_pipe(pipe_serial);
 7733 %}
 7734 
 7735 // Load Float
 7736 instruct loadF_volatile(vRegF dst, /* sync_memory*/indirect mem)
 7737 %{
 7738   match(Set dst (LoadF mem));
 7739 
 7740   ins_cost(VOLATILE_REF_COST);
 7741   format %{ &quot;ldars  $dst, $mem\t# float&quot; %}
 7742 
 7743   ins_encode( aarch64_enc_fldars(dst, mem) );
 7744 
 7745   ins_pipe(pipe_serial);
 7746 %}
 7747 
 7748 // Load Double
 7749 instruct loadD_volatile(vRegD dst, /* sync_memory*/indirect mem)
 7750 %{
 7751   match(Set dst (LoadD mem));
 7752 
 7753   ins_cost(VOLATILE_REF_COST);
 7754   format %{ &quot;ldard  $dst, $mem\t# double&quot; %}
 7755 
 7756   ins_encode( aarch64_enc_fldard(dst, mem) );
 7757 
 7758   ins_pipe(pipe_serial);
 7759 %}
 7760 
 7761 // Store Byte
 7762 instruct storeB_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7763 %{
 7764   match(Set mem (StoreB mem src));
 7765 
 7766   ins_cost(VOLATILE_REF_COST);
 7767   format %{ &quot;stlrb  $src, $mem\t# byte&quot; %}
 7768 
 7769   ins_encode(aarch64_enc_stlrb(src, mem));
 7770 
 7771   ins_pipe(pipe_class_memory);
 7772 %}
 7773 
 7774 // Store Char/Short
 7775 instruct storeC_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7776 %{
 7777   match(Set mem (StoreC mem src));
 7778 
 7779   ins_cost(VOLATILE_REF_COST);
 7780   format %{ &quot;stlrh  $src, $mem\t# short&quot; %}
 7781 
 7782   ins_encode(aarch64_enc_stlrh(src, mem));
 7783 
 7784   ins_pipe(pipe_class_memory);
 7785 %}
 7786 
 7787 // Store Integer
 7788 
 7789 instruct storeI_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7790 %{
 7791   match(Set mem(StoreI mem src));
 7792 
 7793   ins_cost(VOLATILE_REF_COST);
 7794   format %{ &quot;stlrw  $src, $mem\t# int&quot; %}
 7795 
 7796   ins_encode(aarch64_enc_stlrw(src, mem));
 7797 
 7798   ins_pipe(pipe_class_memory);
 7799 %}
 7800 
 7801 // Store Long (64 bit signed)
 7802 instruct storeL_volatile(iRegL src, /* sync_memory*/indirect mem)
 7803 %{
 7804   match(Set mem (StoreL mem src));
 7805 
 7806   ins_cost(VOLATILE_REF_COST);
 7807   format %{ &quot;stlr  $src, $mem\t# int&quot; %}
 7808 
 7809   ins_encode(aarch64_enc_stlr(src, mem));
 7810 
 7811   ins_pipe(pipe_class_memory);
 7812 %}
 7813 
 7814 // Store Pointer
 7815 instruct storeP_volatile(iRegP src, /* sync_memory*/indirect mem)
 7816 %{
 7817   match(Set mem (StoreP mem src));
 7818 
 7819   ins_cost(VOLATILE_REF_COST);
 7820   format %{ &quot;stlr  $src, $mem\t# ptr&quot; %}
 7821 
 7822   ins_encode(aarch64_enc_stlr(src, mem));
 7823 
 7824   ins_pipe(pipe_class_memory);
 7825 %}
 7826 
 7827 // Store Compressed Pointer
 7828 instruct storeN_volatile(iRegN src, /* sync_memory*/indirect mem)
 7829 %{
 7830   match(Set mem (StoreN mem src));
 7831 
 7832   ins_cost(VOLATILE_REF_COST);
 7833   format %{ &quot;stlrw  $src, $mem\t# compressed ptr&quot; %}
 7834 
 7835   ins_encode(aarch64_enc_stlrw(src, mem));
 7836 
 7837   ins_pipe(pipe_class_memory);
 7838 %}
 7839 
 7840 // Store Float
 7841 instruct storeF_volatile(vRegF src, /* sync_memory*/indirect mem)
 7842 %{
 7843   match(Set mem (StoreF mem src));
 7844 
 7845   ins_cost(VOLATILE_REF_COST);
 7846   format %{ &quot;stlrs  $src, $mem\t# float&quot; %}
 7847 
 7848   ins_encode( aarch64_enc_fstlrs(src, mem) );
 7849 
 7850   ins_pipe(pipe_class_memory);
 7851 %}
 7852 
 7853 // TODO
 7854 // implement storeImmF0 and storeFImmPacked
 7855 
 7856 // Store Double
 7857 instruct storeD_volatile(vRegD src, /* sync_memory*/indirect mem)
 7858 %{
 7859   match(Set mem (StoreD mem src));
 7860 
 7861   ins_cost(VOLATILE_REF_COST);
 7862   format %{ &quot;stlrd  $src, $mem\t# double&quot; %}
 7863 
 7864   ins_encode( aarch64_enc_fstlrd(src, mem) );
 7865 
 7866   ins_pipe(pipe_class_memory);
 7867 %}
 7868 
 7869 //  ---------------- end of volatile loads and stores ----------------
 7870 
 7871 instruct cacheWB(indirect addr)
 7872 %{
 7873   predicate(VM_Version::supports_data_cache_line_flush());
 7874   match(CacheWB addr);
 7875 
 7876   ins_cost(100);
 7877   format %{&quot;cache wb $addr&quot; %}
 7878   ins_encode %{
 7879     assert($addr-&gt;index_position() &lt; 0, &quot;should be&quot;);
 7880     assert($addr$$disp == 0, &quot;should be&quot;);
 7881     __ cache_wb(Address($addr$$base$$Register, 0));
 7882   %}
 7883   ins_pipe(pipe_slow); // XXX
 7884 %}
 7885 
 7886 instruct cacheWBPreSync()
 7887 %{
 7888   predicate(VM_Version::supports_data_cache_line_flush());
 7889   match(CacheWBPreSync);
 7890 
 7891   ins_cost(100);
 7892   format %{&quot;cache wb presync&quot; %}
 7893   ins_encode %{
 7894     __ cache_wbsync(true);
 7895   %}
 7896   ins_pipe(pipe_slow); // XXX
 7897 %}
 7898 
 7899 instruct cacheWBPostSync()
 7900 %{
 7901   predicate(VM_Version::supports_data_cache_line_flush());
 7902   match(CacheWBPostSync);
 7903 
 7904   ins_cost(100);
 7905   format %{&quot;cache wb postsync&quot; %}
 7906   ins_encode %{
 7907     __ cache_wbsync(false);
 7908   %}
 7909   ins_pipe(pipe_slow); // XXX
 7910 %}
 7911 
 7912 // ============================================================================
 7913 // BSWAP Instructions
 7914 
 7915 instruct bytes_reverse_int(iRegINoSp dst, iRegIorL2I src) %{
 7916   match(Set dst (ReverseBytesI src));
 7917 
 7918   ins_cost(INSN_COST);
 7919   format %{ &quot;revw  $dst, $src&quot; %}
 7920 
 7921   ins_encode %{
 7922     __ revw(as_Register($dst$$reg), as_Register($src$$reg));
 7923   %}
 7924 
 7925   ins_pipe(ialu_reg);
 7926 %}
 7927 
 7928 instruct bytes_reverse_long(iRegLNoSp dst, iRegL src) %{
 7929   match(Set dst (ReverseBytesL src));
 7930 
 7931   ins_cost(INSN_COST);
 7932   format %{ &quot;rev  $dst, $src&quot; %}
 7933 
 7934   ins_encode %{
 7935     __ rev(as_Register($dst$$reg), as_Register($src$$reg));
 7936   %}
 7937 
 7938   ins_pipe(ialu_reg);
 7939 %}
 7940 
 7941 instruct bytes_reverse_unsigned_short(iRegINoSp dst, iRegIorL2I src) %{
 7942   match(Set dst (ReverseBytesUS src));
 7943 
 7944   ins_cost(INSN_COST);
 7945   format %{ &quot;rev16w  $dst, $src&quot; %}
 7946 
 7947   ins_encode %{
 7948     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7949   %}
 7950 
 7951   ins_pipe(ialu_reg);
 7952 %}
 7953 
 7954 instruct bytes_reverse_short(iRegINoSp dst, iRegIorL2I src) %{
 7955   match(Set dst (ReverseBytesS src));
 7956 
 7957   ins_cost(INSN_COST);
 7958   format %{ &quot;rev16w  $dst, $src\n\t&quot;
 7959             &quot;sbfmw $dst, $dst, #0, #15&quot; %}
 7960 
 7961   ins_encode %{
 7962     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7963     __ sbfmw(as_Register($dst$$reg), as_Register($dst$$reg), 0U, 15U);
 7964   %}
 7965 
 7966   ins_pipe(ialu_reg);
 7967 %}
 7968 
 7969 // ============================================================================
 7970 // Zero Count Instructions
 7971 
 7972 instruct countLeadingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 7973   match(Set dst (CountLeadingZerosI src));
 7974 
 7975   ins_cost(INSN_COST);
 7976   format %{ &quot;clzw  $dst, $src&quot; %}
 7977   ins_encode %{
 7978     __ clzw(as_Register($dst$$reg), as_Register($src$$reg));
 7979   %}
 7980 
 7981   ins_pipe(ialu_reg);
 7982 %}
 7983 
 7984 instruct countLeadingZerosL(iRegINoSp dst, iRegL src) %{
 7985   match(Set dst (CountLeadingZerosL src));
 7986 
 7987   ins_cost(INSN_COST);
 7988   format %{ &quot;clz   $dst, $src&quot; %}
 7989   ins_encode %{
 7990     __ clz(as_Register($dst$$reg), as_Register($src$$reg));
 7991   %}
 7992 
 7993   ins_pipe(ialu_reg);
 7994 %}
 7995 
 7996 instruct countTrailingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 7997   match(Set dst (CountTrailingZerosI src));
 7998 
 7999   ins_cost(INSN_COST * 2);
 8000   format %{ &quot;rbitw  $dst, $src\n\t&quot;
 8001             &quot;clzw   $dst, $dst&quot; %}
 8002   ins_encode %{
 8003     __ rbitw(as_Register($dst$$reg), as_Register($src$$reg));
 8004     __ clzw(as_Register($dst$$reg), as_Register($dst$$reg));
 8005   %}
 8006 
 8007   ins_pipe(ialu_reg);
 8008 %}
 8009 
 8010 instruct countTrailingZerosL(iRegINoSp dst, iRegL src) %{
 8011   match(Set dst (CountTrailingZerosL src));
 8012 
 8013   ins_cost(INSN_COST * 2);
 8014   format %{ &quot;rbit   $dst, $src\n\t&quot;
 8015             &quot;clz    $dst, $dst&quot; %}
 8016   ins_encode %{
 8017     __ rbit(as_Register($dst$$reg), as_Register($src$$reg));
 8018     __ clz(as_Register($dst$$reg), as_Register($dst$$reg));
 8019   %}
 8020 
 8021   ins_pipe(ialu_reg);
 8022 %}
 8023 
 8024 //---------- Population Count Instructions -------------------------------------
 8025 //
 8026 
 8027 instruct popCountI(iRegINoSp dst, iRegIorL2I src, vRegF tmp) %{
 8028   predicate(UsePopCountInstruction);
 8029   match(Set dst (PopCountI src));
 8030   effect(TEMP tmp);
 8031   ins_cost(INSN_COST * 13);
 8032 
 8033   format %{ &quot;movw   $src, $src\n\t&quot;
 8034             &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8035             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8036             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8037             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8038   ins_encode %{
 8039     __ movw($src$$Register, $src$$Register); // ensure top 32 bits 0
 8040     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8041     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8042     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8043     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8044   %}
 8045 
 8046   ins_pipe(pipe_class_default);
 8047 %}
 8048 
 8049 instruct popCountI_mem(iRegINoSp dst, memory4 mem, vRegF tmp) %{
 8050   predicate(UsePopCountInstruction);
 8051   match(Set dst (PopCountI (LoadI mem)));
 8052   effect(TEMP tmp);
 8053   ins_cost(INSN_COST * 13);
 8054 
 8055   format %{ &quot;ldrs   $tmp, $mem\n\t&quot;
 8056             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8057             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8058             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8059   ins_encode %{
 8060     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8061     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, tmp_reg, $mem-&gt;opcode(),
 8062               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 8063     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8064     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8065     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8066   %}
 8067 
 8068   ins_pipe(pipe_class_default);
 8069 %}
 8070 
 8071 // Note: Long.bitCount(long) returns an int.
 8072 instruct popCountL(iRegINoSp dst, iRegL src, vRegD tmp) %{
 8073   predicate(UsePopCountInstruction);
 8074   match(Set dst (PopCountL src));
 8075   effect(TEMP tmp);
 8076   ins_cost(INSN_COST * 13);
 8077 
 8078   format %{ &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8079             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8080             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8081             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8082   ins_encode %{
 8083     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8084     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8085     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8086     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8087   %}
 8088 
 8089   ins_pipe(pipe_class_default);
 8090 %}
 8091 
 8092 instruct popCountL_mem(iRegINoSp dst, memory8 mem, vRegD tmp) %{
 8093   predicate(UsePopCountInstruction);
 8094   match(Set dst (PopCountL (LoadL mem)));
 8095   effect(TEMP tmp);
 8096   ins_cost(INSN_COST * 13);
 8097 
 8098   format %{ &quot;ldrd   $tmp, $mem\n\t&quot;
 8099             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8100             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8101             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8102   ins_encode %{
 8103     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8104     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, tmp_reg, $mem-&gt;opcode(),
 8105               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 8106     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8107     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8108     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8109   %}
 8110 
 8111   ins_pipe(pipe_class_default);
 8112 %}
 8113 
 8114 // ============================================================================
 8115 // MemBar Instruction
 8116 
 8117 instruct load_fence() %{
 8118   match(LoadFence);
 8119   ins_cost(VOLATILE_REF_COST);
 8120 
 8121   format %{ &quot;load_fence&quot; %}
 8122 
 8123   ins_encode %{
 8124     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8125   %}
 8126   ins_pipe(pipe_serial);
 8127 %}
 8128 
 8129 instruct unnecessary_membar_acquire() %{
 8130   predicate(unnecessary_acquire(n));
 8131   match(MemBarAcquire);
 8132   ins_cost(0);
 8133 
 8134   format %{ &quot;membar_acquire (elided)&quot; %}
 8135 
 8136   ins_encode %{
 8137     __ block_comment(&quot;membar_acquire (elided)&quot;);
 8138   %}
 8139 
 8140   ins_pipe(pipe_class_empty);
 8141 %}
 8142 
 8143 instruct membar_acquire() %{
 8144   match(MemBarAcquire);
 8145   ins_cost(VOLATILE_REF_COST);
 8146 
 8147   format %{ &quot;membar_acquire\n\t&quot;
 8148             &quot;dmb ish&quot; %}
 8149 
 8150   ins_encode %{
 8151     __ block_comment(&quot;membar_acquire&quot;);
 8152     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8153   %}
 8154 
 8155   ins_pipe(pipe_serial);
 8156 %}
 8157 
 8158 
 8159 instruct membar_acquire_lock() %{
 8160   match(MemBarAcquireLock);
 8161   ins_cost(VOLATILE_REF_COST);
 8162 
 8163   format %{ &quot;membar_acquire_lock (elided)&quot; %}
 8164 
 8165   ins_encode %{
 8166     __ block_comment(&quot;membar_acquire_lock (elided)&quot;);
 8167   %}
 8168 
 8169   ins_pipe(pipe_serial);
 8170 %}
 8171 
 8172 instruct store_fence() %{
 8173   match(StoreFence);
 8174   ins_cost(VOLATILE_REF_COST);
 8175 
 8176   format %{ &quot;store_fence&quot; %}
 8177 
 8178   ins_encode %{
 8179     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8180   %}
 8181   ins_pipe(pipe_serial);
 8182 %}
 8183 
 8184 instruct unnecessary_membar_release() %{
 8185   predicate(unnecessary_release(n));
 8186   match(MemBarRelease);
 8187   ins_cost(0);
 8188 
 8189   format %{ &quot;membar_release (elided)&quot; %}
 8190 
 8191   ins_encode %{
 8192     __ block_comment(&quot;membar_release (elided)&quot;);
 8193   %}
 8194   ins_pipe(pipe_serial);
 8195 %}
 8196 
 8197 instruct membar_release() %{
 8198   match(MemBarRelease);
 8199   ins_cost(VOLATILE_REF_COST);
 8200 
 8201   format %{ &quot;membar_release\n\t&quot;
 8202             &quot;dmb ish&quot; %}
 8203 
 8204   ins_encode %{
 8205     __ block_comment(&quot;membar_release&quot;);
 8206     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8207   %}
 8208   ins_pipe(pipe_serial);
 8209 %}
 8210 
 8211 instruct membar_storestore() %{
 8212   match(MemBarStoreStore);
 8213   ins_cost(VOLATILE_REF_COST);
 8214 
 8215   format %{ &quot;MEMBAR-store-store&quot; %}
 8216 
 8217   ins_encode %{
 8218     __ membar(Assembler::StoreStore);
 8219   %}
 8220   ins_pipe(pipe_serial);
 8221 %}
 8222 
 8223 instruct membar_release_lock() %{
 8224   match(MemBarReleaseLock);
 8225   ins_cost(VOLATILE_REF_COST);
 8226 
 8227   format %{ &quot;membar_release_lock (elided)&quot; %}
 8228 
 8229   ins_encode %{
 8230     __ block_comment(&quot;membar_release_lock (elided)&quot;);
 8231   %}
 8232 
 8233   ins_pipe(pipe_serial);
 8234 %}
 8235 
 8236 instruct unnecessary_membar_volatile() %{
 8237   predicate(unnecessary_volatile(n));
 8238   match(MemBarVolatile);
 8239   ins_cost(0);
 8240 
 8241   format %{ &quot;membar_volatile (elided)&quot; %}
 8242 
 8243   ins_encode %{
 8244     __ block_comment(&quot;membar_volatile (elided)&quot;);
 8245   %}
 8246 
 8247   ins_pipe(pipe_serial);
 8248 %}
 8249 
 8250 instruct membar_volatile() %{
 8251   match(MemBarVolatile);
 8252   ins_cost(VOLATILE_REF_COST*100);
 8253 
 8254   format %{ &quot;membar_volatile\n\t&quot;
 8255              &quot;dmb ish&quot;%}
 8256 
 8257   ins_encode %{
 8258     __ block_comment(&quot;membar_volatile&quot;);
 8259     __ membar(Assembler::StoreLoad);
 8260   %}
 8261 
 8262   ins_pipe(pipe_serial);
 8263 %}
 8264 
 8265 // ============================================================================
 8266 // Cast/Convert Instructions
 8267 
 8268 instruct castX2P(iRegPNoSp dst, iRegL src) %{
 8269   match(Set dst (CastX2P src));
 8270 
 8271   ins_cost(INSN_COST);
 8272   format %{ &quot;mov $dst, $src\t# long -&gt; ptr&quot; %}
 8273 
 8274   ins_encode %{
 8275     if ($dst$$reg != $src$$reg) {
 8276       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8277     }
 8278   %}
 8279 
 8280   ins_pipe(ialu_reg);
 8281 %}
 8282 
 8283 instruct castP2X(iRegLNoSp dst, iRegP src) %{
 8284   match(Set dst (CastP2X src));
 8285 
 8286   ins_cost(INSN_COST);
 8287   format %{ &quot;mov $dst, $src\t# ptr -&gt; long&quot; %}
 8288 
 8289   ins_encode %{
 8290     if ($dst$$reg != $src$$reg) {
 8291       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8292     }
 8293   %}
 8294 
 8295   ins_pipe(ialu_reg);
 8296 %}
 8297 
 8298 // Convert oop into int for vectors alignment masking
 8299 instruct convP2I(iRegINoSp dst, iRegP src) %{
 8300   match(Set dst (ConvL2I (CastP2X src)));
 8301 
 8302   ins_cost(INSN_COST);
 8303   format %{ &quot;movw $dst, $src\t# ptr -&gt; int&quot; %}
 8304   ins_encode %{
 8305     __ movw($dst$$Register, $src$$Register);
 8306   %}
 8307 
 8308   ins_pipe(ialu_reg);
 8309 %}
 8310 
 8311 // Convert compressed oop into int for vectors alignment masking
 8312 // in case of 32bit oops (heap &lt; 4Gb).
 8313 instruct convN2I(iRegINoSp dst, iRegN src)
 8314 %{
 8315   predicate(CompressedOops::shift() == 0);
 8316   match(Set dst (ConvL2I (CastP2X (DecodeN src))));
 8317 
 8318   ins_cost(INSN_COST);
 8319   format %{ &quot;mov dst, $src\t# compressed ptr -&gt; int&quot; %}
 8320   ins_encode %{
 8321     __ movw($dst$$Register, $src$$Register);
 8322   %}
 8323 
 8324   ins_pipe(ialu_reg);
 8325 %}
 8326 
 8327 
 8328 // Convert oop pointer into compressed form
 8329 instruct encodeHeapOop(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8330   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() != TypePtr::NotNull);
 8331   match(Set dst (EncodeP src));
 8332   effect(KILL cr);
 8333   ins_cost(INSN_COST * 3);
 8334   format %{ &quot;encode_heap_oop $dst, $src&quot; %}
 8335   ins_encode %{
 8336     Register s = $src$$Register;
 8337     Register d = $dst$$Register;
 8338     __ encode_heap_oop(d, s);
 8339   %}
 8340   ins_pipe(ialu_reg);
 8341 %}
 8342 
 8343 instruct encodeHeapOop_not_null(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8344   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() == TypePtr::NotNull);
 8345   match(Set dst (EncodeP src));
 8346   ins_cost(INSN_COST * 3);
 8347   format %{ &quot;encode_heap_oop_not_null $dst, $src&quot; %}
 8348   ins_encode %{
 8349     __ encode_heap_oop_not_null($dst$$Register, $src$$Register);
 8350   %}
 8351   ins_pipe(ialu_reg);
 8352 %}
 8353 
 8354 instruct decodeHeapOop(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8355   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::NotNull &amp;&amp;
 8356             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::Constant);
 8357   match(Set dst (DecodeN src));
 8358   ins_cost(INSN_COST * 3);
 8359   format %{ &quot;decode_heap_oop $dst, $src&quot; %}
 8360   ins_encode %{
 8361     Register s = $src$$Register;
 8362     Register d = $dst$$Register;
 8363     __ decode_heap_oop(d, s);
 8364   %}
 8365   ins_pipe(ialu_reg);
 8366 %}
 8367 
 8368 instruct decodeHeapOop_not_null(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8369   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::NotNull ||
 8370             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::Constant);
 8371   match(Set dst (DecodeN src));
 8372   ins_cost(INSN_COST * 3);
 8373   format %{ &quot;decode_heap_oop_not_null $dst, $src&quot; %}
 8374   ins_encode %{
 8375     Register s = $src$$Register;
 8376     Register d = $dst$$Register;
 8377     __ decode_heap_oop_not_null(d, s);
 8378   %}
 8379   ins_pipe(ialu_reg);
 8380 %}
 8381 
 8382 // n.b. AArch64 implementations of encode_klass_not_null and
 8383 // decode_klass_not_null do not modify the flags register so, unlike
 8384 // Intel, we don&#39;t kill CR as a side effect here
 8385 
 8386 instruct encodeKlass_not_null(iRegNNoSp dst, iRegP src) %{
 8387   match(Set dst (EncodePKlass src));
 8388 
 8389   ins_cost(INSN_COST * 3);
 8390   format %{ &quot;encode_klass_not_null $dst,$src&quot; %}
 8391 
 8392   ins_encode %{
 8393     Register src_reg = as_Register($src$$reg);
 8394     Register dst_reg = as_Register($dst$$reg);
 8395     __ encode_klass_not_null(dst_reg, src_reg);
 8396   %}
 8397 
 8398    ins_pipe(ialu_reg);
 8399 %}
 8400 
 8401 instruct decodeKlass_not_null(iRegPNoSp dst, iRegN src) %{
 8402   match(Set dst (DecodeNKlass src));
 8403 
 8404   ins_cost(INSN_COST * 3);
 8405   format %{ &quot;decode_klass_not_null $dst,$src&quot; %}
 8406 
 8407   ins_encode %{
 8408     Register src_reg = as_Register($src$$reg);
 8409     Register dst_reg = as_Register($dst$$reg);
 8410     if (dst_reg != src_reg) {
 8411       __ decode_klass_not_null(dst_reg, src_reg);
 8412     } else {
 8413       __ decode_klass_not_null(dst_reg);
 8414     }
 8415   %}
 8416 
 8417    ins_pipe(ialu_reg);
 8418 %}
 8419 
 8420 instruct checkCastPP(iRegPNoSp dst)
 8421 %{
 8422   match(Set dst (CheckCastPP dst));
 8423 
 8424   size(0);
 8425   format %{ &quot;# checkcastPP of $dst&quot; %}
 8426   ins_encode(/* empty encoding */);
 8427   ins_pipe(pipe_class_empty);
 8428 %}
 8429 
 8430 instruct castPP(iRegPNoSp dst)
 8431 %{
 8432   match(Set dst (CastPP dst));
 8433 
 8434   size(0);
 8435   format %{ &quot;# castPP of $dst&quot; %}
 8436   ins_encode(/* empty encoding */);
 8437   ins_pipe(pipe_class_empty);
 8438 %}
 8439 
 8440 instruct castII(iRegI dst)
 8441 %{
 8442   match(Set dst (CastII dst));
 8443 
 8444   size(0);
 8445   format %{ &quot;# castII of $dst&quot; %}
 8446   ins_encode(/* empty encoding */);
 8447   ins_cost(0);
 8448   ins_pipe(pipe_class_empty);
 8449 %}
 8450 
 8451 // ============================================================================
 8452 // Atomic operation instructions
 8453 //
 8454 // Intel and SPARC both implement Ideal Node LoadPLocked and
 8455 // Store{PIL}Conditional instructions using a normal load for the
 8456 // LoadPLocked and a CAS for the Store{PIL}Conditional.
 8457 //
 8458 // The ideal code appears only to use LoadPLocked/StorePLocked as a
 8459 // pair to lock object allocations from Eden space when not using
 8460 // TLABs.
 8461 //
 8462 // There does not appear to be a Load{IL}Locked Ideal Node and the
 8463 // Ideal code appears to use Store{IL}Conditional as an alias for CAS
 8464 // and to use StoreIConditional only for 32-bit and StoreLConditional
 8465 // only for 64-bit.
 8466 //
 8467 // We implement LoadPLocked and StorePLocked instructions using,
 8468 // respectively the AArch64 hw load-exclusive and store-conditional
 8469 // instructions. Whereas we must implement each of
 8470 // Store{IL}Conditional using a CAS which employs a pair of
 8471 // instructions comprising a load-exclusive followed by a
 8472 // store-conditional.
 8473 
 8474 
 8475 // Locked-load (linked load) of the current heap-top
 8476 // used when updating the eden heap top
 8477 // implemented using ldaxr on AArch64
 8478 
 8479 instruct loadPLocked(iRegPNoSp dst, indirect mem)
 8480 %{
 8481   match(Set dst (LoadPLocked mem));
 8482 
 8483   ins_cost(VOLATILE_REF_COST);
 8484 
 8485   format %{ &quot;ldaxr $dst, $mem\t# ptr linked acquire&quot; %}
 8486 
 8487   ins_encode(aarch64_enc_ldaxr(dst, mem));
 8488 
 8489   ins_pipe(pipe_serial);
 8490 %}
 8491 
 8492 // Conditional-store of the updated heap-top.
 8493 // Used during allocation of the shared heap.
 8494 // Sets flag (EQ) on success.
 8495 // implemented using stlxr on AArch64.
 8496 
 8497 instruct storePConditional(memory8 heap_top_ptr, iRegP oldval, iRegP newval, rFlagsReg cr)
 8498 %{
 8499   match(Set cr (StorePConditional heap_top_ptr (Binary oldval newval)));
 8500 
 8501   ins_cost(VOLATILE_REF_COST);
 8502 
 8503  // TODO
 8504  // do we need to do a store-conditional release or can we just use a
 8505  // plain store-conditional?
 8506 
 8507   format %{
 8508     &quot;stlxr rscratch1, $newval, $heap_top_ptr\t# ptr cond release&quot;
 8509     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8510   %}
 8511 
 8512   ins_encode(aarch64_enc_stlxr(newval, heap_top_ptr));
 8513 
 8514   ins_pipe(pipe_serial);
 8515 %}
 8516 
 8517 
 8518 // storeLConditional is used by PhaseMacroExpand::expand_lock_node
 8519 // when attempting to rebias a lock towards the current thread.  We
 8520 // must use the acquire form of cmpxchg in order to guarantee acquire
 8521 // semantics in this case.
 8522 instruct storeLConditional(indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr)
 8523 %{
 8524   match(Set cr (StoreLConditional mem (Binary oldval newval)));
 8525 
 8526   ins_cost(VOLATILE_REF_COST);
 8527 
 8528   format %{
 8529     &quot;cmpxchg rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8530     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8531   %}
 8532 
 8533   ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval));
 8534 
 8535   ins_pipe(pipe_slow);
 8536 %}
 8537 
 8538 // storeIConditional also has acquire semantics, for no better reason
 8539 // than matching storeLConditional.  At the time of writing this
 8540 // comment storeIConditional was not used anywhere by AArch64.
 8541 instruct storeIConditional(indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr)
 8542 %{
 8543   match(Set cr (StoreIConditional mem (Binary oldval newval)));
 8544 
 8545   ins_cost(VOLATILE_REF_COST);
 8546 
 8547   format %{
 8548     &quot;cmpxchgw rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8549     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8550   %}
 8551 
 8552   ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval));
 8553 
 8554   ins_pipe(pipe_slow);
 8555 %}
 8556 
 8557 // standard CompareAndSwapX when we are using barriers
 8558 // these have higher priority than the rules selected by a predicate
 8559 
 8560 // XXX No flag versions for CompareAndSwap{I,L,P,N} because matcher
 8561 // can&#39;t match them
 8562 
 8563 instruct compareAndSwapB(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8564 
 8565   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8566   ins_cost(2 * VOLATILE_REF_COST);
 8567 
 8568   effect(KILL cr);
 8569 
 8570   format %{
 8571     &quot;cmpxchgb $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8572     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8573   %}
 8574 
 8575   ins_encode(aarch64_enc_cmpxchgb(mem, oldval, newval),
 8576             aarch64_enc_cset_eq(res));
 8577 
 8578   ins_pipe(pipe_slow);
 8579 %}
 8580 
 8581 instruct compareAndSwapS(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8582 
 8583   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8584   ins_cost(2 * VOLATILE_REF_COST);
 8585 
 8586   effect(KILL cr);
 8587 
 8588   format %{
 8589     &quot;cmpxchgs $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8590     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8591   %}
 8592 
 8593   ins_encode(aarch64_enc_cmpxchgs(mem, oldval, newval),
 8594             aarch64_enc_cset_eq(res));
 8595 
 8596   ins_pipe(pipe_slow);
 8597 %}
 8598 
 8599 instruct compareAndSwapI(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8600 
 8601   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8602   ins_cost(2 * VOLATILE_REF_COST);
 8603 
 8604   effect(KILL cr);
 8605 
 8606  format %{
 8607     &quot;cmpxchgw $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8608     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8609  %}
 8610 
 8611  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8612             aarch64_enc_cset_eq(res));
 8613 
 8614   ins_pipe(pipe_slow);
 8615 %}
 8616 
 8617 instruct compareAndSwapL(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8618 
 8619   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8620   ins_cost(2 * VOLATILE_REF_COST);
 8621 
 8622   effect(KILL cr);
 8623 
 8624  format %{
 8625     &quot;cmpxchg $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8626     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8627  %}
 8628 
 8629  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8630             aarch64_enc_cset_eq(res));
 8631 
 8632   ins_pipe(pipe_slow);
 8633 %}
 8634 
 8635 instruct compareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8636 
 8637   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8638   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8639   ins_cost(2 * VOLATILE_REF_COST);
 8640 
 8641   effect(KILL cr);
 8642 
 8643  format %{
 8644     &quot;cmpxchg $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8645     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8646  %}
 8647 
 8648  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8649             aarch64_enc_cset_eq(res));
 8650 
 8651   ins_pipe(pipe_slow);
 8652 %}
 8653 
 8654 instruct compareAndSwapN(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8655 
 8656   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8657   ins_cost(2 * VOLATILE_REF_COST);
 8658 
 8659   effect(KILL cr);
 8660 
 8661  format %{
 8662     &quot;cmpxchgw $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8663     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8664  %}
 8665 
 8666  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8667             aarch64_enc_cset_eq(res));
 8668 
 8669   ins_pipe(pipe_slow);
 8670 %}
 8671 
 8672 // alternative CompareAndSwapX when we are eliding barriers
 8673 
 8674 instruct compareAndSwapBAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8675 
 8676   predicate(needs_acquiring_load_exclusive(n));
 8677   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8678   ins_cost(VOLATILE_REF_COST);
 8679 
 8680   effect(KILL cr);
 8681 
 8682   format %{
 8683     &quot;cmpxchgb_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8684     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8685   %}
 8686 
 8687   ins_encode(aarch64_enc_cmpxchgb_acq(mem, oldval, newval),
 8688             aarch64_enc_cset_eq(res));
 8689 
 8690   ins_pipe(pipe_slow);
 8691 %}
 8692 
 8693 instruct compareAndSwapSAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8694 
 8695   predicate(needs_acquiring_load_exclusive(n));
 8696   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8697   ins_cost(VOLATILE_REF_COST);
 8698 
 8699   effect(KILL cr);
 8700 
 8701   format %{
 8702     &quot;cmpxchgs_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8703     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8704   %}
 8705 
 8706   ins_encode(aarch64_enc_cmpxchgs_acq(mem, oldval, newval),
 8707             aarch64_enc_cset_eq(res));
 8708 
 8709   ins_pipe(pipe_slow);
 8710 %}
 8711 
 8712 instruct compareAndSwapIAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8713 
 8714   predicate(needs_acquiring_load_exclusive(n));
 8715   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8716   ins_cost(VOLATILE_REF_COST);
 8717 
 8718   effect(KILL cr);
 8719 
 8720  format %{
 8721     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8722     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8723  %}
 8724 
 8725  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8726             aarch64_enc_cset_eq(res));
 8727 
 8728   ins_pipe(pipe_slow);
 8729 %}
 8730 
 8731 instruct compareAndSwapLAcq(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8732 
 8733   predicate(needs_acquiring_load_exclusive(n));
 8734   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8735   ins_cost(VOLATILE_REF_COST);
 8736 
 8737   effect(KILL cr);
 8738 
 8739  format %{
 8740     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8741     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8742  %}
 8743 
 8744  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8745             aarch64_enc_cset_eq(res));
 8746 
 8747   ins_pipe(pipe_slow);
 8748 %}
 8749 
 8750 instruct compareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8751 
 8752   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 8753   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8754   ins_cost(VOLATILE_REF_COST);
 8755 
 8756   effect(KILL cr);
 8757 
 8758  format %{
 8759     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8760     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8761  %}
 8762 
 8763  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8764             aarch64_enc_cset_eq(res));
 8765 
 8766   ins_pipe(pipe_slow);
 8767 %}
 8768 
 8769 instruct compareAndSwapNAcq(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8770 
 8771   predicate(needs_acquiring_load_exclusive(n));
 8772   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8773   ins_cost(VOLATILE_REF_COST);
 8774 
 8775   effect(KILL cr);
 8776 
 8777  format %{
 8778     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8779     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8780  %}
 8781 
 8782  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8783             aarch64_enc_cset_eq(res));
 8784 
 8785   ins_pipe(pipe_slow);
 8786 %}
 8787 
 8788 
 8789 // ---------------------------------------------------------------------
 8790 
 8791 
 8792 // BEGIN This section of the file is automatically generated. Do not edit --------------
 8793 
 8794 // Sundry CAS operations.  Note that release is always true,
 8795 // regardless of the memory ordering of the CAS.  This is because we
 8796 // need the volatile case to be sequentially consistent but there is
 8797 // no trailing StoreLoad barrier emitted by C2.  Unfortunately we
 8798 // can&#39;t check the type of memory ordering here, so we always emit a
 8799 // STLXR.
 8800 
 8801 // This section is generated from aarch64_ad_cas.m4
 8802 
 8803 
 8804 
 8805 instruct compareAndExchangeB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8806   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8807   ins_cost(2 * VOLATILE_REF_COST);
 8808   effect(TEMP_DEF res, KILL cr);
 8809   format %{
 8810     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8811   %}
 8812   ins_encode %{
 8813     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8814                Assembler::byte, /*acquire*/ false, /*release*/ true,
 8815                /*weak*/ false, $res$$Register);
 8816     __ sxtbw($res$$Register, $res$$Register);
 8817   %}
 8818   ins_pipe(pipe_slow);
 8819 %}
 8820 
 8821 instruct compareAndExchangeS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8822   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8823   ins_cost(2 * VOLATILE_REF_COST);
 8824   effect(TEMP_DEF res, KILL cr);
 8825   format %{
 8826     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8827   %}
 8828   ins_encode %{
 8829     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8830                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 8831                /*weak*/ false, $res$$Register);
 8832     __ sxthw($res$$Register, $res$$Register);
 8833   %}
 8834   ins_pipe(pipe_slow);
 8835 %}
 8836 
 8837 instruct compareAndExchangeI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8838   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8839   ins_cost(2 * VOLATILE_REF_COST);
 8840   effect(TEMP_DEF res, KILL cr);
 8841   format %{
 8842     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8843   %}
 8844   ins_encode %{
 8845     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8846                Assembler::word, /*acquire*/ false, /*release*/ true,
 8847                /*weak*/ false, $res$$Register);
 8848   %}
 8849   ins_pipe(pipe_slow);
 8850 %}
 8851 
 8852 instruct compareAndExchangeL(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8853   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8854   ins_cost(2 * VOLATILE_REF_COST);
 8855   effect(TEMP_DEF res, KILL cr);
 8856   format %{
 8857     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8858   %}
 8859   ins_encode %{
 8860     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8861                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8862                /*weak*/ false, $res$$Register);
 8863   %}
 8864   ins_pipe(pipe_slow);
 8865 %}
 8866 
 8867 instruct compareAndExchangeN(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8868   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8869   ins_cost(2 * VOLATILE_REF_COST);
 8870   effect(TEMP_DEF res, KILL cr);
 8871   format %{
 8872     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8873   %}
 8874   ins_encode %{
 8875     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8876                Assembler::word, /*acquire*/ false, /*release*/ true,
 8877                /*weak*/ false, $res$$Register);
 8878   %}
 8879   ins_pipe(pipe_slow);
 8880 %}
 8881 
 8882 instruct compareAndExchangeP(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8883   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8884   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 8885   ins_cost(2 * VOLATILE_REF_COST);
 8886   effect(TEMP_DEF res, KILL cr);
 8887   format %{
 8888     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8889   %}
 8890   ins_encode %{
 8891     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8892                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8893                /*weak*/ false, $res$$Register);
 8894   %}
 8895   ins_pipe(pipe_slow);
 8896 %}
 8897 
 8898 instruct compareAndExchangeBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8899   predicate(needs_acquiring_load_exclusive(n));
 8900   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8901   ins_cost(VOLATILE_REF_COST);
 8902   effect(TEMP_DEF res, KILL cr);
 8903   format %{
 8904     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8905   %}
 8906   ins_encode %{
 8907     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8908                Assembler::byte, /*acquire*/ true, /*release*/ true,
 8909                /*weak*/ false, $res$$Register);
 8910     __ sxtbw($res$$Register, $res$$Register);
 8911   %}
 8912   ins_pipe(pipe_slow);
 8913 %}
 8914 
 8915 instruct compareAndExchangeSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8916   predicate(needs_acquiring_load_exclusive(n));
 8917   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8918   ins_cost(VOLATILE_REF_COST);
 8919   effect(TEMP_DEF res, KILL cr);
 8920   format %{
 8921     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8922   %}
 8923   ins_encode %{
 8924     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8925                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 8926                /*weak*/ false, $res$$Register);
 8927     __ sxthw($res$$Register, $res$$Register);
 8928   %}
 8929   ins_pipe(pipe_slow);
 8930 %}
 8931 
 8932 
 8933 instruct compareAndExchangeIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8934   predicate(needs_acquiring_load_exclusive(n));
 8935   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8936   ins_cost(VOLATILE_REF_COST);
 8937   effect(TEMP_DEF res, KILL cr);
 8938   format %{
 8939     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8940   %}
 8941   ins_encode %{
 8942     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8943                Assembler::word, /*acquire*/ true, /*release*/ true,
 8944                /*weak*/ false, $res$$Register);
 8945   %}
 8946   ins_pipe(pipe_slow);
 8947 %}
 8948 
 8949 instruct compareAndExchangeLAcq(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8950   predicate(needs_acquiring_load_exclusive(n));
 8951   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8952   ins_cost(VOLATILE_REF_COST);
 8953   effect(TEMP_DEF res, KILL cr);
 8954   format %{
 8955     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8956   %}
 8957   ins_encode %{
 8958     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8959                Assembler::xword, /*acquire*/ true, /*release*/ true,
 8960                /*weak*/ false, $res$$Register);
 8961   %}
 8962   ins_pipe(pipe_slow);
 8963 %}
 8964 
 8965 
 8966 instruct compareAndExchangeNAcq(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8967   predicate(needs_acquiring_load_exclusive(n));
 8968   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8969   ins_cost(VOLATILE_REF_COST);
 8970   effect(TEMP_DEF res, KILL cr);
 8971   format %{
 8972     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8973   %}
 8974   ins_encode %{
 8975     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8976                Assembler::word, /*acquire*/ true, /*release*/ true,
 8977                /*weak*/ false, $res$$Register);
 8978   %}
 8979   ins_pipe(pipe_slow);
 8980 %}
 8981 
 8982 instruct compareAndExchangePAcq(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8983   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 8984   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 8985   ins_cost(VOLATILE_REF_COST);
 8986   effect(TEMP_DEF res, KILL cr);
 8987   format %{
 8988     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8989   %}
 8990   ins_encode %{
 8991     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8992                Assembler::xword, /*acquire*/ true, /*release*/ true,
 8993                /*weak*/ false, $res$$Register);
 8994   %}
 8995   ins_pipe(pipe_slow);
 8996 %}
 8997 
 8998 instruct weakCompareAndSwapB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8999   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9000   ins_cost(2 * VOLATILE_REF_COST);
 9001   effect(KILL cr);
 9002   format %{
 9003     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9004     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9005   %}
 9006   ins_encode %{
 9007     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9008                Assembler::byte, /*acquire*/ false, /*release*/ true,
 9009                /*weak*/ true, noreg);
 9010     __ csetw($res$$Register, Assembler::EQ);
 9011   %}
 9012   ins_pipe(pipe_slow);
 9013 %}
 9014 
 9015 instruct weakCompareAndSwapS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9016   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9017   ins_cost(2 * VOLATILE_REF_COST);
 9018   effect(KILL cr);
 9019   format %{
 9020     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9021     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9022   %}
 9023   ins_encode %{
 9024     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9025                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 9026                /*weak*/ true, noreg);
 9027     __ csetw($res$$Register, Assembler::EQ);
 9028   %}
 9029   ins_pipe(pipe_slow);
 9030 %}
 9031 
 9032 instruct weakCompareAndSwapI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9033   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9034   ins_cost(2 * VOLATILE_REF_COST);
 9035   effect(KILL cr);
 9036   format %{
 9037     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9038     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9039   %}
 9040   ins_encode %{
 9041     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9042                Assembler::word, /*acquire*/ false, /*release*/ true,
 9043                /*weak*/ true, noreg);
 9044     __ csetw($res$$Register, Assembler::EQ);
 9045   %}
 9046   ins_pipe(pipe_slow);
 9047 %}
 9048 
 9049 instruct weakCompareAndSwapL(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9050   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9051   ins_cost(2 * VOLATILE_REF_COST);
 9052   effect(KILL cr);
 9053   format %{
 9054     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9055     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9056   %}
 9057   ins_encode %{
 9058     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9059                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9060                /*weak*/ true, noreg);
 9061     __ csetw($res$$Register, Assembler::EQ);
 9062   %}
 9063   ins_pipe(pipe_slow);
 9064 %}
 9065 
 9066 instruct weakCompareAndSwapN(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9067   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9068   ins_cost(2 * VOLATILE_REF_COST);
 9069   effect(KILL cr);
 9070   format %{
 9071     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9072     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9073   %}
 9074   ins_encode %{
 9075     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9076                Assembler::word, /*acquire*/ false, /*release*/ true,
 9077                /*weak*/ true, noreg);
 9078     __ csetw($res$$Register, Assembler::EQ);
 9079   %}
 9080   ins_pipe(pipe_slow);
 9081 %}
 9082 
 9083 instruct weakCompareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9084   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9085   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9086   ins_cost(2 * VOLATILE_REF_COST);
 9087   effect(KILL cr);
 9088   format %{
 9089     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9090     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9091   %}
 9092   ins_encode %{
 9093     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9094                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9095                /*weak*/ true, noreg);
 9096     __ csetw($res$$Register, Assembler::EQ);
 9097   %}
 9098   ins_pipe(pipe_slow);
 9099 %}
 9100 
 9101 instruct weakCompareAndSwapBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9102   predicate(needs_acquiring_load_exclusive(n));
 9103   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9104   ins_cost(VOLATILE_REF_COST);
 9105   effect(KILL cr);
 9106   format %{
 9107     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9108     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9109   %}
 9110   ins_encode %{
 9111     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9112                Assembler::byte, /*acquire*/ true, /*release*/ true,
 9113                /*weak*/ true, noreg);
 9114     __ csetw($res$$Register, Assembler::EQ);
 9115   %}
 9116   ins_pipe(pipe_slow);
 9117 %}
 9118 
 9119 instruct weakCompareAndSwapSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9120   predicate(needs_acquiring_load_exclusive(n));
 9121   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9122   ins_cost(VOLATILE_REF_COST);
 9123   effect(KILL cr);
 9124   format %{
 9125     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9126     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9127   %}
 9128   ins_encode %{
 9129     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9130                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 9131                /*weak*/ true, noreg);
 9132     __ csetw($res$$Register, Assembler::EQ);
 9133   %}
 9134   ins_pipe(pipe_slow);
 9135 %}
 9136 
 9137 instruct weakCompareAndSwapIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9138   predicate(needs_acquiring_load_exclusive(n));
 9139   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9140   ins_cost(VOLATILE_REF_COST);
 9141   effect(KILL cr);
 9142   format %{
 9143     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9144     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9145   %}
 9146   ins_encode %{
 9147     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9148                Assembler::word, /*acquire*/ true, /*release*/ true,
 9149                /*weak*/ true, noreg);
 9150     __ csetw($res$$Register, Assembler::EQ);
 9151   %}
 9152   ins_pipe(pipe_slow);
 9153 %}
 9154 
 9155 instruct weakCompareAndSwapLAcq(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9156   predicate(needs_acquiring_load_exclusive(n));
 9157   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9158   ins_cost(VOLATILE_REF_COST);
 9159   effect(KILL cr);
 9160   format %{
 9161     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9162     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9163   %}
 9164   ins_encode %{
 9165     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9166                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9167                /*weak*/ true, noreg);
 9168     __ csetw($res$$Register, Assembler::EQ);
 9169   %}
 9170   ins_pipe(pipe_slow);
 9171 %}
 9172 
 9173 instruct weakCompareAndSwapNAcq(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9174   predicate(needs_acquiring_load_exclusive(n));
 9175   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9176   ins_cost(VOLATILE_REF_COST);
 9177   effect(KILL cr);
 9178   format %{
 9179     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9180     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9181   %}
 9182   ins_encode %{
 9183     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9184                Assembler::word, /*acquire*/ true, /*release*/ true,
 9185                /*weak*/ true, noreg);
 9186     __ csetw($res$$Register, Assembler::EQ);
 9187   %}
 9188   ins_pipe(pipe_slow);
 9189 %}
 9190 
 9191 instruct weakCompareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9192   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9193   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9194   ins_cost(VOLATILE_REF_COST);
 9195   effect(KILL cr);
 9196   format %{
 9197     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9198     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9199   %}
 9200   ins_encode %{
 9201     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9202                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9203                /*weak*/ true, noreg);
 9204     __ csetw($res$$Register, Assembler::EQ);
 9205   %}
 9206   ins_pipe(pipe_slow);
 9207 %}
 9208 
 9209 // END This section of the file is automatically generated. Do not edit --------------
 9210 // ---------------------------------------------------------------------
 9211 
 9212 instruct get_and_setI(indirect mem, iRegI newv, iRegINoSp prev) %{
 9213   match(Set prev (GetAndSetI mem newv));
 9214   ins_cost(2 * VOLATILE_REF_COST);
 9215   format %{ &quot;atomic_xchgw  $prev, $newv, [$mem]&quot; %}
 9216   ins_encode %{
 9217     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9218   %}
 9219   ins_pipe(pipe_serial);
 9220 %}
 9221 
 9222 instruct get_and_setL(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9223   match(Set prev (GetAndSetL mem newv));
 9224   ins_cost(2 * VOLATILE_REF_COST);
 9225   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9226   ins_encode %{
 9227     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9228   %}
 9229   ins_pipe(pipe_serial);
 9230 %}
 9231 
 9232 instruct get_and_setN(indirect mem, iRegN newv, iRegINoSp prev) %{
 9233   match(Set prev (GetAndSetN mem newv));
 9234   ins_cost(2 * VOLATILE_REF_COST);
 9235   format %{ &quot;atomic_xchgw $prev, $newv, [$mem]&quot; %}
 9236   ins_encode %{
 9237     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9238   %}
 9239   ins_pipe(pipe_serial);
 9240 %}
 9241 
 9242 instruct get_and_setP(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9243   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9244   match(Set prev (GetAndSetP mem newv));
 9245   ins_cost(2 * VOLATILE_REF_COST);
 9246   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9247   ins_encode %{
 9248     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9249   %}
 9250   ins_pipe(pipe_serial);
 9251 %}
 9252 
 9253 instruct get_and_setIAcq(indirect mem, iRegI newv, iRegINoSp prev) %{
 9254   predicate(needs_acquiring_load_exclusive(n));
 9255   match(Set prev (GetAndSetI mem newv));
 9256   ins_cost(VOLATILE_REF_COST);
 9257   format %{ &quot;atomic_xchgw_acq  $prev, $newv, [$mem]&quot; %}
 9258   ins_encode %{
 9259     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9260   %}
 9261   ins_pipe(pipe_serial);
 9262 %}
 9263 
 9264 instruct get_and_setLAcq(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9265   predicate(needs_acquiring_load_exclusive(n));
 9266   match(Set prev (GetAndSetL mem newv));
 9267   ins_cost(VOLATILE_REF_COST);
 9268   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9269   ins_encode %{
 9270     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9271   %}
 9272   ins_pipe(pipe_serial);
 9273 %}
 9274 
 9275 instruct get_and_setNAcq(indirect mem, iRegN newv, iRegINoSp prev) %{
 9276   predicate(needs_acquiring_load_exclusive(n));
 9277   match(Set prev (GetAndSetN mem newv));
 9278   ins_cost(VOLATILE_REF_COST);
 9279   format %{ &quot;atomic_xchgw_acq $prev, $newv, [$mem]&quot; %}
 9280   ins_encode %{
 9281     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9282   %}
 9283   ins_pipe(pipe_serial);
 9284 %}
 9285 
 9286 instruct get_and_setPAcq(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9287   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9288   match(Set prev (GetAndSetP mem newv));
 9289   ins_cost(VOLATILE_REF_COST);
 9290   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9291   ins_encode %{
 9292     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9293   %}
 9294   ins_pipe(pipe_serial);
 9295 %}
 9296 
 9297 
 9298 instruct get_and_addL(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9299   match(Set newval (GetAndAddL mem incr));
 9300   ins_cost(2 * VOLATILE_REF_COST + 1);
 9301   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9302   ins_encode %{
 9303     __ atomic_add($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9304   %}
 9305   ins_pipe(pipe_serial);
 9306 %}
 9307 
 9308 instruct get_and_addL_no_res(indirect mem, Universe dummy, iRegL incr) %{
 9309   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9310   match(Set dummy (GetAndAddL mem incr));
 9311   ins_cost(2 * VOLATILE_REF_COST);
 9312   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9313   ins_encode %{
 9314     __ atomic_add(noreg, $incr$$Register, as_Register($mem$$base));
 9315   %}
 9316   ins_pipe(pipe_serial);
 9317 %}
 9318 
 9319 instruct get_and_addLi(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9320   match(Set newval (GetAndAddL mem incr));
 9321   ins_cost(2 * VOLATILE_REF_COST + 1);
 9322   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9323   ins_encode %{
 9324     __ atomic_add($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9325   %}
 9326   ins_pipe(pipe_serial);
 9327 %}
 9328 
 9329 instruct get_and_addLi_no_res(indirect mem, Universe dummy, immLAddSub incr) %{
 9330   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9331   match(Set dummy (GetAndAddL mem incr));
 9332   ins_cost(2 * VOLATILE_REF_COST);
 9333   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9334   ins_encode %{
 9335     __ atomic_add(noreg, $incr$$constant, as_Register($mem$$base));
 9336   %}
 9337   ins_pipe(pipe_serial);
 9338 %}
 9339 
 9340 instruct get_and_addI(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9341   match(Set newval (GetAndAddI mem incr));
 9342   ins_cost(2 * VOLATILE_REF_COST + 1);
 9343   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9344   ins_encode %{
 9345     __ atomic_addw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9346   %}
 9347   ins_pipe(pipe_serial);
 9348 %}
 9349 
 9350 instruct get_and_addI_no_res(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9351   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9352   match(Set dummy (GetAndAddI mem incr));
 9353   ins_cost(2 * VOLATILE_REF_COST);
 9354   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9355   ins_encode %{
 9356     __ atomic_addw(noreg, $incr$$Register, as_Register($mem$$base));
 9357   %}
 9358   ins_pipe(pipe_serial);
 9359 %}
 9360 
 9361 instruct get_and_addIi(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9362   match(Set newval (GetAndAddI mem incr));
 9363   ins_cost(2 * VOLATILE_REF_COST + 1);
 9364   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9365   ins_encode %{
 9366     __ atomic_addw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9367   %}
 9368   ins_pipe(pipe_serial);
 9369 %}
 9370 
 9371 instruct get_and_addIi_no_res(indirect mem, Universe dummy, immIAddSub incr) %{
 9372   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9373   match(Set dummy (GetAndAddI mem incr));
 9374   ins_cost(2 * VOLATILE_REF_COST);
 9375   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9376   ins_encode %{
 9377     __ atomic_addw(noreg, $incr$$constant, as_Register($mem$$base));
 9378   %}
 9379   ins_pipe(pipe_serial);
 9380 %}
 9381 
 9382 instruct get_and_addLAcq(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9383   predicate(needs_acquiring_load_exclusive(n));
 9384   match(Set newval (GetAndAddL mem incr));
 9385   ins_cost(VOLATILE_REF_COST + 1);
 9386   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9387   ins_encode %{
 9388     __ atomic_addal($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9389   %}
 9390   ins_pipe(pipe_serial);
 9391 %}
 9392 
 9393 instruct get_and_addL_no_resAcq(indirect mem, Universe dummy, iRegL incr) %{
 9394   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9395   match(Set dummy (GetAndAddL mem incr));
 9396   ins_cost(VOLATILE_REF_COST);
 9397   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9398   ins_encode %{
 9399     __ atomic_addal(noreg, $incr$$Register, as_Register($mem$$base));
 9400   %}
 9401   ins_pipe(pipe_serial);
 9402 %}
 9403 
 9404 instruct get_and_addLiAcq(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9405   predicate(needs_acquiring_load_exclusive(n));
 9406   match(Set newval (GetAndAddL mem incr));
 9407   ins_cost(VOLATILE_REF_COST + 1);
 9408   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9409   ins_encode %{
 9410     __ atomic_addal($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9411   %}
 9412   ins_pipe(pipe_serial);
 9413 %}
 9414 
 9415 instruct get_and_addLi_no_resAcq(indirect mem, Universe dummy, immLAddSub incr) %{
 9416   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9417   match(Set dummy (GetAndAddL mem incr));
 9418   ins_cost(VOLATILE_REF_COST);
 9419   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9420   ins_encode %{
 9421     __ atomic_addal(noreg, $incr$$constant, as_Register($mem$$base));
 9422   %}
 9423   ins_pipe(pipe_serial);
 9424 %}
 9425 
 9426 instruct get_and_addIAcq(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9427   predicate(needs_acquiring_load_exclusive(n));
 9428   match(Set newval (GetAndAddI mem incr));
 9429   ins_cost(VOLATILE_REF_COST + 1);
 9430   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9431   ins_encode %{
 9432     __ atomic_addalw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9433   %}
 9434   ins_pipe(pipe_serial);
 9435 %}
 9436 
 9437 instruct get_and_addI_no_resAcq(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9438   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9439   match(Set dummy (GetAndAddI mem incr));
 9440   ins_cost(VOLATILE_REF_COST);
 9441   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9442   ins_encode %{
 9443     __ atomic_addalw(noreg, $incr$$Register, as_Register($mem$$base));
 9444   %}
 9445   ins_pipe(pipe_serial);
 9446 %}
 9447 
 9448 instruct get_and_addIiAcq(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9449   predicate(needs_acquiring_load_exclusive(n));
 9450   match(Set newval (GetAndAddI mem incr));
 9451   ins_cost(VOLATILE_REF_COST + 1);
 9452   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9453   ins_encode %{
 9454     __ atomic_addalw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9455   %}
 9456   ins_pipe(pipe_serial);
 9457 %}
 9458 
 9459 instruct get_and_addIi_no_resAcq(indirect mem, Universe dummy, immIAddSub incr) %{
 9460   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9461   match(Set dummy (GetAndAddI mem incr));
 9462   ins_cost(VOLATILE_REF_COST);
 9463   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9464   ins_encode %{
 9465     __ atomic_addalw(noreg, $incr$$constant, as_Register($mem$$base));
 9466   %}
 9467   ins_pipe(pipe_serial);
 9468 %}
 9469 
 9470 // Manifest a CmpL result in an integer register.
 9471 // (src1 &lt; src2) ? -1 : ((src1 &gt; src2) ? 1 : 0)
 9472 instruct cmpL3_reg_reg(iRegINoSp dst, iRegL src1, iRegL src2, rFlagsReg flags)
 9473 %{
 9474   match(Set dst (CmpL3 src1 src2));
 9475   effect(KILL flags);
 9476 
 9477   ins_cost(INSN_COST * 6);
 9478   format %{
 9479       &quot;cmp $src1, $src2&quot;
 9480       &quot;csetw $dst, ne&quot;
 9481       &quot;cnegw $dst, lt&quot;
 9482   %}
 9483   // format %{ &quot;CmpL3 $dst, $src1, $src2&quot; %}
 9484   ins_encode %{
 9485     __ cmp($src1$$Register, $src2$$Register);
 9486     __ csetw($dst$$Register, Assembler::NE);
 9487     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9488   %}
 9489 
 9490   ins_pipe(pipe_class_default);
 9491 %}
 9492 
 9493 instruct cmpL3_reg_imm(iRegINoSp dst, iRegL src1, immLAddSub src2, rFlagsReg flags)
 9494 %{
 9495   match(Set dst (CmpL3 src1 src2));
 9496   effect(KILL flags);
 9497 
 9498   ins_cost(INSN_COST * 6);
 9499   format %{
 9500       &quot;cmp $src1, $src2&quot;
 9501       &quot;csetw $dst, ne&quot;
 9502       &quot;cnegw $dst, lt&quot;
 9503   %}
 9504   ins_encode %{
 9505     int32_t con = (int32_t)$src2$$constant;
 9506      if (con &lt; 0) {
 9507       __ adds(zr, $src1$$Register, -con);
 9508     } else {
 9509       __ subs(zr, $src1$$Register, con);
 9510     }
 9511     __ csetw($dst$$Register, Assembler::NE);
 9512     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9513   %}
 9514 
 9515   ins_pipe(pipe_class_default);
 9516 %}
 9517 
 9518 // ============================================================================
 9519 // Conditional Move Instructions
 9520 
 9521 // n.b. we have identical rules for both a signed compare op (cmpOp)
 9522 // and an unsigned compare op (cmpOpU). it would be nice if we could
 9523 // define an op class which merged both inputs and use it to type the
 9524 // argument to a single rule. unfortunatelyt his fails because the
 9525 // opclass does not live up to the COND_INTER interface of its
 9526 // component operands. When the generic code tries to negate the
 9527 // operand it ends up running the generci Machoper::negate method
 9528 // which throws a ShouldNotHappen. So, we have to provide two flavours
 9529 // of each rule, one for a cmpOp and a second for a cmpOpU (sigh).
 9530 
 9531 instruct cmovI_reg_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9532   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9533 
 9534   ins_cost(INSN_COST * 2);
 9535   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, int&quot;  %}
 9536 
 9537   ins_encode %{
 9538     __ cselw(as_Register($dst$$reg),
 9539              as_Register($src2$$reg),
 9540              as_Register($src1$$reg),
 9541              (Assembler::Condition)$cmp$$cmpcode);
 9542   %}
 9543 
 9544   ins_pipe(icond_reg_reg);
 9545 %}
 9546 
 9547 instruct cmovUI_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9548   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9549 
 9550   ins_cost(INSN_COST * 2);
 9551   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# unsigned, int&quot;  %}
 9552 
 9553   ins_encode %{
 9554     __ cselw(as_Register($dst$$reg),
 9555              as_Register($src2$$reg),
 9556              as_Register($src1$$reg),
 9557              (Assembler::Condition)$cmp$$cmpcode);
 9558   %}
 9559 
 9560   ins_pipe(icond_reg_reg);
 9561 %}
 9562 
 9563 // special cases where one arg is zero
 9564 
 9565 // n.b. this is selected in preference to the rule above because it
 9566 // avoids loading constant 0 into a source register
 9567 
 9568 // TODO
 9569 // we ought only to be able to cull one of these variants as the ideal
 9570 // transforms ought always to order the zero consistently (to left/right?)
 9571 
 9572 instruct cmovI_zero_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9573   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9574 
 9575   ins_cost(INSN_COST * 2);
 9576   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, int&quot;  %}
 9577 
 9578   ins_encode %{
 9579     __ cselw(as_Register($dst$$reg),
 9580              as_Register($src$$reg),
 9581              zr,
 9582              (Assembler::Condition)$cmp$$cmpcode);
 9583   %}
 9584 
 9585   ins_pipe(icond_reg);
 9586 %}
 9587 
 9588 instruct cmovUI_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9589   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9590 
 9591   ins_cost(INSN_COST * 2);
 9592   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, int&quot;  %}
 9593 
 9594   ins_encode %{
 9595     __ cselw(as_Register($dst$$reg),
 9596              as_Register($src$$reg),
 9597              zr,
 9598              (Assembler::Condition)$cmp$$cmpcode);
 9599   %}
 9600 
 9601   ins_pipe(icond_reg);
 9602 %}
 9603 
 9604 instruct cmovI_reg_zero(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9605   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9606 
 9607   ins_cost(INSN_COST * 2);
 9608   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, int&quot;  %}
 9609 
 9610   ins_encode %{
 9611     __ cselw(as_Register($dst$$reg),
 9612              zr,
 9613              as_Register($src$$reg),
 9614              (Assembler::Condition)$cmp$$cmpcode);
 9615   %}
 9616 
 9617   ins_pipe(icond_reg);
 9618 %}
 9619 
 9620 instruct cmovUI_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9621   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9622 
 9623   ins_cost(INSN_COST * 2);
 9624   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, int&quot;  %}
 9625 
 9626   ins_encode %{
 9627     __ cselw(as_Register($dst$$reg),
 9628              zr,
 9629              as_Register($src$$reg),
 9630              (Assembler::Condition)$cmp$$cmpcode);
 9631   %}
 9632 
 9633   ins_pipe(icond_reg);
 9634 %}
 9635 
 9636 // special case for creating a boolean 0 or 1
 9637 
 9638 // n.b. this is selected in preference to the rule above because it
 9639 // avoids loading constants 0 and 1 into a source register
 9640 
 9641 instruct cmovI_reg_zero_one(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9642   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9643 
 9644   ins_cost(INSN_COST * 2);
 9645   format %{ &quot;csincw $dst, zr, zr $cmp\t# signed, int&quot;  %}
 9646 
 9647   ins_encode %{
 9648     // equivalently
 9649     // cset(as_Register($dst$$reg),
 9650     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9651     __ csincw(as_Register($dst$$reg),
 9652              zr,
 9653              zr,
 9654              (Assembler::Condition)$cmp$$cmpcode);
 9655   %}
 9656 
 9657   ins_pipe(icond_none);
 9658 %}
 9659 
 9660 instruct cmovUI_reg_zero_one(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9661   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9662 
 9663   ins_cost(INSN_COST * 2);
 9664   format %{ &quot;csincw $dst, zr, zr $cmp\t# unsigned, int&quot;  %}
 9665 
 9666   ins_encode %{
 9667     // equivalently
 9668     // cset(as_Register($dst$$reg),
 9669     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9670     __ csincw(as_Register($dst$$reg),
 9671              zr,
 9672              zr,
 9673              (Assembler::Condition)$cmp$$cmpcode);
 9674   %}
 9675 
 9676   ins_pipe(icond_none);
 9677 %}
 9678 
 9679 instruct cmovL_reg_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9680   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9681 
 9682   ins_cost(INSN_COST * 2);
 9683   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, long&quot;  %}
 9684 
 9685   ins_encode %{
 9686     __ csel(as_Register($dst$$reg),
 9687             as_Register($src2$$reg),
 9688             as_Register($src1$$reg),
 9689             (Assembler::Condition)$cmp$$cmpcode);
 9690   %}
 9691 
 9692   ins_pipe(icond_reg_reg);
 9693 %}
 9694 
 9695 instruct cmovUL_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9696   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9697 
 9698   ins_cost(INSN_COST * 2);
 9699   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, long&quot;  %}
 9700 
 9701   ins_encode %{
 9702     __ csel(as_Register($dst$$reg),
 9703             as_Register($src2$$reg),
 9704             as_Register($src1$$reg),
 9705             (Assembler::Condition)$cmp$$cmpcode);
 9706   %}
 9707 
 9708   ins_pipe(icond_reg_reg);
 9709 %}
 9710 
 9711 // special cases where one arg is zero
 9712 
 9713 instruct cmovL_reg_zero(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9714   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9715 
 9716   ins_cost(INSN_COST * 2);
 9717   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, long&quot;  %}
 9718 
 9719   ins_encode %{
 9720     __ csel(as_Register($dst$$reg),
 9721             zr,
 9722             as_Register($src$$reg),
 9723             (Assembler::Condition)$cmp$$cmpcode);
 9724   %}
 9725 
 9726   ins_pipe(icond_reg);
 9727 %}
 9728 
 9729 instruct cmovUL_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9730   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9731 
 9732   ins_cost(INSN_COST * 2);
 9733   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, long&quot;  %}
 9734 
 9735   ins_encode %{
 9736     __ csel(as_Register($dst$$reg),
 9737             zr,
 9738             as_Register($src$$reg),
 9739             (Assembler::Condition)$cmp$$cmpcode);
 9740   %}
 9741 
 9742   ins_pipe(icond_reg);
 9743 %}
 9744 
 9745 instruct cmovL_zero_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9746   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9747 
 9748   ins_cost(INSN_COST * 2);
 9749   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, long&quot;  %}
 9750 
 9751   ins_encode %{
 9752     __ csel(as_Register($dst$$reg),
 9753             as_Register($src$$reg),
 9754             zr,
 9755             (Assembler::Condition)$cmp$$cmpcode);
 9756   %}
 9757 
 9758   ins_pipe(icond_reg);
 9759 %}
 9760 
 9761 instruct cmovUL_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9762   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9763 
 9764   ins_cost(INSN_COST * 2);
 9765   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, long&quot;  %}
 9766 
 9767   ins_encode %{
 9768     __ csel(as_Register($dst$$reg),
 9769             as_Register($src$$reg),
 9770             zr,
 9771             (Assembler::Condition)$cmp$$cmpcode);
 9772   %}
 9773 
 9774   ins_pipe(icond_reg);
 9775 %}
 9776 
 9777 instruct cmovP_reg_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9778   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9779 
 9780   ins_cost(INSN_COST * 2);
 9781   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, ptr&quot;  %}
 9782 
 9783   ins_encode %{
 9784     __ csel(as_Register($dst$$reg),
 9785             as_Register($src2$$reg),
 9786             as_Register($src1$$reg),
 9787             (Assembler::Condition)$cmp$$cmpcode);
 9788   %}
 9789 
 9790   ins_pipe(icond_reg_reg);
 9791 %}
 9792 
 9793 instruct cmovUP_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9794   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9795 
 9796   ins_cost(INSN_COST * 2);
 9797   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, ptr&quot;  %}
 9798 
 9799   ins_encode %{
 9800     __ csel(as_Register($dst$$reg),
 9801             as_Register($src2$$reg),
 9802             as_Register($src1$$reg),
 9803             (Assembler::Condition)$cmp$$cmpcode);
 9804   %}
 9805 
 9806   ins_pipe(icond_reg_reg);
 9807 %}
 9808 
 9809 // special cases where one arg is zero
 9810 
 9811 instruct cmovP_reg_zero(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9812   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9813 
 9814   ins_cost(INSN_COST * 2);
 9815   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, ptr&quot;  %}
 9816 
 9817   ins_encode %{
 9818     __ csel(as_Register($dst$$reg),
 9819             zr,
 9820             as_Register($src$$reg),
 9821             (Assembler::Condition)$cmp$$cmpcode);
 9822   %}
 9823 
 9824   ins_pipe(icond_reg);
 9825 %}
 9826 
 9827 instruct cmovUP_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9828   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9829 
 9830   ins_cost(INSN_COST * 2);
 9831   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, ptr&quot;  %}
 9832 
 9833   ins_encode %{
 9834     __ csel(as_Register($dst$$reg),
 9835             zr,
 9836             as_Register($src$$reg),
 9837             (Assembler::Condition)$cmp$$cmpcode);
 9838   %}
 9839 
 9840   ins_pipe(icond_reg);
 9841 %}
 9842 
 9843 instruct cmovP_zero_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9844   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9845 
 9846   ins_cost(INSN_COST * 2);
 9847   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, ptr&quot;  %}
 9848 
 9849   ins_encode %{
 9850     __ csel(as_Register($dst$$reg),
 9851             as_Register($src$$reg),
 9852             zr,
 9853             (Assembler::Condition)$cmp$$cmpcode);
 9854   %}
 9855 
 9856   ins_pipe(icond_reg);
 9857 %}
 9858 
 9859 instruct cmovUP_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9860   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9861 
 9862   ins_cost(INSN_COST * 2);
 9863   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, ptr&quot;  %}
 9864 
 9865   ins_encode %{
 9866     __ csel(as_Register($dst$$reg),
 9867             as_Register($src$$reg),
 9868             zr,
 9869             (Assembler::Condition)$cmp$$cmpcode);
 9870   %}
 9871 
 9872   ins_pipe(icond_reg);
 9873 %}
 9874 
 9875 instruct cmovN_reg_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9876   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9877 
 9878   ins_cost(INSN_COST * 2);
 9879   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9880 
 9881   ins_encode %{
 9882     __ cselw(as_Register($dst$$reg),
 9883              as_Register($src2$$reg),
 9884              as_Register($src1$$reg),
 9885              (Assembler::Condition)$cmp$$cmpcode);
 9886   %}
 9887 
 9888   ins_pipe(icond_reg_reg);
 9889 %}
 9890 
 9891 instruct cmovUN_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9892   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9893 
 9894   ins_cost(INSN_COST * 2);
 9895   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9896 
 9897   ins_encode %{
 9898     __ cselw(as_Register($dst$$reg),
 9899              as_Register($src2$$reg),
 9900              as_Register($src1$$reg),
 9901              (Assembler::Condition)$cmp$$cmpcode);
 9902   %}
 9903 
 9904   ins_pipe(icond_reg_reg);
 9905 %}
 9906 
 9907 // special cases where one arg is zero
 9908 
 9909 instruct cmovN_reg_zero(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9910   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9911 
 9912   ins_cost(INSN_COST * 2);
 9913   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, compressed ptr&quot;  %}
 9914 
 9915   ins_encode %{
 9916     __ cselw(as_Register($dst$$reg),
 9917              zr,
 9918              as_Register($src$$reg),
 9919              (Assembler::Condition)$cmp$$cmpcode);
 9920   %}
 9921 
 9922   ins_pipe(icond_reg);
 9923 %}
 9924 
 9925 instruct cmovUN_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9926   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9927 
 9928   ins_cost(INSN_COST * 2);
 9929   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, compressed ptr&quot;  %}
 9930 
 9931   ins_encode %{
 9932     __ cselw(as_Register($dst$$reg),
 9933              zr,
 9934              as_Register($src$$reg),
 9935              (Assembler::Condition)$cmp$$cmpcode);
 9936   %}
 9937 
 9938   ins_pipe(icond_reg);
 9939 %}
 9940 
 9941 instruct cmovN_zero_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
 9942   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
 9943 
 9944   ins_cost(INSN_COST * 2);
 9945   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, compressed ptr&quot;  %}
 9946 
 9947   ins_encode %{
 9948     __ cselw(as_Register($dst$$reg),
 9949              as_Register($src$$reg),
 9950              zr,
 9951              (Assembler::Condition)$cmp$$cmpcode);
 9952   %}
 9953 
 9954   ins_pipe(icond_reg);
 9955 %}
 9956 
 9957 instruct cmovUN_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
 9958   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
 9959 
 9960   ins_cost(INSN_COST * 2);
 9961   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, compressed ptr&quot;  %}
 9962 
 9963   ins_encode %{
 9964     __ cselw(as_Register($dst$$reg),
 9965              as_Register($src$$reg),
 9966              zr,
 9967              (Assembler::Condition)$cmp$$cmpcode);
 9968   %}
 9969 
 9970   ins_pipe(icond_reg);
 9971 %}
 9972 
 9973 instruct cmovF_reg(cmpOp cmp, rFlagsReg cr, vRegF dst, vRegF src1,  vRegF src2)
 9974 %{
 9975   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
 9976 
 9977   ins_cost(INSN_COST * 3);
 9978 
 9979   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
 9980   ins_encode %{
 9981     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
 9982     __ fcsels(as_FloatRegister($dst$$reg),
 9983               as_FloatRegister($src2$$reg),
 9984               as_FloatRegister($src1$$reg),
 9985               cond);
 9986   %}
 9987 
 9988   ins_pipe(fp_cond_reg_reg_s);
 9989 %}
 9990 
 9991 instruct cmovUF_reg(cmpOpU cmp, rFlagsRegU cr, vRegF dst, vRegF src1,  vRegF src2)
 9992 %{
 9993   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
 9994 
 9995   ins_cost(INSN_COST * 3);
 9996 
 9997   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
 9998   ins_encode %{
 9999     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10000     __ fcsels(as_FloatRegister($dst$$reg),
10001               as_FloatRegister($src2$$reg),
10002               as_FloatRegister($src1$$reg),
10003               cond);
10004   %}
10005 
10006   ins_pipe(fp_cond_reg_reg_s);
10007 %}
10008 
10009 instruct cmovD_reg(cmpOp cmp, rFlagsReg cr, vRegD dst, vRegD src1,  vRegD src2)
10010 %{
10011   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10012 
10013   ins_cost(INSN_COST * 3);
10014 
10015   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10016   ins_encode %{
10017     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10018     __ fcseld(as_FloatRegister($dst$$reg),
10019               as_FloatRegister($src2$$reg),
10020               as_FloatRegister($src1$$reg),
10021               cond);
10022   %}
10023 
10024   ins_pipe(fp_cond_reg_reg_d);
10025 %}
10026 
10027 instruct cmovUD_reg(cmpOpU cmp, rFlagsRegU cr, vRegD dst, vRegD src1,  vRegD src2)
10028 %{
10029   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10030 
10031   ins_cost(INSN_COST * 3);
10032 
10033   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10034   ins_encode %{
10035     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10036     __ fcseld(as_FloatRegister($dst$$reg),
10037               as_FloatRegister($src2$$reg),
10038               as_FloatRegister($src1$$reg),
10039               cond);
10040   %}
10041 
10042   ins_pipe(fp_cond_reg_reg_d);
10043 %}
10044 
10045 // ============================================================================
10046 // Arithmetic Instructions
10047 //
10048 
10049 // Integer Addition
10050 
10051 // TODO
10052 // these currently employ operations which do not set CR and hence are
10053 // not flagged as killing CR but we would like to isolate the cases
10054 // where we want to set flags from those where we don&#39;t. need to work
10055 // out how to do that.
10056 
10057 instruct addI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10058   match(Set dst (AddI src1 src2));
10059 
10060   ins_cost(INSN_COST);
10061   format %{ &quot;addw  $dst, $src1, $src2&quot; %}
10062 
10063   ins_encode %{
10064     __ addw(as_Register($dst$$reg),
10065             as_Register($src1$$reg),
10066             as_Register($src2$$reg));
10067   %}
10068 
10069   ins_pipe(ialu_reg_reg);
10070 %}
10071 
10072 instruct addI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10073   match(Set dst (AddI src1 src2));
10074 
10075   ins_cost(INSN_COST);
10076   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10077 
10078   // use opcode to indicate that this is an add not a sub
10079   opcode(0x0);
10080 
10081   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10082 
10083   ins_pipe(ialu_reg_imm);
10084 %}
10085 
10086 instruct addI_reg_imm_i2l(iRegINoSp dst, iRegL src1, immIAddSub src2) %{
10087   match(Set dst (AddI (ConvL2I src1) src2));
10088 
10089   ins_cost(INSN_COST);
10090   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10091 
10092   // use opcode to indicate that this is an add not a sub
10093   opcode(0x0);
10094 
10095   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10096 
10097   ins_pipe(ialu_reg_imm);
10098 %}
10099 
10100 // Pointer Addition
10101 instruct addP_reg_reg(iRegPNoSp dst, iRegP src1, iRegL src2) %{
10102   match(Set dst (AddP src1 src2));
10103 
10104   ins_cost(INSN_COST);
10105   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10106 
10107   ins_encode %{
10108     __ add(as_Register($dst$$reg),
10109            as_Register($src1$$reg),
10110            as_Register($src2$$reg));
10111   %}
10112 
10113   ins_pipe(ialu_reg_reg);
10114 %}
10115 
10116 instruct addP_reg_reg_ext(iRegPNoSp dst, iRegP src1, iRegIorL2I src2) %{
10117   match(Set dst (AddP src1 (ConvI2L src2)));
10118 
10119   ins_cost(1.9 * INSN_COST);
10120   format %{ &quot;add $dst, $src1, $src2, sxtw\t# ptr&quot; %}
10121 
10122   ins_encode %{
10123     __ add(as_Register($dst$$reg),
10124            as_Register($src1$$reg),
10125            as_Register($src2$$reg), ext::sxtw);
10126   %}
10127 
10128   ins_pipe(ialu_reg_reg);
10129 %}
10130 
10131 instruct addP_reg_reg_lsl(iRegPNoSp dst, iRegP src1, iRegL src2, immIScale scale) %{
10132   match(Set dst (AddP src1 (LShiftL src2 scale)));
10133 
10134   ins_cost(1.9 * INSN_COST);
10135   format %{ &quot;add $dst, $src1, $src2, LShiftL $scale\t# ptr&quot; %}
10136 
10137   ins_encode %{
10138     __ lea(as_Register($dst$$reg),
10139            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10140                    Address::lsl($scale$$constant)));
10141   %}
10142 
10143   ins_pipe(ialu_reg_reg_shift);
10144 %}
10145 
10146 instruct addP_reg_reg_ext_shift(iRegPNoSp dst, iRegP src1, iRegIorL2I src2, immIScale scale) %{
10147   match(Set dst (AddP src1 (LShiftL (ConvI2L src2) scale)));
10148 
10149   ins_cost(1.9 * INSN_COST);
10150   format %{ &quot;add $dst, $src1, $src2, I2L $scale\t# ptr&quot; %}
10151 
10152   ins_encode %{
10153     __ lea(as_Register($dst$$reg),
10154            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10155                    Address::sxtw($scale$$constant)));
10156   %}
10157 
10158   ins_pipe(ialu_reg_reg_shift);
10159 %}
10160 
10161 instruct lshift_ext(iRegLNoSp dst, iRegIorL2I src, immI scale, rFlagsReg cr) %{
10162   match(Set dst (LShiftL (ConvI2L src) scale));
10163 
10164   ins_cost(INSN_COST);
10165   format %{ &quot;sbfiz $dst, $src, $scale &amp; 63, -$scale &amp; 63\t&quot; %}
10166 
10167   ins_encode %{
10168     __ sbfiz(as_Register($dst$$reg),
10169           as_Register($src$$reg),
10170           $scale$$constant &amp; 63, MIN2(32, (int)((-$scale$$constant) &amp; 63)));
10171   %}
10172 
10173   ins_pipe(ialu_reg_shift);
10174 %}
10175 
10176 // Pointer Immediate Addition
10177 // n.b. this needs to be more expensive than using an indirect memory
10178 // operand
10179 instruct addP_reg_imm(iRegPNoSp dst, iRegP src1, immLAddSub src2) %{
10180   match(Set dst (AddP src1 src2));
10181 
10182   ins_cost(INSN_COST);
10183   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10184 
10185   // use opcode to indicate that this is an add not a sub
10186   opcode(0x0);
10187 
10188   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10189 
10190   ins_pipe(ialu_reg_imm);
10191 %}
10192 
10193 // Long Addition
10194 instruct addL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10195 
10196   match(Set dst (AddL src1 src2));
10197 
10198   ins_cost(INSN_COST);
10199   format %{ &quot;add  $dst, $src1, $src2&quot; %}
10200 
10201   ins_encode %{
10202     __ add(as_Register($dst$$reg),
10203            as_Register($src1$$reg),
10204            as_Register($src2$$reg));
10205   %}
10206 
10207   ins_pipe(ialu_reg_reg);
10208 %}
10209 
10210 // No constant pool entries requiredLong Immediate Addition.
10211 instruct addL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10212   match(Set dst (AddL src1 src2));
10213 
10214   ins_cost(INSN_COST);
10215   format %{ &quot;add $dst, $src1, $src2&quot; %}
10216 
10217   // use opcode to indicate that this is an add not a sub
10218   opcode(0x0);
10219 
10220   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10221 
10222   ins_pipe(ialu_reg_imm);
10223 %}
10224 
10225 // Integer Subtraction
10226 instruct subI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10227   match(Set dst (SubI src1 src2));
10228 
10229   ins_cost(INSN_COST);
10230   format %{ &quot;subw  $dst, $src1, $src2&quot; %}
10231 
10232   ins_encode %{
10233     __ subw(as_Register($dst$$reg),
10234             as_Register($src1$$reg),
10235             as_Register($src2$$reg));
10236   %}
10237 
10238   ins_pipe(ialu_reg_reg);
10239 %}
10240 
10241 // Immediate Subtraction
10242 instruct subI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10243   match(Set dst (SubI src1 src2));
10244 
10245   ins_cost(INSN_COST);
10246   format %{ &quot;subw $dst, $src1, $src2&quot; %}
10247 
10248   // use opcode to indicate that this is a sub not an add
10249   opcode(0x1);
10250 
10251   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10252 
10253   ins_pipe(ialu_reg_imm);
10254 %}
10255 
10256 // Long Subtraction
10257 instruct subL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10258 
10259   match(Set dst (SubL src1 src2));
10260 
10261   ins_cost(INSN_COST);
10262   format %{ &quot;sub  $dst, $src1, $src2&quot; %}
10263 
10264   ins_encode %{
10265     __ sub(as_Register($dst$$reg),
10266            as_Register($src1$$reg),
10267            as_Register($src2$$reg));
10268   %}
10269 
10270   ins_pipe(ialu_reg_reg);
10271 %}
10272 
10273 // No constant pool entries requiredLong Immediate Subtraction.
10274 instruct subL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10275   match(Set dst (SubL src1 src2));
10276 
10277   ins_cost(INSN_COST);
10278   format %{ &quot;sub$dst, $src1, $src2&quot; %}
10279 
10280   // use opcode to indicate that this is a sub not an add
10281   opcode(0x1);
10282 
10283   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10284 
10285   ins_pipe(ialu_reg_imm);
10286 %}
10287 
10288 // Integer Negation (special case for sub)
10289 
10290 instruct negI_reg(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr) %{
10291   match(Set dst (SubI zero src));
10292 
10293   ins_cost(INSN_COST);
10294   format %{ &quot;negw $dst, $src\t# int&quot; %}
10295 
10296   ins_encode %{
10297     __ negw(as_Register($dst$$reg),
10298             as_Register($src$$reg));
10299   %}
10300 
10301   ins_pipe(ialu_reg);
10302 %}
10303 
10304 // Long Negation
10305 
10306 instruct negL_reg(iRegLNoSp dst, iRegL src, immL0 zero, rFlagsReg cr) %{
10307   match(Set dst (SubL zero src));
10308 
10309   ins_cost(INSN_COST);
10310   format %{ &quot;neg $dst, $src\t# long&quot; %}
10311 
10312   ins_encode %{
10313     __ neg(as_Register($dst$$reg),
10314            as_Register($src$$reg));
10315   %}
10316 
10317   ins_pipe(ialu_reg);
10318 %}
10319 
10320 // Integer Multiply
10321 
10322 instruct mulI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10323   match(Set dst (MulI src1 src2));
10324 
10325   ins_cost(INSN_COST * 3);
10326   format %{ &quot;mulw  $dst, $src1, $src2&quot; %}
10327 
10328   ins_encode %{
10329     __ mulw(as_Register($dst$$reg),
10330             as_Register($src1$$reg),
10331             as_Register($src2$$reg));
10332   %}
10333 
10334   ins_pipe(imul_reg_reg);
10335 %}
10336 
10337 instruct smulI(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10338   match(Set dst (MulL (ConvI2L src1) (ConvI2L src2)));
10339 
10340   ins_cost(INSN_COST * 3);
10341   format %{ &quot;smull  $dst, $src1, $src2&quot; %}
10342 
10343   ins_encode %{
10344     __ smull(as_Register($dst$$reg),
10345              as_Register($src1$$reg),
10346              as_Register($src2$$reg));
10347   %}
10348 
10349   ins_pipe(imul_reg_reg);
10350 %}
10351 
10352 // Long Multiply
10353 
10354 instruct mulL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10355   match(Set dst (MulL src1 src2));
10356 
10357   ins_cost(INSN_COST * 5);
10358   format %{ &quot;mul  $dst, $src1, $src2&quot; %}
10359 
10360   ins_encode %{
10361     __ mul(as_Register($dst$$reg),
10362            as_Register($src1$$reg),
10363            as_Register($src2$$reg));
10364   %}
10365 
10366   ins_pipe(lmul_reg_reg);
10367 %}
10368 
10369 instruct mulHiL_rReg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr)
10370 %{
10371   match(Set dst (MulHiL src1 src2));
10372 
10373   ins_cost(INSN_COST * 7);
10374   format %{ &quot;smulh   $dst, $src1, $src2, \t# mulhi&quot; %}
10375 
10376   ins_encode %{
10377     __ smulh(as_Register($dst$$reg),
10378              as_Register($src1$$reg),
10379              as_Register($src2$$reg));
10380   %}
10381 
10382   ins_pipe(lmul_reg_reg);
10383 %}
10384 
10385 // Combined Integer Multiply &amp; Add/Sub
10386 
10387 instruct maddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10388   match(Set dst (AddI src3 (MulI src1 src2)));
10389 
10390   ins_cost(INSN_COST * 3);
10391   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10392 
10393   ins_encode %{
10394     __ maddw(as_Register($dst$$reg),
10395              as_Register($src1$$reg),
10396              as_Register($src2$$reg),
10397              as_Register($src3$$reg));
10398   %}
10399 
10400   ins_pipe(imac_reg_reg);
10401 %}
10402 
10403 instruct msubI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10404   match(Set dst (SubI src3 (MulI src1 src2)));
10405 
10406   ins_cost(INSN_COST * 3);
10407   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10408 
10409   ins_encode %{
10410     __ msubw(as_Register($dst$$reg),
10411              as_Register($src1$$reg),
10412              as_Register($src2$$reg),
10413              as_Register($src3$$reg));
10414   %}
10415 
10416   ins_pipe(imac_reg_reg);
10417 %}
10418 
10419 // Combined Integer Multiply &amp; Neg
10420 
10421 instruct mnegI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI0 zero) %{
10422   match(Set dst (MulI (SubI zero src1) src2));
10423   match(Set dst (MulI src1 (SubI zero src2)));
10424 
10425   ins_cost(INSN_COST * 3);
10426   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10427 
10428   ins_encode %{
10429     __ mnegw(as_Register($dst$$reg),
10430              as_Register($src1$$reg),
10431              as_Register($src2$$reg));
10432   %}
10433 
10434   ins_pipe(imac_reg_reg);
10435 %}
10436 
10437 // Combined Long Multiply &amp; Add/Sub
10438 
10439 instruct maddL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10440   match(Set dst (AddL src3 (MulL src1 src2)));
10441 
10442   ins_cost(INSN_COST * 5);
10443   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10444 
10445   ins_encode %{
10446     __ madd(as_Register($dst$$reg),
10447             as_Register($src1$$reg),
10448             as_Register($src2$$reg),
10449             as_Register($src3$$reg));
10450   %}
10451 
10452   ins_pipe(lmac_reg_reg);
10453 %}
10454 
10455 instruct msubL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10456   match(Set dst (SubL src3 (MulL src1 src2)));
10457 
10458   ins_cost(INSN_COST * 5);
10459   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10460 
10461   ins_encode %{
10462     __ msub(as_Register($dst$$reg),
10463             as_Register($src1$$reg),
10464             as_Register($src2$$reg),
10465             as_Register($src3$$reg));
10466   %}
10467 
10468   ins_pipe(lmac_reg_reg);
10469 %}
10470 
10471 // Combined Long Multiply &amp; Neg
10472 
10473 instruct mnegL(iRegLNoSp dst, iRegL src1, iRegL src2, immL0 zero) %{
10474   match(Set dst (MulL (SubL zero src1) src2));
10475   match(Set dst (MulL src1 (SubL zero src2)));
10476 
10477   ins_cost(INSN_COST * 5);
10478   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10479 
10480   ins_encode %{
10481     __ mneg(as_Register($dst$$reg),
10482             as_Register($src1$$reg),
10483             as_Register($src2$$reg));
10484   %}
10485 
10486   ins_pipe(lmac_reg_reg);
10487 %}
10488 
10489 // Combine Integer Signed Multiply &amp; Add/Sub/Neg Long
10490 
10491 instruct smaddL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10492   match(Set dst (AddL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10493 
10494   ins_cost(INSN_COST * 3);
10495   format %{ &quot;smaddl  $dst, $src1, $src2, $src3&quot; %}
10496 
10497   ins_encode %{
10498     __ smaddl(as_Register($dst$$reg),
10499               as_Register($src1$$reg),
10500               as_Register($src2$$reg),
10501               as_Register($src3$$reg));
10502   %}
10503 
10504   ins_pipe(imac_reg_reg);
10505 %}
10506 
10507 instruct smsubL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10508   match(Set dst (SubL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10509 
10510   ins_cost(INSN_COST * 3);
10511   format %{ &quot;smsubl  $dst, $src1, $src2, $src3&quot; %}
10512 
10513   ins_encode %{
10514     __ smsubl(as_Register($dst$$reg),
10515               as_Register($src1$$reg),
10516               as_Register($src2$$reg),
10517               as_Register($src3$$reg));
10518   %}
10519 
10520   ins_pipe(imac_reg_reg);
10521 %}
10522 
10523 instruct smnegL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, immL0 zero) %{
10524   match(Set dst (MulL (SubL zero (ConvI2L src1)) (ConvI2L src2)));
10525   match(Set dst (MulL (ConvI2L src1) (SubL zero (ConvI2L src2))));
10526 
10527   ins_cost(INSN_COST * 3);
10528   format %{ &quot;smnegl  $dst, $src1, $src2&quot; %}
10529 
10530   ins_encode %{
10531     __ smnegl(as_Register($dst$$reg),
10532               as_Register($src1$$reg),
10533               as_Register($src2$$reg));
10534   %}
10535 
10536   ins_pipe(imac_reg_reg);
10537 %}
10538 
10539 // Combined Multiply-Add Shorts into Integer (dst = src1 * src2 + src3 * src4)
10540 
10541 instruct muladdS2I(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3, iRegIorL2I src4) %{
10542   match(Set dst (MulAddS2I (Binary src1 src2) (Binary src3 src4)));
10543 
10544   ins_cost(INSN_COST * 5);
10545   format %{ &quot;mulw  rscratch1, $src1, $src2\n\t&quot;
10546             &quot;maddw $dst, $src3, $src4, rscratch1&quot; %}
10547 
10548   ins_encode %{
10549     __ mulw(rscratch1, as_Register($src1$$reg), as_Register($src2$$reg));
10550     __ maddw(as_Register($dst$$reg), as_Register($src3$$reg), as_Register($src4$$reg), rscratch1); %}
10551 
10552   ins_pipe(imac_reg_reg);
10553 %}
10554 
10555 // Integer Divide
10556 
10557 instruct divI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10558   match(Set dst (DivI src1 src2));
10559 
10560   ins_cost(INSN_COST * 19);
10561   format %{ &quot;sdivw  $dst, $src1, $src2&quot; %}
10562 
10563   ins_encode(aarch64_enc_divw(dst, src1, src2));
10564   ins_pipe(idiv_reg_reg);
10565 %}
10566 
10567 // Long Divide
10568 
10569 instruct divL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10570   match(Set dst (DivL src1 src2));
10571 
10572   ins_cost(INSN_COST * 35);
10573   format %{ &quot;sdiv   $dst, $src1, $src2&quot; %}
10574 
10575   ins_encode(aarch64_enc_div(dst, src1, src2));
10576   ins_pipe(ldiv_reg_reg);
10577 %}
10578 
10579 // Integer Remainder
10580 
10581 instruct modI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10582   match(Set dst (ModI src1 src2));
10583 
10584   ins_cost(INSN_COST * 22);
10585   format %{ &quot;sdivw  rscratch1, $src1, $src2\n\t&quot;
10586             &quot;msubw($dst, rscratch1, $src2, $src1&quot; %}
10587 
10588   ins_encode(aarch64_enc_modw(dst, src1, src2));
10589   ins_pipe(idiv_reg_reg);
10590 %}
10591 
10592 // Long Remainder
10593 
10594 instruct modL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10595   match(Set dst (ModL src1 src2));
10596 
10597   ins_cost(INSN_COST * 38);
10598   format %{ &quot;sdiv   rscratch1, $src1, $src2\n&quot;
10599             &quot;msub($dst, rscratch1, $src2, $src1&quot; %}
10600 
10601   ins_encode(aarch64_enc_mod(dst, src1, src2));
10602   ins_pipe(ldiv_reg_reg);
10603 %}
10604 
10605 // Integer Shifts
10606 
10607 // Shift Left Register
10608 instruct lShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10609   match(Set dst (LShiftI src1 src2));
10610 
10611   ins_cost(INSN_COST * 2);
10612   format %{ &quot;lslvw  $dst, $src1, $src2&quot; %}
10613 
10614   ins_encode %{
10615     __ lslvw(as_Register($dst$$reg),
10616              as_Register($src1$$reg),
10617              as_Register($src2$$reg));
10618   %}
10619 
10620   ins_pipe(ialu_reg_reg_vshift);
10621 %}
10622 
10623 // Shift Left Immediate
10624 instruct lShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10625   match(Set dst (LShiftI src1 src2));
10626 
10627   ins_cost(INSN_COST);
10628   format %{ &quot;lslw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10629 
10630   ins_encode %{
10631     __ lslw(as_Register($dst$$reg),
10632             as_Register($src1$$reg),
10633             $src2$$constant &amp; 0x1f);
10634   %}
10635 
10636   ins_pipe(ialu_reg_shift);
10637 %}
10638 
10639 // Shift Right Logical Register
10640 instruct urShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10641   match(Set dst (URShiftI src1 src2));
10642 
10643   ins_cost(INSN_COST * 2);
10644   format %{ &quot;lsrvw  $dst, $src1, $src2&quot; %}
10645 
10646   ins_encode %{
10647     __ lsrvw(as_Register($dst$$reg),
10648              as_Register($src1$$reg),
10649              as_Register($src2$$reg));
10650   %}
10651 
10652   ins_pipe(ialu_reg_reg_vshift);
10653 %}
10654 
10655 // Shift Right Logical Immediate
10656 instruct urShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10657   match(Set dst (URShiftI src1 src2));
10658 
10659   ins_cost(INSN_COST);
10660   format %{ &quot;lsrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10661 
10662   ins_encode %{
10663     __ lsrw(as_Register($dst$$reg),
10664             as_Register($src1$$reg),
10665             $src2$$constant &amp; 0x1f);
10666   %}
10667 
10668   ins_pipe(ialu_reg_shift);
10669 %}
10670 
10671 // Shift Right Arithmetic Register
10672 instruct rShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10673   match(Set dst (RShiftI src1 src2));
10674 
10675   ins_cost(INSN_COST * 2);
10676   format %{ &quot;asrvw  $dst, $src1, $src2&quot; %}
10677 
10678   ins_encode %{
10679     __ asrvw(as_Register($dst$$reg),
10680              as_Register($src1$$reg),
10681              as_Register($src2$$reg));
10682   %}
10683 
10684   ins_pipe(ialu_reg_reg_vshift);
10685 %}
10686 
10687 // Shift Right Arithmetic Immediate
10688 instruct rShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10689   match(Set dst (RShiftI src1 src2));
10690 
10691   ins_cost(INSN_COST);
10692   format %{ &quot;asrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10693 
10694   ins_encode %{
10695     __ asrw(as_Register($dst$$reg),
10696             as_Register($src1$$reg),
10697             $src2$$constant &amp; 0x1f);
10698   %}
10699 
10700   ins_pipe(ialu_reg_shift);
10701 %}
10702 
10703 // Combined Int Mask and Right Shift (using UBFM)
10704 // TODO
10705 
10706 // Long Shifts
10707 
10708 // Shift Left Register
10709 instruct lShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10710   match(Set dst (LShiftL src1 src2));
10711 
10712   ins_cost(INSN_COST * 2);
10713   format %{ &quot;lslv  $dst, $src1, $src2&quot; %}
10714 
10715   ins_encode %{
10716     __ lslv(as_Register($dst$$reg),
10717             as_Register($src1$$reg),
10718             as_Register($src2$$reg));
10719   %}
10720 
10721   ins_pipe(ialu_reg_reg_vshift);
10722 %}
10723 
10724 // Shift Left Immediate
10725 instruct lShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10726   match(Set dst (LShiftL src1 src2));
10727 
10728   ins_cost(INSN_COST);
10729   format %{ &quot;lsl $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10730 
10731   ins_encode %{
10732     __ lsl(as_Register($dst$$reg),
10733             as_Register($src1$$reg),
10734             $src2$$constant &amp; 0x3f);
10735   %}
10736 
10737   ins_pipe(ialu_reg_shift);
10738 %}
10739 
10740 // Shift Right Logical Register
10741 instruct urShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10742   match(Set dst (URShiftL src1 src2));
10743 
10744   ins_cost(INSN_COST * 2);
10745   format %{ &quot;lsrv  $dst, $src1, $src2&quot; %}
10746 
10747   ins_encode %{
10748     __ lsrv(as_Register($dst$$reg),
10749             as_Register($src1$$reg),
10750             as_Register($src2$$reg));
10751   %}
10752 
10753   ins_pipe(ialu_reg_reg_vshift);
10754 %}
10755 
10756 // Shift Right Logical Immediate
10757 instruct urShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10758   match(Set dst (URShiftL src1 src2));
10759 
10760   ins_cost(INSN_COST);
10761   format %{ &quot;lsr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10762 
10763   ins_encode %{
10764     __ lsr(as_Register($dst$$reg),
10765            as_Register($src1$$reg),
10766            $src2$$constant &amp; 0x3f);
10767   %}
10768 
10769   ins_pipe(ialu_reg_shift);
10770 %}
10771 
10772 // A special-case pattern for card table stores.
10773 instruct urShiftP_reg_imm(iRegLNoSp dst, iRegP src1, immI src2) %{
10774   match(Set dst (URShiftL (CastP2X src1) src2));
10775 
10776   ins_cost(INSN_COST);
10777   format %{ &quot;lsr $dst, p2x($src1), ($src2 &amp; 0x3f)&quot; %}
10778 
10779   ins_encode %{
10780     __ lsr(as_Register($dst$$reg),
10781            as_Register($src1$$reg),
10782            $src2$$constant &amp; 0x3f);
10783   %}
10784 
10785   ins_pipe(ialu_reg_shift);
10786 %}
10787 
10788 // Shift Right Arithmetic Register
10789 instruct rShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10790   match(Set dst (RShiftL src1 src2));
10791 
10792   ins_cost(INSN_COST * 2);
10793   format %{ &quot;asrv  $dst, $src1, $src2&quot; %}
10794 
10795   ins_encode %{
10796     __ asrv(as_Register($dst$$reg),
10797             as_Register($src1$$reg),
10798             as_Register($src2$$reg));
10799   %}
10800 
10801   ins_pipe(ialu_reg_reg_vshift);
10802 %}
10803 
10804 // Shift Right Arithmetic Immediate
10805 instruct rShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10806   match(Set dst (RShiftL src1 src2));
10807 
10808   ins_cost(INSN_COST);
10809   format %{ &quot;asr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10810 
10811   ins_encode %{
10812     __ asr(as_Register($dst$$reg),
10813            as_Register($src1$$reg),
10814            $src2$$constant &amp; 0x3f);
10815   %}
10816 
10817   ins_pipe(ialu_reg_shift);
10818 %}
10819 
10820 // BEGIN This section of the file is automatically generated. Do not edit --------------
10821 
10822 
10823 // This pattern is automatically generated from aarch64_ad.m4
10824 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
10825 instruct regL_not_reg(iRegLNoSp dst,
10826                          iRegL src1, immL_M1 m1,
10827                          rFlagsReg cr) %{
10828   match(Set dst (XorL src1 m1));
10829   ins_cost(INSN_COST);
10830   format %{ &quot;eon  $dst, $src1, zr&quot; %}
10831 
10832   ins_encode %{
10833     __ eon(as_Register($dst$$reg),
10834               as_Register($src1$$reg),
10835               zr,
10836               Assembler::LSL, 0);
10837   %}
10838 
10839   ins_pipe(ialu_reg);
10840 %}
10841 
10842 // This pattern is automatically generated from aarch64_ad.m4
10843 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
10844 instruct regI_not_reg(iRegINoSp dst,
10845                          iRegIorL2I src1, immI_M1 m1,
10846                          rFlagsReg cr) %{
10847   match(Set dst (XorI src1 m1));
10848   ins_cost(INSN_COST);
10849   format %{ &quot;eonw  $dst, $src1, zr&quot; %}
10850 
10851   ins_encode %{
10852     __ eonw(as_Register($dst$$reg),
10853               as_Register($src1$$reg),
10854               zr,
10855               Assembler::LSL, 0);
10856   %}
10857 
10858   ins_pipe(ialu_reg);
10859 %}
10860 
10861 // This pattern is automatically generated from aarch64_ad.m4
10862 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
10863 instruct AndI_reg_not_reg(iRegINoSp dst,
10864                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10865                          rFlagsReg cr) %{
10866   match(Set dst (AndI src1 (XorI src2 m1)));
10867   ins_cost(INSN_COST);
10868   format %{ &quot;bicw  $dst, $src1, $src2&quot; %}
10869 
10870   ins_encode %{
10871     __ bicw(as_Register($dst$$reg),
10872               as_Register($src1$$reg),
10873               as_Register($src2$$reg),
10874               Assembler::LSL, 0);
10875   %}
10876 
10877   ins_pipe(ialu_reg_reg);
10878 %}
10879 
10880 // This pattern is automatically generated from aarch64_ad.m4
10881 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
10882 instruct AndL_reg_not_reg(iRegLNoSp dst,
10883                          iRegL src1, iRegL src2, immL_M1 m1,
10884                          rFlagsReg cr) %{
10885   match(Set dst (AndL src1 (XorL src2 m1)));
10886   ins_cost(INSN_COST);
10887   format %{ &quot;bic  $dst, $src1, $src2&quot; %}
10888 
10889   ins_encode %{
10890     __ bic(as_Register($dst$$reg),
10891               as_Register($src1$$reg),
10892               as_Register($src2$$reg),
10893               Assembler::LSL, 0);
10894   %}
10895 
10896   ins_pipe(ialu_reg_reg);
10897 %}
10898 
10899 // This pattern is automatically generated from aarch64_ad.m4
10900 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
10901 instruct OrI_reg_not_reg(iRegINoSp dst,
10902                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10903                          rFlagsReg cr) %{
10904   match(Set dst (OrI src1 (XorI src2 m1)));
10905   ins_cost(INSN_COST);
10906   format %{ &quot;ornw  $dst, $src1, $src2&quot; %}
10907 
10908   ins_encode %{
10909     __ ornw(as_Register($dst$$reg),
10910               as_Register($src1$$reg),
10911               as_Register($src2$$reg),
10912               Assembler::LSL, 0);
10913   %}
10914 
10915   ins_pipe(ialu_reg_reg);
10916 %}
10917 
10918 // This pattern is automatically generated from aarch64_ad.m4
10919 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
10920 instruct OrL_reg_not_reg(iRegLNoSp dst,
10921                          iRegL src1, iRegL src2, immL_M1 m1,
10922                          rFlagsReg cr) %{
10923   match(Set dst (OrL src1 (XorL src2 m1)));
10924   ins_cost(INSN_COST);
10925   format %{ &quot;orn  $dst, $src1, $src2&quot; %}
10926 
10927   ins_encode %{
10928     __ orn(as_Register($dst$$reg),
10929               as_Register($src1$$reg),
10930               as_Register($src2$$reg),
10931               Assembler::LSL, 0);
10932   %}
10933 
10934   ins_pipe(ialu_reg_reg);
10935 %}
10936 
10937 // This pattern is automatically generated from aarch64_ad.m4
10938 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
10939 instruct XorI_reg_not_reg(iRegINoSp dst,
10940                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10941                          rFlagsReg cr) %{
10942   match(Set dst (XorI m1 (XorI src2 src1)));
10943   ins_cost(INSN_COST);
10944   format %{ &quot;eonw  $dst, $src1, $src2&quot; %}
10945 
10946   ins_encode %{
10947     __ eonw(as_Register($dst$$reg),
10948               as_Register($src1$$reg),
10949               as_Register($src2$$reg),
10950               Assembler::LSL, 0);
10951   %}
10952 
10953   ins_pipe(ialu_reg_reg);
10954 %}
10955 
10956 // This pattern is automatically generated from aarch64_ad.m4
10957 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
10958 instruct XorL_reg_not_reg(iRegLNoSp dst,
10959                          iRegL src1, iRegL src2, immL_M1 m1,
10960                          rFlagsReg cr) %{
10961   match(Set dst (XorL m1 (XorL src2 src1)));
10962   ins_cost(INSN_COST);
10963   format %{ &quot;eon  $dst, $src1, $src2&quot; %}
10964 
10965   ins_encode %{
10966     __ eon(as_Register($dst$$reg),
10967               as_Register($src1$$reg),
10968               as_Register($src2$$reg),
10969               Assembler::LSL, 0);
10970   %}
10971 
10972   ins_pipe(ialu_reg_reg);
10973 %}
10974 
10975 // This pattern is automatically generated from aarch64_ad.m4
10976 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
10977 instruct AndI_reg_URShift_not_reg(iRegINoSp dst,
10978                          iRegIorL2I src1, iRegIorL2I src2,
10979                          immI src3, immI_M1 src4, rFlagsReg cr) %{
10980   match(Set dst (AndI src1 (XorI(URShiftI src2 src3) src4)));
10981   ins_cost(1.9 * INSN_COST);
10982   format %{ &quot;bicw  $dst, $src1, $src2, LSR $src3&quot; %}
10983 
10984   ins_encode %{
10985     __ bicw(as_Register($dst$$reg),
10986               as_Register($src1$$reg),
10987               as_Register($src2$$reg),
10988               Assembler::LSR,
10989               $src3$$constant &amp; 0x1f);
10990   %}
10991 
10992   ins_pipe(ialu_reg_reg_shift);
10993 %}
10994 
10995 // This pattern is automatically generated from aarch64_ad.m4
10996 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
10997 instruct AndL_reg_URShift_not_reg(iRegLNoSp dst,
10998                          iRegL src1, iRegL src2,
10999                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11000   match(Set dst (AndL src1 (XorL(URShiftL src2 src3) src4)));
11001   ins_cost(1.9 * INSN_COST);
11002   format %{ &quot;bic  $dst, $src1, $src2, LSR $src3&quot; %}
11003 
11004   ins_encode %{
11005     __ bic(as_Register($dst$$reg),
11006               as_Register($src1$$reg),
11007               as_Register($src2$$reg),
11008               Assembler::LSR,
11009               $src3$$constant &amp; 0x3f);
11010   %}
11011 
11012   ins_pipe(ialu_reg_reg_shift);
11013 %}
11014 
11015 // This pattern is automatically generated from aarch64_ad.m4
11016 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11017 instruct AndI_reg_RShift_not_reg(iRegINoSp dst,
11018                          iRegIorL2I src1, iRegIorL2I src2,
11019                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11020   match(Set dst (AndI src1 (XorI(RShiftI src2 src3) src4)));
11021   ins_cost(1.9 * INSN_COST);
11022   format %{ &quot;bicw  $dst, $src1, $src2, ASR $src3&quot; %}
11023 
11024   ins_encode %{
11025     __ bicw(as_Register($dst$$reg),
11026               as_Register($src1$$reg),
11027               as_Register($src2$$reg),
11028               Assembler::ASR,
11029               $src3$$constant &amp; 0x1f);
11030   %}
11031 
11032   ins_pipe(ialu_reg_reg_shift);
11033 %}
11034 
11035 // This pattern is automatically generated from aarch64_ad.m4
11036 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11037 instruct AndL_reg_RShift_not_reg(iRegLNoSp dst,
11038                          iRegL src1, iRegL src2,
11039                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11040   match(Set dst (AndL src1 (XorL(RShiftL src2 src3) src4)));
11041   ins_cost(1.9 * INSN_COST);
11042   format %{ &quot;bic  $dst, $src1, $src2, ASR $src3&quot; %}
11043 
11044   ins_encode %{
11045     __ bic(as_Register($dst$$reg),
11046               as_Register($src1$$reg),
11047               as_Register($src2$$reg),
11048               Assembler::ASR,
11049               $src3$$constant &amp; 0x3f);
11050   %}
11051 
11052   ins_pipe(ialu_reg_reg_shift);
11053 %}
11054 
11055 // This pattern is automatically generated from aarch64_ad.m4
11056 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11057 instruct AndI_reg_LShift_not_reg(iRegINoSp dst,
11058                          iRegIorL2I src1, iRegIorL2I src2,
11059                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11060   match(Set dst (AndI src1 (XorI(LShiftI src2 src3) src4)));
11061   ins_cost(1.9 * INSN_COST);
11062   format %{ &quot;bicw  $dst, $src1, $src2, LSL $src3&quot; %}
11063 
11064   ins_encode %{
11065     __ bicw(as_Register($dst$$reg),
11066               as_Register($src1$$reg),
11067               as_Register($src2$$reg),
11068               Assembler::LSL,
11069               $src3$$constant &amp; 0x1f);
11070   %}
11071 
11072   ins_pipe(ialu_reg_reg_shift);
11073 %}
11074 
11075 // This pattern is automatically generated from aarch64_ad.m4
11076 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11077 instruct AndL_reg_LShift_not_reg(iRegLNoSp dst,
11078                          iRegL src1, iRegL src2,
11079                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11080   match(Set dst (AndL src1 (XorL(LShiftL src2 src3) src4)));
11081   ins_cost(1.9 * INSN_COST);
11082   format %{ &quot;bic  $dst, $src1, $src2, LSL $src3&quot; %}
11083 
11084   ins_encode %{
11085     __ bic(as_Register($dst$$reg),
11086               as_Register($src1$$reg),
11087               as_Register($src2$$reg),
11088               Assembler::LSL,
11089               $src3$$constant &amp; 0x3f);
11090   %}
11091 
11092   ins_pipe(ialu_reg_reg_shift);
11093 %}
11094 
11095 // This pattern is automatically generated from aarch64_ad.m4
11096 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11097 instruct XorI_reg_URShift_not_reg(iRegINoSp dst,
11098                          iRegIorL2I src1, iRegIorL2I src2,
11099                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11100   match(Set dst (XorI src4 (XorI(URShiftI src2 src3) src1)));
11101   ins_cost(1.9 * INSN_COST);
11102   format %{ &quot;eonw  $dst, $src1, $src2, LSR $src3&quot; %}
11103 
11104   ins_encode %{
11105     __ eonw(as_Register($dst$$reg),
11106               as_Register($src1$$reg),
11107               as_Register($src2$$reg),
11108               Assembler::LSR,
11109               $src3$$constant &amp; 0x1f);
11110   %}
11111 
11112   ins_pipe(ialu_reg_reg_shift);
11113 %}
11114 
11115 // This pattern is automatically generated from aarch64_ad.m4
11116 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11117 instruct XorL_reg_URShift_not_reg(iRegLNoSp dst,
11118                          iRegL src1, iRegL src2,
11119                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11120   match(Set dst (XorL src4 (XorL(URShiftL src2 src3) src1)));
11121   ins_cost(1.9 * INSN_COST);
11122   format %{ &quot;eon  $dst, $src1, $src2, LSR $src3&quot; %}
11123 
11124   ins_encode %{
11125     __ eon(as_Register($dst$$reg),
11126               as_Register($src1$$reg),
11127               as_Register($src2$$reg),
11128               Assembler::LSR,
11129               $src3$$constant &amp; 0x3f);
11130   %}
11131 
11132   ins_pipe(ialu_reg_reg_shift);
11133 %}
11134 
11135 // This pattern is automatically generated from aarch64_ad.m4
11136 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11137 instruct XorI_reg_RShift_not_reg(iRegINoSp dst,
11138                          iRegIorL2I src1, iRegIorL2I src2,
11139                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11140   match(Set dst (XorI src4 (XorI(RShiftI src2 src3) src1)));
11141   ins_cost(1.9 * INSN_COST);
11142   format %{ &quot;eonw  $dst, $src1, $src2, ASR $src3&quot; %}
11143 
11144   ins_encode %{
11145     __ eonw(as_Register($dst$$reg),
11146               as_Register($src1$$reg),
11147               as_Register($src2$$reg),
11148               Assembler::ASR,
11149               $src3$$constant &amp; 0x1f);
11150   %}
11151 
11152   ins_pipe(ialu_reg_reg_shift);
11153 %}
11154 
11155 // This pattern is automatically generated from aarch64_ad.m4
11156 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11157 instruct XorL_reg_RShift_not_reg(iRegLNoSp dst,
11158                          iRegL src1, iRegL src2,
11159                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11160   match(Set dst (XorL src4 (XorL(RShiftL src2 src3) src1)));
11161   ins_cost(1.9 * INSN_COST);
11162   format %{ &quot;eon  $dst, $src1, $src2, ASR $src3&quot; %}
11163 
11164   ins_encode %{
11165     __ eon(as_Register($dst$$reg),
11166               as_Register($src1$$reg),
11167               as_Register($src2$$reg),
11168               Assembler::ASR,
11169               $src3$$constant &amp; 0x3f);
11170   %}
11171 
11172   ins_pipe(ialu_reg_reg_shift);
11173 %}
11174 
11175 // This pattern is automatically generated from aarch64_ad.m4
11176 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11177 instruct XorI_reg_LShift_not_reg(iRegINoSp dst,
11178                          iRegIorL2I src1, iRegIorL2I src2,
11179                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11180   match(Set dst (XorI src4 (XorI(LShiftI src2 src3) src1)));
11181   ins_cost(1.9 * INSN_COST);
11182   format %{ &quot;eonw  $dst, $src1, $src2, LSL $src3&quot; %}
11183 
11184   ins_encode %{
11185     __ eonw(as_Register($dst$$reg),
11186               as_Register($src1$$reg),
11187               as_Register($src2$$reg),
11188               Assembler::LSL,
11189               $src3$$constant &amp; 0x1f);
11190   %}
11191 
11192   ins_pipe(ialu_reg_reg_shift);
11193 %}
11194 
11195 // This pattern is automatically generated from aarch64_ad.m4
11196 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11197 instruct XorL_reg_LShift_not_reg(iRegLNoSp dst,
11198                          iRegL src1, iRegL src2,
11199                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11200   match(Set dst (XorL src4 (XorL(LShiftL src2 src3) src1)));
11201   ins_cost(1.9 * INSN_COST);
11202   format %{ &quot;eon  $dst, $src1, $src2, LSL $src3&quot; %}
11203 
11204   ins_encode %{
11205     __ eon(as_Register($dst$$reg),
11206               as_Register($src1$$reg),
11207               as_Register($src2$$reg),
11208               Assembler::LSL,
11209               $src3$$constant &amp; 0x3f);
11210   %}
11211 
11212   ins_pipe(ialu_reg_reg_shift);
11213 %}
11214 
11215 // This pattern is automatically generated from aarch64_ad.m4
11216 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11217 instruct OrI_reg_URShift_not_reg(iRegINoSp dst,
11218                          iRegIorL2I src1, iRegIorL2I src2,
11219                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11220   match(Set dst (OrI src1 (XorI(URShiftI src2 src3) src4)));
11221   ins_cost(1.9 * INSN_COST);
11222   format %{ &quot;ornw  $dst, $src1, $src2, LSR $src3&quot; %}
11223 
11224   ins_encode %{
11225     __ ornw(as_Register($dst$$reg),
11226               as_Register($src1$$reg),
11227               as_Register($src2$$reg),
11228               Assembler::LSR,
11229               $src3$$constant &amp; 0x1f);
11230   %}
11231 
11232   ins_pipe(ialu_reg_reg_shift);
11233 %}
11234 
11235 // This pattern is automatically generated from aarch64_ad.m4
11236 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11237 instruct OrL_reg_URShift_not_reg(iRegLNoSp dst,
11238                          iRegL src1, iRegL src2,
11239                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11240   match(Set dst (OrL src1 (XorL(URShiftL src2 src3) src4)));
11241   ins_cost(1.9 * INSN_COST);
11242   format %{ &quot;orn  $dst, $src1, $src2, LSR $src3&quot; %}
11243 
11244   ins_encode %{
11245     __ orn(as_Register($dst$$reg),
11246               as_Register($src1$$reg),
11247               as_Register($src2$$reg),
11248               Assembler::LSR,
11249               $src3$$constant &amp; 0x3f);
11250   %}
11251 
11252   ins_pipe(ialu_reg_reg_shift);
11253 %}
11254 
11255 // This pattern is automatically generated from aarch64_ad.m4
11256 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11257 instruct OrI_reg_RShift_not_reg(iRegINoSp dst,
11258                          iRegIorL2I src1, iRegIorL2I src2,
11259                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11260   match(Set dst (OrI src1 (XorI(RShiftI src2 src3) src4)));
11261   ins_cost(1.9 * INSN_COST);
11262   format %{ &quot;ornw  $dst, $src1, $src2, ASR $src3&quot; %}
11263 
11264   ins_encode %{
11265     __ ornw(as_Register($dst$$reg),
11266               as_Register($src1$$reg),
11267               as_Register($src2$$reg),
11268               Assembler::ASR,
11269               $src3$$constant &amp; 0x1f);
11270   %}
11271 
11272   ins_pipe(ialu_reg_reg_shift);
11273 %}
11274 
11275 // This pattern is automatically generated from aarch64_ad.m4
11276 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11277 instruct OrL_reg_RShift_not_reg(iRegLNoSp dst,
11278                          iRegL src1, iRegL src2,
11279                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11280   match(Set dst (OrL src1 (XorL(RShiftL src2 src3) src4)));
11281   ins_cost(1.9 * INSN_COST);
11282   format %{ &quot;orn  $dst, $src1, $src2, ASR $src3&quot; %}
11283 
11284   ins_encode %{
11285     __ orn(as_Register($dst$$reg),
11286               as_Register($src1$$reg),
11287               as_Register($src2$$reg),
11288               Assembler::ASR,
11289               $src3$$constant &amp; 0x3f);
11290   %}
11291 
11292   ins_pipe(ialu_reg_reg_shift);
11293 %}
11294 
11295 // This pattern is automatically generated from aarch64_ad.m4
11296 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11297 instruct OrI_reg_LShift_not_reg(iRegINoSp dst,
11298                          iRegIorL2I src1, iRegIorL2I src2,
11299                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11300   match(Set dst (OrI src1 (XorI(LShiftI src2 src3) src4)));
11301   ins_cost(1.9 * INSN_COST);
11302   format %{ &quot;ornw  $dst, $src1, $src2, LSL $src3&quot; %}
11303 
11304   ins_encode %{
11305     __ ornw(as_Register($dst$$reg),
11306               as_Register($src1$$reg),
11307               as_Register($src2$$reg),
11308               Assembler::LSL,
11309               $src3$$constant &amp; 0x1f);
11310   %}
11311 
11312   ins_pipe(ialu_reg_reg_shift);
11313 %}
11314 
11315 // This pattern is automatically generated from aarch64_ad.m4
11316 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11317 instruct OrL_reg_LShift_not_reg(iRegLNoSp dst,
11318                          iRegL src1, iRegL src2,
11319                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11320   match(Set dst (OrL src1 (XorL(LShiftL src2 src3) src4)));
11321   ins_cost(1.9 * INSN_COST);
11322   format %{ &quot;orn  $dst, $src1, $src2, LSL $src3&quot; %}
11323 
11324   ins_encode %{
11325     __ orn(as_Register($dst$$reg),
11326               as_Register($src1$$reg),
11327               as_Register($src2$$reg),
11328               Assembler::LSL,
11329               $src3$$constant &amp; 0x3f);
11330   %}
11331 
11332   ins_pipe(ialu_reg_reg_shift);
11333 %}
11334 
11335 // This pattern is automatically generated from aarch64_ad.m4
11336 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11337 instruct AndI_reg_URShift_reg(iRegINoSp dst,
11338                          iRegIorL2I src1, iRegIorL2I src2,
11339                          immI src3, rFlagsReg cr) %{
11340   match(Set dst (AndI src1 (URShiftI src2 src3)));
11341 
11342   ins_cost(1.9 * INSN_COST);
11343   format %{ &quot;andw  $dst, $src1, $src2, LSR $src3&quot; %}
11344 
11345   ins_encode %{
11346     __ andw(as_Register($dst$$reg),
11347               as_Register($src1$$reg),
11348               as_Register($src2$$reg),
11349               Assembler::LSR,
11350               $src3$$constant &amp; 0x1f);
11351   %}
11352 
11353   ins_pipe(ialu_reg_reg_shift);
11354 %}
11355 
11356 // This pattern is automatically generated from aarch64_ad.m4
11357 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11358 instruct AndL_reg_URShift_reg(iRegLNoSp dst,
11359                          iRegL src1, iRegL src2,
11360                          immI src3, rFlagsReg cr) %{
11361   match(Set dst (AndL src1 (URShiftL src2 src3)));
11362 
11363   ins_cost(1.9 * INSN_COST);
11364   format %{ &quot;andr  $dst, $src1, $src2, LSR $src3&quot; %}
11365 
11366   ins_encode %{
11367     __ andr(as_Register($dst$$reg),
11368               as_Register($src1$$reg),
11369               as_Register($src2$$reg),
11370               Assembler::LSR,
11371               $src3$$constant &amp; 0x3f);
11372   %}
11373 
11374   ins_pipe(ialu_reg_reg_shift);
11375 %}
11376 
11377 // This pattern is automatically generated from aarch64_ad.m4
11378 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11379 instruct AndI_reg_RShift_reg(iRegINoSp dst,
11380                          iRegIorL2I src1, iRegIorL2I src2,
11381                          immI src3, rFlagsReg cr) %{
11382   match(Set dst (AndI src1 (RShiftI src2 src3)));
11383 
11384   ins_cost(1.9 * INSN_COST);
11385   format %{ &quot;andw  $dst, $src1, $src2, ASR $src3&quot; %}
11386 
11387   ins_encode %{
11388     __ andw(as_Register($dst$$reg),
11389               as_Register($src1$$reg),
11390               as_Register($src2$$reg),
11391               Assembler::ASR,
11392               $src3$$constant &amp; 0x1f);
11393   %}
11394 
11395   ins_pipe(ialu_reg_reg_shift);
11396 %}
11397 
11398 // This pattern is automatically generated from aarch64_ad.m4
11399 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11400 instruct AndL_reg_RShift_reg(iRegLNoSp dst,
11401                          iRegL src1, iRegL src2,
11402                          immI src3, rFlagsReg cr) %{
11403   match(Set dst (AndL src1 (RShiftL src2 src3)));
11404 
11405   ins_cost(1.9 * INSN_COST);
11406   format %{ &quot;andr  $dst, $src1, $src2, ASR $src3&quot; %}
11407 
11408   ins_encode %{
11409     __ andr(as_Register($dst$$reg),
11410               as_Register($src1$$reg),
11411               as_Register($src2$$reg),
11412               Assembler::ASR,
11413               $src3$$constant &amp; 0x3f);
11414   %}
11415 
11416   ins_pipe(ialu_reg_reg_shift);
11417 %}
11418 
11419 // This pattern is automatically generated from aarch64_ad.m4
11420 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11421 instruct AndI_reg_LShift_reg(iRegINoSp dst,
11422                          iRegIorL2I src1, iRegIorL2I src2,
11423                          immI src3, rFlagsReg cr) %{
11424   match(Set dst (AndI src1 (LShiftI src2 src3)));
11425 
11426   ins_cost(1.9 * INSN_COST);
11427   format %{ &quot;andw  $dst, $src1, $src2, LSL $src3&quot; %}
11428 
11429   ins_encode %{
11430     __ andw(as_Register($dst$$reg),
11431               as_Register($src1$$reg),
11432               as_Register($src2$$reg),
11433               Assembler::LSL,
11434               $src3$$constant &amp; 0x1f);
11435   %}
11436 
11437   ins_pipe(ialu_reg_reg_shift);
11438 %}
11439 
11440 // This pattern is automatically generated from aarch64_ad.m4
11441 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11442 instruct AndL_reg_LShift_reg(iRegLNoSp dst,
11443                          iRegL src1, iRegL src2,
11444                          immI src3, rFlagsReg cr) %{
11445   match(Set dst (AndL src1 (LShiftL src2 src3)));
11446 
11447   ins_cost(1.9 * INSN_COST);
11448   format %{ &quot;andr  $dst, $src1, $src2, LSL $src3&quot; %}
11449 
11450   ins_encode %{
11451     __ andr(as_Register($dst$$reg),
11452               as_Register($src1$$reg),
11453               as_Register($src2$$reg),
11454               Assembler::LSL,
11455               $src3$$constant &amp; 0x3f);
11456   %}
11457 
11458   ins_pipe(ialu_reg_reg_shift);
11459 %}
11460 
11461 // This pattern is automatically generated from aarch64_ad.m4
11462 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11463 instruct XorI_reg_URShift_reg(iRegINoSp dst,
11464                          iRegIorL2I src1, iRegIorL2I src2,
11465                          immI src3, rFlagsReg cr) %{
11466   match(Set dst (XorI src1 (URShiftI src2 src3)));
11467 
11468   ins_cost(1.9 * INSN_COST);
11469   format %{ &quot;eorw  $dst, $src1, $src2, LSR $src3&quot; %}
11470 
11471   ins_encode %{
11472     __ eorw(as_Register($dst$$reg),
11473               as_Register($src1$$reg),
11474               as_Register($src2$$reg),
11475               Assembler::LSR,
11476               $src3$$constant &amp; 0x1f);
11477   %}
11478 
11479   ins_pipe(ialu_reg_reg_shift);
11480 %}
11481 
11482 // This pattern is automatically generated from aarch64_ad.m4
11483 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11484 instruct XorL_reg_URShift_reg(iRegLNoSp dst,
11485                          iRegL src1, iRegL src2,
11486                          immI src3, rFlagsReg cr) %{
11487   match(Set dst (XorL src1 (URShiftL src2 src3)));
11488 
11489   ins_cost(1.9 * INSN_COST);
11490   format %{ &quot;eor  $dst, $src1, $src2, LSR $src3&quot; %}
11491 
11492   ins_encode %{
11493     __ eor(as_Register($dst$$reg),
11494               as_Register($src1$$reg),
11495               as_Register($src2$$reg),
11496               Assembler::LSR,
11497               $src3$$constant &amp; 0x3f);
11498   %}
11499 
11500   ins_pipe(ialu_reg_reg_shift);
11501 %}
11502 
11503 // This pattern is automatically generated from aarch64_ad.m4
11504 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11505 instruct XorI_reg_RShift_reg(iRegINoSp dst,
11506                          iRegIorL2I src1, iRegIorL2I src2,
11507                          immI src3, rFlagsReg cr) %{
11508   match(Set dst (XorI src1 (RShiftI src2 src3)));
11509 
11510   ins_cost(1.9 * INSN_COST);
11511   format %{ &quot;eorw  $dst, $src1, $src2, ASR $src3&quot; %}
11512 
11513   ins_encode %{
11514     __ eorw(as_Register($dst$$reg),
11515               as_Register($src1$$reg),
11516               as_Register($src2$$reg),
11517               Assembler::ASR,
11518               $src3$$constant &amp; 0x1f);
11519   %}
11520 
11521   ins_pipe(ialu_reg_reg_shift);
11522 %}
11523 
11524 // This pattern is automatically generated from aarch64_ad.m4
11525 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11526 instruct XorL_reg_RShift_reg(iRegLNoSp dst,
11527                          iRegL src1, iRegL src2,
11528                          immI src3, rFlagsReg cr) %{
11529   match(Set dst (XorL src1 (RShiftL src2 src3)));
11530 
11531   ins_cost(1.9 * INSN_COST);
11532   format %{ &quot;eor  $dst, $src1, $src2, ASR $src3&quot; %}
11533 
11534   ins_encode %{
11535     __ eor(as_Register($dst$$reg),
11536               as_Register($src1$$reg),
11537               as_Register($src2$$reg),
11538               Assembler::ASR,
11539               $src3$$constant &amp; 0x3f);
11540   %}
11541 
11542   ins_pipe(ialu_reg_reg_shift);
11543 %}
11544 
11545 // This pattern is automatically generated from aarch64_ad.m4
11546 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11547 instruct XorI_reg_LShift_reg(iRegINoSp dst,
11548                          iRegIorL2I src1, iRegIorL2I src2,
11549                          immI src3, rFlagsReg cr) %{
11550   match(Set dst (XorI src1 (LShiftI src2 src3)));
11551 
11552   ins_cost(1.9 * INSN_COST);
11553   format %{ &quot;eorw  $dst, $src1, $src2, LSL $src3&quot; %}
11554 
11555   ins_encode %{
11556     __ eorw(as_Register($dst$$reg),
11557               as_Register($src1$$reg),
11558               as_Register($src2$$reg),
11559               Assembler::LSL,
11560               $src3$$constant &amp; 0x1f);
11561   %}
11562 
11563   ins_pipe(ialu_reg_reg_shift);
11564 %}
11565 
11566 // This pattern is automatically generated from aarch64_ad.m4
11567 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11568 instruct XorL_reg_LShift_reg(iRegLNoSp dst,
11569                          iRegL src1, iRegL src2,
11570                          immI src3, rFlagsReg cr) %{
11571   match(Set dst (XorL src1 (LShiftL src2 src3)));
11572 
11573   ins_cost(1.9 * INSN_COST);
11574   format %{ &quot;eor  $dst, $src1, $src2, LSL $src3&quot; %}
11575 
11576   ins_encode %{
11577     __ eor(as_Register($dst$$reg),
11578               as_Register($src1$$reg),
11579               as_Register($src2$$reg),
11580               Assembler::LSL,
11581               $src3$$constant &amp; 0x3f);
11582   %}
11583 
11584   ins_pipe(ialu_reg_reg_shift);
11585 %}
11586 
11587 // This pattern is automatically generated from aarch64_ad.m4
11588 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11589 instruct OrI_reg_URShift_reg(iRegINoSp dst,
11590                          iRegIorL2I src1, iRegIorL2I src2,
11591                          immI src3, rFlagsReg cr) %{
11592   match(Set dst (OrI src1 (URShiftI src2 src3)));
11593 
11594   ins_cost(1.9 * INSN_COST);
11595   format %{ &quot;orrw  $dst, $src1, $src2, LSR $src3&quot; %}
11596 
11597   ins_encode %{
11598     __ orrw(as_Register($dst$$reg),
11599               as_Register($src1$$reg),
11600               as_Register($src2$$reg),
11601               Assembler::LSR,
11602               $src3$$constant &amp; 0x1f);
11603   %}
11604 
11605   ins_pipe(ialu_reg_reg_shift);
11606 %}
11607 
11608 // This pattern is automatically generated from aarch64_ad.m4
11609 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11610 instruct OrL_reg_URShift_reg(iRegLNoSp dst,
11611                          iRegL src1, iRegL src2,
11612                          immI src3, rFlagsReg cr) %{
11613   match(Set dst (OrL src1 (URShiftL src2 src3)));
11614 
11615   ins_cost(1.9 * INSN_COST);
11616   format %{ &quot;orr  $dst, $src1, $src2, LSR $src3&quot; %}
11617 
11618   ins_encode %{
11619     __ orr(as_Register($dst$$reg),
11620               as_Register($src1$$reg),
11621               as_Register($src2$$reg),
11622               Assembler::LSR,
11623               $src3$$constant &amp; 0x3f);
11624   %}
11625 
11626   ins_pipe(ialu_reg_reg_shift);
11627 %}
11628 
11629 // This pattern is automatically generated from aarch64_ad.m4
11630 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11631 instruct OrI_reg_RShift_reg(iRegINoSp dst,
11632                          iRegIorL2I src1, iRegIorL2I src2,
11633                          immI src3, rFlagsReg cr) %{
11634   match(Set dst (OrI src1 (RShiftI src2 src3)));
11635 
11636   ins_cost(1.9 * INSN_COST);
11637   format %{ &quot;orrw  $dst, $src1, $src2, ASR $src3&quot; %}
11638 
11639   ins_encode %{
11640     __ orrw(as_Register($dst$$reg),
11641               as_Register($src1$$reg),
11642               as_Register($src2$$reg),
11643               Assembler::ASR,
11644               $src3$$constant &amp; 0x1f);
11645   %}
11646 
11647   ins_pipe(ialu_reg_reg_shift);
11648 %}
11649 
11650 // This pattern is automatically generated from aarch64_ad.m4
11651 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11652 instruct OrL_reg_RShift_reg(iRegLNoSp dst,
11653                          iRegL src1, iRegL src2,
11654                          immI src3, rFlagsReg cr) %{
11655   match(Set dst (OrL src1 (RShiftL src2 src3)));
11656 
11657   ins_cost(1.9 * INSN_COST);
11658   format %{ &quot;orr  $dst, $src1, $src2, ASR $src3&quot; %}
11659 
11660   ins_encode %{
11661     __ orr(as_Register($dst$$reg),
11662               as_Register($src1$$reg),
11663               as_Register($src2$$reg),
11664               Assembler::ASR,
11665               $src3$$constant &amp; 0x3f);
11666   %}
11667 
11668   ins_pipe(ialu_reg_reg_shift);
11669 %}
11670 
11671 // This pattern is automatically generated from aarch64_ad.m4
11672 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11673 instruct OrI_reg_LShift_reg(iRegINoSp dst,
11674                          iRegIorL2I src1, iRegIorL2I src2,
11675                          immI src3, rFlagsReg cr) %{
11676   match(Set dst (OrI src1 (LShiftI src2 src3)));
11677 
11678   ins_cost(1.9 * INSN_COST);
11679   format %{ &quot;orrw  $dst, $src1, $src2, LSL $src3&quot; %}
11680 
11681   ins_encode %{
11682     __ orrw(as_Register($dst$$reg),
11683               as_Register($src1$$reg),
11684               as_Register($src2$$reg),
11685               Assembler::LSL,
11686               $src3$$constant &amp; 0x1f);
11687   %}
11688 
11689   ins_pipe(ialu_reg_reg_shift);
11690 %}
11691 
11692 // This pattern is automatically generated from aarch64_ad.m4
11693 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11694 instruct OrL_reg_LShift_reg(iRegLNoSp dst,
11695                          iRegL src1, iRegL src2,
11696                          immI src3, rFlagsReg cr) %{
11697   match(Set dst (OrL src1 (LShiftL src2 src3)));
11698 
11699   ins_cost(1.9 * INSN_COST);
11700   format %{ &quot;orr  $dst, $src1, $src2, LSL $src3&quot; %}
11701 
11702   ins_encode %{
11703     __ orr(as_Register($dst$$reg),
11704               as_Register($src1$$reg),
11705               as_Register($src2$$reg),
11706               Assembler::LSL,
11707               $src3$$constant &amp; 0x3f);
11708   %}
11709 
11710   ins_pipe(ialu_reg_reg_shift);
11711 %}
11712 
11713 // This pattern is automatically generated from aarch64_ad.m4
11714 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11715 instruct AddI_reg_URShift_reg(iRegINoSp dst,
11716                          iRegIorL2I src1, iRegIorL2I src2,
11717                          immI src3, rFlagsReg cr) %{
11718   match(Set dst (AddI src1 (URShiftI src2 src3)));
11719 
11720   ins_cost(1.9 * INSN_COST);
11721   format %{ &quot;addw  $dst, $src1, $src2, LSR $src3&quot; %}
11722 
11723   ins_encode %{
11724     __ addw(as_Register($dst$$reg),
11725               as_Register($src1$$reg),
11726               as_Register($src2$$reg),
11727               Assembler::LSR,
11728               $src3$$constant &amp; 0x1f);
11729   %}
11730 
11731   ins_pipe(ialu_reg_reg_shift);
11732 %}
11733 
11734 // This pattern is automatically generated from aarch64_ad.m4
11735 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11736 instruct AddL_reg_URShift_reg(iRegLNoSp dst,
11737                          iRegL src1, iRegL src2,
11738                          immI src3, rFlagsReg cr) %{
11739   match(Set dst (AddL src1 (URShiftL src2 src3)));
11740 
11741   ins_cost(1.9 * INSN_COST);
11742   format %{ &quot;add  $dst, $src1, $src2, LSR $src3&quot; %}
11743 
11744   ins_encode %{
11745     __ add(as_Register($dst$$reg),
11746               as_Register($src1$$reg),
11747               as_Register($src2$$reg),
11748               Assembler::LSR,
11749               $src3$$constant &amp; 0x3f);
11750   %}
11751 
11752   ins_pipe(ialu_reg_reg_shift);
11753 %}
11754 
11755 // This pattern is automatically generated from aarch64_ad.m4
11756 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11757 instruct AddI_reg_RShift_reg(iRegINoSp dst,
11758                          iRegIorL2I src1, iRegIorL2I src2,
11759                          immI src3, rFlagsReg cr) %{
11760   match(Set dst (AddI src1 (RShiftI src2 src3)));
11761 
11762   ins_cost(1.9 * INSN_COST);
11763   format %{ &quot;addw  $dst, $src1, $src2, ASR $src3&quot; %}
11764 
11765   ins_encode %{
11766     __ addw(as_Register($dst$$reg),
11767               as_Register($src1$$reg),
11768               as_Register($src2$$reg),
11769               Assembler::ASR,
11770               $src3$$constant &amp; 0x1f);
11771   %}
11772 
11773   ins_pipe(ialu_reg_reg_shift);
11774 %}
11775 
11776 // This pattern is automatically generated from aarch64_ad.m4
11777 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11778 instruct AddL_reg_RShift_reg(iRegLNoSp dst,
11779                          iRegL src1, iRegL src2,
11780                          immI src3, rFlagsReg cr) %{
11781   match(Set dst (AddL src1 (RShiftL src2 src3)));
11782 
11783   ins_cost(1.9 * INSN_COST);
11784   format %{ &quot;add  $dst, $src1, $src2, ASR $src3&quot; %}
11785 
11786   ins_encode %{
11787     __ add(as_Register($dst$$reg),
11788               as_Register($src1$$reg),
11789               as_Register($src2$$reg),
11790               Assembler::ASR,
11791               $src3$$constant &amp; 0x3f);
11792   %}
11793 
11794   ins_pipe(ialu_reg_reg_shift);
11795 %}
11796 
11797 // This pattern is automatically generated from aarch64_ad.m4
11798 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11799 instruct AddI_reg_LShift_reg(iRegINoSp dst,
11800                          iRegIorL2I src1, iRegIorL2I src2,
11801                          immI src3, rFlagsReg cr) %{
11802   match(Set dst (AddI src1 (LShiftI src2 src3)));
11803 
11804   ins_cost(1.9 * INSN_COST);
11805   format %{ &quot;addw  $dst, $src1, $src2, LSL $src3&quot; %}
11806 
11807   ins_encode %{
11808     __ addw(as_Register($dst$$reg),
11809               as_Register($src1$$reg),
11810               as_Register($src2$$reg),
11811               Assembler::LSL,
11812               $src3$$constant &amp; 0x1f);
11813   %}
11814 
11815   ins_pipe(ialu_reg_reg_shift);
11816 %}
11817 
11818 // This pattern is automatically generated from aarch64_ad.m4
11819 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11820 instruct AddL_reg_LShift_reg(iRegLNoSp dst,
11821                          iRegL src1, iRegL src2,
11822                          immI src3, rFlagsReg cr) %{
11823   match(Set dst (AddL src1 (LShiftL src2 src3)));
11824 
11825   ins_cost(1.9 * INSN_COST);
11826   format %{ &quot;add  $dst, $src1, $src2, LSL $src3&quot; %}
11827 
11828   ins_encode %{
11829     __ add(as_Register($dst$$reg),
11830               as_Register($src1$$reg),
11831               as_Register($src2$$reg),
11832               Assembler::LSL,
11833               $src3$$constant &amp; 0x3f);
11834   %}
11835 
11836   ins_pipe(ialu_reg_reg_shift);
11837 %}
11838 
11839 // This pattern is automatically generated from aarch64_ad.m4
11840 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11841 instruct SubI_reg_URShift_reg(iRegINoSp dst,
11842                          iRegIorL2I src1, iRegIorL2I src2,
11843                          immI src3, rFlagsReg cr) %{
11844   match(Set dst (SubI src1 (URShiftI src2 src3)));
11845 
11846   ins_cost(1.9 * INSN_COST);
11847   format %{ &quot;subw  $dst, $src1, $src2, LSR $src3&quot; %}
11848 
11849   ins_encode %{
11850     __ subw(as_Register($dst$$reg),
11851               as_Register($src1$$reg),
11852               as_Register($src2$$reg),
11853               Assembler::LSR,
11854               $src3$$constant &amp; 0x1f);
11855   %}
11856 
11857   ins_pipe(ialu_reg_reg_shift);
11858 %}
11859 
11860 // This pattern is automatically generated from aarch64_ad.m4
11861 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11862 instruct SubL_reg_URShift_reg(iRegLNoSp dst,
11863                          iRegL src1, iRegL src2,
11864                          immI src3, rFlagsReg cr) %{
11865   match(Set dst (SubL src1 (URShiftL src2 src3)));
11866 
11867   ins_cost(1.9 * INSN_COST);
11868   format %{ &quot;sub  $dst, $src1, $src2, LSR $src3&quot; %}
11869 
11870   ins_encode %{
11871     __ sub(as_Register($dst$$reg),
11872               as_Register($src1$$reg),
11873               as_Register($src2$$reg),
11874               Assembler::LSR,
11875               $src3$$constant &amp; 0x3f);
11876   %}
11877 
11878   ins_pipe(ialu_reg_reg_shift);
11879 %}
11880 
11881 // This pattern is automatically generated from aarch64_ad.m4
11882 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11883 instruct SubI_reg_RShift_reg(iRegINoSp dst,
11884                          iRegIorL2I src1, iRegIorL2I src2,
11885                          immI src3, rFlagsReg cr) %{
11886   match(Set dst (SubI src1 (RShiftI src2 src3)));
11887 
11888   ins_cost(1.9 * INSN_COST);
11889   format %{ &quot;subw  $dst, $src1, $src2, ASR $src3&quot; %}
11890 
11891   ins_encode %{
11892     __ subw(as_Register($dst$$reg),
11893               as_Register($src1$$reg),
11894               as_Register($src2$$reg),
11895               Assembler::ASR,
11896               $src3$$constant &amp; 0x1f);
11897   %}
11898 
11899   ins_pipe(ialu_reg_reg_shift);
11900 %}
11901 
11902 // This pattern is automatically generated from aarch64_ad.m4
11903 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11904 instruct SubL_reg_RShift_reg(iRegLNoSp dst,
11905                          iRegL src1, iRegL src2,
11906                          immI src3, rFlagsReg cr) %{
11907   match(Set dst (SubL src1 (RShiftL src2 src3)));
11908 
11909   ins_cost(1.9 * INSN_COST);
11910   format %{ &quot;sub  $dst, $src1, $src2, ASR $src3&quot; %}
11911 
11912   ins_encode %{
11913     __ sub(as_Register($dst$$reg),
11914               as_Register($src1$$reg),
11915               as_Register($src2$$reg),
11916               Assembler::ASR,
11917               $src3$$constant &amp; 0x3f);
11918   %}
11919 
11920   ins_pipe(ialu_reg_reg_shift);
11921 %}
11922 
11923 // This pattern is automatically generated from aarch64_ad.m4
11924 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11925 instruct SubI_reg_LShift_reg(iRegINoSp dst,
11926                          iRegIorL2I src1, iRegIorL2I src2,
11927                          immI src3, rFlagsReg cr) %{
11928   match(Set dst (SubI src1 (LShiftI src2 src3)));
11929 
11930   ins_cost(1.9 * INSN_COST);
11931   format %{ &quot;subw  $dst, $src1, $src2, LSL $src3&quot; %}
11932 
11933   ins_encode %{
11934     __ subw(as_Register($dst$$reg),
11935               as_Register($src1$$reg),
11936               as_Register($src2$$reg),
11937               Assembler::LSL,
11938               $src3$$constant &amp; 0x1f);
11939   %}
11940 
11941   ins_pipe(ialu_reg_reg_shift);
11942 %}
11943 
11944 // This pattern is automatically generated from aarch64_ad.m4
11945 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11946 instruct SubL_reg_LShift_reg(iRegLNoSp dst,
11947                          iRegL src1, iRegL src2,
11948                          immI src3, rFlagsReg cr) %{
11949   match(Set dst (SubL src1 (LShiftL src2 src3)));
11950 
11951   ins_cost(1.9 * INSN_COST);
11952   format %{ &quot;sub  $dst, $src1, $src2, LSL $src3&quot; %}
11953 
11954   ins_encode %{
11955     __ sub(as_Register($dst$$reg),
11956               as_Register($src1$$reg),
11957               as_Register($src2$$reg),
11958               Assembler::LSL,
11959               $src3$$constant &amp; 0x3f);
11960   %}
11961 
11962   ins_pipe(ialu_reg_reg_shift);
11963 %}
11964 
11965  
11966 // This pattern is automatically generated from aarch64_ad.m4
11967 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11968 
11969 // Shift Left followed by Shift Right.
11970 // This idiom is used by the compiler for the i2b bytecode etc.
11971 instruct sbfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11972 %{
11973   match(Set dst (RShiftL (LShiftL src lshift_count) rshift_count));
11974   ins_cost(INSN_COST * 2);
11975   format %{ &quot;sbfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11976   ins_encode %{
11977     int lshift = $lshift_count$$constant &amp; 63;
11978     int rshift = $rshift_count$$constant &amp; 63;
11979     int s = 63 - lshift;
11980     int r = (rshift - lshift) &amp; 63;
11981     __ sbfm(as_Register($dst$$reg),
11982             as_Register($src$$reg),
11983             r, s);
11984   %}
11985 
11986   ins_pipe(ialu_reg_shift);
11987 %}
11988 
11989 // This pattern is automatically generated from aarch64_ad.m4
11990 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
11991 
11992 // Shift Left followed by Shift Right.
11993 // This idiom is used by the compiler for the i2b bytecode etc.
11994 instruct sbfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11995 %{
11996   match(Set dst (RShiftI (LShiftI src lshift_count) rshift_count));
11997   ins_cost(INSN_COST * 2);
11998   format %{ &quot;sbfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
11999   ins_encode %{
12000     int lshift = $lshift_count$$constant &amp; 31;
12001     int rshift = $rshift_count$$constant &amp; 31;
12002     int s = 31 - lshift;
12003     int r = (rshift - lshift) &amp; 31;
12004     __ sbfmw(as_Register($dst$$reg),
12005             as_Register($src$$reg),
12006             r, s);
12007   %}
12008 
12009   ins_pipe(ialu_reg_shift);
12010 %}
12011 
12012 // This pattern is automatically generated from aarch64_ad.m4
12013 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12014 
12015 // Shift Left followed by Shift Right.
12016 // This idiom is used by the compiler for the i2b bytecode etc.
12017 instruct ubfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
12018 %{
12019   match(Set dst (URShiftL (LShiftL src lshift_count) rshift_count));
12020   ins_cost(INSN_COST * 2);
12021   format %{ &quot;ubfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
12022   ins_encode %{
12023     int lshift = $lshift_count$$constant &amp; 63;
12024     int rshift = $rshift_count$$constant &amp; 63;
12025     int s = 63 - lshift;
12026     int r = (rshift - lshift) &amp; 63;
12027     __ ubfm(as_Register($dst$$reg),
12028             as_Register($src$$reg),
12029             r, s);
12030   %}
12031 
12032   ins_pipe(ialu_reg_shift);
12033 %}
12034 
12035 // This pattern is automatically generated from aarch64_ad.m4
12036 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12037 
12038 // Shift Left followed by Shift Right.
12039 // This idiom is used by the compiler for the i2b bytecode etc.
12040 instruct ubfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
12041 %{
12042   match(Set dst (URShiftI (LShiftI src lshift_count) rshift_count));
12043   ins_cost(INSN_COST * 2);
12044   format %{ &quot;ubfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
12045   ins_encode %{
12046     int lshift = $lshift_count$$constant &amp; 31;
12047     int rshift = $rshift_count$$constant &amp; 31;
12048     int s = 31 - lshift;
12049     int r = (rshift - lshift) &amp; 31;
12050     __ ubfmw(as_Register($dst$$reg),
12051             as_Register($src$$reg),
12052             r, s);
12053   %}
12054 
12055   ins_pipe(ialu_reg_shift);
12056 %}
12057 
12058 // Bitfield extract with shift &amp; mask
12059 
12060 // This pattern is automatically generated from aarch64_ad.m4
12061 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12062 instruct ubfxwI(iRegINoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
12063 %{
12064   match(Set dst (AndI (URShiftI src rshift) mask));
12065   // Make sure we are not going to exceed what ubfxw can do.
12066   predicate((exact_log2(n-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12067 
12068   ins_cost(INSN_COST);
12069   format %{ &quot;ubfxw $dst, $src, $rshift, $mask&quot; %}
12070   ins_encode %{
12071     int rshift = $rshift$$constant &amp; 31;
12072     intptr_t mask = $mask$$constant;
12073     int width = exact_log2(mask+1);
12074     __ ubfxw(as_Register($dst$$reg),
12075             as_Register($src$$reg), rshift, width);
12076   %}
12077   ins_pipe(ialu_reg_shift);
12078 %}
12079 
12080 // This pattern is automatically generated from aarch64_ad.m4
12081 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12082 instruct ubfxL(iRegLNoSp dst, iRegL src, immI rshift, immL_bitmask mask)
12083 %{
12084   match(Set dst (AndL (URShiftL src rshift) mask));
12085   // Make sure we are not going to exceed what ubfx can do.
12086   predicate((exact_log2_long(n-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12087 
12088   ins_cost(INSN_COST);
12089   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12090   ins_encode %{
12091     int rshift = $rshift$$constant &amp; 63;
12092     intptr_t mask = $mask$$constant;
12093     int width = exact_log2_long(mask+1);
12094     __ ubfx(as_Register($dst$$reg),
12095             as_Register($src$$reg), rshift, width);
12096   %}
12097   ins_pipe(ialu_reg_shift);
12098 %}
12099 
12100 
12101 // This pattern is automatically generated from aarch64_ad.m4
12102 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12103 
12104 // We can use ubfx when extending an And with a mask when we know mask
12105 // is positive.  We know that because immI_bitmask guarantees it.
12106 instruct ubfxIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
12107 %{
12108   match(Set dst (ConvI2L (AndI (URShiftI src rshift) mask)));
12109   // Make sure we are not going to exceed what ubfxw can do.
12110   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12111 
12112   ins_cost(INSN_COST * 2);
12113   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12114   ins_encode %{
12115     int rshift = $rshift$$constant &amp; 31;
12116     intptr_t mask = $mask$$constant;
12117     int width = exact_log2(mask+1);
12118     __ ubfx(as_Register($dst$$reg),
12119             as_Register($src$$reg), rshift, width);
12120   %}
12121   ins_pipe(ialu_reg_shift);
12122 %}
12123 
12124 
12125 // This pattern is automatically generated from aarch64_ad.m4
12126 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12127 
12128 // We can use ubfiz when masking by a positive number and then left shifting the result.
12129 // We know that the mask is positive because immI_bitmask guarantees it.
12130 instruct ubfizwI(iRegINoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12131 %{
12132   match(Set dst (LShiftI (AndI src mask) lshift));
12133   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12134 
12135   ins_cost(INSN_COST);
12136   format %{ &quot;ubfizw $dst, $src, $lshift, $mask&quot; %}
12137   ins_encode %{
12138     int lshift = $lshift$$constant &amp; 31;
12139     intptr_t mask = $mask$$constant;
12140     int width = exact_log2(mask+1);
12141     __ ubfizw(as_Register($dst$$reg),
12142           as_Register($src$$reg), lshift, width);
12143   %}
12144   ins_pipe(ialu_reg_shift);
12145 %}
12146 
12147 // This pattern is automatically generated from aarch64_ad.m4
12148 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12149 
12150 // We can use ubfiz when masking by a positive number and then left shifting the result.
12151 // We know that the mask is positive because immL_bitmask guarantees it.
12152 instruct ubfizL(iRegLNoSp dst, iRegL src, immI lshift, immL_bitmask mask)
12153 %{
12154   match(Set dst (LShiftL (AndL src mask) lshift));
12155   predicate((exact_log2_long(n-&gt;in(1)-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12156 
12157   ins_cost(INSN_COST);
12158   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12159   ins_encode %{
12160     int lshift = $lshift$$constant &amp; 63;
12161     intptr_t mask = $mask$$constant;
12162     int width = exact_log2_long(mask+1);
12163     __ ubfiz(as_Register($dst$$reg),
12164           as_Register($src$$reg), lshift, width);
12165   %}
12166   ins_pipe(ialu_reg_shift);
12167 %}
12168 
<a name="3" id="anc3"></a><span class="line-added">12169 // This pattern is automatically generated from aarch64_ad.m4</span>
<span class="line-added">12170 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE</span>
<span class="line-added">12171 </span>
<span class="line-added">12172 // We can use ubfiz when masking by a positive number and then left shifting the result.</span>
<span class="line-added">12173 // We know that the mask is positive because immI_bitmask guarantees it.</span>
<span class="line-added">12174 instruct ubfizwIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)</span>
<span class="line-added">12175 %{</span>
<span class="line-added">12176   match(Set dst (ConvI2L (LShiftI (AndI src mask) lshift)));</span>
<span class="line-added">12177   predicate((exact_log2(n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= 31);</span>
<span class="line-added">12178 </span>
<span class="line-added">12179   ins_cost(INSN_COST);</span>
<span class="line-added">12180   format %{ &quot;ubfizw $dst, $src, $lshift, $mask&quot; %}</span>
<span class="line-added">12181   ins_encode %{</span>
<span class="line-added">12182     int lshift = $lshift$$constant &amp; 31;</span>
<span class="line-added">12183     intptr_t mask = $mask$$constant;</span>
<span class="line-added">12184     int width = exact_log2(mask+1);</span>
<span class="line-added">12185     __ ubfizw(as_Register($dst$$reg),</span>
<span class="line-added">12186           as_Register($src$$reg), lshift, width);</span>
<span class="line-added">12187   %}</span>
<span class="line-added">12188   ins_pipe(ialu_reg_shift);</span>
<span class="line-added">12189 %}</span>
<span class="line-added">12190 </span>
<span class="line-added">12191 // This pattern is automatically generated from aarch64_ad.m4</span>
<span class="line-added">12192 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE</span>
<span class="line-added">12193 </span>
<span class="line-added">12194 // We can use ubfiz when masking by a positive number and then left shifting the result.</span>
<span class="line-added">12195 // We know that the mask is positive because immL_bitmask guarantees it.</span>
<span class="line-added">12196 instruct ubfizLConvL2I(iRegINoSp dst, iRegL src, immI lshift, immL_positive_bitmaskI mask)</span>
<span class="line-added">12197 %{</span>
<span class="line-added">12198   match(Set dst (ConvL2I (LShiftL (AndL src mask) lshift)));</span>
<span class="line-added">12199   predicate((exact_log2_long(n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= 31);</span>
<span class="line-added">12200 </span>
<span class="line-added">12201   ins_cost(INSN_COST);</span>
<span class="line-added">12202   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}</span>
<span class="line-added">12203   ins_encode %{</span>
<span class="line-added">12204     int lshift = $lshift$$constant &amp; 63;</span>
<span class="line-added">12205     intptr_t mask = $mask$$constant;</span>
<span class="line-added">12206     int width = exact_log2_long(mask+1);</span>
<span class="line-added">12207     __ ubfiz(as_Register($dst$$reg),</span>
<span class="line-added">12208           as_Register($src$$reg), lshift, width);</span>
<span class="line-added">12209   %}</span>
<span class="line-added">12210   ins_pipe(ialu_reg_shift);</span>
<span class="line-added">12211 %}</span>
<span class="line-added">12212 </span>
12213 
12214 // This pattern is automatically generated from aarch64_ad.m4
12215 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12216 
12217 // If there is a convert I to L block between and AndI and a LShiftL, we can also match ubfiz
12218 instruct ubfizIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12219 %{
12220   match(Set dst (LShiftL (ConvI2L (AndI src mask)) lshift));
12221   predicate((exact_log2(n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12222 
12223   ins_cost(INSN_COST);
12224   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12225   ins_encode %{
12226     int lshift = $lshift$$constant &amp; 63;
12227     intptr_t mask = $mask$$constant;
12228     int width = exact_log2(mask+1);
12229     __ ubfiz(as_Register($dst$$reg),
12230              as_Register($src$$reg), lshift, width);
12231   %}
12232   ins_pipe(ialu_reg_shift);
12233 %}
12234 
<a name="4" id="anc4"></a><span class="line-added">12235 // This pattern is automatically generated from aarch64_ad.m4</span>
<span class="line-added">12236 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE</span>
<span class="line-added">12237 </span>
<span class="line-added">12238 // If there is a convert L to I block between and AndL and a LShiftI, we can also match ubfiz</span>
<span class="line-added">12239 instruct ubfizLConvL2Ix(iRegINoSp dst, iRegL src, immI lshift, immL_positive_bitmaskI mask)</span>
<span class="line-added">12240 %{</span>
<span class="line-added">12241   match(Set dst (LShiftI (ConvL2I (AndL src mask)) lshift));</span>
<span class="line-added">12242   predicate((exact_log2_long(n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= 31);</span>
<span class="line-added">12243 </span>
<span class="line-added">12244   ins_cost(INSN_COST);</span>
<span class="line-added">12245   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}</span>
<span class="line-added">12246   ins_encode %{</span>
<span class="line-added">12247     int lshift = $lshift$$constant &amp; 31;</span>
<span class="line-added">12248     intptr_t mask = $mask$$constant;</span>
<span class="line-added">12249     int width = exact_log2(mask+1);</span>
<span class="line-added">12250     __ ubfiz(as_Register($dst$$reg),</span>
<span class="line-added">12251              as_Register($src$$reg), lshift, width);</span>
<span class="line-added">12252   %}</span>
<span class="line-added">12253   ins_pipe(ialu_reg_shift);</span>
<span class="line-added">12254 %}</span>
<span class="line-added">12255 </span>
<span class="line-added">12256 // This pattern is automatically generated from aarch64_ad.m4</span>
<span class="line-added">12257 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE</span>
<span class="line-added">12258 </span>
<span class="line-added">12259 // Can skip int2long conversions after AND with small bitmask</span>
<span class="line-added">12260 instruct ubfizIConvI2LAndI(iRegLNoSp dst, iRegI src, immI_bitmask msk)</span>
<span class="line-added">12261 %{</span>
<span class="line-added">12262   match(Set dst (ConvI2L (AndI src msk)));</span>
<span class="line-added">12263   ins_cost(INSN_COST);</span>
<span class="line-added">12264   format %{ &quot;ubfiz $dst, $src, 0, exact_log2($msk + 1) &quot; %}</span>
<span class="line-added">12265   ins_encode %{</span>
<span class="line-added">12266     __ ubfiz(as_Register($dst$$reg), as_Register($src$$reg), 0, exact_log2($msk$$constant + 1));</span>
<span class="line-added">12267   %}</span>
<span class="line-added">12268   ins_pipe(ialu_reg_shift);</span>
<span class="line-added">12269 %}</span>
<span class="line-added">12270 </span>
12271 
12272 // Rotations 
12273 // This pattern is automatically generated from aarch64_ad.m4
12274 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12275 instruct extrOrL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12276 %{
12277   match(Set dst (OrL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12278   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12279 
12280   ins_cost(INSN_COST);
12281   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12282 
12283   ins_encode %{
12284     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12285             $rshift$$constant &amp; 63);
12286   %}
12287   ins_pipe(ialu_reg_reg_extr);
12288 %}
12289 
12290 
12291 // This pattern is automatically generated from aarch64_ad.m4
12292 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12293 instruct extrOrI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12294 %{
12295   match(Set dst (OrI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12296   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12297 
12298   ins_cost(INSN_COST);
12299   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12300 
12301   ins_encode %{
12302     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12303             $rshift$$constant &amp; 31);
12304   %}
12305   ins_pipe(ialu_reg_reg_extr);
12306 %}
12307 
12308 
12309 // This pattern is automatically generated from aarch64_ad.m4
12310 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12311 instruct extrAddL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12312 %{
12313   match(Set dst (AddL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12314   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12315 
12316   ins_cost(INSN_COST);
12317   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12318 
12319   ins_encode %{
12320     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12321             $rshift$$constant &amp; 63);
12322   %}
12323   ins_pipe(ialu_reg_reg_extr);
12324 %}
12325 
12326 
12327 // This pattern is automatically generated from aarch64_ad.m4
12328 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12329 instruct extrAddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12330 %{
12331   match(Set dst (AddI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12332   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12333 
12334   ins_cost(INSN_COST);
12335   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12336 
12337   ins_encode %{
12338     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12339             $rshift$$constant &amp; 31);
12340   %}
12341   ins_pipe(ialu_reg_reg_extr);
12342 %}
12343 
12344 
12345 // This pattern is automatically generated from aarch64_ad.m4
12346 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12347 
12348 // rol expander
12349 instruct rolL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12350 %{
12351   effect(DEF dst, USE src, USE shift);
12352 
12353   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12354   ins_cost(INSN_COST * 3);
12355   ins_encode %{
12356     __ subw(rscratch1, zr, as_Register($shift$$reg));
12357     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12358             rscratch1);
12359     %}
12360   ins_pipe(ialu_reg_reg_vshift);
12361 %}
12362 
12363 // This pattern is automatically generated from aarch64_ad.m4
12364 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12365 
12366 // rol expander
12367 instruct rolI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12368 %{
12369   effect(DEF dst, USE src, USE shift);
12370 
12371   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12372   ins_cost(INSN_COST * 3);
12373   ins_encode %{
12374     __ subw(rscratch1, zr, as_Register($shift$$reg));
12375     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12376             rscratch1);
12377     %}
12378   ins_pipe(ialu_reg_reg_vshift);
12379 %}
12380 
12381 // This pattern is automatically generated from aarch64_ad.m4
12382 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12383 instruct rolL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12384 %{
12385   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c_64 shift))));
12386 
12387   expand %{
12388     rolL_rReg(dst, src, shift, cr);
12389   %}
12390 %}
12391 
12392 // This pattern is automatically generated from aarch64_ad.m4
12393 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12394 instruct rolL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12395 %{
12396   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c0 shift))));
12397 
12398   expand %{
12399     rolL_rReg(dst, src, shift, cr);
12400   %}
12401 %}
12402 
12403 // This pattern is automatically generated from aarch64_ad.m4
12404 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12405 instruct rolI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12406 %{
12407   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c_32 shift))));
12408 
12409   expand %{
12410     rolI_rReg(dst, src, shift, cr);
12411   %}
12412 %}
12413 
12414 // This pattern is automatically generated from aarch64_ad.m4
12415 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12416 instruct rolI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12417 %{
12418   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c0 shift))));
12419 
12420   expand %{
12421     rolI_rReg(dst, src, shift, cr);
12422   %}
12423 %}
12424 
12425 // This pattern is automatically generated from aarch64_ad.m4
12426 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12427 
12428 // ror expander
12429 instruct rorL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12430 %{
12431   effect(DEF dst, USE src, USE shift);
12432 
12433   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12434   ins_cost(INSN_COST);
12435   ins_encode %{
12436     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12437             as_Register($shift$$reg));
12438     %}
12439   ins_pipe(ialu_reg_reg_vshift);
12440 %}
12441 
12442 // This pattern is automatically generated from aarch64_ad.m4
12443 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12444 
12445 // ror expander
12446 instruct rorI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12447 %{
12448   effect(DEF dst, USE src, USE shift);
12449 
12450   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12451   ins_cost(INSN_COST);
12452   ins_encode %{
12453     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12454             as_Register($shift$$reg));
12455     %}
12456   ins_pipe(ialu_reg_reg_vshift);
12457 %}
12458 
12459 // This pattern is automatically generated from aarch64_ad.m4
12460 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12461 instruct rorL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12462 %{
12463   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c_64 shift))));
12464 
12465   expand %{
12466     rorL_rReg(dst, src, shift, cr);
12467   %}
12468 %}
12469 
12470 // This pattern is automatically generated from aarch64_ad.m4
12471 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12472 instruct rorL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12473 %{
12474   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c0 shift))));
12475 
12476   expand %{
12477     rorL_rReg(dst, src, shift, cr);
12478   %}
12479 %}
12480 
12481 // This pattern is automatically generated from aarch64_ad.m4
12482 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12483 instruct rorI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12484 %{
12485   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c_32 shift))));
12486 
12487   expand %{
12488     rorI_rReg(dst, src, shift, cr);
12489   %}
12490 %}
12491 
12492 // This pattern is automatically generated from aarch64_ad.m4
12493 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12494 instruct rorI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12495 %{
12496   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c0 shift))));
12497 
12498   expand %{
12499     rorI_rReg(dst, src, shift, cr);
12500   %}
12501 %}
12502 
12503 
12504 // Add/subtract (extended)
12505 
12506 // This pattern is automatically generated from aarch64_ad.m4
12507 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12508 instruct AddExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12509 %{
12510   match(Set dst (AddL src1 (ConvI2L src2)));
12511   ins_cost(INSN_COST);
12512   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12513 
12514    ins_encode %{
12515      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12516             as_Register($src2$$reg), ext::sxtw);
12517    %}
12518   ins_pipe(ialu_reg_reg);
12519 %}
12520 
12521 // This pattern is automatically generated from aarch64_ad.m4
12522 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12523 instruct SubExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12524 %{
12525   match(Set dst (SubL src1 (ConvI2L src2)));
12526   ins_cost(INSN_COST);
12527   format %{ &quot;sub  $dst, $src1, $src2, sxtw&quot; %}
12528 
12529    ins_encode %{
12530      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12531             as_Register($src2$$reg), ext::sxtw);
12532    %}
12533   ins_pipe(ialu_reg_reg);
12534 %}
12535 
12536 // This pattern is automatically generated from aarch64_ad.m4
12537 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12538 instruct AddExtI_sxth(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_16 lshift, immI_16 rshift, rFlagsReg cr)
12539 %{
12540   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12541   ins_cost(INSN_COST);
12542   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12543 
12544    ins_encode %{
12545      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12546             as_Register($src2$$reg), ext::sxth);
12547    %}
12548   ins_pipe(ialu_reg_reg);
12549 %}
12550 
12551 // This pattern is automatically generated from aarch64_ad.m4
12552 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12553 instruct AddExtI_sxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12554 %{
12555   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12556   ins_cost(INSN_COST);
12557   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12558 
12559    ins_encode %{
12560      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12561             as_Register($src2$$reg), ext::sxtb);
12562    %}
12563   ins_pipe(ialu_reg_reg);
12564 %}
12565 
12566 // This pattern is automatically generated from aarch64_ad.m4
12567 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12568 instruct AddExtI_uxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12569 %{
12570   match(Set dst (AddI src1 (URShiftI (LShiftI src2 lshift) rshift)));
12571   ins_cost(INSN_COST);
12572   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12573 
12574    ins_encode %{
12575      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12576             as_Register($src2$$reg), ext::uxtb);
12577    %}
12578   ins_pipe(ialu_reg_reg);
12579 %}
12580 
12581 // This pattern is automatically generated from aarch64_ad.m4
12582 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12583 instruct AddExtL_sxth(iRegLNoSp dst, iRegL src1, iRegL src2, immI_48 lshift, immI_48 rshift, rFlagsReg cr)
12584 %{
12585   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12586   ins_cost(INSN_COST);
12587   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12588 
12589    ins_encode %{
12590      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12591             as_Register($src2$$reg), ext::sxth);
12592    %}
12593   ins_pipe(ialu_reg_reg);
12594 %}
12595 
12596 // This pattern is automatically generated from aarch64_ad.m4
12597 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12598 instruct AddExtL_sxtw(iRegLNoSp dst, iRegL src1, iRegL src2, immI_32 lshift, immI_32 rshift, rFlagsReg cr)
12599 %{
12600   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12601   ins_cost(INSN_COST);
12602   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12603 
12604    ins_encode %{
12605      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12606             as_Register($src2$$reg), ext::sxtw);
12607    %}
12608   ins_pipe(ialu_reg_reg);
12609 %}
12610 
12611 // This pattern is automatically generated from aarch64_ad.m4
12612 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12613 instruct AddExtL_sxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12614 %{
12615   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12616   ins_cost(INSN_COST);
12617   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12618 
12619    ins_encode %{
12620      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12621             as_Register($src2$$reg), ext::sxtb);
12622    %}
12623   ins_pipe(ialu_reg_reg);
12624 %}
12625 
12626 // This pattern is automatically generated from aarch64_ad.m4
12627 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12628 instruct AddExtL_uxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12629 %{
12630   match(Set dst (AddL src1 (URShiftL (LShiftL src2 lshift) rshift)));
12631   ins_cost(INSN_COST);
12632   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12633 
12634    ins_encode %{
12635      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12636             as_Register($src2$$reg), ext::uxtb);
12637    %}
12638   ins_pipe(ialu_reg_reg);
12639 %}
12640 
12641 // This pattern is automatically generated from aarch64_ad.m4
12642 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12643 instruct AddExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12644 %{
12645   match(Set dst (AddI src1 (AndI src2 mask)));
12646   ins_cost(INSN_COST);
12647   format %{ &quot;addw  $dst, $src1, $src2, uxtb&quot; %}
12648 
12649    ins_encode %{
12650      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12651             as_Register($src2$$reg), ext::uxtb);
12652    %}
12653   ins_pipe(ialu_reg_reg);
12654 %}
12655 
12656 // This pattern is automatically generated from aarch64_ad.m4
12657 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12658 instruct AddExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12659 %{
12660   match(Set dst (AddI src1 (AndI src2 mask)));
12661   ins_cost(INSN_COST);
12662   format %{ &quot;addw  $dst, $src1, $src2, uxth&quot; %}
12663 
12664    ins_encode %{
12665      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12666             as_Register($src2$$reg), ext::uxth);
12667    %}
12668   ins_pipe(ialu_reg_reg);
12669 %}
12670 
12671 // This pattern is automatically generated from aarch64_ad.m4
12672 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12673 instruct AddExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12674 %{
12675   match(Set dst (AddL src1 (AndL src2 mask)));
12676   ins_cost(INSN_COST);
12677   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12678 
12679    ins_encode %{
12680      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12681             as_Register($src2$$reg), ext::uxtb);
12682    %}
12683   ins_pipe(ialu_reg_reg);
12684 %}
12685 
12686 // This pattern is automatically generated from aarch64_ad.m4
12687 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12688 instruct AddExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12689 %{
12690   match(Set dst (AddL src1 (AndL src2 mask)));
12691   ins_cost(INSN_COST);
12692   format %{ &quot;add  $dst, $src1, $src2, uxth&quot; %}
12693 
12694    ins_encode %{
12695      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12696             as_Register($src2$$reg), ext::uxth);
12697    %}
12698   ins_pipe(ialu_reg_reg);
12699 %}
12700 
12701 // This pattern is automatically generated from aarch64_ad.m4
12702 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12703 instruct AddExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12704 %{
12705   match(Set dst (AddL src1 (AndL src2 mask)));
12706   ins_cost(INSN_COST);
12707   format %{ &quot;add  $dst, $src1, $src2, uxtw&quot; %}
12708 
12709    ins_encode %{
12710      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12711             as_Register($src2$$reg), ext::uxtw);
12712    %}
12713   ins_pipe(ialu_reg_reg);
12714 %}
12715 
12716 // This pattern is automatically generated from aarch64_ad.m4
12717 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12718 instruct SubExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12719 %{
12720   match(Set dst (SubI src1 (AndI src2 mask)));
12721   ins_cost(INSN_COST);
12722   format %{ &quot;subw  $dst, $src1, $src2, uxtb&quot; %}
12723 
12724    ins_encode %{
12725      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12726             as_Register($src2$$reg), ext::uxtb);
12727    %}
12728   ins_pipe(ialu_reg_reg);
12729 %}
12730 
12731 // This pattern is automatically generated from aarch64_ad.m4
12732 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12733 instruct SubExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12734 %{
12735   match(Set dst (SubI src1 (AndI src2 mask)));
12736   ins_cost(INSN_COST);
12737   format %{ &quot;subw  $dst, $src1, $src2, uxth&quot; %}
12738 
12739    ins_encode %{
12740      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12741             as_Register($src2$$reg), ext::uxth);
12742    %}
12743   ins_pipe(ialu_reg_reg);
12744 %}
12745 
12746 // This pattern is automatically generated from aarch64_ad.m4
12747 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12748 instruct SubExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12749 %{
12750   match(Set dst (SubL src1 (AndL src2 mask)));
12751   ins_cost(INSN_COST);
12752   format %{ &quot;sub  $dst, $src1, $src2, uxtb&quot; %}
12753 
12754    ins_encode %{
12755      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12756             as_Register($src2$$reg), ext::uxtb);
12757    %}
12758   ins_pipe(ialu_reg_reg);
12759 %}
12760 
12761 // This pattern is automatically generated from aarch64_ad.m4
12762 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12763 instruct SubExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12764 %{
12765   match(Set dst (SubL src1 (AndL src2 mask)));
12766   ins_cost(INSN_COST);
12767   format %{ &quot;sub  $dst, $src1, $src2, uxth&quot; %}
12768 
12769    ins_encode %{
12770      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12771             as_Register($src2$$reg), ext::uxth);
12772    %}
12773   ins_pipe(ialu_reg_reg);
12774 %}
12775 
12776 // This pattern is automatically generated from aarch64_ad.m4
12777 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12778 instruct SubExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12779 %{
12780   match(Set dst (SubL src1 (AndL src2 mask)));
12781   ins_cost(INSN_COST);
12782   format %{ &quot;sub  $dst, $src1, $src2, uxtw&quot; %}
12783 
12784    ins_encode %{
12785      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12786             as_Register($src2$$reg), ext::uxtw);
12787    %}
12788   ins_pipe(ialu_reg_reg);
12789 %}
12790 
12791 
12792 // This pattern is automatically generated from aarch64_ad.m4
12793 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12794 instruct AddExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12795 %{
12796   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12797   ins_cost(1.9 * INSN_COST);
12798   format %{ &quot;add  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12799 
12800    ins_encode %{
12801      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12802             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12803    %}
12804   ins_pipe(ialu_reg_reg_shift);
12805 %}
12806 
12807 // This pattern is automatically generated from aarch64_ad.m4
12808 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12809 instruct AddExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12810 %{
12811   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12812   ins_cost(1.9 * INSN_COST);
12813   format %{ &quot;add  $dst, $src1, $src2, sxth #lshift2&quot; %}
12814 
12815    ins_encode %{
12816      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12817             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12818    %}
12819   ins_pipe(ialu_reg_reg_shift);
12820 %}
12821 
12822 // This pattern is automatically generated from aarch64_ad.m4
12823 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12824 instruct AddExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12825 %{
12826   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12827   ins_cost(1.9 * INSN_COST);
12828   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12829 
12830    ins_encode %{
12831      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12832             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12833    %}
12834   ins_pipe(ialu_reg_reg_shift);
12835 %}
12836 
12837 // This pattern is automatically generated from aarch64_ad.m4
12838 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12839 instruct SubExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12840 %{
12841   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12842   ins_cost(1.9 * INSN_COST);
12843   format %{ &quot;sub  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12844 
12845    ins_encode %{
12846      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12847             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12848    %}
12849   ins_pipe(ialu_reg_reg_shift);
12850 %}
12851 
12852 // This pattern is automatically generated from aarch64_ad.m4
12853 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12854 instruct SubExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12855 %{
12856   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12857   ins_cost(1.9 * INSN_COST);
12858   format %{ &quot;sub  $dst, $src1, $src2, sxth #lshift2&quot; %}
12859 
12860    ins_encode %{
12861      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12862             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12863    %}
12864   ins_pipe(ialu_reg_reg_shift);
12865 %}
12866 
12867 // This pattern is automatically generated from aarch64_ad.m4
12868 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12869 instruct SubExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12870 %{
12871   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12872   ins_cost(1.9 * INSN_COST);
12873   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12874 
12875    ins_encode %{
12876      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12877             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12878    %}
12879   ins_pipe(ialu_reg_reg_shift);
12880 %}
12881 
12882 // This pattern is automatically generated from aarch64_ad.m4
12883 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12884 instruct AddExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12885 %{
12886   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12887   ins_cost(1.9 * INSN_COST);
12888   format %{ &quot;addw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12889 
12890    ins_encode %{
12891      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12892             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12893    %}
12894   ins_pipe(ialu_reg_reg_shift);
12895 %}
12896 
12897 // This pattern is automatically generated from aarch64_ad.m4
12898 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12899 instruct AddExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12900 %{
12901   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12902   ins_cost(1.9 * INSN_COST);
12903   format %{ &quot;addw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12904 
12905    ins_encode %{
12906      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12907             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12908    %}
12909   ins_pipe(ialu_reg_reg_shift);
12910 %}
12911 
12912 // This pattern is automatically generated from aarch64_ad.m4
12913 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12914 instruct SubExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12915 %{
12916   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12917   ins_cost(1.9 * INSN_COST);
12918   format %{ &quot;subw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12919 
12920    ins_encode %{
12921      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12922             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12923    %}
12924   ins_pipe(ialu_reg_reg_shift);
12925 %}
12926 
12927 // This pattern is automatically generated from aarch64_ad.m4
12928 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12929 instruct SubExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12930 %{
12931   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12932   ins_cost(1.9 * INSN_COST);
12933   format %{ &quot;subw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12934 
12935    ins_encode %{
12936      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12937             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12938    %}
12939   ins_pipe(ialu_reg_reg_shift);
12940 %}
12941 
12942 // This pattern is automatically generated from aarch64_ad.m4
12943 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12944 instruct AddExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12945 %{
12946   match(Set dst (AddL src1 (LShiftL (ConvI2L src2) lshift)));
12947   ins_cost(1.9 * INSN_COST);
12948   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift&quot; %}
12949 
12950    ins_encode %{
12951      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12952             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12953    %}
12954   ins_pipe(ialu_reg_reg_shift);
12955 %}
12956 
12957 // This pattern is automatically generated from aarch64_ad.m4
12958 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12959 instruct SubExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12960 %{
12961   match(Set dst (SubL src1 (LShiftL (ConvI2L src2) lshift)));
12962   ins_cost(1.9 * INSN_COST);
12963   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift&quot; %}
12964 
12965    ins_encode %{
12966      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12967             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12968    %}
12969   ins_pipe(ialu_reg_reg_shift);
12970 %}
12971 
12972 // This pattern is automatically generated from aarch64_ad.m4
12973 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12974 instruct AddExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12975 %{
12976   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12977   ins_cost(1.9 * INSN_COST);
12978   format %{ &quot;add  $dst, $src1, $src2, uxtb #lshift&quot; %}
12979 
12980    ins_encode %{
12981      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12982             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12983    %}
12984   ins_pipe(ialu_reg_reg_shift);
12985 %}
12986 
12987 // This pattern is automatically generated from aarch64_ad.m4
12988 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
12989 instruct AddExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12990 %{
12991   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12992   ins_cost(1.9 * INSN_COST);
12993   format %{ &quot;add  $dst, $src1, $src2, uxth #lshift&quot; %}
12994 
12995    ins_encode %{
12996      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12997             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12998    %}
12999   ins_pipe(ialu_reg_reg_shift);
13000 %}
13001 
13002 // This pattern is automatically generated from aarch64_ad.m4
13003 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
13004 instruct AddExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
13005 %{
13006   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
13007   ins_cost(1.9 * INSN_COST);
13008   format %{ &quot;add  $dst, $src1, $src2, uxtw #lshift&quot; %}
13009 
13010    ins_encode %{
13011      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
13012             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
13013    %}
13014   ins_pipe(ialu_reg_reg_shift);
13015 %}
13016 
13017 // This pattern is automatically generated from aarch64_ad.m4
13018 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
13019 instruct SubExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
13020 %{
13021   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
13022   ins_cost(1.9 * INSN_COST);
13023   format %{ &quot;sub  $dst, $src1, $src2, uxtb #lshift&quot; %}
13024 
13025    ins_encode %{
13026      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
13027             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
13028    %}
13029   ins_pipe(ialu_reg_reg_shift);
13030 %}
13031 
13032 // This pattern is automatically generated from aarch64_ad.m4
13033 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
13034 instruct SubExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
13035 %{
13036   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
13037   ins_cost(1.9 * INSN_COST);
13038   format %{ &quot;sub  $dst, $src1, $src2, uxth #lshift&quot; %}
13039 
13040    ins_encode %{
13041      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
13042             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
13043    %}
13044   ins_pipe(ialu_reg_reg_shift);
13045 %}
13046 
13047 // This pattern is automatically generated from aarch64_ad.m4
13048 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
13049 instruct SubExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
13050 %{
13051   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
13052   ins_cost(1.9 * INSN_COST);
13053   format %{ &quot;sub  $dst, $src1, $src2, uxtw #lshift&quot; %}
13054 
13055    ins_encode %{
13056      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
13057             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
13058    %}
13059   ins_pipe(ialu_reg_reg_shift);
13060 %}
13061 
13062 // This pattern is automatically generated from aarch64_ad.m4
13063 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
13064 instruct AddExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
13065 %{
13066   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
13067   ins_cost(1.9 * INSN_COST);
13068   format %{ &quot;addw  $dst, $src1, $src2, uxtb #lshift&quot; %}
13069 
13070    ins_encode %{
13071      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
13072             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
13073    %}
13074   ins_pipe(ialu_reg_reg_shift);
13075 %}
13076 
13077 // This pattern is automatically generated from aarch64_ad.m4
13078 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
13079 instruct AddExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
13080 %{
13081   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
13082   ins_cost(1.9 * INSN_COST);
13083   format %{ &quot;addw  $dst, $src1, $src2, uxth #lshift&quot; %}
13084 
13085    ins_encode %{
13086      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
13087             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
13088    %}
13089   ins_pipe(ialu_reg_reg_shift);
13090 %}
13091 
13092 // This pattern is automatically generated from aarch64_ad.m4
13093 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
13094 instruct SubExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
13095 %{
13096   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
13097   ins_cost(1.9 * INSN_COST);
13098   format %{ &quot;subw  $dst, $src1, $src2, uxtb #lshift&quot; %}
13099 
13100    ins_encode %{
13101      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
13102             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
13103    %}
13104   ins_pipe(ialu_reg_reg_shift);
13105 %}
13106 
13107 // This pattern is automatically generated from aarch64_ad.m4
13108 // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
13109 instruct SubExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
13110 %{
13111   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
13112   ins_cost(1.9 * INSN_COST);
13113   format %{ &quot;subw  $dst, $src1, $src2, uxth #lshift&quot; %}
13114 
13115    ins_encode %{
13116      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
13117             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
13118    %}
13119   ins_pipe(ialu_reg_reg_shift);
13120 %}
13121 
13122 
13123 
13124 // END This section of the file is automatically generated. Do not edit --------------
13125 
13126 
13127 // ============================================================================
13128 // Floating Point Arithmetic Instructions
13129 
13130 instruct addF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13131   match(Set dst (AddF src1 src2));
13132 
13133   ins_cost(INSN_COST * 5);
13134   format %{ &quot;fadds   $dst, $src1, $src2&quot; %}
13135 
13136   ins_encode %{
13137     __ fadds(as_FloatRegister($dst$$reg),
13138              as_FloatRegister($src1$$reg),
13139              as_FloatRegister($src2$$reg));
13140   %}
13141 
13142   ins_pipe(fp_dop_reg_reg_s);
13143 %}
13144 
13145 instruct addD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13146   match(Set dst (AddD src1 src2));
13147 
13148   ins_cost(INSN_COST * 5);
13149   format %{ &quot;faddd   $dst, $src1, $src2&quot; %}
13150 
13151   ins_encode %{
13152     __ faddd(as_FloatRegister($dst$$reg),
13153              as_FloatRegister($src1$$reg),
13154              as_FloatRegister($src2$$reg));
13155   %}
13156 
13157   ins_pipe(fp_dop_reg_reg_d);
13158 %}
13159 
13160 instruct subF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13161   match(Set dst (SubF src1 src2));
13162 
13163   ins_cost(INSN_COST * 5);
13164   format %{ &quot;fsubs   $dst, $src1, $src2&quot; %}
13165 
13166   ins_encode %{
13167     __ fsubs(as_FloatRegister($dst$$reg),
13168              as_FloatRegister($src1$$reg),
13169              as_FloatRegister($src2$$reg));
13170   %}
13171 
13172   ins_pipe(fp_dop_reg_reg_s);
13173 %}
13174 
13175 instruct subD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13176   match(Set dst (SubD src1 src2));
13177 
13178   ins_cost(INSN_COST * 5);
13179   format %{ &quot;fsubd   $dst, $src1, $src2&quot; %}
13180 
13181   ins_encode %{
13182     __ fsubd(as_FloatRegister($dst$$reg),
13183              as_FloatRegister($src1$$reg),
13184              as_FloatRegister($src2$$reg));
13185   %}
13186 
13187   ins_pipe(fp_dop_reg_reg_d);
13188 %}
13189 
13190 instruct mulF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13191   match(Set dst (MulF src1 src2));
13192 
13193   ins_cost(INSN_COST * 6);
13194   format %{ &quot;fmuls   $dst, $src1, $src2&quot; %}
13195 
13196   ins_encode %{
13197     __ fmuls(as_FloatRegister($dst$$reg),
13198              as_FloatRegister($src1$$reg),
13199              as_FloatRegister($src2$$reg));
13200   %}
13201 
13202   ins_pipe(fp_dop_reg_reg_s);
13203 %}
13204 
13205 instruct mulD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13206   match(Set dst (MulD src1 src2));
13207 
13208   ins_cost(INSN_COST * 6);
13209   format %{ &quot;fmuld   $dst, $src1, $src2&quot; %}
13210 
13211   ins_encode %{
13212     __ fmuld(as_FloatRegister($dst$$reg),
13213              as_FloatRegister($src1$$reg),
13214              as_FloatRegister($src2$$reg));
13215   %}
13216 
13217   ins_pipe(fp_dop_reg_reg_d);
13218 %}
13219 
13220 // src1 * src2 + src3
13221 instruct maddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
13222   predicate(UseFMA);
13223   match(Set dst (FmaF src3 (Binary src1 src2)));
13224 
13225   format %{ &quot;fmadds   $dst, $src1, $src2, $src3&quot; %}
13226 
13227   ins_encode %{
13228     __ fmadds(as_FloatRegister($dst$$reg),
13229              as_FloatRegister($src1$$reg),
13230              as_FloatRegister($src2$$reg),
13231              as_FloatRegister($src3$$reg));
13232   %}
13233 
13234   ins_pipe(pipe_class_default);
13235 %}
13236 
13237 // src1 * src2 + src3
13238 instruct maddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13239   predicate(UseFMA);
13240   match(Set dst (FmaD src3 (Binary src1 src2)));
13241 
13242   format %{ &quot;fmaddd   $dst, $src1, $src2, $src3&quot; %}
13243 
13244   ins_encode %{
13245     __ fmaddd(as_FloatRegister($dst$$reg),
13246              as_FloatRegister($src1$$reg),
13247              as_FloatRegister($src2$$reg),
13248              as_FloatRegister($src3$$reg));
13249   %}
13250 
13251   ins_pipe(pipe_class_default);
13252 %}
13253 
13254 // -src1 * src2 + src3
13255 instruct msubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
13256   predicate(UseFMA);
13257   match(Set dst (FmaF src3 (Binary (NegF src1) src2)));
13258   match(Set dst (FmaF src3 (Binary src1 (NegF src2))));
13259 
13260   format %{ &quot;fmsubs   $dst, $src1, $src2, $src3&quot; %}
13261 
13262   ins_encode %{
13263     __ fmsubs(as_FloatRegister($dst$$reg),
13264               as_FloatRegister($src1$$reg),
13265               as_FloatRegister($src2$$reg),
13266               as_FloatRegister($src3$$reg));
13267   %}
13268 
13269   ins_pipe(pipe_class_default);
13270 %}
13271 
13272 // -src1 * src2 + src3
13273 instruct msubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13274   predicate(UseFMA);
13275   match(Set dst (FmaD src3 (Binary (NegD src1) src2)));
13276   match(Set dst (FmaD src3 (Binary src1 (NegD src2))));
13277 
13278   format %{ &quot;fmsubd   $dst, $src1, $src2, $src3&quot; %}
13279 
13280   ins_encode %{
13281     __ fmsubd(as_FloatRegister($dst$$reg),
13282               as_FloatRegister($src1$$reg),
13283               as_FloatRegister($src2$$reg),
13284               as_FloatRegister($src3$$reg));
13285   %}
13286 
13287   ins_pipe(pipe_class_default);
13288 %}
13289 
13290 // -src1 * src2 - src3
13291 instruct mnaddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
13292   predicate(UseFMA);
13293   match(Set dst (FmaF (NegF src3) (Binary (NegF src1) src2)));
13294   match(Set dst (FmaF (NegF src3) (Binary src1 (NegF src2))));
13295 
13296   format %{ &quot;fnmadds  $dst, $src1, $src2, $src3&quot; %}
13297 
13298   ins_encode %{
13299     __ fnmadds(as_FloatRegister($dst$$reg),
13300                as_FloatRegister($src1$$reg),
13301                as_FloatRegister($src2$$reg),
13302                as_FloatRegister($src3$$reg));
13303   %}
13304 
13305   ins_pipe(pipe_class_default);
13306 %}
13307 
13308 // -src1 * src2 - src3
13309 instruct mnaddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13310   predicate(UseFMA);
13311   match(Set dst (FmaD (NegD src3) (Binary (NegD src1) src2)));
13312   match(Set dst (FmaD (NegD src3) (Binary src1 (NegD src2))));
13313 
13314   format %{ &quot;fnmaddd   $dst, $src1, $src2, $src3&quot; %}
13315 
13316   ins_encode %{
13317     __ fnmaddd(as_FloatRegister($dst$$reg),
13318                as_FloatRegister($src1$$reg),
13319                as_FloatRegister($src2$$reg),
13320                as_FloatRegister($src3$$reg));
13321   %}
13322 
13323   ins_pipe(pipe_class_default);
13324 %}
13325 
13326 // src1 * src2 - src3
13327 instruct mnsubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3, immF0 zero) %{
13328   predicate(UseFMA);
13329   match(Set dst (FmaF (NegF src3) (Binary src1 src2)));
13330 
13331   format %{ &quot;fnmsubs  $dst, $src1, $src2, $src3&quot; %}
13332 
13333   ins_encode %{
13334     __ fnmsubs(as_FloatRegister($dst$$reg),
13335                as_FloatRegister($src1$$reg),
13336                as_FloatRegister($src2$$reg),
13337                as_FloatRegister($src3$$reg));
13338   %}
13339 
13340   ins_pipe(pipe_class_default);
13341 %}
13342 
13343 // src1 * src2 - src3
13344 instruct mnsubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3, immD0 zero) %{
13345   predicate(UseFMA);
13346   match(Set dst (FmaD (NegD src3) (Binary src1 src2)));
13347 
13348   format %{ &quot;fnmsubd   $dst, $src1, $src2, $src3&quot; %}
13349 
13350   ins_encode %{
13351   // n.b. insn name should be fnmsubd
13352     __ fnmsub(as_FloatRegister($dst$$reg),
13353               as_FloatRegister($src1$$reg),
13354               as_FloatRegister($src2$$reg),
13355               as_FloatRegister($src3$$reg));
13356   %}
13357 
13358   ins_pipe(pipe_class_default);
13359 %}
13360 
13361 
13362 // Math.max(FF)F
13363 instruct maxF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13364   match(Set dst (MaxF src1 src2));
13365 
13366   format %{ &quot;fmaxs   $dst, $src1, $src2&quot; %}
13367   ins_encode %{
13368     __ fmaxs(as_FloatRegister($dst$$reg),
13369              as_FloatRegister($src1$$reg),
13370              as_FloatRegister($src2$$reg));
13371   %}
13372 
13373   ins_pipe(fp_dop_reg_reg_s);
13374 %}
13375 
13376 // Math.min(FF)F
13377 instruct minF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13378   match(Set dst (MinF src1 src2));
13379 
13380   format %{ &quot;fmins   $dst, $src1, $src2&quot; %}
13381   ins_encode %{
13382     __ fmins(as_FloatRegister($dst$$reg),
13383              as_FloatRegister($src1$$reg),
13384              as_FloatRegister($src2$$reg));
13385   %}
13386 
13387   ins_pipe(fp_dop_reg_reg_s);
13388 %}
13389 
13390 // Math.max(DD)D
13391 instruct maxD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13392   match(Set dst (MaxD src1 src2));
13393 
13394   format %{ &quot;fmaxd   $dst, $src1, $src2&quot; %}
13395   ins_encode %{
13396     __ fmaxd(as_FloatRegister($dst$$reg),
13397              as_FloatRegister($src1$$reg),
13398              as_FloatRegister($src2$$reg));
13399   %}
13400 
13401   ins_pipe(fp_dop_reg_reg_d);
13402 %}
13403 
13404 // Math.min(DD)D
13405 instruct minD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13406   match(Set dst (MinD src1 src2));
13407 
13408   format %{ &quot;fmind   $dst, $src1, $src2&quot; %}
13409   ins_encode %{
13410     __ fmind(as_FloatRegister($dst$$reg),
13411              as_FloatRegister($src1$$reg),
13412              as_FloatRegister($src2$$reg));
13413   %}
13414 
13415   ins_pipe(fp_dop_reg_reg_d);
13416 %}
13417 
13418 
13419 instruct divF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13420   match(Set dst (DivF src1  src2));
13421 
13422   ins_cost(INSN_COST * 18);
13423   format %{ &quot;fdivs   $dst, $src1, $src2&quot; %}
13424 
13425   ins_encode %{
13426     __ fdivs(as_FloatRegister($dst$$reg),
13427              as_FloatRegister($src1$$reg),
13428              as_FloatRegister($src2$$reg));
13429   %}
13430 
13431   ins_pipe(fp_div_s);
13432 %}
13433 
13434 instruct divD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13435   match(Set dst (DivD src1  src2));
13436 
13437   ins_cost(INSN_COST * 32);
13438   format %{ &quot;fdivd   $dst, $src1, $src2&quot; %}
13439 
13440   ins_encode %{
13441     __ fdivd(as_FloatRegister($dst$$reg),
13442              as_FloatRegister($src1$$reg),
13443              as_FloatRegister($src2$$reg));
13444   %}
13445 
13446   ins_pipe(fp_div_d);
13447 %}
13448 
13449 instruct negF_reg_reg(vRegF dst, vRegF src) %{
13450   match(Set dst (NegF src));
13451 
13452   ins_cost(INSN_COST * 3);
13453   format %{ &quot;fneg   $dst, $src&quot; %}
13454 
13455   ins_encode %{
13456     __ fnegs(as_FloatRegister($dst$$reg),
13457              as_FloatRegister($src$$reg));
13458   %}
13459 
13460   ins_pipe(fp_uop_s);
13461 %}
13462 
13463 instruct negD_reg_reg(vRegD dst, vRegD src) %{
13464   match(Set dst (NegD src));
13465 
13466   ins_cost(INSN_COST * 3);
13467   format %{ &quot;fnegd   $dst, $src&quot; %}
13468 
13469   ins_encode %{
13470     __ fnegd(as_FloatRegister($dst$$reg),
13471              as_FloatRegister($src$$reg));
13472   %}
13473 
13474   ins_pipe(fp_uop_d);
13475 %}
13476 
13477 instruct absI_reg(iRegINoSp dst, iRegIorL2I src, rFlagsReg cr)
13478 %{
13479   match(Set dst (AbsI src));
13480 
13481   effect(KILL cr);
13482   ins_cost(INSN_COST * 2);
13483   format %{ &quot;cmpw  $src, zr\n\t&quot;
13484             &quot;cnegw $dst, $src, Assembler::LT\t# int abs&quot;
13485   %}
13486 
13487   ins_encode %{
13488     __ cmpw(as_Register($src$$reg), zr);
13489     __ cnegw(as_Register($dst$$reg), as_Register($src$$reg), Assembler::LT);
13490   %}
13491   ins_pipe(pipe_class_default);
13492 %}
13493 
13494 instruct absL_reg(iRegLNoSp dst, iRegL src, rFlagsReg cr)
13495 %{
13496   match(Set dst (AbsL src));
13497 
13498   effect(KILL cr);
13499   ins_cost(INSN_COST * 2);
13500   format %{ &quot;cmp  $src, zr\n\t&quot;
13501             &quot;cneg $dst, $src, Assembler::LT\t# long abs&quot;
13502   %}
13503 
13504   ins_encode %{
13505     __ cmp(as_Register($src$$reg), zr);
13506     __ cneg(as_Register($dst$$reg), as_Register($src$$reg), Assembler::LT);
13507   %}
13508   ins_pipe(pipe_class_default);
13509 %}
13510 
13511 instruct absF_reg(vRegF dst, vRegF src) %{
13512   match(Set dst (AbsF src));
13513 
13514   ins_cost(INSN_COST * 3);
13515   format %{ &quot;fabss   $dst, $src&quot; %}
13516   ins_encode %{
13517     __ fabss(as_FloatRegister($dst$$reg),
13518              as_FloatRegister($src$$reg));
13519   %}
13520 
13521   ins_pipe(fp_uop_s);
13522 %}
13523 
13524 instruct absD_reg(vRegD dst, vRegD src) %{
13525   match(Set dst (AbsD src));
13526 
13527   ins_cost(INSN_COST * 3);
13528   format %{ &quot;fabsd   $dst, $src&quot; %}
13529   ins_encode %{
13530     __ fabsd(as_FloatRegister($dst$$reg),
13531              as_FloatRegister($src$$reg));
13532   %}
13533 
13534   ins_pipe(fp_uop_d);
13535 %}
13536 
13537 instruct sqrtD_reg(vRegD dst, vRegD src) %{
13538   match(Set dst (SqrtD src));
13539 
13540   ins_cost(INSN_COST * 50);
13541   format %{ &quot;fsqrtd  $dst, $src&quot; %}
13542   ins_encode %{
13543     __ fsqrtd(as_FloatRegister($dst$$reg),
13544              as_FloatRegister($src$$reg));
13545   %}
13546 
13547   ins_pipe(fp_div_s);
13548 %}
13549 
13550 instruct sqrtF_reg(vRegF dst, vRegF src) %{
13551   match(Set dst (SqrtF src));
13552 
13553   ins_cost(INSN_COST * 50);
13554   format %{ &quot;fsqrts  $dst, $src&quot; %}
13555   ins_encode %{
13556     __ fsqrts(as_FloatRegister($dst$$reg),
13557              as_FloatRegister($src$$reg));
13558   %}
13559 
13560   ins_pipe(fp_div_d);
13561 %}
13562 
13563 // Math.rint, floor, ceil
13564 instruct roundD_reg(vRegD dst, vRegD src, immI rmode) %{
13565   match(Set dst (RoundDoubleMode src rmode));
13566   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
13567   ins_encode %{
13568     switch ($rmode$$constant) {
13569       case RoundDoubleModeNode::rmode_rint:
13570         __ frintnd(as_FloatRegister($dst$$reg),
13571                    as_FloatRegister($src$$reg));
13572         break;
13573       case RoundDoubleModeNode::rmode_floor:
13574         __ frintmd(as_FloatRegister($dst$$reg),
13575                    as_FloatRegister($src$$reg));
13576         break;
13577       case RoundDoubleModeNode::rmode_ceil:
13578         __ frintpd(as_FloatRegister($dst$$reg),
13579                    as_FloatRegister($src$$reg));
13580         break;
13581     }
13582   %}
13583   ins_pipe(fp_uop_d);
13584 %}
13585 
13586 // ============================================================================
13587 // Logical Instructions
13588 
13589 // Integer Logical Instructions
13590 
13591 // And Instructions
13592 
13593 
13594 instruct andI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, rFlagsReg cr) %{
13595   match(Set dst (AndI src1 src2));
13596 
13597   format %{ &quot;andw  $dst, $src1, $src2\t# int&quot; %}
13598 
13599   ins_cost(INSN_COST);
13600   ins_encode %{
13601     __ andw(as_Register($dst$$reg),
13602             as_Register($src1$$reg),
13603             as_Register($src2$$reg));
13604   %}
13605 
13606   ins_pipe(ialu_reg_reg);
13607 %}
13608 
13609 instruct andI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2, rFlagsReg cr) %{
13610   match(Set dst (AndI src1 src2));
13611 
13612   format %{ &quot;andsw  $dst, $src1, $src2\t# int&quot; %}
13613 
13614   ins_cost(INSN_COST);
13615   ins_encode %{
13616     __ andw(as_Register($dst$$reg),
13617             as_Register($src1$$reg),
13618             (uint64_t)($src2$$constant));
13619   %}
13620 
13621   ins_pipe(ialu_reg_imm);
13622 %}
13623 
13624 // Or Instructions
13625 
13626 instruct orI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13627   match(Set dst (OrI src1 src2));
13628 
13629   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13630 
13631   ins_cost(INSN_COST);
13632   ins_encode %{
13633     __ orrw(as_Register($dst$$reg),
13634             as_Register($src1$$reg),
13635             as_Register($src2$$reg));
13636   %}
13637 
13638   ins_pipe(ialu_reg_reg);
13639 %}
13640 
13641 instruct orI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13642   match(Set dst (OrI src1 src2));
13643 
13644   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13645 
13646   ins_cost(INSN_COST);
13647   ins_encode %{
13648     __ orrw(as_Register($dst$$reg),
13649             as_Register($src1$$reg),
13650             (uint64_t)($src2$$constant));
13651   %}
13652 
13653   ins_pipe(ialu_reg_imm);
13654 %}
13655 
13656 // Xor Instructions
13657 
13658 instruct xorI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13659   match(Set dst (XorI src1 src2));
13660 
13661   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13662 
13663   ins_cost(INSN_COST);
13664   ins_encode %{
13665     __ eorw(as_Register($dst$$reg),
13666             as_Register($src1$$reg),
13667             as_Register($src2$$reg));
13668   %}
13669 
13670   ins_pipe(ialu_reg_reg);
13671 %}
13672 
13673 instruct xorI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13674   match(Set dst (XorI src1 src2));
13675 
13676   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13677 
13678   ins_cost(INSN_COST);
13679   ins_encode %{
13680     __ eorw(as_Register($dst$$reg),
13681             as_Register($src1$$reg),
13682             (uint64_t)($src2$$constant));
13683   %}
13684 
13685   ins_pipe(ialu_reg_imm);
13686 %}
13687 
13688 // Long Logical Instructions
13689 // TODO
13690 
13691 instruct andL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr) %{
13692   match(Set dst (AndL src1 src2));
13693 
13694   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13695 
13696   ins_cost(INSN_COST);
13697   ins_encode %{
13698     __ andr(as_Register($dst$$reg),
13699             as_Register($src1$$reg),
13700             as_Register($src2$$reg));
13701   %}
13702 
13703   ins_pipe(ialu_reg_reg);
13704 %}
13705 
13706 instruct andL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2, rFlagsReg cr) %{
13707   match(Set dst (AndL src1 src2));
13708 
13709   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13710 
13711   ins_cost(INSN_COST);
13712   ins_encode %{
13713     __ andr(as_Register($dst$$reg),
13714             as_Register($src1$$reg),
13715             (uint64_t)($src2$$constant));
13716   %}
13717 
13718   ins_pipe(ialu_reg_imm);
13719 %}
13720 
13721 // Or Instructions
13722 
13723 instruct orL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13724   match(Set dst (OrL src1 src2));
13725 
13726   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13727 
13728   ins_cost(INSN_COST);
13729   ins_encode %{
13730     __ orr(as_Register($dst$$reg),
13731            as_Register($src1$$reg),
13732            as_Register($src2$$reg));
13733   %}
13734 
13735   ins_pipe(ialu_reg_reg);
13736 %}
13737 
13738 instruct orL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13739   match(Set dst (OrL src1 src2));
13740 
13741   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13742 
13743   ins_cost(INSN_COST);
13744   ins_encode %{
13745     __ orr(as_Register($dst$$reg),
13746            as_Register($src1$$reg),
13747            (uint64_t)($src2$$constant));
13748   %}
13749 
13750   ins_pipe(ialu_reg_imm);
13751 %}
13752 
13753 // Xor Instructions
13754 
13755 instruct xorL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13756   match(Set dst (XorL src1 src2));
13757 
13758   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13759 
13760   ins_cost(INSN_COST);
13761   ins_encode %{
13762     __ eor(as_Register($dst$$reg),
13763            as_Register($src1$$reg),
13764            as_Register($src2$$reg));
13765   %}
13766 
13767   ins_pipe(ialu_reg_reg);
13768 %}
13769 
13770 instruct xorL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13771   match(Set dst (XorL src1 src2));
13772 
13773   ins_cost(INSN_COST);
13774   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13775 
13776   ins_encode %{
13777     __ eor(as_Register($dst$$reg),
13778            as_Register($src1$$reg),
13779            (uint64_t)($src2$$constant));
13780   %}
13781 
13782   ins_pipe(ialu_reg_imm);
13783 %}
13784 
13785 instruct convI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src)
13786 %{
13787   match(Set dst (ConvI2L src));
13788 
13789   ins_cost(INSN_COST);
13790   format %{ &quot;sxtw  $dst, $src\t# i2l&quot; %}
13791   ins_encode %{
13792     __ sbfm($dst$$Register, $src$$Register, 0, 31);
13793   %}
13794   ins_pipe(ialu_reg_shift);
13795 %}
13796 
13797 // this pattern occurs in bigmath arithmetic
13798 instruct convUI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src, immL_32bits mask)
13799 %{
13800   match(Set dst (AndL (ConvI2L src) mask));
13801 
13802   ins_cost(INSN_COST);
13803   format %{ &quot;ubfm  $dst, $src, 0, 31\t# ui2l&quot; %}
13804   ins_encode %{
13805     __ ubfm($dst$$Register, $src$$Register, 0, 31);
13806   %}
13807 
13808   ins_pipe(ialu_reg_shift);
13809 %}
13810 
13811 instruct convL2I_reg(iRegINoSp dst, iRegL src) %{
13812   match(Set dst (ConvL2I src));
13813 
13814   ins_cost(INSN_COST);
13815   format %{ &quot;movw  $dst, $src \t// l2i&quot; %}
13816 
13817   ins_encode %{
13818     __ movw(as_Register($dst$$reg), as_Register($src$$reg));
13819   %}
13820 
13821   ins_pipe(ialu_reg);
13822 %}
13823 
13824 instruct convI2B(iRegINoSp dst, iRegIorL2I src, rFlagsReg cr)
13825 %{
13826   match(Set dst (Conv2B src));
13827   effect(KILL cr);
13828 
13829   format %{
13830     &quot;cmpw $src, zr\n\t&quot;
13831     &quot;cset $dst, ne&quot;
13832   %}
13833 
13834   ins_encode %{
13835     __ cmpw(as_Register($src$$reg), zr);
13836     __ cset(as_Register($dst$$reg), Assembler::NE);
13837   %}
13838 
13839   ins_pipe(ialu_reg);
13840 %}
13841 
13842 instruct convP2B(iRegINoSp dst, iRegP src, rFlagsReg cr)
13843 %{
13844   match(Set dst (Conv2B src));
13845   effect(KILL cr);
13846 
13847   format %{
13848     &quot;cmp  $src, zr\n\t&quot;
13849     &quot;cset $dst, ne&quot;
13850   %}
13851 
13852   ins_encode %{
13853     __ cmp(as_Register($src$$reg), zr);
13854     __ cset(as_Register($dst$$reg), Assembler::NE);
13855   %}
13856 
13857   ins_pipe(ialu_reg);
13858 %}
13859 
13860 instruct convD2F_reg(vRegF dst, vRegD src) %{
13861   match(Set dst (ConvD2F src));
13862 
13863   ins_cost(INSN_COST * 5);
13864   format %{ &quot;fcvtd  $dst, $src \t// d2f&quot; %}
13865 
13866   ins_encode %{
13867     __ fcvtd(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13868   %}
13869 
13870   ins_pipe(fp_d2f);
13871 %}
13872 
13873 instruct convF2D_reg(vRegD dst, vRegF src) %{
13874   match(Set dst (ConvF2D src));
13875 
13876   ins_cost(INSN_COST * 5);
13877   format %{ &quot;fcvts  $dst, $src \t// f2d&quot; %}
13878 
13879   ins_encode %{
13880     __ fcvts(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13881   %}
13882 
13883   ins_pipe(fp_f2d);
13884 %}
13885 
13886 instruct convF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13887   match(Set dst (ConvF2I src));
13888 
13889   ins_cost(INSN_COST * 5);
13890   format %{ &quot;fcvtzsw  $dst, $src \t// f2i&quot; %}
13891 
13892   ins_encode %{
13893     __ fcvtzsw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13894   %}
13895 
13896   ins_pipe(fp_f2i);
13897 %}
13898 
13899 instruct convF2L_reg_reg(iRegLNoSp dst, vRegF src) %{
13900   match(Set dst (ConvF2L src));
13901 
13902   ins_cost(INSN_COST * 5);
13903   format %{ &quot;fcvtzs  $dst, $src \t// f2l&quot; %}
13904 
13905   ins_encode %{
13906     __ fcvtzs(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13907   %}
13908 
13909   ins_pipe(fp_f2l);
13910 %}
13911 
13912 instruct convI2F_reg_reg(vRegF dst, iRegIorL2I src) %{
13913   match(Set dst (ConvI2F src));
13914 
13915   ins_cost(INSN_COST * 5);
13916   format %{ &quot;scvtfws  $dst, $src \t// i2f&quot; %}
13917 
13918   ins_encode %{
13919     __ scvtfws(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13920   %}
13921 
13922   ins_pipe(fp_i2f);
13923 %}
13924 
13925 instruct convL2F_reg_reg(vRegF dst, iRegL src) %{
13926   match(Set dst (ConvL2F src));
13927 
13928   ins_cost(INSN_COST * 5);
13929   format %{ &quot;scvtfs  $dst, $src \t// l2f&quot; %}
13930 
13931   ins_encode %{
13932     __ scvtfs(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13933   %}
13934 
13935   ins_pipe(fp_l2f);
13936 %}
13937 
13938 instruct convD2I_reg_reg(iRegINoSp dst, vRegD src) %{
13939   match(Set dst (ConvD2I src));
13940 
13941   ins_cost(INSN_COST * 5);
13942   format %{ &quot;fcvtzdw  $dst, $src \t// d2i&quot; %}
13943 
13944   ins_encode %{
13945     __ fcvtzdw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13946   %}
13947 
13948   ins_pipe(fp_d2i);
13949 %}
13950 
13951 instruct convD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13952   match(Set dst (ConvD2L src));
13953 
13954   ins_cost(INSN_COST * 5);
13955   format %{ &quot;fcvtzd  $dst, $src \t// d2l&quot; %}
13956 
13957   ins_encode %{
13958     __ fcvtzd(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13959   %}
13960 
13961   ins_pipe(fp_d2l);
13962 %}
13963 
13964 instruct convI2D_reg_reg(vRegD dst, iRegIorL2I src) %{
13965   match(Set dst (ConvI2D src));
13966 
13967   ins_cost(INSN_COST * 5);
13968   format %{ &quot;scvtfwd  $dst, $src \t// i2d&quot; %}
13969 
13970   ins_encode %{
13971     __ scvtfwd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13972   %}
13973 
13974   ins_pipe(fp_i2d);
13975 %}
13976 
13977 instruct convL2D_reg_reg(vRegD dst, iRegL src) %{
13978   match(Set dst (ConvL2D src));
13979 
13980   ins_cost(INSN_COST * 5);
13981   format %{ &quot;scvtfd  $dst, $src \t// l2d&quot; %}
13982 
13983   ins_encode %{
13984     __ scvtfd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13985   %}
13986 
13987   ins_pipe(fp_l2d);
13988 %}
13989 
13990 // stack &lt;-&gt; reg and reg &lt;-&gt; reg shuffles with no conversion
13991 
13992 instruct MoveF2I_stack_reg(iRegINoSp dst, stackSlotF src) %{
13993 
13994   match(Set dst (MoveF2I src));
13995 
13996   effect(DEF dst, USE src);
13997 
13998   ins_cost(4 * INSN_COST);
13999 
14000   format %{ &quot;ldrw $dst, $src\t# MoveF2I_stack_reg&quot; %}
14001 
14002   ins_encode %{
14003     __ ldrw($dst$$Register, Address(sp, $src$$disp));
14004   %}
14005 
14006   ins_pipe(iload_reg_reg);
14007 
14008 %}
14009 
14010 instruct MoveI2F_stack_reg(vRegF dst, stackSlotI src) %{
14011 
14012   match(Set dst (MoveI2F src));
14013 
14014   effect(DEF dst, USE src);
14015 
14016   ins_cost(4 * INSN_COST);
14017 
14018   format %{ &quot;ldrs $dst, $src\t# MoveI2F_stack_reg&quot; %}
14019 
14020   ins_encode %{
14021     __ ldrs(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
14022   %}
14023 
14024   ins_pipe(pipe_class_memory);
14025 
14026 %}
14027 
14028 instruct MoveD2L_stack_reg(iRegLNoSp dst, stackSlotD src) %{
14029 
14030   match(Set dst (MoveD2L src));
14031 
14032   effect(DEF dst, USE src);
14033 
14034   ins_cost(4 * INSN_COST);
14035 
14036   format %{ &quot;ldr $dst, $src\t# MoveD2L_stack_reg&quot; %}
14037 
14038   ins_encode %{
14039     __ ldr($dst$$Register, Address(sp, $src$$disp));
14040   %}
14041 
14042   ins_pipe(iload_reg_reg);
14043 
14044 %}
14045 
14046 instruct MoveL2D_stack_reg(vRegD dst, stackSlotL src) %{
14047 
14048   match(Set dst (MoveL2D src));
14049 
14050   effect(DEF dst, USE src);
14051 
14052   ins_cost(4 * INSN_COST);
14053 
14054   format %{ &quot;ldrd $dst, $src\t# MoveL2D_stack_reg&quot; %}
14055 
14056   ins_encode %{
14057     __ ldrd(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
14058   %}
14059 
14060   ins_pipe(pipe_class_memory);
14061 
14062 %}
14063 
14064 instruct MoveF2I_reg_stack(stackSlotI dst, vRegF src) %{
14065 
14066   match(Set dst (MoveF2I src));
14067 
14068   effect(DEF dst, USE src);
14069 
14070   ins_cost(INSN_COST);
14071 
14072   format %{ &quot;strs $src, $dst\t# MoveF2I_reg_stack&quot; %}
14073 
14074   ins_encode %{
14075     __ strs(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
14076   %}
14077 
14078   ins_pipe(pipe_class_memory);
14079 
14080 %}
14081 
14082 instruct MoveI2F_reg_stack(stackSlotF dst, iRegI src) %{
14083 
14084   match(Set dst (MoveI2F src));
14085 
14086   effect(DEF dst, USE src);
14087 
14088   ins_cost(INSN_COST);
14089 
14090   format %{ &quot;strw $src, $dst\t# MoveI2F_reg_stack&quot; %}
14091 
14092   ins_encode %{
14093     __ strw($src$$Register, Address(sp, $dst$$disp));
14094   %}
14095 
14096   ins_pipe(istore_reg_reg);
14097 
14098 %}
14099 
14100 instruct MoveD2L_reg_stack(stackSlotL dst, vRegD src) %{
14101 
14102   match(Set dst (MoveD2L src));
14103 
14104   effect(DEF dst, USE src);
14105 
14106   ins_cost(INSN_COST);
14107 
14108   format %{ &quot;strd $dst, $src\t# MoveD2L_reg_stack&quot; %}
14109 
14110   ins_encode %{
14111     __ strd(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
14112   %}
14113 
14114   ins_pipe(pipe_class_memory);
14115 
14116 %}
14117 
14118 instruct MoveL2D_reg_stack(stackSlotD dst, iRegL src) %{
14119 
14120   match(Set dst (MoveL2D src));
14121 
14122   effect(DEF dst, USE src);
14123 
14124   ins_cost(INSN_COST);
14125 
14126   format %{ &quot;str $src, $dst\t# MoveL2D_reg_stack&quot; %}
14127 
14128   ins_encode %{
14129     __ str($src$$Register, Address(sp, $dst$$disp));
14130   %}
14131 
14132   ins_pipe(istore_reg_reg);
14133 
14134 %}
14135 
14136 instruct MoveF2I_reg_reg(iRegINoSp dst, vRegF src) %{
14137 
14138   match(Set dst (MoveF2I src));
14139 
14140   effect(DEF dst, USE src);
14141 
14142   ins_cost(INSN_COST);
14143 
14144   format %{ &quot;fmovs $dst, $src\t# MoveF2I_reg_reg&quot; %}
14145 
14146   ins_encode %{
14147     __ fmovs($dst$$Register, as_FloatRegister($src$$reg));
14148   %}
14149 
14150   ins_pipe(fp_f2i);
14151 
14152 %}
14153 
14154 instruct MoveI2F_reg_reg(vRegF dst, iRegI src) %{
14155 
14156   match(Set dst (MoveI2F src));
14157 
14158   effect(DEF dst, USE src);
14159 
14160   ins_cost(INSN_COST);
14161 
14162   format %{ &quot;fmovs $dst, $src\t# MoveI2F_reg_reg&quot; %}
14163 
14164   ins_encode %{
14165     __ fmovs(as_FloatRegister($dst$$reg), $src$$Register);
14166   %}
14167 
14168   ins_pipe(fp_i2f);
14169 
14170 %}
14171 
14172 instruct MoveD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
14173 
14174   match(Set dst (MoveD2L src));
14175 
14176   effect(DEF dst, USE src);
14177 
14178   ins_cost(INSN_COST);
14179 
14180   format %{ &quot;fmovd $dst, $src\t# MoveD2L_reg_reg&quot; %}
14181 
14182   ins_encode %{
14183     __ fmovd($dst$$Register, as_FloatRegister($src$$reg));
14184   %}
14185 
14186   ins_pipe(fp_d2l);
14187 
14188 %}
14189 
14190 instruct MoveL2D_reg_reg(vRegD dst, iRegL src) %{
14191 
14192   match(Set dst (MoveL2D src));
14193 
14194   effect(DEF dst, USE src);
14195 
14196   ins_cost(INSN_COST);
14197 
14198   format %{ &quot;fmovd $dst, $src\t# MoveL2D_reg_reg&quot; %}
14199 
14200   ins_encode %{
14201     __ fmovd(as_FloatRegister($dst$$reg), $src$$Register);
14202   %}
14203 
14204   ins_pipe(fp_l2d);
14205 
14206 %}
14207 
14208 // ============================================================================
14209 // clearing of an array
14210 
14211 instruct clearArray_reg_reg(iRegL_R11 cnt, iRegP_R10 base, Universe dummy, rFlagsReg cr)
14212 %{
14213   match(Set dummy (ClearArray cnt base));
14214   effect(USE_KILL cnt, USE_KILL base, KILL cr);
14215 
14216   ins_cost(4 * INSN_COST);
14217   format %{ &quot;ClearArray $cnt, $base&quot; %}
14218 
14219   ins_encode %{
14220     __ zero_words($base$$Register, $cnt$$Register);
14221   %}
14222 
14223   ins_pipe(pipe_class_memory);
14224 %}
14225 
14226 instruct clearArray_imm_reg(immL cnt, iRegP_R10 base, Universe dummy, rFlagsReg cr)
14227 %{
14228   predicate((uint64_t)n-&gt;in(2)-&gt;get_long()
14229             &lt; (uint64_t)(BlockZeroingLowLimit &gt;&gt; LogBytesPerWord));
14230   match(Set dummy (ClearArray cnt base));
14231   effect(USE_KILL base);
14232 
14233   ins_cost(4 * INSN_COST);
14234   format %{ &quot;ClearArray $cnt, $base&quot; %}
14235 
14236   ins_encode %{
14237     __ zero_words($base$$Register, (uint64_t)$cnt$$constant);
14238   %}
14239 
14240   ins_pipe(pipe_class_memory);
14241 %}
14242 
14243 // ============================================================================
14244 // Overflow Math Instructions
14245 
14246 instruct overflowAddI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14247 %{
14248   match(Set cr (OverflowAddI op1 op2));
14249 
14250   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
14251   ins_cost(INSN_COST);
14252   ins_encode %{
14253     __ cmnw($op1$$Register, $op2$$Register);
14254   %}
14255 
14256   ins_pipe(icmp_reg_reg);
14257 %}
14258 
14259 instruct overflowAddI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
14260 %{
14261   match(Set cr (OverflowAddI op1 op2));
14262 
14263   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
14264   ins_cost(INSN_COST);
14265   ins_encode %{
14266     __ cmnw($op1$$Register, $op2$$constant);
14267   %}
14268 
14269   ins_pipe(icmp_reg_imm);
14270 %}
14271 
14272 instruct overflowAddL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14273 %{
14274   match(Set cr (OverflowAddL op1 op2));
14275 
14276   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
14277   ins_cost(INSN_COST);
14278   ins_encode %{
14279     __ cmn($op1$$Register, $op2$$Register);
14280   %}
14281 
14282   ins_pipe(icmp_reg_reg);
14283 %}
14284 
14285 instruct overflowAddL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
14286 %{
14287   match(Set cr (OverflowAddL op1 op2));
14288 
14289   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
14290   ins_cost(INSN_COST);
14291   ins_encode %{
14292     __ cmn($op1$$Register, $op2$$constant);
14293   %}
14294 
14295   ins_pipe(icmp_reg_imm);
14296 %}
14297 
14298 instruct overflowSubI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14299 %{
14300   match(Set cr (OverflowSubI op1 op2));
14301 
14302   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
14303   ins_cost(INSN_COST);
14304   ins_encode %{
14305     __ cmpw($op1$$Register, $op2$$Register);
14306   %}
14307 
14308   ins_pipe(icmp_reg_reg);
14309 %}
14310 
14311 instruct overflowSubI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
14312 %{
14313   match(Set cr (OverflowSubI op1 op2));
14314 
14315   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
14316   ins_cost(INSN_COST);
14317   ins_encode %{
14318     __ cmpw($op1$$Register, $op2$$constant);
14319   %}
14320 
14321   ins_pipe(icmp_reg_imm);
14322 %}
14323 
14324 instruct overflowSubL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14325 %{
14326   match(Set cr (OverflowSubL op1 op2));
14327 
14328   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
14329   ins_cost(INSN_COST);
14330   ins_encode %{
14331     __ cmp($op1$$Register, $op2$$Register);
14332   %}
14333 
14334   ins_pipe(icmp_reg_reg);
14335 %}
14336 
14337 instruct overflowSubL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
14338 %{
14339   match(Set cr (OverflowSubL op1 op2));
14340 
14341   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
14342   ins_cost(INSN_COST);
14343   ins_encode %{
14344     __ subs(zr, $op1$$Register, $op2$$constant);
14345   %}
14346 
14347   ins_pipe(icmp_reg_imm);
14348 %}
14349 
14350 instruct overflowNegI_reg(rFlagsReg cr, immI0 zero, iRegIorL2I op1)
14351 %{
14352   match(Set cr (OverflowSubI zero op1));
14353 
14354   format %{ &quot;cmpw  zr, $op1\t# overflow check int&quot; %}
14355   ins_cost(INSN_COST);
14356   ins_encode %{
14357     __ cmpw(zr, $op1$$Register);
14358   %}
14359 
14360   ins_pipe(icmp_reg_imm);
14361 %}
14362 
14363 instruct overflowNegL_reg(rFlagsReg cr, immI0 zero, iRegL op1)
14364 %{
14365   match(Set cr (OverflowSubL zero op1));
14366 
14367   format %{ &quot;cmp   zr, $op1\t# overflow check long&quot; %}
14368   ins_cost(INSN_COST);
14369   ins_encode %{
14370     __ cmp(zr, $op1$$Register);
14371   %}
14372 
14373   ins_pipe(icmp_reg_imm);
14374 %}
14375 
14376 instruct overflowMulI_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14377 %{
14378   match(Set cr (OverflowMulI op1 op2));
14379 
14380   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14381             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14382             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14383             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14384             &quot;cmpw  rscratch1, #1&quot; %}
14385   ins_cost(5 * INSN_COST);
14386   ins_encode %{
14387     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14388     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14389     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14390     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14391     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14392   %}
14393 
14394   ins_pipe(pipe_slow);
14395 %}
14396 
14397 instruct overflowMulI_reg_branch(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, label labl, rFlagsReg cr)
14398 %{
14399   match(If cmp (OverflowMulI op1 op2));
14400   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14401             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14402   effect(USE labl, KILL cr);
14403 
14404   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14405             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14406             &quot;b$cmp   $labl&quot; %}
14407   ins_cost(3 * INSN_COST); // Branch is rare so treat as INSN_COST
14408   ins_encode %{
14409     Label* L = $labl$$label;
14410     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14411     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14412     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14413     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14414   %}
14415 
14416   ins_pipe(pipe_serial);
14417 %}
14418 
14419 instruct overflowMulL_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14420 %{
14421   match(Set cr (OverflowMulL op1 op2));
14422 
14423   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14424             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14425             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14426             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14427             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14428             &quot;cmpw  rscratch1, #1&quot; %}
14429   ins_cost(6 * INSN_COST);
14430   ins_encode %{
14431     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14432     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14433     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14434     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14435     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14436     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14437   %}
14438 
14439   ins_pipe(pipe_slow);
14440 %}
14441 
14442 instruct overflowMulL_reg_branch(cmpOp cmp, iRegL op1, iRegL op2, label labl, rFlagsReg cr)
14443 %{
14444   match(If cmp (OverflowMulL op1 op2));
14445   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14446             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14447   effect(USE labl, KILL cr);
14448 
14449   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14450             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14451             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14452             &quot;b$cmp $labl&quot; %}
14453   ins_cost(4 * INSN_COST); // Branch is rare so treat as INSN_COST
14454   ins_encode %{
14455     Label* L = $labl$$label;
14456     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14457     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14458     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14459     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14460     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14461   %}
14462 
14463   ins_pipe(pipe_serial);
14464 %}
14465 
14466 // ============================================================================
14467 // Compare Instructions
14468 
14469 instruct compI_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
14470 %{
14471   match(Set cr (CmpI op1 op2));
14472 
14473   effect(DEF cr, USE op1, USE op2);
14474 
14475   ins_cost(INSN_COST);
14476   format %{ &quot;cmpw  $op1, $op2&quot; %}
14477 
14478   ins_encode(aarch64_enc_cmpw(op1, op2));
14479 
14480   ins_pipe(icmp_reg_reg);
14481 %}
14482 
14483 instruct compI_reg_immI0(rFlagsReg cr, iRegI op1, immI0 zero)
14484 %{
14485   match(Set cr (CmpI op1 zero));
14486 
14487   effect(DEF cr, USE op1);
14488 
14489   ins_cost(INSN_COST);
14490   format %{ &quot;cmpw $op1, 0&quot; %}
14491 
14492   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14493 
14494   ins_pipe(icmp_reg_imm);
14495 %}
14496 
14497 instruct compI_reg_immIAddSub(rFlagsReg cr, iRegI op1, immIAddSub op2)
14498 %{
14499   match(Set cr (CmpI op1 op2));
14500 
14501   effect(DEF cr, USE op1);
14502 
14503   ins_cost(INSN_COST);
14504   format %{ &quot;cmpw  $op1, $op2&quot; %}
14505 
14506   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14507 
14508   ins_pipe(icmp_reg_imm);
14509 %}
14510 
14511 instruct compI_reg_immI(rFlagsReg cr, iRegI op1, immI op2)
14512 %{
14513   match(Set cr (CmpI op1 op2));
14514 
14515   effect(DEF cr, USE op1);
14516 
14517   ins_cost(INSN_COST * 2);
14518   format %{ &quot;cmpw  $op1, $op2&quot; %}
14519 
14520   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14521 
14522   ins_pipe(icmp_reg_imm);
14523 %}
14524 
14525 // Unsigned compare Instructions; really, same as signed compare
14526 // except it should only be used to feed an If or a CMovI which takes a
14527 // cmpOpU.
14528 
14529 instruct compU_reg_reg(rFlagsRegU cr, iRegI op1, iRegI op2)
14530 %{
14531   match(Set cr (CmpU op1 op2));
14532 
14533   effect(DEF cr, USE op1, USE op2);
14534 
14535   ins_cost(INSN_COST);
14536   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14537 
14538   ins_encode(aarch64_enc_cmpw(op1, op2));
14539 
14540   ins_pipe(icmp_reg_reg);
14541 %}
14542 
14543 instruct compU_reg_immI0(rFlagsRegU cr, iRegI op1, immI0 zero)
14544 %{
14545   match(Set cr (CmpU op1 zero));
14546 
14547   effect(DEF cr, USE op1);
14548 
14549   ins_cost(INSN_COST);
14550   format %{ &quot;cmpw $op1, #0\t# unsigned&quot; %}
14551 
14552   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14553 
14554   ins_pipe(icmp_reg_imm);
14555 %}
14556 
14557 instruct compU_reg_immIAddSub(rFlagsRegU cr, iRegI op1, immIAddSub op2)
14558 %{
14559   match(Set cr (CmpU op1 op2));
14560 
14561   effect(DEF cr, USE op1);
14562 
14563   ins_cost(INSN_COST);
14564   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14565 
14566   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14567 
14568   ins_pipe(icmp_reg_imm);
14569 %}
14570 
14571 instruct compU_reg_immI(rFlagsRegU cr, iRegI op1, immI op2)
14572 %{
14573   match(Set cr (CmpU op1 op2));
14574 
14575   effect(DEF cr, USE op1);
14576 
14577   ins_cost(INSN_COST * 2);
14578   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14579 
14580   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14581 
14582   ins_pipe(icmp_reg_imm);
14583 %}
14584 
14585 instruct compL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14586 %{
14587   match(Set cr (CmpL op1 op2));
14588 
14589   effect(DEF cr, USE op1, USE op2);
14590 
14591   ins_cost(INSN_COST);
14592   format %{ &quot;cmp  $op1, $op2&quot; %}
14593 
14594   ins_encode(aarch64_enc_cmp(op1, op2));
14595 
14596   ins_pipe(icmp_reg_reg);
14597 %}
14598 
14599 instruct compL_reg_immL0(rFlagsReg cr, iRegL op1, immL0 zero)
14600 %{
14601   match(Set cr (CmpL op1 zero));
14602 
14603   effect(DEF cr, USE op1);
14604 
14605   ins_cost(INSN_COST);
14606   format %{ &quot;tst  $op1&quot; %}
14607 
14608   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14609 
14610   ins_pipe(icmp_reg_imm);
14611 %}
14612 
14613 instruct compL_reg_immLAddSub(rFlagsReg cr, iRegL op1, immLAddSub op2)
14614 %{
14615   match(Set cr (CmpL op1 op2));
14616 
14617   effect(DEF cr, USE op1);
14618 
14619   ins_cost(INSN_COST);
14620   format %{ &quot;cmp  $op1, $op2&quot; %}
14621 
14622   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14623 
14624   ins_pipe(icmp_reg_imm);
14625 %}
14626 
14627 instruct compL_reg_immL(rFlagsReg cr, iRegL op1, immL op2)
14628 %{
14629   match(Set cr (CmpL op1 op2));
14630 
14631   effect(DEF cr, USE op1);
14632 
14633   ins_cost(INSN_COST * 2);
14634   format %{ &quot;cmp  $op1, $op2&quot; %}
14635 
14636   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14637 
14638   ins_pipe(icmp_reg_imm);
14639 %}
14640 
14641 instruct compUL_reg_reg(rFlagsRegU cr, iRegL op1, iRegL op2)
14642 %{
14643   match(Set cr (CmpUL op1 op2));
14644 
14645   effect(DEF cr, USE op1, USE op2);
14646 
14647   ins_cost(INSN_COST);
14648   format %{ &quot;cmp  $op1, $op2&quot; %}
14649 
14650   ins_encode(aarch64_enc_cmp(op1, op2));
14651 
14652   ins_pipe(icmp_reg_reg);
14653 %}
14654 
14655 instruct compUL_reg_immL0(rFlagsRegU cr, iRegL op1, immL0 zero)
14656 %{
14657   match(Set cr (CmpUL op1 zero));
14658 
14659   effect(DEF cr, USE op1);
14660 
14661   ins_cost(INSN_COST);
14662   format %{ &quot;tst  $op1&quot; %}
14663 
14664   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14665 
14666   ins_pipe(icmp_reg_imm);
14667 %}
14668 
14669 instruct compUL_reg_immLAddSub(rFlagsRegU cr, iRegL op1, immLAddSub op2)
14670 %{
14671   match(Set cr (CmpUL op1 op2));
14672 
14673   effect(DEF cr, USE op1);
14674 
14675   ins_cost(INSN_COST);
14676   format %{ &quot;cmp  $op1, $op2&quot; %}
14677 
14678   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14679 
14680   ins_pipe(icmp_reg_imm);
14681 %}
14682 
14683 instruct compUL_reg_immL(rFlagsRegU cr, iRegL op1, immL op2)
14684 %{
14685   match(Set cr (CmpUL op1 op2));
14686 
14687   effect(DEF cr, USE op1);
14688 
14689   ins_cost(INSN_COST * 2);
14690   format %{ &quot;cmp  $op1, $op2&quot; %}
14691 
14692   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14693 
14694   ins_pipe(icmp_reg_imm);
14695 %}
14696 
14697 instruct compP_reg_reg(rFlagsRegU cr, iRegP op1, iRegP op2)
14698 %{
14699   match(Set cr (CmpP op1 op2));
14700 
14701   effect(DEF cr, USE op1, USE op2);
14702 
14703   ins_cost(INSN_COST);
14704   format %{ &quot;cmp  $op1, $op2\t // ptr&quot; %}
14705 
14706   ins_encode(aarch64_enc_cmpp(op1, op2));
14707 
14708   ins_pipe(icmp_reg_reg);
14709 %}
14710 
14711 instruct compN_reg_reg(rFlagsRegU cr, iRegN op1, iRegN op2)
14712 %{
14713   match(Set cr (CmpN op1 op2));
14714 
14715   effect(DEF cr, USE op1, USE op2);
14716 
14717   ins_cost(INSN_COST);
14718   format %{ &quot;cmp  $op1, $op2\t // compressed ptr&quot; %}
14719 
14720   ins_encode(aarch64_enc_cmpn(op1, op2));
14721 
14722   ins_pipe(icmp_reg_reg);
14723 %}
14724 
14725 instruct testP_reg(rFlagsRegU cr, iRegP op1, immP0 zero)
14726 %{
14727   match(Set cr (CmpP op1 zero));
14728 
14729   effect(DEF cr, USE op1, USE zero);
14730 
14731   ins_cost(INSN_COST);
14732   format %{ &quot;cmp  $op1, 0\t // ptr&quot; %}
14733 
14734   ins_encode(aarch64_enc_testp(op1));
14735 
14736   ins_pipe(icmp_reg_imm);
14737 %}
14738 
14739 instruct testN_reg(rFlagsRegU cr, iRegN op1, immN0 zero)
14740 %{
14741   match(Set cr (CmpN op1 zero));
14742 
14743   effect(DEF cr, USE op1, USE zero);
14744 
14745   ins_cost(INSN_COST);
14746   format %{ &quot;cmp  $op1, 0\t // compressed ptr&quot; %}
14747 
14748   ins_encode(aarch64_enc_testn(op1));
14749 
14750   ins_pipe(icmp_reg_imm);
14751 %}
14752 
14753 // FP comparisons
14754 //
14755 // n.b. CmpF/CmpD set a normal flags reg which then gets compared
14756 // using normal cmpOp. See declaration of rFlagsReg for details.
14757 
14758 instruct compF_reg_reg(rFlagsReg cr, vRegF src1, vRegF src2)
14759 %{
14760   match(Set cr (CmpF src1 src2));
14761 
14762   ins_cost(3 * INSN_COST);
14763   format %{ &quot;fcmps $src1, $src2&quot; %}
14764 
14765   ins_encode %{
14766     __ fcmps(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14767   %}
14768 
14769   ins_pipe(pipe_class_compare);
14770 %}
14771 
14772 instruct compF_reg_zero(rFlagsReg cr, vRegF src1, immF0 src2)
14773 %{
14774   match(Set cr (CmpF src1 src2));
14775 
14776   ins_cost(3 * INSN_COST);
14777   format %{ &quot;fcmps $src1, 0.0&quot; %}
14778 
14779   ins_encode %{
14780     __ fcmps(as_FloatRegister($src1$$reg), 0.0);
14781   %}
14782 
14783   ins_pipe(pipe_class_compare);
14784 %}
14785 // FROM HERE
14786 
14787 instruct compD_reg_reg(rFlagsReg cr, vRegD src1, vRegD src2)
14788 %{
14789   match(Set cr (CmpD src1 src2));
14790 
14791   ins_cost(3 * INSN_COST);
14792   format %{ &quot;fcmpd $src1, $src2&quot; %}
14793 
14794   ins_encode %{
14795     __ fcmpd(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14796   %}
14797 
14798   ins_pipe(pipe_class_compare);
14799 %}
14800 
14801 instruct compD_reg_zero(rFlagsReg cr, vRegD src1, immD0 src2)
14802 %{
14803   match(Set cr (CmpD src1 src2));
14804 
14805   ins_cost(3 * INSN_COST);
14806   format %{ &quot;fcmpd $src1, 0.0&quot; %}
14807 
14808   ins_encode %{
14809     __ fcmpd(as_FloatRegister($src1$$reg), 0.0);
14810   %}
14811 
14812   ins_pipe(pipe_class_compare);
14813 %}
14814 
14815 instruct compF3_reg_reg(iRegINoSp dst, vRegF src1, vRegF src2, rFlagsReg cr)
14816 %{
14817   match(Set dst (CmpF3 src1 src2));
14818   effect(KILL cr);
14819 
14820   ins_cost(5 * INSN_COST);
14821   format %{ &quot;fcmps $src1, $src2\n\t&quot;
14822             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14823             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14824   %}
14825 
14826   ins_encode %{
14827     Label done;
14828     FloatRegister s1 = as_FloatRegister($src1$$reg);
14829     FloatRegister s2 = as_FloatRegister($src2$$reg);
14830     Register d = as_Register($dst$$reg);
14831     __ fcmps(s1, s2);
14832     // installs 0 if EQ else -1
14833     __ csinvw(d, zr, zr, Assembler::EQ);
14834     // keeps -1 if less or unordered else installs 1
14835     __ csnegw(d, d, d, Assembler::LT);
14836     __ bind(done);
14837   %}
14838 
14839   ins_pipe(pipe_class_default);
14840 
14841 %}
14842 
14843 instruct compD3_reg_reg(iRegINoSp dst, vRegD src1, vRegD src2, rFlagsReg cr)
14844 %{
14845   match(Set dst (CmpD3 src1 src2));
14846   effect(KILL cr);
14847 
14848   ins_cost(5 * INSN_COST);
14849   format %{ &quot;fcmpd $src1, $src2\n\t&quot;
14850             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14851             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14852   %}
14853 
14854   ins_encode %{
14855     Label done;
14856     FloatRegister s1 = as_FloatRegister($src1$$reg);
14857     FloatRegister s2 = as_FloatRegister($src2$$reg);
14858     Register d = as_Register($dst$$reg);
14859     __ fcmpd(s1, s2);
14860     // installs 0 if EQ else -1
14861     __ csinvw(d, zr, zr, Assembler::EQ);
14862     // keeps -1 if less or unordered else installs 1
14863     __ csnegw(d, d, d, Assembler::LT);
14864     __ bind(done);
14865   %}
14866   ins_pipe(pipe_class_default);
14867 
14868 %}
14869 
14870 instruct compF3_reg_immF0(iRegINoSp dst, vRegF src1, immF0 zero, rFlagsReg cr)
14871 %{
14872   match(Set dst (CmpF3 src1 zero));
14873   effect(KILL cr);
14874 
14875   ins_cost(5 * INSN_COST);
14876   format %{ &quot;fcmps $src1, 0.0\n\t&quot;
14877             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14878             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14879   %}
14880 
14881   ins_encode %{
14882     Label done;
14883     FloatRegister s1 = as_FloatRegister($src1$$reg);
14884     Register d = as_Register($dst$$reg);
14885     __ fcmps(s1, 0.0);
14886     // installs 0 if EQ else -1
14887     __ csinvw(d, zr, zr, Assembler::EQ);
14888     // keeps -1 if less or unordered else installs 1
14889     __ csnegw(d, d, d, Assembler::LT);
14890     __ bind(done);
14891   %}
14892 
14893   ins_pipe(pipe_class_default);
14894 
14895 %}
14896 
14897 instruct compD3_reg_immD0(iRegINoSp dst, vRegD src1, immD0 zero, rFlagsReg cr)
14898 %{
14899   match(Set dst (CmpD3 src1 zero));
14900   effect(KILL cr);
14901 
14902   ins_cost(5 * INSN_COST);
14903   format %{ &quot;fcmpd $src1, 0.0\n\t&quot;
14904             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14905             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14906   %}
14907 
14908   ins_encode %{
14909     Label done;
14910     FloatRegister s1 = as_FloatRegister($src1$$reg);
14911     Register d = as_Register($dst$$reg);
14912     __ fcmpd(s1, 0.0);
14913     // installs 0 if EQ else -1
14914     __ csinvw(d, zr, zr, Assembler::EQ);
14915     // keeps -1 if less or unordered else installs 1
14916     __ csnegw(d, d, d, Assembler::LT);
14917     __ bind(done);
14918   %}
14919   ins_pipe(pipe_class_default);
14920 
14921 %}
14922 
14923 instruct cmpLTMask_reg_reg(iRegINoSp dst, iRegIorL2I p, iRegIorL2I q, rFlagsReg cr)
14924 %{
14925   match(Set dst (CmpLTMask p q));
14926   effect(KILL cr);
14927 
14928   ins_cost(3 * INSN_COST);
14929 
14930   format %{ &quot;cmpw $p, $q\t# cmpLTMask\n\t&quot;
14931             &quot;csetw $dst, lt\n\t&quot;
14932             &quot;subw $dst, zr, $dst&quot;
14933   %}
14934 
14935   ins_encode %{
14936     __ cmpw(as_Register($p$$reg), as_Register($q$$reg));
14937     __ csetw(as_Register($dst$$reg), Assembler::LT);
14938     __ subw(as_Register($dst$$reg), zr, as_Register($dst$$reg));
14939   %}
14940 
14941   ins_pipe(ialu_reg_reg);
14942 %}
14943 
14944 instruct cmpLTMask_reg_zero(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr)
14945 %{
14946   match(Set dst (CmpLTMask src zero));
14947   effect(KILL cr);
14948 
14949   ins_cost(INSN_COST);
14950 
14951   format %{ &quot;asrw $dst, $src, #31\t# cmpLTMask0&quot; %}
14952 
14953   ins_encode %{
14954     __ asrw(as_Register($dst$$reg), as_Register($src$$reg), 31);
14955   %}
14956 
14957   ins_pipe(ialu_reg_shift);
14958 %}
14959 
14960 // ============================================================================
14961 // Max and Min
14962 
14963 instruct cmovI_reg_reg_lt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14964 %{
14965   effect( DEF dst, USE src1, USE src2, USE cr );
14966 
14967   ins_cost(INSN_COST * 2);
14968   format %{ &quot;cselw $dst, $src1, $src2 lt\t&quot;  %}
14969 
14970   ins_encode %{
14971     __ cselw(as_Register($dst$$reg),
14972              as_Register($src1$$reg),
14973              as_Register($src2$$reg),
14974              Assembler::LT);
14975   %}
14976 
14977   ins_pipe(icond_reg_reg);
14978 %}
14979 
14980 instruct minI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14981 %{
14982   match(Set dst (MinI src1 src2));
14983   ins_cost(INSN_COST * 3);
14984 
14985   expand %{
14986     rFlagsReg cr;
14987     compI_reg_reg(cr, src1, src2);
14988     cmovI_reg_reg_lt(dst, src1, src2, cr);
14989   %}
14990 
14991 %}
14992 // FROM HERE
14993 
14994 instruct cmovI_reg_reg_gt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14995 %{
14996   effect( DEF dst, USE src1, USE src2, USE cr );
14997 
14998   ins_cost(INSN_COST * 2);
14999   format %{ &quot;cselw $dst, $src1, $src2 gt\t&quot;  %}
15000 
15001   ins_encode %{
15002     __ cselw(as_Register($dst$$reg),
15003              as_Register($src1$$reg),
15004              as_Register($src2$$reg),
15005              Assembler::GT);
15006   %}
15007 
15008   ins_pipe(icond_reg_reg);
15009 %}
15010 
15011 instruct maxI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
15012 %{
15013   match(Set dst (MaxI src1 src2));
15014   ins_cost(INSN_COST * 3);
15015   expand %{
15016     rFlagsReg cr;
15017     compI_reg_reg(cr, src1, src2);
15018     cmovI_reg_reg_gt(dst, src1, src2, cr);
15019   %}
15020 %}
15021 
15022 // ============================================================================
15023 // Branch Instructions
15024 
15025 // Direct Branch.
15026 instruct branch(label lbl)
15027 %{
15028   match(Goto);
15029 
15030   effect(USE lbl);
15031 
15032   ins_cost(BRANCH_COST);
15033   format %{ &quot;b  $lbl&quot; %}
15034 
15035   ins_encode(aarch64_enc_b(lbl));
15036 
15037   ins_pipe(pipe_branch);
15038 %}
15039 
15040 // Conditional Near Branch
15041 instruct branchCon(cmpOp cmp, rFlagsReg cr, label lbl)
15042 %{
15043   // Same match rule as `branchConFar&#39;.
15044   match(If cmp cr);
15045 
15046   effect(USE lbl);
15047 
15048   ins_cost(BRANCH_COST);
15049   // If set to 1 this indicates that the current instruction is a
15050   // short variant of a long branch. This avoids using this
15051   // instruction in first-pass matching. It will then only be used in
15052   // the `Shorten_branches&#39; pass.
15053   // ins_short_branch(1);
15054   format %{ &quot;b$cmp  $lbl&quot; %}
15055 
15056   ins_encode(aarch64_enc_br_con(cmp, lbl));
15057 
15058   ins_pipe(pipe_branch_cond);
15059 %}
15060 
15061 // Conditional Near Branch Unsigned
15062 instruct branchConU(cmpOpU cmp, rFlagsRegU cr, label lbl)
15063 %{
15064   // Same match rule as `branchConFar&#39;.
15065   match(If cmp cr);
15066 
15067   effect(USE lbl);
15068 
15069   ins_cost(BRANCH_COST);
15070   // If set to 1 this indicates that the current instruction is a
15071   // short variant of a long branch. This avoids using this
15072   // instruction in first-pass matching. It will then only be used in
15073   // the `Shorten_branches&#39; pass.
15074   // ins_short_branch(1);
15075   format %{ &quot;b$cmp  $lbl\t# unsigned&quot; %}
15076 
15077   ins_encode(aarch64_enc_br_conU(cmp, lbl));
15078 
15079   ins_pipe(pipe_branch_cond);
15080 %}
15081 
15082 // Make use of CBZ and CBNZ.  These instructions, as well as being
15083 // shorter than (cmp; branch), have the additional benefit of not
15084 // killing the flags.
15085 
15086 instruct cmpI_imm0_branch(cmpOpEqNe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsReg cr) %{
15087   match(If cmp (CmpI op1 op2));
15088   effect(USE labl);
15089 
15090   ins_cost(BRANCH_COST);
15091   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
15092   ins_encode %{
15093     Label* L = $labl$$label;
15094     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15095     if (cond == Assembler::EQ)
15096       __ cbzw($op1$$Register, *L);
15097     else
15098       __ cbnzw($op1$$Register, *L);
15099   %}
15100   ins_pipe(pipe_cmp_branch);
15101 %}
15102 
15103 instruct cmpL_imm0_branch(cmpOpEqNe cmp, iRegL op1, immL0 op2, label labl, rFlagsReg cr) %{
15104   match(If cmp (CmpL op1 op2));
15105   effect(USE labl);
15106 
15107   ins_cost(BRANCH_COST);
15108   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
15109   ins_encode %{
15110     Label* L = $labl$$label;
15111     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15112     if (cond == Assembler::EQ)
15113       __ cbz($op1$$Register, *L);
15114     else
15115       __ cbnz($op1$$Register, *L);
15116   %}
15117   ins_pipe(pipe_cmp_branch);
15118 %}
15119 
15120 instruct cmpP_imm0_branch(cmpOpEqNe cmp, iRegP op1, immP0 op2, label labl, rFlagsReg cr) %{
15121   match(If cmp (CmpP op1 op2));
15122   effect(USE labl);
15123 
15124   ins_cost(BRANCH_COST);
15125   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
15126   ins_encode %{
15127     Label* L = $labl$$label;
15128     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15129     if (cond == Assembler::EQ)
15130       __ cbz($op1$$Register, *L);
15131     else
15132       __ cbnz($op1$$Register, *L);
15133   %}
15134   ins_pipe(pipe_cmp_branch);
15135 %}
15136 
15137 instruct cmpN_imm0_branch(cmpOpEqNe cmp, iRegN op1, immN0 op2, label labl, rFlagsReg cr) %{
15138   match(If cmp (CmpN op1 op2));
15139   effect(USE labl);
15140 
15141   ins_cost(BRANCH_COST);
15142   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
15143   ins_encode %{
15144     Label* L = $labl$$label;
15145     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15146     if (cond == Assembler::EQ)
15147       __ cbzw($op1$$Register, *L);
15148     else
15149       __ cbnzw($op1$$Register, *L);
15150   %}
15151   ins_pipe(pipe_cmp_branch);
15152 %}
15153 
15154 instruct cmpP_narrowOop_imm0_branch(cmpOpEqNe cmp, iRegN oop, immP0 zero, label labl, rFlagsReg cr) %{
15155   match(If cmp (CmpP (DecodeN oop) zero));
15156   effect(USE labl);
15157 
15158   ins_cost(BRANCH_COST);
15159   format %{ &quot;cb$cmp   $oop, $labl&quot; %}
15160   ins_encode %{
15161     Label* L = $labl$$label;
15162     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15163     if (cond == Assembler::EQ)
15164       __ cbzw($oop$$Register, *L);
15165     else
15166       __ cbnzw($oop$$Register, *L);
15167   %}
15168   ins_pipe(pipe_cmp_branch);
15169 %}
15170 
15171 instruct cmpUI_imm0_branch(cmpOpUEqNeLtGe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsRegU cr) %{
15172   match(If cmp (CmpU op1 op2));
15173   effect(USE labl);
15174 
15175   ins_cost(BRANCH_COST);
15176   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
15177   ins_encode %{
15178     Label* L = $labl$$label;
15179     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15180     if (cond == Assembler::EQ || cond == Assembler::LS)
15181       __ cbzw($op1$$Register, *L);
15182     else
15183       __ cbnzw($op1$$Register, *L);
15184   %}
15185   ins_pipe(pipe_cmp_branch);
15186 %}
15187 
15188 instruct cmpUL_imm0_branch(cmpOpUEqNeLtGe cmp, iRegL op1, immL0 op2, label labl, rFlagsRegU cr) %{
15189   match(If cmp (CmpUL op1 op2));
15190   effect(USE labl);
15191 
15192   ins_cost(BRANCH_COST);
15193   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
15194   ins_encode %{
15195     Label* L = $labl$$label;
15196     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15197     if (cond == Assembler::EQ || cond == Assembler::LS)
15198       __ cbz($op1$$Register, *L);
15199     else
15200       __ cbnz($op1$$Register, *L);
15201   %}
15202   ins_pipe(pipe_cmp_branch);
15203 %}
15204 
15205 // Test bit and Branch
15206 
15207 // Patterns for short (&lt; 32KiB) variants
15208 instruct cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
15209   match(If cmp (CmpL op1 op2));
15210   effect(USE labl);
15211 
15212   ins_cost(BRANCH_COST);
15213   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
15214   ins_encode %{
15215     Label* L = $labl$$label;
15216     Assembler::Condition cond =
15217       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
15218     __ tbr(cond, $op1$$Register, 63, *L);
15219   %}
15220   ins_pipe(pipe_cmp_branch);
15221   ins_short_branch(1);
15222 %}
15223 
15224 instruct cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
15225   match(If cmp (CmpI op1 op2));
15226   effect(USE labl);
15227 
15228   ins_cost(BRANCH_COST);
15229   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
15230   ins_encode %{
15231     Label* L = $labl$$label;
15232     Assembler::Condition cond =
15233       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
15234     __ tbr(cond, $op1$$Register, 31, *L);
15235   %}
15236   ins_pipe(pipe_cmp_branch);
15237   ins_short_branch(1);
15238 %}
15239 
15240 instruct cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
15241   match(If cmp (CmpL (AndL op1 op2) op3));
15242   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15243   effect(USE labl);
15244 
15245   ins_cost(BRANCH_COST);
15246   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15247   ins_encode %{
15248     Label* L = $labl$$label;
15249     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15250     int bit = exact_log2_long($op2$$constant);
15251     __ tbr(cond, $op1$$Register, bit, *L);
15252   %}
15253   ins_pipe(pipe_cmp_branch);
15254   ins_short_branch(1);
15255 %}
15256 
15257 instruct cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
15258   match(If cmp (CmpI (AndI op1 op2) op3));
15259   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15260   effect(USE labl);
15261 
15262   ins_cost(BRANCH_COST);
15263   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15264   ins_encode %{
15265     Label* L = $labl$$label;
15266     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15267     int bit = exact_log2((juint)$op2$$constant);
15268     __ tbr(cond, $op1$$Register, bit, *L);
15269   %}
15270   ins_pipe(pipe_cmp_branch);
15271   ins_short_branch(1);
15272 %}
15273 
15274 // And far variants
15275 instruct far_cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
15276   match(If cmp (CmpL op1 op2));
15277   effect(USE labl);
15278 
15279   ins_cost(BRANCH_COST);
15280   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
15281   ins_encode %{
15282     Label* L = $labl$$label;
15283     Assembler::Condition cond =
15284       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
15285     __ tbr(cond, $op1$$Register, 63, *L, /*far*/true);
15286   %}
15287   ins_pipe(pipe_cmp_branch);
15288 %}
15289 
15290 instruct far_cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
15291   match(If cmp (CmpI op1 op2));
15292   effect(USE labl);
15293 
15294   ins_cost(BRANCH_COST);
15295   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
15296   ins_encode %{
15297     Label* L = $labl$$label;
15298     Assembler::Condition cond =
15299       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
15300     __ tbr(cond, $op1$$Register, 31, *L, /*far*/true);
15301   %}
15302   ins_pipe(pipe_cmp_branch);
15303 %}
15304 
15305 instruct far_cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
15306   match(If cmp (CmpL (AndL op1 op2) op3));
15307   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15308   effect(USE labl);
15309 
15310   ins_cost(BRANCH_COST);
15311   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15312   ins_encode %{
15313     Label* L = $labl$$label;
15314     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15315     int bit = exact_log2_long($op2$$constant);
15316     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15317   %}
15318   ins_pipe(pipe_cmp_branch);
15319 %}
15320 
15321 instruct far_cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
15322   match(If cmp (CmpI (AndI op1 op2) op3));
15323   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15324   effect(USE labl);
15325 
15326   ins_cost(BRANCH_COST);
15327   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15328   ins_encode %{
15329     Label* L = $labl$$label;
15330     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15331     int bit = exact_log2((juint)$op2$$constant);
15332     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15333   %}
15334   ins_pipe(pipe_cmp_branch);
15335 %}
15336 
15337 // Test bits
15338 
15339 instruct cmpL_and(cmpOp cmp, iRegL op1, immL op2, immL0 op3, rFlagsReg cr) %{
15340   match(Set cr (CmpL (AndL op1 op2) op3));
15341   predicate(Assembler::operand_valid_for_logical_immediate
15342             (/*is_32*/false, n-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15343 
15344   ins_cost(INSN_COST);
15345   format %{ &quot;tst $op1, $op2 # long&quot; %}
15346   ins_encode %{
15347     __ tst($op1$$Register, $op2$$constant);
15348   %}
15349   ins_pipe(ialu_reg_reg);
15350 %}
15351 
15352 instruct cmpI_and(cmpOp cmp, iRegIorL2I op1, immI op2, immI0 op3, rFlagsReg cr) %{
15353   match(Set cr (CmpI (AndI op1 op2) op3));
15354   predicate(Assembler::operand_valid_for_logical_immediate
15355             (/*is_32*/true, n-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15356 
15357   ins_cost(INSN_COST);
15358   format %{ &quot;tst $op1, $op2 # int&quot; %}
15359   ins_encode %{
15360     __ tstw($op1$$Register, $op2$$constant);
15361   %}
15362   ins_pipe(ialu_reg_reg);
15363 %}
15364 
15365 instruct cmpL_and_reg(cmpOp cmp, iRegL op1, iRegL op2, immL0 op3, rFlagsReg cr) %{
15366   match(Set cr (CmpL (AndL op1 op2) op3));
15367 
15368   ins_cost(INSN_COST);
15369   format %{ &quot;tst $op1, $op2 # long&quot; %}
15370   ins_encode %{
15371     __ tst($op1$$Register, $op2$$Register);
15372   %}
15373   ins_pipe(ialu_reg_reg);
15374 %}
15375 
15376 instruct cmpI_and_reg(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, immI0 op3, rFlagsReg cr) %{
15377   match(Set cr (CmpI (AndI op1 op2) op3));
15378 
15379   ins_cost(INSN_COST);
15380   format %{ &quot;tstw $op1, $op2 # int&quot; %}
15381   ins_encode %{
15382     __ tstw($op1$$Register, $op2$$Register);
15383   %}
15384   ins_pipe(ialu_reg_reg);
15385 %}
15386 
15387 
15388 // Conditional Far Branch
15389 // Conditional Far Branch Unsigned
15390 // TODO: fixme
15391 
15392 // counted loop end branch near
15393 instruct branchLoopEnd(cmpOp cmp, rFlagsReg cr, label lbl)
15394 %{
15395   match(CountedLoopEnd cmp cr);
15396 
15397   effect(USE lbl);
15398 
15399   ins_cost(BRANCH_COST);
15400   // short variant.
15401   // ins_short_branch(1);
15402   format %{ &quot;b$cmp $lbl \t// counted loop end&quot; %}
15403 
15404   ins_encode(aarch64_enc_br_con(cmp, lbl));
15405 
15406   ins_pipe(pipe_branch);
15407 %}
15408 
15409 // counted loop end branch near Unsigned
15410 instruct branchLoopEndU(cmpOpU cmp, rFlagsRegU cr, label lbl)
15411 %{
15412   match(CountedLoopEnd cmp cr);
15413 
15414   effect(USE lbl);
15415 
15416   ins_cost(BRANCH_COST);
15417   // short variant.
15418   // ins_short_branch(1);
15419   format %{ &quot;b$cmp $lbl \t// counted loop end unsigned&quot; %}
15420 
15421   ins_encode(aarch64_enc_br_conU(cmp, lbl));
15422 
15423   ins_pipe(pipe_branch);
15424 %}
15425 
15426 // counted loop end branch far
15427 // counted loop end branch far unsigned
15428 // TODO: fixme
15429 
15430 // ============================================================================
15431 // inlined locking and unlocking
15432 
15433 instruct cmpFastLock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15434 %{
15435   match(Set cr (FastLock object box));
15436   effect(TEMP tmp, TEMP tmp2);
15437 
15438   // TODO
15439   // identify correct cost
15440   ins_cost(5 * INSN_COST);
15441   format %{ &quot;fastlock $object,$box\t! kills $tmp,$tmp2&quot; %}
15442 
15443   ins_encode(aarch64_enc_fast_lock(object, box, tmp, tmp2));
15444 
15445   ins_pipe(pipe_serial);
15446 %}
15447 
15448 instruct cmpFastUnlock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15449 %{
15450   match(Set cr (FastUnlock object box));
15451   effect(TEMP tmp, TEMP tmp2);
15452 
15453   ins_cost(5 * INSN_COST);
15454   format %{ &quot;fastunlock $object,$box\t! kills $tmp, $tmp2&quot; %}
15455 
15456   ins_encode(aarch64_enc_fast_unlock(object, box, tmp, tmp2));
15457 
15458   ins_pipe(pipe_serial);
15459 %}
15460 
15461 
15462 // ============================================================================
15463 // Safepoint Instructions
15464 
15465 // TODO
15466 // provide a near and far version of this code
15467 
15468 instruct safePoint(rFlagsReg cr, iRegP poll)
15469 %{
15470   match(SafePoint poll);
15471   effect(KILL cr);
15472 
15473   format %{
15474     &quot;ldrw zr, [$poll]\t# Safepoint: poll for GC&quot;
15475   %}
15476   ins_encode %{
15477     __ read_polling_page(as_Register($poll$$reg), relocInfo::poll_type);
15478   %}
15479   ins_pipe(pipe_serial); // ins_pipe(iload_reg_mem);
15480 %}
15481 
15482 
15483 // ============================================================================
15484 // Procedure Call/Return Instructions
15485 
15486 // Call Java Static Instruction
15487 
15488 instruct CallStaticJavaDirect(method meth)
15489 %{
15490   match(CallStaticJava);
15491 
15492   effect(USE meth);
15493 
15494   ins_cost(CALL_COST);
15495 
15496   format %{ &quot;call,static $meth \t// ==&gt; &quot; %}
15497 
15498   ins_encode( aarch64_enc_java_static_call(meth),
15499               aarch64_enc_call_epilog );
15500 
15501   ins_pipe(pipe_class_call);
15502 %}
15503 
15504 // TO HERE
15505 
15506 // Call Java Dynamic Instruction
15507 instruct CallDynamicJavaDirect(method meth)
15508 %{
15509   match(CallDynamicJava);
15510 
15511   effect(USE meth);
15512 
15513   ins_cost(CALL_COST);
15514 
15515   format %{ &quot;CALL,dynamic $meth \t// ==&gt; &quot; %}
15516 
15517   ins_encode( aarch64_enc_java_dynamic_call(meth),
15518                aarch64_enc_call_epilog );
15519 
15520   ins_pipe(pipe_class_call);
15521 %}
15522 
15523 // Call Runtime Instruction
15524 
15525 instruct CallRuntimeDirect(method meth)
15526 %{
15527   match(CallRuntime);
15528 
15529   effect(USE meth);
15530 
15531   ins_cost(CALL_COST);
15532 
15533   format %{ &quot;CALL, runtime $meth&quot; %}
15534 
15535   ins_encode( aarch64_enc_java_to_runtime(meth) );
15536 
15537   ins_pipe(pipe_class_call);
15538 %}
15539 
15540 // Call Runtime Instruction
15541 
15542 instruct CallLeafDirect(method meth)
15543 %{
15544   match(CallLeaf);
15545 
15546   effect(USE meth);
15547 
15548   ins_cost(CALL_COST);
15549 
15550   format %{ &quot;CALL, runtime leaf $meth&quot; %}
15551 
15552   ins_encode( aarch64_enc_java_to_runtime(meth) );
15553 
15554   ins_pipe(pipe_class_call);
15555 %}
15556 
15557 // Call Runtime Instruction
15558 
15559 instruct CallLeafNoFPDirect(method meth)
15560 %{
15561   match(CallLeafNoFP);
15562 
15563   effect(USE meth);
15564 
15565   ins_cost(CALL_COST);
15566 
15567   format %{ &quot;CALL, runtime leaf nofp $meth&quot; %}
15568 
15569   ins_encode( aarch64_enc_java_to_runtime(meth) );
15570 
15571   ins_pipe(pipe_class_call);
15572 %}
15573 
15574 // Tail Call; Jump from runtime stub to Java code.
15575 // Also known as an &#39;interprocedural jump&#39;.
15576 // Target of jump will eventually return to caller.
15577 // TailJump below removes the return address.
<a name="5" id="anc5"></a><span class="line-modified">15578 instruct TailCalljmpInd(iRegPNoSp jump_target, inline_cache_RegP method_ptr)</span>
15579 %{
<a name="6" id="anc6"></a><span class="line-modified">15580   match(TailCall jump_target method_ptr);</span>
15581 
15582   ins_cost(CALL_COST);
15583 
<a name="7" id="anc7"></a><span class="line-modified">15584   format %{ &quot;br $jump_target\t# $method_ptr holds method&quot; %}</span>
15585 
15586   ins_encode(aarch64_enc_tail_call(jump_target));
15587 
15588   ins_pipe(pipe_class_call);
15589 %}
15590 
15591 instruct TailjmpInd(iRegPNoSp jump_target, iRegP_R0 ex_oop)
15592 %{
15593   match(TailJump jump_target ex_oop);
15594 
15595   ins_cost(CALL_COST);
15596 
15597   format %{ &quot;br $jump_target\t# $ex_oop holds exception oop&quot; %}
15598 
15599   ins_encode(aarch64_enc_tail_jmp(jump_target));
15600 
15601   ins_pipe(pipe_class_call);
15602 %}
15603 
15604 // Create exception oop: created by stack-crawling runtime code.
15605 // Created exception is now available to this handler, and is setup
15606 // just prior to jumping to this handler. No code emitted.
15607 // TODO check
15608 // should ex_oop be in r0? intel uses rax, ppc cannot use r0 so uses rarg1
15609 instruct CreateException(iRegP_R0 ex_oop)
15610 %{
15611   match(Set ex_oop (CreateEx));
15612 
15613   format %{ &quot; -- \t// exception oop; no code emitted&quot; %}
15614 
15615   size(0);
15616 
15617   ins_encode( /*empty*/ );
15618 
15619   ins_pipe(pipe_class_empty);
15620 %}
15621 
15622 // Rethrow exception: The exception oop will come in the first
15623 // argument position. Then JUMP (not call) to the rethrow stub code.
15624 instruct RethrowException() %{
15625   match(Rethrow);
15626   ins_cost(CALL_COST);
15627 
15628   format %{ &quot;b rethrow_stub&quot; %}
15629 
15630   ins_encode( aarch64_enc_rethrow() );
15631 
15632   ins_pipe(pipe_class_call);
15633 %}
15634 
15635 
15636 // Return Instruction
15637 // epilog node loads ret address into lr as part of frame pop
15638 instruct Ret()
15639 %{
15640   match(Return);
15641 
15642   format %{ &quot;ret\t// return register&quot; %}
15643 
15644   ins_encode( aarch64_enc_ret() );
15645 
15646   ins_pipe(pipe_branch);
15647 %}
15648 
15649 // Die now.
15650 instruct ShouldNotReachHere() %{
15651   match(Halt);
15652 
15653   ins_cost(CALL_COST);
15654   format %{ &quot;ShouldNotReachHere&quot; %}
15655 
15656   ins_encode %{
15657     if (is_reachable()) {
15658       __ stop(_halt_reason);
15659     }
15660   %}
15661 
15662   ins_pipe(pipe_class_default);
15663 %}
15664 
15665 // ============================================================================
15666 // Partial Subtype Check
15667 //
15668 // superklass array for an instance of the superklass.  Set a hidden
15669 // internal cache on a hit (cache is checked with exposed code in
15670 // gen_subtype_check()).  Return NZ for a miss or zero for a hit.  The
15671 // encoding ALSO sets flags.
15672 
15673 instruct partialSubtypeCheck(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, rFlagsReg cr)
15674 %{
15675   match(Set result (PartialSubtypeCheck sub super));
15676   effect(KILL cr, KILL temp);
15677 
15678   ins_cost(1100);  // slightly larger than the next version
15679   format %{ &quot;partialSubtypeCheck $result, $sub, $super&quot; %}
15680 
15681   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15682 
15683   opcode(0x1); // Force zero of result reg on hit
15684 
15685   ins_pipe(pipe_class_memory);
15686 %}
15687 
15688 instruct partialSubtypeCheckVsZero(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, immP0 zero, rFlagsReg cr)
15689 %{
15690   match(Set cr (CmpP (PartialSubtypeCheck sub super) zero));
15691   effect(KILL temp, KILL result);
15692 
15693   ins_cost(1100);  // slightly larger than the next version
15694   format %{ &quot;partialSubtypeCheck $result, $sub, $super == 0&quot; %}
15695 
15696   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15697 
15698   opcode(0x0); // Don&#39;t zero result reg on hit
15699 
15700   ins_pipe(pipe_class_memory);
15701 %}
15702 
15703 instruct string_compareU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15704                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15705 %{
15706   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15707   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15708   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15709 
15710   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15711   ins_encode %{
15712     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15713     __ string_compare($str1$$Register, $str2$$Register,
15714                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15715                       $tmp1$$Register, $tmp2$$Register,
15716                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::UU);
15717   %}
15718   ins_pipe(pipe_class_memory);
15719 %}
15720 
15721 instruct string_compareL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15722                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15723 %{
15724   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15725   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15726   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15727 
15728   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15729   ins_encode %{
15730     __ string_compare($str1$$Register, $str2$$Register,
15731                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15732                       $tmp1$$Register, $tmp2$$Register,
15733                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::LL);
15734   %}
15735   ins_pipe(pipe_class_memory);
15736 %}
15737 
15738 instruct string_compareUL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15739                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15740                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15741 %{
15742   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15743   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15744   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15745          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15746 
15747   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15748   ins_encode %{
15749     __ string_compare($str1$$Register, $str2$$Register,
15750                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15751                       $tmp1$$Register, $tmp2$$Register,
15752                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15753                       $vtmp3$$FloatRegister, StrIntrinsicNode::UL);
15754   %}
15755   ins_pipe(pipe_class_memory);
15756 %}
15757 
15758 instruct string_compareLU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15759                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15760                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15761 %{
15762   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LU);
15763   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15764   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15765          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15766 
15767   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15768   ins_encode %{
15769     __ string_compare($str1$$Register, $str2$$Register,
15770                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15771                       $tmp1$$Register, $tmp2$$Register,
15772                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15773                       $vtmp3$$FloatRegister,StrIntrinsicNode::LU);
15774   %}
15775   ins_pipe(pipe_class_memory);
15776 %}
15777 
15778 instruct string_indexofUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15779        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15780        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15781 %{
15782   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15783   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15784   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15785          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15786   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UU)&quot; %}
15787 
15788   ins_encode %{
15789     __ string_indexof($str1$$Register, $str2$$Register,
15790                       $cnt1$$Register, $cnt2$$Register,
15791                       $tmp1$$Register, $tmp2$$Register,
15792                       $tmp3$$Register, $tmp4$$Register,
15793                       $tmp5$$Register, $tmp6$$Register,
15794                       -1, $result$$Register, StrIntrinsicNode::UU);
15795   %}
15796   ins_pipe(pipe_class_memory);
15797 %}
15798 
15799 instruct string_indexofLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15800        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15801        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15802 %{
15803   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15804   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15805   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15806          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15807   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (LL)&quot; %}
15808 
15809   ins_encode %{
15810     __ string_indexof($str1$$Register, $str2$$Register,
15811                       $cnt1$$Register, $cnt2$$Register,
15812                       $tmp1$$Register, $tmp2$$Register,
15813                       $tmp3$$Register, $tmp4$$Register,
15814                       $tmp5$$Register, $tmp6$$Register,
15815                       -1, $result$$Register, StrIntrinsicNode::LL);
15816   %}
15817   ins_pipe(pipe_class_memory);
15818 %}
15819 
15820 instruct string_indexofUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15821        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15822        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15823 %{
15824   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15825   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15826   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15827          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15828   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UL)&quot; %}
15829 
15830   ins_encode %{
15831     __ string_indexof($str1$$Register, $str2$$Register,
15832                       $cnt1$$Register, $cnt2$$Register,
15833                       $tmp1$$Register, $tmp2$$Register,
15834                       $tmp3$$Register, $tmp4$$Register,
15835                       $tmp5$$Register, $tmp6$$Register,
15836                       -1, $result$$Register, StrIntrinsicNode::UL);
15837   %}
15838   ins_pipe(pipe_class_memory);
15839 %}
15840 
15841 instruct string_indexof_conUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15842                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15843                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15844 %{
15845   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15846   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15847   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15848          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15849   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UU)&quot; %}
15850 
15851   ins_encode %{
15852     int icnt2 = (int)$int_cnt2$$constant;
15853     __ string_indexof($str1$$Register, $str2$$Register,
15854                       $cnt1$$Register, zr,
15855                       $tmp1$$Register, $tmp2$$Register,
15856                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15857                       icnt2, $result$$Register, StrIntrinsicNode::UU);
15858   %}
15859   ins_pipe(pipe_class_memory);
15860 %}
15861 
15862 instruct string_indexof_conLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15863                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15864                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15865 %{
15866   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15867   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15868   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15869          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15870   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (LL)&quot; %}
15871 
15872   ins_encode %{
15873     int icnt2 = (int)$int_cnt2$$constant;
15874     __ string_indexof($str1$$Register, $str2$$Register,
15875                       $cnt1$$Register, zr,
15876                       $tmp1$$Register, $tmp2$$Register,
15877                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15878                       icnt2, $result$$Register, StrIntrinsicNode::LL);
15879   %}
15880   ins_pipe(pipe_class_memory);
15881 %}
15882 
15883 instruct string_indexof_conUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15884                  immI_1 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15885                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15886 %{
15887   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15888   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15889   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15890          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15891   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UL)&quot; %}
15892 
15893   ins_encode %{
15894     int icnt2 = (int)$int_cnt2$$constant;
15895     __ string_indexof($str1$$Register, $str2$$Register,
15896                       $cnt1$$Register, zr,
15897                       $tmp1$$Register, $tmp2$$Register,
15898                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15899                       icnt2, $result$$Register, StrIntrinsicNode::UL);
15900   %}
15901   ins_pipe(pipe_class_memory);
15902 %}
15903 
15904 instruct string_indexofU_char(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,
15905                               iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15906                               iRegINoSp tmp3, rFlagsReg cr)
15907 %{
15908   match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));
15909   effect(USE_KILL str1, USE_KILL cnt1, USE_KILL ch,
15910          TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15911 
15912   format %{ &quot;String IndexOf char[] $str1,$cnt1,$ch -&gt; $result&quot; %}
15913 
15914   ins_encode %{
15915     __ string_indexof_char($str1$$Register, $cnt1$$Register, $ch$$Register,
15916                            $result$$Register, $tmp1$$Register, $tmp2$$Register,
15917                            $tmp3$$Register);
15918   %}
15919   ins_pipe(pipe_class_memory);
15920 %}
15921 
15922 instruct string_equalsL(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15923                         iRegI_R0 result, rFlagsReg cr)
15924 %{
15925   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15926   match(Set result (StrEquals (Binary str1 str2) cnt));
15927   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15928 
15929   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15930   ins_encode %{
15931     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15932     __ string_equals($str1$$Register, $str2$$Register,
15933                      $result$$Register, $cnt$$Register, 1);
15934   %}
15935   ins_pipe(pipe_class_memory);
15936 %}
15937 
15938 instruct string_equalsU(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15939                         iRegI_R0 result, rFlagsReg cr)
15940 %{
15941   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15942   match(Set result (StrEquals (Binary str1 str2) cnt));
15943   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15944 
15945   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15946   ins_encode %{
15947     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15948     __ string_equals($str1$$Register, $str2$$Register,
15949                      $result$$Register, $cnt$$Register, 2);
15950   %}
15951   ins_pipe(pipe_class_memory);
15952 %}
15953 
15954 instruct array_equalsB(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15955                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15956                        iRegP_R10 tmp, rFlagsReg cr)
15957 %{
15958   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15959   match(Set result (AryEq ary1 ary2));
15960   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15961 
15962   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15963   ins_encode %{
15964     __ arrays_equals($ary1$$Register, $ary2$$Register,
15965                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15966                      $result$$Register, $tmp$$Register, 1);
15967     %}
15968   ins_pipe(pipe_class_memory);
15969 %}
15970 
15971 instruct array_equalsC(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15972                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15973                        iRegP_R10 tmp, rFlagsReg cr)
15974 %{
15975   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15976   match(Set result (AryEq ary1 ary2));
15977   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15978 
15979   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15980   ins_encode %{
15981     __ arrays_equals($ary1$$Register, $ary2$$Register,
15982                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15983                      $result$$Register, $tmp$$Register, 2);
15984   %}
15985   ins_pipe(pipe_class_memory);
15986 %}
15987 
15988 instruct has_negatives(iRegP_R1 ary1, iRegI_R2 len, iRegI_R0 result, rFlagsReg cr)
15989 %{
15990   match(Set result (HasNegatives ary1 len));
15991   effect(USE_KILL ary1, USE_KILL len, KILL cr);
15992   format %{ &quot;has negatives byte[] $ary1,$len -&gt; $result&quot; %}
15993   ins_encode %{
15994     __ has_negatives($ary1$$Register, $len$$Register, $result$$Register);
15995   %}
15996   ins_pipe( pipe_slow );
15997 %}
15998 
15999 // fast char[] to byte[] compression
16000 instruct string_compress(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
16001                          vRegD_V0 tmp1, vRegD_V1 tmp2,
16002                          vRegD_V2 tmp3, vRegD_V3 tmp4,
16003                          iRegI_R0 result, rFlagsReg cr)
16004 %{
16005   match(Set result (StrCompressedCopy src (Binary dst len)));
16006   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
16007 
16008   format %{ &quot;String Compress $src,$dst -&gt; $result    // KILL R1, R2, R3, R4&quot; %}
16009   ins_encode %{
16010     __ char_array_compress($src$$Register, $dst$$Register, $len$$Register,
16011                            $tmp1$$FloatRegister, $tmp2$$FloatRegister,
16012                            $tmp3$$FloatRegister, $tmp4$$FloatRegister,
16013                            $result$$Register);
16014   %}
16015   ins_pipe( pipe_slow );
16016 %}
16017 
16018 // fast byte[] to char[] inflation
16019 instruct string_inflate(Universe dummy, iRegP_R0 src, iRegP_R1 dst, iRegI_R2 len,
16020                         vRegD_V0 tmp1, vRegD_V1 tmp2, vRegD_V2 tmp3, iRegP_R3 tmp4, rFlagsReg cr)
16021 %{
16022   match(Set dummy (StrInflatedCopy src (Binary dst len)));
16023   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
16024 
16025   format %{ &quot;String Inflate $src,$dst    // KILL $tmp1, $tmp2&quot; %}
16026   ins_encode %{
16027     __ byte_array_inflate($src$$Register, $dst$$Register, $len$$Register,
16028                           $tmp1$$FloatRegister, $tmp2$$FloatRegister, $tmp3$$FloatRegister, $tmp4$$Register);
16029   %}
16030   ins_pipe(pipe_class_memory);
16031 %}
16032 
16033 // encode char[] to byte[] in ISO_8859_1
16034 instruct encode_iso_array(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
16035                           vRegD_V0 Vtmp1, vRegD_V1 Vtmp2,
16036                           vRegD_V2 Vtmp3, vRegD_V3 Vtmp4,
16037                           iRegI_R0 result, rFlagsReg cr)
16038 %{
16039   match(Set result (EncodeISOArray src (Binary dst len)));
16040   effect(USE_KILL src, USE_KILL dst, USE_KILL len,
16041          KILL Vtmp1, KILL Vtmp2, KILL Vtmp3, KILL Vtmp4, KILL cr);
16042 
16043   format %{ &quot;Encode array $src,$dst,$len -&gt; $result&quot; %}
16044   ins_encode %{
16045     __ encode_iso_array($src$$Register, $dst$$Register, $len$$Register,
16046          $result$$Register, $Vtmp1$$FloatRegister,  $Vtmp2$$FloatRegister,
16047          $Vtmp3$$FloatRegister,  $Vtmp4$$FloatRegister);
16048   %}
16049   ins_pipe( pipe_class_memory );
16050 %}
16051 
16052 // ============================================================================
16053 // This name is KNOWN by the ADLC and cannot be changed.
16054 // The ADLC forces a &#39;TypeRawPtr::BOTTOM&#39; output type
16055 // for this guy.
16056 instruct tlsLoadP(thread_RegP dst)
16057 %{
16058   match(Set dst (ThreadLocal));
16059 
16060   ins_cost(0);
16061 
16062   format %{ &quot; -- \t// $dst=Thread::current(), empty&quot; %}
16063 
16064   size(0);
16065 
16066   ins_encode( /*empty*/ );
16067 
16068   ins_pipe(pipe_class_empty);
16069 %}
16070 
16071 // ====================VECTOR INSTRUCTIONS=====================================
16072 
16073 // Load vector (32 bits)
16074 instruct loadV4(vecD dst, vmem4 mem)
16075 %{
16076   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 4);
16077   match(Set dst (LoadVector mem));
16078   ins_cost(4 * INSN_COST);
16079   format %{ &quot;ldrs   $dst,$mem\t# vector (32 bits)&quot; %}
16080   ins_encode( aarch64_enc_ldrvS(dst, mem) );
16081   ins_pipe(vload_reg_mem64);
16082 %}
16083 
16084 // Load vector (64 bits)
16085 instruct loadV8(vecD dst, vmem8 mem)
16086 %{
16087   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 8);
16088   match(Set dst (LoadVector mem));
16089   ins_cost(4 * INSN_COST);
16090   format %{ &quot;ldrd   $dst,$mem\t# vector (64 bits)&quot; %}
16091   ins_encode( aarch64_enc_ldrvD(dst, mem) );
16092   ins_pipe(vload_reg_mem64);
16093 %}
16094 
16095 // Load Vector (128 bits)
16096 instruct loadV16(vecX dst, vmem16 mem)
16097 %{
16098   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 16);
16099   match(Set dst (LoadVector mem));
16100   ins_cost(4 * INSN_COST);
16101   format %{ &quot;ldrq   $dst,$mem\t# vector (128 bits)&quot; %}
16102   ins_encode( aarch64_enc_ldrvQ(dst, mem) );
16103   ins_pipe(vload_reg_mem128);
16104 %}
16105 
16106 // Store Vector (32 bits)
16107 instruct storeV4(vecD src, vmem4 mem)
16108 %{
16109   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 4);
16110   match(Set mem (StoreVector mem src));
16111   ins_cost(4 * INSN_COST);
16112   format %{ &quot;strs   $mem,$src\t# vector (32 bits)&quot; %}
16113   ins_encode( aarch64_enc_strvS(src, mem) );
16114   ins_pipe(vstore_reg_mem64);
16115 %}
16116 
16117 // Store Vector (64 bits)
16118 instruct storeV8(vecD src, vmem8 mem)
16119 %{
16120   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 8);
16121   match(Set mem (StoreVector mem src));
16122   ins_cost(4 * INSN_COST);
16123   format %{ &quot;strd   $mem,$src\t# vector (64 bits)&quot; %}
16124   ins_encode( aarch64_enc_strvD(src, mem) );
16125   ins_pipe(vstore_reg_mem64);
16126 %}
16127 
16128 // Store Vector (128 bits)
16129 instruct storeV16(vecX src, vmem16 mem)
16130 %{
16131   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 16);
16132   match(Set mem (StoreVector mem src));
16133   ins_cost(4 * INSN_COST);
16134   format %{ &quot;strq   $mem,$src\t# vector (128 bits)&quot; %}
16135   ins_encode( aarch64_enc_strvQ(src, mem) );
16136   ins_pipe(vstore_reg_mem128);
16137 %}
16138 
16139 instruct replicate8B(vecD dst, iRegIorL2I src)
16140 %{
16141   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16142             n-&gt;as_Vector()-&gt;length() == 8);
16143   match(Set dst (ReplicateB src));
16144   ins_cost(INSN_COST);
16145   format %{ &quot;dup  $dst, $src\t# vector (8B)&quot; %}
16146   ins_encode %{
16147     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($src$$reg));
16148   %}
16149   ins_pipe(vdup_reg_reg64);
16150 %}
16151 
16152 instruct replicate16B(vecX dst, iRegIorL2I src)
16153 %{
16154   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16155   match(Set dst (ReplicateB src));
16156   ins_cost(INSN_COST);
16157   format %{ &quot;dup  $dst, $src\t# vector (16B)&quot; %}
16158   ins_encode %{
16159     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($src$$reg));
16160   %}
16161   ins_pipe(vdup_reg_reg128);
16162 %}
16163 
16164 instruct replicate8B_imm(vecD dst, immI con)
16165 %{
16166   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16167             n-&gt;as_Vector()-&gt;length() == 8);
16168   match(Set dst (ReplicateB con));
16169   ins_cost(INSN_COST);
16170   format %{ &quot;movi  $dst, $con\t# vector(8B)&quot; %}
16171   ins_encode %{
16172     __ mov(as_FloatRegister($dst$$reg), __ T8B, $con$$constant &amp; 0xff);
16173   %}
16174   ins_pipe(vmovi_reg_imm64);
16175 %}
16176 
16177 instruct replicate16B_imm(vecX dst, immI con)
16178 %{
16179   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16180   match(Set dst (ReplicateB con));
16181   ins_cost(INSN_COST);
16182   format %{ &quot;movi  $dst, $con\t# vector(16B)&quot; %}
16183   ins_encode %{
16184     __ mov(as_FloatRegister($dst$$reg), __ T16B, $con$$constant &amp; 0xff);
16185   %}
16186   ins_pipe(vmovi_reg_imm128);
16187 %}
16188 
16189 instruct replicate4S(vecD dst, iRegIorL2I src)
16190 %{
16191   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16192             n-&gt;as_Vector()-&gt;length() == 4);
16193   match(Set dst (ReplicateS src));
16194   ins_cost(INSN_COST);
16195   format %{ &quot;dup  $dst, $src\t# vector (4S)&quot; %}
16196   ins_encode %{
16197     __ dup(as_FloatRegister($dst$$reg), __ T4H, as_Register($src$$reg));
16198   %}
16199   ins_pipe(vdup_reg_reg64);
16200 %}
16201 
16202 instruct replicate8S(vecX dst, iRegIorL2I src)
16203 %{
16204   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16205   match(Set dst (ReplicateS src));
16206   ins_cost(INSN_COST);
16207   format %{ &quot;dup  $dst, $src\t# vector (8S)&quot; %}
16208   ins_encode %{
16209     __ dup(as_FloatRegister($dst$$reg), __ T8H, as_Register($src$$reg));
16210   %}
16211   ins_pipe(vdup_reg_reg128);
16212 %}
16213 
16214 instruct replicate4S_imm(vecD dst, immI con)
16215 %{
16216   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16217             n-&gt;as_Vector()-&gt;length() == 4);
16218   match(Set dst (ReplicateS con));
16219   ins_cost(INSN_COST);
16220   format %{ &quot;movi  $dst, $con\t# vector(4H)&quot; %}
16221   ins_encode %{
16222     __ mov(as_FloatRegister($dst$$reg), __ T4H, $con$$constant &amp; 0xffff);
16223   %}
16224   ins_pipe(vmovi_reg_imm64);
16225 %}
16226 
16227 instruct replicate8S_imm(vecX dst, immI con)
16228 %{
16229   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16230   match(Set dst (ReplicateS con));
16231   ins_cost(INSN_COST);
16232   format %{ &quot;movi  $dst, $con\t# vector(8H)&quot; %}
16233   ins_encode %{
16234     __ mov(as_FloatRegister($dst$$reg), __ T8H, $con$$constant &amp; 0xffff);
16235   %}
16236   ins_pipe(vmovi_reg_imm128);
16237 %}
16238 
16239 instruct replicate2I(vecD dst, iRegIorL2I src)
16240 %{
16241   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16242   match(Set dst (ReplicateI src));
16243   ins_cost(INSN_COST);
16244   format %{ &quot;dup  $dst, $src\t# vector (2I)&quot; %}
16245   ins_encode %{
16246     __ dup(as_FloatRegister($dst$$reg), __ T2S, as_Register($src$$reg));
16247   %}
16248   ins_pipe(vdup_reg_reg64);
16249 %}
16250 
16251 instruct replicate4I(vecX dst, iRegIorL2I src)
16252 %{
16253   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16254   match(Set dst (ReplicateI src));
16255   ins_cost(INSN_COST);
16256   format %{ &quot;dup  $dst, $src\t# vector (4I)&quot; %}
16257   ins_encode %{
16258     __ dup(as_FloatRegister($dst$$reg), __ T4S, as_Register($src$$reg));
16259   %}
16260   ins_pipe(vdup_reg_reg128);
16261 %}
16262 
16263 instruct replicate2I_imm(vecD dst, immI con)
16264 %{
16265   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16266   match(Set dst (ReplicateI con));
16267   ins_cost(INSN_COST);
16268   format %{ &quot;movi  $dst, $con\t# vector(2I)&quot; %}
16269   ins_encode %{
16270     __ mov(as_FloatRegister($dst$$reg), __ T2S, $con$$constant);
16271   %}
16272   ins_pipe(vmovi_reg_imm64);
16273 %}
16274 
16275 instruct replicate4I_imm(vecX dst, immI con)
16276 %{
16277   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16278   match(Set dst (ReplicateI con));
16279   ins_cost(INSN_COST);
16280   format %{ &quot;movi  $dst, $con\t# vector(4I)&quot; %}
16281   ins_encode %{
16282     __ mov(as_FloatRegister($dst$$reg), __ T4S, $con$$constant);
16283   %}
16284   ins_pipe(vmovi_reg_imm128);
16285 %}
16286 
16287 instruct replicate2L(vecX dst, iRegL src)
16288 %{
16289   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16290   match(Set dst (ReplicateL src));
16291   ins_cost(INSN_COST);
16292   format %{ &quot;dup  $dst, $src\t# vector (2L)&quot; %}
16293   ins_encode %{
16294     __ dup(as_FloatRegister($dst$$reg), __ T2D, as_Register($src$$reg));
16295   %}
16296   ins_pipe(vdup_reg_reg128);
16297 %}
16298 
16299 instruct replicate2L_zero(vecX dst, immI0 zero)
16300 %{
16301   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16302   match(Set dst (ReplicateI zero));
16303   ins_cost(INSN_COST);
16304   format %{ &quot;movi  $dst, $zero\t# vector(4I)&quot; %}
16305   ins_encode %{
16306     __ eor(as_FloatRegister($dst$$reg), __ T16B,
16307            as_FloatRegister($dst$$reg),
16308            as_FloatRegister($dst$$reg));
16309   %}
16310   ins_pipe(vmovi_reg_imm128);
16311 %}
16312 
16313 instruct replicate2F(vecD dst, vRegF src)
16314 %{
16315   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16316   match(Set dst (ReplicateF src));
16317   ins_cost(INSN_COST);
16318   format %{ &quot;dup  $dst, $src\t# vector (2F)&quot; %}
16319   ins_encode %{
16320     __ dup(as_FloatRegister($dst$$reg), __ T2S,
16321            as_FloatRegister($src$$reg));
16322   %}
16323   ins_pipe(vdup_reg_freg64);
16324 %}
16325 
16326 instruct replicate4F(vecX dst, vRegF src)
16327 %{
16328   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16329   match(Set dst (ReplicateF src));
16330   ins_cost(INSN_COST);
16331   format %{ &quot;dup  $dst, $src\t# vector (4F)&quot; %}
16332   ins_encode %{
16333     __ dup(as_FloatRegister($dst$$reg), __ T4S,
16334            as_FloatRegister($src$$reg));
16335   %}
16336   ins_pipe(vdup_reg_freg128);
16337 %}
16338 
16339 instruct replicate2D(vecX dst, vRegD src)
16340 %{
16341   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16342   match(Set dst (ReplicateD src));
16343   ins_cost(INSN_COST);
16344   format %{ &quot;dup  $dst, $src\t# vector (2D)&quot; %}
16345   ins_encode %{
16346     __ dup(as_FloatRegister($dst$$reg), __ T2D,
16347            as_FloatRegister($src$$reg));
16348   %}
16349   ins_pipe(vdup_reg_dreg128);
16350 %}
16351 
16352 // ====================REDUCTION ARITHMETIC====================================
16353 
16354 instruct reduce_add2I(iRegINoSp dst, iRegIorL2I isrc, vecD vsrc, iRegINoSp tmp, iRegINoSp tmp2)
16355 %{
16356   match(Set dst (AddReductionVI isrc vsrc));
16357   ins_cost(INSN_COST);
16358   effect(TEMP tmp, TEMP tmp2);
16359   format %{ &quot;umov  $tmp, $vsrc, S, 0\n\t&quot;
16360             &quot;umov  $tmp2, $vsrc, S, 1\n\t&quot;
16361             &quot;addw  $tmp, $isrc, $tmp\n\t&quot;
16362             &quot;addw  $dst, $tmp, $tmp2\t# add reduction2I&quot;
16363   %}
16364   ins_encode %{
16365     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 0);
16366     __ umov($tmp2$$Register, as_FloatRegister($vsrc$$reg), __ S, 1);
16367     __ addw($tmp$$Register, $isrc$$Register, $tmp$$Register);
16368     __ addw($dst$$Register, $tmp$$Register, $tmp2$$Register);
16369   %}
16370   ins_pipe(pipe_class_default);
16371 %}
16372 
16373 instruct reduce_add4I(iRegINoSp dst, iRegIorL2I isrc, vecX vsrc, vecX vtmp, iRegINoSp itmp)
16374 %{
16375   match(Set dst (AddReductionVI isrc vsrc));
16376   ins_cost(INSN_COST);
16377   effect(TEMP vtmp, TEMP itmp);
16378   format %{ &quot;addv  $vtmp, T4S, $vsrc\n\t&quot;
16379             &quot;umov  $itmp, $vtmp, S, 0\n\t&quot;
16380             &quot;addw  $dst, $itmp, $isrc\t# add reduction4I&quot;
16381   %}
16382   ins_encode %{
16383     __ addv(as_FloatRegister($vtmp$$reg), __ T4S,
16384             as_FloatRegister($vsrc$$reg));
16385     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 0);
16386     __ addw($dst$$Register, $itmp$$Register, $isrc$$Register);
16387   %}
16388   ins_pipe(pipe_class_default);
16389 %}
16390 
16391 instruct reduce_mul2I(iRegINoSp dst, iRegIorL2I isrc, vecD vsrc, iRegINoSp tmp)
16392 %{
16393   match(Set dst (MulReductionVI isrc vsrc));
16394   ins_cost(INSN_COST);
16395   effect(TEMP tmp, TEMP dst);
16396   format %{ &quot;umov  $tmp, $vsrc, S, 0\n\t&quot;
16397             &quot;mul   $dst, $tmp, $isrc\n\t&quot;
16398             &quot;umov  $tmp, $vsrc, S, 1\n\t&quot;
16399             &quot;mul   $dst, $tmp, $dst\t# mul reduction2I&quot;
16400   %}
16401   ins_encode %{
16402     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 0);
16403     __ mul($dst$$Register, $tmp$$Register, $isrc$$Register);
16404     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 1);
16405     __ mul($dst$$Register, $tmp$$Register, $dst$$Register);
16406   %}
16407   ins_pipe(pipe_class_default);
16408 %}
16409 
16410 instruct reduce_mul4I(iRegINoSp dst, iRegIorL2I isrc, vecX vsrc, vecX vtmp, iRegINoSp itmp)
16411 %{
16412   match(Set dst (MulReductionVI isrc vsrc));
16413   ins_cost(INSN_COST);
16414   effect(TEMP vtmp, TEMP itmp, TEMP dst);
16415   format %{ &quot;ins   $vtmp, D, $vsrc, 0, 1\n\t&quot;
16416             &quot;mulv  $vtmp, T2S, $vtmp, $vsrc\n\t&quot;
16417             &quot;umov  $itmp, $vtmp, S, 0\n\t&quot;
16418             &quot;mul   $dst, $itmp, $isrc\n\t&quot;
16419             &quot;umov  $itmp, $vtmp, S, 1\n\t&quot;
16420             &quot;mul   $dst, $itmp, $dst\t# mul reduction4I&quot;
16421   %}
16422   ins_encode %{
16423     __ ins(as_FloatRegister($vtmp$$reg), __ D,
16424            as_FloatRegister($vsrc$$reg), 0, 1);
16425     __ mulv(as_FloatRegister($vtmp$$reg), __ T2S,
16426             as_FloatRegister($vtmp$$reg), as_FloatRegister($vsrc$$reg));
16427     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 0);
16428     __ mul($dst$$Register, $itmp$$Register, $isrc$$Register);
16429     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 1);
16430     __ mul($dst$$Register, $itmp$$Register, $dst$$Register);
16431   %}
16432   ins_pipe(pipe_class_default);
16433 %}
16434 
16435 instruct reduce_add2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp)
16436 %{
16437   match(Set dst (AddReductionVF fsrc vsrc));
16438   ins_cost(INSN_COST);
16439   effect(TEMP tmp, TEMP dst);
16440   format %{ &quot;fadds $dst, $fsrc, $vsrc\n\t&quot;
16441             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16442             &quot;fadds $dst, $dst, $tmp\t# add reduction2F&quot;
16443   %}
16444   ins_encode %{
16445     __ fadds(as_FloatRegister($dst$$reg),
16446              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16447     __ ins(as_FloatRegister($tmp$$reg), __ S,
16448            as_FloatRegister($vsrc$$reg), 0, 1);
16449     __ fadds(as_FloatRegister($dst$$reg),
16450              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16451   %}
16452   ins_pipe(pipe_class_default);
16453 %}
16454 
16455 instruct reduce_add4F(vRegF dst, vRegF fsrc, vecX vsrc, vecX tmp)
16456 %{
16457   match(Set dst (AddReductionVF fsrc vsrc));
16458   ins_cost(INSN_COST);
16459   effect(TEMP tmp, TEMP dst);
16460   format %{ &quot;fadds $dst, $fsrc, $vsrc\n\t&quot;
16461             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16462             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16463             &quot;ins   $tmp, S, $vsrc, 0, 2\n\t&quot;
16464             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16465             &quot;ins   $tmp, S, $vsrc, 0, 3\n\t&quot;
16466             &quot;fadds $dst, $dst, $tmp\t# add reduction4F&quot;
16467   %}
16468   ins_encode %{
16469     __ fadds(as_FloatRegister($dst$$reg),
16470              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16471     __ ins(as_FloatRegister($tmp$$reg), __ S,
16472            as_FloatRegister($vsrc$$reg), 0, 1);
16473     __ fadds(as_FloatRegister($dst$$reg),
16474              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16475     __ ins(as_FloatRegister($tmp$$reg), __ S,
16476            as_FloatRegister($vsrc$$reg), 0, 2);
16477     __ fadds(as_FloatRegister($dst$$reg),
16478              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16479     __ ins(as_FloatRegister($tmp$$reg), __ S,
16480            as_FloatRegister($vsrc$$reg), 0, 3);
16481     __ fadds(as_FloatRegister($dst$$reg),
16482              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16483   %}
16484   ins_pipe(pipe_class_default);
16485 %}
16486 
16487 instruct reduce_mul2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp)
16488 %{
16489   match(Set dst (MulReductionVF fsrc vsrc));
16490   ins_cost(INSN_COST);
16491   effect(TEMP tmp, TEMP dst);
16492   format %{ &quot;fmuls $dst, $fsrc, $vsrc\n\t&quot;
16493             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16494             &quot;fmuls $dst, $dst, $tmp\t# mul reduction2F&quot;
16495   %}
16496   ins_encode %{
16497     __ fmuls(as_FloatRegister($dst$$reg),
16498              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16499     __ ins(as_FloatRegister($tmp$$reg), __ S,
16500            as_FloatRegister($vsrc$$reg), 0, 1);
16501     __ fmuls(as_FloatRegister($dst$$reg),
16502              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16503   %}
16504   ins_pipe(pipe_class_default);
16505 %}
16506 
16507 instruct reduce_mul4F(vRegF dst, vRegF fsrc, vecX vsrc, vecX tmp)
16508 %{
16509   match(Set dst (MulReductionVF fsrc vsrc));
16510   ins_cost(INSN_COST);
16511   effect(TEMP tmp, TEMP dst);
16512   format %{ &quot;fmuls $dst, $fsrc, $vsrc\n\t&quot;
16513             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16514             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16515             &quot;ins   $tmp, S, $vsrc, 0, 2\n\t&quot;
16516             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16517             &quot;ins   $tmp, S, $vsrc, 0, 3\n\t&quot;
16518             &quot;fmuls $dst, $dst, $tmp\t# mul reduction4F&quot;
16519   %}
16520   ins_encode %{
16521     __ fmuls(as_FloatRegister($dst$$reg),
16522              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16523     __ ins(as_FloatRegister($tmp$$reg), __ S,
16524            as_FloatRegister($vsrc$$reg), 0, 1);
16525     __ fmuls(as_FloatRegister($dst$$reg),
16526              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16527     __ ins(as_FloatRegister($tmp$$reg), __ S,
16528            as_FloatRegister($vsrc$$reg), 0, 2);
16529     __ fmuls(as_FloatRegister($dst$$reg),
16530              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16531     __ ins(as_FloatRegister($tmp$$reg), __ S,
16532            as_FloatRegister($vsrc$$reg), 0, 3);
16533     __ fmuls(as_FloatRegister($dst$$reg),
16534              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16535   %}
16536   ins_pipe(pipe_class_default);
16537 %}
16538 
16539 instruct reduce_add2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp)
16540 %{
16541   match(Set dst (AddReductionVD dsrc vsrc));
16542   ins_cost(INSN_COST);
16543   effect(TEMP tmp, TEMP dst);
16544   format %{ &quot;faddd $dst, $dsrc, $vsrc\n\t&quot;
16545             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16546             &quot;faddd $dst, $dst, $tmp\t# add reduction2D&quot;
16547   %}
16548   ins_encode %{
16549     __ faddd(as_FloatRegister($dst$$reg),
16550              as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16551     __ ins(as_FloatRegister($tmp$$reg), __ D,
16552            as_FloatRegister($vsrc$$reg), 0, 1);
16553     __ faddd(as_FloatRegister($dst$$reg),
16554              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16555   %}
16556   ins_pipe(pipe_class_default);
16557 %}
16558 
16559 instruct reduce_mul2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp)
16560 %{
16561   match(Set dst (MulReductionVD dsrc vsrc));
16562   ins_cost(INSN_COST);
16563   effect(TEMP tmp, TEMP dst);
16564   format %{ &quot;fmuld $dst, $dsrc, $vsrc\n\t&quot;
16565             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16566             &quot;fmuld $dst, $dst, $tmp\t# mul reduction2D&quot;
16567   %}
16568   ins_encode %{
16569     __ fmuld(as_FloatRegister($dst$$reg),
16570              as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16571     __ ins(as_FloatRegister($tmp$$reg), __ D,
16572            as_FloatRegister($vsrc$$reg), 0, 1);
16573     __ fmuld(as_FloatRegister($dst$$reg),
16574              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16575   %}
16576   ins_pipe(pipe_class_default);
16577 %}
16578 
16579 instruct reduce_max2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp) %{
16580   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16581   match(Set dst (MaxReductionV fsrc vsrc));
16582   ins_cost(INSN_COST);
16583   effect(TEMP_DEF dst, TEMP tmp);
16584   format %{ &quot;fmaxs $dst, $fsrc, $vsrc\n\t&quot;
16585             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16586             &quot;fmaxs $dst, $dst, $tmp\t# max reduction2F&quot; %}
16587   ins_encode %{
16588     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16589     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($vsrc$$reg), 0, 1);
16590     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16591   %}
16592   ins_pipe(pipe_class_default);
16593 %}
16594 
16595 instruct reduce_max4F(vRegF dst, vRegF fsrc, vecX vsrc) %{
16596   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16597   match(Set dst (MaxReductionV fsrc vsrc));
16598   ins_cost(INSN_COST);
16599   effect(TEMP_DEF dst);
16600   format %{ &quot;fmaxv $dst, T4S, $vsrc\n\t&quot;
16601             &quot;fmaxs $dst, $dst, $fsrc\t# max reduction4F&quot; %}
16602   ins_encode %{
16603     __ fmaxv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($vsrc$$reg));
16604     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));
16605   %}
16606   ins_pipe(pipe_class_default);
16607 %}
16608 
16609 instruct reduce_max2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp) %{
16610   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16611   match(Set dst (MaxReductionV dsrc vsrc));
16612   ins_cost(INSN_COST);
16613   effect(TEMP_DEF dst, TEMP tmp);
16614   format %{ &quot;fmaxd $dst, $dsrc, $vsrc\n\t&quot;
16615             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16616             &quot;fmaxd $dst, $dst, $tmp\t# max reduction2D&quot; %}
16617   ins_encode %{
16618     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16619     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($vsrc$$reg), 0, 1);
16620     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16621   %}
16622   ins_pipe(pipe_class_default);
16623 %}
16624 
16625 instruct reduce_min2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp) %{
16626   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16627   match(Set dst (MinReductionV fsrc vsrc));
16628   ins_cost(INSN_COST);
16629   effect(TEMP_DEF dst, TEMP tmp);
16630   format %{ &quot;fmins $dst, $fsrc, $vsrc\n\t&quot;
16631             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16632             &quot;fmins $dst, $dst, $tmp\t# min reduction2F&quot; %}
16633   ins_encode %{
16634     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16635     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($vsrc$$reg), 0, 1);
16636     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16637   %}
16638   ins_pipe(pipe_class_default);
16639 %}
16640 
16641 instruct reduce_min4F(vRegF dst, vRegF fsrc, vecX vsrc) %{
16642   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16643   match(Set dst (MinReductionV fsrc vsrc));
16644   ins_cost(INSN_COST);
16645   effect(TEMP_DEF dst);
16646   format %{ &quot;fminv $dst, T4S, $vsrc\n\t&quot;
16647             &quot;fmins $dst, $dst, $fsrc\t# min reduction4F&quot; %}
16648   ins_encode %{
16649     __ fminv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($vsrc$$reg));
16650     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));
16651   %}
16652   ins_pipe(pipe_class_default);
16653 %}
16654 
16655 instruct reduce_min2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp) %{
16656   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16657   match(Set dst (MinReductionV dsrc vsrc));
16658   ins_cost(INSN_COST);
16659   effect(TEMP_DEF dst, TEMP tmp);
16660   format %{ &quot;fmind $dst, $dsrc, $vsrc\n\t&quot;
16661             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16662             &quot;fmind $dst, $dst, $tmp\t# min reduction2D&quot; %}
16663   ins_encode %{
16664     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16665     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($vsrc$$reg), 0, 1);
16666     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16667   %}
16668   ins_pipe(pipe_class_default);
16669 %}
16670 
16671 // ====================VECTOR ARITHMETIC=======================================
16672 
16673 // --------------------------------- ADD --------------------------------------
16674 
16675 instruct vadd8B(vecD dst, vecD src1, vecD src2)
16676 %{
16677   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16678             n-&gt;as_Vector()-&gt;length() == 8);
16679   match(Set dst (AddVB src1 src2));
16680   ins_cost(INSN_COST);
16681   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16682   ins_encode %{
16683     __ addv(as_FloatRegister($dst$$reg), __ T8B,
16684             as_FloatRegister($src1$$reg),
16685             as_FloatRegister($src2$$reg));
16686   %}
16687   ins_pipe(vdop64);
16688 %}
16689 
16690 instruct vadd16B(vecX dst, vecX src1, vecX src2)
16691 %{
16692   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16693   match(Set dst (AddVB src1 src2));
16694   ins_cost(INSN_COST);
16695   format %{ &quot;addv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16696   ins_encode %{
16697     __ addv(as_FloatRegister($dst$$reg), __ T16B,
16698             as_FloatRegister($src1$$reg),
16699             as_FloatRegister($src2$$reg));
16700   %}
16701   ins_pipe(vdop128);
16702 %}
16703 
16704 instruct vadd4S(vecD dst, vecD src1, vecD src2)
16705 %{
16706   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16707             n-&gt;as_Vector()-&gt;length() == 4);
16708   match(Set dst (AddVS src1 src2));
16709   ins_cost(INSN_COST);
16710   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16711   ins_encode %{
16712     __ addv(as_FloatRegister($dst$$reg), __ T4H,
16713             as_FloatRegister($src1$$reg),
16714             as_FloatRegister($src2$$reg));
16715   %}
16716   ins_pipe(vdop64);
16717 %}
16718 
16719 instruct vadd8S(vecX dst, vecX src1, vecX src2)
16720 %{
16721   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16722   match(Set dst (AddVS src1 src2));
16723   ins_cost(INSN_COST);
16724   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16725   ins_encode %{
16726     __ addv(as_FloatRegister($dst$$reg), __ T8H,
16727             as_FloatRegister($src1$$reg),
16728             as_FloatRegister($src2$$reg));
16729   %}
16730   ins_pipe(vdop128);
16731 %}
16732 
16733 instruct vadd2I(vecD dst, vecD src1, vecD src2)
16734 %{
16735   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16736   match(Set dst (AddVI src1 src2));
16737   ins_cost(INSN_COST);
16738   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16739   ins_encode %{
16740     __ addv(as_FloatRegister($dst$$reg), __ T2S,
16741             as_FloatRegister($src1$$reg),
16742             as_FloatRegister($src2$$reg));
16743   %}
16744   ins_pipe(vdop64);
16745 %}
16746 
16747 instruct vadd4I(vecX dst, vecX src1, vecX src2)
16748 %{
16749   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16750   match(Set dst (AddVI src1 src2));
16751   ins_cost(INSN_COST);
16752   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16753   ins_encode %{
16754     __ addv(as_FloatRegister($dst$$reg), __ T4S,
16755             as_FloatRegister($src1$$reg),
16756             as_FloatRegister($src2$$reg));
16757   %}
16758   ins_pipe(vdop128);
16759 %}
16760 
16761 instruct vadd2L(vecX dst, vecX src1, vecX src2)
16762 %{
16763   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16764   match(Set dst (AddVL src1 src2));
16765   ins_cost(INSN_COST);
16766   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16767   ins_encode %{
16768     __ addv(as_FloatRegister($dst$$reg), __ T2D,
16769             as_FloatRegister($src1$$reg),
16770             as_FloatRegister($src2$$reg));
16771   %}
16772   ins_pipe(vdop128);
16773 %}
16774 
16775 instruct vadd2F(vecD dst, vecD src1, vecD src2)
16776 %{
16777   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16778   match(Set dst (AddVF src1 src2));
16779   ins_cost(INSN_COST);
16780   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2S)&quot; %}
16781   ins_encode %{
16782     __ fadd(as_FloatRegister($dst$$reg), __ T2S,
16783             as_FloatRegister($src1$$reg),
16784             as_FloatRegister($src2$$reg));
16785   %}
16786   ins_pipe(vdop_fp64);
16787 %}
16788 
16789 instruct vadd4F(vecX dst, vecX src1, vecX src2)
16790 %{
16791   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16792   match(Set dst (AddVF src1 src2));
16793   ins_cost(INSN_COST);
16794   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (4S)&quot; %}
16795   ins_encode %{
16796     __ fadd(as_FloatRegister($dst$$reg), __ T4S,
16797             as_FloatRegister($src1$$reg),
16798             as_FloatRegister($src2$$reg));
16799   %}
16800   ins_pipe(vdop_fp128);
16801 %}
16802 
16803 instruct vadd2D(vecX dst, vecX src1, vecX src2)
16804 %{
16805   match(Set dst (AddVD src1 src2));
16806   ins_cost(INSN_COST);
16807   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2D)&quot; %}
16808   ins_encode %{
16809     __ fadd(as_FloatRegister($dst$$reg), __ T2D,
16810             as_FloatRegister($src1$$reg),
16811             as_FloatRegister($src2$$reg));
16812   %}
16813   ins_pipe(vdop_fp128);
16814 %}
16815 
16816 // --------------------------------- SUB --------------------------------------
16817 
16818 instruct vsub8B(vecD dst, vecD src1, vecD src2)
16819 %{
16820   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16821             n-&gt;as_Vector()-&gt;length() == 8);
16822   match(Set dst (SubVB src1 src2));
16823   ins_cost(INSN_COST);
16824   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16825   ins_encode %{
16826     __ subv(as_FloatRegister($dst$$reg), __ T8B,
16827             as_FloatRegister($src1$$reg),
16828             as_FloatRegister($src2$$reg));
16829   %}
16830   ins_pipe(vdop64);
16831 %}
16832 
16833 instruct vsub16B(vecX dst, vecX src1, vecX src2)
16834 %{
16835   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16836   match(Set dst (SubVB src1 src2));
16837   ins_cost(INSN_COST);
16838   format %{ &quot;subv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16839   ins_encode %{
16840     __ subv(as_FloatRegister($dst$$reg), __ T16B,
16841             as_FloatRegister($src1$$reg),
16842             as_FloatRegister($src2$$reg));
16843   %}
16844   ins_pipe(vdop128);
16845 %}
16846 
16847 instruct vsub4S(vecD dst, vecD src1, vecD src2)
16848 %{
16849   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16850             n-&gt;as_Vector()-&gt;length() == 4);
16851   match(Set dst (SubVS src1 src2));
16852   ins_cost(INSN_COST);
16853   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16854   ins_encode %{
16855     __ subv(as_FloatRegister($dst$$reg), __ T4H,
16856             as_FloatRegister($src1$$reg),
16857             as_FloatRegister($src2$$reg));
16858   %}
16859   ins_pipe(vdop64);
16860 %}
16861 
16862 instruct vsub8S(vecX dst, vecX src1, vecX src2)
16863 %{
16864   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16865   match(Set dst (SubVS src1 src2));
16866   ins_cost(INSN_COST);
16867   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16868   ins_encode %{
16869     __ subv(as_FloatRegister($dst$$reg), __ T8H,
16870             as_FloatRegister($src1$$reg),
16871             as_FloatRegister($src2$$reg));
16872   %}
16873   ins_pipe(vdop128);
16874 %}
16875 
16876 instruct vsub2I(vecD dst, vecD src1, vecD src2)
16877 %{
16878   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16879   match(Set dst (SubVI src1 src2));
16880   ins_cost(INSN_COST);
16881   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16882   ins_encode %{
16883     __ subv(as_FloatRegister($dst$$reg), __ T2S,
16884             as_FloatRegister($src1$$reg),
16885             as_FloatRegister($src2$$reg));
16886   %}
16887   ins_pipe(vdop64);
16888 %}
16889 
16890 instruct vsub4I(vecX dst, vecX src1, vecX src2)
16891 %{
16892   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16893   match(Set dst (SubVI src1 src2));
16894   ins_cost(INSN_COST);
16895   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16896   ins_encode %{
16897     __ subv(as_FloatRegister($dst$$reg), __ T4S,
16898             as_FloatRegister($src1$$reg),
16899             as_FloatRegister($src2$$reg));
16900   %}
16901   ins_pipe(vdop128);
16902 %}
16903 
16904 instruct vsub2L(vecX dst, vecX src1, vecX src2)
16905 %{
16906   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16907   match(Set dst (SubVL src1 src2));
16908   ins_cost(INSN_COST);
16909   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16910   ins_encode %{
16911     __ subv(as_FloatRegister($dst$$reg), __ T2D,
16912             as_FloatRegister($src1$$reg),
16913             as_FloatRegister($src2$$reg));
16914   %}
16915   ins_pipe(vdop128);
16916 %}
16917 
16918 instruct vsub2F(vecD dst, vecD src1, vecD src2)
16919 %{
16920   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16921   match(Set dst (SubVF src1 src2));
16922   ins_cost(INSN_COST);
16923   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2S)&quot; %}
16924   ins_encode %{
16925     __ fsub(as_FloatRegister($dst$$reg), __ T2S,
16926             as_FloatRegister($src1$$reg),
16927             as_FloatRegister($src2$$reg));
16928   %}
16929   ins_pipe(vdop_fp64);
16930 %}
16931 
16932 instruct vsub4F(vecX dst, vecX src1, vecX src2)
16933 %{
16934   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16935   match(Set dst (SubVF src1 src2));
16936   ins_cost(INSN_COST);
16937   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (4S)&quot; %}
16938   ins_encode %{
16939     __ fsub(as_FloatRegister($dst$$reg), __ T4S,
16940             as_FloatRegister($src1$$reg),
16941             as_FloatRegister($src2$$reg));
16942   %}
16943   ins_pipe(vdop_fp128);
16944 %}
16945 
16946 instruct vsub2D(vecX dst, vecX src1, vecX src2)
16947 %{
16948   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16949   match(Set dst (SubVD src1 src2));
16950   ins_cost(INSN_COST);
16951   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2D)&quot; %}
16952   ins_encode %{
16953     __ fsub(as_FloatRegister($dst$$reg), __ T2D,
16954             as_FloatRegister($src1$$reg),
16955             as_FloatRegister($src2$$reg));
16956   %}
16957   ins_pipe(vdop_fp128);
16958 %}
16959 
16960 // --------------------------------- MUL --------------------------------------
16961 
16962 instruct vmul8B(vecD dst, vecD src1, vecD src2)
16963 %{
16964   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16965             n-&gt;as_Vector()-&gt;length() == 8);
16966   match(Set dst (MulVB src1 src2));
16967   ins_cost(INSN_COST);
16968   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16969   ins_encode %{
16970     __ mulv(as_FloatRegister($dst$$reg), __ T8B,
16971             as_FloatRegister($src1$$reg),
16972             as_FloatRegister($src2$$reg));
16973   %}
16974   ins_pipe(vmul64);
16975 %}
16976 
16977 instruct vmul16B(vecX dst, vecX src1, vecX src2)
16978 %{
16979   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16980   match(Set dst (MulVB src1 src2));
16981   ins_cost(INSN_COST);
16982   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16983   ins_encode %{
16984     __ mulv(as_FloatRegister($dst$$reg), __ T16B,
16985             as_FloatRegister($src1$$reg),
16986             as_FloatRegister($src2$$reg));
16987   %}
16988   ins_pipe(vmul128);
16989 %}
16990 
16991 instruct vmul4S(vecD dst, vecD src1, vecD src2)
16992 %{
16993   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16994             n-&gt;as_Vector()-&gt;length() == 4);
16995   match(Set dst (MulVS src1 src2));
16996   ins_cost(INSN_COST);
16997   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16998   ins_encode %{
16999     __ mulv(as_FloatRegister($dst$$reg), __ T4H,
17000             as_FloatRegister($src1$$reg),
17001             as_FloatRegister($src2$$reg));
17002   %}
17003   ins_pipe(vmul64);
17004 %}
17005 
17006 instruct vmul8S(vecX dst, vecX src1, vecX src2)
17007 %{
17008   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17009   match(Set dst (MulVS src1 src2));
17010   ins_cost(INSN_COST);
17011   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8H)&quot; %}
17012   ins_encode %{
17013     __ mulv(as_FloatRegister($dst$$reg), __ T8H,
17014             as_FloatRegister($src1$$reg),
17015             as_FloatRegister($src2$$reg));
17016   %}
17017   ins_pipe(vmul128);
17018 %}
17019 
17020 instruct vmul2I(vecD dst, vecD src1, vecD src2)
17021 %{
17022   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17023   match(Set dst (MulVI src1 src2));
17024   ins_cost(INSN_COST);
17025   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (2S)&quot; %}
17026   ins_encode %{
17027     __ mulv(as_FloatRegister($dst$$reg), __ T2S,
17028             as_FloatRegister($src1$$reg),
17029             as_FloatRegister($src2$$reg));
17030   %}
17031   ins_pipe(vmul64);
17032 %}
17033 
17034 instruct vmul4I(vecX dst, vecX src1, vecX src2)
17035 %{
17036   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17037   match(Set dst (MulVI src1 src2));
17038   ins_cost(INSN_COST);
17039   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4S)&quot; %}
17040   ins_encode %{
17041     __ mulv(as_FloatRegister($dst$$reg), __ T4S,
17042             as_FloatRegister($src1$$reg),
17043             as_FloatRegister($src2$$reg));
17044   %}
17045   ins_pipe(vmul128);
17046 %}
17047 
17048 instruct vmul2F(vecD dst, vecD src1, vecD src2)
17049 %{
17050   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17051   match(Set dst (MulVF src1 src2));
17052   ins_cost(INSN_COST);
17053   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2S)&quot; %}
17054   ins_encode %{
17055     __ fmul(as_FloatRegister($dst$$reg), __ T2S,
17056             as_FloatRegister($src1$$reg),
17057             as_FloatRegister($src2$$reg));
17058   %}
17059   ins_pipe(vmuldiv_fp64);
17060 %}
17061 
17062 instruct vmul4F(vecX dst, vecX src1, vecX src2)
17063 %{
17064   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17065   match(Set dst (MulVF src1 src2));
17066   ins_cost(INSN_COST);
17067   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (4S)&quot; %}
17068   ins_encode %{
17069     __ fmul(as_FloatRegister($dst$$reg), __ T4S,
17070             as_FloatRegister($src1$$reg),
17071             as_FloatRegister($src2$$reg));
17072   %}
17073   ins_pipe(vmuldiv_fp128);
17074 %}
17075 
17076 instruct vmul2D(vecX dst, vecX src1, vecX src2)
17077 %{
17078   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17079   match(Set dst (MulVD src1 src2));
17080   ins_cost(INSN_COST);
17081   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2D)&quot; %}
17082   ins_encode %{
17083     __ fmul(as_FloatRegister($dst$$reg), __ T2D,
17084             as_FloatRegister($src1$$reg),
17085             as_FloatRegister($src2$$reg));
17086   %}
17087   ins_pipe(vmuldiv_fp128);
17088 %}
17089 
17090 // --------------------------------- MLA --------------------------------------
17091 
17092 instruct vmla4S(vecD dst, vecD src1, vecD src2)
17093 %{
17094   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17095             n-&gt;as_Vector()-&gt;length() == 4);
17096   match(Set dst (AddVS dst (MulVS src1 src2)));
17097   ins_cost(INSN_COST);
17098   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4H)&quot; %}
17099   ins_encode %{
17100     __ mlav(as_FloatRegister($dst$$reg), __ T4H,
17101             as_FloatRegister($src1$$reg),
17102             as_FloatRegister($src2$$reg));
17103   %}
17104   ins_pipe(vmla64);
17105 %}
17106 
17107 instruct vmla8S(vecX dst, vecX src1, vecX src2)
17108 %{
17109   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17110   match(Set dst (AddVS dst (MulVS src1 src2)));
17111   ins_cost(INSN_COST);
17112   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (8H)&quot; %}
17113   ins_encode %{
17114     __ mlav(as_FloatRegister($dst$$reg), __ T8H,
17115             as_FloatRegister($src1$$reg),
17116             as_FloatRegister($src2$$reg));
17117   %}
17118   ins_pipe(vmla128);
17119 %}
17120 
17121 instruct vmla2I(vecD dst, vecD src1, vecD src2)
17122 %{
17123   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17124   match(Set dst (AddVI dst (MulVI src1 src2)));
17125   ins_cost(INSN_COST);
17126   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (2S)&quot; %}
17127   ins_encode %{
17128     __ mlav(as_FloatRegister($dst$$reg), __ T2S,
17129             as_FloatRegister($src1$$reg),
17130             as_FloatRegister($src2$$reg));
17131   %}
17132   ins_pipe(vmla64);
17133 %}
17134 
17135 instruct vmla4I(vecX dst, vecX src1, vecX src2)
17136 %{
17137   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17138   match(Set dst (AddVI dst (MulVI src1 src2)));
17139   ins_cost(INSN_COST);
17140   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4S)&quot; %}
17141   ins_encode %{
17142     __ mlav(as_FloatRegister($dst$$reg), __ T4S,
17143             as_FloatRegister($src1$$reg),
17144             as_FloatRegister($src2$$reg));
17145   %}
17146   ins_pipe(vmla128);
17147 %}
17148 
17149 // dst + src1 * src2
17150 instruct vmla2F(vecD dst, vecD src1, vecD src2) %{
17151   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
17152   match(Set dst (FmaVF  dst (Binary src1 src2)));
17153   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2S)&quot; %}
17154   ins_cost(INSN_COST);
17155   ins_encode %{
17156     __ fmla(as_FloatRegister($dst$$reg), __ T2S,
17157             as_FloatRegister($src1$$reg),
17158             as_FloatRegister($src2$$reg));
17159   %}
17160   ins_pipe(vmuldiv_fp64);
17161 %}
17162 
17163 // dst + src1 * src2
17164 instruct vmla4F(vecX dst, vecX src1, vecX src2) %{
17165   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
17166   match(Set dst (FmaVF  dst (Binary src1 src2)));
17167   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (4S)&quot; %}
17168   ins_cost(INSN_COST);
17169   ins_encode %{
17170     __ fmla(as_FloatRegister($dst$$reg), __ T4S,
17171             as_FloatRegister($src1$$reg),
17172             as_FloatRegister($src2$$reg));
17173   %}
17174   ins_pipe(vmuldiv_fp128);
17175 %}
17176 
17177 // dst + src1 * src2
17178 instruct vmla2D(vecX dst, vecX src1, vecX src2) %{
17179   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
17180   match(Set dst (FmaVD  dst (Binary src1 src2)));
17181   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2D)&quot; %}
17182   ins_cost(INSN_COST);
17183   ins_encode %{
17184     __ fmla(as_FloatRegister($dst$$reg), __ T2D,
17185             as_FloatRegister($src1$$reg),
17186             as_FloatRegister($src2$$reg));
17187   %}
17188   ins_pipe(vmuldiv_fp128);
17189 %}
17190 
17191 // --------------------------------- MLS --------------------------------------
17192 
17193 instruct vmls4S(vecD dst, vecD src1, vecD src2)
17194 %{
17195   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17196             n-&gt;as_Vector()-&gt;length() == 4);
17197   match(Set dst (SubVS dst (MulVS src1 src2)));
17198   ins_cost(INSN_COST);
17199   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4H)&quot; %}
17200   ins_encode %{
17201     __ mlsv(as_FloatRegister($dst$$reg), __ T4H,
17202             as_FloatRegister($src1$$reg),
17203             as_FloatRegister($src2$$reg));
17204   %}
17205   ins_pipe(vmla64);
17206 %}
17207 
17208 instruct vmls8S(vecX dst, vecX src1, vecX src2)
17209 %{
17210   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17211   match(Set dst (SubVS dst (MulVS src1 src2)));
17212   ins_cost(INSN_COST);
17213   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (8H)&quot; %}
17214   ins_encode %{
17215     __ mlsv(as_FloatRegister($dst$$reg), __ T8H,
17216             as_FloatRegister($src1$$reg),
17217             as_FloatRegister($src2$$reg));
17218   %}
17219   ins_pipe(vmla128);
17220 %}
17221 
17222 instruct vmls2I(vecD dst, vecD src1, vecD src2)
17223 %{
17224   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17225   match(Set dst (SubVI dst (MulVI src1 src2)));
17226   ins_cost(INSN_COST);
17227   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (2S)&quot; %}
17228   ins_encode %{
17229     __ mlsv(as_FloatRegister($dst$$reg), __ T2S,
17230             as_FloatRegister($src1$$reg),
17231             as_FloatRegister($src2$$reg));
17232   %}
17233   ins_pipe(vmla64);
17234 %}
17235 
17236 instruct vmls4I(vecX dst, vecX src1, vecX src2)
17237 %{
17238   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17239   match(Set dst (SubVI dst (MulVI src1 src2)));
17240   ins_cost(INSN_COST);
17241   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4S)&quot; %}
17242   ins_encode %{
17243     __ mlsv(as_FloatRegister($dst$$reg), __ T4S,
17244             as_FloatRegister($src1$$reg),
17245             as_FloatRegister($src2$$reg));
17246   %}
17247   ins_pipe(vmla128);
17248 %}
17249 
17250 // dst - src1 * src2
17251 instruct vmls2F(vecD dst, vecD src1, vecD src2) %{
17252   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
17253   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
17254   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
17255   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2S)&quot; %}
17256   ins_cost(INSN_COST);
17257   ins_encode %{
17258     __ fmls(as_FloatRegister($dst$$reg), __ T2S,
17259             as_FloatRegister($src1$$reg),
17260             as_FloatRegister($src2$$reg));
17261   %}
17262   ins_pipe(vmuldiv_fp64);
17263 %}
17264 
17265 // dst - src1 * src2
17266 instruct vmls4F(vecX dst, vecX src1, vecX src2) %{
17267   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
17268   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
17269   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
17270   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (4S)&quot; %}
17271   ins_cost(INSN_COST);
17272   ins_encode %{
17273     __ fmls(as_FloatRegister($dst$$reg), __ T4S,
17274             as_FloatRegister($src1$$reg),
17275             as_FloatRegister($src2$$reg));
17276   %}
17277   ins_pipe(vmuldiv_fp128);
17278 %}
17279 
17280 // dst - src1 * src2
17281 instruct vmls2D(vecX dst, vecX src1, vecX src2) %{
17282   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
17283   match(Set dst (FmaVD  dst (Binary (NegVD src1) src2)));
17284   match(Set dst (FmaVD  dst (Binary src1 (NegVD src2))));
17285   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2D)&quot; %}
17286   ins_cost(INSN_COST);
17287   ins_encode %{
17288     __ fmls(as_FloatRegister($dst$$reg), __ T2D,
17289             as_FloatRegister($src1$$reg),
17290             as_FloatRegister($src2$$reg));
17291   %}
17292   ins_pipe(vmuldiv_fp128);
17293 %}
17294 
17295 // --------------- Vector Multiply-Add Shorts into Integer --------------------
17296 
17297 instruct vmuladdS2I(vecX dst, vecX src1, vecX src2, vecX tmp) %{
17298   predicate(n-&gt;in(1)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_SHORT);
17299   match(Set dst (MulAddVS2VI src1 src2));
17300   ins_cost(INSN_COST);
17301   effect(TEMP_DEF dst, TEMP tmp);
17302   format %{ &quot;smullv  $tmp, $src1, $src2\t# vector (4H)\n\t&quot;
17303             &quot;smullv  $dst, $src1, $src2\t# vector (8H)\n\t&quot;
17304             &quot;addpv   $dst, $tmp, $dst\t# vector (4S)\n\t&quot; %}
17305   ins_encode %{
17306     __ smullv(as_FloatRegister($tmp$$reg), __ T4H,
17307               as_FloatRegister($src1$$reg),
17308               as_FloatRegister($src2$$reg));
17309     __ smullv(as_FloatRegister($dst$$reg), __ T8H,
17310               as_FloatRegister($src1$$reg),
17311               as_FloatRegister($src2$$reg));
17312     __ addpv(as_FloatRegister($dst$$reg), __ T4S,
17313              as_FloatRegister($tmp$$reg),
17314              as_FloatRegister($dst$$reg));
17315   %}
17316   ins_pipe(vmuldiv_fp128);
17317 %}
17318 
17319 // --------------------------------- DIV --------------------------------------
17320 
17321 instruct vdiv2F(vecD dst, vecD src1, vecD src2)
17322 %{
17323   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17324   match(Set dst (DivVF src1 src2));
17325   ins_cost(INSN_COST);
17326   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2S)&quot; %}
17327   ins_encode %{
17328     __ fdiv(as_FloatRegister($dst$$reg), __ T2S,
17329             as_FloatRegister($src1$$reg),
17330             as_FloatRegister($src2$$reg));
17331   %}
17332   ins_pipe(vmuldiv_fp64);
17333 %}
17334 
17335 instruct vdiv4F(vecX dst, vecX src1, vecX src2)
17336 %{
17337   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17338   match(Set dst (DivVF src1 src2));
17339   ins_cost(INSN_COST);
17340   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (4S)&quot; %}
17341   ins_encode %{
17342     __ fdiv(as_FloatRegister($dst$$reg), __ T4S,
17343             as_FloatRegister($src1$$reg),
17344             as_FloatRegister($src2$$reg));
17345   %}
17346   ins_pipe(vmuldiv_fp128);
17347 %}
17348 
17349 instruct vdiv2D(vecX dst, vecX src1, vecX src2)
17350 %{
17351   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17352   match(Set dst (DivVD src1 src2));
17353   ins_cost(INSN_COST);
17354   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2D)&quot; %}
17355   ins_encode %{
17356     __ fdiv(as_FloatRegister($dst$$reg), __ T2D,
17357             as_FloatRegister($src1$$reg),
17358             as_FloatRegister($src2$$reg));
17359   %}
17360   ins_pipe(vmuldiv_fp128);
17361 %}
17362 
17363 // --------------------------------- SQRT -------------------------------------
17364 
17365 instruct vsqrt2F(vecD dst, vecD src)
17366 %{
17367   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17368   match(Set dst (SqrtVF src));
17369   format %{ &quot;fsqrt  $dst, $src\t# vector (2F)&quot; %}
17370   ins_encode %{
17371     __ fsqrt(as_FloatRegister($dst$$reg), __ T2S, as_FloatRegister($src$$reg));
17372   %}
17373   ins_pipe(vunop_fp64);
17374 %}
17375 
17376 instruct vsqrt4F(vecX dst, vecX src)
17377 %{
17378   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17379   match(Set dst (SqrtVF src));
17380   format %{ &quot;fsqrt  $dst, $src\t# vector (4F)&quot; %}
17381   ins_encode %{
17382     __ fsqrt(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src$$reg));
17383   %}
17384   ins_pipe(vsqrt_fp128);
17385 %}
17386 
17387 instruct vsqrt2D(vecX dst, vecX src)
17388 %{
17389   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17390   match(Set dst (SqrtVD src));
17391   format %{ &quot;fsqrt  $dst, $src\t# vector (2D)&quot; %}
17392   ins_encode %{
17393     __ fsqrt(as_FloatRegister($dst$$reg), __ T2D,
17394              as_FloatRegister($src$$reg));
17395   %}
17396   ins_pipe(vsqrt_fp128);
17397 %}
17398 
17399 // --------------------------------- ABS --------------------------------------
17400 
17401 instruct vabs8B(vecD dst, vecD src)
17402 %{
17403   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17404             n-&gt;as_Vector()-&gt;length() == 8);
17405   match(Set dst (AbsVB src));
17406   ins_cost(INSN_COST);
17407   format %{ &quot;abs  $dst, $src\t# vector (8B)&quot; %}
17408   ins_encode %{
17409     __ absr(as_FloatRegister($dst$$reg), __ T8B, as_FloatRegister($src$$reg));
17410   %}
17411   ins_pipe(vlogical64);
17412 %}
17413 
17414 instruct vabs16B(vecX dst, vecX src)
17415 %{
17416   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17417   match(Set dst (AbsVB src));
17418   ins_cost(INSN_COST);
17419   format %{ &quot;abs  $dst, $src\t# vector (16B)&quot; %}
17420   ins_encode %{
17421     __ absr(as_FloatRegister($dst$$reg), __ T16B, as_FloatRegister($src$$reg));
17422   %}
17423   ins_pipe(vlogical128);
17424 %}
17425 
17426 instruct vabs4S(vecD dst, vecD src)
17427 %{
17428   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17429   match(Set dst (AbsVS src));
17430   ins_cost(INSN_COST);
17431   format %{ &quot;abs  $dst, $src\t# vector (4H)&quot; %}
17432   ins_encode %{
17433     __ absr(as_FloatRegister($dst$$reg), __ T4H, as_FloatRegister($src$$reg));
17434   %}
17435   ins_pipe(vlogical64);
17436 %}
17437 
17438 instruct vabs8S(vecX dst, vecX src)
17439 %{
17440   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17441   match(Set dst (AbsVS src));
17442   ins_cost(INSN_COST);
17443   format %{ &quot;abs  $dst, $src\t# vector (8H)&quot; %}
17444   ins_encode %{
17445     __ absr(as_FloatRegister($dst$$reg), __ T8H, as_FloatRegister($src$$reg));
17446   %}
17447   ins_pipe(vlogical128);
17448 %}
17449 
17450 instruct vabs2I(vecD dst, vecD src)
17451 %{
17452   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17453   match(Set dst (AbsVI src));
17454   ins_cost(INSN_COST);
17455   format %{ &quot;abs  $dst, $src\t# vector (2S)&quot; %}
17456   ins_encode %{
17457     __ absr(as_FloatRegister($dst$$reg), __ T2S, as_FloatRegister($src$$reg));
17458   %}
17459   ins_pipe(vlogical64);
17460 %}
17461 
17462 instruct vabs4I(vecX dst, vecX src)
17463 %{
17464   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17465   match(Set dst (AbsVI src));
17466   ins_cost(INSN_COST);
17467   format %{ &quot;abs  $dst, $src\t# vector (4S)&quot; %}
17468   ins_encode %{
17469     __ absr(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src$$reg));
17470   %}
17471   ins_pipe(vlogical128);
17472 %}
17473 
17474 instruct vabs2L(vecX dst, vecX src)
17475 %{
17476   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17477   match(Set dst (AbsVL src));
17478   ins_cost(INSN_COST);
17479   format %{ &quot;abs  $dst, $src\t# vector (2D)&quot; %}
17480   ins_encode %{
17481     __ absr(as_FloatRegister($dst$$reg), __ T2D, as_FloatRegister($src$$reg));
17482   %}
17483   ins_pipe(vlogical128);
17484 %}
17485 
17486 instruct vabs2F(vecD dst, vecD src)
17487 %{
17488   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17489   match(Set dst (AbsVF src));
17490   ins_cost(INSN_COST * 3);
17491   format %{ &quot;fabs  $dst,$src\t# vector (2S)&quot; %}
17492   ins_encode %{
17493     __ fabs(as_FloatRegister($dst$$reg), __ T2S,
17494             as_FloatRegister($src$$reg));
17495   %}
17496   ins_pipe(vunop_fp64);
17497 %}
17498 
17499 instruct vabs4F(vecX dst, vecX src)
17500 %{
17501   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17502   match(Set dst (AbsVF src));
17503   ins_cost(INSN_COST * 3);
17504   format %{ &quot;fabs  $dst,$src\t# vector (4S)&quot; %}
17505   ins_encode %{
17506     __ fabs(as_FloatRegister($dst$$reg), __ T4S,
17507             as_FloatRegister($src$$reg));
17508   %}
17509   ins_pipe(vunop_fp128);
17510 %}
17511 
17512 instruct vabs2D(vecX dst, vecX src)
17513 %{
17514   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17515   match(Set dst (AbsVD src));
17516   ins_cost(INSN_COST * 3);
17517   format %{ &quot;fabs  $dst,$src\t# vector (2D)&quot; %}
17518   ins_encode %{
17519     __ fabs(as_FloatRegister($dst$$reg), __ T2D,
17520             as_FloatRegister($src$$reg));
17521   %}
17522   ins_pipe(vunop_fp128);
17523 %}
17524 
17525 // --------------------------------- NEG --------------------------------------
17526 
17527 instruct vneg2F(vecD dst, vecD src)
17528 %{
17529   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17530   match(Set dst (NegVF src));
17531   ins_cost(INSN_COST * 3);
17532   format %{ &quot;fneg  $dst,$src\t# vector (2S)&quot; %}
17533   ins_encode %{
17534     __ fneg(as_FloatRegister($dst$$reg), __ T2S,
17535             as_FloatRegister($src$$reg));
17536   %}
17537   ins_pipe(vunop_fp64);
17538 %}
17539 
17540 instruct vneg4F(vecX dst, vecX src)
17541 %{
17542   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17543   match(Set dst (NegVF src));
17544   ins_cost(INSN_COST * 3);
17545   format %{ &quot;fneg  $dst,$src\t# vector (4S)&quot; %}
17546   ins_encode %{
17547     __ fneg(as_FloatRegister($dst$$reg), __ T4S,
17548             as_FloatRegister($src$$reg));
17549   %}
17550   ins_pipe(vunop_fp128);
17551 %}
17552 
17553 instruct vneg2D(vecX dst, vecX src)
17554 %{
17555   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17556   match(Set dst (NegVD src));
17557   ins_cost(INSN_COST * 3);
17558   format %{ &quot;fneg  $dst,$src\t# vector (2D)&quot; %}
17559   ins_encode %{
17560     __ fneg(as_FloatRegister($dst$$reg), __ T2D,
17561             as_FloatRegister($src$$reg));
17562   %}
17563   ins_pipe(vunop_fp128);
17564 %}
17565 
17566 // --------------------------------- AND --------------------------------------
17567 
17568 instruct vand8B(vecD dst, vecD src1, vecD src2)
17569 %{
17570   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17571             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17572   match(Set dst (AndV src1 src2));
17573   ins_cost(INSN_COST);
17574   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17575   ins_encode %{
17576     __ andr(as_FloatRegister($dst$$reg), __ T8B,
17577             as_FloatRegister($src1$$reg),
17578             as_FloatRegister($src2$$reg));
17579   %}
17580   ins_pipe(vlogical64);
17581 %}
17582 
17583 instruct vand16B(vecX dst, vecX src1, vecX src2)
17584 %{
17585   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17586   match(Set dst (AndV src1 src2));
17587   ins_cost(INSN_COST);
17588   format %{ &quot;and  $dst,$src1,$src2\t# vector (16B)&quot; %}
17589   ins_encode %{
17590     __ andr(as_FloatRegister($dst$$reg), __ T16B,
17591             as_FloatRegister($src1$$reg),
17592             as_FloatRegister($src2$$reg));
17593   %}
17594   ins_pipe(vlogical128);
17595 %}
17596 
17597 // --------------------------------- OR ---------------------------------------
17598 
17599 instruct vor8B(vecD dst, vecD src1, vecD src2)
17600 %{
17601   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17602             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17603   match(Set dst (OrV src1 src2));
17604   ins_cost(INSN_COST);
17605   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17606   ins_encode %{
17607     __ orr(as_FloatRegister($dst$$reg), __ T8B,
17608             as_FloatRegister($src1$$reg),
17609             as_FloatRegister($src2$$reg));
17610   %}
17611   ins_pipe(vlogical64);
17612 %}
17613 
17614 instruct vor16B(vecX dst, vecX src1, vecX src2)
17615 %{
17616   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17617   match(Set dst (OrV src1 src2));
17618   ins_cost(INSN_COST);
17619   format %{ &quot;orr  $dst,$src1,$src2\t# vector (16B)&quot; %}
17620   ins_encode %{
17621     __ orr(as_FloatRegister($dst$$reg), __ T16B,
17622             as_FloatRegister($src1$$reg),
17623             as_FloatRegister($src2$$reg));
17624   %}
17625   ins_pipe(vlogical128);
17626 %}
17627 
17628 // --------------------------------- XOR --------------------------------------
17629 
17630 instruct vxor8B(vecD dst, vecD src1, vecD src2)
17631 %{
17632   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17633             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17634   match(Set dst (XorV src1 src2));
17635   ins_cost(INSN_COST);
17636   format %{ &quot;xor  $dst,$src1,$src2\t# vector (8B)&quot; %}
17637   ins_encode %{
17638     __ eor(as_FloatRegister($dst$$reg), __ T8B,
17639             as_FloatRegister($src1$$reg),
17640             as_FloatRegister($src2$$reg));
17641   %}
17642   ins_pipe(vlogical64);
17643 %}
17644 
17645 instruct vxor16B(vecX dst, vecX src1, vecX src2)
17646 %{
17647   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17648   match(Set dst (XorV src1 src2));
17649   ins_cost(INSN_COST);
17650   format %{ &quot;xor  $dst,$src1,$src2\t# vector (16B)&quot; %}
17651   ins_encode %{
17652     __ eor(as_FloatRegister($dst$$reg), __ T16B,
17653             as_FloatRegister($src1$$reg),
17654             as_FloatRegister($src2$$reg));
17655   %}
17656   ins_pipe(vlogical128);
17657 %}
17658 
17659 // ------------------------------ Shift ---------------------------------------
17660 instruct vshiftcnt8B(vecD dst, iRegIorL2I cnt) %{
17661   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17662   match(Set dst (LShiftCntV cnt));
17663   match(Set dst (RShiftCntV cnt));
17664   format %{ &quot;dup  $dst, $cnt\t# shift count vector (8B)&quot; %}
17665   ins_encode %{
17666     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($cnt$$reg));
17667   %}
17668   ins_pipe(vdup_reg_reg64);
17669 %}
17670 
17671 instruct vshiftcnt16B(vecX dst, iRegIorL2I cnt) %{
17672   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17673   match(Set dst (LShiftCntV cnt));
17674   match(Set dst (RShiftCntV cnt));
17675   format %{ &quot;dup  $dst, $cnt\t# shift count vector (16B)&quot; %}
17676   ins_encode %{
17677     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($cnt$$reg));
17678   %}
17679   ins_pipe(vdup_reg_reg128);
17680 %}
17681 
17682 instruct vsll8B(vecD dst, vecD src, vecD shift) %{
17683   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17684             n-&gt;as_Vector()-&gt;length() == 8);
17685   match(Set dst (LShiftVB src shift));
17686   ins_cost(INSN_COST);
17687   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8B)&quot; %}
17688   ins_encode %{
17689     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17690             as_FloatRegister($src$$reg),
17691             as_FloatRegister($shift$$reg));
17692   %}
17693   ins_pipe(vshift64);
17694 %}
17695 
17696 instruct vsll16B(vecX dst, vecX src, vecX shift) %{
17697   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17698   match(Set dst (LShiftVB src shift));
17699   ins_cost(INSN_COST);
17700   format %{ &quot;sshl  $dst,$src,$shift\t# vector (16B)&quot; %}
17701   ins_encode %{
17702     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17703             as_FloatRegister($src$$reg),
17704             as_FloatRegister($shift$$reg));
17705   %}
17706   ins_pipe(vshift128);
17707 %}
17708 
17709 // Right shifts with vector shift count on aarch64 SIMD are implemented
17710 // as left shift by negative shift count.
17711 // There are two cases for vector shift count.
17712 //
17713 // Case 1: The vector shift count is from replication.
17714 //        |            |
17715 //    LoadVector  RShiftCntV
17716 //        |       /
17717 //     RShiftVI
17718 // Note: In inner loop, multiple neg instructions are used, which can be
17719 // moved to outer loop and merge into one neg instruction.
17720 //
17721 // Case 2: The vector shift count is from loading.
17722 // This case isn&#39;t supported by middle-end now. But it&#39;s supported by
17723 // panama/vectorIntrinsics(JEP 338: Vector API).
17724 //        |            |
17725 //    LoadVector  LoadVector
17726 //        |       /
17727 //     RShiftVI
17728 //
17729 
17730 instruct vsra8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17731   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17732             n-&gt;as_Vector()-&gt;length() == 8);
17733   match(Set dst (RShiftVB src shift));
17734   ins_cost(INSN_COST);
17735   effect(TEMP tmp);
17736   format %{ &quot;negr  $tmp,$shift\t&quot;
17737             &quot;sshl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17738   ins_encode %{
17739     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17740             as_FloatRegister($shift$$reg));
17741     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17742             as_FloatRegister($src$$reg),
17743             as_FloatRegister($tmp$$reg));
17744   %}
17745   ins_pipe(vshift64);
17746 %}
17747 
17748 instruct vsra16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17749   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17750   match(Set dst (RShiftVB src shift));
17751   ins_cost(INSN_COST);
17752   effect(TEMP tmp);
17753   format %{ &quot;negr  $tmp,$shift\t&quot;
17754             &quot;sshl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17755   ins_encode %{
17756     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17757             as_FloatRegister($shift$$reg));
17758     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17759             as_FloatRegister($src$$reg),
17760             as_FloatRegister($tmp$$reg));
17761   %}
17762   ins_pipe(vshift128);
17763 %}
17764 
17765 instruct vsrl8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17766   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17767             n-&gt;as_Vector()-&gt;length() == 8);
17768   match(Set dst (URShiftVB src shift));
17769   ins_cost(INSN_COST);
17770   effect(TEMP tmp);
17771   format %{ &quot;negr  $tmp,$shift\t&quot;
17772             &quot;ushl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17773   ins_encode %{
17774     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17775             as_FloatRegister($shift$$reg));
17776     __ ushl(as_FloatRegister($dst$$reg), __ T8B,
17777             as_FloatRegister($src$$reg),
17778             as_FloatRegister($tmp$$reg));
17779   %}
17780   ins_pipe(vshift64);
17781 %}
17782 
17783 instruct vsrl16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17784   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17785   match(Set dst (URShiftVB src shift));
17786   ins_cost(INSN_COST);
17787   effect(TEMP tmp);
17788   format %{ &quot;negr  $tmp,$shift\t&quot;
17789             &quot;ushl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17790   ins_encode %{
17791     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17792             as_FloatRegister($shift$$reg));
17793     __ ushl(as_FloatRegister($dst$$reg), __ T16B,
17794             as_FloatRegister($src$$reg),
17795             as_FloatRegister($tmp$$reg));
17796   %}
17797   ins_pipe(vshift128);
17798 %}
17799 
17800 instruct vsll8B_imm(vecD dst, vecD src, immI shift) %{
17801   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17802             n-&gt;as_Vector()-&gt;length() == 8);
17803   match(Set dst (LShiftVB src (LShiftCntV shift)));
17804   ins_cost(INSN_COST);
17805   format %{ &quot;shl    $dst, $src, $shift\t# vector (8B)&quot; %}
17806   ins_encode %{
17807     int sh = (int)$shift$$constant;
17808     if (sh &gt;= 8) {
17809       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17810              as_FloatRegister($src$$reg),
17811              as_FloatRegister($src$$reg));
17812     } else {
17813       __ shl(as_FloatRegister($dst$$reg), __ T8B,
17814              as_FloatRegister($src$$reg), sh);
17815     }
17816   %}
17817   ins_pipe(vshift64_imm);
17818 %}
17819 
17820 instruct vsll16B_imm(vecX dst, vecX src, immI shift) %{
17821   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17822   match(Set dst (LShiftVB src (LShiftCntV shift)));
17823   ins_cost(INSN_COST);
17824   format %{ &quot;shl    $dst, $src, $shift\t# vector (16B)&quot; %}
17825   ins_encode %{
17826     int sh = (int)$shift$$constant;
17827     if (sh &gt;= 8) {
17828       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17829              as_FloatRegister($src$$reg),
17830              as_FloatRegister($src$$reg));
17831     } else {
17832       __ shl(as_FloatRegister($dst$$reg), __ T16B,
17833              as_FloatRegister($src$$reg), sh);
17834     }
17835   %}
17836   ins_pipe(vshift128_imm);
17837 %}
17838 
17839 instruct vsra8B_imm(vecD dst, vecD src, immI shift) %{
17840   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17841             n-&gt;as_Vector()-&gt;length() == 8);
17842   match(Set dst (RShiftVB src (RShiftCntV shift)));
17843   ins_cost(INSN_COST);
17844   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8B)&quot; %}
17845   ins_encode %{
17846     int sh = (int)$shift$$constant;
17847     if (sh &gt;= 8) sh = 7;
17848     __ sshr(as_FloatRegister($dst$$reg), __ T8B,
17849            as_FloatRegister($src$$reg), sh);
17850   %}
17851   ins_pipe(vshift64_imm);
17852 %}
17853 
17854 instruct vsra16B_imm(vecX dst, vecX src, immI shift) %{
17855   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17856   match(Set dst (RShiftVB src (RShiftCntV shift)));
17857   ins_cost(INSN_COST);
17858   format %{ &quot;sshr    $dst, $src, $shift\t# vector (16B)&quot; %}
17859   ins_encode %{
17860     int sh = (int)$shift$$constant;
17861     if (sh &gt;= 8) sh = 7;
17862     __ sshr(as_FloatRegister($dst$$reg), __ T16B,
17863            as_FloatRegister($src$$reg), sh);
17864   %}
17865   ins_pipe(vshift128_imm);
17866 %}
17867 
17868 instruct vsrl8B_imm(vecD dst, vecD src, immI shift) %{
17869   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17870             n-&gt;as_Vector()-&gt;length() == 8);
17871   match(Set dst (URShiftVB src (RShiftCntV shift)));
17872   ins_cost(INSN_COST);
17873   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8B)&quot; %}
17874   ins_encode %{
17875     int sh = (int)$shift$$constant;
17876     if (sh &gt;= 8) {
17877       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17878              as_FloatRegister($src$$reg),
17879              as_FloatRegister($src$$reg));
17880     } else {
17881       __ ushr(as_FloatRegister($dst$$reg), __ T8B,
17882              as_FloatRegister($src$$reg), sh);
17883     }
17884   %}
17885   ins_pipe(vshift64_imm);
17886 %}
17887 
17888 instruct vsrl16B_imm(vecX dst, vecX src, immI shift) %{
17889   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17890   match(Set dst (URShiftVB src (RShiftCntV shift)));
17891   ins_cost(INSN_COST);
17892   format %{ &quot;ushr    $dst, $src, $shift\t# vector (16B)&quot; %}
17893   ins_encode %{
17894     int sh = (int)$shift$$constant;
17895     if (sh &gt;= 8) {
17896       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17897              as_FloatRegister($src$$reg),
17898              as_FloatRegister($src$$reg));
17899     } else {
17900       __ ushr(as_FloatRegister($dst$$reg), __ T16B,
17901              as_FloatRegister($src$$reg), sh);
17902     }
17903   %}
17904   ins_pipe(vshift128_imm);
17905 %}
17906 
17907 instruct vsll4S(vecD dst, vecD src, vecD shift) %{
17908   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17909             n-&gt;as_Vector()-&gt;length() == 4);
17910   match(Set dst (LShiftVS src shift));
17911   ins_cost(INSN_COST);
17912   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4H)&quot; %}
17913   ins_encode %{
17914     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17915             as_FloatRegister($src$$reg),
17916             as_FloatRegister($shift$$reg));
17917   %}
17918   ins_pipe(vshift64);
17919 %}
17920 
17921 instruct vsll8S(vecX dst, vecX src, vecX shift) %{
17922   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17923   match(Set dst (LShiftVS src shift));
17924   ins_cost(INSN_COST);
17925   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8H)&quot; %}
17926   ins_encode %{
17927     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17928             as_FloatRegister($src$$reg),
17929             as_FloatRegister($shift$$reg));
17930   %}
17931   ins_pipe(vshift128);
17932 %}
17933 
17934 instruct vsra4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17935   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17936             n-&gt;as_Vector()-&gt;length() == 4);
17937   match(Set dst (RShiftVS src shift));
17938   ins_cost(INSN_COST);
17939   effect(TEMP tmp);
17940   format %{ &quot;negr  $tmp,$shift\t&quot;
17941             &quot;sshl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17942   ins_encode %{
17943     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17944             as_FloatRegister($shift$$reg));
17945     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17946             as_FloatRegister($src$$reg),
17947             as_FloatRegister($tmp$$reg));
17948   %}
17949   ins_pipe(vshift64);
17950 %}
17951 
17952 instruct vsra8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17953   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17954   match(Set dst (RShiftVS src shift));
17955   ins_cost(INSN_COST);
17956   effect(TEMP tmp);
17957   format %{ &quot;negr  $tmp,$shift\t&quot;
17958             &quot;sshl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17959   ins_encode %{
17960     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17961             as_FloatRegister($shift$$reg));
17962     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17963             as_FloatRegister($src$$reg),
17964             as_FloatRegister($tmp$$reg));
17965   %}
17966   ins_pipe(vshift128);
17967 %}
17968 
17969 instruct vsrl4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17970   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17971             n-&gt;as_Vector()-&gt;length() == 4);
17972   match(Set dst (URShiftVS src shift));
17973   ins_cost(INSN_COST);
17974   effect(TEMP tmp);
17975   format %{ &quot;negr  $tmp,$shift\t&quot;
17976             &quot;ushl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17977   ins_encode %{
17978     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17979             as_FloatRegister($shift$$reg));
17980     __ ushl(as_FloatRegister($dst$$reg), __ T4H,
17981             as_FloatRegister($src$$reg),
17982             as_FloatRegister($tmp$$reg));
17983   %}
17984   ins_pipe(vshift64);
17985 %}
17986 
17987 instruct vsrl8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17988   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17989   match(Set dst (URShiftVS src shift));
17990   ins_cost(INSN_COST);
17991   effect(TEMP tmp);
17992   format %{ &quot;negr  $tmp,$shift\t&quot;
17993             &quot;ushl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17994   ins_encode %{
17995     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17996             as_FloatRegister($shift$$reg));
17997     __ ushl(as_FloatRegister($dst$$reg), __ T8H,
17998             as_FloatRegister($src$$reg),
17999             as_FloatRegister($tmp$$reg));
18000   %}
18001   ins_pipe(vshift128);
18002 %}
18003 
18004 instruct vsll4S_imm(vecD dst, vecD src, immI shift) %{
18005   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
18006             n-&gt;as_Vector()-&gt;length() == 4);
18007   match(Set dst (LShiftVS src (LShiftCntV shift)));
18008   ins_cost(INSN_COST);
18009   format %{ &quot;shl    $dst, $src, $shift\t# vector (4H)&quot; %}
18010   ins_encode %{
18011     int sh = (int)$shift$$constant;
18012     if (sh &gt;= 16) {
18013       __ eor(as_FloatRegister($dst$$reg), __ T8B,
18014              as_FloatRegister($src$$reg),
18015              as_FloatRegister($src$$reg));
18016     } else {
18017       __ shl(as_FloatRegister($dst$$reg), __ T4H,
18018              as_FloatRegister($src$$reg), sh);
18019     }
18020   %}
18021   ins_pipe(vshift64_imm);
18022 %}
18023 
18024 instruct vsll8S_imm(vecX dst, vecX src, immI shift) %{
18025   predicate(n-&gt;as_Vector()-&gt;length() == 8);
18026   match(Set dst (LShiftVS src (LShiftCntV shift)));
18027   ins_cost(INSN_COST);
18028   format %{ &quot;shl    $dst, $src, $shift\t# vector (8H)&quot; %}
18029   ins_encode %{
18030     int sh = (int)$shift$$constant;
18031     if (sh &gt;= 16) {
18032       __ eor(as_FloatRegister($dst$$reg), __ T16B,
18033              as_FloatRegister($src$$reg),
18034              as_FloatRegister($src$$reg));
18035     } else {
18036       __ shl(as_FloatRegister($dst$$reg), __ T8H,
18037              as_FloatRegister($src$$reg), sh);
18038     }
18039   %}
18040   ins_pipe(vshift128_imm);
18041 %}
18042 
18043 instruct vsra4S_imm(vecD dst, vecD src, immI shift) %{
18044   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
18045             n-&gt;as_Vector()-&gt;length() == 4);
18046   match(Set dst (RShiftVS src (RShiftCntV shift)));
18047   ins_cost(INSN_COST);
18048   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4H)&quot; %}
18049   ins_encode %{
18050     int sh = (int)$shift$$constant;
18051     if (sh &gt;= 16) sh = 15;
18052     __ sshr(as_FloatRegister($dst$$reg), __ T4H,
18053            as_FloatRegister($src$$reg), sh);
18054   %}
18055   ins_pipe(vshift64_imm);
18056 %}
18057 
18058 instruct vsra8S_imm(vecX dst, vecX src, immI shift) %{
18059   predicate(n-&gt;as_Vector()-&gt;length() == 8);
18060   match(Set dst (RShiftVS src (RShiftCntV shift)));
18061   ins_cost(INSN_COST);
18062   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8H)&quot; %}
18063   ins_encode %{
18064     int sh = (int)$shift$$constant;
18065     if (sh &gt;= 16) sh = 15;
18066     __ sshr(as_FloatRegister($dst$$reg), __ T8H,
18067            as_FloatRegister($src$$reg), sh);
18068   %}
18069   ins_pipe(vshift128_imm);
18070 %}
18071 
18072 instruct vsrl4S_imm(vecD dst, vecD src, immI shift) %{
18073   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
18074             n-&gt;as_Vector()-&gt;length() == 4);
18075   match(Set dst (URShiftVS src (RShiftCntV shift)));
18076   ins_cost(INSN_COST);
18077   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4H)&quot; %}
18078   ins_encode %{
18079     int sh = (int)$shift$$constant;
18080     if (sh &gt;= 16) {
18081       __ eor(as_FloatRegister($dst$$reg), __ T8B,
18082              as_FloatRegister($src$$reg),
18083              as_FloatRegister($src$$reg));
18084     } else {
18085       __ ushr(as_FloatRegister($dst$$reg), __ T4H,
18086              as_FloatRegister($src$$reg), sh);
18087     }
18088   %}
18089   ins_pipe(vshift64_imm);
18090 %}
18091 
18092 instruct vsrl8S_imm(vecX dst, vecX src, immI shift) %{
18093   predicate(n-&gt;as_Vector()-&gt;length() == 8);
18094   match(Set dst (URShiftVS src (RShiftCntV shift)));
18095   ins_cost(INSN_COST);
18096   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8H)&quot; %}
18097   ins_encode %{
18098     int sh = (int)$shift$$constant;
18099     if (sh &gt;= 16) {
18100       __ eor(as_FloatRegister($dst$$reg), __ T16B,
18101              as_FloatRegister($src$$reg),
18102              as_FloatRegister($src$$reg));
18103     } else {
18104       __ ushr(as_FloatRegister($dst$$reg), __ T8H,
18105              as_FloatRegister($src$$reg), sh);
18106     }
18107   %}
18108   ins_pipe(vshift128_imm);
18109 %}
18110 
18111 instruct vsll2I(vecD dst, vecD src, vecD shift) %{
18112   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18113   match(Set dst (LShiftVI src shift));
18114   ins_cost(INSN_COST);
18115   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2S)&quot; %}
18116   ins_encode %{
18117     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
18118             as_FloatRegister($src$$reg),
18119             as_FloatRegister($shift$$reg));
18120   %}
18121   ins_pipe(vshift64);
18122 %}
18123 
18124 instruct vsll4I(vecX dst, vecX src, vecX shift) %{
18125   predicate(n-&gt;as_Vector()-&gt;length() == 4);
18126   match(Set dst (LShiftVI src shift));
18127   ins_cost(INSN_COST);
18128   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4S)&quot; %}
18129   ins_encode %{
18130     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
18131             as_FloatRegister($src$$reg),
18132             as_FloatRegister($shift$$reg));
18133   %}
18134   ins_pipe(vshift128);
18135 %}
18136 
18137 instruct vsra2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
18138   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18139   match(Set dst (RShiftVI src shift));
18140   ins_cost(INSN_COST);
18141   effect(TEMP tmp);
18142   format %{ &quot;negr  $tmp,$shift\t&quot;
18143             &quot;sshl  $dst,$src,$tmp\t# vector (2S)&quot; %}
18144   ins_encode %{
18145     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
18146             as_FloatRegister($shift$$reg));
18147     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
18148             as_FloatRegister($src$$reg),
18149             as_FloatRegister($tmp$$reg));
18150   %}
18151   ins_pipe(vshift64);
18152 %}
18153 
18154 instruct vsra4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
18155   predicate(n-&gt;as_Vector()-&gt;length() == 4);
18156   match(Set dst (RShiftVI src shift));
18157   ins_cost(INSN_COST);
18158   effect(TEMP tmp);
18159   format %{ &quot;negr  $tmp,$shift\t&quot;
18160             &quot;sshl  $dst,$src,$tmp\t# vector (4S)&quot; %}
18161   ins_encode %{
18162     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
18163             as_FloatRegister($shift$$reg));
18164     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
18165             as_FloatRegister($src$$reg),
18166             as_FloatRegister($tmp$$reg));
18167   %}
18168   ins_pipe(vshift128);
18169 %}
18170 
18171 instruct vsrl2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
18172   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18173   match(Set dst (URShiftVI src shift));
18174   ins_cost(INSN_COST);
18175   effect(TEMP tmp);
18176   format %{ &quot;negr  $tmp,$shift\t&quot;
18177             &quot;ushl  $dst,$src,$tmp\t# vector (2S)&quot; %}
18178   ins_encode %{
18179     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
18180             as_FloatRegister($shift$$reg));
18181     __ ushl(as_FloatRegister($dst$$reg), __ T2S,
18182             as_FloatRegister($src$$reg),
18183             as_FloatRegister($tmp$$reg));
18184   %}
18185   ins_pipe(vshift64);
18186 %}
18187 
18188 instruct vsrl4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
18189   predicate(n-&gt;as_Vector()-&gt;length() == 4);
18190   match(Set dst (URShiftVI src shift));
18191   ins_cost(INSN_COST);
18192   effect(TEMP tmp);
18193   format %{ &quot;negr  $tmp,$shift\t&quot;
18194             &quot;ushl  $dst,$src,$tmp\t# vector (4S)&quot; %}
18195   ins_encode %{
18196     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
18197             as_FloatRegister($shift$$reg));
18198     __ ushl(as_FloatRegister($dst$$reg), __ T4S,
18199             as_FloatRegister($src$$reg),
18200             as_FloatRegister($tmp$$reg));
18201   %}
18202   ins_pipe(vshift128);
18203 %}
18204 
18205 instruct vsll2I_imm(vecD dst, vecD src, immI shift) %{
18206   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18207   match(Set dst (LShiftVI src (LShiftCntV shift)));
18208   ins_cost(INSN_COST);
18209   format %{ &quot;shl    $dst, $src, $shift\t# vector (2S)&quot; %}
18210   ins_encode %{
18211     __ shl(as_FloatRegister($dst$$reg), __ T2S,
18212            as_FloatRegister($src$$reg),
18213            (int)$shift$$constant);
18214   %}
18215   ins_pipe(vshift64_imm);
18216 %}
18217 
18218 instruct vsll4I_imm(vecX dst, vecX src, immI shift) %{
18219   predicate(n-&gt;as_Vector()-&gt;length() == 4);
18220   match(Set dst (LShiftVI src (LShiftCntV shift)));
18221   ins_cost(INSN_COST);
18222   format %{ &quot;shl    $dst, $src, $shift\t# vector (4S)&quot; %}
18223   ins_encode %{
18224     __ shl(as_FloatRegister($dst$$reg), __ T4S,
18225            as_FloatRegister($src$$reg),
18226            (int)$shift$$constant);
18227   %}
18228   ins_pipe(vshift128_imm);
18229 %}
18230 
18231 instruct vsra2I_imm(vecD dst, vecD src, immI shift) %{
18232   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18233   match(Set dst (RShiftVI src (RShiftCntV shift)));
18234   ins_cost(INSN_COST);
18235   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2S)&quot; %}
18236   ins_encode %{
18237     __ sshr(as_FloatRegister($dst$$reg), __ T2S,
18238             as_FloatRegister($src$$reg),
18239             (int)$shift$$constant);
18240   %}
18241   ins_pipe(vshift64_imm);
18242 %}
18243 
18244 instruct vsra4I_imm(vecX dst, vecX src, immI shift) %{
18245   predicate(n-&gt;as_Vector()-&gt;length() == 4);
18246   match(Set dst (RShiftVI src (RShiftCntV shift)));
18247   ins_cost(INSN_COST);
18248   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4S)&quot; %}
18249   ins_encode %{
18250     __ sshr(as_FloatRegister($dst$$reg), __ T4S,
18251             as_FloatRegister($src$$reg),
18252             (int)$shift$$constant);
18253   %}
18254   ins_pipe(vshift128_imm);
18255 %}
18256 
18257 instruct vsrl2I_imm(vecD dst, vecD src, immI shift) %{
18258   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18259   match(Set dst (URShiftVI src (RShiftCntV shift)));
18260   ins_cost(INSN_COST);
18261   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2S)&quot; %}
18262   ins_encode %{
18263     __ ushr(as_FloatRegister($dst$$reg), __ T2S,
18264             as_FloatRegister($src$$reg),
18265             (int)$shift$$constant);
18266   %}
18267   ins_pipe(vshift64_imm);
18268 %}
18269 
18270 instruct vsrl4I_imm(vecX dst, vecX src, immI shift) %{
18271   predicate(n-&gt;as_Vector()-&gt;length() == 4);
18272   match(Set dst (URShiftVI src (RShiftCntV shift)));
18273   ins_cost(INSN_COST);
18274   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4S)&quot; %}
18275   ins_encode %{
18276     __ ushr(as_FloatRegister($dst$$reg), __ T4S,
18277             as_FloatRegister($src$$reg),
18278             (int)$shift$$constant);
18279   %}
18280   ins_pipe(vshift128_imm);
18281 %}
18282 
18283 instruct vsll2L(vecX dst, vecX src, vecX shift) %{
18284   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18285   match(Set dst (LShiftVL src shift));
18286   ins_cost(INSN_COST);
18287   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2D)&quot; %}
18288   ins_encode %{
18289     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
18290             as_FloatRegister($src$$reg),
18291             as_FloatRegister($shift$$reg));
18292   %}
18293   ins_pipe(vshift128);
18294 %}
18295 
18296 instruct vsra2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
18297   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18298   match(Set dst (RShiftVL src shift));
18299   ins_cost(INSN_COST);
18300   effect(TEMP tmp);
18301   format %{ &quot;negr  $tmp,$shift\t&quot;
18302             &quot;sshl  $dst,$src,$tmp\t# vector (2D)&quot; %}
18303   ins_encode %{
18304     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
18305             as_FloatRegister($shift$$reg));
18306     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
18307             as_FloatRegister($src$$reg),
18308             as_FloatRegister($tmp$$reg));
18309   %}
18310   ins_pipe(vshift128);
18311 %}
18312 
18313 instruct vsrl2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
18314   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18315   match(Set dst (URShiftVL src shift));
18316   ins_cost(INSN_COST);
18317   effect(TEMP tmp);
18318   format %{ &quot;negr  $tmp,$shift\t&quot;
18319             &quot;ushl  $dst,$src,$tmp\t# vector (2D)&quot; %}
18320   ins_encode %{
18321     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
18322             as_FloatRegister($shift$$reg));
18323     __ ushl(as_FloatRegister($dst$$reg), __ T2D,
18324             as_FloatRegister($src$$reg),
18325             as_FloatRegister($tmp$$reg));
18326   %}
18327   ins_pipe(vshift128);
18328 %}
18329 
18330 instruct vsll2L_imm(vecX dst, vecX src, immI shift) %{
18331   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18332   match(Set dst (LShiftVL src (LShiftCntV shift)));
18333   ins_cost(INSN_COST);
18334   format %{ &quot;shl    $dst, $src, $shift\t# vector (2D)&quot; %}
18335   ins_encode %{
18336     __ shl(as_FloatRegister($dst$$reg), __ T2D,
18337            as_FloatRegister($src$$reg),
18338            (int)$shift$$constant);
18339   %}
18340   ins_pipe(vshift128_imm);
18341 %}
18342 
18343 instruct vsra2L_imm(vecX dst, vecX src, immI shift) %{
18344   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18345   match(Set dst (RShiftVL src (RShiftCntV shift)));
18346   ins_cost(INSN_COST);
18347   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2D)&quot; %}
18348   ins_encode %{
18349     __ sshr(as_FloatRegister($dst$$reg), __ T2D,
18350             as_FloatRegister($src$$reg),
18351             (int)$shift$$constant);
18352   %}
18353   ins_pipe(vshift128_imm);
18354 %}
18355 
18356 instruct vsrl2L_imm(vecX dst, vecX src, immI shift) %{
18357   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18358   match(Set dst (URShiftVL src (RShiftCntV shift)));
18359   ins_cost(INSN_COST);
18360   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2D)&quot; %}
18361   ins_encode %{
18362     __ ushr(as_FloatRegister($dst$$reg), __ T2D,
18363             as_FloatRegister($src$$reg),
18364             (int)$shift$$constant);
18365   %}
18366   ins_pipe(vshift128_imm);
18367 %}
18368 
18369 instruct vmax2F(vecD dst, vecD src1, vecD src2)
18370 %{
18371   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18372   match(Set dst (MaxV src1 src2));
18373   ins_cost(INSN_COST);
18374   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2F)&quot; %}
18375   ins_encode %{
18376     __ fmax(as_FloatRegister($dst$$reg), __ T2S,
18377             as_FloatRegister($src1$$reg),
18378             as_FloatRegister($src2$$reg));
18379   %}
18380   ins_pipe(vdop_fp64);
18381 %}
18382 
18383 instruct vmax4F(vecX dst, vecX src1, vecX src2)
18384 %{
18385   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18386   match(Set dst (MaxV src1 src2));
18387   ins_cost(INSN_COST);
18388   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (4S)&quot; %}
18389   ins_encode %{
18390     __ fmax(as_FloatRegister($dst$$reg), __ T4S,
18391             as_FloatRegister($src1$$reg),
18392             as_FloatRegister($src2$$reg));
18393   %}
18394   ins_pipe(vdop_fp128);
18395 %}
18396 
18397 instruct vmax2D(vecX dst, vecX src1, vecX src2)
18398 %{
18399   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18400   match(Set dst (MaxV src1 src2));
18401   ins_cost(INSN_COST);
18402   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2D)&quot; %}
18403   ins_encode %{
18404     __ fmax(as_FloatRegister($dst$$reg), __ T2D,
18405             as_FloatRegister($src1$$reg),
18406             as_FloatRegister($src2$$reg));
18407   %}
18408   ins_pipe(vdop_fp128);
18409 %}
18410 
18411 instruct vmin2F(vecD dst, vecD src1, vecD src2)
18412 %{
18413   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18414   match(Set dst (MinV src1 src2));
18415   ins_cost(INSN_COST);
18416   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2F)&quot; %}
18417   ins_encode %{
18418     __ fmin(as_FloatRegister($dst$$reg), __ T2S,
18419             as_FloatRegister($src1$$reg),
18420             as_FloatRegister($src2$$reg));
18421   %}
18422   ins_pipe(vdop_fp64);
18423 %}
18424 
18425 instruct vmin4F(vecX dst, vecX src1, vecX src2)
18426 %{
18427   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18428   match(Set dst (MinV src1 src2));
18429   ins_cost(INSN_COST);
18430   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (4S)&quot; %}
18431   ins_encode %{
18432     __ fmin(as_FloatRegister($dst$$reg), __ T4S,
18433             as_FloatRegister($src1$$reg),
18434             as_FloatRegister($src2$$reg));
18435   %}
18436   ins_pipe(vdop_fp128);
18437 %}
18438 
18439 instruct vmin2D(vecX dst, vecX src1, vecX src2)
18440 %{
18441   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18442   match(Set dst (MinV src1 src2));
18443   ins_cost(INSN_COST);
18444   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2D)&quot; %}
18445   ins_encode %{
18446     __ fmin(as_FloatRegister($dst$$reg), __ T2D,
18447             as_FloatRegister($src1$$reg),
18448             as_FloatRegister($src2$$reg));
18449   %}
18450   ins_pipe(vdop_fp128);
18451 %}
18452 
18453 instruct vround2D_reg(vecX dst, vecX src, immI rmode) %{
18454   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18455   match(Set dst (RoundDoubleModeV src rmode));
18456   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
18457   ins_encode %{
18458     switch ($rmode$$constant) {
18459       case RoundDoubleModeNode::rmode_rint:
18460         __ frintn(as_FloatRegister($dst$$reg), __ T2D,
18461                   as_FloatRegister($src$$reg));
18462         break;
18463       case RoundDoubleModeNode::rmode_floor:
18464         __ frintm(as_FloatRegister($dst$$reg), __ T2D,
18465                   as_FloatRegister($src$$reg));
18466         break;
18467       case RoundDoubleModeNode::rmode_ceil:
18468         __ frintp(as_FloatRegister($dst$$reg), __ T2D,
18469                   as_FloatRegister($src$$reg));
18470         break;
18471     }
18472   %}
18473   ins_pipe(vdop_fp128);
18474 %}
18475 
18476 instruct vpopcount4I(vecX dst, vecX src) %{
18477   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
18478   match(Set dst (PopCountVI src));
18479   format %{
18480     &quot;cnt     $dst, $src\t# vector (16B)\n\t&quot;
18481     &quot;uaddlp  $dst, $dst\t# vector (16B)\n\t&quot;
18482     &quot;uaddlp  $dst, $dst\t# vector (8H)&quot;
18483   %}
18484   ins_encode %{
18485      __ cnt(as_FloatRegister($dst$$reg), __ T16B,
18486             as_FloatRegister($src$$reg));
18487      __ uaddlp(as_FloatRegister($dst$$reg), __ T16B,
18488                as_FloatRegister($dst$$reg));
18489      __ uaddlp(as_FloatRegister($dst$$reg), __ T8H,
18490                as_FloatRegister($dst$$reg));
18491   %}
18492   ins_pipe(pipe_class_default);
18493 %}
18494 
18495 instruct vpopcount2I(vecD dst, vecD src) %{
18496   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
18497   match(Set dst (PopCountVI src));
18498   format %{
18499     &quot;cnt     $dst, $src\t# vector (8B)\n\t&quot;
18500     &quot;uaddlp  $dst, $dst\t# vector (8B)\n\t&quot;
18501     &quot;uaddlp  $dst, $dst\t# vector (4H)&quot;
18502   %}
18503   ins_encode %{
18504      __ cnt(as_FloatRegister($dst$$reg), __ T8B,
18505             as_FloatRegister($src$$reg));
18506      __ uaddlp(as_FloatRegister($dst$$reg), __ T8B,
18507                as_FloatRegister($dst$$reg));
18508      __ uaddlp(as_FloatRegister($dst$$reg), __ T4H,
18509                as_FloatRegister($dst$$reg));
18510   %}
18511   ins_pipe(pipe_class_default);
18512 %}
18513 
18514 //----------PEEPHOLE RULES-----------------------------------------------------
18515 // These must follow all instruction definitions as they use the names
18516 // defined in the instructions definitions.
18517 //
18518 // peepmatch ( root_instr_name [preceding_instruction]* );
18519 //
18520 // peepconstraint %{
18521 // (instruction_number.operand_name relational_op instruction_number.operand_name
18522 //  [, ...] );
18523 // // instruction numbers are zero-based using left to right order in peepmatch
18524 //
18525 // peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
18526 // // provide an instruction_number.operand_name for each operand that appears
18527 // // in the replacement instruction&#39;s match rule
18528 //
18529 // ---------VM FLAGS---------------------------------------------------------
18530 //
18531 // All peephole optimizations can be turned off using -XX:-OptoPeephole
18532 //
18533 // Each peephole rule is given an identifying number starting with zero and
18534 // increasing by one in the order seen by the parser.  An individual peephole
18535 // can be enabled, and all others disabled, by using -XX:OptoPeepholeAt=#
18536 // on the command-line.
18537 //
18538 // ---------CURRENT LIMITATIONS----------------------------------------------
18539 //
18540 // Only match adjacent instructions in same basic block
18541 // Only equality constraints
18542 // Only constraints between operands, not (0.dest_reg == RAX_enc)
18543 // Only one replacement instruction
18544 //
18545 // ---------EXAMPLE----------------------------------------------------------
18546 //
18547 // // pertinent parts of existing instructions in architecture description
18548 // instruct movI(iRegINoSp dst, iRegI src)
18549 // %{
18550 //   match(Set dst (CopyI src));
18551 // %}
18552 //
18553 // instruct incI_iReg(iRegINoSp dst, immI1 src, rFlagsReg cr)
18554 // %{
18555 //   match(Set dst (AddI dst src));
18556 //   effect(KILL cr);
18557 // %}
18558 //
18559 // // Change (inc mov) to lea
18560 // peephole %{
18561 //   // increment preceeded by register-register move
18562 //   peepmatch ( incI_iReg movI );
18563 //   // require that the destination register of the increment
18564 //   // match the destination register of the move
18565 //   peepconstraint ( 0.dst == 1.dst );
18566 //   // construct a replacement instruction that sets
18567 //   // the destination to ( move&#39;s source register + one )
18568 //   peepreplace ( leaI_iReg_immI( 0.dst 1.src 0.src ) );
18569 // %}
18570 //
18571 
18572 // Implementation no longer uses movX instructions since
18573 // machine-independent system no longer uses CopyX nodes.
18574 //
18575 // peephole
18576 // %{
18577 //   peepmatch (incI_iReg movI);
18578 //   peepconstraint (0.dst == 1.dst);
18579 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18580 // %}
18581 
18582 // peephole
18583 // %{
18584 //   peepmatch (decI_iReg movI);
18585 //   peepconstraint (0.dst == 1.dst);
18586 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18587 // %}
18588 
18589 // peephole
18590 // %{
18591 //   peepmatch (addI_iReg_imm movI);
18592 //   peepconstraint (0.dst == 1.dst);
18593 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18594 // %}
18595 
18596 // peephole
18597 // %{
18598 //   peepmatch (incL_iReg movL);
18599 //   peepconstraint (0.dst == 1.dst);
18600 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18601 // %}
18602 
18603 // peephole
18604 // %{
18605 //   peepmatch (decL_iReg movL);
18606 //   peepconstraint (0.dst == 1.dst);
18607 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18608 // %}
18609 
18610 // peephole
18611 // %{
18612 //   peepmatch (addL_iReg_imm movL);
18613 //   peepconstraint (0.dst == 1.dst);
18614 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18615 // %}
18616 
18617 // peephole
18618 // %{
18619 //   peepmatch (addP_iReg_imm movP);
18620 //   peepconstraint (0.dst == 1.dst);
18621 //   peepreplace (leaP_iReg_imm(0.dst 1.src 0.src));
18622 // %}
18623 
18624 // // Change load of spilled value to only a spill
18625 // instruct storeI(memory mem, iRegI src)
18626 // %{
18627 //   match(Set mem (StoreI mem src));
18628 // %}
18629 //
18630 // instruct loadI(iRegINoSp dst, memory mem)
18631 // %{
18632 //   match(Set dst (LoadI mem));
18633 // %}
18634 //
18635 
18636 //----------SMARTSPILL RULES---------------------------------------------------
18637 // These must follow all instruction definitions as they use the names
18638 // defined in the instructions definitions.
18639 
18640 // Local Variables:
18641 // mode: c++
18642 // End:
<a name="8" id="anc8"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="8" type="hidden" />
</body>
</html>