<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/os_cpu/windows_x86/atomic_windows_x86.hpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
<a name="1" id="anc1"></a><span class="line-modified">  2  * Copyright (c) 1999, 2020, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #ifndef OS_CPU_WINDOWS_X86_ATOMIC_WINDOWS_X86_HPP
 26 #define OS_CPU_WINDOWS_X86_ATOMIC_WINDOWS_X86_HPP
 27 
<a name="2" id="anc2"></a><span class="line-added"> 28 #include &lt;intrin.h&gt;</span>
 29 #include &quot;runtime/os.hpp&quot;
 30 
 31 // Note that in MSVC, volatile memory accesses are explicitly
 32 // guaranteed to have acquire release semantics (w.r.t. compiler
 33 // reordering) and therefore does not even need a compiler barrier
 34 // for normal acquire release accesses. And all generalized
 35 // bound calls like release_store go through Atomic::load
 36 // and Atomic::store which do volatile memory accesses.
 37 template&lt;&gt; inline void ScopedFence&lt;X_ACQUIRE&gt;::postfix()       { }
 38 template&lt;&gt; inline void ScopedFence&lt;RELEASE_X&gt;::prefix()        { }
 39 template&lt;&gt; inline void ScopedFence&lt;RELEASE_X_FENCE&gt;::prefix()  { }
 40 template&lt;&gt; inline void ScopedFence&lt;RELEASE_X_FENCE&gt;::postfix() { OrderAccess::fence(); }
 41 
<a name="3" id="anc3"></a>














 42 template&lt;size_t byte_size&gt;
 43 struct Atomic::PlatformAdd {
 44   template&lt;typename D, typename I&gt;
 45   D add_and_fetch(D volatile* dest, I add_value, atomic_memory_order order) const;
 46 
 47   template&lt;typename D, typename I&gt;
 48   D fetch_and_add(D volatile* dest, I add_value, atomic_memory_order order) const {
 49     return add_and_fetch(dest, add_value, order) - add_value;
 50   }
 51 };
 52 
<a name="4" id="anc4"></a><span class="line-modified"> 53 // The Interlocked* APIs only take long and will not accept __int32. That is</span>
<span class="line-modified"> 54 // acceptable on Windows, since long is a 32-bits integer type.</span>
<span class="line-modified"> 55 </span>
<span class="line-modified"> 56 #define DEFINE_INTRINSIC_ADD(IntrinsicName, IntrinsicType)                \</span>
<span class="line-modified"> 57   template&lt;&gt;                                                              \</span>
<span class="line-modified"> 58   template&lt;typename D, typename I&gt;                                        \</span>
<span class="line-modified"> 59   inline D Atomic::PlatformAdd&lt;sizeof(IntrinsicType)&gt;::add_and_fetch(D volatile* dest, \</span>
<span class="line-modified"> 60                                                                      I add_value, \</span>
<span class="line-modified"> 61                                                                      atomic_memory_order order) const { \</span>
<span class="line-modified"> 62     STATIC_ASSERT(sizeof(IntrinsicType) == sizeof(D));                    \</span>
<span class="line-modified"> 63     return PrimitiveConversions::cast&lt;D&gt;(                                 \</span>
<span class="line-modified"> 64       IntrinsicName(reinterpret_cast&lt;IntrinsicType volatile *&gt;(dest),     \</span>
<span class="line-modified"> 65                     PrimitiveConversions::cast&lt;IntrinsicType&gt;(add_value))); \</span>










 66   }
 67 
<a name="5" id="anc5"></a><span class="line-modified"> 68 DEFINE_INTRINSIC_ADD(InterlockedAdd,   long)</span>
<span class="line-modified"> 69 DEFINE_INTRINSIC_ADD(InterlockedAdd64, __int64)</span>
<span class="line-modified"> 70 </span>
<span class="line-modified"> 71 #undef DEFINE_INTRINSIC_ADD</span>
<span class="line-modified"> 72 </span>
<span class="line-modified"> 73 #define DEFINE_INTRINSIC_XCHG(IntrinsicName, IntrinsicType)               \</span>
<span class="line-modified"> 74   template&lt;&gt;                                                              \</span>
<span class="line-modified"> 75   template&lt;typename T&gt;                                                    \</span>
<span class="line-modified"> 76   inline T Atomic::PlatformXchg&lt;sizeof(IntrinsicType)&gt;::operator()(T volatile* dest, \</span>
<span class="line-modified"> 77                                                                    T exchange_value, \</span>
<span class="line-modified"> 78                                                                    atomic_memory_order order) const { \</span>
<span class="line-modified"> 79     STATIC_ASSERT(sizeof(IntrinsicType) == sizeof(T));                    \</span>
<span class="line-modified"> 80     return PrimitiveConversions::cast&lt;T&gt;(                                 \</span>
<span class="line-modified"> 81       IntrinsicName(reinterpret_cast&lt;IntrinsicType volatile *&gt;(dest),     \</span>
<span class="line-added"> 82                     PrimitiveConversions::cast&lt;IntrinsicType&gt;(exchange_value))); \</span>
 83   }
 84 
<a name="6" id="anc6"></a><span class="line-modified"> 85 DEFINE_INTRINSIC_XCHG(InterlockedExchange,   long)</span>
<span class="line-modified"> 86 DEFINE_INTRINSIC_XCHG(InterlockedExchange64, __int64)</span>
<span class="line-modified"> 87 </span>
<span class="line-modified"> 88 #undef DEFINE_INTRINSIC_XCHG</span>
<span class="line-modified"> 89 </span>
<span class="line-modified"> 90 // Note: the order of the parameters is different between</span>
<span class="line-modified"> 91 // Atomic::PlatformCmpxchg&lt;*&gt;::operator() and the</span>
<span class="line-modified"> 92 // InterlockedCompareExchange* API.</span>
<span class="line-modified"> 93 </span>
<span class="line-modified"> 94 #define DEFINE_INTRINSIC_CMPXCHG(IntrinsicName, IntrinsicType)            \</span>
<span class="line-modified"> 95   template&lt;&gt;                                                              \</span>
<span class="line-modified"> 96   template&lt;typename T&gt;                                                    \</span>
<span class="line-modified"> 97   inline T Atomic::PlatformCmpxchg&lt;sizeof(IntrinsicType)&gt;::operator()(T volatile* dest, \</span>
<span class="line-modified"> 98                                                                       T compare_value, \</span>
<span class="line-modified"> 99                                                                       T exchange_value, \</span>
<span class="line-modified">100                                                                       atomic_memory_order order) const { \</span>
<span class="line-modified">101     STATIC_ASSERT(sizeof(IntrinsicType) == sizeof(T));                    \</span>
<span class="line-modified">102     return PrimitiveConversions::cast&lt;T&gt;(                                 \</span>
<span class="line-modified">103       IntrinsicName(reinterpret_cast&lt;IntrinsicType volatile *&gt;(dest),     \</span>
<span class="line-modified">104                     PrimitiveConversions::cast&lt;IntrinsicType&gt;(exchange_value), \</span>
<span class="line-added">105                     PrimitiveConversions::cast&lt;IntrinsicType&gt;(compare_value))); \</span>
106   }
<a name="7" id="anc7"></a>
107 
<a name="8" id="anc8"></a><span class="line-modified">108 DEFINE_INTRINSIC_CMPXCHG(_InterlockedCompareExchange8, char) // Use the intrinsic as InterlockedCompareExchange8 does not exist</span>
<span class="line-modified">109 DEFINE_INTRINSIC_CMPXCHG(InterlockedCompareExchange,   long)</span>
<span class="line-modified">110 DEFINE_INTRINSIC_CMPXCHG(InterlockedCompareExchange64, __int64)</span>










111 
<a name="9" id="anc9"></a><span class="line-modified">112 #undef DEFINE_INTRINSIC_CMPXCHG</span>














113 
<a name="10" id="anc10"></a><span class="line-modified">114 #ifndef AMD64</span>














115 
<a name="11" id="anc11"></a><span class="line-modified">116 #pragma warning(disable: 4035) // Disables warnings reporting missing return statement</span>























117 
118 template&lt;&gt;
119 template&lt;typename T&gt;
120 inline T Atomic::PlatformLoad&lt;8&gt;::operator()(T const volatile* src) const {
121   STATIC_ASSERT(8 == sizeof(T));
122   volatile T dest;
123   volatile T* pdest = &amp;dest;
124   __asm {
125     mov eax, src
126     fild     qword ptr [eax]
127     mov eax, pdest
128     fistp    qword ptr [eax]
129   }
130   return dest;
131 }
132 
133 template&lt;&gt;
134 template&lt;typename T&gt;
135 inline void Atomic::PlatformStore&lt;8&gt;::operator()(T volatile* dest,
136                                                  T store_value) const {
137   STATIC_ASSERT(8 == sizeof(T));
138   volatile T* src = &amp;store_value;
139   __asm {
140     mov eax, src
141     fild     qword ptr [eax]
142     mov eax, dest
143     fistp    qword ptr [eax]
144   }
145 }
146 
<a name="12" id="anc12"></a>

147 #pragma warning(default: 4035) // Enables warnings reporting missing return statement
148 
<a name="13" id="anc13"></a>
149 template&lt;&gt;
150 struct Atomic::PlatformOrderedStore&lt;1, RELEASE_X_FENCE&gt;
151 {
152   template &lt;typename T&gt;
153   void operator()(volatile T* p, T v) const {
154     __asm {
155       mov edx, p;
156       mov al, v;
157       xchg al, byte ptr [edx];
158     }
159   }
160 };
161 
162 template&lt;&gt;
163 struct Atomic::PlatformOrderedStore&lt;2, RELEASE_X_FENCE&gt;
164 {
165   template &lt;typename T&gt;
166   void operator()(volatile T* p, T v) const {
167     __asm {
168       mov edx, p;
169       mov ax, v;
170       xchg ax, word ptr [edx];
171     }
172   }
173 };
174 
175 template&lt;&gt;
176 struct Atomic::PlatformOrderedStore&lt;4, RELEASE_X_FENCE&gt;
177 {
178   template &lt;typename T&gt;
179   void operator()(volatile T* p, T v) const {
180     __asm {
181       mov edx, p;
182       mov eax, v;
183       xchg eax, dword ptr [edx];
184     }
185   }
186 };
187 #endif // AMD64
188 
189 #endif // OS_CPU_WINDOWS_X86_ATOMIC_WINDOWS_X86_HPP
<a name="14" id="anc14"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="14" type="hidden" />
</body>
</html>