<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/share/opto/loopopts.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>   1 /*
   2  * Copyright (c) 1999, 2019, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;gc/shared/barrierSet.hpp&quot;
  27 #include &quot;gc/shared/c2/barrierSetC2.hpp&quot;
  28 #include &quot;memory/allocation.inline.hpp&quot;
  29 #include &quot;memory/resourceArea.hpp&quot;
  30 #include &quot;opto/addnode.hpp&quot;
  31 #include &quot;opto/callnode.hpp&quot;
  32 #include &quot;opto/castnode.hpp&quot;
  33 #include &quot;opto/connode.hpp&quot;
  34 #include &quot;opto/castnode.hpp&quot;
  35 #include &quot;opto/divnode.hpp&quot;
  36 #include &quot;opto/loopnode.hpp&quot;
  37 #include &quot;opto/matcher.hpp&quot;
  38 #include &quot;opto/mulnode.hpp&quot;
  39 #include &quot;opto/movenode.hpp&quot;
  40 #include &quot;opto/opaquenode.hpp&quot;
  41 #include &quot;opto/rootnode.hpp&quot;
  42 #include &quot;opto/subnode.hpp&quot;
  43 #include &quot;opto/subtypenode.hpp&quot;
  44 #include &quot;utilities/macros.hpp&quot;
  45 
  46 //=============================================================================
  47 //------------------------------split_thru_phi---------------------------------
  48 // Split Node &#39;n&#39; through merge point if there is enough win.
<a name="1" id="anc1"></a><span class="line-modified">  49 Node *PhaseIdealLoop::split_thru_phi( Node *n, Node *region, int policy ) {</span>
  50   if (n-&gt;Opcode() == Op_ConvI2L &amp;&amp; n-&gt;bottom_type() != TypeLong::LONG) {
  51     // ConvI2L may have type information on it which is unsafe to push up
  52     // so disable this for now
  53     return NULL;
  54   }
  55 
  56   // Splitting range check CastIIs through a loop induction Phi can
  57   // cause new Phis to be created that are left unrelated to the loop
  58   // induction Phi and prevent optimizations (vectorization)
  59   if (n-&gt;Opcode() == Op_CastII &amp;&amp; n-&gt;as_CastII()-&gt;has_range_check() &amp;&amp;
  60       region-&gt;is_CountedLoop() &amp;&amp; n-&gt;in(1) == region-&gt;as_CountedLoop()-&gt;phi()) {
  61     return NULL;
  62   }
  63 
<a name="2" id="anc2"></a>














  64   int wins = 0;
  65   assert(!n-&gt;is_CFG(), &quot;&quot;);
  66   assert(region-&gt;is_Region(), &quot;&quot;);
  67 
  68   const Type* type = n-&gt;bottom_type();
<a name="3" id="anc3"></a><span class="line-modified">  69   const TypeOopPtr *t_oop = _igvn.type(n)-&gt;isa_oopptr();</span>
<span class="line-modified">  70   Node *phi;</span>
  71   if (t_oop != NULL &amp;&amp; t_oop-&gt;is_known_instance_field()) {
  72     int iid    = t_oop-&gt;instance_id();
  73     int index  = C-&gt;get_alias_index(t_oop);
  74     int offset = t_oop-&gt;offset();
  75     phi = new PhiNode(region, type, NULL, iid, index, offset);
  76   } else {
  77     phi = PhiNode::make_blank(region, n);
  78   }
  79   uint old_unique = C-&gt;unique();
  80   for (uint i = 1; i &lt; region-&gt;req(); i++) {
<a name="4" id="anc4"></a><span class="line-modified">  81     Node *x;</span>
  82     Node* the_clone = NULL;
  83     if (region-&gt;in(i) == C-&gt;top()) {
  84       x = C-&gt;top();             // Dead path?  Use a dead data op
  85     } else {
  86       x = n-&gt;clone();           // Else clone up the data op
  87       the_clone = x;            // Remember for possible deletion.
  88       // Alter data node to use pre-phi inputs
  89       if (n-&gt;in(0) == region)
  90         x-&gt;set_req( 0, region-&gt;in(i) );
  91       for (uint j = 1; j &lt; n-&gt;req(); j++) {
<a name="5" id="anc5"></a><span class="line-modified">  92         Node *in = n-&gt;in(j);</span>
  93         if (in-&gt;is_Phi() &amp;&amp; in-&gt;in(0) == region)
<a name="6" id="anc6"></a><span class="line-modified">  94           x-&gt;set_req( j, in-&gt;in(i) ); // Use pre-Phi input for the clone</span>
  95       }
  96     }
  97     // Check for a &#39;win&#39; on some paths
<a name="7" id="anc7"></a><span class="line-modified">  98     const Type *t = x-&gt;Value(&amp;_igvn);</span>
  99 
 100     bool singleton = t-&gt;singleton();
 101 
 102     // A TOP singleton indicates that there are no possible values incoming
 103     // along a particular edge. In most cases, this is OK, and the Phi will
 104     // be eliminated later in an Ideal call. However, we can&#39;t allow this to
 105     // happen if the singleton occurs on loop entry, as the elimination of
 106     // the PhiNode may cause the resulting node to migrate back to a previous
 107     // loop iteration.
 108     if (singleton &amp;&amp; t == Type::TOP) {
 109       // Is_Loop() == false does not confirm the absence of a loop (e.g., an
 110       // irreducible loop may not be indicated by an affirmative is_Loop());
 111       // therefore, the only top we can split thru a phi is on a backedge of
 112       // a loop.
 113       singleton &amp;= region-&gt;is_Loop() &amp;&amp; (i != LoopNode::EntryControl);
 114     }
 115 
 116     if (singleton) {
 117       wins++;
 118       x = ((PhaseGVN&amp;)_igvn).makecon(t);
 119     } else {
 120       // We now call Identity to try to simplify the cloned node.
 121       // Note that some Identity methods call phase-&gt;type(this).
 122       // Make sure that the type array is big enough for
 123       // our new node, even though we may throw the node away.
 124       // (Note: This tweaking with igvn only works because x is a new node.)
 125       _igvn.set_type(x, t);
 126       // If x is a TypeNode, capture any more-precise type permanently into Node
 127       // otherwise it will be not updated during igvn-&gt;transform since
 128       // igvn-&gt;type(x) is set to x-&gt;Value() already.
 129       x-&gt;raise_bottom_type(t);
 130       Node* y = x-&gt;Identity(&amp;_igvn);
 131       if (y != x) {
 132         wins++;
 133         x = y;
 134       } else {
 135         y = _igvn.hash_find(x);
 136         if (y) {
 137           wins++;
 138           x = y;
 139         } else {
 140           // Else x is a new node we are keeping
 141           // We do not need register_new_node_with_optimizer
 142           // because set_type has already been called.
 143           _igvn._worklist.push(x);
 144         }
 145       }
 146     }
 147     if (x != the_clone &amp;&amp; the_clone != NULL)
 148       _igvn.remove_dead_node(the_clone);
 149     phi-&gt;set_req( i, x );
 150   }
 151   // Too few wins?
 152   if (wins &lt;= policy) {
 153     _igvn.remove_dead_node(phi);
 154     return NULL;
 155   }
 156 
 157   // Record Phi
 158   register_new_node( phi, region );
 159 
 160   for (uint i2 = 1; i2 &lt; phi-&gt;req(); i2++) {
 161     Node *x = phi-&gt;in(i2);
 162     // If we commoned up the cloned &#39;x&#39; with another existing Node,
 163     // the existing Node picks up a new use.  We need to make the
 164     // existing Node occur higher up so it dominates its uses.
 165     Node *old_ctrl;
 166     IdealLoopTree *old_loop;
 167 
 168     if (x-&gt;is_Con()) {
 169       // Constant&#39;s control is always root.
 170       set_ctrl(x, C-&gt;root());
 171       continue;
 172     }
 173     // The occasional new node
 174     if (x-&gt;_idx &gt;= old_unique) {     // Found a new, unplaced node?
 175       old_ctrl = NULL;
 176       old_loop = NULL;               // Not in any prior loop
 177     } else {
 178       old_ctrl = get_ctrl(x);
 179       old_loop = get_loop(old_ctrl); // Get prior loop
 180     }
 181     // New late point must dominate new use
 182     Node *new_ctrl = dom_lca(old_ctrl, region-&gt;in(i2));
 183     if (new_ctrl == old_ctrl) // Nothing is changed
 184       continue;
 185 
 186     IdealLoopTree *new_loop = get_loop(new_ctrl);
 187 
 188     // Don&#39;t move x into a loop if its uses are
 189     // outside of loop. Otherwise x will be cloned
 190     // for each use outside of this loop.
 191     IdealLoopTree *use_loop = get_loop(region);
 192     if (!new_loop-&gt;is_member(use_loop) &amp;&amp;
 193         (old_loop == NULL || !new_loop-&gt;is_member(old_loop))) {
 194       // Take early control, later control will be recalculated
 195       // during next iteration of loop optimizations.
 196       new_ctrl = get_early_ctrl(x);
 197       new_loop = get_loop(new_ctrl);
 198     }
 199     // Set new location
 200     set_ctrl(x, new_ctrl);
 201     // If changing loop bodies, see if we need to collect into new body
 202     if (old_loop != new_loop) {
 203       if (old_loop &amp;&amp; !old_loop-&gt;_child)
 204         old_loop-&gt;_body.yank(x);
 205       if (!new_loop-&gt;_child)
 206         new_loop-&gt;_body.push(x);  // Collect body info
 207     }
 208   }
 209 
 210   return phi;
 211 }
 212 
 213 //------------------------------dominated_by------------------------------------
 214 // Replace the dominated test with an obvious true or false.  Place it on the
 215 // IGVN worklist for later cleanup.  Move control-dependent data Nodes on the
 216 // live path up to the dominating control.
 217 void PhaseIdealLoop::dominated_by( Node *prevdom, Node *iff, bool flip, bool exclude_loop_predicate ) {
 218   if (VerifyLoopOptimizations &amp;&amp; PrintOpto) { tty-&gt;print_cr(&quot;dominating test&quot;); }
 219 
 220   // prevdom is the dominating projection of the dominating test.
 221   assert( iff-&gt;is_If(), &quot;&quot; );
 222   assert(iff-&gt;Opcode() == Op_If || iff-&gt;Opcode() == Op_CountedLoopEnd || iff-&gt;Opcode() == Op_RangeCheck, &quot;Check this code when new subtype is added&quot;);
 223   int pop = prevdom-&gt;Opcode();
 224   assert( pop == Op_IfFalse || pop == Op_IfTrue, &quot;&quot; );
 225   if (flip) {
 226     if (pop == Op_IfTrue)
 227       pop = Op_IfFalse;
 228     else
 229       pop = Op_IfTrue;
 230   }
 231   // &#39;con&#39; is set to true or false to kill the dominated test.
 232   Node *con = _igvn.makecon(pop == Op_IfTrue ? TypeInt::ONE : TypeInt::ZERO);
 233   set_ctrl(con, C-&gt;root()); // Constant gets a new use
 234   // Hack the dominated test
 235   _igvn.replace_input_of(iff, 1, con);
 236 
 237   // If I dont have a reachable TRUE and FALSE path following the IfNode then
 238   // I can assume this path reaches an infinite loop.  In this case it&#39;s not
 239   // important to optimize the data Nodes - either the whole compilation will
 240   // be tossed or this path (and all data Nodes) will go dead.
 241   if (iff-&gt;outcnt() != 2) return;
 242 
 243   // Make control-dependent data Nodes on the live path (path that will remain
 244   // once the dominated IF is removed) become control-dependent on the
 245   // dominating projection.
 246   Node* dp = iff-&gt;as_If()-&gt;proj_out_or_null(pop == Op_IfTrue);
 247 
 248   // Loop predicates may have depending checks which should not
 249   // be skipped. For example, range check predicate has two checks
 250   // for lower and upper bounds.
 251   if (dp == NULL)
 252     return;
 253 
 254   ProjNode* dp_proj  = dp-&gt;as_Proj();
 255   ProjNode* unc_proj = iff-&gt;as_If()-&gt;proj_out(1 - dp_proj-&gt;_con)-&gt;as_Proj();
 256   if (exclude_loop_predicate &amp;&amp;
 257       (unc_proj-&gt;is_uncommon_trap_proj(Deoptimization::Reason_predicate) != NULL ||
 258        unc_proj-&gt;is_uncommon_trap_proj(Deoptimization::Reason_profile_predicate) != NULL ||
 259        unc_proj-&gt;is_uncommon_trap_proj(Deoptimization::Reason_range_check) != NULL)) {
 260     // If this is a range check (IfNode::is_range_check), do not
 261     // reorder because Compile::allow_range_check_smearing might have
 262     // changed the check.
 263     return; // Let IGVN transformation change control dependence.
 264   }
 265 
 266   IdealLoopTree *old_loop = get_loop(dp);
 267 
 268   for (DUIterator_Fast imax, i = dp-&gt;fast_outs(imax); i &lt; imax; i++) {
 269     Node* cd = dp-&gt;fast_out(i); // Control-dependent node
 270     if (cd-&gt;depends_only_on_test()) {
 271       assert(cd-&gt;in(0) == dp, &quot;&quot;);
 272       _igvn.replace_input_of(cd, 0, prevdom);
 273       set_early_ctrl(cd);
 274       IdealLoopTree *new_loop = get_loop(get_ctrl(cd));
 275       if (old_loop != new_loop) {
 276         if (!old_loop-&gt;_child) old_loop-&gt;_body.yank(cd);
 277         if (!new_loop-&gt;_child) new_loop-&gt;_body.push(cd);
 278       }
 279       --i;
 280       --imax;
 281     }
 282   }
 283 }
 284 
 285 //------------------------------has_local_phi_input----------------------------
 286 // Return TRUE if &#39;n&#39; has Phi inputs from its local block and no other
 287 // block-local inputs (all non-local-phi inputs come from earlier blocks)
 288 Node *PhaseIdealLoop::has_local_phi_input( Node *n ) {
 289   Node *n_ctrl = get_ctrl(n);
 290   // See if some inputs come from a Phi in this block, or from before
 291   // this block.
 292   uint i;
 293   for( i = 1; i &lt; n-&gt;req(); i++ ) {
 294     Node *phi = n-&gt;in(i);
 295     if( phi-&gt;is_Phi() &amp;&amp; phi-&gt;in(0) == n_ctrl )
 296       break;
 297   }
 298   if( i &gt;= n-&gt;req() )
 299     return NULL;                // No Phi inputs; nowhere to clone thru
 300 
 301   // Check for inputs created between &#39;n&#39; and the Phi input.  These
 302   // must split as well; they have already been given the chance
 303   // (courtesy of a post-order visit) and since they did not we must
 304   // recover the &#39;cost&#39; of splitting them by being very profitable
 305   // when splitting &#39;n&#39;.  Since this is unlikely we simply give up.
 306   for( i = 1; i &lt; n-&gt;req(); i++ ) {
 307     Node *m = n-&gt;in(i);
 308     if( get_ctrl(m) == n_ctrl &amp;&amp; !m-&gt;is_Phi() ) {
 309       // We allow the special case of AddP&#39;s with no local inputs.
 310       // This allows us to split-up address expressions.
 311       if (m-&gt;is_AddP() &amp;&amp;
 312           get_ctrl(m-&gt;in(2)) != n_ctrl &amp;&amp;
 313           get_ctrl(m-&gt;in(3)) != n_ctrl) {
 314         // Move the AddP up to dominating point
 315         Node* c = find_non_split_ctrl(idom(n_ctrl));
 316         if (c-&gt;is_OuterStripMinedLoop()) {
 317           c-&gt;as_Loop()-&gt;verify_strip_mined(1);
 318           c = c-&gt;in(LoopNode::EntryControl);
 319         }
 320         set_ctrl_and_loop(m, c);
 321         continue;
 322       }
 323       return NULL;
 324     }
 325     assert(n-&gt;is_Phi() || m-&gt;is_Phi() || is_dominator(get_ctrl(m), n_ctrl), &quot;m has strange control&quot;);
 326   }
 327 
 328   return n_ctrl;
 329 }
 330 
 331 //------------------------------remix_address_expressions----------------------
 332 // Rework addressing expressions to get the most loop-invariant stuff
 333 // moved out.  We&#39;d like to do all associative operators, but it&#39;s especially
 334 // important (common) to do address expressions.
 335 Node *PhaseIdealLoop::remix_address_expressions( Node *n ) {
 336   if (!has_ctrl(n))  return NULL;
 337   Node *n_ctrl = get_ctrl(n);
 338   IdealLoopTree *n_loop = get_loop(n_ctrl);
 339 
 340   // See if &#39;n&#39; mixes loop-varying and loop-invariant inputs and
 341   // itself is loop-varying.
 342 
 343   // Only interested in binary ops (and AddP)
 344   if( n-&gt;req() &lt; 3 || n-&gt;req() &gt; 4 ) return NULL;
 345 
 346   Node *n1_ctrl = get_ctrl(n-&gt;in(                    1));
 347   Node *n2_ctrl = get_ctrl(n-&gt;in(                    2));
 348   Node *n3_ctrl = get_ctrl(n-&gt;in(n-&gt;req() == 3 ? 2 : 3));
 349   IdealLoopTree *n1_loop = get_loop( n1_ctrl );
 350   IdealLoopTree *n2_loop = get_loop( n2_ctrl );
 351   IdealLoopTree *n3_loop = get_loop( n3_ctrl );
 352 
 353   // Does one of my inputs spin in a tighter loop than self?
 354   if( (n_loop-&gt;is_member( n1_loop ) &amp;&amp; n_loop != n1_loop) ||
 355       (n_loop-&gt;is_member( n2_loop ) &amp;&amp; n_loop != n2_loop) ||
 356       (n_loop-&gt;is_member( n3_loop ) &amp;&amp; n_loop != n3_loop) )
 357     return NULL;                // Leave well enough alone
 358 
 359   // Is at least one of my inputs loop-invariant?
 360   if( n1_loop == n_loop &amp;&amp;
 361       n2_loop == n_loop &amp;&amp;
 362       n3_loop == n_loop )
 363     return NULL;                // No loop-invariant inputs
 364 
 365 
 366   int n_op = n-&gt;Opcode();
 367 
 368   // Replace expressions like ((V+I) &lt;&lt; 2) with (V&lt;&lt;2 + I&lt;&lt;2).
 369   if( n_op == Op_LShiftI ) {
 370     // Scale is loop invariant
 371     Node *scale = n-&gt;in(2);
 372     Node *scale_ctrl = get_ctrl(scale);
 373     IdealLoopTree *scale_loop = get_loop(scale_ctrl );
 374     if( n_loop == scale_loop || !scale_loop-&gt;is_member( n_loop ) )
 375       return NULL;
 376     const TypeInt *scale_t = scale-&gt;bottom_type()-&gt;isa_int();
 377     if( scale_t &amp;&amp; scale_t-&gt;is_con() &amp;&amp; scale_t-&gt;get_con() &gt;= 16 )
 378       return NULL;              // Dont bother with byte/short masking
 379     // Add must vary with loop (else shift would be loop-invariant)
 380     Node *add = n-&gt;in(1);
 381     Node *add_ctrl = get_ctrl(add);
 382     IdealLoopTree *add_loop = get_loop(add_ctrl);
 383     //assert( n_loop == add_loop, &quot;&quot; );
 384     if( n_loop != add_loop ) return NULL;  // happens w/ evil ZKM loops
 385 
 386     // Convert I-V into I+ (0-V); same for V-I
 387     if( add-&gt;Opcode() == Op_SubI &amp;&amp;
 388         _igvn.type( add-&gt;in(1) ) != TypeInt::ZERO ) {
 389       Node *zero = _igvn.intcon(0);
 390       set_ctrl(zero, C-&gt;root());
 391       Node *neg = new SubINode( _igvn.intcon(0), add-&gt;in(2) );
 392       register_new_node( neg, get_ctrl(add-&gt;in(2) ) );
 393       add = new AddINode( add-&gt;in(1), neg );
 394       register_new_node( add, add_ctrl );
 395     }
 396     if( add-&gt;Opcode() != Op_AddI ) return NULL;
 397     // See if one add input is loop invariant
 398     Node *add_var = add-&gt;in(1);
 399     Node *add_var_ctrl = get_ctrl(add_var);
 400     IdealLoopTree *add_var_loop = get_loop(add_var_ctrl );
 401     Node *add_invar = add-&gt;in(2);
 402     Node *add_invar_ctrl = get_ctrl(add_invar);
 403     IdealLoopTree *add_invar_loop = get_loop(add_invar_ctrl );
 404     if( add_var_loop == n_loop ) {
 405     } else if( add_invar_loop == n_loop ) {
 406       // Swap to find the invariant part
 407       add_invar = add_var;
 408       add_invar_ctrl = add_var_ctrl;
 409       add_invar_loop = add_var_loop;
 410       add_var = add-&gt;in(2);
 411       Node *add_var_ctrl = get_ctrl(add_var);
 412       IdealLoopTree *add_var_loop = get_loop(add_var_ctrl );
 413     } else                      // Else neither input is loop invariant
 414       return NULL;
 415     if( n_loop == add_invar_loop || !add_invar_loop-&gt;is_member( n_loop ) )
 416       return NULL;              // No invariant part of the add?
 417 
 418     // Yes!  Reshape address expression!
 419     Node *inv_scale = new LShiftINode( add_invar, scale );
 420     Node *inv_scale_ctrl =
 421       dom_depth(add_invar_ctrl) &gt; dom_depth(scale_ctrl) ?
 422       add_invar_ctrl : scale_ctrl;
 423     register_new_node( inv_scale, inv_scale_ctrl );
 424     Node *var_scale = new LShiftINode( add_var, scale );
 425     register_new_node( var_scale, n_ctrl );
 426     Node *var_add = new AddINode( var_scale, inv_scale );
 427     register_new_node( var_add, n_ctrl );
 428     _igvn.replace_node( n, var_add );
 429     return var_add;
 430   }
 431 
 432   // Replace (I+V) with (V+I)
 433   if( n_op == Op_AddI ||
 434       n_op == Op_AddL ||
 435       n_op == Op_AddF ||
 436       n_op == Op_AddD ||
 437       n_op == Op_MulI ||
 438       n_op == Op_MulL ||
 439       n_op == Op_MulF ||
 440       n_op == Op_MulD ) {
 441     if( n2_loop == n_loop ) {
 442       assert( n1_loop != n_loop, &quot;&quot; );
 443       n-&gt;swap_edges(1, 2);
 444     }
 445   }
 446 
 447   // Replace ((I1 +p V) +p I2) with ((I1 +p I2) +p V),
 448   // but not if I2 is a constant.
 449   if( n_op == Op_AddP ) {
 450     if( n2_loop == n_loop &amp;&amp; n3_loop != n_loop ) {
 451       if( n-&gt;in(2)-&gt;Opcode() == Op_AddP &amp;&amp; !n-&gt;in(3)-&gt;is_Con() ) {
 452         Node *n22_ctrl = get_ctrl(n-&gt;in(2)-&gt;in(2));
 453         Node *n23_ctrl = get_ctrl(n-&gt;in(2)-&gt;in(3));
 454         IdealLoopTree *n22loop = get_loop( n22_ctrl );
 455         IdealLoopTree *n23_loop = get_loop( n23_ctrl );
 456         if( n22loop != n_loop &amp;&amp; n22loop-&gt;is_member(n_loop) &amp;&amp;
 457             n23_loop == n_loop ) {
 458           Node *add1 = new AddPNode( n-&gt;in(1), n-&gt;in(2)-&gt;in(2), n-&gt;in(3) );
 459           // Stuff new AddP in the loop preheader
 460           register_new_node( add1, n_loop-&gt;_head-&gt;in(LoopNode::EntryControl) );
 461           Node *add2 = new AddPNode( n-&gt;in(1), add1, n-&gt;in(2)-&gt;in(3) );
 462           register_new_node( add2, n_ctrl );
 463           _igvn.replace_node( n, add2 );
 464           return add2;
 465         }
 466       }
 467     }
 468 
 469     // Replace (I1 +p (I2 + V)) with ((I1 +p I2) +p V)
 470     if (n2_loop != n_loop &amp;&amp; n3_loop == n_loop) {
 471       if (n-&gt;in(3)-&gt;Opcode() == Op_AddX) {
 472         Node *V = n-&gt;in(3)-&gt;in(1);
 473         Node *I = n-&gt;in(3)-&gt;in(2);
 474         if (is_member(n_loop,get_ctrl(V))) {
 475         } else {
 476           Node *tmp = V; V = I; I = tmp;
 477         }
 478         if (!is_member(n_loop,get_ctrl(I))) {
 479           Node *add1 = new AddPNode(n-&gt;in(1), n-&gt;in(2), I);
 480           // Stuff new AddP in the loop preheader
 481           register_new_node(add1, n_loop-&gt;_head-&gt;in(LoopNode::EntryControl));
 482           Node *add2 = new AddPNode(n-&gt;in(1), add1, V);
 483           register_new_node(add2, n_ctrl);
 484           _igvn.replace_node(n, add2);
 485           return add2;
 486         }
 487       }
 488     }
 489   }
 490 
 491   return NULL;
 492 }
 493 
 494 // Optimize ((in1[2*i] * in2[2*i]) + (in1[2*i+1] * in2[2*i+1]))
 495 Node *PhaseIdealLoop::convert_add_to_muladd(Node* n) {
 496   assert(n-&gt;Opcode() == Op_AddI, &quot;sanity&quot;);
 497   Node * nn = NULL;
 498   Node * in1 = n-&gt;in(1);
 499   Node * in2 = n-&gt;in(2);
 500   if (in1-&gt;Opcode() == Op_MulI &amp;&amp; in2-&gt;Opcode() == Op_MulI) {
 501     IdealLoopTree* loop_n = get_loop(get_ctrl(n));
 502     if (loop_n-&gt;is_counted() &amp;&amp;
 503         loop_n-&gt;_head-&gt;as_Loop()-&gt;is_valid_counted_loop() &amp;&amp;
 504         Matcher::match_rule_supported(Op_MulAddVS2VI) &amp;&amp;
 505         Matcher::match_rule_supported(Op_MulAddS2I)) {
 506       Node* mul_in1 = in1-&gt;in(1);
 507       Node* mul_in2 = in1-&gt;in(2);
 508       Node* mul_in3 = in2-&gt;in(1);
 509       Node* mul_in4 = in2-&gt;in(2);
 510       if (mul_in1-&gt;Opcode() == Op_LoadS &amp;&amp;
 511           mul_in2-&gt;Opcode() == Op_LoadS &amp;&amp;
 512           mul_in3-&gt;Opcode() == Op_LoadS &amp;&amp;
 513           mul_in4-&gt;Opcode() == Op_LoadS) {
 514         IdealLoopTree* loop1 = get_loop(get_ctrl(mul_in1));
 515         IdealLoopTree* loop2 = get_loop(get_ctrl(mul_in2));
 516         IdealLoopTree* loop3 = get_loop(get_ctrl(mul_in3));
 517         IdealLoopTree* loop4 = get_loop(get_ctrl(mul_in4));
 518         IdealLoopTree* loop5 = get_loop(get_ctrl(in1));
 519         IdealLoopTree* loop6 = get_loop(get_ctrl(in2));
 520         // All nodes should be in the same counted loop.
 521         if (loop_n == loop1 &amp;&amp; loop_n == loop2 &amp;&amp; loop_n == loop3 &amp;&amp;
 522             loop_n == loop4 &amp;&amp; loop_n == loop5 &amp;&amp; loop_n == loop6) {
 523           Node* adr1 = mul_in1-&gt;in(MemNode::Address);
 524           Node* adr2 = mul_in2-&gt;in(MemNode::Address);
 525           Node* adr3 = mul_in3-&gt;in(MemNode::Address);
 526           Node* adr4 = mul_in4-&gt;in(MemNode::Address);
 527           if (adr1-&gt;is_AddP() &amp;&amp; adr2-&gt;is_AddP() &amp;&amp; adr3-&gt;is_AddP() &amp;&amp; adr4-&gt;is_AddP()) {
 528             if ((adr1-&gt;in(AddPNode::Base) == adr3-&gt;in(AddPNode::Base)) &amp;&amp;
 529                 (adr2-&gt;in(AddPNode::Base) == adr4-&gt;in(AddPNode::Base))) {
 530               nn = new MulAddS2INode(mul_in1, mul_in2, mul_in3, mul_in4);
 531               register_new_node(nn, get_ctrl(n));
 532               _igvn.replace_node(n, nn);
 533               return nn;
 534             } else if ((adr1-&gt;in(AddPNode::Base) == adr4-&gt;in(AddPNode::Base)) &amp;&amp;
 535                        (adr2-&gt;in(AddPNode::Base) == adr3-&gt;in(AddPNode::Base))) {
 536               nn = new MulAddS2INode(mul_in1, mul_in2, mul_in4, mul_in3);
 537               register_new_node(nn, get_ctrl(n));
 538               _igvn.replace_node(n, nn);
 539               return nn;
 540             }
 541           }
 542         }
 543       }
 544     }
 545   }
 546   return nn;
 547 }
 548 
 549 //------------------------------conditional_move-------------------------------
 550 // Attempt to replace a Phi with a conditional move.  We have some pretty
 551 // strict profitability requirements.  All Phis at the merge point must
 552 // be converted, so we can remove the control flow.  We need to limit the
 553 // number of c-moves to a small handful.  All code that was in the side-arms
 554 // of the CFG diamond is now speculatively executed.  This code has to be
 555 // &quot;cheap enough&quot;.  We are pretty much limited to CFG diamonds that merge
 556 // 1 or 2 items with a total of 1 or 2 ops executed speculatively.
 557 Node *PhaseIdealLoop::conditional_move( Node *region ) {
 558 
 559   assert(region-&gt;is_Region(), &quot;sanity check&quot;);
 560   if (region-&gt;req() != 3) return NULL;
 561 
 562   // Check for CFG diamond
 563   Node *lp = region-&gt;in(1);
 564   Node *rp = region-&gt;in(2);
 565   if (!lp || !rp) return NULL;
 566   Node *lp_c = lp-&gt;in(0);
 567   if (lp_c == NULL || lp_c != rp-&gt;in(0) || !lp_c-&gt;is_If()) return NULL;
 568   IfNode *iff = lp_c-&gt;as_If();
 569 
 570   // Check for ops pinned in an arm of the diamond.
 571   // Can&#39;t remove the control flow in this case
 572   if (lp-&gt;outcnt() &gt; 1) return NULL;
 573   if (rp-&gt;outcnt() &gt; 1) return NULL;
 574 
 575   IdealLoopTree* r_loop = get_loop(region);
 576   assert(r_loop == get_loop(iff), &quot;sanity&quot;);
 577   // Always convert to CMOVE if all results are used only outside this loop.
 578   bool used_inside_loop = (r_loop == _ltree_root);
 579 
 580   // Check profitability
 581   int cost = 0;
 582   int phis = 0;
 583   for (DUIterator_Fast imax, i = region-&gt;fast_outs(imax); i &lt; imax; i++) {
 584     Node *out = region-&gt;fast_out(i);
 585     if (!out-&gt;is_Phi()) continue; // Ignore other control edges, etc
 586     phis++;
 587     PhiNode* phi = out-&gt;as_Phi();
 588     BasicType bt = phi-&gt;type()-&gt;basic_type();
 589     switch (bt) {
 590     case T_DOUBLE:
 591     case T_FLOAT:
 592       if (C-&gt;use_cmove()) {
 593         continue; //TODO: maybe we want to add some cost
 594       }
 595       cost += Matcher::float_cmove_cost(); // Could be very expensive
 596       break;
 597     case T_LONG: {
 598       cost += Matcher::long_cmove_cost(); // May encodes as 2 CMOV&#39;s
 599     }
 600     case T_INT:                 // These all CMOV fine
 601     case T_ADDRESS: {           // (RawPtr)
 602       cost++;
 603       break;
 604     }
 605     case T_NARROWOOP: // Fall through
 606     case T_OBJECT: {            // Base oops are OK, but not derived oops
 607       const TypeOopPtr *tp = phi-&gt;type()-&gt;make_ptr()-&gt;isa_oopptr();
 608       // Derived pointers are Bad (tm): what&#39;s the Base (for GC purposes) of a
 609       // CMOVE&#39;d derived pointer?  It&#39;s a CMOVE&#39;d derived base.  Thus
 610       // CMOVE&#39;ing a derived pointer requires we also CMOVE the base.  If we
 611       // have a Phi for the base here that we convert to a CMOVE all is well
 612       // and good.  But if the base is dead, we&#39;ll not make a CMOVE.  Later
 613       // the allocator will have to produce a base by creating a CMOVE of the
 614       // relevant bases.  This puts the allocator in the business of
 615       // manufacturing expensive instructions, generally a bad plan.
 616       // Just Say No to Conditionally-Moved Derived Pointers.
 617       if (tp &amp;&amp; tp-&gt;offset() != 0)
 618         return NULL;
 619       cost++;
 620       break;
 621     }
 622     default:
 623       return NULL;              // In particular, can&#39;t do memory or I/O
 624     }
 625     // Add in cost any speculative ops
 626     for (uint j = 1; j &lt; region-&gt;req(); j++) {
 627       Node *proj = region-&gt;in(j);
 628       Node *inp = phi-&gt;in(j);
 629       if (get_ctrl(inp) == proj) { // Found local op
 630         cost++;
 631         // Check for a chain of dependent ops; these will all become
 632         // speculative in a CMOV.
 633         for (uint k = 1; k &lt; inp-&gt;req(); k++)
 634           if (get_ctrl(inp-&gt;in(k)) == proj)
 635             cost += ConditionalMoveLimit; // Too much speculative goo
 636       }
 637     }
 638     // See if the Phi is used by a Cmp or Narrow oop Decode/Encode.
 639     // This will likely Split-If, a higher-payoff operation.
 640     for (DUIterator_Fast kmax, k = phi-&gt;fast_outs(kmax); k &lt; kmax; k++) {
 641       Node* use = phi-&gt;fast_out(k);
 642       if (use-&gt;is_Cmp() || use-&gt;is_DecodeNarrowPtr() || use-&gt;is_EncodeNarrowPtr())
 643         cost += ConditionalMoveLimit;
 644       // Is there a use inside the loop?
 645       // Note: check only basic types since CMoveP is pinned.
 646       if (!used_inside_loop &amp;&amp; is_java_primitive(bt)) {
 647         IdealLoopTree* u_loop = get_loop(has_ctrl(use) ? get_ctrl(use) : use);
 648         if (r_loop == u_loop || r_loop-&gt;is_member(u_loop)) {
 649           used_inside_loop = true;
 650         }
 651       }
 652     }
 653   }//for
 654   Node* bol = iff-&gt;in(1);
 655   if (bol-&gt;Opcode() == Op_Opaque4) {
 656     return NULL; // Ignore loop predicate checks (the Opaque4 ensures they will go away)
 657   }
 658   assert(bol-&gt;Opcode() == Op_Bool, &quot;Unexpected node&quot;);
 659   int cmp_op = bol-&gt;in(1)-&gt;Opcode();
 660   if (cmp_op == Op_SubTypeCheck) { // SubTypeCheck expansion expects an IfNode
 661     return NULL;
 662   }
 663   // It is expensive to generate flags from a float compare.
 664   // Avoid duplicated float compare.
 665   if (phis &gt; 1 &amp;&amp; (cmp_op == Op_CmpF || cmp_op == Op_CmpD)) return NULL;
 666 
 667   float infrequent_prob = PROB_UNLIKELY_MAG(3);
 668   // Ignore cost and blocks frequency if CMOVE can be moved outside the loop.
 669   if (used_inside_loop) {
 670     if (cost &gt;= ConditionalMoveLimit) return NULL; // Too much goo
 671 
 672     // BlockLayoutByFrequency optimization moves infrequent branch
 673     // from hot path. No point in CMOV&#39;ing in such case (110 is used
 674     // instead of 100 to take into account not exactness of float value).
 675     if (BlockLayoutByFrequency) {
 676       infrequent_prob = MAX2(infrequent_prob, (float)BlockLayoutMinDiamondPercentage/110.0f);
 677     }
 678   }
 679   // Check for highly predictable branch.  No point in CMOV&#39;ing if
 680   // we are going to predict accurately all the time.
 681   if (C-&gt;use_cmove() &amp;&amp; (cmp_op == Op_CmpF || cmp_op == Op_CmpD)) {
 682     //keep going
 683   } else if (iff-&gt;_prob &lt; infrequent_prob ||
 684       iff-&gt;_prob &gt; (1.0f - infrequent_prob))
 685     return NULL;
 686 
 687   // --------------
 688   // Now replace all Phis with CMOV&#39;s
 689   Node *cmov_ctrl = iff-&gt;in(0);
 690   uint flip = (lp-&gt;Opcode() == Op_IfTrue);
 691   Node_List wq;
 692   while (1) {
 693     PhiNode* phi = NULL;
 694     for (DUIterator_Fast imax, i = region-&gt;fast_outs(imax); i &lt; imax; i++) {
 695       Node *out = region-&gt;fast_out(i);
 696       if (out-&gt;is_Phi()) {
 697         phi = out-&gt;as_Phi();
 698         break;
 699       }
 700     }
 701     if (phi == NULL)  break;
 702     if (PrintOpto &amp;&amp; VerifyLoopOptimizations) { tty-&gt;print_cr(&quot;CMOV&quot;); }
 703     // Move speculative ops
 704     wq.push(phi);
 705     while (wq.size() &gt; 0) {
 706       Node *n = wq.pop();
 707       for (uint j = 1; j &lt; n-&gt;req(); j++) {
 708         Node* m = n-&gt;in(j);
 709         if (m != NULL &amp;&amp; !is_dominator(get_ctrl(m), cmov_ctrl)) {
 710 #ifndef PRODUCT
 711           if (PrintOpto &amp;&amp; VerifyLoopOptimizations) {
 712             tty-&gt;print(&quot;  speculate: &quot;);
 713             m-&gt;dump();
 714           }
 715 #endif
 716           set_ctrl(m, cmov_ctrl);
 717           wq.push(m);
 718         }
 719       }
 720     }
 721     Node *cmov = CMoveNode::make(cmov_ctrl, iff-&gt;in(1), phi-&gt;in(1+flip), phi-&gt;in(2-flip), _igvn.type(phi));
 722     register_new_node( cmov, cmov_ctrl );
 723     _igvn.replace_node( phi, cmov );
 724 #ifndef PRODUCT
 725     if (TraceLoopOpts) {
 726       tty-&gt;print(&quot;CMOV  &quot;);
 727       r_loop-&gt;dump_head();
 728       if (Verbose) {
 729         bol-&gt;in(1)-&gt;dump(1);
 730         cmov-&gt;dump(1);
 731       }
 732     }
 733     if (VerifyLoopOptimizations) verify();
 734 #endif
 735   }
 736 
 737   // The useless CFG diamond will fold up later; see the optimization in
 738   // RegionNode::Ideal.
 739   _igvn._worklist.push(region);
 740 
 741   return iff-&gt;in(1);
 742 }
 743 
 744 static void enqueue_cfg_uses(Node* m, Unique_Node_List&amp; wq) {
 745   for (DUIterator_Fast imax, i = m-&gt;fast_outs(imax); i &lt; imax; i++) {
 746     Node* u = m-&gt;fast_out(i);
 747     if (u-&gt;is_CFG()) {
 748       if (u-&gt;Opcode() == Op_NeverBranch) {
 749         u = ((NeverBranchNode*)u)-&gt;proj_out(0);
 750         enqueue_cfg_uses(u, wq);
 751       } else {
 752         wq.push(u);
 753       }
 754     }
 755   }
 756 }
 757 
 758 // Try moving a store out of a loop, right before the loop
 759 Node* PhaseIdealLoop::try_move_store_before_loop(Node* n, Node *n_ctrl) {
 760   // Store has to be first in the loop body
 761   IdealLoopTree *n_loop = get_loop(n_ctrl);
 762   if (n-&gt;is_Store() &amp;&amp; n_loop != _ltree_root &amp;&amp;
 763       n_loop-&gt;is_loop() &amp;&amp; n_loop-&gt;_head-&gt;is_Loop() &amp;&amp;
 764       n-&gt;in(0) != NULL) {
 765     Node* address = n-&gt;in(MemNode::Address);
 766     Node* value = n-&gt;in(MemNode::ValueIn);
 767     Node* mem = n-&gt;in(MemNode::Memory);
 768     IdealLoopTree* address_loop = get_loop(get_ctrl(address));
 769     IdealLoopTree* value_loop = get_loop(get_ctrl(value));
 770 
 771     // - address and value must be loop invariant
 772     // - memory must be a memory Phi for the loop
 773     // - Store must be the only store on this memory slice in the
 774     // loop: if there&#39;s another store following this one then value
 775     // written at iteration i by the second store could be overwritten
 776     // at iteration i+n by the first store: it&#39;s not safe to move the
 777     // first store out of the loop
 778     // - nothing must observe the memory Phi: it guarantees no read
 779     // before the store, we are also guaranteed the store post
 780     // dominates the loop head (ignoring a possible early
 781     // exit). Otherwise there would be extra Phi involved between the
 782     // loop&#39;s Phi and the store.
 783     // - there must be no early exit from the loop before the Store
 784     // (such an exit most of the time would be an extra use of the
 785     // memory Phi but sometimes is a bottom memory Phi that takes the
 786     // store as input).
 787 
 788     if (!n_loop-&gt;is_member(address_loop) &amp;&amp;
 789         !n_loop-&gt;is_member(value_loop) &amp;&amp;
 790         mem-&gt;is_Phi() &amp;&amp; mem-&gt;in(0) == n_loop-&gt;_head &amp;&amp;
 791         mem-&gt;outcnt() == 1 &amp;&amp;
 792         mem-&gt;in(LoopNode::LoopBackControl) == n) {
 793 
 794       assert(n_loop-&gt;_tail != NULL, &quot;need a tail&quot;);
 795       assert(is_dominator(n_ctrl, n_loop-&gt;_tail), &quot;store control must not be in a branch in the loop&quot;);
 796 
 797       // Verify that there&#39;s no early exit of the loop before the store.
 798       bool ctrl_ok = false;
 799       {
 800         // Follow control from loop head until n, we exit the loop or
 801         // we reach the tail
 802         ResourceMark rm;
 803         Unique_Node_List wq;
 804         wq.push(n_loop-&gt;_head);
 805 
 806         for (uint next = 0; next &lt; wq.size(); ++next) {
 807           Node *m = wq.at(next);
 808           if (m == n-&gt;in(0)) {
 809             ctrl_ok = true;
 810             continue;
 811           }
 812           assert(!has_ctrl(m), &quot;should be CFG&quot;);
 813           if (!n_loop-&gt;is_member(get_loop(m)) || m == n_loop-&gt;_tail) {
 814             ctrl_ok = false;
 815             break;
 816           }
 817           enqueue_cfg_uses(m, wq);
 818           if (wq.size() &gt; 10) {
 819             ctrl_ok = false;
 820             break;
 821           }
 822         }
 823       }
 824       if (ctrl_ok) {
 825         // move the Store
 826         _igvn.replace_input_of(mem, LoopNode::LoopBackControl, mem);
 827         _igvn.replace_input_of(n, 0, n_loop-&gt;_head-&gt;as_Loop()-&gt;skip_strip_mined()-&gt;in(LoopNode::EntryControl));
 828         _igvn.replace_input_of(n, MemNode::Memory, mem-&gt;in(LoopNode::EntryControl));
 829         // Disconnect the phi now. An empty phi can confuse other
 830         // optimizations in this pass of loop opts.
 831         _igvn.replace_node(mem, mem-&gt;in(LoopNode::EntryControl));
 832         n_loop-&gt;_body.yank(mem);
 833 
 834         set_ctrl_and_loop(n, n-&gt;in(0));
 835 
 836         return n;
 837       }
 838     }
 839   }
 840   return NULL;
 841 }
 842 
 843 // Try moving a store out of a loop, right after the loop
 844 void PhaseIdealLoop::try_move_store_after_loop(Node* n) {
 845   if (n-&gt;is_Store() &amp;&amp; n-&gt;in(0) != NULL) {
 846     Node *n_ctrl = get_ctrl(n);
 847     IdealLoopTree *n_loop = get_loop(n_ctrl);
 848     // Store must be in a loop
 849     if (n_loop != _ltree_root &amp;&amp; !n_loop-&gt;_irreducible) {
 850       Node* address = n-&gt;in(MemNode::Address);
 851       Node* value = n-&gt;in(MemNode::ValueIn);
 852       IdealLoopTree* address_loop = get_loop(get_ctrl(address));
 853       // address must be loop invariant
 854       if (!n_loop-&gt;is_member(address_loop)) {
 855         // Store must be last on this memory slice in the loop and
 856         // nothing in the loop must observe it
 857         Node* phi = NULL;
 858         for (DUIterator_Fast imax, i = n-&gt;fast_outs(imax); i &lt; imax; i++) {
 859           Node* u = n-&gt;fast_out(i);
 860           if (has_ctrl(u)) { // control use?
 861             IdealLoopTree *u_loop = get_loop(get_ctrl(u));
 862             if (!n_loop-&gt;is_member(u_loop)) {
 863               continue;
 864             }
 865             if (u-&gt;is_Phi() &amp;&amp; u-&gt;in(0) == n_loop-&gt;_head) {
 866               assert(_igvn.type(u) == Type::MEMORY, &quot;bad phi&quot;);
 867               // multiple phis on the same slice are possible
 868               if (phi != NULL) {
 869                 return;
 870               }
 871               phi = u;
 872               continue;
 873             }
 874           }
 875           return;
 876         }
 877         if (phi != NULL) {
 878           // Nothing in the loop before the store (next iteration)
 879           // must observe the stored value
 880           bool mem_ok = true;
 881           {
 882             ResourceMark rm;
 883             Unique_Node_List wq;
 884             wq.push(phi);
 885             for (uint next = 0; next &lt; wq.size() &amp;&amp; mem_ok; ++next) {
 886               Node *m = wq.at(next);
 887               for (DUIterator_Fast imax, i = m-&gt;fast_outs(imax); i &lt; imax &amp;&amp; mem_ok; i++) {
 888                 Node* u = m-&gt;fast_out(i);
 889                 if (u-&gt;is_Store() || u-&gt;is_Phi()) {
 890                   if (u != n) {
 891                     wq.push(u);
 892                     mem_ok = (wq.size() &lt;= 10);
 893                   }
 894                 } else {
 895                   mem_ok = false;
 896                   break;
 897                 }
 898               }
 899             }
 900           }
 901           if (mem_ok) {
 902             // Move the store out of the loop if the LCA of all
 903             // users (except for the phi) is outside the loop.
 904             Node* hook = new Node(1);
 905             hook-&gt;init_req(0, n_ctrl); // Add an input to prevent hook from being dead
 906             _igvn.rehash_node_delayed(phi);
 907             int count = phi-&gt;replace_edge(n, hook);
 908             assert(count &gt; 0, &quot;inconsistent phi&quot;);
 909 
 910             // Compute latest point this store can go
 911             Node* lca = get_late_ctrl(n, get_ctrl(n));
 912             if (lca-&gt;is_OuterStripMinedLoop()) {
 913               lca = lca-&gt;in(LoopNode::EntryControl);
 914             }
 915             if (n_loop-&gt;is_member(get_loop(lca))) {
 916               // LCA is in the loop - bail out
 917               _igvn.replace_node(hook, n);
 918               return;
 919             }
 920 #ifdef ASSERT
 921             if (n_loop-&gt;_head-&gt;is_Loop() &amp;&amp; n_loop-&gt;_head-&gt;as_Loop()-&gt;is_strip_mined()) {
 922               assert(n_loop-&gt;_head-&gt;Opcode() == Op_CountedLoop, &quot;outer loop is a strip mined&quot;);
 923               n_loop-&gt;_head-&gt;as_Loop()-&gt;verify_strip_mined(1);
 924               Node* outer = n_loop-&gt;_head-&gt;as_CountedLoop()-&gt;outer_loop();
 925               IdealLoopTree* outer_loop = get_loop(outer);
 926               assert(n_loop-&gt;_parent == outer_loop, &quot;broken loop tree&quot;);
 927               assert(get_loop(lca) == outer_loop, &quot;safepoint in outer loop consume all memory state&quot;);
 928             }
 929 #endif
 930 
 931             // Move store out of the loop
 932             _igvn.replace_node(hook, n-&gt;in(MemNode::Memory));
 933             _igvn.replace_input_of(n, 0, lca);
 934             set_ctrl_and_loop(n, lca);
 935 
 936             // Disconnect the phi now. An empty phi can confuse other
 937             // optimizations in this pass of loop opts..
 938             if (phi-&gt;in(LoopNode::LoopBackControl) == phi) {
 939               _igvn.replace_node(phi, phi-&gt;in(LoopNode::EntryControl));
 940               n_loop-&gt;_body.yank(phi);
 941             }
 942           }
 943         }
 944       }
 945     }
 946   }
 947 }
 948 
 949 //------------------------------split_if_with_blocks_pre-----------------------
 950 // Do the real work in a non-recursive function.  Data nodes want to be
 951 // cloned in the pre-order so they can feed each other nicely.
 952 Node *PhaseIdealLoop::split_if_with_blocks_pre( Node *n ) {
 953   // Cloning these guys is unlikely to win
 954   int n_op = n-&gt;Opcode();
 955   if (n_op == Op_MergeMem) {
 956     return n;
 957   }
 958   if (n-&gt;is_Proj()) {
 959     return n;
 960   }
 961   // Do not clone-up CmpFXXX variations, as these are always
 962   // followed by a CmpI
 963   if (n-&gt;is_Cmp()) {
 964     return n;
 965   }
 966   // Attempt to use a conditional move instead of a phi/branch
 967   if (ConditionalMoveLimit &gt; 0 &amp;&amp; n_op == Op_Region) {
 968     Node *cmov = conditional_move( n );
 969     if (cmov) {
 970       return cmov;
 971     }
 972   }
 973   if (n-&gt;is_CFG() || n-&gt;is_LoadStore()) {
 974     return n;
 975   }
 976   if (n-&gt;is_Opaque1() ||     // Opaque nodes cannot be mod&#39;d
 977       n_op == Op_Opaque2) {
 978     if (!C-&gt;major_progress()) {   // If chance of no more loop opts...
 979       _igvn._worklist.push(n);  // maybe we&#39;ll remove them
 980     }
 981     return n;
 982   }
 983 
 984   if (n-&gt;is_Con()) {
 985     return n;   // No cloning for Con nodes
 986   }
 987 
 988   Node *n_ctrl = get_ctrl(n);
 989   if (!n_ctrl) {
 990     return n;       // Dead node
 991   }
 992 
 993   Node* res = try_move_store_before_loop(n, n_ctrl);
 994   if (res != NULL) {
 995     return n;
 996   }
 997 
 998   // Attempt to remix address expressions for loop invariants
 999   Node *m = remix_address_expressions( n );
1000   if( m ) return m;
1001 
1002   if (n_op == Op_AddI) {
1003     Node *nn = convert_add_to_muladd( n );
1004     if ( nn ) return nn;
1005   }
1006 
1007   if (n-&gt;is_ConstraintCast()) {
1008     Node* dom_cast = n-&gt;as_ConstraintCast()-&gt;dominating_cast(&amp;_igvn, this);
1009     // ConstraintCastNode::dominating_cast() uses node control input to determine domination.
1010     // Node control inputs don&#39;t necessarily agree with loop control info (due to
1011     // transformations happened in between), thus additional dominance check is needed
1012     // to keep loop info valid.
1013     if (dom_cast != NULL &amp;&amp; is_dominator(get_ctrl(dom_cast), get_ctrl(n))) {
1014       _igvn.replace_node(n, dom_cast);
1015       return dom_cast;
1016     }
1017   }
1018 
1019   // Determine if the Node has inputs from some local Phi.
1020   // Returns the block to clone thru.
1021   Node *n_blk = has_local_phi_input( n );
1022   if( !n_blk ) return n;
1023 
1024   // Do not clone the trip counter through on a CountedLoop
1025   // (messes up the canonical shape).
1026   if( n_blk-&gt;is_CountedLoop() &amp;&amp; n-&gt;Opcode() == Op_AddI ) return n;
1027 
1028   // Check for having no control input; not pinned.  Allow
1029   // dominating control.
1030   if (n-&gt;in(0)) {
1031     Node *dom = idom(n_blk);
1032     if (dom_lca(n-&gt;in(0), dom) != n-&gt;in(0)) {
1033       return n;
1034     }
1035   }
1036   // Policy: when is it profitable.  You must get more wins than
1037   // policy before it is considered profitable.  Policy is usually 0,
1038   // so 1 win is considered profitable.  Big merges will require big
1039   // cloning, so get a larger policy.
1040   int policy = n_blk-&gt;req() &gt;&gt; 2;
1041 
1042   // If the loop is a candidate for range check elimination,
1043   // delay splitting through it&#39;s phi until a later loop optimization
1044   if (n_blk-&gt;is_CountedLoop()) {
1045     IdealLoopTree *lp = get_loop(n_blk);
1046     if (lp &amp;&amp; lp-&gt;_rce_candidate) {
1047       return n;
1048     }
1049   }
1050 
1051   if (must_throttle_split_if()) return n;
1052 
1053   // Split &#39;n&#39; through the merge point if it is profitable
1054   Node *phi = split_thru_phi( n, n_blk, policy );
1055   if (!phi) return n;
1056 
1057   // Found a Phi to split thru!
1058   // Replace &#39;n&#39; with the new phi
1059   _igvn.replace_node( n, phi );
1060   // Moved a load around the loop, &#39;en-registering&#39; something.
1061   if (n_blk-&gt;is_Loop() &amp;&amp; n-&gt;is_Load() &amp;&amp;
1062       !phi-&gt;in(LoopNode::LoopBackControl)-&gt;is_Load())
1063     C-&gt;set_major_progress();
1064 
1065   return phi;
1066 }
1067 
1068 static bool merge_point_too_heavy(Compile* C, Node* region) {
1069   // Bail out if the region and its phis have too many users.
1070   int weight = 0;
1071   for (DUIterator_Fast imax, i = region-&gt;fast_outs(imax); i &lt; imax; i++) {
1072     weight += region-&gt;fast_out(i)-&gt;outcnt();
1073   }
1074   int nodes_left = C-&gt;max_node_limit() - C-&gt;live_nodes();
1075   if (weight * 8 &gt; nodes_left) {
1076     if (PrintOpto) {
1077       tty-&gt;print_cr(&quot;*** Split-if bails out:  %d nodes, region weight %d&quot;, C-&gt;unique(), weight);
1078     }
1079     return true;
1080   } else {
1081     return false;
1082   }
1083 }
1084 
1085 static bool merge_point_safe(Node* region) {
1086   // 4799512: Stop split_if_with_blocks from splitting a block with a ConvI2LNode
1087   // having a PhiNode input. This sidesteps the dangerous case where the split
1088   // ConvI2LNode may become TOP if the input Value() does not
1089   // overlap the ConvI2L range, leaving a node which may not dominate its
1090   // uses.
1091   // A better fix for this problem can be found in the BugTraq entry, but
1092   // expediency for Mantis demands this hack.
1093 #ifdef _LP64
1094   for (DUIterator_Fast imax, i = region-&gt;fast_outs(imax); i &lt; imax; i++) {
1095     Node* n = region-&gt;fast_out(i);
1096     if (n-&gt;is_Phi()) {
1097       for (DUIterator_Fast jmax, j = n-&gt;fast_outs(jmax); j &lt; jmax; j++) {
1098         Node* m = n-&gt;fast_out(j);
1099         if (m-&gt;Opcode() == Op_ConvI2L)
1100           return false;
1101         if (m-&gt;is_CastII() &amp;&amp; m-&gt;isa_CastII()-&gt;has_range_check()) {
1102           return false;
1103         }
1104       }
1105     }
1106   }
1107 #endif
1108   return true;
1109 }
1110 
1111 
1112 //------------------------------place_near_use---------------------------------
1113 // Place some computation next to use but not inside inner loops.
1114 // For inner loop uses move it to the preheader area.
1115 Node *PhaseIdealLoop::place_near_use(Node *useblock) const {
1116   IdealLoopTree *u_loop = get_loop( useblock );
1117   if (u_loop-&gt;_irreducible) {
1118     return useblock;
1119   }
1120   if (u_loop-&gt;_child) {
1121     if (useblock == u_loop-&gt;_head &amp;&amp; u_loop-&gt;_head-&gt;is_OuterStripMinedLoop()) {
1122       return u_loop-&gt;_head-&gt;in(LoopNode::EntryControl);
1123     }
1124     return useblock;
1125   }
1126   return u_loop-&gt;_head-&gt;as_Loop()-&gt;skip_strip_mined()-&gt;in(LoopNode::EntryControl);
1127 }
1128 
1129 
1130 bool PhaseIdealLoop::identical_backtoback_ifs(Node *n) {
1131   if (!n-&gt;is_If() || n-&gt;is_CountedLoopEnd()) {
1132     return false;
1133   }
1134   if (!n-&gt;in(0)-&gt;is_Region()) {
1135     return false;
1136   }
1137   Node* region = n-&gt;in(0);
1138   Node* dom = idom(region);
1139   if (!dom-&gt;is_If() || dom-&gt;in(1) != n-&gt;in(1)) {
1140     return false;
1141   }
1142   IfNode* dom_if = dom-&gt;as_If();
1143   Node* proj_true = dom_if-&gt;proj_out(1);
1144   Node* proj_false = dom_if-&gt;proj_out(0);
1145 
1146   for (uint i = 1; i &lt; region-&gt;req(); i++) {
1147     if (is_dominator(proj_true, region-&gt;in(i))) {
1148       continue;
1149     }
1150     if (is_dominator(proj_false, region-&gt;in(i))) {
1151       continue;
1152     }
1153     return false;
1154   }
1155 
1156   return true;
1157 }
1158 
1159 
1160 bool PhaseIdealLoop::can_split_if(Node* n_ctrl) {
1161   if (must_throttle_split_if()) {
1162     return false;
1163   }
1164 
1165   // Do not do &#39;split-if&#39; if irreducible loops are present.
1166   if (_has_irreducible_loops) {
1167     return false;
1168   }
1169 
1170   if (merge_point_too_heavy(C, n_ctrl)) {
1171     return false;
1172   }
1173 
1174   // Do not do &#39;split-if&#39; if some paths are dead.  First do dead code
1175   // elimination and then see if its still profitable.
1176   for (uint i = 1; i &lt; n_ctrl-&gt;req(); i++) {
1177     if (n_ctrl-&gt;in(i) == C-&gt;top()) {
1178       return false;
1179     }
1180   }
1181 
1182   // If trying to do a &#39;Split-If&#39; at the loop head, it is only
1183   // profitable if the cmp folds up on BOTH paths.  Otherwise we
1184   // risk peeling a loop forever.
1185 
1186   // CNC - Disabled for now.  Requires careful handling of loop
1187   // body selection for the cloned code.  Also, make sure we check
1188   // for any input path not being in the same loop as n_ctrl.  For
1189   // irreducible loops we cannot check for &#39;n_ctrl-&gt;is_Loop()&#39;
1190   // because the alternative loop entry points won&#39;t be converted
1191   // into LoopNodes.
1192   IdealLoopTree *n_loop = get_loop(n_ctrl);
1193   for (uint j = 1; j &lt; n_ctrl-&gt;req(); j++) {
1194     if (get_loop(n_ctrl-&gt;in(j)) != n_loop) {
1195       return false;
1196     }
1197   }
1198 
1199   // Check for safety of the merge point.
1200   if (!merge_point_safe(n_ctrl)) {
1201     return false;
1202   }
1203 
1204   return true;
1205 }
1206 
1207 // Detect if the node is the inner strip-mined loop
1208 // Return: NULL if it&#39;s not the case, or the exit of outer strip-mined loop
1209 static Node* is_inner_of_stripmined_loop(const Node* out) {
1210   Node* out_le = NULL;
1211 
1212   if (out-&gt;is_CountedLoopEnd()) {
1213       const CountedLoopNode* loop = out-&gt;as_CountedLoopEnd()-&gt;loopnode();
1214 
1215       if (loop != NULL &amp;&amp; loop-&gt;is_strip_mined()) {
1216         out_le = loop-&gt;in(LoopNode::EntryControl)-&gt;as_OuterStripMinedLoop()-&gt;outer_loop_exit();
1217       }
1218   }
1219 
1220   return out_le;
1221 }
1222 
1223 //------------------------------split_if_with_blocks_post----------------------
1224 // Do the real work in a non-recursive function.  CFG hackery wants to be
1225 // in the post-order, so it can dirty the I-DOM info and not use the dirtied
1226 // info.
1227 void PhaseIdealLoop::split_if_with_blocks_post(Node *n) {
1228 
1229   // Cloning Cmp through Phi&#39;s involves the split-if transform.
1230   // FastLock is not used by an If
1231   if (n-&gt;is_Cmp() &amp;&amp; !n-&gt;is_FastLock()) {
1232     Node *n_ctrl = get_ctrl(n);
1233     // Determine if the Node has inputs from some local Phi.
1234     // Returns the block to clone thru.
1235     Node *n_blk = has_local_phi_input(n);
1236     if (n_blk != n_ctrl) {
1237       return;
1238     }
1239 
1240     if (!can_split_if(n_ctrl)) {
1241       return;
1242     }
1243 
1244     if (n-&gt;outcnt() != 1) {
1245       return; // Multiple bool&#39;s from 1 compare?
1246     }
1247     Node *bol = n-&gt;unique_out();
1248     assert(bol-&gt;is_Bool(), &quot;expect a bool here&quot;);
1249     if (bol-&gt;outcnt() != 1) {
1250       return;// Multiple branches from 1 compare?
1251     }
1252     Node *iff = bol-&gt;unique_out();
1253 
1254     // Check some safety conditions
1255     if (iff-&gt;is_If()) {        // Classic split-if?
1256       if (iff-&gt;in(0) != n_ctrl) {
1257         return; // Compare must be in same blk as if
1258       }
1259     } else if (iff-&gt;is_CMove()) { // Trying to split-up a CMOVE
1260       // Can&#39;t split CMove with different control edge.
1261       if (iff-&gt;in(0) != NULL &amp;&amp; iff-&gt;in(0) != n_ctrl ) {
1262         return;
1263       }
1264       if (get_ctrl(iff-&gt;in(2)) == n_ctrl ||
1265           get_ctrl(iff-&gt;in(3)) == n_ctrl) {
1266         return;                 // Inputs not yet split-up
1267       }
1268       if (get_loop(n_ctrl) != get_loop(get_ctrl(iff))) {
1269         return;                 // Loop-invar test gates loop-varying CMOVE
1270       }
1271     } else {
1272       return;  // some other kind of node, such as an Allocate
1273     }
1274 
1275     // When is split-if profitable?  Every &#39;win&#39; on means some control flow
1276     // goes dead, so it&#39;s almost always a win.
1277     int policy = 0;
1278     // Split compare &#39;n&#39; through the merge point if it is profitable
1279     Node *phi = split_thru_phi( n, n_ctrl, policy);
1280     if (!phi) {
1281       return;
1282     }
1283 
1284     // Found a Phi to split thru!
1285     // Replace &#39;n&#39; with the new phi
1286     _igvn.replace_node(n, phi);
1287 
1288     // Now split the bool up thru the phi
1289     Node *bolphi = split_thru_phi(bol, n_ctrl, -1);
1290     guarantee(bolphi != NULL, &quot;null boolean phi node&quot;);
1291 
1292     _igvn.replace_node(bol, bolphi);
1293     assert(iff-&gt;in(1) == bolphi, &quot;&quot;);
1294 
1295     if (bolphi-&gt;Value(&amp;_igvn)-&gt;singleton()) {
1296       return;
1297     }
1298 
1299     // Conditional-move?  Must split up now
1300     if (!iff-&gt;is_If()) {
1301       Node *cmovphi = split_thru_phi(iff, n_ctrl, -1);
1302       _igvn.replace_node(iff, cmovphi);
1303       return;
1304     }
1305 
1306     // Now split the IF
1307     do_split_if(iff);
1308     return;
1309   }
1310 
1311   // Two identical ifs back to back can be merged
1312   if (identical_backtoback_ifs(n) &amp;&amp; can_split_if(n-&gt;in(0))) {
1313     Node *n_ctrl = n-&gt;in(0);
1314     PhiNode* bolphi = PhiNode::make_blank(n_ctrl, n-&gt;in(1));
1315     IfNode* dom_if = idom(n_ctrl)-&gt;as_If();
1316     Node* proj_true = dom_if-&gt;proj_out(1);
1317     Node* proj_false = dom_if-&gt;proj_out(0);
1318     Node* con_true = _igvn.makecon(TypeInt::ONE);
1319     Node* con_false = _igvn.makecon(TypeInt::ZERO);
1320 
1321     for (uint i = 1; i &lt; n_ctrl-&gt;req(); i++) {
1322       if (is_dominator(proj_true, n_ctrl-&gt;in(i))) {
1323         bolphi-&gt;init_req(i, con_true);
1324       } else {
1325         assert(is_dominator(proj_false, n_ctrl-&gt;in(i)), &quot;bad if&quot;);
1326         bolphi-&gt;init_req(i, con_false);
1327       }
1328     }
1329     register_new_node(bolphi, n_ctrl);
1330     _igvn.replace_input_of(n, 1, bolphi);
1331 
1332     // Now split the IF
1333     do_split_if(n);
1334     return;
1335   }
1336 
1337   // Check for an IF ready to split; one that has its
1338   // condition codes input coming from a Phi at the block start.
1339   int n_op = n-&gt;Opcode();
1340 
1341   // Check for an IF being dominated by another IF same test
1342   if (n_op == Op_If ||
1343       n_op == Op_RangeCheck) {
1344     Node *bol = n-&gt;in(1);
1345     uint max = bol-&gt;outcnt();
1346     // Check for same test used more than once?
1347     if (max &gt; 1 &amp;&amp; bol-&gt;is_Bool()) {
1348       // Search up IDOMs to see if this IF is dominated.
1349       Node *cutoff = get_ctrl(bol);
1350 
1351       // Now search up IDOMs till cutoff, looking for a dominating test
1352       Node *prevdom = n;
1353       Node *dom = idom(prevdom);
1354       while (dom != cutoff) {
1355         if (dom-&gt;req() &gt; 1 &amp;&amp; dom-&gt;in(1) == bol &amp;&amp; prevdom-&gt;in(0) == dom) {
1356           // It&#39;s invalid to move control dependent data nodes in the inner
1357           // strip-mined loop, because:
1358           //  1) break validation of LoopNode::verify_strip_mined()
1359           //  2) move code with side-effect in strip-mined loop
1360           // Move to the exit of outer strip-mined loop in that case.
1361           Node* out_le = is_inner_of_stripmined_loop(dom);
1362           if (out_le != NULL) {
1363             prevdom = out_le;
1364           }
1365           // Replace the dominated test with an obvious true or false.
1366           // Place it on the IGVN worklist for later cleanup.
1367           C-&gt;set_major_progress();
1368           dominated_by(prevdom, n, false, true);
1369 #ifndef PRODUCT
1370           if( VerifyLoopOptimizations ) verify();
1371 #endif
1372           return;
1373         }
1374         prevdom = dom;
1375         dom = idom(prevdom);
1376       }
1377     }
1378   }
1379 
1380   // See if a shared loop-varying computation has no loop-varying uses.
1381   // Happens if something is only used for JVM state in uncommon trap exits,
1382   // like various versions of induction variable+offset.  Clone the
1383   // computation per usage to allow it to sink out of the loop.
1384   if (has_ctrl(n) &amp;&amp; !n-&gt;in(0)) {// n not dead and has no control edge (can float about)
1385     Node *n_ctrl = get_ctrl(n);
1386     IdealLoopTree *n_loop = get_loop(n_ctrl);
1387     if( n_loop != _ltree_root ) {
1388       DUIterator_Fast imax, i = n-&gt;fast_outs(imax);
1389       for (; i &lt; imax; i++) {
1390         Node* u = n-&gt;fast_out(i);
1391         if( !has_ctrl(u) )     break; // Found control user
1392         IdealLoopTree *u_loop = get_loop(get_ctrl(u));
1393         if( u_loop == n_loop ) break; // Found loop-varying use
1394         if( n_loop-&gt;is_member( u_loop ) ) break; // Found use in inner loop
1395         if( u-&gt;Opcode() == Op_Opaque1 ) break; // Found loop limit, bugfix for 4677003
1396       }
1397       bool did_break = (i &lt; imax);  // Did we break out of the previous loop?
1398       if (!did_break &amp;&amp; n-&gt;outcnt() &gt; 1) { // All uses in outer loops!
1399         Node *late_load_ctrl = NULL;
1400         if (n-&gt;is_Load()) {
1401           // If n is a load, get and save the result from get_late_ctrl(),
1402           // to be later used in calculating the control for n&#39;s clones.
1403           clear_dom_lca_tags();
1404           late_load_ctrl = get_late_ctrl(n, n_ctrl);
1405         }
1406         // If n is a load, and the late control is the same as the current
1407         // control, then the cloning of n is a pointless exercise, because
1408         // GVN will ensure that we end up where we started.
1409         if (!n-&gt;is_Load() || late_load_ctrl != n_ctrl) {
1410           for (DUIterator_Last jmin, j = n-&gt;last_outs(jmin); j &gt;= jmin; ) {
1411             Node *u = n-&gt;last_out(j); // Clone private computation per use
1412             _igvn.rehash_node_delayed(u);
1413             Node *x = n-&gt;clone(); // Clone computation
1414             Node *x_ctrl = NULL;
1415             if( u-&gt;is_Phi() ) {
1416               // Replace all uses of normal nodes.  Replace Phi uses
1417               // individually, so the separate Nodes can sink down
1418               // different paths.
1419               uint k = 1;
1420               while( u-&gt;in(k) != n ) k++;
1421               u-&gt;set_req( k, x );
1422               // x goes next to Phi input path
1423               x_ctrl = u-&gt;in(0)-&gt;in(k);
1424               --j;
1425             } else {              // Normal use
1426               // Replace all uses
1427               for( uint k = 0; k &lt; u-&gt;req(); k++ ) {
1428                 if( u-&gt;in(k) == n ) {
1429                   u-&gt;set_req( k, x );
1430                   --j;
1431                 }
1432               }
1433               x_ctrl = get_ctrl(u);
1434             }
1435 
1436             // Find control for &#39;x&#39; next to use but not inside inner loops.
1437             // For inner loop uses get the preheader area.
1438             x_ctrl = place_near_use(x_ctrl);
1439 
1440             if (n-&gt;is_Load()) {
1441               // For loads, add a control edge to a CFG node outside of the loop
1442               // to force them to not combine and return back inside the loop
1443               // during GVN optimization (4641526).
1444               //
1445               // Because we are setting the actual control input, factor in
1446               // the result from get_late_ctrl() so we respect any
1447               // anti-dependences. (6233005).
1448               x_ctrl = dom_lca(late_load_ctrl, x_ctrl);
1449 
1450               // Don&#39;t allow the control input to be a CFG splitting node.
1451               // Such nodes should only have ProjNodes as outs, e.g. IfNode
1452               // should only have IfTrueNode and IfFalseNode (4985384).
1453               x_ctrl = find_non_split_ctrl(x_ctrl);
1454 
1455               IdealLoopTree* x_loop = get_loop(x_ctrl);
1456               Node* x_head = x_loop-&gt;_head;
1457               if (x_head-&gt;is_Loop() &amp;&amp; (x_head-&gt;is_OuterStripMinedLoop() || x_head-&gt;as_Loop()-&gt;is_strip_mined()) &amp;&amp; is_dominator(n_ctrl, x_head)) {
1458                 // Anti dependence analysis is sometimes too
1459                 // conservative: a store in the outer strip mined loop
1460                 // can prevent a load from floating out of the outer
1461                 // strip mined loop but the load may not be referenced
1462                 // from the safepoint: loop strip mining verification
1463                 // code reports a problem in that case. Make sure the
1464                 // load is not moved in the outer strip mined loop in
1465                 // that case.
1466                 x_ctrl = x_head-&gt;as_Loop()-&gt;skip_strip_mined()-&gt;in(LoopNode::EntryControl);
1467               }
1468               assert(dom_depth(n_ctrl) &lt;= dom_depth(x_ctrl), &quot;n is later than its clone&quot;);
1469 
1470               x-&gt;set_req(0, x_ctrl);
1471             }
1472             register_new_node(x, x_ctrl);
1473 
1474             // Some institutional knowledge is needed here: &#39;x&#39; is
1475             // yanked because if the optimizer runs GVN on it all the
1476             // cloned x&#39;s will common up and undo this optimization and
1477             // be forced back in the loop.
1478             // I tried setting control edges on the x&#39;s to force them to
1479             // not combine, but the matching gets worried when it tries
1480             // to fold a StoreP and an AddP together (as part of an
1481             // address expression) and the AddP and StoreP have
1482             // different controls.
1483             if (!x-&gt;is_Load() &amp;&amp; !x-&gt;is_DecodeNarrowPtr()) _igvn._worklist.yank(x);
1484           }
1485           _igvn.remove_dead_node(n);
1486         }
1487       }
1488     }
1489   }
1490 
1491   try_move_store_after_loop(n);
1492 
1493   // Check for Opaque2&#39;s who&#39;s loop has disappeared - who&#39;s input is in the
1494   // same loop nest as their output.  Remove &#39;em, they are no longer useful.
1495   if( n_op == Op_Opaque2 &amp;&amp;
1496       n-&gt;in(1) != NULL &amp;&amp;
1497       get_loop(get_ctrl(n)) == get_loop(get_ctrl(n-&gt;in(1))) ) {
1498     _igvn.replace_node( n, n-&gt;in(1) );
1499   }
1500 }
1501 
1502 //------------------------------split_if_with_blocks---------------------------
1503 // Check for aggressive application of &#39;split-if&#39; optimization,
1504 // using basic block level info.
1505 void PhaseIdealLoop::split_if_with_blocks(VectorSet &amp;visited, Node_Stack &amp;nstack) {
1506   Node* root = C-&gt;root();
1507   visited.set(root-&gt;_idx); // first, mark root as visited
1508   // Do pre-visit work for root
1509   Node* n   = split_if_with_blocks_pre(root);
1510   uint  cnt = n-&gt;outcnt();
1511   uint  i   = 0;
1512 
1513   while (true) {
1514     // Visit all children
1515     if (i &lt; cnt) {
1516       Node* use = n-&gt;raw_out(i);
1517       ++i;
1518       if (use-&gt;outcnt() != 0 &amp;&amp; !visited.test_set(use-&gt;_idx)) {
1519         // Now do pre-visit work for this use
1520         use = split_if_with_blocks_pre(use);
1521         nstack.push(n, i); // Save parent and next use&#39;s index.
1522         n   = use;         // Process all children of current use.
1523         cnt = use-&gt;outcnt();
1524         i   = 0;
1525       }
1526     }
1527     else {
1528       // All of n&#39;s children have been processed, complete post-processing.
1529       if (cnt != 0 &amp;&amp; !n-&gt;is_Con()) {
1530         assert(has_node(n), &quot;no dead nodes&quot;);
1531         split_if_with_blocks_post(n);
1532       }
1533       if (must_throttle_split_if()) {
1534         nstack.clear();
1535       }
1536       if (nstack.is_empty()) {
1537         // Finished all nodes on stack.
1538         break;
1539       }
1540       // Get saved parent node and next use&#39;s index. Visit the rest of uses.
1541       n   = nstack.node();
1542       cnt = n-&gt;outcnt();
1543       i   = nstack.index();
1544       nstack.pop();
1545     }
1546   }
1547 }
1548 
1549 
1550 //=============================================================================
1551 //
1552 //                   C L O N E   A   L O O P   B O D Y
1553 //
1554 
1555 //------------------------------clone_iff--------------------------------------
1556 // Passed in a Phi merging (recursively) some nearly equivalent Bool/Cmps.
1557 // &quot;Nearly&quot; because all Nodes have been cloned from the original in the loop,
1558 // but the fall-in edges to the Cmp are different.  Clone bool/Cmp pairs
1559 // through the Phi recursively, and return a Bool.
1560 Node* PhaseIdealLoop::clone_iff(PhiNode *phi, IdealLoopTree *loop) {
1561 
1562   // Convert this Phi into a Phi merging Bools
1563   uint i;
1564   for (i = 1; i &lt; phi-&gt;req(); i++) {
1565     Node *b = phi-&gt;in(i);
1566     if (b-&gt;is_Phi()) {
1567       _igvn.replace_input_of(phi, i, clone_iff(b-&gt;as_Phi(), loop));
1568     } else {
1569       assert(b-&gt;is_Bool() || b-&gt;Opcode() == Op_Opaque4, &quot;&quot;);
1570     }
1571   }
1572 
1573   Node* n = phi-&gt;in(1);
1574   Node* sample_opaque = NULL;
1575   Node *sample_bool = NULL;
1576   if (n-&gt;Opcode() == Op_Opaque4) {
1577     sample_opaque = n;
1578     sample_bool = n-&gt;in(1);
1579     assert(sample_bool-&gt;is_Bool(), &quot;wrong type&quot;);
1580   } else {
1581     sample_bool = n;
1582   }
1583   Node *sample_cmp = sample_bool-&gt;in(1);
1584 
1585   // Make Phis to merge the Cmp&#39;s inputs.
1586   PhiNode *phi1 = new PhiNode(phi-&gt;in(0), Type::TOP);
1587   PhiNode *phi2 = new PhiNode(phi-&gt;in(0), Type::TOP);
1588   for (i = 1; i &lt; phi-&gt;req(); i++) {
1589     Node *n1 = sample_opaque == NULL ? phi-&gt;in(i)-&gt;in(1)-&gt;in(1) : phi-&gt;in(i)-&gt;in(1)-&gt;in(1)-&gt;in(1);
1590     Node *n2 = sample_opaque == NULL ? phi-&gt;in(i)-&gt;in(1)-&gt;in(2) : phi-&gt;in(i)-&gt;in(1)-&gt;in(1)-&gt;in(2);
1591     phi1-&gt;set_req(i, n1);
1592     phi2-&gt;set_req(i, n2);
1593     phi1-&gt;set_type(phi1-&gt;type()-&gt;meet_speculative(n1-&gt;bottom_type()));
1594     phi2-&gt;set_type(phi2-&gt;type()-&gt;meet_speculative(n2-&gt;bottom_type()));
1595   }
1596   // See if these Phis have been made before.
1597   // Register with optimizer
1598   Node *hit1 = _igvn.hash_find_insert(phi1);
1599   if (hit1) {                   // Hit, toss just made Phi
1600     _igvn.remove_dead_node(phi1); // Remove new phi
1601     assert(hit1-&gt;is_Phi(), &quot;&quot; );
1602     phi1 = (PhiNode*)hit1;      // Use existing phi
1603   } else {                      // Miss
1604     _igvn.register_new_node_with_optimizer(phi1);
1605   }
1606   Node *hit2 = _igvn.hash_find_insert(phi2);
1607   if (hit2) {                   // Hit, toss just made Phi
1608     _igvn.remove_dead_node(phi2); // Remove new phi
1609     assert(hit2-&gt;is_Phi(), &quot;&quot; );
1610     phi2 = (PhiNode*)hit2;      // Use existing phi
1611   } else {                      // Miss
1612     _igvn.register_new_node_with_optimizer(phi2);
1613   }
1614   // Register Phis with loop/block info
1615   set_ctrl(phi1, phi-&gt;in(0));
1616   set_ctrl(phi2, phi-&gt;in(0));
1617   // Make a new Cmp
1618   Node *cmp = sample_cmp-&gt;clone();
1619   cmp-&gt;set_req(1, phi1);
1620   cmp-&gt;set_req(2, phi2);
1621   _igvn.register_new_node_with_optimizer(cmp);
1622   set_ctrl(cmp, phi-&gt;in(0));
1623 
1624   // Make a new Bool
1625   Node *b = sample_bool-&gt;clone();
1626   b-&gt;set_req(1,cmp);
1627   _igvn.register_new_node_with_optimizer(b);
1628   set_ctrl(b, phi-&gt;in(0));
1629 
1630   if (sample_opaque != NULL) {
1631     Node* opaque = sample_opaque-&gt;clone();
1632     opaque-&gt;set_req(1, b);
1633     _igvn.register_new_node_with_optimizer(opaque);
1634     set_ctrl(opaque, phi-&gt;in(0));
1635     return opaque;
1636   }
1637 
1638   assert(b-&gt;is_Bool(), &quot;&quot;);
1639   return b;
1640 }
1641 
1642 //------------------------------clone_bool-------------------------------------
1643 // Passed in a Phi merging (recursively) some nearly equivalent Bool/Cmps.
1644 // &quot;Nearly&quot; because all Nodes have been cloned from the original in the loop,
1645 // but the fall-in edges to the Cmp are different.  Clone bool/Cmp pairs
1646 // through the Phi recursively, and return a Bool.
1647 CmpNode *PhaseIdealLoop::clone_bool( PhiNode *phi, IdealLoopTree *loop ) {
1648   uint i;
1649   // Convert this Phi into a Phi merging Bools
1650   for( i = 1; i &lt; phi-&gt;req(); i++ ) {
1651     Node *b = phi-&gt;in(i);
1652     if( b-&gt;is_Phi() ) {
1653       _igvn.replace_input_of(phi, i, clone_bool( b-&gt;as_Phi(), loop ));
1654     } else {
1655       assert( b-&gt;is_Cmp() || b-&gt;is_top(), &quot;inputs are all Cmp or TOP&quot; );
1656     }
1657   }
1658 
1659   Node *sample_cmp = phi-&gt;in(1);
1660 
1661   // Make Phis to merge the Cmp&#39;s inputs.
1662   PhiNode *phi1 = new PhiNode( phi-&gt;in(0), Type::TOP );
1663   PhiNode *phi2 = new PhiNode( phi-&gt;in(0), Type::TOP );
1664   for( uint j = 1; j &lt; phi-&gt;req(); j++ ) {
1665     Node *cmp_top = phi-&gt;in(j); // Inputs are all Cmp or TOP
1666     Node *n1, *n2;
1667     if( cmp_top-&gt;is_Cmp() ) {
1668       n1 = cmp_top-&gt;in(1);
1669       n2 = cmp_top-&gt;in(2);
1670     } else {
1671       n1 = n2 = cmp_top;
1672     }
1673     phi1-&gt;set_req( j, n1 );
1674     phi2-&gt;set_req( j, n2 );
1675     phi1-&gt;set_type(phi1-&gt;type()-&gt;meet_speculative(n1-&gt;bottom_type()));
1676     phi2-&gt;set_type(phi2-&gt;type()-&gt;meet_speculative(n2-&gt;bottom_type()));
1677   }
1678 
1679   // See if these Phis have been made before.
1680   // Register with optimizer
1681   Node *hit1 = _igvn.hash_find_insert(phi1);
1682   if( hit1 ) {                  // Hit, toss just made Phi
1683     _igvn.remove_dead_node(phi1); // Remove new phi
1684     assert( hit1-&gt;is_Phi(), &quot;&quot; );
1685     phi1 = (PhiNode*)hit1;      // Use existing phi
1686   } else {                      // Miss
1687     _igvn.register_new_node_with_optimizer(phi1);
1688   }
1689   Node *hit2 = _igvn.hash_find_insert(phi2);
1690   if( hit2 ) {                  // Hit, toss just made Phi
1691     _igvn.remove_dead_node(phi2); // Remove new phi
1692     assert( hit2-&gt;is_Phi(), &quot;&quot; );
1693     phi2 = (PhiNode*)hit2;      // Use existing phi
1694   } else {                      // Miss
1695     _igvn.register_new_node_with_optimizer(phi2);
1696   }
1697   // Register Phis with loop/block info
1698   set_ctrl(phi1, phi-&gt;in(0));
1699   set_ctrl(phi2, phi-&gt;in(0));
1700   // Make a new Cmp
1701   Node *cmp = sample_cmp-&gt;clone();
1702   cmp-&gt;set_req( 1, phi1 );
1703   cmp-&gt;set_req( 2, phi2 );
1704   _igvn.register_new_node_with_optimizer(cmp);
1705   set_ctrl(cmp, phi-&gt;in(0));
1706 
1707   assert( cmp-&gt;is_Cmp(), &quot;&quot; );
1708   return (CmpNode*)cmp;
1709 }
1710 
1711 //------------------------------sink_use---------------------------------------
1712 // If &#39;use&#39; was in the loop-exit block, it now needs to be sunk
1713 // below the post-loop merge point.
1714 void PhaseIdealLoop::sink_use( Node *use, Node *post_loop ) {
1715   if (!use-&gt;is_CFG() &amp;&amp; get_ctrl(use) == post_loop-&gt;in(2)) {
1716     set_ctrl(use, post_loop);
1717     for (DUIterator j = use-&gt;outs(); use-&gt;has_out(j); j++)
1718       sink_use(use-&gt;out(j), post_loop);
1719   }
1720 }
1721 
1722 void PhaseIdealLoop::clone_loop_handle_data_uses(Node* old, Node_List &amp;old_new,
1723                                                  IdealLoopTree* loop, IdealLoopTree* outer_loop,
1724                                                  Node_List*&amp; split_if_set, Node_List*&amp; split_bool_set,
1725                                                  Node_List*&amp; split_cex_set, Node_List&amp; worklist,
1726                                                  uint new_counter, CloneLoopMode mode) {
1727   Node* nnn = old_new[old-&gt;_idx];
1728   // Copy uses to a worklist, so I can munge the def-use info
1729   // with impunity.
1730   for (DUIterator_Fast jmax, j = old-&gt;fast_outs(jmax); j &lt; jmax; j++)
1731     worklist.push(old-&gt;fast_out(j));
1732 
1733   while( worklist.size() ) {
1734     Node *use = worklist.pop();
1735     if (!has_node(use))  continue; // Ignore dead nodes
1736     if (use-&gt;in(0) == C-&gt;top())  continue;
1737     IdealLoopTree *use_loop = get_loop( has_ctrl(use) ? get_ctrl(use) : use );
1738     // Check for data-use outside of loop - at least one of OLD or USE
1739     // must not be a CFG node.
1740 #ifdef ASSERT
1741     if (loop-&gt;_head-&gt;as_Loop()-&gt;is_strip_mined() &amp;&amp; outer_loop-&gt;is_member(use_loop) &amp;&amp; !loop-&gt;is_member(use_loop) &amp;&amp; old_new[use-&gt;_idx] == NULL) {
1742       Node* sfpt = loop-&gt;_head-&gt;as_CountedLoop()-&gt;outer_safepoint();
1743       assert(mode != IgnoreStripMined, &quot;incorrect cloning mode&quot;);
1744       assert((mode == ControlAroundStripMined &amp;&amp; use == sfpt) || !use-&gt;is_reachable_from_root(), &quot;missed a node&quot;);
1745     }
1746 #endif
1747     if (!loop-&gt;is_member(use_loop) &amp;&amp; !outer_loop-&gt;is_member(use_loop) &amp;&amp; (!old-&gt;is_CFG() || !use-&gt;is_CFG())) {
1748 
1749       // If the Data use is an IF, that means we have an IF outside of the
1750       // loop that is switching on a condition that is set inside of the
1751       // loop.  Happens if people set a loop-exit flag; then test the flag
1752       // in the loop to break the loop, then test is again outside of the
1753       // loop to determine which way the loop exited.
1754       // Loop predicate If node connects to Bool node through Opaque1 node.
1755       if (use-&gt;is_If() || use-&gt;is_CMove() || C-&gt;is_predicate_opaq(use) || use-&gt;Opcode() == Op_Opaque4) {
1756         // Since this code is highly unlikely, we lazily build the worklist
1757         // of such Nodes to go split.
1758         if (!split_if_set) {
1759           split_if_set = new Node_List();
1760         }
1761         split_if_set-&gt;push(use);
1762       }
1763       if (use-&gt;is_Bool()) {
1764         if (!split_bool_set) {
1765           split_bool_set = new Node_List();
1766         }
1767         split_bool_set-&gt;push(use);
1768       }
1769       if (use-&gt;Opcode() == Op_CreateEx) {
1770         if (!split_cex_set) {
1771           split_cex_set = new Node_List();
1772         }
1773         split_cex_set-&gt;push(use);
1774       }
1775 
1776 
1777       // Get &quot;block&quot; use is in
1778       uint idx = 0;
1779       while( use-&gt;in(idx) != old ) idx++;
1780       Node *prev = use-&gt;is_CFG() ? use : get_ctrl(use);
1781       assert(!loop-&gt;is_member(get_loop(prev)) &amp;&amp; !outer_loop-&gt;is_member(get_loop(prev)), &quot;&quot; );
1782       Node *cfg = prev-&gt;_idx &gt;= new_counter
1783         ? prev-&gt;in(2)
1784         : idom(prev);
1785       if( use-&gt;is_Phi() )     // Phi use is in prior block
1786         cfg = prev-&gt;in(idx);  // NOT in block of Phi itself
1787       if (cfg-&gt;is_top()) {    // Use is dead?
1788         _igvn.replace_input_of(use, idx, C-&gt;top());
1789         continue;
1790       }
1791 
1792       // If use is referenced through control edge... (idx == 0)
1793       if (mode == IgnoreStripMined &amp;&amp; idx == 0) {
1794         LoopNode *head = loop-&gt;_head-&gt;as_Loop();
1795         if (head-&gt;is_strip_mined() &amp;&amp; is_dominator(head-&gt;outer_loop_exit(), prev)) {
1796           // That node is outside the inner loop, leave it outside the
1797           // outer loop as well to not confuse verification code.
1798           assert(!loop-&gt;_parent-&gt;is_member(use_loop), &quot;should be out of the outer loop&quot;);
1799           _igvn.replace_input_of(use, 0, head-&gt;outer_loop_exit());
1800           continue;
1801         }
1802       }
1803 
1804       while(!outer_loop-&gt;is_member(get_loop(cfg))) {
1805         prev = cfg;
1806         cfg = cfg-&gt;_idx &gt;= new_counter ? cfg-&gt;in(2) : idom(cfg);
1807       }
1808       // If the use occurs after merging several exits from the loop, then
1809       // old value must have dominated all those exits.  Since the same old
1810       // value was used on all those exits we did not need a Phi at this
1811       // merge point.  NOW we do need a Phi here.  Each loop exit value
1812       // is now merged with the peeled body exit; each exit gets its own
1813       // private Phi and those Phis need to be merged here.
1814       Node *phi;
1815       if( prev-&gt;is_Region() ) {
1816         if( idx == 0 ) {      // Updating control edge?
1817           phi = prev;         // Just use existing control
1818         } else {              // Else need a new Phi
1819           phi = PhiNode::make( prev, old );
1820           // Now recursively fix up the new uses of old!
1821           for( uint i = 1; i &lt; prev-&gt;req(); i++ ) {
1822             worklist.push(phi); // Onto worklist once for each &#39;old&#39; input
1823           }
1824         }
1825       } else {
1826         // Get new RegionNode merging old and new loop exits
1827         prev = old_new[prev-&gt;_idx];
1828         assert( prev, &quot;just made this in step 7&quot; );
1829         if( idx == 0) {      // Updating control edge?
1830           phi = prev;         // Just use existing control
1831         } else {              // Else need a new Phi
1832           // Make a new Phi merging data values properly
1833           phi = PhiNode::make( prev, old );
1834           phi-&gt;set_req( 1, nnn );
1835         }
1836       }
1837       // If inserting a new Phi, check for prior hits
1838       if( idx != 0 ) {
1839         Node *hit = _igvn.hash_find_insert(phi);
1840         if( hit == NULL ) {
1841           _igvn.register_new_node_with_optimizer(phi); // Register new phi
1842         } else {                                      // or
1843           // Remove the new phi from the graph and use the hit
1844           _igvn.remove_dead_node(phi);
1845           phi = hit;                                  // Use existing phi
1846         }
1847         set_ctrl(phi, prev);
1848       }
1849       // Make &#39;use&#39; use the Phi instead of the old loop body exit value
1850       _igvn.replace_input_of(use, idx, phi);
1851       if( use-&gt;_idx &gt;= new_counter ) { // If updating new phis
1852         // Not needed for correctness, but prevents a weak assert
1853         // in AddPNode from tripping (when we end up with different
1854         // base &amp; derived Phis that will become the same after
1855         // IGVN does CSE).
1856         Node *hit = _igvn.hash_find_insert(use);
1857         if( hit )             // Go ahead and re-hash for hits.
1858           _igvn.replace_node( use, hit );
1859       }
1860 
1861       // If &#39;use&#39; was in the loop-exit block, it now needs to be sunk
1862       // below the post-loop merge point.
1863       sink_use( use, prev );
1864     }
1865   }
1866 }
1867 
1868 static void clone_outer_loop_helper(Node* n, const IdealLoopTree *loop, const IdealLoopTree* outer_loop,
1869                                     const Node_List &amp;old_new, Unique_Node_List&amp; wq, PhaseIdealLoop* phase,
1870                                     bool check_old_new) {
1871   for (DUIterator_Fast jmax, j = n-&gt;fast_outs(jmax); j &lt; jmax; j++) {
1872     Node* u = n-&gt;fast_out(j);
1873     assert(check_old_new || old_new[u-&gt;_idx] == NULL, &quot;shouldn&#39;t have been cloned&quot;);
1874     if (!u-&gt;is_CFG() &amp;&amp; (!check_old_new || old_new[u-&gt;_idx] == NULL)) {
1875       Node* c = phase-&gt;get_ctrl(u);
1876       IdealLoopTree* u_loop = phase-&gt;get_loop(c);
1877       assert(!loop-&gt;is_member(u_loop), &quot;can be in outer loop or out of both loops only&quot;);
1878       if (outer_loop-&gt;is_member(u_loop)) {
1879         wq.push(u);
1880       }
1881     }
1882   }
1883 }
1884 
1885 void PhaseIdealLoop::clone_outer_loop(LoopNode* head, CloneLoopMode mode, IdealLoopTree *loop,
1886                                       IdealLoopTree* outer_loop, int dd, Node_List &amp;old_new,
1887                                       Node_List&amp; extra_data_nodes) {
1888   if (head-&gt;is_strip_mined() &amp;&amp; mode != IgnoreStripMined) {
1889     CountedLoopNode* cl = head-&gt;as_CountedLoop();
1890     Node* l = cl-&gt;outer_loop();
1891     Node* tail = cl-&gt;outer_loop_tail();
1892     IfNode* le = cl-&gt;outer_loop_end();
1893     Node* sfpt = cl-&gt;outer_safepoint();
1894     CountedLoopEndNode* cle = cl-&gt;loopexit();
1895     CountedLoopNode* new_cl = old_new[cl-&gt;_idx]-&gt;as_CountedLoop();
1896     CountedLoopEndNode* new_cle = new_cl-&gt;as_CountedLoop()-&gt;loopexit_or_null();
1897     Node* cle_out = cle-&gt;proj_out(false);
1898 
1899     Node* new_sfpt = NULL;
1900     Node* new_cle_out = cle_out-&gt;clone();
1901     old_new.map(cle_out-&gt;_idx, new_cle_out);
1902     if (mode == CloneIncludesStripMined) {
1903       // clone outer loop body
1904       Node* new_l = l-&gt;clone();
1905       Node* new_tail = tail-&gt;clone();
1906       IfNode* new_le = le-&gt;clone()-&gt;as_If();
1907       new_sfpt = sfpt-&gt;clone();
1908 
1909       set_loop(new_l, outer_loop-&gt;_parent);
1910       set_idom(new_l, new_l-&gt;in(LoopNode::EntryControl), dd);
1911       set_loop(new_cle_out, outer_loop-&gt;_parent);
1912       set_idom(new_cle_out, new_cle, dd);
1913       set_loop(new_sfpt, outer_loop-&gt;_parent);
1914       set_idom(new_sfpt, new_cle_out, dd);
1915       set_loop(new_le, outer_loop-&gt;_parent);
1916       set_idom(new_le, new_sfpt, dd);
1917       set_loop(new_tail, outer_loop-&gt;_parent);
1918       set_idom(new_tail, new_le, dd);
1919       set_idom(new_cl, new_l, dd);
1920 
1921       old_new.map(l-&gt;_idx, new_l);
1922       old_new.map(tail-&gt;_idx, new_tail);
1923       old_new.map(le-&gt;_idx, new_le);
1924       old_new.map(sfpt-&gt;_idx, new_sfpt);
1925 
1926       new_l-&gt;set_req(LoopNode::LoopBackControl, new_tail);
1927       new_l-&gt;set_req(0, new_l);
1928       new_tail-&gt;set_req(0, new_le);
1929       new_le-&gt;set_req(0, new_sfpt);
1930       new_sfpt-&gt;set_req(0, new_cle_out);
1931       new_cle_out-&gt;set_req(0, new_cle);
1932       new_cl-&gt;set_req(LoopNode::EntryControl, new_l);
1933 
1934       _igvn.register_new_node_with_optimizer(new_l);
1935       _igvn.register_new_node_with_optimizer(new_tail);
1936       _igvn.register_new_node_with_optimizer(new_le);
1937     } else {
1938       Node *newhead = old_new[loop-&gt;_head-&gt;_idx];
1939       newhead-&gt;as_Loop()-&gt;clear_strip_mined();
1940       _igvn.replace_input_of(newhead, LoopNode::EntryControl, newhead-&gt;in(LoopNode::EntryControl)-&gt;in(LoopNode::EntryControl));
1941       set_idom(newhead, newhead-&gt;in(LoopNode::EntryControl), dd);
1942     }
1943     // Look at data node that were assigned a control in the outer
1944     // loop: they are kept in the outer loop by the safepoint so start
1945     // from the safepoint node&#39;s inputs.
1946     IdealLoopTree* outer_loop = get_loop(l);
1947     Node_Stack stack(2);
1948     stack.push(sfpt, 1);
1949     uint new_counter = C-&gt;unique();
1950     while (stack.size() &gt; 0) {
1951       Node* n = stack.node();
1952       uint i = stack.index();
1953       while (i &lt; n-&gt;req() &amp;&amp;
1954              (n-&gt;in(i) == NULL ||
1955               !has_ctrl(n-&gt;in(i)) ||
1956               get_loop(get_ctrl(n-&gt;in(i))) != outer_loop ||
1957               (old_new[n-&gt;in(i)-&gt;_idx] != NULL &amp;&amp; old_new[n-&gt;in(i)-&gt;_idx]-&gt;_idx &gt;= new_counter))) {
1958         i++;
1959       }
1960       if (i &lt; n-&gt;req()) {
1961         stack.set_index(i+1);
1962         stack.push(n-&gt;in(i), 0);
1963       } else {
1964         assert(old_new[n-&gt;_idx] == NULL || n == sfpt || old_new[n-&gt;_idx]-&gt;_idx &lt; new_counter, &quot;no clone yet&quot;);
1965         Node* m = n == sfpt ? new_sfpt : n-&gt;clone();
1966         if (m != NULL) {
1967           for (uint i = 0; i &lt; n-&gt;req(); i++) {
1968             if (m-&gt;in(i) != NULL &amp;&amp; old_new[m-&gt;in(i)-&gt;_idx] != NULL) {
1969               m-&gt;set_req(i, old_new[m-&gt;in(i)-&gt;_idx]);
1970             }
1971           }
1972         } else {
1973           assert(n == sfpt &amp;&amp; mode != CloneIncludesStripMined, &quot;where&#39;s the safepoint clone?&quot;);
1974         }
1975         if (n != sfpt) {
1976           extra_data_nodes.push(n);
1977           _igvn.register_new_node_with_optimizer(m);
1978           assert(get_ctrl(n) == cle_out, &quot;what other control?&quot;);
1979           set_ctrl(m, new_cle_out);
1980           old_new.map(n-&gt;_idx, m);
1981         }
1982         stack.pop();
1983       }
1984     }
1985     if (mode == CloneIncludesStripMined) {
1986       _igvn.register_new_node_with_optimizer(new_sfpt);
1987       _igvn.register_new_node_with_optimizer(new_cle_out);
1988     }
1989     // Some other transformation may have pessimistically assign some
1990     // data nodes to the outer loop. Set their control so they are out
1991     // of the outer loop.
1992     ResourceMark rm;
1993     Unique_Node_List wq;
1994     for (uint i = 0; i &lt; extra_data_nodes.size(); i++) {
1995       Node* old = extra_data_nodes.at(i);
1996       clone_outer_loop_helper(old, loop, outer_loop, old_new, wq, this, true);
1997     }
1998     Node* new_ctrl = cl-&gt;outer_loop_exit();
1999     assert(get_loop(new_ctrl) != outer_loop, &quot;must be out of the loop nest&quot;);
2000     for (uint i = 0; i &lt; wq.size(); i++) {
2001       Node* n = wq.at(i);
2002       set_ctrl(n, new_ctrl);
2003       clone_outer_loop_helper(n, loop, outer_loop, old_new, wq, this, false);
2004     }
2005   } else {
2006     Node *newhead = old_new[loop-&gt;_head-&gt;_idx];
2007     set_idom(newhead, newhead-&gt;in(LoopNode::EntryControl), dd);
2008   }
2009 }
2010 
2011 //------------------------------clone_loop-------------------------------------
2012 //
2013 //                   C L O N E   A   L O O P   B O D Y
2014 //
2015 // This is the basic building block of the loop optimizations.  It clones an
2016 // entire loop body.  It makes an old_new loop body mapping; with this mapping
2017 // you can find the new-loop equivalent to an old-loop node.  All new-loop
2018 // nodes are exactly equal to their old-loop counterparts, all edges are the
2019 // same.  All exits from the old-loop now have a RegionNode that merges the
2020 // equivalent new-loop path.  This is true even for the normal &quot;loop-exit&quot;
2021 // condition.  All uses of loop-invariant old-loop values now come from (one
2022 // or more) Phis that merge their new-loop equivalents.
2023 //
2024 // This operation leaves the graph in an illegal state: there are two valid
2025 // control edges coming from the loop pre-header to both loop bodies.  I&#39;ll
2026 // definitely have to hack the graph after running this transform.
2027 //
2028 // From this building block I will further edit edges to perform loop peeling
2029 // or loop unrolling or iteration splitting (Range-Check-Elimination), etc.
2030 //
2031 // Parameter side_by_size_idom:
2032 //   When side_by_size_idom is NULL, the dominator tree is constructed for
2033 //      the clone loop to dominate the original.  Used in construction of
2034 //      pre-main-post loop sequence.
2035 //   When nonnull, the clone and original are side-by-side, both are
2036 //      dominated by the side_by_side_idom node.  Used in construction of
2037 //      unswitched loops.
2038 void PhaseIdealLoop::clone_loop( IdealLoopTree *loop, Node_List &amp;old_new, int dd,
2039                                 CloneLoopMode mode, Node* side_by_side_idom) {
2040 
2041   LoopNode* head = loop-&gt;_head-&gt;as_Loop();
2042   head-&gt;verify_strip_mined(1);
2043 
2044   if (C-&gt;do_vector_loop() &amp;&amp; PrintOpto) {
2045     const char* mname = C-&gt;method()-&gt;name()-&gt;as_quoted_ascii();
2046     if (mname != NULL) {
2047       tty-&gt;print(&quot;PhaseIdealLoop::clone_loop: for vectorize method %s\n&quot;, mname);
2048     }
2049   }
2050 
2051   CloneMap&amp; cm = C-&gt;clone_map();
2052   Dict* dict = cm.dict();
2053   if (C-&gt;do_vector_loop()) {
2054     cm.set_clone_idx(cm.max_gen()+1);
2055 #ifndef PRODUCT
2056     if (PrintOpto) {
2057       tty-&gt;print_cr(&quot;PhaseIdealLoop::clone_loop: _clone_idx %d&quot;, cm.clone_idx());
2058       loop-&gt;dump_head();
2059     }
2060 #endif
2061   }
2062 
2063   // Step 1: Clone the loop body.  Make the old-&gt;new mapping.
2064   uint i;
2065   for( i = 0; i &lt; loop-&gt;_body.size(); i++ ) {
2066     Node *old = loop-&gt;_body.at(i);
2067     Node *nnn = old-&gt;clone();
2068     old_new.map( old-&gt;_idx, nnn );
2069     if (C-&gt;do_vector_loop()) {
2070       cm.verify_insert_and_clone(old, nnn, cm.clone_idx());
2071     }
2072     _igvn.register_new_node_with_optimizer(nnn);
2073   }
2074 
2075   IdealLoopTree* outer_loop = (head-&gt;is_strip_mined() &amp;&amp; mode != IgnoreStripMined) ? get_loop(head-&gt;as_CountedLoop()-&gt;outer_loop()) : loop;
2076 
2077   // Step 2: Fix the edges in the new body.  If the old input is outside the
2078   // loop use it.  If the old input is INside the loop, use the corresponding
2079   // new node instead.
2080   for( i = 0; i &lt; loop-&gt;_body.size(); i++ ) {
2081     Node *old = loop-&gt;_body.at(i);
2082     Node *nnn = old_new[old-&gt;_idx];
2083     // Fix CFG/Loop controlling the new node
2084     if (has_ctrl(old)) {
2085       set_ctrl(nnn, old_new[get_ctrl(old)-&gt;_idx]);
2086     } else {
2087       set_loop(nnn, outer_loop-&gt;_parent);
2088       if (old-&gt;outcnt() &gt; 0) {
2089         set_idom( nnn, old_new[idom(old)-&gt;_idx], dd );
2090       }
2091     }
2092     // Correct edges to the new node
2093     for( uint j = 0; j &lt; nnn-&gt;req(); j++ ) {
2094         Node *n = nnn-&gt;in(j);
2095         if( n ) {
2096           IdealLoopTree *old_in_loop = get_loop( has_ctrl(n) ? get_ctrl(n) : n );
2097           if( loop-&gt;is_member( old_in_loop ) )
2098             nnn-&gt;set_req(j, old_new[n-&gt;_idx]);
2099         }
2100     }
2101     _igvn.hash_find_insert(nnn);
2102   }
2103 
2104   Node_List extra_data_nodes; // data nodes in the outer strip mined loop
2105   clone_outer_loop(head, mode, loop, outer_loop, dd, old_new, extra_data_nodes);
2106 
2107   // Step 3: Now fix control uses.  Loop varying control uses have already
2108   // been fixed up (as part of all input edges in Step 2).  Loop invariant
2109   // control uses must be either an IfFalse or an IfTrue.  Make a merge
2110   // point to merge the old and new IfFalse/IfTrue nodes; make the use
2111   // refer to this.
2112   Node_List worklist;
2113   uint new_counter = C-&gt;unique();
2114   for( i = 0; i &lt; loop-&gt;_body.size(); i++ ) {
2115     Node* old = loop-&gt;_body.at(i);
2116     if( !old-&gt;is_CFG() ) continue;
2117 
2118     // Copy uses to a worklist, so I can munge the def-use info
2119     // with impunity.
2120     for (DUIterator_Fast jmax, j = old-&gt;fast_outs(jmax); j &lt; jmax; j++)
2121       worklist.push(old-&gt;fast_out(j));
2122 
2123     while( worklist.size() ) {  // Visit all uses
2124       Node *use = worklist.pop();
2125       if (!has_node(use))  continue; // Ignore dead nodes
2126       IdealLoopTree *use_loop = get_loop( has_ctrl(use) ? get_ctrl(use) : use );
2127       if( !loop-&gt;is_member( use_loop ) &amp;&amp; use-&gt;is_CFG() ) {
2128         // Both OLD and USE are CFG nodes here.
2129         assert( use-&gt;is_Proj(), &quot;&quot; );
2130         Node* nnn = old_new[old-&gt;_idx];
2131 
2132         Node* newuse = NULL;
2133         if (head-&gt;is_strip_mined() &amp;&amp; mode != IgnoreStripMined) {
2134           CountedLoopNode* cl = head-&gt;as_CountedLoop();
2135           CountedLoopEndNode* cle = cl-&gt;loopexit();
2136           Node* cle_out = cle-&gt;proj_out_or_null(false);
2137           if (use == cle_out) {
2138             IfNode* le = cl-&gt;outer_loop_end();
2139             use = le-&gt;proj_out(false);
2140             use_loop = get_loop(use);
2141             if (mode == CloneIncludesStripMined) {
2142               nnn = old_new[le-&gt;_idx];
2143             } else {
2144               newuse = old_new[cle_out-&gt;_idx];
2145             }
2146           }
2147         }
2148         if (newuse == NULL) {
2149           newuse = use-&gt;clone();
2150         }
2151 
2152         // Clone the loop exit control projection
2153         if (C-&gt;do_vector_loop()) {
2154           cm.verify_insert_and_clone(use, newuse, cm.clone_idx());
2155         }
2156         newuse-&gt;set_req(0,nnn);
2157         _igvn.register_new_node_with_optimizer(newuse);
2158         set_loop(newuse, use_loop);
2159         set_idom(newuse, nnn, dom_depth(nnn) + 1 );
2160 
2161         // We need a Region to merge the exit from the peeled body and the
2162         // exit from the old loop body.
2163         RegionNode *r = new RegionNode(3);
2164         // Map the old use to the new merge point
2165         old_new.map( use-&gt;_idx, r );
2166         uint dd_r = MIN2(dom_depth(newuse),dom_depth(use));
2167         assert( dd_r &gt;= dom_depth(dom_lca(newuse,use)), &quot;&quot; );
2168 
2169         // The original user of &#39;use&#39; uses &#39;r&#39; instead.
2170         for (DUIterator_Last lmin, l = use-&gt;last_outs(lmin); l &gt;= lmin;) {
2171           Node* useuse = use-&gt;last_out(l);
2172           _igvn.rehash_node_delayed(useuse);
2173           uint uses_found = 0;
2174           if( useuse-&gt;in(0) == use ) {
2175             useuse-&gt;set_req(0, r);
2176             uses_found++;
2177             if( useuse-&gt;is_CFG() ) {
2178               // This is not a dom_depth &gt; dd_r because when new
2179               // control flow is constructed by a loop opt, a node and
2180               // its dominator can end up at the same dom_depth
2181               assert(dom_depth(useuse) &gt;= dd_r, &quot;&quot;);
2182               set_idom(useuse, r, dom_depth(useuse));
2183             }
2184           }
2185           for( uint k = 1; k &lt; useuse-&gt;req(); k++ ) {
2186             if( useuse-&gt;in(k) == use ) {
2187               useuse-&gt;set_req(k, r);
2188               uses_found++;
2189               if (useuse-&gt;is_Loop() &amp;&amp; k == LoopNode::EntryControl) {
2190                 // This is not a dom_depth &gt; dd_r because when new
2191                 // control flow is constructed by a loop opt, a node
2192                 // and its dominator can end up at the same dom_depth
2193                 assert(dom_depth(useuse) &gt;= dd_r , &quot;&quot;);
2194                 set_idom(useuse, r, dom_depth(useuse));
2195               }
2196             }
2197           }
2198           l -= uses_found;    // we deleted 1 or more copies of this edge
2199         }
2200 
2201         // Now finish up &#39;r&#39;
2202         r-&gt;set_req( 1, newuse );
2203         r-&gt;set_req( 2,    use );
2204         _igvn.register_new_node_with_optimizer(r);
2205         set_loop(r, use_loop);
2206         set_idom(r, !side_by_side_idom ? newuse-&gt;in(0) : side_by_side_idom, dd_r);
2207       } // End of if a loop-exit test
2208     }
2209   }
2210 
2211   // Step 4: If loop-invariant use is not control, it must be dominated by a
2212   // loop exit IfFalse/IfTrue.  Find &quot;proper&quot; loop exit.  Make a Region
2213   // there if needed.  Make a Phi there merging old and new used values.
2214   Node_List *split_if_set = NULL;
2215   Node_List *split_bool_set = NULL;
2216   Node_List *split_cex_set = NULL;
2217   for( i = 0; i &lt; loop-&gt;_body.size(); i++ ) {
2218     Node* old = loop-&gt;_body.at(i);
2219     clone_loop_handle_data_uses(old, old_new, loop, outer_loop, split_if_set,
2220                                 split_bool_set, split_cex_set, worklist, new_counter,
2221                                 mode);
2222   }
2223 
2224   for (i = 0; i &lt; extra_data_nodes.size(); i++) {
2225     Node* old = extra_data_nodes.at(i);
2226     clone_loop_handle_data_uses(old, old_new, loop, outer_loop, split_if_set,
2227                                 split_bool_set, split_cex_set, worklist, new_counter,
2228                                 mode);
2229   }
2230 
2231   // Check for IFs that need splitting/cloning.  Happens if an IF outside of
2232   // the loop uses a condition set in the loop.  The original IF probably
2233   // takes control from one or more OLD Regions (which in turn get from NEW
2234   // Regions).  In any case, there will be a set of Phis for each merge point
2235   // from the IF up to where the original BOOL def exists the loop.
2236   if (split_if_set) {
2237     while (split_if_set-&gt;size()) {
2238       Node *iff = split_if_set-&gt;pop();
2239       if (iff-&gt;in(1)-&gt;is_Phi()) {
2240         Node *b = clone_iff(iff-&gt;in(1)-&gt;as_Phi(), loop);
2241         _igvn.replace_input_of(iff, 1, b);
2242       }
2243     }
2244   }
2245   if (split_bool_set) {
2246     while (split_bool_set-&gt;size()) {
2247       Node *b = split_bool_set-&gt;pop();
2248       Node *phi = b-&gt;in(1);
2249       assert(phi-&gt;is_Phi(), &quot;&quot;);
2250       CmpNode *cmp = clone_bool((PhiNode*)phi, loop);
2251       _igvn.replace_input_of(b, 1, cmp);
2252     }
2253   }
2254   if (split_cex_set) {
2255     while (split_cex_set-&gt;size()) {
2256       Node *b = split_cex_set-&gt;pop();
2257       assert(b-&gt;in(0)-&gt;is_Region(), &quot;&quot;);
2258       assert(b-&gt;in(1)-&gt;is_Phi(), &quot;&quot;);
2259       assert(b-&gt;in(0)-&gt;in(0) == b-&gt;in(1)-&gt;in(0), &quot;&quot;);
2260       split_up(b, b-&gt;in(0), NULL);
2261     }
2262   }
2263 
2264 }
2265 
2266 
2267 //---------------------- stride_of_possible_iv -------------------------------------
2268 // Looks for an iff/bool/comp with one operand of the compare
2269 // being a cycle involving an add and a phi,
2270 // with an optional truncation (left-shift followed by a right-shift)
2271 // of the add. Returns zero if not an iv.
2272 int PhaseIdealLoop::stride_of_possible_iv(Node* iff) {
2273   Node* trunc1 = NULL;
2274   Node* trunc2 = NULL;
2275   const TypeInt* ttype = NULL;
2276   if (!iff-&gt;is_If() || iff-&gt;in(1) == NULL || !iff-&gt;in(1)-&gt;is_Bool()) {
2277     return 0;
2278   }
2279   BoolNode* bl = iff-&gt;in(1)-&gt;as_Bool();
2280   Node* cmp = bl-&gt;in(1);
2281   if (!cmp || (cmp-&gt;Opcode() != Op_CmpI &amp;&amp; cmp-&gt;Opcode() != Op_CmpU)) {
2282     return 0;
2283   }
2284   // Must have an invariant operand
2285   if (is_member(get_loop(iff), get_ctrl(cmp-&gt;in(2)))) {
2286     return 0;
2287   }
2288   Node* add2 = NULL;
2289   Node* cmp1 = cmp-&gt;in(1);
2290   if (cmp1-&gt;is_Phi()) {
2291     // (If (Bool (CmpX phi:(Phi ...(Optional-trunc(AddI phi add2))) )))
2292     Node* phi = cmp1;
2293     for (uint i = 1; i &lt; phi-&gt;req(); i++) {
2294       Node* in = phi-&gt;in(i);
2295       Node* add = CountedLoopNode::match_incr_with_optional_truncation(in,
2296                                 &amp;trunc1, &amp;trunc2, &amp;ttype);
2297       if (add &amp;&amp; add-&gt;in(1) == phi) {
2298         add2 = add-&gt;in(2);
2299         break;
2300       }
2301     }
2302   } else {
2303     // (If (Bool (CmpX addtrunc:(Optional-trunc((AddI (Phi ...addtrunc...) add2)) )))
2304     Node* addtrunc = cmp1;
2305     Node* add = CountedLoopNode::match_incr_with_optional_truncation(addtrunc,
2306                                 &amp;trunc1, &amp;trunc2, &amp;ttype);
2307     if (add &amp;&amp; add-&gt;in(1)-&gt;is_Phi()) {
2308       Node* phi = add-&gt;in(1);
2309       for (uint i = 1; i &lt; phi-&gt;req(); i++) {
2310         if (phi-&gt;in(i) == addtrunc) {
2311           add2 = add-&gt;in(2);
2312           break;
2313         }
2314       }
2315     }
2316   }
2317   if (add2 != NULL) {
2318     const TypeInt* add2t = _igvn.type(add2)-&gt;is_int();
2319     if (add2t-&gt;is_con()) {
2320       return add2t-&gt;get_con();
2321     }
2322   }
2323   return 0;
2324 }
2325 
2326 
2327 //---------------------- stay_in_loop -------------------------------------
2328 // Return the (unique) control output node that&#39;s in the loop (if it exists.)
2329 Node* PhaseIdealLoop::stay_in_loop( Node* n, IdealLoopTree *loop) {
2330   Node* unique = NULL;
2331   if (!n) return NULL;
2332   for (DUIterator_Fast imax, i = n-&gt;fast_outs(imax); i &lt; imax; i++) {
2333     Node* use = n-&gt;fast_out(i);
2334     if (!has_ctrl(use) &amp;&amp; loop-&gt;is_member(get_loop(use))) {
2335       if (unique != NULL) {
2336         return NULL;
2337       }
2338       unique = use;
2339     }
2340   }
2341   return unique;
2342 }
2343 
2344 //------------------------------ register_node -------------------------------------
2345 // Utility to register node &quot;n&quot; with PhaseIdealLoop
2346 void PhaseIdealLoop::register_node(Node* n, IdealLoopTree *loop, Node* pred, int ddepth) {
2347   _igvn.register_new_node_with_optimizer(n);
2348   loop-&gt;_body.push(n);
2349   if (n-&gt;is_CFG()) {
2350     set_loop(n, loop);
2351     set_idom(n, pred, ddepth);
2352   } else {
2353     set_ctrl(n, pred);
2354   }
2355 }
2356 
2357 //------------------------------ proj_clone -------------------------------------
2358 // Utility to create an if-projection
2359 ProjNode* PhaseIdealLoop::proj_clone(ProjNode* p, IfNode* iff) {
2360   ProjNode* c = p-&gt;clone()-&gt;as_Proj();
2361   c-&gt;set_req(0, iff);
2362   return c;
2363 }
2364 
2365 //------------------------------ short_circuit_if -------------------------------------
2366 // Force the iff control output to be the live_proj
2367 Node* PhaseIdealLoop::short_circuit_if(IfNode* iff, ProjNode* live_proj) {
2368   guarantee(live_proj != NULL, &quot;null projection&quot;);
2369   int proj_con = live_proj-&gt;_con;
2370   assert(proj_con == 0 || proj_con == 1, &quot;false or true projection&quot;);
2371   Node *con = _igvn.intcon(proj_con);
2372   set_ctrl(con, C-&gt;root());
2373   if (iff) {
2374     iff-&gt;set_req(1, con);
2375   }
2376   return con;
2377 }
2378 
2379 //------------------------------ insert_if_before_proj -------------------------------------
2380 // Insert a new if before an if projection (* - new node)
2381 //
2382 // before
2383 //           if(test)
2384 //           /     \
2385 //          v       v
2386 //    other-proj   proj (arg)
2387 //
2388 // after
2389 //           if(test)
2390 //           /     \
2391 //          /       v
2392 //         |      * proj-clone
2393 //         v          |
2394 //    other-proj      v
2395 //                * new_if(relop(cmp[IU](left,right)))
2396 //                  /  \
2397 //                 v    v
2398 //         * new-proj  proj
2399 //         (returned)
2400 //
2401 ProjNode* PhaseIdealLoop::insert_if_before_proj(Node* left, bool Signed, BoolTest::mask relop, Node* right, ProjNode* proj) {
2402   IfNode* iff = proj-&gt;in(0)-&gt;as_If();
2403   IdealLoopTree *loop = get_loop(proj);
2404   ProjNode *other_proj = iff-&gt;proj_out(!proj-&gt;is_IfTrue())-&gt;as_Proj();
2405   int ddepth = dom_depth(proj);
2406 
2407   _igvn.rehash_node_delayed(iff);
2408   _igvn.rehash_node_delayed(proj);
2409 
2410   proj-&gt;set_req(0, NULL);  // temporary disconnect
2411   ProjNode* proj2 = proj_clone(proj, iff);
2412   register_node(proj2, loop, iff, ddepth);
2413 
2414   Node* cmp = Signed ? (Node*) new CmpINode(left, right) : (Node*) new CmpUNode(left, right);
2415   register_node(cmp, loop, proj2, ddepth);
2416 
2417   BoolNode* bol = new BoolNode(cmp, relop);
2418   register_node(bol, loop, proj2, ddepth);
2419 
2420   int opcode = iff-&gt;Opcode();
2421   assert(opcode == Op_If || opcode == Op_RangeCheck, &quot;unexpected opcode&quot;);
2422   IfNode* new_if = (opcode == Op_If) ? new IfNode(proj2, bol, iff-&gt;_prob, iff-&gt;_fcnt):
2423     new RangeCheckNode(proj2, bol, iff-&gt;_prob, iff-&gt;_fcnt);
2424   register_node(new_if, loop, proj2, ddepth);
2425 
2426   proj-&gt;set_req(0, new_if); // reattach
2427   set_idom(proj, new_if, ddepth);
2428 
2429   ProjNode* new_exit = proj_clone(other_proj, new_if)-&gt;as_Proj();
2430   guarantee(new_exit != NULL, &quot;null exit node&quot;);
2431   register_node(new_exit, get_loop(other_proj), new_if, ddepth);
2432 
2433   return new_exit;
2434 }
2435 
2436 //------------------------------ insert_region_before_proj -------------------------------------
2437 // Insert a region before an if projection (* - new node)
2438 //
2439 // before
2440 //           if(test)
2441 //          /      |
2442 //         v       |
2443 //       proj      v
2444 //               other-proj
2445 //
2446 // after
2447 //           if(test)
2448 //          /      |
2449 //         v       |
2450 // * proj-clone    v
2451 //         |     other-proj
2452 //         v
2453 // * new-region
2454 //         |
2455 //         v
2456 // *      dum_if
2457 //       /     \
2458 //      v       \
2459 // * dum-proj    v
2460 //              proj
2461 //
2462 RegionNode* PhaseIdealLoop::insert_region_before_proj(ProjNode* proj) {
2463   IfNode* iff = proj-&gt;in(0)-&gt;as_If();
2464   IdealLoopTree *loop = get_loop(proj);
2465   ProjNode *other_proj = iff-&gt;proj_out(!proj-&gt;is_IfTrue())-&gt;as_Proj();
2466   int ddepth = dom_depth(proj);
2467 
2468   _igvn.rehash_node_delayed(iff);
2469   _igvn.rehash_node_delayed(proj);
2470 
2471   proj-&gt;set_req(0, NULL);  // temporary disconnect
2472   ProjNode* proj2 = proj_clone(proj, iff);
2473   register_node(proj2, loop, iff, ddepth);
2474 
2475   RegionNode* reg = new RegionNode(2);
2476   reg-&gt;set_req(1, proj2);
2477   register_node(reg, loop, iff, ddepth);
2478 
2479   IfNode* dum_if = new IfNode(reg, short_circuit_if(NULL, proj), iff-&gt;_prob, iff-&gt;_fcnt);
2480   register_node(dum_if, loop, reg, ddepth);
2481 
2482   proj-&gt;set_req(0, dum_if); // reattach
2483   set_idom(proj, dum_if, ddepth);
2484 
2485   ProjNode* dum_proj = proj_clone(other_proj, dum_if);
2486   register_node(dum_proj, loop, dum_if, ddepth);
2487 
2488   return reg;
2489 }
2490 
2491 //------------------------------ insert_cmpi_loop_exit -------------------------------------
2492 // Clone a signed compare loop exit from an unsigned compare and
2493 // insert it before the unsigned cmp on the stay-in-loop path.
2494 // All new nodes inserted in the dominator tree between the original
2495 // if and it&#39;s projections.  The original if test is replaced with
2496 // a constant to force the stay-in-loop path.
2497 //
2498 // This is done to make sure that the original if and it&#39;s projections
2499 // still dominate the same set of control nodes, that the ctrl() relation
2500 // from data nodes to them is preserved, and that their loop nesting is
2501 // preserved.
2502 //
2503 // before
2504 //          if(i &lt;u limit)    unsigned compare loop exit
2505 //         /       |
2506 //        v        v
2507 //   exit-proj   stay-in-loop-proj
2508 //
2509 // after
2510 //          if(stay-in-loop-const)  original if
2511 //         /       |
2512 //        /        v
2513 //       /  if(i &lt;  limit)    new signed test
2514 //      /  /       |
2515 //     /  /        v
2516 //    /  /  if(i &lt;u limit)    new cloned unsigned test
2517 //   /  /   /      |
2518 //   v  v  v       |
2519 //    region       |
2520 //        |        |
2521 //      dum-if     |
2522 //     /  |        |
2523 // ether  |        |
2524 //        v        v
2525 //   exit-proj   stay-in-loop-proj
2526 //
2527 IfNode* PhaseIdealLoop::insert_cmpi_loop_exit(IfNode* if_cmpu, IdealLoopTree *loop) {
2528   const bool Signed   = true;
2529   const bool Unsigned = false;
2530 
2531   BoolNode* bol = if_cmpu-&gt;in(1)-&gt;as_Bool();
2532   if (bol-&gt;_test._test != BoolTest::lt) return NULL;
2533   CmpNode* cmpu = bol-&gt;in(1)-&gt;as_Cmp();
2534   if (cmpu-&gt;Opcode() != Op_CmpU) return NULL;
2535   int stride = stride_of_possible_iv(if_cmpu);
2536   if (stride == 0) return NULL;
2537 
2538   Node* lp_proj = stay_in_loop(if_cmpu, loop);
2539   guarantee(lp_proj != NULL, &quot;null loop node&quot;);
2540 
2541   ProjNode* lp_continue = lp_proj-&gt;as_Proj();
2542   ProjNode* lp_exit     = if_cmpu-&gt;proj_out(!lp_continue-&gt;is_IfTrue())-&gt;as_Proj();
2543 
2544   Node* limit = NULL;
2545   if (stride &gt; 0) {
2546     limit = cmpu-&gt;in(2);
2547   } else {
2548     limit = _igvn.makecon(TypeInt::ZERO);
2549     set_ctrl(limit, C-&gt;root());
2550   }
2551   // Create a new region on the exit path
2552   RegionNode* reg = insert_region_before_proj(lp_exit);
2553   guarantee(reg != NULL, &quot;null region node&quot;);
2554 
2555   // Clone the if-cmpu-true-false using a signed compare
2556   BoolTest::mask rel_i = stride &gt; 0 ? bol-&gt;_test._test : BoolTest::ge;
2557   ProjNode* cmpi_exit = insert_if_before_proj(cmpu-&gt;in(1), Signed, rel_i, limit, lp_continue);
2558   reg-&gt;add_req(cmpi_exit);
2559 
2560   // Clone the if-cmpu-true-false
2561   BoolTest::mask rel_u = bol-&gt;_test._test;
2562   ProjNode* cmpu_exit = insert_if_before_proj(cmpu-&gt;in(1), Unsigned, rel_u, cmpu-&gt;in(2), lp_continue);
2563   reg-&gt;add_req(cmpu_exit);
2564 
2565   // Force original if to stay in loop.
2566   short_circuit_if(if_cmpu, lp_continue);
2567 
2568   return cmpi_exit-&gt;in(0)-&gt;as_If();
2569 }
2570 
2571 //------------------------------ remove_cmpi_loop_exit -------------------------------------
2572 // Remove a previously inserted signed compare loop exit.
2573 void PhaseIdealLoop::remove_cmpi_loop_exit(IfNode* if_cmp, IdealLoopTree *loop) {
2574   Node* lp_proj = stay_in_loop(if_cmp, loop);
2575   assert(if_cmp-&gt;in(1)-&gt;in(1)-&gt;Opcode() == Op_CmpI &amp;&amp;
2576          stay_in_loop(lp_proj, loop)-&gt;is_If() &amp;&amp;
2577          stay_in_loop(lp_proj, loop)-&gt;in(1)-&gt;in(1)-&gt;Opcode() == Op_CmpU, &quot;inserted cmpi before cmpu&quot;);
2578   Node *con = _igvn.makecon(lp_proj-&gt;is_IfTrue() ? TypeInt::ONE : TypeInt::ZERO);
2579   set_ctrl(con, C-&gt;root());
2580   if_cmp-&gt;set_req(1, con);
2581 }
2582 
2583 //------------------------------ scheduled_nodelist -------------------------------------
2584 // Create a post order schedule of nodes that are in the
2585 // &quot;member&quot; set.  The list is returned in &quot;sched&quot;.
2586 // The first node in &quot;sched&quot; is the loop head, followed by
2587 // nodes which have no inputs in the &quot;member&quot; set, and then
2588 // followed by the nodes that have an immediate input dependence
2589 // on a node in &quot;sched&quot;.
2590 void PhaseIdealLoop::scheduled_nodelist( IdealLoopTree *loop, VectorSet&amp; member, Node_List &amp;sched ) {
2591 
2592   assert(member.test(loop-&gt;_head-&gt;_idx), &quot;loop head must be in member set&quot;);
2593   VectorSet visited;
2594   Node_Stack nstack(loop-&gt;_body.size());
2595 
2596   Node* n  = loop-&gt;_head;  // top of stack is cached in &quot;n&quot;
2597   uint idx = 0;
2598   visited.set(n-&gt;_idx);
2599 
2600   // Initially push all with no inputs from within member set
2601   for(uint i = 0; i &lt; loop-&gt;_body.size(); i++ ) {
2602     Node *elt = loop-&gt;_body.at(i);
2603     if (member.test(elt-&gt;_idx)) {
2604       bool found = false;
2605       for (uint j = 0; j &lt; elt-&gt;req(); j++) {
2606         Node* def = elt-&gt;in(j);
2607         if (def &amp;&amp; member.test(def-&gt;_idx) &amp;&amp; def != elt) {
2608           found = true;
2609           break;
2610         }
2611       }
2612       if (!found &amp;&amp; elt != loop-&gt;_head) {
2613         nstack.push(n, idx);
2614         n = elt;
2615         assert(!visited.test(n-&gt;_idx), &quot;not seen yet&quot;);
2616         visited.set(n-&gt;_idx);
2617       }
2618     }
2619   }
2620 
2621   // traverse out&#39;s that are in the member set
2622   while (true) {
2623     if (idx &lt; n-&gt;outcnt()) {
2624       Node* use = n-&gt;raw_out(idx);
2625       idx++;
2626       if (!visited.test_set(use-&gt;_idx)) {
2627         if (member.test(use-&gt;_idx)) {
2628           nstack.push(n, idx);
2629           n = use;
2630           idx = 0;
2631         }
2632       }
2633     } else {
2634       // All outputs processed
2635       sched.push(n);
2636       if (nstack.is_empty()) break;
2637       n   = nstack.node();
2638       idx = nstack.index();
2639       nstack.pop();
2640     }
2641   }
2642 }
2643 
2644 
2645 //------------------------------ has_use_in_set -------------------------------------
2646 // Has a use in the vector set
2647 bool PhaseIdealLoop::has_use_in_set( Node* n, VectorSet&amp; vset ) {
2648   for (DUIterator_Fast jmax, j = n-&gt;fast_outs(jmax); j &lt; jmax; j++) {
2649     Node* use = n-&gt;fast_out(j);
2650     if (vset.test(use-&gt;_idx)) {
2651       return true;
2652     }
2653   }
2654   return false;
2655 }
2656 
2657 
2658 //------------------------------ has_use_internal_to_set -------------------------------------
2659 // Has use internal to the vector set (ie. not in a phi at the loop head)
2660 bool PhaseIdealLoop::has_use_internal_to_set( Node* n, VectorSet&amp; vset, IdealLoopTree *loop ) {
2661   Node* head  = loop-&gt;_head;
2662   for (DUIterator_Fast jmax, j = n-&gt;fast_outs(jmax); j &lt; jmax; j++) {
2663     Node* use = n-&gt;fast_out(j);
2664     if (vset.test(use-&gt;_idx) &amp;&amp; !(use-&gt;is_Phi() &amp;&amp; use-&gt;in(0) == head)) {
2665       return true;
2666     }
2667   }
2668   return false;
2669 }
2670 
2671 
2672 //------------------------------ clone_for_use_outside_loop -------------------------------------
2673 // clone &quot;n&quot; for uses that are outside of loop
2674 int PhaseIdealLoop::clone_for_use_outside_loop( IdealLoopTree *loop, Node* n, Node_List&amp; worklist ) {
2675   int cloned = 0;
2676   assert(worklist.size() == 0, &quot;should be empty&quot;);
2677   for (DUIterator_Fast jmax, j = n-&gt;fast_outs(jmax); j &lt; jmax; j++) {
2678     Node* use = n-&gt;fast_out(j);
2679     if( !loop-&gt;is_member(get_loop(has_ctrl(use) ? get_ctrl(use) : use)) ) {
2680       worklist.push(use);
2681     }
2682   }
2683   while( worklist.size() ) {
2684     Node *use = worklist.pop();
2685     if (!has_node(use) || use-&gt;in(0) == C-&gt;top()) continue;
2686     uint j;
2687     for (j = 0; j &lt; use-&gt;req(); j++) {
2688       if (use-&gt;in(j) == n) break;
2689     }
2690     assert(j &lt; use-&gt;req(), &quot;must be there&quot;);
2691 
2692     // clone &quot;n&quot; and insert it between the inputs of &quot;n&quot; and the use outside the loop
2693     Node* n_clone = n-&gt;clone();
2694     _igvn.replace_input_of(use, j, n_clone);
2695     cloned++;
2696     Node* use_c;
2697     if (!use-&gt;is_Phi()) {
2698       use_c = has_ctrl(use) ? get_ctrl(use) : use-&gt;in(0);
2699     } else {
2700       // Use in a phi is considered a use in the associated predecessor block
2701       use_c = use-&gt;in(0)-&gt;in(j);
2702     }
2703     set_ctrl(n_clone, use_c);
2704     assert(!loop-&gt;is_member(get_loop(use_c)), &quot;should be outside loop&quot;);
2705     get_loop(use_c)-&gt;_body.push(n_clone);
2706     _igvn.register_new_node_with_optimizer(n_clone);
2707 #ifndef PRODUCT
2708     if (TracePartialPeeling) {
2709       tty-&gt;print_cr(&quot;loop exit cloning old: %d new: %d newbb: %d&quot;, n-&gt;_idx, n_clone-&gt;_idx, get_ctrl(n_clone)-&gt;_idx);
2710     }
2711 #endif
2712   }
2713   return cloned;
2714 }
2715 
2716 
2717 //------------------------------ clone_for_special_use_inside_loop -------------------------------------
2718 // clone &quot;n&quot; for special uses that are in the not_peeled region.
2719 // If these def-uses occur in separate blocks, the code generator
2720 // marks the method as not compilable.  For example, if a &quot;BoolNode&quot;
2721 // is in a different basic block than the &quot;IfNode&quot; that uses it, then
2722 // the compilation is aborted in the code generator.
2723 void PhaseIdealLoop::clone_for_special_use_inside_loop( IdealLoopTree *loop, Node* n,
2724                                                         VectorSet&amp; not_peel, Node_List&amp; sink_list, Node_List&amp; worklist ) {
2725   if (n-&gt;is_Phi() || n-&gt;is_Load()) {
2726     return;
2727   }
2728   assert(worklist.size() == 0, &quot;should be empty&quot;);
2729   for (DUIterator_Fast jmax, j = n-&gt;fast_outs(jmax); j &lt; jmax; j++) {
2730     Node* use = n-&gt;fast_out(j);
2731     if ( not_peel.test(use-&gt;_idx) &amp;&amp;
2732          (use-&gt;is_If() || use-&gt;is_CMove() || use-&gt;is_Bool()) &amp;&amp;
2733          use-&gt;in(1) == n)  {
2734       worklist.push(use);
2735     }
2736   }
2737   if (worklist.size() &gt; 0) {
2738     // clone &quot;n&quot; and insert it between inputs of &quot;n&quot; and the use
2739     Node* n_clone = n-&gt;clone();
2740     loop-&gt;_body.push(n_clone);
2741     _igvn.register_new_node_with_optimizer(n_clone);
2742     set_ctrl(n_clone, get_ctrl(n));
2743     sink_list.push(n_clone);
2744     not_peel.set(n_clone-&gt;_idx);
2745 #ifndef PRODUCT
2746     if (TracePartialPeeling) {
2747       tty-&gt;print_cr(&quot;special not_peeled cloning old: %d new: %d&quot;, n-&gt;_idx, n_clone-&gt;_idx);
2748     }
2749 #endif
2750     while( worklist.size() ) {
2751       Node *use = worklist.pop();
2752       _igvn.rehash_node_delayed(use);
2753       for (uint j = 1; j &lt; use-&gt;req(); j++) {
2754         if (use-&gt;in(j) == n) {
2755           use-&gt;set_req(j, n_clone);
2756         }
2757       }
2758     }
2759   }
2760 }
2761 
2762 
2763 //------------------------------ insert_phi_for_loop -------------------------------------
2764 // Insert phi(lp_entry_val, back_edge_val) at use-&gt;in(idx) for loop lp if phi does not already exist
2765 void PhaseIdealLoop::insert_phi_for_loop( Node* use, uint idx, Node* lp_entry_val, Node* back_edge_val, LoopNode* lp ) {
2766   Node *phi = PhiNode::make(lp, back_edge_val);
2767   phi-&gt;set_req(LoopNode::EntryControl, lp_entry_val);
2768   // Use existing phi if it already exists
2769   Node *hit = _igvn.hash_find_insert(phi);
2770   if( hit == NULL ) {
2771     _igvn.register_new_node_with_optimizer(phi);
2772     set_ctrl(phi, lp);
2773   } else {
2774     // Remove the new phi from the graph and use the hit
2775     _igvn.remove_dead_node(phi);
2776     phi = hit;
2777   }
2778   _igvn.replace_input_of(use, idx, phi);
2779 }
2780 
2781 #ifdef ASSERT
2782 //------------------------------ is_valid_loop_partition -------------------------------------
2783 // Validate the loop partition sets: peel and not_peel
2784 bool PhaseIdealLoop::is_valid_loop_partition( IdealLoopTree *loop, VectorSet&amp; peel, Node_List&amp; peel_list,
2785                                               VectorSet&amp; not_peel ) {
2786   uint i;
2787   // Check that peel_list entries are in the peel set
2788   for (i = 0; i &lt; peel_list.size(); i++) {
2789     if (!peel.test(peel_list.at(i)-&gt;_idx)) {
2790       return false;
2791     }
2792   }
2793   // Check at loop members are in one of peel set or not_peel set
2794   for (i = 0; i &lt; loop-&gt;_body.size(); i++ ) {
2795     Node *def  = loop-&gt;_body.at(i);
2796     uint di = def-&gt;_idx;
2797     // Check that peel set elements are in peel_list
2798     if (peel.test(di)) {
2799       if (not_peel.test(di)) {
2800         return false;
2801       }
2802       // Must be in peel_list also
2803       bool found = false;
2804       for (uint j = 0; j &lt; peel_list.size(); j++) {
2805         if (peel_list.at(j)-&gt;_idx == di) {
2806           found = true;
2807           break;
2808         }
2809       }
2810       if (!found) {
2811         return false;
2812       }
2813     } else if (not_peel.test(di)) {
2814       if (peel.test(di)) {
2815         return false;
2816       }
2817     } else {
2818       return false;
2819     }
2820   }
2821   return true;
2822 }
2823 
2824 //------------------------------ is_valid_clone_loop_exit_use -------------------------------------
2825 // Ensure a use outside of loop is of the right form
2826 bool PhaseIdealLoop::is_valid_clone_loop_exit_use( IdealLoopTree *loop, Node* use, uint exit_idx) {
2827   Node *use_c = has_ctrl(use) ? get_ctrl(use) : use;
2828   return (use-&gt;is_Phi() &amp;&amp;
2829           use_c-&gt;is_Region() &amp;&amp; use_c-&gt;req() == 3 &amp;&amp;
2830           (use_c-&gt;in(exit_idx)-&gt;Opcode() == Op_IfTrue ||
2831            use_c-&gt;in(exit_idx)-&gt;Opcode() == Op_IfFalse ||
2832            use_c-&gt;in(exit_idx)-&gt;Opcode() == Op_JumpProj) &amp;&amp;
2833           loop-&gt;is_member( get_loop( use_c-&gt;in(exit_idx)-&gt;in(0) ) ) );
2834 }
2835 
2836 //------------------------------ is_valid_clone_loop_form -------------------------------------
2837 // Ensure that all uses outside of loop are of the right form
2838 bool PhaseIdealLoop::is_valid_clone_loop_form( IdealLoopTree *loop, Node_List&amp; peel_list,
2839                                                uint orig_exit_idx, uint clone_exit_idx) {
2840   uint len = peel_list.size();
2841   for (uint i = 0; i &lt; len; i++) {
2842     Node *def = peel_list.at(i);
2843 
2844     for (DUIterator_Fast jmax, j = def-&gt;fast_outs(jmax); j &lt; jmax; j++) {
2845       Node *use = def-&gt;fast_out(j);
2846       Node *use_c = has_ctrl(use) ? get_ctrl(use) : use;
2847       if (!loop-&gt;is_member(get_loop(use_c))) {
2848         // use is not in the loop, check for correct structure
2849         if (use-&gt;in(0) == def) {
2850           // Okay
2851         } else if (!is_valid_clone_loop_exit_use(loop, use, orig_exit_idx)) {
2852           return false;
2853         }
2854       }
2855     }
2856   }
2857   return true;
2858 }
2859 #endif
2860 
2861 //------------------------------ partial_peel -------------------------------------
2862 // Partially peel (aka loop rotation) the top portion of a loop (called
2863 // the peel section below) by cloning it and placing one copy just before
2864 // the new loop head and the other copy at the bottom of the new loop.
2865 //
2866 //    before                       after                where it came from
2867 //
2868 //    stmt1                        stmt1
2869 //  loop:                          stmt2                     clone
2870 //    stmt2                        if condA goto exitA       clone
2871 //    if condA goto exitA        new_loop:                   new
2872 //    stmt3                        stmt3                     clone
2873 //    if !condB goto loop          if condB goto exitB       clone
2874 //  exitB:                         stmt2                     orig
2875 //    stmt4                        if !condA goto new_loop   orig
2876 //  exitA:                         goto exitA
2877 //                               exitB:
2878 //                                 stmt4
2879 //                               exitA:
2880 //
2881 // Step 1: find the cut point: an exit test on probable
2882 //         induction variable.
2883 // Step 2: schedule (with cloning) operations in the peel
2884 //         section that can be executed after the cut into
2885 //         the section that is not peeled.  This may need
2886 //         to clone operations into exit blocks.  For
2887 //         instance, a reference to A[i] in the not-peel
2888 //         section and a reference to B[i] in an exit block
2889 //         may cause a left-shift of i by 2 to be placed
2890 //         in the peel block.  This step will clone the left
2891 //         shift into the exit block and sink the left shift
2892 //         from the peel to the not-peel section.
2893 // Step 3: clone the loop, retarget the control, and insert
2894 //         phis for values that are live across the new loop
2895 //         head.  This is very dependent on the graph structure
2896 //         from clone_loop.  It creates region nodes for
2897 //         exit control and associated phi nodes for values
2898 //         flow out of the loop through that exit.  The region
2899 //         node is dominated by the clone&#39;s control projection.
2900 //         So the clone&#39;s peel section is placed before the
2901 //         new loop head, and the clone&#39;s not-peel section is
2902 //         forms the top part of the new loop.  The original
2903 //         peel section forms the tail of the new loop.
2904 // Step 4: update the dominator tree and recompute the
2905 //         dominator depth.
2906 //
2907 //                   orig
2908 //
2909 //                   stmt1
2910 //                     |
2911 //                     v
2912 //               loop predicate
2913 //                     |
2914 //                     v
2915 //                   loop&lt;----+
2916 //                     |      |
2917 //                   stmt2    |
2918 //                     |      |
2919 //                     v      |
2920 //                    ifA     |
2921 //                   / |      |
2922 //                  v  v      |
2923 //               false true   ^  &lt;-- last_peel
2924 //               /     |      |
2925 //              /   ===|==cut |
2926 //             /     stmt3    |  &lt;-- first_not_peel
2927 //            /        |      |
2928 //            |        v      |
2929 //            v       ifB     |
2930 //          exitA:   / \      |
2931 //                  /   \     |
2932 //                 v     v    |
2933 //               false true   |
2934 //               /       \    |
2935 //              /         ----+
2936 //             |
2937 //             v
2938 //           exitB:
2939 //           stmt4
2940 //
2941 //
2942 //            after clone loop
2943 //
2944 //                   stmt1
2945 //                     |
2946 //                     v
2947 //               loop predicate
2948 //                 /       \
2949 //        clone   /         \   orig
2950 //               /           \
2951 //              /             \
2952 //             v               v
2953 //   +----&gt;loop                loop&lt;----+
2954 //   |      |                    |      |
2955 //   |    stmt2                stmt2    |
2956 //   |      |                    |      |
2957 //   |      v                    v      |
2958 //   |      ifA                 ifA     |
2959 //   |      | \                / |      |
2960 //   |      v  v              v  v      |
2961 //   ^    true  false      false true   ^  &lt;-- last_peel
2962 //   |      |   ^   \       /    |      |
2963 //   | cut==|==  \   \     /  ===|==cut |
2964 //   |    stmt3   \   \   /    stmt3    |  &lt;-- first_not_peel
2965 //   |      |    dom   | |       |      |
2966 //   |      v      \  1v v2      v      |
2967 //   |      ifB     regionA     ifB     |
2968 //   |      / \        |       / \      |
2969 //   |     /   \       v      /   \     |
2970 //   |    v     v    exitA:  v     v    |
2971 //   |    true  false      false true   |
2972 //   |    /     ^   \      /       \    |
2973 //   +----       \   \    /         ----+
2974 //               dom  \  /
2975 //                 \  1v v2
2976 //                  regionB
2977 //                     |
2978 //                     v
2979 //                   exitB:
2980 //                   stmt4
2981 //
2982 //
2983 //           after partial peel
2984 //
2985 //                  stmt1
2986 //                     |
2987 //                     v
2988 //               loop predicate
2989 //                 /
2990 //        clone   /             orig
2991 //               /          TOP
2992 //              /             \
2993 //             v               v
2994 //    TOP-&gt;loop                loop----+
2995 //          |                    |      |
2996 //        stmt2                stmt2    |
2997 //          |                    |      |
2998 //          v                    v      |
2999 //          ifA                 ifA     |
3000 //          | \                / |      |
3001 //          v  v              v  v      |
3002 //        true  false      false true   |     &lt;-- last_peel
3003 //          |   ^   \       /    +------|---+
3004 //  +-&gt;newloop   \   \     /  === ==cut |   |
3005 //  |     stmt3   \   \   /     TOP     |   |
3006 //  |       |    dom   | |      stmt3   |   | &lt;-- first_not_peel
3007 //  |       v      \  1v v2      v      |   |
3008 //  |       ifB     regionA     ifB     ^   v
3009 //  |       / \        |       / \      |   |
3010 //  |      /   \       v      /   \     |   |
3011 //  |     v     v    exitA:  v     v    |   |
3012 //  |     true  false      false true   |   |
3013 //  |     /     ^   \      /       \    |   |
3014 //  |    |       \   \    /         v   |   |
3015 //  |    |       dom  \  /         TOP  |   |
3016 //  |    |         \  1v v2             |   |
3017 //  ^    v          regionB             |   |
3018 //  |    |             |                |   |
3019 //  |    |             v                ^   v
3020 //  |    |           exitB:             |   |
3021 //  |    |           stmt4              |   |
3022 //  |    +------------&gt;-----------------+   |
3023 //  |                                       |
3024 //  +-----------------&lt;---------------------+
3025 //
3026 //
3027 //              final graph
3028 //
3029 //                  stmt1
3030 //                    |
3031 //                    v
3032 //               loop predicate
3033 //                    |
3034 //                    v
3035 //                  stmt2 clone
3036 //                    |
3037 //                    v
3038 //         ........&gt; ifA clone
3039 //         :        / |
3040 //        dom      /  |
3041 //         :      v   v
3042 //         :  false   true
3043 //         :  |       |
3044 //         :  |       v
3045 //         :  |    newloop&lt;-----+
3046 //         :  |        |        |
3047 //         :  |     stmt3 clone |
3048 //         :  |        |        |
3049 //         :  |        v        |
3050 //         :  |       ifB       |
3051 //         :  |      / \        |
3052 //         :  |     v   v       |
3053 //         :  |  false true     |
3054 //         :  |   |     |       |
3055 //         :  |   v    stmt2    |
3056 //         :  | exitB:  |       |
3057 //         :  | stmt4   v       |
3058 //         :  |       ifA orig  |
3059 //         :  |      /  \       |
3060 //         :  |     /    \      |
3061 //         :  |    v     v      |
3062 //         :  |  false  true    |
3063 //         :  |  /        \     |
3064 //         :  v  v         -----+
3065 //          RegionA
3066 //             |
3067 //             v
3068 //           exitA
3069 //
3070 bool PhaseIdealLoop::partial_peel( IdealLoopTree *loop, Node_List &amp;old_new ) {
3071 
3072   assert(!loop-&gt;_head-&gt;is_CountedLoop(), &quot;Non-counted loop only&quot;);
3073   if (!loop-&gt;_head-&gt;is_Loop()) {
3074     return false;
3075   }
3076   LoopNode *head = loop-&gt;_head-&gt;as_Loop();
3077 
3078   if (head-&gt;is_partial_peel_loop() || head-&gt;partial_peel_has_failed()) {
3079     return false;
3080   }
3081 
3082   // Check for complex exit control
3083   for (uint ii = 0; ii &lt; loop-&gt;_body.size(); ii++) {
3084     Node *n = loop-&gt;_body.at(ii);
3085     int opc = n-&gt;Opcode();
3086     if (n-&gt;is_Call()        ||
3087         opc == Op_Catch     ||
3088         opc == Op_CatchProj ||
3089         opc == Op_Jump      ||
3090         opc == Op_JumpProj) {
3091 #ifndef PRODUCT
3092       if (TracePartialPeeling) {
3093         tty-&gt;print_cr(&quot;\nExit control too complex: lp: %d&quot;, head-&gt;_idx);
3094       }
3095 #endif
3096       return false;
3097     }
3098   }
3099 
3100   int dd = dom_depth(head);
3101 
3102   // Step 1: find cut point
3103 
3104   // Walk up dominators to loop head looking for first loop exit
3105   // which is executed on every path thru loop.
3106   IfNode *peel_if = NULL;
3107   IfNode *peel_if_cmpu = NULL;
3108 
3109   Node *iff = loop-&gt;tail();
3110   while (iff != head) {
3111     if (iff-&gt;is_If()) {
3112       Node *ctrl = get_ctrl(iff-&gt;in(1));
3113       if (ctrl-&gt;is_top()) return false; // Dead test on live IF.
3114       // If loop-varying exit-test, check for induction variable
3115       if (loop-&gt;is_member(get_loop(ctrl)) &amp;&amp;
3116           loop-&gt;is_loop_exit(iff) &amp;&amp;
3117           is_possible_iv_test(iff)) {
3118         Node* cmp = iff-&gt;in(1)-&gt;in(1);
3119         if (cmp-&gt;Opcode() == Op_CmpI) {
3120           peel_if = iff-&gt;as_If();
3121         } else {
3122           assert(cmp-&gt;Opcode() == Op_CmpU, &quot;must be CmpI or CmpU&quot;);
3123           peel_if_cmpu = iff-&gt;as_If();
3124         }
3125       }
3126     }
3127     iff = idom(iff);
3128   }
3129 
3130   // Prefer signed compare over unsigned compare.
3131   IfNode* new_peel_if = NULL;
3132   if (peel_if == NULL) {
3133     if (!PartialPeelAtUnsignedTests || peel_if_cmpu == NULL) {
3134       return false;   // No peel point found
3135     }
3136     new_peel_if = insert_cmpi_loop_exit(peel_if_cmpu, loop);
3137     if (new_peel_if == NULL) {
3138       return false;   // No peel point found
3139     }
3140     peel_if = new_peel_if;
3141   }
3142   Node* last_peel        = stay_in_loop(peel_if, loop);
3143   Node* first_not_peeled = stay_in_loop(last_peel, loop);
3144   if (first_not_peeled == NULL || first_not_peeled == head) {
3145     return false;
3146   }
3147 
3148 #ifndef PRODUCT
3149   if (TraceLoopOpts) {
3150     tty-&gt;print(&quot;PartialPeel  &quot;);
3151     loop-&gt;dump_head();
3152   }
3153 
3154   if (TracePartialPeeling) {
3155     tty-&gt;print_cr(&quot;before partial peel one iteration&quot;);
3156     Node_List wl;
3157     Node* t = head-&gt;in(2);
3158     while (true) {
3159       wl.push(t);
3160       if (t == head) break;
3161       t = idom(t);
3162     }
3163     while (wl.size() &gt; 0) {
3164       Node* tt = wl.pop();
3165       tt-&gt;dump();
3166       if (tt == last_peel) tty-&gt;print_cr(&quot;-- cut --&quot;);
3167     }
3168   }
3169 #endif
3170   VectorSet peel;
3171   VectorSet not_peel;
3172   Node_List peel_list;
3173   Node_List worklist;
3174   Node_List sink_list;
3175 
3176   uint estimate = loop-&gt;est_loop_clone_sz(1);
3177   if (exceeding_node_budget(estimate)) {
3178     return false;
3179   }
3180 
3181   // Set of cfg nodes to peel are those that are executable from
3182   // the head through last_peel.
3183   assert(worklist.size() == 0, &quot;should be empty&quot;);
3184   worklist.push(head);
3185   peel.set(head-&gt;_idx);
3186   while (worklist.size() &gt; 0) {
3187     Node *n = worklist.pop();
3188     if (n != last_peel) {
3189       for (DUIterator_Fast jmax, j = n-&gt;fast_outs(jmax); j &lt; jmax; j++) {
3190         Node* use = n-&gt;fast_out(j);
3191         if (use-&gt;is_CFG() &amp;&amp;
3192             loop-&gt;is_member(get_loop(use)) &amp;&amp;
3193             !peel.test_set(use-&gt;_idx)) {
3194           worklist.push(use);
3195         }
3196       }
3197     }
3198   }
3199 
3200   // Set of non-cfg nodes to peel are those that are control
3201   // dependent on the cfg nodes.
3202   for (uint i = 0; i &lt; loop-&gt;_body.size(); i++) {
3203     Node *n = loop-&gt;_body.at(i);
3204     Node *n_c = has_ctrl(n) ? get_ctrl(n) : n;
3205     if (peel.test(n_c-&gt;_idx)) {
3206       peel.set(n-&gt;_idx);
3207     } else {
3208       not_peel.set(n-&gt;_idx);
3209     }
3210   }
3211 
3212   // Step 2: move operations from the peeled section down into the
3213   //         not-peeled section
3214 
3215   // Get a post order schedule of nodes in the peel region
3216   // Result in right-most operand.
3217   scheduled_nodelist(loop, peel, peel_list);
3218 
3219   assert(is_valid_loop_partition(loop, peel, peel_list, not_peel), &quot;bad partition&quot;);
3220 
3221   // For future check for too many new phis
3222   uint old_phi_cnt = 0;
3223   for (DUIterator_Fast jmax, j = head-&gt;fast_outs(jmax); j &lt; jmax; j++) {
3224     Node* use = head-&gt;fast_out(j);
3225     if (use-&gt;is_Phi()) old_phi_cnt++;
3226   }
3227 
3228 #ifndef PRODUCT
3229   if (TracePartialPeeling) {
3230     tty-&gt;print_cr(&quot;\npeeled list&quot;);
3231   }
3232 #endif
3233 
3234   // Evacuate nodes in peel region into the not_peeled region if possible
3235   uint new_phi_cnt = 0;
3236   uint cloned_for_outside_use = 0;
3237   for (uint i = 0; i &lt; peel_list.size();) {
3238     Node* n = peel_list.at(i);
3239 #ifndef PRODUCT
3240   if (TracePartialPeeling) n-&gt;dump();
3241 #endif
3242     bool incr = true;
3243     if (!n-&gt;is_CFG()) {
3244       if (has_use_in_set(n, not_peel)) {
3245         // If not used internal to the peeled region,
3246         // move &quot;n&quot; from peeled to not_peeled region.
3247         if (!has_use_internal_to_set(n, peel, loop)) {
3248           // if not pinned and not a load (which maybe anti-dependent on a store)
3249           // and not a CMove (Matcher expects only bool-&gt;cmove).
3250           if (n-&gt;in(0) == NULL &amp;&amp; !n-&gt;is_Load() &amp;&amp; !n-&gt;is_CMove()) {
3251             cloned_for_outside_use += clone_for_use_outside_loop(loop, n, worklist);
3252             sink_list.push(n);
3253             peel.remove(n-&gt;_idx);
3254             not_peel.set(n-&gt;_idx);
3255             peel_list.remove(i);
3256             incr = false;
3257 #ifndef PRODUCT
3258             if (TracePartialPeeling) {
3259               tty-&gt;print_cr(&quot;sink to not_peeled region: %d newbb: %d&quot;,
3260                             n-&gt;_idx, get_ctrl(n)-&gt;_idx);
3261             }
3262 #endif
3263           }
3264         } else {
3265           // Otherwise check for special def-use cases that span
3266           // the peel/not_peel boundary such as bool-&gt;if
3267           clone_for_special_use_inside_loop(loop, n, not_peel, sink_list, worklist);
3268           new_phi_cnt++;
3269         }
3270       }
3271     }
3272     if (incr) i++;
3273   }
3274 
3275   estimate += cloned_for_outside_use + new_phi_cnt;
3276   bool exceed_node_budget = !may_require_nodes(estimate);
3277   bool exceed_phi_limit = new_phi_cnt &gt; old_phi_cnt + PartialPeelNewPhiDelta;
3278 
3279   if (exceed_node_budget || exceed_phi_limit) {
3280 #ifndef PRODUCT
3281     if (TracePartialPeeling) {
3282       tty-&gt;print_cr(&quot;\nToo many new phis: %d  old %d new cmpi: %c&quot;,
3283                     new_phi_cnt, old_phi_cnt, new_peel_if != NULL?&#39;T&#39;:&#39;F&#39;);
3284     }
3285 #endif
3286     if (new_peel_if != NULL) {
3287       remove_cmpi_loop_exit(new_peel_if, loop);
3288     }
3289     // Inhibit more partial peeling on this loop
3290     assert(!head-&gt;is_partial_peel_loop(), &quot;not partial peeled&quot;);
3291     head-&gt;mark_partial_peel_failed();
3292     if (cloned_for_outside_use &gt; 0) {
3293       // Terminate this round of loop opts because
3294       // the graph outside this loop was changed.
3295       C-&gt;set_major_progress();
3296       return true;
3297     }
3298     return false;
3299   }
3300 
3301   // Step 3: clone loop, retarget control, and insert new phis
3302 
3303   // Create new loop head for new phis and to hang
3304   // the nodes being moved (sinked) from the peel region.
3305   LoopNode* new_head = new LoopNode(last_peel, last_peel);
3306   new_head-&gt;set_unswitch_count(head-&gt;unswitch_count()); // Preserve
3307   _igvn.register_new_node_with_optimizer(new_head);
3308   assert(first_not_peeled-&gt;in(0) == last_peel, &quot;last_peel &lt;- first_not_peeled&quot;);
3309   _igvn.replace_input_of(first_not_peeled, 0, new_head);
3310   set_loop(new_head, loop);
3311   loop-&gt;_body.push(new_head);
3312   not_peel.set(new_head-&gt;_idx);
3313   set_idom(new_head, last_peel, dom_depth(first_not_peeled));
3314   set_idom(first_not_peeled, new_head, dom_depth(first_not_peeled));
3315 
3316   while (sink_list.size() &gt; 0) {
3317     Node* n = sink_list.pop();
3318     set_ctrl(n, new_head);
3319   }
3320 
3321   assert(is_valid_loop_partition(loop, peel, peel_list, not_peel), &quot;bad partition&quot;);
3322 
3323   clone_loop(loop, old_new, dd, IgnoreStripMined);
3324 
3325   const uint clone_exit_idx = 1;
3326   const uint orig_exit_idx  = 2;
3327   assert(is_valid_clone_loop_form(loop, peel_list, orig_exit_idx, clone_exit_idx), &quot;bad clone loop&quot;);
3328 
3329   Node* head_clone             = old_new[head-&gt;_idx];
3330   LoopNode* new_head_clone     = old_new[new_head-&gt;_idx]-&gt;as_Loop();
3331   Node* orig_tail_clone        = head_clone-&gt;in(2);
3332 
3333   // Add phi if &quot;def&quot; node is in peel set and &quot;use&quot; is not
3334 
3335   for (uint i = 0; i &lt; peel_list.size(); i++) {
3336     Node *def  = peel_list.at(i);
3337     if (!def-&gt;is_CFG()) {
3338       for (DUIterator_Fast jmax, j = def-&gt;fast_outs(jmax); j &lt; jmax; j++) {
3339         Node *use = def-&gt;fast_out(j);
3340         if (has_node(use) &amp;&amp; use-&gt;in(0) != C-&gt;top() &amp;&amp;
3341             (!peel.test(use-&gt;_idx) ||
3342              (use-&gt;is_Phi() &amp;&amp; use-&gt;in(0) == head)) ) {
3343           worklist.push(use);
3344         }
3345       }
3346       while( worklist.size() ) {
3347         Node *use = worklist.pop();
3348         for (uint j = 1; j &lt; use-&gt;req(); j++) {
3349           Node* n = use-&gt;in(j);
3350           if (n == def) {
3351 
3352             // &quot;def&quot; is in peel set, &quot;use&quot; is not in peel set
3353             // or &quot;use&quot; is in the entry boundary (a phi) of the peel set
3354 
3355             Node* use_c = has_ctrl(use) ? get_ctrl(use) : use;
3356 
3357             if ( loop-&gt;is_member(get_loop( use_c )) ) {
3358               // use is in loop
3359               if (old_new[use-&gt;_idx] != NULL) { // null for dead code
3360                 Node* use_clone = old_new[use-&gt;_idx];
3361                 _igvn.replace_input_of(use, j, C-&gt;top());
3362                 insert_phi_for_loop( use_clone, j, old_new[def-&gt;_idx], def, new_head_clone );
3363               }
3364             } else {
3365               assert(is_valid_clone_loop_exit_use(loop, use, orig_exit_idx), &quot;clone loop format&quot;);
3366               // use is not in the loop, check if the live range includes the cut
3367               Node* lp_if = use_c-&gt;in(orig_exit_idx)-&gt;in(0);
3368               if (not_peel.test(lp_if-&gt;_idx)) {
3369                 assert(j == orig_exit_idx, &quot;use from original loop&quot;);
3370                 insert_phi_for_loop( use, clone_exit_idx, old_new[def-&gt;_idx], def, new_head_clone );
3371               }
3372             }
3373           }
3374         }
3375       }
3376     }
3377   }
3378 
3379   // Step 3b: retarget control
3380 
3381   // Redirect control to the new loop head if a cloned node in
3382   // the not_peeled region has control that points into the peeled region.
3383   // This necessary because the cloned peeled region will be outside
3384   // the loop.
3385   //                            from    to
3386   //          cloned-peeled    &lt;---+
3387   //    new_head_clone:            |    &lt;--+
3388   //          cloned-not_peeled  in(0)    in(0)
3389   //          orig-peeled
3390 
3391   for (uint i = 0; i &lt; loop-&gt;_body.size(); i++) {
3392     Node *n = loop-&gt;_body.at(i);
3393     if (!n-&gt;is_CFG()           &amp;&amp; n-&gt;in(0) != NULL        &amp;&amp;
3394         not_peel.test(n-&gt;_idx) &amp;&amp; peel.test(n-&gt;in(0)-&gt;_idx)) {
3395       Node* n_clone = old_new[n-&gt;_idx];
3396       _igvn.replace_input_of(n_clone, 0, new_head_clone);
3397     }
3398   }
3399 
3400   // Backedge of the surviving new_head (the clone) is original last_peel
3401   _igvn.replace_input_of(new_head_clone, LoopNode::LoopBackControl, last_peel);
3402 
3403   // Cut first node in original not_peel set
3404   _igvn.rehash_node_delayed(new_head);                     // Multiple edge updates:
3405   new_head-&gt;set_req(LoopNode::EntryControl,    C-&gt;top());  //   use rehash_node_delayed / set_req instead of
3406   new_head-&gt;set_req(LoopNode::LoopBackControl, C-&gt;top());  //   multiple replace_input_of calls
3407 
3408   // Copy head_clone back-branch info to original head
3409   // and remove original head&#39;s loop entry and
3410   // clone head&#39;s back-branch
3411   _igvn.rehash_node_delayed(head); // Multiple edge updates
3412   head-&gt;set_req(LoopNode::EntryControl,    head_clone-&gt;in(LoopNode::LoopBackControl));
3413   head-&gt;set_req(LoopNode::LoopBackControl, C-&gt;top());
3414   _igvn.replace_input_of(head_clone, LoopNode::LoopBackControl, C-&gt;top());
3415 
3416   // Similarly modify the phis
3417   for (DUIterator_Fast kmax, k = head-&gt;fast_outs(kmax); k &lt; kmax; k++) {
3418     Node* use = head-&gt;fast_out(k);
3419     if (use-&gt;is_Phi() &amp;&amp; use-&gt;outcnt() &gt; 0) {
3420       Node* use_clone = old_new[use-&gt;_idx];
3421       _igvn.rehash_node_delayed(use); // Multiple edge updates
3422       use-&gt;set_req(LoopNode::EntryControl,    use_clone-&gt;in(LoopNode::LoopBackControl));
3423       use-&gt;set_req(LoopNode::LoopBackControl, C-&gt;top());
3424       _igvn.replace_input_of(use_clone, LoopNode::LoopBackControl, C-&gt;top());
3425     }
3426   }
3427 
3428   // Step 4: update dominator tree and dominator depth
3429 
3430   set_idom(head, orig_tail_clone, dd);
3431   recompute_dom_depth();
3432 
3433   // Inhibit more partial peeling on this loop
3434   new_head_clone-&gt;set_partial_peel_loop();
3435   C-&gt;set_major_progress();
3436   loop-&gt;record_for_igvn();
3437 
3438 #ifndef PRODUCT
3439   if (TracePartialPeeling) {
3440     tty-&gt;print_cr(&quot;\nafter partial peel one iteration&quot;);
3441     Node_List wl;
3442     Node* t = last_peel;
3443     while (true) {
3444       wl.push(t);
3445       if (t == head_clone) break;
3446       t = idom(t);
3447     }
3448     while (wl.size() &gt; 0) {
3449       Node* tt = wl.pop();
3450       if (tt == head) tty-&gt;print_cr(&quot;orig head&quot;);
3451       else if (tt == new_head_clone) tty-&gt;print_cr(&quot;new head&quot;);
3452       else if (tt == head_clone) tty-&gt;print_cr(&quot;clone head&quot;);
3453       tt-&gt;dump();
3454     }
3455   }
3456 #endif
3457   return true;
3458 }
3459 
3460 //------------------------------reorg_offsets----------------------------------
3461 // Reorganize offset computations to lower register pressure.  Mostly
3462 // prevent loop-fallout uses of the pre-incremented trip counter (which are
3463 // then alive with the post-incremented trip counter forcing an extra
3464 // register move)
3465 void PhaseIdealLoop::reorg_offsets(IdealLoopTree *loop) {
3466   // Perform it only for canonical counted loops.
3467   // Loop&#39;s shape could be messed up by iteration_split_impl.
3468   if (!loop-&gt;_head-&gt;is_CountedLoop())
3469     return;
3470   if (!loop-&gt;_head-&gt;as_Loop()-&gt;is_valid_counted_loop())
3471     return;
3472 
3473   CountedLoopNode *cl = loop-&gt;_head-&gt;as_CountedLoop();
3474   CountedLoopEndNode *cle = cl-&gt;loopexit();
3475   Node *exit = cle-&gt;proj_out(false);
3476   Node *phi = cl-&gt;phi();
3477 
3478   // Check for the special case when using the pre-incremented trip-counter on
3479   // the fall-out  path (forces the pre-incremented  and post-incremented trip
3480   // counter to be live  at the same time).  Fix this by  adjusting to use the
3481   // post-increment trip counter.
3482 
3483   bool progress = true;
3484   while (progress) {
3485     progress = false;
3486     for (DUIterator_Fast imax, i = phi-&gt;fast_outs(imax); i &lt; imax; i++) {
3487       Node* use = phi-&gt;fast_out(i);   // User of trip-counter
3488       if (!has_ctrl(use))  continue;
3489       Node *u_ctrl = get_ctrl(use);
3490       if (use-&gt;is_Phi()) {
3491         u_ctrl = NULL;
3492         for (uint j = 1; j &lt; use-&gt;req(); j++)
3493           if (use-&gt;in(j) == phi)
3494             u_ctrl = dom_lca(u_ctrl, use-&gt;in(0)-&gt;in(j));
3495       }
3496       IdealLoopTree *u_loop = get_loop(u_ctrl);
3497       // Look for loop-invariant use
3498       if (u_loop == loop) continue;
3499       if (loop-&gt;is_member(u_loop)) continue;
3500       // Check that use is live out the bottom.  Assuming the trip-counter
3501       // update is right at the bottom, uses of of the loop middle are ok.
3502       if (dom_lca(exit, u_ctrl) != exit) continue;
3503       // Hit!  Refactor use to use the post-incremented tripcounter.
3504       // Compute a post-increment tripcounter.
3505       Node* c = exit;
3506       if (cl-&gt;is_strip_mined()) {
3507         IdealLoopTree* outer_loop = get_loop(cl-&gt;outer_loop());
3508         if (!outer_loop-&gt;is_member(u_loop)) {
3509           c = cl-&gt;outer_loop_exit();
3510         }
3511       }
3512       Node *opaq = new Opaque2Node(C, cle-&gt;incr());
3513       register_new_node(opaq, c);
3514       Node *neg_stride = _igvn.intcon(-cle-&gt;stride_con());
3515       set_ctrl(neg_stride, C-&gt;root());
3516       Node *post = new AddINode(opaq, neg_stride);
3517       register_new_node(post, c);
3518       _igvn.rehash_node_delayed(use);
3519       for (uint j = 1; j &lt; use-&gt;req(); j++) {
3520         if (use-&gt;in(j) == phi)
3521           use-&gt;set_req(j, post);
3522       }
3523       // Since DU info changed, rerun loop
3524       progress = true;
3525       break;
3526     }
3527   }
3528 
3529 }
<a name="8" id="anc8"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="8" type="hidden" />
</body>
</html>